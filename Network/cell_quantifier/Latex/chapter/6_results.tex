\chapter {Results}
\label{chap:results}

This chapter provides the learning parameters, graphical representations of the training progressions and results of the test runs performed using the 3- and 4-class datasets with a number of networks based on the original U-Net, each with slight variations. For instance, different loss functions such as the weighted Cross-Entropy loss and the F-Measure are tested, alongside Batch Normalization, shuffling of the training set, different weight initialization schemes and multiple activation functions. Each network's results are compared with the results of the network preceding it in order to find a network that achieves the best possible results on the test data. Finally, the results of the best network are compared with results achieved by the image segmentation methods described in Chapter \textbf{\ref{chap:concepts}} which are not based on neural networks.

	\section{Hardware}
All variants of the U-Net were trained on two Nvidia TITAN X Pascal GPUs (12 GB GDDR5X RAM), using Caffe's CUDA/cuDNN support, training different networks seperately on different GPUs. Further, the workstation used an Intel Xeon E5-2695 CPU with 18 physical cores (36 logical cores with Hyper-threading) running at 2.1 GHz (up to 3.3 GHz) and 128 GB DDR4 RAM.

	\section {Micro and Macro F-Measures as Performance Measures}

\noindent As there are many possible variations of the U-Net architecture, these variations were tested iteratively, choosing the best network of a number of networks and modifying it further. This was done because an exhaustive search for the best combination of weight initialization, activation functions, hyperparameters like the learning rate and techniques such as Dropout and Batch Normalization would have exceeded the time limit of this thesis. Also, at the time of writing, it was not yet known how these different approaches interact precisely. For example, Batch Normalization and specialized weight initialization schemes have the same goal but achieve it in different ways, making it unclear whether one or the other performs better in practice.\\

\noindent To compare the performance of all methods on the validation set with each other, the \textit{Micro} and \textit{Macro} variants of the F-Measure \cite{micromacro} are a suitable way to quantify how well the segmentation works. The Micro F-Measure is defined by the Precision and Recall quantities (see Section \textbf{\ref{subsec:fmeasure}}) of the validation set:

\[ F_{1\mu} = 2 \left ( \frac{\text{PR}_\mu \cdot \text{RC}_\mu}{\text{PR}_\mu + \text{RC}_\mu} \right ) \]

\noindent Here, $\text{PR}_\mu$ and $\text{RC}_\mu$ denote the micro-average Precision and Recall over the entire validation set. $\text{PR}_\mu$ and $\text{RC}_\mu$ are calculated by taking the sum of all TP, FP and FN values for all images and deriving the Precision and Recall over all $n$ validation images from these sums, i.e.

\[ \text{PR}_\mu = \frac{\sum_{i=1}^{n}\text{TP}_i}{\sum_{i=1}^{n} (\text{TP}_i + \text{FP}_i)} \quad \text{ and } \quad \text{RC}_\mu = \frac{\sum_{i=1}^{n} \text{TP}_i}{\sum_{i=1}^{n} (\text{TP}_i + \text{FN}_i)} \]

\noindent The Macro F-Measure likewise is defined as

\[ F_{\text{1M}} = 2 \left ( \frac{\text{PR}_\text{M} \cdot \text{RC}_\text{M}}{\text{PR}_\text{M} + \text{RC}_\text{M}} \right ) \,,\]

\noindent where $\text{PR}_\text{M}$ and $\text{RC}_\text{M}$ are the macro-average Precision and Recall. These are calculated for each sample independently, summed, and averaged over all $n$ samples:

\[ \text{PR}_\text{M} = \frac{1}{n} \sum_{i=1}^{n} \frac{\text{TP}_i}{\text{TP}_i + \text{FP}_i} \text \quad \text{ and } \quad \text{RC}_\text{M} = \frac{1}{n} \sum_{i=1}^{n} \frac{\text{TP}_i}{\text{TP}_i + \text{FN}_i} \] 

\noindent \cite[pp. 317-318]{information_retrieval} highlights that the Micro F-Measure is dominated by ``large'' classes, meaning classes that occur often in the ground truth data. This would shift the focus of the evaluation of the segmentation effectiveness towards whether the primarily large classes are segmented correctly. As most pixels in the validation images are background pixels and the correct segmentation of the non-background class pixels is of more interest, the Macro F-Measure is therefore chosen for assessing which method performs best because it is biased towards smaller classes rather than large ones, but for completeness, both scores are listed.\\


	\section{Segmentation Performance Evaluation}

	\subsubsection{Loss functions}

\noindent The first test run pitted two nearly identical U-Net networks against each other, using ReLU activations and Dropout with $p = 0.5$. The only difference was the choice of the loss function. The \textbf{W} networks used the weighted Cross-Entropy Loss\footnote{The weighted Cross-Entropy loss is not included in the vanilla Caffe implementation and was manually added to the Caffe codebase using outdated code by Ronneberger et al.  for guidance, available here: \url{https://lmb.informatik.uni-freiburg.de/resources/opensource/unet.en.html} .}, while the \textbf{F1} networks employed the multi-class F-Measure by means of a custom Caffe layer written in Python. Both networks were trained for 80,000 iterations (or about 32 epochs) on both the 3- and the 4-class training set (indicated by an additional $\_3$ or $\_4$ suffix in the network name), while testing the network on the respective validation set every 1,000 iterations.

The \textbf{W} network used an initial learning rate of 0.001, a step learning rate decay of a factor $\zeta = 0.1$ every 20,000 iterations and a momentum modifier $\gamma = 0.99$, while the \textbf{F1} network used an initial learning rate of 0.0001, $\zeta = 0.3$ every 20,000 iterations and $\gamma = 0.99$. Both networks used $\text{L}^2$ gradient regularization and a mini-batch size of 5.

The progress of the training is shown in Figure \textbf{\ref{fig:weighted_f1_training}}. The training of the 3- and 4-class \textbf{W} networks took approximately 26 hours each, while the training of the \textbf{F1} networks took approximately 27 hours each because the Python implementation of the F-Measure loss function is run on the CPU, not on the GPU as the native Caffe loss functions such as the Cross-Entropy loss are.\\

\begin {figure}[!htb]
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_3.pgf}}
		\caption{\textbf{W\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_4.pgf}}
		\caption{\textbf{W\_4}}
	\end {subfigure}

	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_f1_3.pgf}}
		\caption{\textbf{F1\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_f1_4.pgf}}
		\caption{\textbf{F1\_4}}
	\end {subfigure}

		\caption[Training progress of the first collection of networks.]{Training progress of the first collection of networks. The training loss is shown in muted colors, while the validation loss is denoted by bright colors.}
		\label{fig:weighted_f1_training}
\end {figure}

\noindent The results of testing the networks on the validation set are shown in Table \textbf{\ref{tab:results1}}. They indicate that both networks perform similarly well: For the 3-class dataset, the \textbf{W\_3} network has a Macro F-Measure score of $\approx0.875$, slightly better than the score achieved by the \textbf{F1\_3} network, which was $\approx0.861$. Reducing the dataset to three classes by merging the Lamellopodia and Filopodia classes improves the results for both networks regardless of the loss function. The \textbf{W\_4} network achieved an overall Macro F-Measure score of $\approx0.746$, slightly worse than the \textbf{F1\_4} network score of $\approx0.749$. Since the \textbf{W} networks were better at segmenting the 3-class dataset and because the difference in performance on the 4-class dataset was very small and could be due to initialization randomness, the weighted Cross-Entropy loss was chosen as the loss function for further experiments.\\


\begin {table}
	\begin{flushleft}
		\begin {tabular}[!htb]{|l|l|l|l|l|}
			\hline\multicolumn{5}{|l|}{\textbf{3-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_3& \cellcolor{green!25}0.980159& \cellcolor{green!25}0.852122& 0.934006& \cellcolor{green!25}0.961419 \\ \hline
			F1\_3& 0.973661& 0.809751& \cellcolor{green!25}0.934676& 0.950451\\ \hline
			\multicolumn{5}{|l|}{\textbf{3-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_3& \cellcolor{green!25}0.978033& \cellcolor{green!25}0.808224& \cellcolor{green!25}0.828686& \cellcolor{green!25}0.874772 \\ \hline
			F1\_3& 0.970553& 0.771874& 0.827895& 0.860840\\ \hline
		\end {tabular}
		\vspace{0.5cm}\\
		\begin {tabular}[!htb]{|l|l|l|l|l|l|}
			\hline\multicolumn{6}{|l|}{\textbf{4-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_4& 0.978283& \cellcolor{green!25}0.663734& 0.922784& 0.63427& 0.934613 \\ \hline
			F1\_4& \cellcolor{green!25}0.978905& 0.648421& \cellcolor{green!25}0.929386& \cellcolor{green!25}0.641471& \cellcolor{green!25}0.936407 \\ \hline
			\multicolumn{6}{|l|}{\textbf{4-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_4& 0.975677& 0.564365& 0.817776& 0.606856& 0.746027 \\ \hline
			F1\_4& \cellcolor{green!25}0.976674& \cellcolor{green!25}0.568730& \cellcolor{green!25}0.821611& \cellcolor{green!25}0.621359& \cellcolor{green!25}0.748524 \\ \hline
		\end {tabular}
	\end {flushleft}

\caption[Micro and Macro F-Measure scores for networks with weighted Cross-Entropy and F-Measure loss functions.]{Micro and Macro F-Measure scores achieved by the \textbf{W} and \textbf{F1} networks when segmenting the validation set images into 3 or 4 classes. In the 4-class dataset, there are classes for background, the cell body, Filopodia and Lamellopodia, while in the 3-class dataset, the Filopodia and Lamellopodia classes are combined into the ``Protrusions'' class. The best scores in each category, per class, as well as the overall winner, are marked in green.}
\label{tab:results1}
\end {table}


	\subsubsection{Batch Normalization}

\noindent The second training case tested whether using Batch Normalization provides benefits, either in convergence speed or validation score. Therefore, the \textbf{W} networks were modified to perform Batch Normalization before each ReLU activation, implemented in Caffe as a ``Batch Normalization'' layer that normalizes its input according to the mini-batch statistics, followed by a ``Scale'' layer that applies the affine transformation. Also, all Dropout layers were removed, as advised in \cite{batchnorm}. These networks receive an additional \textbf{\_BN} as part of their name.

Again, the networks were trained on the 3- and 4-class datasets, this time, considering the notes on accelerating a network with Batch Normalization in \cite{batchnorm}, with a higher initial learning rate of 0.005, and a faster step learning rate decay that reduces the learning rate by $\zeta = 0.1$ every 7,500 iterations. Momentum was kept at $\gamma = 0.99$. However, the network parameters did not fit into memory with a mini-batch size of 5 because of the added Batch Normalization layers, and therefore the mini-batch size had to be lowered to 2. To be able to still compare the training to previous results, the number of iterations was raised to 200,000 so that the network was trained for about 32 epochs as before.

The training progress is shown in Figure \textbf{\ref{fig:weighted_weighted_batchnorm_training}}. As expected, the networks converge much faster when using Batch Normalization, taking only about 5 epochs of training until convergence, which is a five-fold reduction of the required training epochs. As such, the \textbf{W\_BN} networks took only about 7 hours each to converge, down from 26 hours.\\



\begin {figure}[!htb]
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_3.pgf}}
		\caption{\textbf{W\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_4.pgf}}
		\caption{\textbf{W\_4}}
	\end {subfigure}

	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_3.pgf}}
		\caption{\textbf{W\_BN\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_4.pgf}}
		\caption{\textbf{W\_BN\_4}}
	\end {subfigure}

		\caption[Training progress of the second collection of networks.]{Training progress of the second collection of networks. The networks with added Batch Normalization converge approximately five times faster.}
		\label{fig:weighted_weighted_batchnorm_training}
\end {figure}

\noindent From the test results, shown in Table \textbf{\ref{tab:results2}}, it is evident that the \textbf{W\_BN} networks were better consistently for the 3-class dataset, achieving an overall Macro F-Measure score of $\approx0.777$, which is an improvement towards the previous score of $\approx0.746$. For the easier 3-class dataset however, the overall Macro F-Measure score was $\approx0.869$ which is slightly worse than the result of the network without Batch Normalization, achieving a score of $\approx0.874$. Despite this, it was still deemed advisable to use Batch Normalization from hereafter to massively reduce the training time of the networks.\\

\begin {table}
	\begin{flushleft}
		\begin {tabular}[!htb]{|l|l|l|l|l|}
			\hline\multicolumn{5}{|l|}{\textbf{3-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_3& \cellcolor{green!25}0.980159& \cellcolor{green!25}0.852122& \cellcolor{green!25}0.934006& \cellcolor{green!25}0.961419 \\ \hline
			W\_BN\_3& 0.97894& 0.840205& 0.929242& 0.958793 \\ \hline
			\multicolumn{5}{|l|}{\textbf{3-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_3& \cellcolor{green!25}0.978033& \cellcolor{green!25}0.808224& \cellcolor{green!25}0.828686& \cellcolor{green!25}0.874772 \\ \hline
			W\_BN\_3& 0.976777& 0.797868& 0.823922& 0.868310 \\ \hline
		\end {tabular}
		\vspace{0.5cm}\\
		\begin {tabular}[!htb]{|l|l|l|l|l|l|}
			\hline\multicolumn{6}{|l|}{\textbf{4-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_4& 0.978283& 0.663734& 0.922784& 0.63427& 0.934613 \\ \hline
			W\_BN\_4& \cellcolor{green!25}0.980579& \cellcolor{green!25}0.733308& \cellcolor{green!25}0.928468& \cellcolor{green!25}0.657326& \cellcolor{green!25}0.945016 \\ \hline
			\multicolumn{6}{|l|}{\textbf{4-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_4& 0.975677& 0.564365& 0.817776& 0.606856& 0.746027 \\ \hline
			W\_BN\_4& \cellcolor{green!25}0.978607& \cellcolor{green!25}0.642202& \cellcolor{green!25}0.828532& \cellcolor{green!25}0.644209& \cellcolor{green!25}0.776984 \\ \hline
		\end {tabular}
	\end {flushleft}

\caption[Micro and Macro F-Measure scores for a network with and without Batch Normalization.]{Micro and Macro F-Measure scores of 3 and 4-class segmenations achieved by the \textbf{W} network with and without Batch Normalization.}
\label{tab:results2}
\end {table}

	\subsubsection{Training set shuffling}

In the next round of tests, the effect of shuffling on the training of weighted Cross-Entropy Loss networks with Batch Normalization was evaluated, using the same training parameters as before. Especially the number of epochs was chosen to be identical because shuffling was expected to either reduce the number of epochs necessary for convergence via speeding up the learning process, or alternatively make the network take longer to converge, but perhaps gaining additional validation score improvements in return. Depending on the results, the epoch number could then be reduced to whichever number of epochs is necessary, which should provide a large training time reduction in comparison to the prior number of about 32 epochs in either case. The networks with enabled shuffling have an additional \textbf{\_S} as part of their name.

The training progress is shown in Figure \textbf{\ref{fig:weighted_batchnorm_shuffle_training}}. Indeed, the \textbf{W\_BN\_S} networks now took only 1 - 2 epochs to converge as opposed to previously about 5 epochs, which is equivalent to about 4 1/2 hours of training each, down from 7 hours.


\begin {figure}[!htb]
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_3_SCALED.pgf}}
		\caption{\textbf{W\_BN\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_4_SCALED.pgf}}
		\caption{\textbf{W\_BN\_4}}
	\end {subfigure}

	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_shuffle_3.pgf}}
		\caption{\textbf{W\_BN\_S\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_shuffle_4.pgf}}
		\caption{\textbf{W\_BN\_S\_4}}
	\end {subfigure}

		\caption[Training progress of the third collection of networks.]{Training progress of the third collection of networks. The networks with enabled shuffling converge even faster than the ones without shuffling. Note that the scale of the Y-axis has been altered slightly in comparison to the previous figure to better illustrate the training progress.}
		\label{fig:weighted_batchnorm_shuffle_training}
\end {figure}


The testing results are shown in Table \textbf{\ref{tab:results3}}. Surprisingly though, the \textbf{W\_BN\_S} networks performed worse for both 3 and 4 classes in terms of their Macro F-Measure scores, with scores of $\approx0.853$ (down from $\approx0.868$) and $\approx0.762$ (down from $\approx0.777$). As in each epoch, all training samples are presented to the network for training and shuffling merely changes their order, it was unclear why shuffling would have a negative effect on the generalization capability of the network.


\begin {table}
	\begin{flushleft}
		\begin {tabular}[!htb]{|l|l|l|l|l|}
			\hline\multicolumn{5}{|l|}{\textbf{3-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_BN\_3& \cellcolor{green!25}0.97894& \cellcolor{green!25}0.840205& \cellcolor{green!25}0.929242& \cellcolor{green!25}0.958793 \\ \hline
			W\_BN\_S\_3& 0.971224& 0.801529& 0.924549& 0.946244 \\ \hline
			\multicolumn{5}{|l|}{\textbf{3-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_BN\_3& \cellcolor{green!25}0.976777& \cellcolor{green!25}0.797868& 0.823922& \cellcolor{green!25}0.868310 \\ \hline
			W\_BN\_S\_3& 0.96827& 0.7514& \cellcolor{green!25}0.824780& 0.853336 \\ \hline
		\end {tabular}
		\vspace{0.5cm}\\
		\begin {tabular}[!htb]{|l|l|l|l|l|l|}
			\hline\multicolumn{6}{|l|}{\textbf{4-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_BN\_4& \cellcolor{green!25}0.980579& \cellcolor{green!25}0.733308& \cellcolor{green!25}0.928468& \cellcolor{green!25}0.657326& \cellcolor{green!25}0.945016 \\ \hline
			W\_BN\_S\_4& 0.974023& 0.682878& 0.923356& 0.645053& 0.932581 \\ \hline
			\multicolumn{6}{|l|}{\textbf{4-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_BN\_4& \cellcolor{green!25}0.978607& \cellcolor{green!25}0.642202& \cellcolor{green!25}0.828532& \cellcolor{green!25}0.644209& \cellcolor{green!25}0.776984 \\ \hline
			W\_BN\_S\_4& 0.971439& 0.599044& 0.822736& 0.630631& 0.761619 \\ \hline
		\end {tabular}
	\end {flushleft}

\caption[Micro and Macro F-Measure scores for a network with Batch Normalization and with or without shuffling.]{Micro and Macro F-Measure scores of 3 and 4-class segmenations achieved by \textbf{W\_BN} with and without shuffling.}
\label{tab:results3}
\end {table}


	\subsubsection {MSRA weight initialization and initialization noise}

	\label{subsec:msra_weight_jitter}

\noindent As the next evaluation step, the effect of the weight initialization on \textbf{W\_BN\_S} was compared, using the Xavier and the MSRA initializations. It was believed that MSRA should work better for all networks using ReLU activations or its variations. The networks up to this point used the Xavier initialization, so the networks with MSRA initialization received an additional \textbf{\_MS} tag. The number of epochs was reduced to about 6.

The training progress is shown in Figure \textbf{\ref{fig:weighted_batchnorm_shuffle_msra_training}}. However, the new initialization does not change the progress of the training noticeably, and the \textbf{W\_BN\_S\_MS} networks still converge after 1 - 2 epochs.\\


\begin {figure}[!htb]
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_shuffle_3_SCALED.pgf}}
		\caption{\textbf{W\_BN\_S\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_shuffle_4_SCALED.pgf}}
		\caption{\textbf{W\_BN\_S\_4}}
	\end {subfigure}

	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_shuffle_msra_3.pgf}}
		\caption{\textbf{W\_BN\_S\_MS\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_shuffle_msra_4.pgf}}
		\caption{\textbf{W\_BN\_S\_MS\_4}}
	\end {subfigure}

		\caption[Training progress of the fourth collection of networks.]{Training progress of the fourth collection of networks. The networks with MSRA initialization do not differ much from the networks with Xavier initialization. Only the first 6 epochs of the progress of the \textbf{W\_BN\_S} networks are shown here for comparison.}
		\label{fig:weighted_batchnorm_shuffle_msra_training}
\end {figure}


The test results are shown in Table \textbf{\ref{tab:results4}}. For both the 3- and 4-class networks, using the MSRA initialization led to slight score improvements, namely to values of $\approx0.855$ (up from $\approx0.853$) and $\approx0.7618$ (up from $\approx0.7616$). However, at this point, it was evident that to properly evaluate the results, the effect of the weight initialization noise on the results had to be considered. To this account, both the \textbf {W\_BN\_S} and \textbf{W\_BN\_S\_MS} networks were trained again for 20,000 iterations, using the 3- and 4-class datasets. This was done to obtain an averaged loss as well as a rough error interval in which the validation loss could potentially lie for a newly trained network. The results are shown in Figure \textbf{\ref{fig:weight_jitter}}.

For the \textbf {W\_BN\_S\_3} network, the difference between the minimum and maximum loss in the later iterations where the network had already converged was $\approx0.0156$, while for the 4-class version of the network this difference was $\approx0.0184$. For the \textbf{W\_BN\_S\_MS} networks, these values were $\approx0.0129$ and $\approx0.0125$, respectively. While this helps explain the drop in performance when using shuffling as the worse values lay in the error interval given by the initialization randomness, it also seems as though MSRA initialization is a little more stable, jittering less than the Xavier initialization does - although this requires further testing. Concludingly, as the effect on the loss was rather neutral, but might be more stable because of the new initialization, MSRA initialization was therefore used for the last round of experiments.\\

\begin {figure}[!htb]
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_jitter_weighted_batchnorm_shuffle_3.pgf}}
		\caption{\textbf{W\_BN\_S\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_jitter_weighted_batchnorm_shuffle_4.pgf}}
		\caption{\textbf{W\_BN\_S\_4}}
	\end {subfigure}

	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_jitter_weighted_batchnorm_shuffle_msra_3.pgf}}
		\caption{\textbf{W\_BN\_S\_MS\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_jitter_weighted_batchnorm_shuffle_msra_4.pgf}}
		\caption{\textbf{W\_BN\_S\_MS\_4}}
	\end {subfigure}

		\caption[Weight jitter testing.]{Testing the effect of weight initialization randomness on the end result. The blue line shows the average validation loss, while the orange bars show the minimum and maximum validation losses at each step, taken from the five training passes of the same network, each lasting 20,000 iterations. The first 5,000 iterations were omitted because the initial training loss fluctuated wildly and the network had not already converged in these iterations anyway.}
		\label{fig:weight_jitter}
\end {figure}

\begin {table}
	\begin{flushleft}
		\begin {tabular}[!htb]{|l|l|l|l|l|}
			\hline\multicolumn{5}{|l|}{\textbf{3-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_BN\_S\_3& 0.971224& 0.801529& 0.924549& 0.946244 \\ \hline
			W\_BN\_S\_MS\_3& \cellcolor{green!25}0.972544& \cellcolor{green!25}0.806668& \cellcolor{green!25}0.924910& \cellcolor{green!25}0.948196 \\ \hline
			\multicolumn{5}{|l|}{\textbf{3-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_BN\_S\_3& 0.96827& 0.7514& \cellcolor{green!25}0.824780& 0.853336 \\ \hline
			W\_BN\_S\_MS\_3& \cellcolor{green!25}0.969960& \cellcolor{green!25}0.756508& 0.823536& \cellcolor{green!25}0.85484 \\ \hline
		\end {tabular}
		\vspace{0.5cm}\\
		\begin {tabular}[!htb]{|l|l|l|l|l|l|}
			\hline\multicolumn{6}{|l|}{\textbf{4-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_BN\_S\_4& \cellcolor{green!25}0.974023& \cellcolor{green!25}0.682878& 0.923356& 0.645053& \cellcolor{green!25}0.932581 \\ \hline
			W\_BN\_S\_MS\_4& 0.972521& 0.676638& \cellcolor{green!25}0.924545& \cellcolor{green!25}0.647229& 0.930357 \\ \hline
			\multicolumn{6}{|l|}{\textbf{4-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_BN\_S\_4& \cellcolor{green!25}0.971439& \cellcolor{green!25}0.599044& 0.822736& \cellcolor{green!25}0.630631& 0.761619 \\ \hline
			W\_BN\_S\_MS\_4& 0.969880& 0.596355& \cellcolor{green!25}0.825985& 0.626172& \cellcolor{green!25}0.761833 \\ \hline
		\end {tabular}
	\end {flushleft}
\caption[Multi-class F-Measure scores for networks with Xavier and MSRA weight initialization.]{Multi-class F-Measure scores of 3 and 4-class segmentations for the \textbf{W\_BN\_S} network with either Xavier or MSRA weight initialization.}
\label{tab:results4}
\end {table}


	\subsubsection{Activation functions}

In the last experiment, the choice of the activation function used throughout the network was evaluated. The previous networks used ReLU activations, which were subsequently replaced with ELU (\textbf{\_EL}), LReLU (\textbf{\_LR}) and PReLU (\textbf{\_PR}) activations. The ELU used the standard value of $\alpha = 1.0$ as implemented by Caffe, while the LReLU activations used $\alpha = 0.01$.

The training progress is shown in Figure \textbf{\ref{fig:weighted_batchnorm_shuffle_msra_acts_training}}. However, the training progress again did not differ much from the convential ReLU training, although the ELU activation function achieves a lower loss than the two other activation functions after 1 - 2 epochs on the 4-class dataset.\\


\begin {figure}[!htb]
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_shuffle_msra_3.pgf}}
		\caption{\textbf{W\_BN\_S\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_shuffle_msra_4.pgf}}
		\caption{\textbf{W\_BN\_S\_4}}
	\end {subfigure}

	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_shuffle_msra_combinedacts_3.pgf}}
		\caption{\textbf{W\_BN\_S\_MS\_EL/LR/PR\_3}}
	\end {subfigure}\hspace{1.75cm}
	\begin {subfigure}[b]{0.4\linewidth}
		\scalebox{0.65}{\input{img/fig_train_unet_weighted_batchnorm_shuffle_msra_combinedacts_4.pgf}}
		\caption{\textbf{W\_BN\_S\_MS\_EL/LR/PR\_4}}
	\end {subfigure}

		\caption[Training progress of the fifth collection of networks.]{Training progress of the fifth and final collection of networks, using ELU (red), LReLU (green) and PReLU (blue) activation functions for the \textbf{W\_BN\_S\_MS} network.}
		\label{fig:weighted_batchnorm_shuffle_msra_acts_training}
\end {figure}

The test results are shown in Table \textbf{\ref{tab:results5}}. For the 3-class dataset, the LReLU outperforms the ReLU activation and the other two activation functions tested by a small margin of $\approx0.86$ (up from the ReLU score of $\approx0.855$), while for the 4-class dataset, the ELU performs much better than the other two activation functions, but only slightly better than the ReLU activation, achieving a Macro F-Measure score of $\approx0.765$ (up from the ReLU score of $\approx0.762$). As these improvements again lay in the error interval, they may or may not represent an improvement in practice, but using the best networks in this collection of networks respectively should work just as well as using the ReLU activation function, which is why they were declared the best overall networks.\\

\begin {table}
	\begin{flushleft}
		\begin {tabular}[!htb]{|l|l|l|l|l|}
			\hline\multicolumn{5}{|l|}{\textbf{3-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_BN\_S\_MS\_3& 0.972544& 0.806668& 0.924910& 0.948196 \\ \hline
			W\_BN\_S\_MS\_EL\_3& 0.970800& 0.794595& 0.926807& 0.945134 \\ \hline
			W\_BN\_S\_MS\_LR\_3& \cellcolor{green!25}0.974278& \cellcolor{green!25}0.81579& 0.927586& \cellcolor{green!25}0.951177 \\ \hline
			W\_BN\_S\_MS\_PR\_3& 0.971991& 0.804978& \cellcolor{green!25}0.927779& 0.947568 \\ \hline
			\multicolumn{5}{|l|}{\textbf{3-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_BN\_S\_MS\_3& 0.969960& 0.756508& 0.823536& 0.85484 \\ \hline
			W\_BN\_S\_MS\_EL\_3& 0.967883& 0.737727& 0.822989& 0.848497 \\ \hline
			W\_BN\_S\_MS\_LR\_3& \cellcolor{green!25}0.971674& \cellcolor{green!25}0.767961& \cellcolor{green!25}0.826753& \cellcolor{green!25}0.859652 \\ \hline
			W\_BN\_S\_MS\_PR\_3& 0.96934& 0.753306& 0.826270& 0.855507 \\ \hline
		\end {tabular}
		\vspace{0.5cm}\\
		\begin {tabular}[!htb]{|l|l|l|l|l|l|}
			\hline\multicolumn{6}{|l|}{\textbf{4-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_BN\_S\_MS\_4& 0.972521& 0.676638& 0.924545& 0.647229& 0.930357 \\ \hline
			W\_BN\_S\_MS\_EL\_4& \cellcolor{green!25}0.974655& \cellcolor{green!25}0.688037& \cellcolor{green!25}0.928248& \cellcolor{green!25}0.657683& \cellcolor{green!25}0.93436 \\ \hline
			W\_BN\_S\_MS\_LR\_4& 0.970666& 0.662726& 0.919516& 0.626966& 0.926315 \\ \hline
			W\_BN\_S\_MS\_PR\_4& 0.972195& 0.672126& 0.922898& 0.635264& 0.929459 \\ \hline
			\multicolumn{6}{|l|}{\textbf{4-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_BN\_S\_MS\_4& 0.969880& 0.596355& \cellcolor{green!25}0.825985& 0.626172& 0.761833 \\ \hline
			W\_BN\_S\_MS\_EL\_4& \cellcolor{green!25}0.972144& \cellcolor{green!25}0.597324& 0.825157& \cellcolor{green!25}0.642953& \cellcolor{green!25}0.764857 \\ \hline
			W\_BN\_S\_MS\_LR\_4& 0.967521& 0.581588& 0.817467& 0.596097& 0.748987 \\ \hline
			W\_BN\_S\_MS\_PR\_4& 0.969504& 0.590348& 0.819656& 0.606304& 0.753922 \\ \hline
		\end {tabular}
	\end {flushleft}
\caption[Multi-class F-Measure scores for networks with different activation functions.]{Multi-class F-Measure scores of 3 and 4-class segmentations for the \textbf{W\_BN\_S\_MS} network with ELU, LReLU or PReLU activations.}
\label{tab:results5}
\end {table}

	
	\subsubsection{Comparison with traditional methods}

\noindent The final results of the \textbf{W\_BN\_MS\_LR} and \textbf{W\_BN\_MS\_EL} networks were compared to the Macro F-Measure scores of the segmentations performed using the more traditional image segmentation methods described in Chapter \textbf{\ref{chap:concepts}}. Because Otsu thresholding, K-Means and Gaussian Mixture Models are all unsupervised methods, i.e. they do not depend on ground truth images, the labels they output have no direct relation to the ground truth labels used in the CNN training. Therefore, all combinations of matching the output labels with the ground truth labels are evaluated and for each, a multi-class F-Measure score is calculated. The assignment with the highest score is assumed to be the correct one, which is then used for comparing the performance of the unsupervised methods to the CNN performance.\\


\begin {table}
	\begin{flushleft}
		\begin {tabular}[!htb]{|l|l|l|l|l|}
			\hline\multicolumn{5}{|l|}{\textbf{3-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_BN\_S\_MS\_LR\_3& \cellcolor{green!25}0.974278& \cellcolor{green!25}0.81579& \cellcolor{green!25}0.927586& \cellcolor{green!25}0.951177 \\ \hline
			Kmeans\_3& 0.911726& 0.203548& 0.55854& 0.827114 \\ \hline
			Otsu\_3& 0.948289& 0.293253& 0.825507& 0.893721 \\ \hline
			GMM\_3& 0.918865& 0.454169& 0.592041& 0.839736 \\ \hline
			\multicolumn{5}{|l|}{\textbf{3-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Protrusions}& \textbf{Body}& \textbf{Overall} \\ \hline
			W\_BN\_S\_MS\_LR\_3& \cellcolor{green!25}0.971674& \cellcolor{green!25}0.767961& \cellcolor{green!25}0.826753& \cellcolor{green!25}0.859652 \\ \hline
			Kmeans\_3& 0.913368& 0.285729& 0.651961& 0.621961 \\ \hline
			Otsu\_3& 0.945845& 0.288723& 0.724415& 0.690693 \\ \hline
			GMM\_3& 0.923315& 0.469288& 0.662101& 0.686225 \\ \hline
		\end {tabular}
		\vspace{0.5cm}\\
		\begin {tabular}[!htb]{|l|l|l|l|l|l|}
			\hline\multicolumn{6}{|l|}{\textbf{4-class Micro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_BN\_S\_MS\_EL\_4& \cellcolor{green!25}0.974655& \cellcolor{green!25}0.688037& \cellcolor{green!25}0.928248& \cellcolor{green!25}0.657683& \cellcolor{green!25}0.93436 \\ \hline
			Kmeans\_4& 0.903179& 0.143972& 0.506803& 0.264708& 0.798993 \\ \hline
			Otsu\_4& 0.952084& 0.211475& 0.826076& 0.290935& 0.888612 \\ \hline
			GMM\_4& 0.907277& 0.353604& 0.572532& 0.267892& 0.801932 \\ \hline
			\multicolumn{6}{|l|}{\textbf{4-class Macro F-Measure Scores}} \\ \hline
			\textbf{Network}& \textbf{BG}& \textbf{Lamell.}& \textbf{Body}& \textbf{Filopod.}& \textbf{Overall} \\ \hline
			W\_BN\_S\_MS\_EL\_4& \cellcolor{green!25}0.972144& \cellcolor{green!25}0.597324& \cellcolor{green!25}0.825157& \cellcolor{green!25}0.642953& \cellcolor{green!25}0.764857 \\ \hline
			Kmeans\_4& 0.910968& 0.165100& 0.608527& 0.332654& 0.515816 \\ \hline
			Otsu\_4& 0.949528& 0.216677& 0.717499& 0.272930& 0.553722 \\ \hline
			GMM\_4& 0.912145& 0.309169& 0.638074& 0.299744& 0.552376 \\ \hline
		\end {tabular}
	\end {flushleft}
\caption[Multi-class F-Measure scores for final network and other image segmentation methods.]{Multi-class F-Measure scores of 3- and 4-class segmentations for the \textbf{W\_BN\_MS\_LR} and \textbf{W\_BN\_MS\_EL} networks and the unsupervised K-Means, Otsu and GMM segmentation methods.}
\label{tab:resultsfinal}
\end {table}

Unsurprisingly, the modified U-Net produces better results than the other segmentation methods by a large margin, with the runner-up being Otsu segmentation, which achieves a Macro F-Measure score of $\approx0.691$ for 3 classes and a score of $\approx0.554$ for 4 classes. This puts the CNN at an advantage of $\approx$16\% and $\approx$21\% for segmenting the 3- and 4-class data, respectively. Processing an entire image (made up of several tiles) took $\approx0.357$ seconds for both the 3- and 4-class networks, neglecting the time it takes to initialize the network, which took a few seconds on its own.

Qualitative results in the form of comparisons between segmentation and ground truth data for some image tiles are shown in Figure \textbf{\ref{fig:qualitative}}.


\begin {figure}[!htb]
	\centering
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile3.png}
	\end {subfigure}\hspace{0.5cm}
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile3_pred_c3.png}
	\end {subfigure}\hspace{0.5cm}
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile3_pred_c3_GT.png}
	\end {subfigure}
	\par\medskip
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile4.png}
	\end {subfigure}\hspace{0.5cm}
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile4_pred_c3.png}
	\end {subfigure}\hspace{0.5cm}
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile4_pred_c3_GT.png}
	\end {subfigure}
	\par\bigskip\par\bigskip
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile3.png}
	\end {subfigure}\hspace{0.5cm}
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile3_pred_c4.png}
	\end {subfigure}\hspace{0.5cm}
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile3_pred_c4_GT.png}
	\end {subfigure}
	\par\medskip
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile4.png}
	\end {subfigure}\hspace{0.5cm}
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile4_pred_c4.png}
	\end {subfigure}\hspace{0.5cm}
	\begin {subfigure}[b]{0.25\linewidth}
		\includegraphics[scale=0.45]{img/fig_quali_tile4_pred_c4_GT.png}
	\end {subfigure}

		\caption[Qualitative prediction results.]{Qualitative results from predicting validation data tiles with the best 3-class network, \textbf{W\_BN\_S\_MS\_LR\_3}, (top two rows) and the best 4-class network, \textbf{W\_BN\_S\_MS\_EL\_4}, (bottom two rows). \textbf{From left to right}: Input image, prediction and image ground truth. In the 4-class examples, it is evident that the Filopodia (blue) are hard to learn, often appearing ``broken'', with pieces of the Filopodia existing that are detached from the cell body. Lamellopodia and and especially cell bodies are learned much more precisely.}
		\label{fig:qualitative}
\end {figure}