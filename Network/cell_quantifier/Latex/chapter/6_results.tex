\chapter {Results}
\label{chap:results}

	\section{Hardware}
All variants of the U-Net were trained on a NVIDIA TITAN Xp GPU (12 GB VRAM) using Caffe's CUDA/cuDNN support.

	\section {Timings and segmentation precision}
\textbf{TODO: Use Cross-Entropy after manually recoloring images?}

\begin {table}
	\centering
	\begin {tabular}[!ht]{|l|c|c|}
		\hline
		\textbf{CNN variant}& \textbf{3 classes}& \textbf{4 classes}\\ \hline
		Unet& & \\ \hline
		Unet\_Batchnorm& & \\ \hline
		Unet\_Weighted& & \\ \hline
		Unet\_Weighted\_Batchnorm& & \\ \hline
		Unet\_F1& & \\ \hline
		Unet\_F1\_Batchnorm & & \\ \hline
	\end {tabular}
\caption[]{Precision of 3 and 4-class segmentations according to the ?? metric.}
\end {table}

\noindent Among the CNNs, the best network \textbf{TODO} was selected and its ReLU activation functions were replaced by LReLUs, PReLUs and ELUs to evaluate the differences in performance with respect to the activation function used.

\begin {table}
	\centering
	\begin {tabular}[!ht]{|l|c|c|}
		\hline
		\textbf{Activation}& \textbf{3 classes}& \textbf{4 classes}\\ \hline
		ReLU& & \\ \hline
		LReLU& & \\ \hline
		PReLU& & \\ \hline
		ELU& & \\ \hline
	\end {tabular}
\caption[]{Precision of 3 and 4-class segmentations for the \textbf{TODO} network, using different activations functions.}
\end {table}

\noindent Then, the effect of the weight initialization on the best network was compared, using the Xavier and the MSRA initializations.

\begin {table}
	\centering
	\begin {tabular}[!ht]{|l|c|c|}
		\hline
		\textbf{Init method}& \textbf{3 classes}& \textbf{4 classes}\\ \hline
		Xavier& & \\ \hline
		MSRA& & \\ \hline
	\end {tabular}
\caption[]{Precision of 3 and 4-class segmentations for the \textbf{TODO} network, using \textbf{TODO} activations and either Xavier or MSRA weight initialization.}
\end {table}

\textbf{TODO: Evaluation of training progress, i.e. validation loss progession}


To compare the CNN results with the results of the other methods, the ``unreliable label'' problem has to be dealt with. Because Otsu thresholding, K-Means and Gaussian Mixture Models are all unsupervised methods, i.e. they do not depend on ground truth images, the labels they output have no direct relation to the ground truth labels used in the CNN training. Therefore, the results from these methods needs to be converted into a representation that can be compared to the ground truth without falsifying the results.

\textbf{TODO: how to fix unreliable labels?}

\begin {table}
	\centering
	\begin {tabular}[!ht]{|l|c|c|}
		\hline
		\textbf{Method}& \textbf{3 classes}& \textbf{4 classes}\\ \hline
		Otsu& & \\ \hline
		K-Means& & \\ \hline
		GMM& & \\ \hline
		\textbf{TODO-network}& & \\ \hline
	\end {tabular}
\caption[]{Precision of 3 and 4-class segmentations according to the \textbf{TODO} metric. The best network is compared to the outputs of unsupervised methods.}
\end {table}