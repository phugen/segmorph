I0427 16:20:19.158841 13425 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3456
test_interval: 1000
base_lr: 5e-05
display: 100
max_iter: 300000
lr_policy: "step"
gamma: 0.1
momentum: 0.99
stepsize: 20000
snapshot: 5000
snapshot_prefix: "./snapshots/unet_f1_3/unet_f1_3"
solver_mode: GPU
net: "./unet_f1_3/unet_f1_3.prototxt"
regularization_type: "L2"
test_initialization: true
iter_size: 1
I0427 16:20:19.159297 13425 solver.cpp:91] Creating training net from net file: ./unet_f1_3/unet_f1_3.prototxt
I0427 16:20:19.159955 13425 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer loaddata
I0427 16:20:19.160362 13425 net.cpp:58] Initializing net from parameters: 
name: "unet_f1_3"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "caffeHDF5_3.txt"
    batch_size: 5
  }
}
layer {
  name: "conv_d0a-b"
  type: "Convolution"
  bottom: "data"
  top: "d0b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0b"
  type: "ReLU"
  bottom: "d0b"
  top: "d0b"
}
layer {
  name: "conv_d0b-c"
  type: "Convolution"
  bottom: "d0b"
  top: "d0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0c"
  type: "ReLU"
  bottom: "d0c"
  top: "d0c"
}
layer {
  name: "pool_d0c-1a"
  type: "Pooling"
  bottom: "d0c"
  top: "d1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d1a-b"
  type: "Convolution"
  bottom: "d1a"
  top: "d1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1b"
  type: "ReLU"
  bottom: "d1b"
  top: "d1b"
}
layer {
  name: "conv_d1b-c"
  type: "Convolution"
  bottom: "d1b"
  top: "d1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1c"
  type: "ReLU"
  bottom: "d1c"
  top: "d1c"
}
layer {
  name: "pool_d1c-2a"
  type: "Pooling"
  bottom: "d1c"
  top: "d2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d2a-b"
  type: "Convolution"
  bottom: "d2a"
  top: "d2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2b"
  type: "ReLU"
  bottom: "d2b"
  top: "d2b"
}
layer {
  name: "conv_d2b-c"
  type: "Convolution"
  bottom: "d2b"
  top: "d2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2c"
  type: "ReLU"
  bottom: "d2c"
  top: "d2c"
}
layer {
  name: "pool_d2c-3a"
  type: "Pooling"
  bottom: "d2c"
  top: "d3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d3a-b"
  type: "Convolution"
  bottom: "d3a"
  top: "d3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3b"
  type: "ReLU"
  bottom: "d3b"
  top: "d3b"
}
layer {
  name: "conv_d3b-c"
  type: "Convolution"
  bottom: "d3b"
  top: "d3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3c"
  type: "ReLU"
  bottom: "d3c"
  top: "d3c"
}
layer {
  name: "dropout_d3c"
  type: "Dropout"
  bottom: "d3c"
  top: "d3c"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool_d3c-4a"
  type: "Pooling"
  bottom: "d3c"
  top: "d4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d4a-b"
  type: "Convolution"
  bottom: "d4a"
  top: "d4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4b"
  type: "ReLU"
  bottom: "d4b"
  top: "d4b"
}
layer {
  name: "conv_d4b-c"
  type: "Convolution"
  bottom: "d4b"
  top: "d4c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4c"
  type: "ReLU"
  bottom: "d4c"
  top: "d4c"
}
layer {
  name: "dropout_d4c"
  type: "Dropout"
  bottom: "d4c"
  top: "d4c"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upconv_d4c_u3a"
  type: "Deconvolution"
  bottom: "d4c"
  top: "u3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u3a"
  type: "ReLU"
  bottom: "u3a"
  top: "u3a"
}
layer {
  name: "crop_d3c-d3cc"
  type: "Crop"
  bottom: "d3c"
  bottom: "u3a"
  top: "d3cc"
  crop_param {
    axis: 2
    offset: 4
  }
}
layer {
  name: "concat_d3cc_u3a-b"
  type: "Concat"
  bottom: "u3a"
  bottom: "d3cc"
  top: "u3b"
}
layer {
  name: "conv_u3b-c"
  type: "Convolution"
  bottom: "u3b"
  top: "u3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3c"
  type: "ReLU"
  bottom: "u3c"
  top: "u3c"
}
layer {
  name: "conv_u3c-d"
  type: "Convolution"
  bottom: "u3c"
  top: "u3d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3d"
  type: "ReLU"
  bottom: "u3d"
  top: "u3d"
}
layer {
  name: "upconv_u3d_u2a"
  type: "Deconvolution"
  bottom: "u3d"
  top: "u2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u2a"
  type: "ReLU"
  bottom: "u2a"
  top: "u2a"
}
layer {
  name: "crop_d2c-d2cc"
  type: "Crop"
  bottom: "d2c"
  bottom: "u2a"
  top: "d2cc"
  crop_param {
    axis: 2
    offset: 16
  }
}
layer {
  name: "concat_d2cc_u2a-b"
  type: "Concat"
  bottom: "u2a"
  bottom: "d2cc"
  top: "u2b"
}
layer {
  name: "conv_u2b-c"
  type: "Convolution"
  bottom: "u2b"
  top: "u2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2c"
  type: "ReLU"
  bottom: "u2c"
  top: "u2c"
}
layer {
  name: "conv_u2c-d"
  type: "Convolution"
  bottom: "u2c"
  top: "u2d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2d"
  type: "ReLU"
  bottom: "u2d"
  top: "u2d"
}
layer {
  name: "upconv_u2d_u1a"
  type: "Deconvolution"
  bottom: "u2d"
  top: "u1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u1a"
  type: "ReLU"
  bottom: "u1a"
  top: "u1a"
}
layer {
  name: "crop_d1c-d1cc"
  type: "Crop"
  bottom: "d1c"
  bottom: "u1a"
  top: "d1cc"
  crop_param {
    axis: 2
    offset: 40
  }
}
layer {
  name: "concat_d1cc_u1a-b"
  type: "Concat"
  bottom: "u1a"
  bottom: "d1cc"
  top: "u1b"
}
layer {
  name: "conv_u1b-c"
  type: "Convolution"
  bottom: "u1b"
  top: "u1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1c"
  type: "ReLU"
  bottom: "u1c"
  top: "u1c"
}
layer {
  name: "conv_u1c-d"
  type: "Convolution"
  bottom: "u1c"
  top: "u1d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1d"
  type: "ReLU"
  bottom: "u1d"
  top: "u1d"
}
layer {
  name: "upconv_u1d_u0a"
  type: "Deconvolution"
  bottom: "u1d"
  top: "u0a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u0a"
  type: "ReLU"
  bottom: "u0a"
  top: "u0a"
}
layer {
  name: "crop_d0c-d0cc"
  type: "Crop"
  bottom: "d0c"
  bottom: "u0a"
  top: "d0cc"
  crop_param {
    axis: 2
    offset: 88
  }
}
layer {
  name: "concat_d0cc_u0a-b"
  type: "Concat"
  bottom: "u0a"
  bottom: "d0cc"
  top: "u0b"
}
layer {
  name: "conv_u0b-c"
  type: "Convolution"
  bottom: "u0b"
  top: "u0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0c"
  type: "ReLU"
  bottom: "u0c"
  top: "u0c"
}
layer {
  name: "conv_u0c-d"
  type: "Convolution"
  bottom: "u0c"
  top: "u0d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0d"
  type: "ReLU"
  bottom: "u0d"
  top: "u0d"
}
layer {
  name: "conv_u0d-score"
  type: "Convolution"
  bottom: "u0d"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "score"
  top: "softmax_out"
}
layer {
  name: "reshapelab"
  type: "Reshape"
  bottom: "label"
  top: "label_flat"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "reshaperes"
  type: "Reshape"
  bottom: "softmax_out"
  top: "softmax_out_flat"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "loss"
  type: "Python"
  bottom: "softmax_out_flat"
  bottom: "label_flat"
  top: "loss"
  loss_weight: 1
  python_param {
    module: "multiclass_f1_loss"
    layer: "F1Loss"
  }
}
layer {
  name: "visualize"
  type: "Softmax"
  bottom: "score"
  top: "visualize_out"
  include {
    phase: TRAIN
  }
}
layer {
  name: "fake"
  type: "Silence"
  bottom: "visualize_out"
  include {
    phase: TRAIN
  }
}
I0427 16:20:19.160712 13425 layer_factory.hpp:77] Creating layer loaddata
I0427 16:20:19.160725 13425 net.cpp:100] Creating Layer loaddata
I0427 16:20:19.160742 13425 net.cpp:408] loaddata -> data
I0427 16:20:19.160753 13425 net.cpp:408] loaddata -> label
I0427 16:20:19.160763 13425 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: caffeHDF5_3.txt
I0427 16:20:19.162760 13425 hdf5_data_layer.cpp:93] Number of HDF5 files: 20
I0427 16:20:24.784201 13425 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0427 16:20:38.544567 13425 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0427 16:20:38.964170 13425 net.cpp:150] Setting up loaddata
I0427 16:20:38.964210 13425 net.cpp:157] Top shape: 5 3 428 428 (2747760)
I0427 16:20:38.964218 13425 net.cpp:157] Top shape: 5 244 244 (297680)
I0427 16:20:38.964222 13425 net.cpp:165] Memory required for data: 12181760
I0427 16:20:38.964233 13425 layer_factory.hpp:77] Creating layer conv_d0a-b
I0427 16:20:38.964262 13425 net.cpp:100] Creating Layer conv_d0a-b
I0427 16:20:38.964267 13425 net.cpp:434] conv_d0a-b <- data
I0427 16:20:38.964279 13425 net.cpp:408] conv_d0a-b -> d0b
I0427 16:20:38.968552 13425 net.cpp:150] Setting up conv_d0a-b
I0427 16:20:38.968582 13425 net.cpp:157] Top shape: 5 64 426 426 (58072320)
I0427 16:20:38.968587 13425 net.cpp:165] Memory required for data: 244471040
I0427 16:20:38.968605 13425 layer_factory.hpp:77] Creating layer relu_d0b
I0427 16:20:38.968618 13425 net.cpp:100] Creating Layer relu_d0b
I0427 16:20:38.968624 13425 net.cpp:434] relu_d0b <- d0b
I0427 16:20:38.968632 13425 net.cpp:395] relu_d0b -> d0b (in-place)
I0427 16:20:39.406834 13425 net.cpp:150] Setting up relu_d0b
I0427 16:20:39.406865 13425 net.cpp:157] Top shape: 5 64 426 426 (58072320)
I0427 16:20:39.406869 13425 net.cpp:165] Memory required for data: 476760320
I0427 16:20:39.406877 13425 layer_factory.hpp:77] Creating layer conv_d0b-c
I0427 16:20:39.406895 13425 net.cpp:100] Creating Layer conv_d0b-c
I0427 16:20:39.406900 13425 net.cpp:434] conv_d0b-c <- d0b
I0427 16:20:39.406911 13425 net.cpp:408] conv_d0b-c -> d0c
I0427 16:20:39.408820 13425 net.cpp:150] Setting up conv_d0b-c
I0427 16:20:39.408840 13425 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0427 16:20:39.408843 13425 net.cpp:165] Memory required for data: 706873600
I0427 16:20:39.408857 13425 layer_factory.hpp:77] Creating layer relu_d0c
I0427 16:20:39.408867 13425 net.cpp:100] Creating Layer relu_d0c
I0427 16:20:39.408871 13425 net.cpp:434] relu_d0c <- d0c
I0427 16:20:39.408876 13425 net.cpp:395] relu_d0c -> d0c (in-place)
I0427 16:20:39.409875 13425 net.cpp:150] Setting up relu_d0c
I0427 16:20:39.409895 13425 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0427 16:20:39.409898 13425 net.cpp:165] Memory required for data: 936986880
I0427 16:20:39.409903 13425 layer_factory.hpp:77] Creating layer d0c_relu_d0c_0_split
I0427 16:20:39.409910 13425 net.cpp:100] Creating Layer d0c_relu_d0c_0_split
I0427 16:20:39.409914 13425 net.cpp:434] d0c_relu_d0c_0_split <- d0c
I0427 16:20:39.409920 13425 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_0
I0427 16:20:39.409931 13425 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_1
I0427 16:20:39.409981 13425 net.cpp:150] Setting up d0c_relu_d0c_0_split
I0427 16:20:39.409987 13425 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0427 16:20:39.409998 13425 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0427 16:20:39.410001 13425 net.cpp:165] Memory required for data: 1397213440
I0427 16:20:39.410006 13425 layer_factory.hpp:77] Creating layer pool_d0c-1a
I0427 16:20:39.410013 13425 net.cpp:100] Creating Layer pool_d0c-1a
I0427 16:20:39.410017 13425 net.cpp:434] pool_d0c-1a <- d0c_relu_d0c_0_split_0
I0427 16:20:39.410022 13425 net.cpp:408] pool_d0c-1a -> d1a
I0427 16:20:39.410071 13425 net.cpp:150] Setting up pool_d0c-1a
I0427 16:20:39.410080 13425 net.cpp:157] Top shape: 5 64 212 212 (14382080)
I0427 16:20:39.410084 13425 net.cpp:165] Memory required for data: 1454741760
I0427 16:20:39.410085 13425 layer_factory.hpp:77] Creating layer conv_d1a-b
I0427 16:20:39.410096 13425 net.cpp:100] Creating Layer conv_d1a-b
I0427 16:20:39.410104 13425 net.cpp:434] conv_d1a-b <- d1a
I0427 16:20:39.410109 13425 net.cpp:408] conv_d1a-b -> d1b
I0427 16:20:39.410977 13425 net.cpp:150] Setting up conv_d1a-b
I0427 16:20:39.410991 13425 net.cpp:157] Top shape: 5 128 210 210 (28224000)
I0427 16:20:39.410995 13425 net.cpp:165] Memory required for data: 1567637760
I0427 16:20:39.411005 13425 layer_factory.hpp:77] Creating layer relu_d1b
I0427 16:20:39.411011 13425 net.cpp:100] Creating Layer relu_d1b
I0427 16:20:39.411016 13425 net.cpp:434] relu_d1b <- d1b
I0427 16:20:39.411021 13425 net.cpp:395] relu_d1b -> d1b (in-place)
I0427 16:20:39.411231 13425 net.cpp:150] Setting up relu_d1b
I0427 16:20:39.411244 13425 net.cpp:157] Top shape: 5 128 210 210 (28224000)
I0427 16:20:39.411248 13425 net.cpp:165] Memory required for data: 1680533760
I0427 16:20:39.411252 13425 layer_factory.hpp:77] Creating layer conv_d1b-c
I0427 16:20:39.411260 13425 net.cpp:100] Creating Layer conv_d1b-c
I0427 16:20:39.411264 13425 net.cpp:434] conv_d1b-c <- d1b
I0427 16:20:39.411270 13425 net.cpp:408] conv_d1b-c -> d1c
I0427 16:20:39.413734 13425 net.cpp:150] Setting up conv_d1b-c
I0427 16:20:39.413753 13425 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0427 16:20:39.413758 13425 net.cpp:165] Memory required for data: 1791289600
I0427 16:20:39.413765 13425 layer_factory.hpp:77] Creating layer relu_d1c
I0427 16:20:39.413772 13425 net.cpp:100] Creating Layer relu_d1c
I0427 16:20:39.413775 13425 net.cpp:434] relu_d1c <- d1c
I0427 16:20:39.413781 13425 net.cpp:395] relu_d1c -> d1c (in-place)
I0427 16:20:39.413997 13425 net.cpp:150] Setting up relu_d1c
I0427 16:20:39.414010 13425 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0427 16:20:39.414012 13425 net.cpp:165] Memory required for data: 1902045440
I0427 16:20:39.414016 13425 layer_factory.hpp:77] Creating layer d1c_relu_d1c_0_split
I0427 16:20:39.414022 13425 net.cpp:100] Creating Layer d1c_relu_d1c_0_split
I0427 16:20:39.414026 13425 net.cpp:434] d1c_relu_d1c_0_split <- d1c
I0427 16:20:39.414031 13425 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_0
I0427 16:20:39.414038 13425 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_1
I0427 16:20:39.414084 13425 net.cpp:150] Setting up d1c_relu_d1c_0_split
I0427 16:20:39.414093 13425 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0427 16:20:39.414098 13425 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0427 16:20:39.414100 13425 net.cpp:165] Memory required for data: 2123557120
I0427 16:20:39.414103 13425 layer_factory.hpp:77] Creating layer pool_d1c-2a
I0427 16:20:39.414109 13425 net.cpp:100] Creating Layer pool_d1c-2a
I0427 16:20:39.414113 13425 net.cpp:434] pool_d1c-2a <- d1c_relu_d1c_0_split_0
I0427 16:20:39.414119 13425 net.cpp:408] pool_d1c-2a -> d2a
I0427 16:20:39.414156 13425 net.cpp:150] Setting up pool_d1c-2a
I0427 16:20:39.414165 13425 net.cpp:157] Top shape: 5 128 104 104 (6922240)
I0427 16:20:39.414167 13425 net.cpp:165] Memory required for data: 2151246080
I0427 16:20:39.414170 13425 layer_factory.hpp:77] Creating layer conv_d2a-b
I0427 16:20:39.414180 13425 net.cpp:100] Creating Layer conv_d2a-b
I0427 16:20:39.414183 13425 net.cpp:434] conv_d2a-b <- d2a
I0427 16:20:39.414188 13425 net.cpp:408] conv_d2a-b -> d2b
I0427 16:20:39.417614 13425 net.cpp:150] Setting up conv_d2a-b
I0427 16:20:39.417634 13425 net.cpp:157] Top shape: 5 256 102 102 (13317120)
I0427 16:20:39.417636 13425 net.cpp:165] Memory required for data: 2204514560
I0427 16:20:39.417647 13425 layer_factory.hpp:77] Creating layer relu_d2b
I0427 16:20:39.417654 13425 net.cpp:100] Creating Layer relu_d2b
I0427 16:20:39.417659 13425 net.cpp:434] relu_d2b <- d2b
I0427 16:20:39.417666 13425 net.cpp:395] relu_d2b -> d2b (in-place)
I0427 16:20:39.417886 13425 net.cpp:150] Setting up relu_d2b
I0427 16:20:39.417897 13425 net.cpp:157] Top shape: 5 256 102 102 (13317120)
I0427 16:20:39.417901 13425 net.cpp:165] Memory required for data: 2257783040
I0427 16:20:39.417904 13425 layer_factory.hpp:77] Creating layer conv_d2b-c
I0427 16:20:39.417914 13425 net.cpp:100] Creating Layer conv_d2b-c
I0427 16:20:39.417918 13425 net.cpp:434] conv_d2b-c <- d2b
I0427 16:20:39.417924 13425 net.cpp:408] conv_d2b-c -> d2c
I0427 16:20:39.423521 13425 net.cpp:150] Setting up conv_d2b-c
I0427 16:20:39.423538 13425 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0427 16:20:39.423542 13425 net.cpp:165] Memory required for data: 2308983040
I0427 16:20:39.423550 13425 layer_factory.hpp:77] Creating layer relu_d2c
I0427 16:20:39.423560 13425 net.cpp:100] Creating Layer relu_d2c
I0427 16:20:39.423563 13425 net.cpp:434] relu_d2c <- d2c
I0427 16:20:39.423571 13425 net.cpp:395] relu_d2c -> d2c (in-place)
I0427 16:20:39.424521 13425 net.cpp:150] Setting up relu_d2c
I0427 16:20:39.424537 13425 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0427 16:20:39.424540 13425 net.cpp:165] Memory required for data: 2360183040
I0427 16:20:39.424545 13425 layer_factory.hpp:77] Creating layer d2c_relu_d2c_0_split
I0427 16:20:39.424552 13425 net.cpp:100] Creating Layer d2c_relu_d2c_0_split
I0427 16:20:39.424556 13425 net.cpp:434] d2c_relu_d2c_0_split <- d2c
I0427 16:20:39.424562 13425 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_0
I0427 16:20:39.424571 13425 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_1
I0427 16:20:39.424620 13425 net.cpp:150] Setting up d2c_relu_d2c_0_split
I0427 16:20:39.424633 13425 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0427 16:20:39.424636 13425 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0427 16:20:39.424639 13425 net.cpp:165] Memory required for data: 2462583040
I0427 16:20:39.424643 13425 layer_factory.hpp:77] Creating layer pool_d2c-3a
I0427 16:20:39.424649 13425 net.cpp:100] Creating Layer pool_d2c-3a
I0427 16:20:39.424654 13425 net.cpp:434] pool_d2c-3a <- d2c_relu_d2c_0_split_0
I0427 16:20:39.424659 13425 net.cpp:408] pool_d2c-3a -> d3a
I0427 16:20:39.424702 13425 net.cpp:150] Setting up pool_d2c-3a
I0427 16:20:39.424711 13425 net.cpp:157] Top shape: 5 256 50 50 (3200000)
I0427 16:20:39.424715 13425 net.cpp:165] Memory required for data: 2475383040
I0427 16:20:39.424717 13425 layer_factory.hpp:77] Creating layer conv_d3a-b
I0427 16:20:39.424728 13425 net.cpp:100] Creating Layer conv_d3a-b
I0427 16:20:39.424731 13425 net.cpp:434] conv_d3a-b <- d3a
I0427 16:20:39.424736 13425 net.cpp:408] conv_d3a-b -> d3b
I0427 16:20:39.436337 13425 net.cpp:150] Setting up conv_d3a-b
I0427 16:20:39.436357 13425 net.cpp:157] Top shape: 5 512 48 48 (5898240)
I0427 16:20:39.436359 13425 net.cpp:165] Memory required for data: 2498976000
I0427 16:20:39.436367 13425 layer_factory.hpp:77] Creating layer relu_d3b
I0427 16:20:39.436373 13425 net.cpp:100] Creating Layer relu_d3b
I0427 16:20:39.436378 13425 net.cpp:434] relu_d3b <- d3b
I0427 16:20:39.436383 13425 net.cpp:395] relu_d3b -> d3b (in-place)
I0427 16:20:39.436601 13425 net.cpp:150] Setting up relu_d3b
I0427 16:20:39.436612 13425 net.cpp:157] Top shape: 5 512 48 48 (5898240)
I0427 16:20:39.436616 13425 net.cpp:165] Memory required for data: 2522568960
I0427 16:20:39.436619 13425 layer_factory.hpp:77] Creating layer conv_d3b-c
I0427 16:20:39.436630 13425 net.cpp:100] Creating Layer conv_d3b-c
I0427 16:20:39.436632 13425 net.cpp:434] conv_d3b-c <- d3b
I0427 16:20:39.436640 13425 net.cpp:408] conv_d3b-c -> d3c
I0427 16:20:39.457041 13425 net.cpp:150] Setting up conv_d3b-c
I0427 16:20:39.457057 13425 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0427 16:20:39.457060 13425 net.cpp:165] Memory required for data: 2544236800
I0427 16:20:39.457068 13425 layer_factory.hpp:77] Creating layer relu_d3c
I0427 16:20:39.457075 13425 net.cpp:100] Creating Layer relu_d3c
I0427 16:20:39.457079 13425 net.cpp:434] relu_d3c <- d3c
I0427 16:20:39.457084 13425 net.cpp:395] relu_d3c -> d3c (in-place)
I0427 16:20:39.457351 13425 net.cpp:150] Setting up relu_d3c
I0427 16:20:39.457365 13425 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0427 16:20:39.457367 13425 net.cpp:165] Memory required for data: 2565904640
I0427 16:20:39.457371 13425 layer_factory.hpp:77] Creating layer dropout_d3c
I0427 16:20:39.457381 13425 net.cpp:100] Creating Layer dropout_d3c
I0427 16:20:39.457383 13425 net.cpp:434] dropout_d3c <- d3c
I0427 16:20:39.457389 13425 net.cpp:395] dropout_d3c -> d3c (in-place)
I0427 16:20:39.457486 13425 net.cpp:150] Setting up dropout_d3c
I0427 16:20:39.457499 13425 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0427 16:20:39.457502 13425 net.cpp:165] Memory required for data: 2587572480
I0427 16:20:39.457505 13425 layer_factory.hpp:77] Creating layer d3c_dropout_d3c_0_split
I0427 16:20:39.457512 13425 net.cpp:100] Creating Layer d3c_dropout_d3c_0_split
I0427 16:20:39.457516 13425 net.cpp:434] d3c_dropout_d3c_0_split <- d3c
I0427 16:20:39.457523 13425 net.cpp:408] d3c_dropout_d3c_0_split -> d3c_dropout_d3c_0_split_0
I0427 16:20:39.457530 13425 net.cpp:408] d3c_dropout_d3c_0_split -> d3c_dropout_d3c_0_split_1
I0427 16:20:39.457584 13425 net.cpp:150] Setting up d3c_dropout_d3c_0_split
I0427 16:20:39.457600 13425 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0427 16:20:39.457604 13425 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0427 16:20:39.457607 13425 net.cpp:165] Memory required for data: 2630908160
I0427 16:20:39.457609 13425 layer_factory.hpp:77] Creating layer pool_d3c-4a
I0427 16:20:39.457617 13425 net.cpp:100] Creating Layer pool_d3c-4a
I0427 16:20:39.457622 13425 net.cpp:434] pool_d3c-4a <- d3c_dropout_d3c_0_split_0
I0427 16:20:39.457636 13425 net.cpp:408] pool_d3c-4a -> d4a
I0427 16:20:39.457685 13425 net.cpp:150] Setting up pool_d3c-4a
I0427 16:20:39.457695 13425 net.cpp:157] Top shape: 5 512 23 23 (1354240)
I0427 16:20:39.457697 13425 net.cpp:165] Memory required for data: 2636325120
I0427 16:20:39.457700 13425 layer_factory.hpp:77] Creating layer conv_d4a-b
I0427 16:20:39.457710 13425 net.cpp:100] Creating Layer conv_d4a-b
I0427 16:20:39.457716 13425 net.cpp:434] conv_d4a-b <- d4a
I0427 16:20:39.457721 13425 net.cpp:408] conv_d4a-b -> d4b
I0427 16:20:39.497728 13425 net.cpp:150] Setting up conv_d4a-b
I0427 16:20:39.497746 13425 net.cpp:157] Top shape: 5 1024 21 21 (2257920)
I0427 16:20:39.497750 13425 net.cpp:165] Memory required for data: 2645356800
I0427 16:20:39.497763 13425 layer_factory.hpp:77] Creating layer relu_d4b
I0427 16:20:39.497771 13425 net.cpp:100] Creating Layer relu_d4b
I0427 16:20:39.497777 13425 net.cpp:434] relu_d4b <- d4b
I0427 16:20:39.497783 13425 net.cpp:395] relu_d4b -> d4b (in-place)
I0427 16:20:39.498769 13425 net.cpp:150] Setting up relu_d4b
I0427 16:20:39.498786 13425 net.cpp:157] Top shape: 5 1024 21 21 (2257920)
I0427 16:20:39.498790 13425 net.cpp:165] Memory required for data: 2654388480
I0427 16:20:39.498795 13425 layer_factory.hpp:77] Creating layer conv_d4b-c
I0427 16:20:39.498808 13425 net.cpp:100] Creating Layer conv_d4b-c
I0427 16:20:39.498812 13425 net.cpp:434] conv_d4b-c <- d4b
I0427 16:20:39.498821 13425 net.cpp:408] conv_d4b-c -> d4c
I0427 16:20:39.578559 13425 net.cpp:150] Setting up conv_d4b-c
I0427 16:20:39.578584 13425 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0427 16:20:39.578588 13425 net.cpp:165] Memory required for data: 2661781760
I0427 16:20:39.578596 13425 layer_factory.hpp:77] Creating layer relu_d4c
I0427 16:20:39.578606 13425 net.cpp:100] Creating Layer relu_d4c
I0427 16:20:39.578611 13425 net.cpp:434] relu_d4c <- d4c
I0427 16:20:39.578619 13425 net.cpp:395] relu_d4c -> d4c (in-place)
I0427 16:20:39.578860 13425 net.cpp:150] Setting up relu_d4c
I0427 16:20:39.578872 13425 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0427 16:20:39.578876 13425 net.cpp:165] Memory required for data: 2669175040
I0427 16:20:39.578879 13425 layer_factory.hpp:77] Creating layer dropout_d4c
I0427 16:20:39.578887 13425 net.cpp:100] Creating Layer dropout_d4c
I0427 16:20:39.578891 13425 net.cpp:434] dropout_d4c <- d4c
I0427 16:20:39.578897 13425 net.cpp:395] dropout_d4c -> d4c (in-place)
I0427 16:20:39.578929 13425 net.cpp:150] Setting up dropout_d4c
I0427 16:20:39.578938 13425 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0427 16:20:39.578941 13425 net.cpp:165] Memory required for data: 2676568320
I0427 16:20:39.578944 13425 layer_factory.hpp:77] Creating layer upconv_d4c_u3a
I0427 16:20:39.578953 13425 net.cpp:100] Creating Layer upconv_d4c_u3a
I0427 16:20:39.578956 13425 net.cpp:434] upconv_d4c_u3a <- d4c
I0427 16:20:39.578987 13425 net.cpp:408] upconv_d4c_u3a -> u3a
I0427 16:20:39.597090 13425 net.cpp:150] Setting up upconv_d4c_u3a
I0427 16:20:39.597106 13425 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0427 16:20:39.597110 13425 net.cpp:165] Memory required for data: 2691354880
I0427 16:20:39.597118 13425 layer_factory.hpp:77] Creating layer relu_u3a
I0427 16:20:39.597131 13425 net.cpp:100] Creating Layer relu_u3a
I0427 16:20:39.597136 13425 net.cpp:434] relu_u3a <- u3a
I0427 16:20:39.597141 13425 net.cpp:395] relu_u3a -> u3a (in-place)
I0427 16:20:39.597363 13425 net.cpp:150] Setting up relu_u3a
I0427 16:20:39.597375 13425 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0427 16:20:39.597378 13425 net.cpp:165] Memory required for data: 2706141440
I0427 16:20:39.597381 13425 layer_factory.hpp:77] Creating layer u3a_relu_u3a_0_split
I0427 16:20:39.597389 13425 net.cpp:100] Creating Layer u3a_relu_u3a_0_split
I0427 16:20:39.597393 13425 net.cpp:434] u3a_relu_u3a_0_split <- u3a
I0427 16:20:39.597398 13425 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_0
I0427 16:20:39.597406 13425 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_1
I0427 16:20:39.597462 13425 net.cpp:150] Setting up u3a_relu_u3a_0_split
I0427 16:20:39.597471 13425 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0427 16:20:39.597476 13425 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0427 16:20:39.597478 13425 net.cpp:165] Memory required for data: 2735714560
I0427 16:20:39.597483 13425 layer_factory.hpp:77] Creating layer crop_d3c-d3cc
I0427 16:20:39.597491 13425 net.cpp:100] Creating Layer crop_d3c-d3cc
I0427 16:20:39.597493 13425 net.cpp:434] crop_d3c-d3cc <- d3c_dropout_d3c_0_split_1
I0427 16:20:39.597498 13425 net.cpp:434] crop_d3c-d3cc <- u3a_relu_u3a_0_split_0
I0427 16:20:39.597504 13425 net.cpp:408] crop_d3c-d3cc -> d3cc
I0427 16:20:39.597530 13425 net.cpp:150] Setting up crop_d3c-d3cc
I0427 16:20:39.597538 13425 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0427 16:20:39.597542 13425 net.cpp:165] Memory required for data: 2750501120
I0427 16:20:39.597545 13425 layer_factory.hpp:77] Creating layer concat_d3cc_u3a-b
I0427 16:20:39.597559 13425 net.cpp:100] Creating Layer concat_d3cc_u3a-b
I0427 16:20:39.597563 13425 net.cpp:434] concat_d3cc_u3a-b <- u3a_relu_u3a_0_split_1
I0427 16:20:39.597568 13425 net.cpp:434] concat_d3cc_u3a-b <- d3cc
I0427 16:20:39.597573 13425 net.cpp:408] concat_d3cc_u3a-b -> u3b
I0427 16:20:39.597599 13425 net.cpp:150] Setting up concat_d3cc_u3a-b
I0427 16:20:39.597606 13425 net.cpp:157] Top shape: 5 1024 38 38 (7393280)
I0427 16:20:39.597609 13425 net.cpp:165] Memory required for data: 2780074240
I0427 16:20:39.597612 13425 layer_factory.hpp:77] Creating layer conv_u3b-c
I0427 16:20:39.597622 13425 net.cpp:100] Creating Layer conv_u3b-c
I0427 16:20:39.597625 13425 net.cpp:434] conv_u3b-c <- u3b
I0427 16:20:39.597635 13425 net.cpp:408] conv_u3b-c -> u3c
I0427 16:20:39.637296 13425 net.cpp:150] Setting up conv_u3b-c
I0427 16:20:39.637315 13425 net.cpp:157] Top shape: 5 512 36 36 (3317760)
I0427 16:20:39.637318 13425 net.cpp:165] Memory required for data: 2793345280
I0427 16:20:39.637326 13425 layer_factory.hpp:77] Creating layer relu_u3c
I0427 16:20:39.637333 13425 net.cpp:100] Creating Layer relu_u3c
I0427 16:20:39.637337 13425 net.cpp:434] relu_u3c <- u3c
I0427 16:20:39.637342 13425 net.cpp:395] relu_u3c -> u3c (in-place)
I0427 16:20:39.637574 13425 net.cpp:150] Setting up relu_u3c
I0427 16:20:39.637588 13425 net.cpp:157] Top shape: 5 512 36 36 (3317760)
I0427 16:20:39.637590 13425 net.cpp:165] Memory required for data: 2806616320
I0427 16:20:39.637593 13425 layer_factory.hpp:77] Creating layer conv_u3c-d
I0427 16:20:39.637603 13425 net.cpp:100] Creating Layer conv_u3c-d
I0427 16:20:39.637608 13425 net.cpp:434] conv_u3c-d <- u3c
I0427 16:20:39.637614 13425 net.cpp:408] conv_u3c-d -> u3d
I0427 16:20:39.657747 13425 net.cpp:150] Setting up conv_u3c-d
I0427 16:20:39.657763 13425 net.cpp:157] Top shape: 5 512 34 34 (2959360)
I0427 16:20:39.657768 13425 net.cpp:165] Memory required for data: 2818453760
I0427 16:20:39.657774 13425 layer_factory.hpp:77] Creating layer relu_u3d
I0427 16:20:39.657804 13425 net.cpp:100] Creating Layer relu_u3d
I0427 16:20:39.657807 13425 net.cpp:434] relu_u3d <- u3d
I0427 16:20:39.657814 13425 net.cpp:395] relu_u3d -> u3d (in-place)
I0427 16:20:39.658799 13425 net.cpp:150] Setting up relu_u3d
I0427 16:20:39.658815 13425 net.cpp:157] Top shape: 5 512 34 34 (2959360)
I0427 16:20:39.658818 13425 net.cpp:165] Memory required for data: 2830291200
I0427 16:20:39.658823 13425 layer_factory.hpp:77] Creating layer upconv_u3d_u2a
I0427 16:20:39.658833 13425 net.cpp:100] Creating Layer upconv_u3d_u2a
I0427 16:20:39.658836 13425 net.cpp:434] upconv_u3d_u2a <- u3d
I0427 16:20:39.658843 13425 net.cpp:408] upconv_u3d_u2a -> u2a
I0427 16:20:39.663803 13425 net.cpp:150] Setting up upconv_u3d_u2a
I0427 16:20:39.663820 13425 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0427 16:20:39.663823 13425 net.cpp:165] Memory required for data: 2853966080
I0427 16:20:39.663830 13425 layer_factory.hpp:77] Creating layer relu_u2a
I0427 16:20:39.663837 13425 net.cpp:100] Creating Layer relu_u2a
I0427 16:20:39.663841 13425 net.cpp:434] relu_u2a <- u2a
I0427 16:20:39.663847 13425 net.cpp:395] relu_u2a -> u2a (in-place)
I0427 16:20:39.664057 13425 net.cpp:150] Setting up relu_u2a
I0427 16:20:39.664069 13425 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0427 16:20:39.664072 13425 net.cpp:165] Memory required for data: 2877640960
I0427 16:20:39.664075 13425 layer_factory.hpp:77] Creating layer u2a_relu_u2a_0_split
I0427 16:20:39.664080 13425 net.cpp:100] Creating Layer u2a_relu_u2a_0_split
I0427 16:20:39.664085 13425 net.cpp:434] u2a_relu_u2a_0_split <- u2a
I0427 16:20:39.664090 13425 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_0
I0427 16:20:39.664104 13425 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_1
I0427 16:20:39.664152 13425 net.cpp:150] Setting up u2a_relu_u2a_0_split
I0427 16:20:39.664163 13425 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0427 16:20:39.664167 13425 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0427 16:20:39.664170 13425 net.cpp:165] Memory required for data: 2924990720
I0427 16:20:39.664173 13425 layer_factory.hpp:77] Creating layer crop_d2c-d2cc
I0427 16:20:39.664181 13425 net.cpp:100] Creating Layer crop_d2c-d2cc
I0427 16:20:39.664186 13425 net.cpp:434] crop_d2c-d2cc <- d2c_relu_d2c_0_split_1
I0427 16:20:39.664189 13425 net.cpp:434] crop_d2c-d2cc <- u2a_relu_u2a_0_split_0
I0427 16:20:39.664196 13425 net.cpp:408] crop_d2c-d2cc -> d2cc
I0427 16:20:39.664222 13425 net.cpp:150] Setting up crop_d2c-d2cc
I0427 16:20:39.664230 13425 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0427 16:20:39.664233 13425 net.cpp:165] Memory required for data: 2948665600
I0427 16:20:39.664237 13425 layer_factory.hpp:77] Creating layer concat_d2cc_u2a-b
I0427 16:20:39.664242 13425 net.cpp:100] Creating Layer concat_d2cc_u2a-b
I0427 16:20:39.664247 13425 net.cpp:434] concat_d2cc_u2a-b <- u2a_relu_u2a_0_split_1
I0427 16:20:39.664250 13425 net.cpp:434] concat_d2cc_u2a-b <- d2cc
I0427 16:20:39.664254 13425 net.cpp:408] concat_d2cc_u2a-b -> u2b
I0427 16:20:39.664279 13425 net.cpp:150] Setting up concat_d2cc_u2a-b
I0427 16:20:39.664288 13425 net.cpp:157] Top shape: 5 512 68 68 (11837440)
I0427 16:20:39.664290 13425 net.cpp:165] Memory required for data: 2996015360
I0427 16:20:39.664294 13425 layer_factory.hpp:77] Creating layer conv_u2b-c
I0427 16:20:39.664302 13425 net.cpp:100] Creating Layer conv_u2b-c
I0427 16:20:39.664306 13425 net.cpp:434] conv_u2b-c <- u2b
I0427 16:20:39.664311 13425 net.cpp:408] conv_u2b-c -> u2c
I0427 16:20:39.674710 13425 net.cpp:150] Setting up conv_u2b-c
I0427 16:20:39.674728 13425 net.cpp:157] Top shape: 5 256 66 66 (5575680)
I0427 16:20:39.674731 13425 net.cpp:165] Memory required for data: 3018318080
I0427 16:20:39.674738 13425 layer_factory.hpp:77] Creating layer relu_u2c
I0427 16:20:39.674746 13425 net.cpp:100] Creating Layer relu_u2c
I0427 16:20:39.674751 13425 net.cpp:434] relu_u2c <- u2c
I0427 16:20:39.674756 13425 net.cpp:395] relu_u2c -> u2c (in-place)
I0427 16:20:39.674973 13425 net.cpp:150] Setting up relu_u2c
I0427 16:20:39.675001 13425 net.cpp:157] Top shape: 5 256 66 66 (5575680)
I0427 16:20:39.675006 13425 net.cpp:165] Memory required for data: 3040620800
I0427 16:20:39.675009 13425 layer_factory.hpp:77] Creating layer conv_u2c-d
I0427 16:20:39.675020 13425 net.cpp:100] Creating Layer conv_u2c-d
I0427 16:20:39.675024 13425 net.cpp:434] conv_u2c-d <- u2c
I0427 16:20:39.675030 13425 net.cpp:408] conv_u2c-d -> u2d
I0427 16:20:39.680543 13425 net.cpp:150] Setting up conv_u2c-d
I0427 16:20:39.680560 13425 net.cpp:157] Top shape: 5 256 64 64 (5242880)
I0427 16:20:39.680563 13425 net.cpp:165] Memory required for data: 3061592320
I0427 16:20:39.680572 13425 layer_factory.hpp:77] Creating layer relu_u2d
I0427 16:20:39.680578 13425 net.cpp:100] Creating Layer relu_u2d
I0427 16:20:39.680583 13425 net.cpp:434] relu_u2d <- u2d
I0427 16:20:39.680588 13425 net.cpp:395] relu_u2d -> u2d (in-place)
I0427 16:20:39.680806 13425 net.cpp:150] Setting up relu_u2d
I0427 16:20:39.680819 13425 net.cpp:157] Top shape: 5 256 64 64 (5242880)
I0427 16:20:39.680821 13425 net.cpp:165] Memory required for data: 3082563840
I0427 16:20:39.680824 13425 layer_factory.hpp:77] Creating layer upconv_u2d_u1a
I0427 16:20:39.680832 13425 net.cpp:100] Creating Layer upconv_u2d_u1a
I0427 16:20:39.680836 13425 net.cpp:434] upconv_u2d_u1a <- u2d
I0427 16:20:39.680843 13425 net.cpp:408] upconv_u2d_u1a -> u1a
I0427 16:20:39.683102 13425 net.cpp:150] Setting up upconv_u2d_u1a
I0427 16:20:39.683120 13425 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0427 16:20:39.683123 13425 net.cpp:165] Memory required for data: 3124506880
I0427 16:20:39.683136 13425 layer_factory.hpp:77] Creating layer relu_u1a
I0427 16:20:39.683145 13425 net.cpp:100] Creating Layer relu_u1a
I0427 16:20:39.683148 13425 net.cpp:434] relu_u1a <- u1a
I0427 16:20:39.683154 13425 net.cpp:395] relu_u1a -> u1a (in-place)
I0427 16:20:39.684134 13425 net.cpp:150] Setting up relu_u1a
I0427 16:20:39.684149 13425 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0427 16:20:39.684154 13425 net.cpp:165] Memory required for data: 3166449920
I0427 16:20:39.684157 13425 layer_factory.hpp:77] Creating layer u1a_relu_u1a_0_split
I0427 16:20:39.684164 13425 net.cpp:100] Creating Layer u1a_relu_u1a_0_split
I0427 16:20:39.684167 13425 net.cpp:434] u1a_relu_u1a_0_split <- u1a
I0427 16:20:39.684175 13425 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_0
I0427 16:20:39.684182 13425 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_1
I0427 16:20:39.684233 13425 net.cpp:150] Setting up u1a_relu_u1a_0_split
I0427 16:20:39.684239 13425 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0427 16:20:39.684244 13425 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0427 16:20:39.684247 13425 net.cpp:165] Memory required for data: 3250336000
I0427 16:20:39.684250 13425 layer_factory.hpp:77] Creating layer crop_d1c-d1cc
I0427 16:20:39.684257 13425 net.cpp:100] Creating Layer crop_d1c-d1cc
I0427 16:20:39.684262 13425 net.cpp:434] crop_d1c-d1cc <- d1c_relu_d1c_0_split_1
I0427 16:20:39.684265 13425 net.cpp:434] crop_d1c-d1cc <- u1a_relu_u1a_0_split_0
I0427 16:20:39.684270 13425 net.cpp:408] crop_d1c-d1cc -> d1cc
I0427 16:20:39.684296 13425 net.cpp:150] Setting up crop_d1c-d1cc
I0427 16:20:39.684309 13425 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0427 16:20:39.684312 13425 net.cpp:165] Memory required for data: 3292279040
I0427 16:20:39.684315 13425 layer_factory.hpp:77] Creating layer concat_d1cc_u1a-b
I0427 16:20:39.684320 13425 net.cpp:100] Creating Layer concat_d1cc_u1a-b
I0427 16:20:39.684324 13425 net.cpp:434] concat_d1cc_u1a-b <- u1a_relu_u1a_0_split_1
I0427 16:20:39.684329 13425 net.cpp:434] concat_d1cc_u1a-b <- d1cc
I0427 16:20:39.684334 13425 net.cpp:408] concat_d1cc_u1a-b -> u1b
I0427 16:20:39.684357 13425 net.cpp:150] Setting up concat_d1cc_u1a-b
I0427 16:20:39.684365 13425 net.cpp:157] Top shape: 5 256 128 128 (20971520)
I0427 16:20:39.684366 13425 net.cpp:165] Memory required for data: 3376165120
I0427 16:20:39.684370 13425 layer_factory.hpp:77] Creating layer conv_u1b-c
I0427 16:20:39.684399 13425 net.cpp:100] Creating Layer conv_u1b-c
I0427 16:20:39.684407 13425 net.cpp:434] conv_u1b-c <- u1b
I0427 16:20:39.684412 13425 net.cpp:408] conv_u1b-c -> u1c
I0427 16:20:39.686754 13425 net.cpp:150] Setting up conv_u1b-c
I0427 16:20:39.686766 13425 net.cpp:157] Top shape: 5 128 126 126 (10160640)
I0427 16:20:39.686769 13425 net.cpp:165] Memory required for data: 3416807680
I0427 16:20:39.686776 13425 layer_factory.hpp:77] Creating layer relu_u1c
I0427 16:20:39.686782 13425 net.cpp:100] Creating Layer relu_u1c
I0427 16:20:39.686785 13425 net.cpp:434] relu_u1c <- u1c
I0427 16:20:39.686791 13425 net.cpp:395] relu_u1c -> u1c (in-place)
I0427 16:20:39.686995 13425 net.cpp:150] Setting up relu_u1c
I0427 16:20:39.687006 13425 net.cpp:157] Top shape: 5 128 126 126 (10160640)
I0427 16:20:39.687010 13425 net.cpp:165] Memory required for data: 3457450240
I0427 16:20:39.687013 13425 layer_factory.hpp:77] Creating layer conv_u1c-d
I0427 16:20:39.687023 13425 net.cpp:100] Creating Layer conv_u1c-d
I0427 16:20:39.687027 13425 net.cpp:434] conv_u1c-d <- u1c
I0427 16:20:39.687033 13425 net.cpp:408] conv_u1c-d -> u1d
I0427 16:20:39.689399 13425 net.cpp:150] Setting up conv_u1c-d
I0427 16:20:39.689415 13425 net.cpp:157] Top shape: 5 128 124 124 (9840640)
I0427 16:20:39.689419 13425 net.cpp:165] Memory required for data: 3496812800
I0427 16:20:39.689425 13425 layer_factory.hpp:77] Creating layer relu_u1d
I0427 16:20:39.689432 13425 net.cpp:100] Creating Layer relu_u1d
I0427 16:20:39.689446 13425 net.cpp:434] relu_u1d <- u1d
I0427 16:20:39.689451 13425 net.cpp:395] relu_u1d -> u1d (in-place)
I0427 16:20:39.689682 13425 net.cpp:150] Setting up relu_u1d
I0427 16:20:39.689695 13425 net.cpp:157] Top shape: 5 128 124 124 (9840640)
I0427 16:20:39.689698 13425 net.cpp:165] Memory required for data: 3536175360
I0427 16:20:39.689702 13425 layer_factory.hpp:77] Creating layer upconv_u1d_u0a
I0427 16:20:39.689713 13425 net.cpp:100] Creating Layer upconv_u1d_u0a
I0427 16:20:39.689716 13425 net.cpp:434] upconv_u1d_u0a <- u1d
I0427 16:20:39.689723 13425 net.cpp:408] upconv_u1d_u0a -> u0a
I0427 16:20:39.690532 13425 net.cpp:150] Setting up upconv_u1d_u0a
I0427 16:20:39.690542 13425 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0427 16:20:39.690546 13425 net.cpp:165] Memory required for data: 3693625600
I0427 16:20:39.690552 13425 layer_factory.hpp:77] Creating layer relu_u0a
I0427 16:20:39.690557 13425 net.cpp:100] Creating Layer relu_u0a
I0427 16:20:39.690562 13425 net.cpp:434] relu_u0a <- u0a
I0427 16:20:39.690568 13425 net.cpp:395] relu_u0a -> u0a (in-place)
I0427 16:20:39.690788 13425 net.cpp:150] Setting up relu_u0a
I0427 16:20:39.690798 13425 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0427 16:20:39.690801 13425 net.cpp:165] Memory required for data: 3851075840
I0427 16:20:39.690805 13425 layer_factory.hpp:77] Creating layer u0a_relu_u0a_0_split
I0427 16:20:39.690811 13425 net.cpp:100] Creating Layer u0a_relu_u0a_0_split
I0427 16:20:39.690814 13425 net.cpp:434] u0a_relu_u0a_0_split <- u0a
I0427 16:20:39.690821 13425 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_0
I0427 16:20:39.690829 13425 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_1
I0427 16:20:39.690881 13425 net.cpp:150] Setting up u0a_relu_u0a_0_split
I0427 16:20:39.690889 13425 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0427 16:20:39.690893 13425 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0427 16:20:39.690896 13425 net.cpp:165] Memory required for data: 4165976320
I0427 16:20:39.690899 13425 layer_factory.hpp:77] Creating layer crop_d0c-d0cc
I0427 16:20:39.690907 13425 net.cpp:100] Creating Layer crop_d0c-d0cc
I0427 16:20:39.690909 13425 net.cpp:434] crop_d0c-d0cc <- d0c_relu_d0c_0_split_1
I0427 16:20:39.690915 13425 net.cpp:434] crop_d0c-d0cc <- u0a_relu_u0a_0_split_0
I0427 16:20:39.690922 13425 net.cpp:408] crop_d0c-d0cc -> d0cc
I0427 16:20:39.690948 13425 net.cpp:150] Setting up crop_d0c-d0cc
I0427 16:20:39.690953 13425 net.cpp:157] Top shape: 5 64 248 248 (19681280)
I0427 16:20:39.690958 13425 net.cpp:165] Memory required for data: 4244701440
I0427 16:20:39.690982 13425 layer_factory.hpp:77] Creating layer concat_d0cc_u0a-b
I0427 16:20:39.690991 13425 net.cpp:100] Creating Layer concat_d0cc_u0a-b
I0427 16:20:39.690994 13425 net.cpp:434] concat_d0cc_u0a-b <- u0a_relu_u0a_0_split_1
I0427 16:20:39.691000 13425 net.cpp:434] concat_d0cc_u0a-b <- d0cc
I0427 16:20:39.691004 13425 net.cpp:408] concat_d0cc_u0a-b -> u0b
I0427 16:20:39.691035 13425 net.cpp:150] Setting up concat_d0cc_u0a-b
I0427 16:20:39.691043 13425 net.cpp:157] Top shape: 5 192 248 248 (59043840)
I0427 16:20:39.691047 13425 net.cpp:165] Memory required for data: 4480876800
I0427 16:20:39.691051 13425 layer_factory.hpp:77] Creating layer conv_u0b-c
I0427 16:20:39.691061 13425 net.cpp:100] Creating Layer conv_u0b-c
I0427 16:20:39.691064 13425 net.cpp:434] conv_u0b-c <- u0b
I0427 16:20:39.691076 13425 net.cpp:408] conv_u0b-c -> u0c
I0427 16:20:39.692183 13425 net.cpp:150] Setting up conv_u0b-c
I0427 16:20:39.692194 13425 net.cpp:157] Top shape: 5 64 246 246 (19365120)
I0427 16:20:39.692198 13425 net.cpp:165] Memory required for data: 4558337280
I0427 16:20:39.692204 13425 layer_factory.hpp:77] Creating layer relu_u0c
I0427 16:20:39.692221 13425 net.cpp:100] Creating Layer relu_u0c
I0427 16:20:39.692226 13425 net.cpp:434] relu_u0c <- u0c
I0427 16:20:39.692231 13425 net.cpp:395] relu_u0c -> u0c (in-place)
I0427 16:20:39.693223 13425 net.cpp:150] Setting up relu_u0c
I0427 16:20:39.693240 13425 net.cpp:157] Top shape: 5 64 246 246 (19365120)
I0427 16:20:39.693243 13425 net.cpp:165] Memory required for data: 4635797760
I0427 16:20:39.693248 13425 layer_factory.hpp:77] Creating layer conv_u0c-d
I0427 16:20:39.693260 13425 net.cpp:100] Creating Layer conv_u0c-d
I0427 16:20:39.693264 13425 net.cpp:434] conv_u0c-d <- u0c
I0427 16:20:39.693272 13425 net.cpp:408] conv_u0c-d -> u0d
I0427 16:20:39.693907 13425 net.cpp:150] Setting up conv_u0c-d
I0427 16:20:39.693919 13425 net.cpp:157] Top shape: 5 64 244 244 (19051520)
I0427 16:20:39.693922 13425 net.cpp:165] Memory required for data: 4712003840
I0427 16:20:39.693929 13425 layer_factory.hpp:77] Creating layer relu_u0d
I0427 16:20:39.693934 13425 net.cpp:100] Creating Layer relu_u0d
I0427 16:20:39.693939 13425 net.cpp:434] relu_u0d <- u0d
I0427 16:20:39.693943 13425 net.cpp:395] relu_u0d -> u0d (in-place)
I0427 16:20:39.694166 13425 net.cpp:150] Setting up relu_u0d
I0427 16:20:39.694177 13425 net.cpp:157] Top shape: 5 64 244 244 (19051520)
I0427 16:20:39.694181 13425 net.cpp:165] Memory required for data: 4788209920
I0427 16:20:39.694185 13425 layer_factory.hpp:77] Creating layer conv_u0d-score
I0427 16:20:39.694195 13425 net.cpp:100] Creating Layer conv_u0d-score
I0427 16:20:39.694197 13425 net.cpp:434] conv_u0d-score <- u0d
I0427 16:20:39.694205 13425 net.cpp:408] conv_u0d-score -> score
I0427 16:20:39.694555 13425 net.cpp:150] Setting up conv_u0d-score
I0427 16:20:39.694564 13425 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0427 16:20:39.694567 13425 net.cpp:165] Memory required for data: 4791782080
I0427 16:20:39.694574 13425 layer_factory.hpp:77] Creating layer score_conv_u0d-score_0_split
I0427 16:20:39.694582 13425 net.cpp:100] Creating Layer score_conv_u0d-score_0_split
I0427 16:20:39.694586 13425 net.cpp:434] score_conv_u0d-score_0_split <- score
I0427 16:20:39.694592 13425 net.cpp:408] score_conv_u0d-score_0_split -> score_conv_u0d-score_0_split_0
I0427 16:20:39.694602 13425 net.cpp:408] score_conv_u0d-score_0_split -> score_conv_u0d-score_0_split_1
I0427 16:20:39.694648 13425 net.cpp:150] Setting up score_conv_u0d-score_0_split
I0427 16:20:39.694655 13425 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0427 16:20:39.694659 13425 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0427 16:20:39.694664 13425 net.cpp:165] Memory required for data: 4798926400
I0427 16:20:39.694666 13425 layer_factory.hpp:77] Creating layer softmax
I0427 16:20:39.694671 13425 net.cpp:100] Creating Layer softmax
I0427 16:20:39.694675 13425 net.cpp:434] softmax <- score_conv_u0d-score_0_split_0
I0427 16:20:39.694681 13425 net.cpp:408] softmax -> softmax_out
I0427 16:20:39.694984 13425 net.cpp:150] Setting up softmax
I0427 16:20:39.694996 13425 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0427 16:20:39.694999 13425 net.cpp:165] Memory required for data: 4802498560
I0427 16:20:39.695003 13425 layer_factory.hpp:77] Creating layer reshapelab
I0427 16:20:39.695013 13425 net.cpp:100] Creating Layer reshapelab
I0427 16:20:39.695016 13425 net.cpp:434] reshapelab <- label
I0427 16:20:39.695022 13425 net.cpp:408] reshapelab -> label_flat
I0427 16:20:39.695065 13425 net.cpp:150] Setting up reshapelab
I0427 16:20:39.695070 13425 net.cpp:157] Top shape: 5 59536 (297680)
I0427 16:20:39.695072 13425 net.cpp:165] Memory required for data: 4803689280
I0427 16:20:39.695075 13425 layer_factory.hpp:77] Creating layer reshaperes
I0427 16:20:39.695081 13425 net.cpp:100] Creating Layer reshaperes
I0427 16:20:39.695086 13425 net.cpp:434] reshaperes <- softmax_out
I0427 16:20:39.695091 13425 net.cpp:408] reshaperes -> softmax_out_flat
I0427 16:20:39.695122 13425 net.cpp:150] Setting up reshaperes
I0427 16:20:39.695133 13425 net.cpp:157] Top shape: 5 3 59536 (893040)
I0427 16:20:39.695137 13425 net.cpp:165] Memory required for data: 4807261440
I0427 16:20:39.695139 13425 layer_factory.hpp:77] Creating layer loss
I0427 16:20:39.706751 13425 net.cpp:100] Creating Layer loss
I0427 16:20:39.706768 13425 net.cpp:434] loss <- softmax_out_flat
I0427 16:20:39.706775 13425 net.cpp:434] loss <- label_flat
I0427 16:20:39.706781 13425 net.cpp:408] loss -> loss
I0427 16:20:39.717646 13425 net.cpp:150] Setting up loss
I0427 16:20:39.717666 13425 net.cpp:157] Top shape: 3 (3)
I0427 16:20:39.717669 13425 net.cpp:160]     with loss weight 1
I0427 16:20:39.717687 13425 net.cpp:165] Memory required for data: 4807261452
I0427 16:20:39.717692 13425 layer_factory.hpp:77] Creating layer visualize
I0427 16:20:39.717701 13425 net.cpp:100] Creating Layer visualize
I0427 16:20:39.717706 13425 net.cpp:434] visualize <- score_conv_u0d-score_0_split_1
I0427 16:20:39.717712 13425 net.cpp:408] visualize -> visualize_out
I0427 16:20:39.718806 13425 net.cpp:150] Setting up visualize
I0427 16:20:39.718824 13425 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0427 16:20:39.718827 13425 net.cpp:165] Memory required for data: 4810833612
I0427 16:20:39.718832 13425 layer_factory.hpp:77] Creating layer fake
I0427 16:20:39.718838 13425 net.cpp:100] Creating Layer fake
I0427 16:20:39.718842 13425 net.cpp:434] fake <- visualize_out
I0427 16:20:39.718848 13425 net.cpp:150] Setting up fake
I0427 16:20:39.718852 13425 net.cpp:165] Memory required for data: 4810833612
I0427 16:20:39.718854 13425 net.cpp:228] fake does not need backward computation.
I0427 16:20:39.718859 13425 net.cpp:228] visualize does not need backward computation.
I0427 16:20:39.718863 13425 net.cpp:226] loss needs backward computation.
I0427 16:20:39.718868 13425 net.cpp:226] reshaperes needs backward computation.
I0427 16:20:39.718871 13425 net.cpp:228] reshapelab does not need backward computation.
I0427 16:20:39.718875 13425 net.cpp:226] softmax needs backward computation.
I0427 16:20:39.718879 13425 net.cpp:226] score_conv_u0d-score_0_split needs backward computation.
I0427 16:20:39.718883 13425 net.cpp:226] conv_u0d-score needs backward computation.
I0427 16:20:39.718886 13425 net.cpp:226] relu_u0d needs backward computation.
I0427 16:20:39.718890 13425 net.cpp:226] conv_u0c-d needs backward computation.
I0427 16:20:39.718894 13425 net.cpp:226] relu_u0c needs backward computation.
I0427 16:20:39.718896 13425 net.cpp:226] conv_u0b-c needs backward computation.
I0427 16:20:39.718900 13425 net.cpp:226] concat_d0cc_u0a-b needs backward computation.
I0427 16:20:39.718904 13425 net.cpp:226] crop_d0c-d0cc needs backward computation.
I0427 16:20:39.718909 13425 net.cpp:226] u0a_relu_u0a_0_split needs backward computation.
I0427 16:20:39.718912 13425 net.cpp:226] relu_u0a needs backward computation.
I0427 16:20:39.718915 13425 net.cpp:226] upconv_u1d_u0a needs backward computation.
I0427 16:20:39.718920 13425 net.cpp:226] relu_u1d needs backward computation.
I0427 16:20:39.718924 13425 net.cpp:226] conv_u1c-d needs backward computation.
I0427 16:20:39.718945 13425 net.cpp:226] relu_u1c needs backward computation.
I0427 16:20:39.718950 13425 net.cpp:226] conv_u1b-c needs backward computation.
I0427 16:20:39.718953 13425 net.cpp:226] concat_d1cc_u1a-b needs backward computation.
I0427 16:20:39.718957 13425 net.cpp:226] crop_d1c-d1cc needs backward computation.
I0427 16:20:39.718961 13425 net.cpp:226] u1a_relu_u1a_0_split needs backward computation.
I0427 16:20:39.718964 13425 net.cpp:226] relu_u1a needs backward computation.
I0427 16:20:39.718969 13425 net.cpp:226] upconv_u2d_u1a needs backward computation.
I0427 16:20:39.718972 13425 net.cpp:226] relu_u2d needs backward computation.
I0427 16:20:39.718976 13425 net.cpp:226] conv_u2c-d needs backward computation.
I0427 16:20:39.718978 13425 net.cpp:226] relu_u2c needs backward computation.
I0427 16:20:39.718982 13425 net.cpp:226] conv_u2b-c needs backward computation.
I0427 16:20:39.718986 13425 net.cpp:226] concat_d2cc_u2a-b needs backward computation.
I0427 16:20:39.718989 13425 net.cpp:226] crop_d2c-d2cc needs backward computation.
I0427 16:20:39.718993 13425 net.cpp:226] u2a_relu_u2a_0_split needs backward computation.
I0427 16:20:39.718997 13425 net.cpp:226] relu_u2a needs backward computation.
I0427 16:20:39.719000 13425 net.cpp:226] upconv_u3d_u2a needs backward computation.
I0427 16:20:39.719003 13425 net.cpp:226] relu_u3d needs backward computation.
I0427 16:20:39.719007 13425 net.cpp:226] conv_u3c-d needs backward computation.
I0427 16:20:39.719012 13425 net.cpp:226] relu_u3c needs backward computation.
I0427 16:20:39.719014 13425 net.cpp:226] conv_u3b-c needs backward computation.
I0427 16:20:39.719017 13425 net.cpp:226] concat_d3cc_u3a-b needs backward computation.
I0427 16:20:39.719022 13425 net.cpp:226] crop_d3c-d3cc needs backward computation.
I0427 16:20:39.719027 13425 net.cpp:226] u3a_relu_u3a_0_split needs backward computation.
I0427 16:20:39.719029 13425 net.cpp:226] relu_u3a needs backward computation.
I0427 16:20:39.719033 13425 net.cpp:226] upconv_d4c_u3a needs backward computation.
I0427 16:20:39.719038 13425 net.cpp:226] dropout_d4c needs backward computation.
I0427 16:20:39.719041 13425 net.cpp:226] relu_d4c needs backward computation.
I0427 16:20:39.719044 13425 net.cpp:226] conv_d4b-c needs backward computation.
I0427 16:20:39.719048 13425 net.cpp:226] relu_d4b needs backward computation.
I0427 16:20:39.719051 13425 net.cpp:226] conv_d4a-b needs backward computation.
I0427 16:20:39.719055 13425 net.cpp:226] pool_d3c-4a needs backward computation.
I0427 16:20:39.719059 13425 net.cpp:226] d3c_dropout_d3c_0_split needs backward computation.
I0427 16:20:39.719063 13425 net.cpp:226] dropout_d3c needs backward computation.
I0427 16:20:39.719066 13425 net.cpp:226] relu_d3c needs backward computation.
I0427 16:20:39.719070 13425 net.cpp:226] conv_d3b-c needs backward computation.
I0427 16:20:39.719074 13425 net.cpp:226] relu_d3b needs backward computation.
I0427 16:20:39.719076 13425 net.cpp:226] conv_d3a-b needs backward computation.
I0427 16:20:39.719079 13425 net.cpp:226] pool_d2c-3a needs backward computation.
I0427 16:20:39.719084 13425 net.cpp:226] d2c_relu_d2c_0_split needs backward computation.
I0427 16:20:39.719087 13425 net.cpp:226] relu_d2c needs backward computation.
I0427 16:20:39.719091 13425 net.cpp:226] conv_d2b-c needs backward computation.
I0427 16:20:39.719094 13425 net.cpp:226] relu_d2b needs backward computation.
I0427 16:20:39.719099 13425 net.cpp:226] conv_d2a-b needs backward computation.
I0427 16:20:39.719101 13425 net.cpp:226] pool_d1c-2a needs backward computation.
I0427 16:20:39.719105 13425 net.cpp:226] d1c_relu_d1c_0_split needs backward computation.
I0427 16:20:39.719108 13425 net.cpp:226] relu_d1c needs backward computation.
I0427 16:20:39.719112 13425 net.cpp:226] conv_d1b-c needs backward computation.
I0427 16:20:39.719116 13425 net.cpp:226] relu_d1b needs backward computation.
I0427 16:20:39.719120 13425 net.cpp:226] conv_d1a-b needs backward computation.
I0427 16:20:39.719122 13425 net.cpp:226] pool_d0c-1a needs backward computation.
I0427 16:20:39.719136 13425 net.cpp:226] d0c_relu_d0c_0_split needs backward computation.
I0427 16:20:39.719141 13425 net.cpp:226] relu_d0c needs backward computation.
I0427 16:20:39.719143 13425 net.cpp:226] conv_d0b-c needs backward computation.
I0427 16:20:39.719147 13425 net.cpp:226] relu_d0b needs backward computation.
I0427 16:20:39.719151 13425 net.cpp:226] conv_d0a-b needs backward computation.
I0427 16:20:39.719156 13425 net.cpp:228] loaddata does not need backward computation.
I0427 16:20:39.719163 13425 net.cpp:270] This network produces output loss
I0427 16:20:39.719218 13425 net.cpp:283] Network initialization done.
I0427 16:20:39.719926 13425 solver.cpp:181] Creating test net (#0) specified by net file: ./unet_f1_3/unet_f1_3.prototxt
I0427 16:20:39.720005 13425 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer loaddata
I0427 16:20:39.720026 13425 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer dropout_d3c
I0427 16:20:39.720033 13425 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer dropout_d4c
I0427 16:20:39.720055 13425 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer visualize
I0427 16:20:39.720062 13425 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer fake
I0427 16:20:39.720417 13425 net.cpp:58] Initializing net from parameters: 
name: "unet_f1_3"
force_backward: true
state {
  phase: TEST
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "caffeHDF5_validation_3.txt"
    batch_size: 1
  }
}
layer {
  name: "conv_d0a-b"
  type: "Convolution"
  bottom: "data"
  top: "d0b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0b"
  type: "ReLU"
  bottom: "d0b"
  top: "d0b"
}
layer {
  name: "conv_d0b-c"
  type: "Convolution"
  bottom: "d0b"
  top: "d0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0c"
  type: "ReLU"
  bottom: "d0c"
  top: "d0c"
}
layer {
  name: "pool_d0c-1a"
  type: "Pooling"
  bottom: "d0c"
  top: "d1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d1a-b"
  type: "Convolution"
  bottom: "d1a"
  top: "d1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1b"
  type: "ReLU"
  bottom: "d1b"
  top: "d1b"
}
layer {
  name: "conv_d1b-c"
  type: "Convolution"
  bottom: "d1b"
  top: "d1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1c"
  type: "ReLU"
  bottom: "d1c"
  top: "d1c"
}
layer {
  name: "pool_d1c-2a"
  type: "Pooling"
  bottom: "d1c"
  top: "d2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d2a-b"
  type: "Convolution"
  bottom: "d2a"
  top: "d2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2b"
  type: "ReLU"
  bottom: "d2b"
  top: "d2b"
}
layer {
  name: "conv_d2b-c"
  type: "Convolution"
  bottom: "d2b"
  top: "d2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2c"
  type: "ReLU"
  bottom: "d2c"
  top: "d2c"
}
layer {
  name: "pool_d2c-3a"
  type: "Pooling"
  bottom: "d2c"
  top: "d3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d3a-b"
  type: "Convolution"
  bottom: "d3a"
  top: "d3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3b"
  type: "ReLU"
  bottom: "d3b"
  top: "d3b"
}
layer {
  name: "conv_d3b-c"
  type: "Convolution"
  bottom: "d3b"
  top: "d3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3c"
  type: "ReLU"
  bottom: "d3c"
  top: "d3c"
}
layer {
  name: "pool_d3c-4a"
  type: "Pooling"
  bottom: "d3c"
  top: "d4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d4a-b"
  type: "Convolution"
  bottom: "d4a"
  top: "d4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4b"
  type: "ReLU"
  bottom: "d4b"
  top: "d4b"
}
layer {
  name: "conv_d4b-c"
  type: "Convolution"
  bottom: "d4b"
  top: "d4c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4c"
  type: "ReLU"
  bottom: "d4c"
  top: "d4c"
}
layer {
  name: "upconv_d4c_u3a"
  type: "Deconvolution"
  bottom: "d4c"
  top: "u3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u3a"
  type: "ReLU"
  bottom: "u3a"
  top: "u3a"
}
layer {
  name: "crop_d3c-d3cc"
  type: "Crop"
  bottom: "d3c"
  bottom: "u3a"
  top: "d3cc"
  crop_param {
    axis: 2
    offset: 4
  }
}
layer {
  name: "concat_d3cc_u3a-b"
  type: "Concat"
  bottom: "u3a"
  bottom: "d3cc"
  top: "u3b"
}
layer {
  name: "conv_u3b-c"
  type: "Convolution"
  bottom: "u3b"
  top: "u3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3c"
  type: "ReLU"
  bottom: "u3c"
  top: "u3c"
}
layer {
  name: "conv_u3c-d"
  type: "Convolution"
  bottom: "u3c"
  top: "u3d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3d"
  type: "ReLU"
  bottom: "u3d"
  top: "u3d"
}
layer {
  name: "upconv_u3d_u2a"
  type: "Deconvolution"
  bottom: "u3d"
  top: "u2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u2a"
  type: "ReLU"
  bottom: "u2a"
  top: "u2a"
}
layer {
  name: "crop_d2c-d2cc"
  type: "Crop"
  bottom: "d2c"
  bottom: "u2a"
  top: "d2cc"
  crop_param {
    axis: 2
    offset: 16
  }
}
layer {
  name: "concat_d2cc_u2a-b"
  type: "Concat"
  bottom: "u2a"
  bottom: "d2cc"
  top: "u2b"
}
layer {
  name: "conv_u2b-c"
  type: "Convolution"
  bottom: "u2b"
  top: "u2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2c"
  type: "ReLU"
  bottom: "u2c"
  top: "u2c"
}
layer {
  name: "conv_u2c-d"
  type: "Convolution"
  bottom: "u2c"
  top: "u2d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2d"
  type: "ReLU"
  bottom: "u2d"
  top: "u2d"
}
layer {
  name: "upconv_u2d_u1a"
  type: "Deconvolution"
  bottom: "u2d"
  top: "u1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u1a"
  type: "ReLU"
  bottom: "u1a"
  top: "u1a"
}
layer {
  name: "crop_d1c-d1cc"
  type: "Crop"
  bottom: "d1c"
  bottom: "u1a"
  top: "d1cc"
  crop_param {
    axis: 2
    offset: 40
  }
}
layer {
  name: "concat_d1cc_u1a-b"
  type: "Concat"
  bottom: "u1a"
  bottom: "d1cc"
  top: "u1b"
}
layer {
  name: "conv_u1b-c"
  type: "Convolution"
  bottom: "u1b"
  top: "u1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1c"
  type: "ReLU"
  bottom: "u1c"
  top: "u1c"
}
layer {
  name: "conv_u1c-d"
  type: "Convolution"
  bottom: "u1c"
  top: "u1d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1d"
  type: "ReLU"
  bottom: "u1d"
  top: "u1d"
}
layer {
  name: "upconv_u1d_u0a"
  type: "Deconvolution"
  bottom: "u1d"
  top: "u0a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u0a"
  type: "ReLU"
  bottom: "u0a"
  top: "u0a"
}
layer {
  name: "crop_d0c-d0cc"
  type: "Crop"
  bottom: "d0c"
  bottom: "u0a"
  top: "d0cc"
  crop_param {
    axis: 2
    offset: 88
  }
}
layer {
  name: "concat_d0cc_u0a-b"
  type: "Concat"
  bottom: "u0a"
  bottom: "d0cc"
  top: "u0b"
}
layer {
  name: "conv_u0b-c"
  type: "Convolution"
  bottom: "u0b"
  top: "u0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0c"
  type: "ReLU"
  bottom: "u0c"
  top: "u0c"
}
layer {
  name: "conv_u0c-d"
  type: "Convolution"
  bottom: "u0c"
  top: "u0d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0d"
  type: "ReLU"
  bottom: "u0d"
  top: "u0d"
}
layer {
  name: "conv_u0d-score"
  type: "Convolution"
  bottom: "u0d"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "score"
  top: "softmax_out"
}
layer {
  name: "reshapelab"
  type: "Reshape"
  bottom: "label"
  top: "label_flat"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "reshaperes"
  type: "Reshape"
  bottom: "softmax_out"
  top: "softmax_out_flat"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "loss"
  type: "Python"
  bottom: "softmax_out_flat"
  bottom: "label_flat"
  top: "loss"
  loss_weight: 1
  python_param {
    module: "multiclass_f1_loss"
    layer: "F1Loss"
  }
}
I0427 16:20:39.720685 13425 layer_factory.hpp:77] Creating layer loaddata
I0427 16:20:39.720697 13425 net.cpp:100] Creating Layer loaddata
I0427 16:20:39.720701 13425 net.cpp:408] loaddata -> data
I0427 16:20:39.720710 13425 net.cpp:408] loaddata -> label
I0427 16:20:39.720717 13425 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: caffeHDF5_validation_3.txt
I0427 16:20:39.731802 13425 hdf5_data_layer.cpp:93] Number of HDF5 files: 10
I0427 16:20:42.401340 13425 net.cpp:150] Setting up loaddata
I0427 16:20:42.401376 13425 net.cpp:157] Top shape: 1 3 428 428 (549552)
I0427 16:20:42.401381 13425 net.cpp:157] Top shape: 1 244 244 (59536)
I0427 16:20:42.401386 13425 net.cpp:165] Memory required for data: 2436352
I0427 16:20:42.401394 13425 layer_factory.hpp:77] Creating layer conv_d0a-b
I0427 16:20:42.401419 13425 net.cpp:100] Creating Layer conv_d0a-b
I0427 16:20:42.401424 13425 net.cpp:434] conv_d0a-b <- data
I0427 16:20:42.401459 13425 net.cpp:408] conv_d0a-b -> d0b
I0427 16:20:42.402122 13425 net.cpp:150] Setting up conv_d0a-b
I0427 16:20:42.402139 13425 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0427 16:20:42.402143 13425 net.cpp:165] Memory required for data: 48894208
I0427 16:20:42.402158 13425 layer_factory.hpp:77] Creating layer relu_d0b
I0427 16:20:42.402168 13425 net.cpp:100] Creating Layer relu_d0b
I0427 16:20:42.402171 13425 net.cpp:434] relu_d0b <- d0b
I0427 16:20:42.402178 13425 net.cpp:395] relu_d0b -> d0b (in-place)
I0427 16:20:42.402516 13425 net.cpp:150] Setting up relu_d0b
I0427 16:20:42.402530 13425 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0427 16:20:42.402534 13425 net.cpp:165] Memory required for data: 95352064
I0427 16:20:42.402537 13425 layer_factory.hpp:77] Creating layer conv_d0b-c
I0427 16:20:42.402549 13425 net.cpp:100] Creating Layer conv_d0b-c
I0427 16:20:42.402554 13425 net.cpp:434] conv_d0b-c <- d0b
I0427 16:20:42.402560 13425 net.cpp:408] conv_d0b-c -> d0c
I0427 16:20:42.403446 13425 net.cpp:150] Setting up conv_d0b-c
I0427 16:20:42.403462 13425 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0427 16:20:42.403465 13425 net.cpp:165] Memory required for data: 141374720
I0427 16:20:42.403475 13425 layer_factory.hpp:77] Creating layer relu_d0c
I0427 16:20:42.403484 13425 net.cpp:100] Creating Layer relu_d0c
I0427 16:20:42.403489 13425 net.cpp:434] relu_d0c <- d0c
I0427 16:20:42.403496 13425 net.cpp:395] relu_d0c -> d0c (in-place)
I0427 16:20:42.403770 13425 net.cpp:150] Setting up relu_d0c
I0427 16:20:42.403784 13425 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0427 16:20:42.403787 13425 net.cpp:165] Memory required for data: 187397376
I0427 16:20:42.403791 13425 layer_factory.hpp:77] Creating layer d0c_relu_d0c_0_split
I0427 16:20:42.403800 13425 net.cpp:100] Creating Layer d0c_relu_d0c_0_split
I0427 16:20:42.403803 13425 net.cpp:434] d0c_relu_d0c_0_split <- d0c
I0427 16:20:42.403811 13425 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_0
I0427 16:20:42.403822 13425 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_1
I0427 16:20:42.403884 13425 net.cpp:150] Setting up d0c_relu_d0c_0_split
I0427 16:20:42.403893 13425 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0427 16:20:42.403899 13425 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0427 16:20:42.403903 13425 net.cpp:165] Memory required for data: 279442688
I0427 16:20:42.403905 13425 layer_factory.hpp:77] Creating layer pool_d0c-1a
I0427 16:20:42.403913 13425 net.cpp:100] Creating Layer pool_d0c-1a
I0427 16:20:42.403918 13425 net.cpp:434] pool_d0c-1a <- d0c_relu_d0c_0_split_0
I0427 16:20:42.403966 13425 net.cpp:408] pool_d0c-1a -> d1a
I0427 16:20:42.404042 13425 net.cpp:150] Setting up pool_d0c-1a
I0427 16:20:42.404053 13425 net.cpp:157] Top shape: 1 64 212 212 (2876416)
I0427 16:20:42.404058 13425 net.cpp:165] Memory required for data: 290948352
I0427 16:20:42.404062 13425 layer_factory.hpp:77] Creating layer conv_d1a-b
I0427 16:20:42.404074 13425 net.cpp:100] Creating Layer conv_d1a-b
I0427 16:20:42.404078 13425 net.cpp:434] conv_d1a-b <- d1a
I0427 16:20:42.404088 13425 net.cpp:408] conv_d1a-b -> d1b
I0427 16:20:42.406514 13425 net.cpp:150] Setting up conv_d1a-b
I0427 16:20:42.406538 13425 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0427 16:20:42.406541 13425 net.cpp:165] Memory required for data: 313527552
I0427 16:20:42.406556 13425 layer_factory.hpp:77] Creating layer relu_d1b
I0427 16:20:42.406568 13425 net.cpp:100] Creating Layer relu_d1b
I0427 16:20:42.406571 13425 net.cpp:434] relu_d1b <- d1b
I0427 16:20:42.406579 13425 net.cpp:395] relu_d1b -> d1b (in-place)
I0427 16:20:42.406875 13425 net.cpp:150] Setting up relu_d1b
I0427 16:20:42.406890 13425 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0427 16:20:42.406894 13425 net.cpp:165] Memory required for data: 336106752
I0427 16:20:42.406898 13425 layer_factory.hpp:77] Creating layer conv_d1b-c
I0427 16:20:42.406910 13425 net.cpp:100] Creating Layer conv_d1b-c
I0427 16:20:42.406914 13425 net.cpp:434] conv_d1b-c <- d1b
I0427 16:20:42.406921 13425 net.cpp:408] conv_d1b-c -> d1c
I0427 16:20:42.409858 13425 net.cpp:150] Setting up conv_d1b-c
I0427 16:20:42.409883 13425 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0427 16:20:42.409888 13425 net.cpp:165] Memory required for data: 358257920
I0427 16:20:42.409896 13425 layer_factory.hpp:77] Creating layer relu_d1c
I0427 16:20:42.409904 13425 net.cpp:100] Creating Layer relu_d1c
I0427 16:20:42.409909 13425 net.cpp:434] relu_d1c <- d1c
I0427 16:20:42.409916 13425 net.cpp:395] relu_d1c -> d1c (in-place)
I0427 16:20:42.411123 13425 net.cpp:150] Setting up relu_d1c
I0427 16:20:42.411145 13425 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0427 16:20:42.411150 13425 net.cpp:165] Memory required for data: 380409088
I0427 16:20:42.411154 13425 layer_factory.hpp:77] Creating layer d1c_relu_d1c_0_split
I0427 16:20:42.411164 13425 net.cpp:100] Creating Layer d1c_relu_d1c_0_split
I0427 16:20:42.411167 13425 net.cpp:434] d1c_relu_d1c_0_split <- d1c
I0427 16:20:42.411176 13425 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_0
I0427 16:20:42.411187 13425 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_1
I0427 16:20:42.411257 13425 net.cpp:150] Setting up d1c_relu_d1c_0_split
I0427 16:20:42.411269 13425 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0427 16:20:42.411275 13425 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0427 16:20:42.411278 13425 net.cpp:165] Memory required for data: 424711424
I0427 16:20:42.411281 13425 layer_factory.hpp:77] Creating layer pool_d1c-2a
I0427 16:20:42.411289 13425 net.cpp:100] Creating Layer pool_d1c-2a
I0427 16:20:42.411293 13425 net.cpp:434] pool_d1c-2a <- d1c_relu_d1c_0_split_0
I0427 16:20:42.411300 13425 net.cpp:408] pool_d1c-2a -> d2a
I0427 16:20:42.411352 13425 net.cpp:150] Setting up pool_d1c-2a
I0427 16:20:42.411363 13425 net.cpp:157] Top shape: 1 128 104 104 (1384448)
I0427 16:20:42.411367 13425 net.cpp:165] Memory required for data: 430249216
I0427 16:20:42.411370 13425 layer_factory.hpp:77] Creating layer conv_d2a-b
I0427 16:20:42.411382 13425 net.cpp:100] Creating Layer conv_d2a-b
I0427 16:20:42.411386 13425 net.cpp:434] conv_d2a-b <- d2a
I0427 16:20:42.411396 13425 net.cpp:408] conv_d2a-b -> d2b
I0427 16:20:42.414085 13425 net.cpp:150] Setting up conv_d2a-b
I0427 16:20:42.414100 13425 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0427 16:20:42.414103 13425 net.cpp:165] Memory required for data: 440902912
I0427 16:20:42.414118 13425 layer_factory.hpp:77] Creating layer relu_d2b
I0427 16:20:42.414124 13425 net.cpp:100] Creating Layer relu_d2b
I0427 16:20:42.414129 13425 net.cpp:434] relu_d2b <- d2b
I0427 16:20:42.414160 13425 net.cpp:395] relu_d2b -> d2b (in-place)
I0427 16:20:42.414419 13425 net.cpp:150] Setting up relu_d2b
I0427 16:20:42.414433 13425 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0427 16:20:42.414436 13425 net.cpp:165] Memory required for data: 451556608
I0427 16:20:42.414443 13425 layer_factory.hpp:77] Creating layer conv_d2b-c
I0427 16:20:42.414453 13425 net.cpp:100] Creating Layer conv_d2b-c
I0427 16:20:42.414458 13425 net.cpp:434] conv_d2b-c <- d2b
I0427 16:20:42.414465 13425 net.cpp:408] conv_d2b-c -> d2c
I0427 16:20:42.420848 13425 net.cpp:150] Setting up conv_d2b-c
I0427 16:20:42.420872 13425 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0427 16:20:42.420876 13425 net.cpp:165] Memory required for data: 461796608
I0427 16:20:42.420884 13425 layer_factory.hpp:77] Creating layer relu_d2c
I0427 16:20:42.420895 13425 net.cpp:100] Creating Layer relu_d2c
I0427 16:20:42.420903 13425 net.cpp:434] relu_d2c <- d2c
I0427 16:20:42.420909 13425 net.cpp:395] relu_d2c -> d2c (in-place)
I0427 16:20:42.421174 13425 net.cpp:150] Setting up relu_d2c
I0427 16:20:42.421188 13425 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0427 16:20:42.421193 13425 net.cpp:165] Memory required for data: 472036608
I0427 16:20:42.421196 13425 layer_factory.hpp:77] Creating layer d2c_relu_d2c_0_split
I0427 16:20:42.421203 13425 net.cpp:100] Creating Layer d2c_relu_d2c_0_split
I0427 16:20:42.421217 13425 net.cpp:434] d2c_relu_d2c_0_split <- d2c
I0427 16:20:42.421226 13425 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_0
I0427 16:20:42.421234 13425 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_1
I0427 16:20:42.421296 13425 net.cpp:150] Setting up d2c_relu_d2c_0_split
I0427 16:20:42.421308 13425 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0427 16:20:42.421314 13425 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0427 16:20:42.421316 13425 net.cpp:165] Memory required for data: 492516608
I0427 16:20:42.421319 13425 layer_factory.hpp:77] Creating layer pool_d2c-3a
I0427 16:20:42.421326 13425 net.cpp:100] Creating Layer pool_d2c-3a
I0427 16:20:42.421331 13425 net.cpp:434] pool_d2c-3a <- d2c_relu_d2c_0_split_0
I0427 16:20:42.421339 13425 net.cpp:408] pool_d2c-3a -> d3a
I0427 16:20:42.421394 13425 net.cpp:150] Setting up pool_d2c-3a
I0427 16:20:42.421406 13425 net.cpp:157] Top shape: 1 256 50 50 (640000)
I0427 16:20:42.421411 13425 net.cpp:165] Memory required for data: 495076608
I0427 16:20:42.421413 13425 layer_factory.hpp:77] Creating layer conv_d3a-b
I0427 16:20:42.421424 13425 net.cpp:100] Creating Layer conv_d3a-b
I0427 16:20:42.421428 13425 net.cpp:434] conv_d3a-b <- d3a
I0427 16:20:42.421450 13425 net.cpp:408] conv_d3a-b -> d3b
I0427 16:20:42.432955 13425 net.cpp:150] Setting up conv_d3a-b
I0427 16:20:42.432976 13425 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0427 16:20:42.432981 13425 net.cpp:165] Memory required for data: 499795200
I0427 16:20:42.432989 13425 layer_factory.hpp:77] Creating layer relu_d3b
I0427 16:20:42.432996 13425 net.cpp:100] Creating Layer relu_d3b
I0427 16:20:42.433001 13425 net.cpp:434] relu_d3b <- d3b
I0427 16:20:42.433007 13425 net.cpp:395] relu_d3b -> d3b (in-place)
I0427 16:20:42.433271 13425 net.cpp:150] Setting up relu_d3b
I0427 16:20:42.433285 13425 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0427 16:20:42.433289 13425 net.cpp:165] Memory required for data: 504513792
I0427 16:20:42.433292 13425 layer_factory.hpp:77] Creating layer conv_d3b-c
I0427 16:20:42.433305 13425 net.cpp:100] Creating Layer conv_d3b-c
I0427 16:20:42.433308 13425 net.cpp:434] conv_d3b-c <- d3b
I0427 16:20:42.433315 13425 net.cpp:408] conv_d3b-c -> d3c
I0427 16:20:42.454576 13425 net.cpp:150] Setting up conv_d3b-c
I0427 16:20:42.454598 13425 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0427 16:20:42.454602 13425 net.cpp:165] Memory required for data: 508847360
I0427 16:20:42.454609 13425 layer_factory.hpp:77] Creating layer relu_d3c
I0427 16:20:42.454617 13425 net.cpp:100] Creating Layer relu_d3c
I0427 16:20:42.454622 13425 net.cpp:434] relu_d3c <- d3c
I0427 16:20:42.454649 13425 net.cpp:395] relu_d3c -> d3c (in-place)
I0427 16:20:42.455857 13425 net.cpp:150] Setting up relu_d3c
I0427 16:20:42.455875 13425 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0427 16:20:42.455880 13425 net.cpp:165] Memory required for data: 513180928
I0427 16:20:42.455884 13425 layer_factory.hpp:77] Creating layer d3c_relu_d3c_0_split
I0427 16:20:42.455891 13425 net.cpp:100] Creating Layer d3c_relu_d3c_0_split
I0427 16:20:42.455895 13425 net.cpp:434] d3c_relu_d3c_0_split <- d3c
I0427 16:20:42.455904 13425 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_0
I0427 16:20:42.455914 13425 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_1
I0427 16:20:42.455976 13425 net.cpp:150] Setting up d3c_relu_d3c_0_split
I0427 16:20:42.455984 13425 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0427 16:20:42.455991 13425 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0427 16:20:42.455992 13425 net.cpp:165] Memory required for data: 521848064
I0427 16:20:42.455996 13425 layer_factory.hpp:77] Creating layer pool_d3c-4a
I0427 16:20:42.456003 13425 net.cpp:100] Creating Layer pool_d3c-4a
I0427 16:20:42.456008 13425 net.cpp:434] pool_d3c-4a <- d3c_relu_d3c_0_split_0
I0427 16:20:42.456014 13425 net.cpp:408] pool_d3c-4a -> d4a
I0427 16:20:42.456059 13425 net.cpp:150] Setting up pool_d3c-4a
I0427 16:20:42.456068 13425 net.cpp:157] Top shape: 1 512 23 23 (270848)
I0427 16:20:42.456073 13425 net.cpp:165] Memory required for data: 522931456
I0427 16:20:42.456075 13425 layer_factory.hpp:77] Creating layer conv_d4a-b
I0427 16:20:42.456085 13425 net.cpp:100] Creating Layer conv_d4a-b
I0427 16:20:42.456090 13425 net.cpp:434] conv_d4a-b <- d4a
I0427 16:20:42.456099 13425 net.cpp:408] conv_d4a-b -> d4b
I0427 16:20:42.496729 13425 net.cpp:150] Setting up conv_d4a-b
I0427 16:20:42.496749 13425 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0427 16:20:42.496752 13425 net.cpp:165] Memory required for data: 524737792
I0427 16:20:42.496767 13425 layer_factory.hpp:77] Creating layer relu_d4b
I0427 16:20:42.496775 13425 net.cpp:100] Creating Layer relu_d4b
I0427 16:20:42.496780 13425 net.cpp:434] relu_d4b <- d4b
I0427 16:20:42.496786 13425 net.cpp:395] relu_d4b -> d4b (in-place)
I0427 16:20:42.497025 13425 net.cpp:150] Setting up relu_d4b
I0427 16:20:42.497037 13425 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0427 16:20:42.497040 13425 net.cpp:165] Memory required for data: 526544128
I0427 16:20:42.497043 13425 layer_factory.hpp:77] Creating layer conv_d4b-c
I0427 16:20:42.497054 13425 net.cpp:100] Creating Layer conv_d4b-c
I0427 16:20:42.497058 13425 net.cpp:434] conv_d4b-c <- d4b
I0427 16:20:42.497066 13425 net.cpp:408] conv_d4b-c -> d4c
I0427 16:20:42.576977 13425 net.cpp:150] Setting up conv_d4b-c
I0427 16:20:42.577003 13425 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0427 16:20:42.577008 13425 net.cpp:165] Memory required for data: 528022784
I0427 16:20:42.577018 13425 layer_factory.hpp:77] Creating layer relu_d4c
I0427 16:20:42.577028 13425 net.cpp:100] Creating Layer relu_d4c
I0427 16:20:42.577033 13425 net.cpp:434] relu_d4c <- d4c
I0427 16:20:42.577041 13425 net.cpp:395] relu_d4c -> d4c (in-place)
I0427 16:20:42.577322 13425 net.cpp:150] Setting up relu_d4c
I0427 16:20:42.577333 13425 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0427 16:20:42.577337 13425 net.cpp:165] Memory required for data: 529501440
I0427 16:20:42.577342 13425 layer_factory.hpp:77] Creating layer upconv_d4c_u3a
I0427 16:20:42.577352 13425 net.cpp:100] Creating Layer upconv_d4c_u3a
I0427 16:20:42.577355 13425 net.cpp:434] upconv_d4c_u3a <- d4c
I0427 16:20:42.577363 13425 net.cpp:408] upconv_d4c_u3a -> u3a
I0427 16:20:42.595623 13425 net.cpp:150] Setting up upconv_d4c_u3a
I0427 16:20:42.595640 13425 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0427 16:20:42.595643 13425 net.cpp:165] Memory required for data: 532458752
I0427 16:20:42.595652 13425 layer_factory.hpp:77] Creating layer relu_u3a
I0427 16:20:42.595659 13425 net.cpp:100] Creating Layer relu_u3a
I0427 16:20:42.595664 13425 net.cpp:434] relu_u3a <- u3a
I0427 16:20:42.595669 13425 net.cpp:395] relu_u3a -> u3a (in-place)
I0427 16:20:42.595932 13425 net.cpp:150] Setting up relu_u3a
I0427 16:20:42.595944 13425 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0427 16:20:42.595948 13425 net.cpp:165] Memory required for data: 535416064
I0427 16:20:42.595952 13425 layer_factory.hpp:77] Creating layer u3a_relu_u3a_0_split
I0427 16:20:42.595959 13425 net.cpp:100] Creating Layer u3a_relu_u3a_0_split
I0427 16:20:42.595963 13425 net.cpp:434] u3a_relu_u3a_0_split <- u3a
I0427 16:20:42.595969 13425 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_0
I0427 16:20:42.595978 13425 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_1
I0427 16:20:42.596035 13425 net.cpp:150] Setting up u3a_relu_u3a_0_split
I0427 16:20:42.596043 13425 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0427 16:20:42.596047 13425 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0427 16:20:42.596050 13425 net.cpp:165] Memory required for data: 541330688
I0427 16:20:42.596053 13425 layer_factory.hpp:77] Creating layer crop_d3c-d3cc
I0427 16:20:42.596067 13425 net.cpp:100] Creating Layer crop_d3c-d3cc
I0427 16:20:42.596071 13425 net.cpp:434] crop_d3c-d3cc <- d3c_relu_d3c_0_split_1
I0427 16:20:42.596076 13425 net.cpp:434] crop_d3c-d3cc <- u3a_relu_u3a_0_split_0
I0427 16:20:42.596082 13425 net.cpp:408] crop_d3c-d3cc -> d3cc
I0427 16:20:42.596123 13425 net.cpp:150] Setting up crop_d3c-d3cc
I0427 16:20:42.596132 13425 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0427 16:20:42.596135 13425 net.cpp:165] Memory required for data: 544288000
I0427 16:20:42.596139 13425 layer_factory.hpp:77] Creating layer concat_d3cc_u3a-b
I0427 16:20:42.596145 13425 net.cpp:100] Creating Layer concat_d3cc_u3a-b
I0427 16:20:42.596148 13425 net.cpp:434] concat_d3cc_u3a-b <- u3a_relu_u3a_0_split_1
I0427 16:20:42.596153 13425 net.cpp:434] concat_d3cc_u3a-b <- d3cc
I0427 16:20:42.596159 13425 net.cpp:408] concat_d3cc_u3a-b -> u3b
I0427 16:20:42.596187 13425 net.cpp:150] Setting up concat_d3cc_u3a-b
I0427 16:20:42.596195 13425 net.cpp:157] Top shape: 1 1024 38 38 (1478656)
I0427 16:20:42.596199 13425 net.cpp:165] Memory required for data: 550202624
I0427 16:20:42.596201 13425 layer_factory.hpp:77] Creating layer conv_u3b-c
I0427 16:20:42.596211 13425 net.cpp:100] Creating Layer conv_u3b-c
I0427 16:20:42.596215 13425 net.cpp:434] conv_u3b-c <- u3b
I0427 16:20:42.596220 13425 net.cpp:408] conv_u3b-c -> u3c
I0427 16:20:42.635795 13425 net.cpp:150] Setting up conv_u3b-c
I0427 16:20:42.635815 13425 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0427 16:20:42.635819 13425 net.cpp:165] Memory required for data: 552856832
I0427 16:20:42.635828 13425 layer_factory.hpp:77] Creating layer relu_u3c
I0427 16:20:42.635836 13425 net.cpp:100] Creating Layer relu_u3c
I0427 16:20:42.635840 13425 net.cpp:434] relu_u3c <- u3c
I0427 16:20:42.635849 13425 net.cpp:395] relu_u3c -> u3c (in-place)
I0427 16:20:42.636907 13425 net.cpp:150] Setting up relu_u3c
I0427 16:20:42.636924 13425 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0427 16:20:42.636929 13425 net.cpp:165] Memory required for data: 555511040
I0427 16:20:42.636931 13425 layer_factory.hpp:77] Creating layer conv_u3c-d
I0427 16:20:42.636945 13425 net.cpp:100] Creating Layer conv_u3c-d
I0427 16:20:42.636950 13425 net.cpp:434] conv_u3c-d <- u3c
I0427 16:20:42.636956 13425 net.cpp:408] conv_u3c-d -> u3d
I0427 16:20:42.657287 13425 net.cpp:150] Setting up conv_u3c-d
I0427 16:20:42.657305 13425 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0427 16:20:42.657310 13425 net.cpp:165] Memory required for data: 557878528
I0427 16:20:42.657316 13425 layer_factory.hpp:77] Creating layer relu_u3d
I0427 16:20:42.657323 13425 net.cpp:100] Creating Layer relu_u3d
I0427 16:20:42.657327 13425 net.cpp:434] relu_u3d <- u3d
I0427 16:20:42.657335 13425 net.cpp:395] relu_u3d -> u3d (in-place)
I0427 16:20:42.657572 13425 net.cpp:150] Setting up relu_u3d
I0427 16:20:42.657585 13425 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0427 16:20:42.657588 13425 net.cpp:165] Memory required for data: 560246016
I0427 16:20:42.657593 13425 layer_factory.hpp:77] Creating layer upconv_u3d_u2a
I0427 16:20:42.657626 13425 net.cpp:100] Creating Layer upconv_u3d_u2a
I0427 16:20:42.657630 13425 net.cpp:434] upconv_u3d_u2a <- u3d
I0427 16:20:42.657639 13425 net.cpp:408] upconv_u3d_u2a -> u2a
I0427 16:20:42.662729 13425 net.cpp:150] Setting up upconv_u3d_u2a
I0427 16:20:42.662747 13425 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0427 16:20:42.662750 13425 net.cpp:165] Memory required for data: 564980992
I0427 16:20:42.662758 13425 layer_factory.hpp:77] Creating layer relu_u2a
I0427 16:20:42.662765 13425 net.cpp:100] Creating Layer relu_u2a
I0427 16:20:42.662770 13425 net.cpp:434] relu_u2a <- u2a
I0427 16:20:42.662775 13425 net.cpp:395] relu_u2a -> u2a (in-place)
I0427 16:20:42.663007 13425 net.cpp:150] Setting up relu_u2a
I0427 16:20:42.663019 13425 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0427 16:20:42.663022 13425 net.cpp:165] Memory required for data: 569715968
I0427 16:20:42.663025 13425 layer_factory.hpp:77] Creating layer u2a_relu_u2a_0_split
I0427 16:20:42.663031 13425 net.cpp:100] Creating Layer u2a_relu_u2a_0_split
I0427 16:20:42.663036 13425 net.cpp:434] u2a_relu_u2a_0_split <- u2a
I0427 16:20:42.663043 13425 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_0
I0427 16:20:42.663059 13425 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_1
I0427 16:20:42.663115 13425 net.cpp:150] Setting up u2a_relu_u2a_0_split
I0427 16:20:42.663126 13425 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0427 16:20:42.663130 13425 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0427 16:20:42.663133 13425 net.cpp:165] Memory required for data: 579185920
I0427 16:20:42.663136 13425 layer_factory.hpp:77] Creating layer crop_d2c-d2cc
I0427 16:20:42.663144 13425 net.cpp:100] Creating Layer crop_d2c-d2cc
I0427 16:20:42.663148 13425 net.cpp:434] crop_d2c-d2cc <- d2c_relu_d2c_0_split_1
I0427 16:20:42.663153 13425 net.cpp:434] crop_d2c-d2cc <- u2a_relu_u2a_0_split_0
I0427 16:20:42.663159 13425 net.cpp:408] crop_d2c-d2cc -> d2cc
I0427 16:20:42.663197 13425 net.cpp:150] Setting up crop_d2c-d2cc
I0427 16:20:42.663204 13425 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0427 16:20:42.663208 13425 net.cpp:165] Memory required for data: 583920896
I0427 16:20:42.663210 13425 layer_factory.hpp:77] Creating layer concat_d2cc_u2a-b
I0427 16:20:42.663218 13425 net.cpp:100] Creating Layer concat_d2cc_u2a-b
I0427 16:20:42.663220 13425 net.cpp:434] concat_d2cc_u2a-b <- u2a_relu_u2a_0_split_1
I0427 16:20:42.663224 13425 net.cpp:434] concat_d2cc_u2a-b <- d2cc
I0427 16:20:42.663230 13425 net.cpp:408] concat_d2cc_u2a-b -> u2b
I0427 16:20:42.663259 13425 net.cpp:150] Setting up concat_d2cc_u2a-b
I0427 16:20:42.663267 13425 net.cpp:157] Top shape: 1 512 68 68 (2367488)
I0427 16:20:42.663270 13425 net.cpp:165] Memory required for data: 593390848
I0427 16:20:42.663272 13425 layer_factory.hpp:77] Creating layer conv_u2b-c
I0427 16:20:42.663283 13425 net.cpp:100] Creating Layer conv_u2b-c
I0427 16:20:42.663286 13425 net.cpp:434] conv_u2b-c <- u2b
I0427 16:20:42.663293 13425 net.cpp:408] conv_u2b-c -> u2c
I0427 16:20:42.673810 13425 net.cpp:150] Setting up conv_u2b-c
I0427 16:20:42.673828 13425 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0427 16:20:42.673831 13425 net.cpp:165] Memory required for data: 597851392
I0427 16:20:42.673840 13425 layer_factory.hpp:77] Creating layer relu_u2c
I0427 16:20:42.673847 13425 net.cpp:100] Creating Layer relu_u2c
I0427 16:20:42.673856 13425 net.cpp:434] relu_u2c <- u2c
I0427 16:20:42.673861 13425 net.cpp:395] relu_u2c -> u2c (in-place)
I0427 16:20:42.674916 13425 net.cpp:150] Setting up relu_u2c
I0427 16:20:42.674932 13425 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0427 16:20:42.674937 13425 net.cpp:165] Memory required for data: 602311936
I0427 16:20:42.674942 13425 layer_factory.hpp:77] Creating layer conv_u2c-d
I0427 16:20:42.674952 13425 net.cpp:100] Creating Layer conv_u2c-d
I0427 16:20:42.674957 13425 net.cpp:434] conv_u2c-d <- u2c
I0427 16:20:42.674964 13425 net.cpp:408] conv_u2c-d -> u2d
I0427 16:20:42.680564 13425 net.cpp:150] Setting up conv_u2c-d
I0427 16:20:42.680599 13425 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0427 16:20:42.680604 13425 net.cpp:165] Memory required for data: 606506240
I0427 16:20:42.680613 13425 layer_factory.hpp:77] Creating layer relu_u2d
I0427 16:20:42.680619 13425 net.cpp:100] Creating Layer relu_u2d
I0427 16:20:42.680624 13425 net.cpp:434] relu_u2d <- u2d
I0427 16:20:42.680629 13425 net.cpp:395] relu_u2d -> u2d (in-place)
I0427 16:20:42.680858 13425 net.cpp:150] Setting up relu_u2d
I0427 16:20:42.680871 13425 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0427 16:20:42.680873 13425 net.cpp:165] Memory required for data: 610700544
I0427 16:20:42.680876 13425 layer_factory.hpp:77] Creating layer upconv_u2d_u1a
I0427 16:20:42.680886 13425 net.cpp:100] Creating Layer upconv_u2d_u1a
I0427 16:20:42.680889 13425 net.cpp:434] upconv_u2d_u1a <- u2d
I0427 16:20:42.680896 13425 net.cpp:408] upconv_u2d_u1a -> u1a
I0427 16:20:42.683248 13425 net.cpp:150] Setting up upconv_u2d_u1a
I0427 16:20:42.683267 13425 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0427 16:20:42.683270 13425 net.cpp:165] Memory required for data: 619089152
I0427 16:20:42.683284 13425 layer_factory.hpp:77] Creating layer relu_u1a
I0427 16:20:42.683291 13425 net.cpp:100] Creating Layer relu_u1a
I0427 16:20:42.683296 13425 net.cpp:434] relu_u1a <- u1a
I0427 16:20:42.683302 13425 net.cpp:395] relu_u1a -> u1a (in-place)
I0427 16:20:42.683538 13425 net.cpp:150] Setting up relu_u1a
I0427 16:20:42.683550 13425 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0427 16:20:42.683554 13425 net.cpp:165] Memory required for data: 627477760
I0427 16:20:42.683558 13425 layer_factory.hpp:77] Creating layer u1a_relu_u1a_0_split
I0427 16:20:42.683564 13425 net.cpp:100] Creating Layer u1a_relu_u1a_0_split
I0427 16:20:42.683568 13425 net.cpp:434] u1a_relu_u1a_0_split <- u1a
I0427 16:20:42.683575 13425 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_0
I0427 16:20:42.683583 13425 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_1
I0427 16:20:42.683639 13425 net.cpp:150] Setting up u1a_relu_u1a_0_split
I0427 16:20:42.683647 13425 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0427 16:20:42.683655 13425 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0427 16:20:42.683658 13425 net.cpp:165] Memory required for data: 644254976
I0427 16:20:42.683661 13425 layer_factory.hpp:77] Creating layer crop_d1c-d1cc
I0427 16:20:42.683668 13425 net.cpp:100] Creating Layer crop_d1c-d1cc
I0427 16:20:42.683672 13425 net.cpp:434] crop_d1c-d1cc <- d1c_relu_d1c_0_split_1
I0427 16:20:42.683677 13425 net.cpp:434] crop_d1c-d1cc <- u1a_relu_u1a_0_split_0
I0427 16:20:42.683682 13425 net.cpp:408] crop_d1c-d1cc -> d1cc
I0427 16:20:42.683712 13425 net.cpp:150] Setting up crop_d1c-d1cc
I0427 16:20:42.683720 13425 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0427 16:20:42.683723 13425 net.cpp:165] Memory required for data: 652643584
I0427 16:20:42.683727 13425 layer_factory.hpp:77] Creating layer concat_d1cc_u1a-b
I0427 16:20:42.683732 13425 net.cpp:100] Creating Layer concat_d1cc_u1a-b
I0427 16:20:42.683735 13425 net.cpp:434] concat_d1cc_u1a-b <- u1a_relu_u1a_0_split_1
I0427 16:20:42.683740 13425 net.cpp:434] concat_d1cc_u1a-b <- d1cc
I0427 16:20:42.683745 13425 net.cpp:408] concat_d1cc_u1a-b -> u1b
I0427 16:20:42.683773 13425 net.cpp:150] Setting up concat_d1cc_u1a-b
I0427 16:20:42.683782 13425 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0427 16:20:42.683784 13425 net.cpp:165] Memory required for data: 669420800
I0427 16:20:42.683787 13425 layer_factory.hpp:77] Creating layer conv_u1b-c
I0427 16:20:42.683797 13425 net.cpp:100] Creating Layer conv_u1b-c
I0427 16:20:42.683802 13425 net.cpp:434] conv_u1b-c <- u1b
I0427 16:20:42.683807 13425 net.cpp:408] conv_u1b-c -> u1c
I0427 16:20:42.686187 13425 net.cpp:150] Setting up conv_u1b-c
I0427 16:20:42.686198 13425 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0427 16:20:42.686203 13425 net.cpp:165] Memory required for data: 677549312
I0427 16:20:42.686208 13425 layer_factory.hpp:77] Creating layer relu_u1c
I0427 16:20:42.686214 13425 net.cpp:100] Creating Layer relu_u1c
I0427 16:20:42.686234 13425 net.cpp:434] relu_u1c <- u1c
I0427 16:20:42.686242 13425 net.cpp:395] relu_u1c -> u1c (in-place)
I0427 16:20:42.686472 13425 net.cpp:150] Setting up relu_u1c
I0427 16:20:42.686486 13425 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0427 16:20:42.686488 13425 net.cpp:165] Memory required for data: 685677824
I0427 16:20:42.686492 13425 layer_factory.hpp:77] Creating layer conv_u1c-d
I0427 16:20:42.686501 13425 net.cpp:100] Creating Layer conv_u1c-d
I0427 16:20:42.686506 13425 net.cpp:434] conv_u1c-d <- u1c
I0427 16:20:42.686512 13425 net.cpp:408] conv_u1c-d -> u1d
I0427 16:20:42.688967 13425 net.cpp:150] Setting up conv_u1c-d
I0427 16:20:42.688985 13425 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0427 16:20:42.688989 13425 net.cpp:165] Memory required for data: 693550336
I0427 16:20:42.688997 13425 layer_factory.hpp:77] Creating layer relu_u1d
I0427 16:20:42.689003 13425 net.cpp:100] Creating Layer relu_u1d
I0427 16:20:42.689012 13425 net.cpp:434] relu_u1d <- u1d
I0427 16:20:42.689018 13425 net.cpp:395] relu_u1d -> u1d (in-place)
I0427 16:20:42.690073 13425 net.cpp:150] Setting up relu_u1d
I0427 16:20:42.690090 13425 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0427 16:20:42.690093 13425 net.cpp:165] Memory required for data: 701422848
I0427 16:20:42.690098 13425 layer_factory.hpp:77] Creating layer upconv_u1d_u0a
I0427 16:20:42.690106 13425 net.cpp:100] Creating Layer upconv_u1d_u0a
I0427 16:20:42.690111 13425 net.cpp:434] upconv_u1d_u0a <- u1d
I0427 16:20:42.690119 13425 net.cpp:408] upconv_u1d_u0a -> u0a
I0427 16:20:42.690974 13425 net.cpp:150] Setting up upconv_u1d_u0a
I0427 16:20:42.690985 13425 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0427 16:20:42.690989 13425 net.cpp:165] Memory required for data: 732912896
I0427 16:20:42.690996 13425 layer_factory.hpp:77] Creating layer relu_u0a
I0427 16:20:42.691002 13425 net.cpp:100] Creating Layer relu_u0a
I0427 16:20:42.691005 13425 net.cpp:434] relu_u0a <- u0a
I0427 16:20:42.691011 13425 net.cpp:395] relu_u0a -> u0a (in-place)
I0427 16:20:42.691224 13425 net.cpp:150] Setting up relu_u0a
I0427 16:20:42.691236 13425 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0427 16:20:42.691238 13425 net.cpp:165] Memory required for data: 764402944
I0427 16:20:42.691243 13425 layer_factory.hpp:77] Creating layer u0a_relu_u0a_0_split
I0427 16:20:42.691248 13425 net.cpp:100] Creating Layer u0a_relu_u0a_0_split
I0427 16:20:42.691252 13425 net.cpp:434] u0a_relu_u0a_0_split <- u0a
I0427 16:20:42.691258 13425 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_0
I0427 16:20:42.691267 13425 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_1
I0427 16:20:42.691320 13425 net.cpp:150] Setting up u0a_relu_u0a_0_split
I0427 16:20:42.691329 13425 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0427 16:20:42.691334 13425 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0427 16:20:42.691336 13425 net.cpp:165] Memory required for data: 827383040
I0427 16:20:42.691339 13425 layer_factory.hpp:77] Creating layer crop_d0c-d0cc
I0427 16:20:42.691346 13425 net.cpp:100] Creating Layer crop_d0c-d0cc
I0427 16:20:42.691349 13425 net.cpp:434] crop_d0c-d0cc <- d0c_relu_d0c_0_split_1
I0427 16:20:42.691355 13425 net.cpp:434] crop_d0c-d0cc <- u0a_relu_u0a_0_split_0
I0427 16:20:42.691361 13425 net.cpp:408] crop_d0c-d0cc -> d0cc
I0427 16:20:42.691393 13425 net.cpp:150] Setting up crop_d0c-d0cc
I0427 16:20:42.691408 13425 net.cpp:157] Top shape: 1 64 248 248 (3936256)
I0427 16:20:42.691412 13425 net.cpp:165] Memory required for data: 843128064
I0427 16:20:42.691416 13425 layer_factory.hpp:77] Creating layer concat_d0cc_u0a-b
I0427 16:20:42.691421 13425 net.cpp:100] Creating Layer concat_d0cc_u0a-b
I0427 16:20:42.691424 13425 net.cpp:434] concat_d0cc_u0a-b <- u0a_relu_u0a_0_split_1
I0427 16:20:42.691429 13425 net.cpp:434] concat_d0cc_u0a-b <- d0cc
I0427 16:20:42.691434 13425 net.cpp:408] concat_d0cc_u0a-b -> u0b
I0427 16:20:42.691462 13425 net.cpp:150] Setting up concat_d0cc_u0a-b
I0427 16:20:42.691468 13425 net.cpp:157] Top shape: 1 192 248 248 (11808768)
I0427 16:20:42.691498 13425 net.cpp:165] Memory required for data: 890363136
I0427 16:20:42.691500 13425 layer_factory.hpp:77] Creating layer conv_u0b-c
I0427 16:20:42.691510 13425 net.cpp:100] Creating Layer conv_u0b-c
I0427 16:20:42.691519 13425 net.cpp:434] conv_u0b-c <- u0b
I0427 16:20:42.691525 13425 net.cpp:408] conv_u0b-c -> u0c
I0427 16:20:42.692678 13425 net.cpp:150] Setting up conv_u0b-c
I0427 16:20:42.692688 13425 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0427 16:20:42.692692 13425 net.cpp:165] Memory required for data: 905855232
I0427 16:20:42.692699 13425 layer_factory.hpp:77] Creating layer relu_u0c
I0427 16:20:42.692705 13425 net.cpp:100] Creating Layer relu_u0c
I0427 16:20:42.692708 13425 net.cpp:434] relu_u0c <- u0c
I0427 16:20:42.692713 13425 net.cpp:395] relu_u0c -> u0c (in-place)
I0427 16:20:42.692937 13425 net.cpp:150] Setting up relu_u0c
I0427 16:20:42.692948 13425 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0427 16:20:42.692951 13425 net.cpp:165] Memory required for data: 921347328
I0427 16:20:42.692955 13425 layer_factory.hpp:77] Creating layer conv_u0c-d
I0427 16:20:42.692965 13425 net.cpp:100] Creating Layer conv_u0c-d
I0427 16:20:42.692968 13425 net.cpp:434] conv_u0c-d <- u0c
I0427 16:20:42.692975 13425 net.cpp:408] conv_u0c-d -> u0d
I0427 16:20:42.693629 13425 net.cpp:150] Setting up conv_u0c-d
I0427 16:20:42.693639 13425 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0427 16:20:42.693642 13425 net.cpp:165] Memory required for data: 936588544
I0427 16:20:42.693650 13425 layer_factory.hpp:77] Creating layer relu_u0d
I0427 16:20:42.693663 13425 net.cpp:100] Creating Layer relu_u0d
I0427 16:20:42.693668 13425 net.cpp:434] relu_u0d <- u0d
I0427 16:20:42.693673 13425 net.cpp:395] relu_u0d -> u0d (in-place)
I0427 16:20:42.693891 13425 net.cpp:150] Setting up relu_u0d
I0427 16:20:42.693902 13425 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0427 16:20:42.693905 13425 net.cpp:165] Memory required for data: 951829760
I0427 16:20:42.693909 13425 layer_factory.hpp:77] Creating layer conv_u0d-score
I0427 16:20:42.693918 13425 net.cpp:100] Creating Layer conv_u0d-score
I0427 16:20:42.693922 13425 net.cpp:434] conv_u0d-score <- u0d
I0427 16:20:42.693928 13425 net.cpp:408] conv_u0d-score -> score
I0427 16:20:42.694303 13425 net.cpp:150] Setting up conv_u0d-score
I0427 16:20:42.694311 13425 net.cpp:157] Top shape: 1 3 244 244 (178608)
I0427 16:20:42.694314 13425 net.cpp:165] Memory required for data: 952544192
I0427 16:20:42.694321 13425 layer_factory.hpp:77] Creating layer softmax
I0427 16:20:42.694327 13425 net.cpp:100] Creating Layer softmax
I0427 16:20:42.694330 13425 net.cpp:434] softmax <- score
I0427 16:20:42.694336 13425 net.cpp:408] softmax -> softmax_out
I0427 16:20:42.695461 13425 net.cpp:150] Setting up softmax
I0427 16:20:42.695477 13425 net.cpp:157] Top shape: 1 3 244 244 (178608)
I0427 16:20:42.695482 13425 net.cpp:165] Memory required for data: 953258624
I0427 16:20:42.695485 13425 layer_factory.hpp:77] Creating layer reshapelab
I0427 16:20:42.695494 13425 net.cpp:100] Creating Layer reshapelab
I0427 16:20:42.695498 13425 net.cpp:434] reshapelab <- label
I0427 16:20:42.695505 13425 net.cpp:408] reshapelab -> label_flat
I0427 16:20:42.695544 13425 net.cpp:150] Setting up reshapelab
I0427 16:20:42.695550 13425 net.cpp:157] Top shape: 1 59536 (59536)
I0427 16:20:42.695554 13425 net.cpp:165] Memory required for data: 953496768
I0427 16:20:42.695556 13425 layer_factory.hpp:77] Creating layer reshaperes
I0427 16:20:42.695561 13425 net.cpp:100] Creating Layer reshaperes
I0427 16:20:42.695565 13425 net.cpp:434] reshaperes <- softmax_out
I0427 16:20:42.695571 13425 net.cpp:408] reshaperes -> softmax_out_flat
I0427 16:20:42.695602 13425 net.cpp:150] Setting up reshaperes
I0427 16:20:42.695608 13425 net.cpp:157] Top shape: 1 3 59536 (178608)
I0427 16:20:42.695612 13425 net.cpp:165] Memory required for data: 954211200
I0427 16:20:42.695614 13425 layer_factory.hpp:77] Creating layer loss
I0427 16:20:42.695665 13425 net.cpp:100] Creating Layer loss
I0427 16:20:42.695674 13425 net.cpp:434] loss <- softmax_out_flat
I0427 16:20:42.695698 13425 net.cpp:434] loss <- label_flat
I0427 16:20:42.695705 13425 net.cpp:408] loss -> loss
I0427 16:20:42.697156 13425 net.cpp:150] Setting up loss
I0427 16:20:42.697168 13425 net.cpp:157] Top shape: 3 (3)
I0427 16:20:42.697172 13425 net.cpp:160]     with loss weight 1
I0427 16:20:42.697182 13425 net.cpp:165] Memory required for data: 954211212
I0427 16:20:42.697185 13425 net.cpp:226] loss needs backward computation.
I0427 16:20:42.697190 13425 net.cpp:226] reshaperes needs backward computation.
I0427 16:20:42.697196 13425 net.cpp:228] reshapelab does not need backward computation.
I0427 16:20:42.697201 13425 net.cpp:226] softmax needs backward computation.
I0427 16:20:42.697204 13425 net.cpp:226] conv_u0d-score needs backward computation.
I0427 16:20:42.697207 13425 net.cpp:226] relu_u0d needs backward computation.
I0427 16:20:42.697211 13425 net.cpp:226] conv_u0c-d needs backward computation.
I0427 16:20:42.697216 13425 net.cpp:226] relu_u0c needs backward computation.
I0427 16:20:42.697218 13425 net.cpp:226] conv_u0b-c needs backward computation.
I0427 16:20:42.697221 13425 net.cpp:226] concat_d0cc_u0a-b needs backward computation.
I0427 16:20:42.697227 13425 net.cpp:226] crop_d0c-d0cc needs backward computation.
I0427 16:20:42.697232 13425 net.cpp:226] u0a_relu_u0a_0_split needs backward computation.
I0427 16:20:42.697235 13425 net.cpp:226] relu_u0a needs backward computation.
I0427 16:20:42.697238 13425 net.cpp:226] upconv_u1d_u0a needs backward computation.
I0427 16:20:42.697242 13425 net.cpp:226] relu_u1d needs backward computation.
I0427 16:20:42.697245 13425 net.cpp:226] conv_u1c-d needs backward computation.
I0427 16:20:42.697249 13425 net.cpp:226] relu_u1c needs backward computation.
I0427 16:20:42.697252 13425 net.cpp:226] conv_u1b-c needs backward computation.
I0427 16:20:42.697257 13425 net.cpp:226] concat_d1cc_u1a-b needs backward computation.
I0427 16:20:42.697260 13425 net.cpp:226] crop_d1c-d1cc needs backward computation.
I0427 16:20:42.697265 13425 net.cpp:226] u1a_relu_u1a_0_split needs backward computation.
I0427 16:20:42.697268 13425 net.cpp:226] relu_u1a needs backward computation.
I0427 16:20:42.697273 13425 net.cpp:226] upconv_u2d_u1a needs backward computation.
I0427 16:20:42.697276 13425 net.cpp:226] relu_u2d needs backward computation.
I0427 16:20:42.697279 13425 net.cpp:226] conv_u2c-d needs backward computation.
I0427 16:20:42.697283 13425 net.cpp:226] relu_u2c needs backward computation.
I0427 16:20:42.697286 13425 net.cpp:226] conv_u2b-c needs backward computation.
I0427 16:20:42.697289 13425 net.cpp:226] concat_d2cc_u2a-b needs backward computation.
I0427 16:20:42.697294 13425 net.cpp:226] crop_d2c-d2cc needs backward computation.
I0427 16:20:42.697299 13425 net.cpp:226] u2a_relu_u2a_0_split needs backward computation.
I0427 16:20:42.697304 13425 net.cpp:226] relu_u2a needs backward computation.
I0427 16:20:42.697306 13425 net.cpp:226] upconv_u3d_u2a needs backward computation.
I0427 16:20:42.697309 13425 net.cpp:226] relu_u3d needs backward computation.
I0427 16:20:42.697312 13425 net.cpp:226] conv_u3c-d needs backward computation.
I0427 16:20:42.697317 13425 net.cpp:226] relu_u3c needs backward computation.
I0427 16:20:42.697320 13425 net.cpp:226] conv_u3b-c needs backward computation.
I0427 16:20:42.697324 13425 net.cpp:226] concat_d3cc_u3a-b needs backward computation.
I0427 16:20:42.697329 13425 net.cpp:226] crop_d3c-d3cc needs backward computation.
I0427 16:20:42.697334 13425 net.cpp:226] u3a_relu_u3a_0_split needs backward computation.
I0427 16:20:42.697337 13425 net.cpp:226] relu_u3a needs backward computation.
I0427 16:20:42.697340 13425 net.cpp:226] upconv_d4c_u3a needs backward computation.
I0427 16:20:42.697345 13425 net.cpp:226] relu_d4c needs backward computation.
I0427 16:20:42.697348 13425 net.cpp:226] conv_d4b-c needs backward computation.
I0427 16:20:42.697352 13425 net.cpp:226] relu_d4b needs backward computation.
I0427 16:20:42.697355 13425 net.cpp:226] conv_d4a-b needs backward computation.
I0427 16:20:42.697360 13425 net.cpp:226] pool_d3c-4a needs backward computation.
I0427 16:20:42.697383 13425 net.cpp:226] d3c_relu_d3c_0_split needs backward computation.
I0427 16:20:42.697387 13425 net.cpp:226] relu_d3c needs backward computation.
I0427 16:20:42.697391 13425 net.cpp:226] conv_d3b-c needs backward computation.
I0427 16:20:42.697394 13425 net.cpp:226] relu_d3b needs backward computation.
I0427 16:20:42.697398 13425 net.cpp:226] conv_d3a-b needs backward computation.
I0427 16:20:42.697402 13425 net.cpp:226] pool_d2c-3a needs backward computation.
I0427 16:20:42.697405 13425 net.cpp:226] d2c_relu_d2c_0_split needs backward computation.
I0427 16:20:42.697409 13425 net.cpp:226] relu_d2c needs backward computation.
I0427 16:20:42.697413 13425 net.cpp:226] conv_d2b-c needs backward computation.
I0427 16:20:42.697417 13425 net.cpp:226] relu_d2b needs backward computation.
I0427 16:20:42.697420 13425 net.cpp:226] conv_d2a-b needs backward computation.
I0427 16:20:42.697423 13425 net.cpp:226] pool_d1c-2a needs backward computation.
I0427 16:20:42.697428 13425 net.cpp:226] d1c_relu_d1c_0_split needs backward computation.
I0427 16:20:42.697432 13425 net.cpp:226] relu_d1c needs backward computation.
I0427 16:20:42.697445 13425 net.cpp:226] conv_d1b-c needs backward computation.
I0427 16:20:42.697449 13425 net.cpp:226] relu_d1b needs backward computation.
I0427 16:20:42.697453 13425 net.cpp:226] conv_d1a-b needs backward computation.
I0427 16:20:42.697458 13425 net.cpp:226] pool_d0c-1a needs backward computation.
I0427 16:20:42.697460 13425 net.cpp:226] d0c_relu_d0c_0_split needs backward computation.
I0427 16:20:42.697464 13425 net.cpp:226] relu_d0c needs backward computation.
I0427 16:20:42.697468 13425 net.cpp:226] conv_d0b-c needs backward computation.
I0427 16:20:42.697473 13425 net.cpp:226] relu_d0b needs backward computation.
I0427 16:20:42.697475 13425 net.cpp:226] conv_d0a-b needs backward computation.
I0427 16:20:42.697479 13425 net.cpp:228] loaddata does not need backward computation.
I0427 16:20:42.697489 13425 net.cpp:270] This network produces output loss
I0427 16:20:42.697551 13425 net.cpp:283] Network initialization done.
I0427 16:20:42.697774 13425 solver.cpp:60] Solver scaffolding done.
I0427 16:20:42.715571 13425 solver.cpp:337] Iteration 0, Testing net (#0)
I0427 16:20:42.719606 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 16:20:42.719620 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 16:20:42.729575 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 16:20:42.738965 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 16:20:42.738981 13425 net.cpp:693] Ignoring source layer visualize
I0427 16:20:42.738983 13425 net.cpp:693] Ignoring source layer fake
I0427 16:24:51.944011 13425 solver.cpp:404]     Test net output #0: loss = 0.883081 (* 1 = 0.883081 loss)
I0427 16:24:51.944102 13425 solver.cpp:404]     Test net output #1: loss = 0.13707 (* 1 = 0.13707 loss)
I0427 16:24:51.944108 13425 solver.cpp:404]     Test net output #2: loss = 0.389982 (* 1 = 0.389982 loss)
I0427 16:24:52.635820 13425 solver.cpp:228] Iteration 0, loss = 1.41801
I0427 16:24:52.635864 13425 solver.cpp:244]     Train net output #0: loss = 0.825372 (* 1 = 0.825372 loss)
I0427 16:24:52.635870 13425 solver.cpp:244]     Train net output #1: loss = 0.137961 (* 1 = 0.137961 loss)
I0427 16:24:52.635875 13425 solver.cpp:244]     Train net output #2: loss = 0.454674 (* 1 = 0.454674 loss)
I0427 16:24:52.635882 13425 sgd_solver.cpp:106] Iteration 0, lr = 5e-05
I0427 16:26:44.227679 13425 solver.cpp:228] Iteration 100, loss = 1.59504
I0427 16:26:44.227898 13425 solver.cpp:244]     Train net output #0: loss = 0.930172 (* 1 = 0.930172 loss)
I0427 16:26:44.227908 13425 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0427 16:26:44.227913 13425 solver.cpp:244]     Train net output #2: loss = 0.664868 (* 1 = 0.664868 loss)
I0427 16:26:44.227918 13425 sgd_solver.cpp:106] Iteration 100, lr = 5e-05
I0427 16:28:22.341295 13425 solver.cpp:228] Iteration 200, loss = 1.61815
I0427 16:28:22.341491 13425 solver.cpp:244]     Train net output #0: loss = 0.943718 (* 1 = 0.943718 loss)
I0427 16:28:22.341500 13425 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0427 16:28:22.341506 13425 solver.cpp:244]     Train net output #2: loss = 0.674428 (* 1 = 0.674428 loss)
I0427 16:28:22.341511 13425 sgd_solver.cpp:106] Iteration 200, lr = 5e-05
I0427 16:30:13.509169 13425 solver.cpp:228] Iteration 300, loss = 1.62812
I0427 16:30:13.509335 13425 solver.cpp:244]     Train net output #0: loss = 0.944296 (* 1 = 0.944296 loss)
I0427 16:30:13.509342 13425 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0427 16:30:13.509348 13425 solver.cpp:244]     Train net output #2: loss = 0.683824 (* 1 = 0.683824 loss)
I0427 16:30:13.509354 13425 sgd_solver.cpp:106] Iteration 300, lr = 5e-05
I0427 16:32:06.808661 13425 solver.cpp:228] Iteration 400, loss = 1.65903
I0427 16:32:06.808825 13425 solver.cpp:244]     Train net output #0: loss = 0.901268 (* 1 = 0.901268 loss)
I0427 16:32:06.808832 13425 solver.cpp:244]     Train net output #1: loss = 2.2539e-05 (* 1 = 2.2539e-05 loss)
I0427 16:32:06.808840 13425 solver.cpp:244]     Train net output #2: loss = 0.757739 (* 1 = 0.757739 loss)
I0427 16:32:06.808845 13425 sgd_solver.cpp:106] Iteration 400, lr = 5e-05
I0427 16:34:00.917351 13425 solver.cpp:228] Iteration 500, loss = 1.97722
I0427 16:34:00.917528 13425 solver.cpp:244]     Train net output #0: loss = 0.930688 (* 1 = 0.930688 loss)
I0427 16:34:00.917538 13425 solver.cpp:244]     Train net output #1: loss = 0.233182 (* 1 = 0.233182 loss)
I0427 16:34:00.917543 13425 solver.cpp:244]     Train net output #2: loss = 0.813347 (* 1 = 0.813347 loss)
I0427 16:34:00.917549 13425 sgd_solver.cpp:106] Iteration 500, lr = 5e-05
I0427 16:35:55.027837 13425 solver.cpp:228] Iteration 600, loss = 2.31023
I0427 16:35:55.028007 13425 solver.cpp:244]     Train net output #0: loss = 0.940194 (* 1 = 0.940194 loss)
I0427 16:35:55.028015 13425 solver.cpp:244]     Train net output #1: loss = 0.513772 (* 1 = 0.513772 loss)
I0427 16:35:55.028030 13425 solver.cpp:244]     Train net output #2: loss = 0.85626 (* 1 = 0.85626 loss)
I0427 16:35:55.028036 13425 sgd_solver.cpp:106] Iteration 600, lr = 5e-05
I0427 16:37:33.136030 13425 solver.cpp:228] Iteration 700, loss = 2.38831
I0427 16:37:33.136193 13425 solver.cpp:244]     Train net output #0: loss = 0.945352 (* 1 = 0.945352 loss)
I0427 16:37:33.136200 13425 solver.cpp:244]     Train net output #1: loss = 0.640994 (* 1 = 0.640994 loss)
I0427 16:37:33.136205 13425 solver.cpp:244]     Train net output #2: loss = 0.80196 (* 1 = 0.80196 loss)
I0427 16:37:33.136211 13425 sgd_solver.cpp:106] Iteration 700, lr = 5e-05
I0427 16:39:26.576958 13425 solver.cpp:228] Iteration 800, loss = 2.35452
I0427 16:39:26.577143 13425 solver.cpp:244]     Train net output #0: loss = 0.972063 (* 1 = 0.972063 loss)
I0427 16:39:26.577154 13425 solver.cpp:244]     Train net output #1: loss = 0.550888 (* 1 = 0.550888 loss)
I0427 16:39:26.577163 13425 solver.cpp:244]     Train net output #2: loss = 0.831569 (* 1 = 0.831569 loss)
I0427 16:39:26.577172 13425 sgd_solver.cpp:106] Iteration 800, lr = 5e-05
I0427 16:41:19.954645 13425 solver.cpp:228] Iteration 900, loss = 2.10127
I0427 16:41:19.954785 13425 solver.cpp:244]     Train net output #0: loss = 0.978926 (* 1 = 0.978926 loss)
I0427 16:41:19.954794 13425 solver.cpp:244]     Train net output #1: loss = 0.484686 (* 1 = 0.484686 loss)
I0427 16:41:19.954800 13425 solver.cpp:244]     Train net output #2: loss = 0.637656 (* 1 = 0.637656 loss)
I0427 16:41:19.954805 13425 sgd_solver.cpp:106] Iteration 900, lr = 5e-05
I0427 16:43:12.306856 13425 solver.cpp:337] Iteration 1000, Testing net (#0)
I0427 16:43:12.308531 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 16:43:12.308537 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 16:43:12.308539 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 16:43:12.308553 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 16:43:12.308557 13425 net.cpp:693] Ignoring source layer visualize
I0427 16:43:12.308559 13425 net.cpp:693] Ignoring source layer fake
I0427 16:46:48.027446 13425 solver.cpp:404]     Test net output #0: loss = 0.943652 (* 1 = 0.943652 loss)
I0427 16:46:48.027598 13425 solver.cpp:404]     Test net output #1: loss = 0.494745 (* 1 = 0.494745 loss)
I0427 16:46:48.027606 13425 solver.cpp:404]     Test net output #2: loss = 0.72621 (* 1 = 0.72621 loss)
I0427 16:46:48.687152 13425 solver.cpp:228] Iteration 1000, loss = 2.22615
I0427 16:46:48.687196 13425 solver.cpp:244]     Train net output #0: loss = 0.961452 (* 1 = 0.961452 loss)
I0427 16:46:48.687202 13425 solver.cpp:244]     Train net output #1: loss = 0.555316 (* 1 = 0.555316 loss)
I0427 16:46:48.687207 13425 solver.cpp:244]     Train net output #2: loss = 0.709383 (* 1 = 0.709383 loss)
I0427 16:46:48.687213 13425 sgd_solver.cpp:106] Iteration 1000, lr = 5e-05
I0427 16:48:27.107949 13425 solver.cpp:228] Iteration 1100, loss = 2.22181
I0427 16:48:27.108095 13425 solver.cpp:244]     Train net output #0: loss = 0.969563 (* 1 = 0.969563 loss)
I0427 16:48:27.108108 13425 solver.cpp:244]     Train net output #1: loss = 0.55114 (* 1 = 0.55114 loss)
I0427 16:48:27.108115 13425 solver.cpp:244]     Train net output #2: loss = 0.701108 (* 1 = 0.701108 loss)
I0427 16:48:27.108122 13425 sgd_solver.cpp:106] Iteration 1100, lr = 5e-05
I0427 16:50:19.146806 13425 solver.cpp:228] Iteration 1200, loss = 2.35399
I0427 16:50:19.146996 13425 solver.cpp:244]     Train net output #0: loss = 0.962112 (* 1 = 0.962112 loss)
I0427 16:50:19.147008 13425 solver.cpp:244]     Train net output #1: loss = 0.498509 (* 1 = 0.498509 loss)
I0427 16:50:19.147017 13425 solver.cpp:244]     Train net output #2: loss = 0.893366 (* 1 = 0.893366 loss)
I0427 16:50:19.147024 13425 sgd_solver.cpp:106] Iteration 1200, lr = 5e-05
I0427 16:52:11.298616 13425 solver.cpp:228] Iteration 1300, loss = 1.86629
I0427 16:52:11.298809 13425 solver.cpp:244]     Train net output #0: loss = 0.95825 (* 1 = 0.95825 loss)
I0427 16:52:11.298820 13425 solver.cpp:244]     Train net output #1: loss = 0.18602 (* 1 = 0.18602 loss)
I0427 16:52:11.298827 13425 solver.cpp:244]     Train net output #2: loss = 0.722025 (* 1 = 0.722025 loss)
I0427 16:52:11.298835 13425 sgd_solver.cpp:106] Iteration 1300, lr = 5e-05
I0427 16:54:02.535821 13425 solver.cpp:228] Iteration 1400, loss = 2.31877
I0427 16:54:02.536011 13425 solver.cpp:244]     Train net output #0: loss = 0.968731 (* 1 = 0.968731 loss)
I0427 16:54:02.536022 13425 solver.cpp:244]     Train net output #1: loss = 0.672359 (* 1 = 0.672359 loss)
I0427 16:54:02.536032 13425 solver.cpp:244]     Train net output #2: loss = 0.677678 (* 1 = 0.677678 loss)
I0427 16:54:02.536039 13425 sgd_solver.cpp:106] Iteration 1400, lr = 5e-05
I0427 16:55:54.124157 13425 solver.cpp:228] Iteration 1500, loss = 2.03188
I0427 16:55:54.124300 13425 solver.cpp:244]     Train net output #0: loss = 0.966057 (* 1 = 0.966057 loss)
I0427 16:55:54.124308 13425 solver.cpp:244]     Train net output #1: loss = 0.426454 (* 1 = 0.426454 loss)
I0427 16:55:54.124315 13425 solver.cpp:244]     Train net output #2: loss = 0.639372 (* 1 = 0.639372 loss)
I0427 16:55:54.124320 13425 sgd_solver.cpp:106] Iteration 1500, lr = 5e-05
I0427 16:57:47.238829 13425 solver.cpp:228] Iteration 1600, loss = 2.10031
I0427 16:57:47.239032 13425 solver.cpp:244]     Train net output #0: loss = 0.805068 (* 1 = 0.805068 loss)
I0427 16:57:47.239040 13425 solver.cpp:244]     Train net output #1: loss = 0.549315 (* 1 = 0.549315 loss)
I0427 16:57:47.239045 13425 solver.cpp:244]     Train net output #2: loss = 0.745922 (* 1 = 0.745922 loss)
I0427 16:57:47.239050 13425 sgd_solver.cpp:106] Iteration 1600, lr = 5e-05
I0427 16:59:25.447165 13425 solver.cpp:228] Iteration 1700, loss = 2.3554
I0427 16:59:25.447365 13425 solver.cpp:244]     Train net output #0: loss = 0.830516 (* 1 = 0.830516 loss)
I0427 16:59:25.447373 13425 solver.cpp:244]     Train net output #1: loss = 0.637124 (* 1 = 0.637124 loss)
I0427 16:59:25.447378 13425 solver.cpp:244]     Train net output #2: loss = 0.887756 (* 1 = 0.887756 loss)
I0427 16:59:25.447384 13425 sgd_solver.cpp:106] Iteration 1700, lr = 5e-05
I0427 17:01:19.904772 13425 solver.cpp:228] Iteration 1800, loss = 2.36945
I0427 17:01:19.904930 13425 solver.cpp:244]     Train net output #0: loss = 0.959894 (* 1 = 0.959894 loss)
I0427 17:01:19.904938 13425 solver.cpp:244]     Train net output #1: loss = 0.66224 (* 1 = 0.66224 loss)
I0427 17:01:19.904944 13425 solver.cpp:244]     Train net output #2: loss = 0.74732 (* 1 = 0.74732 loss)
I0427 17:01:19.904950 13425 sgd_solver.cpp:106] Iteration 1800, lr = 5e-05
I0427 17:03:14.149154 13425 solver.cpp:228] Iteration 1900, loss = 2.37759
I0427 17:03:14.149302 13425 solver.cpp:244]     Train net output #0: loss = 0.91139 (* 1 = 0.91139 loss)
I0427 17:03:14.149312 13425 solver.cpp:244]     Train net output #1: loss = 0.585025 (* 1 = 0.585025 loss)
I0427 17:03:14.149317 13425 solver.cpp:244]     Train net output #2: loss = 0.881176 (* 1 = 0.881176 loss)
I0427 17:03:14.149322 13425 sgd_solver.cpp:106] Iteration 1900, lr = 5e-05
I0427 17:05:06.459066 13425 solver.cpp:337] Iteration 2000, Testing net (#0)
I0427 17:05:06.459228 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 17:05:06.459233 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 17:05:06.459236 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 17:05:06.459251 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 17:05:06.459255 13425 net.cpp:693] Ignoring source layer visualize
I0427 17:05:06.459257 13425 net.cpp:693] Ignoring source layer fake
I0427 17:08:42.419780 13425 solver.cpp:404]     Test net output #0: loss = 0.940575 (* 1 = 0.940575 loss)
I0427 17:08:42.419940 13425 solver.cpp:404]     Test net output #1: loss = 0.560698 (* 1 = 0.560698 loss)
I0427 17:08:42.419948 13425 solver.cpp:404]     Test net output #2: loss = 0.732782 (* 1 = 0.732782 loss)
I0427 17:08:43.085728 13425 solver.cpp:228] Iteration 2000, loss = 2.35563
I0427 17:08:43.085770 13425 solver.cpp:244]     Train net output #0: loss = 0.969677 (* 1 = 0.969677 loss)
I0427 17:08:43.085794 13425 solver.cpp:244]     Train net output #1: loss = 0.594829 (* 1 = 0.594829 loss)
I0427 17:08:43.085803 13425 solver.cpp:244]     Train net output #2: loss = 0.79112 (* 1 = 0.79112 loss)
I0427 17:08:43.085809 13425 sgd_solver.cpp:106] Iteration 2000, lr = 5e-05
I0427 17:10:21.544740 13425 solver.cpp:228] Iteration 2100, loss = 2.33195
I0427 17:10:21.544916 13425 solver.cpp:244]     Train net output #0: loss = 0.976457 (* 1 = 0.976457 loss)
I0427 17:10:21.544929 13425 solver.cpp:244]     Train net output #1: loss = 0.570042 (* 1 = 0.570042 loss)
I0427 17:10:21.544936 13425 solver.cpp:244]     Train net output #2: loss = 0.785447 (* 1 = 0.785447 loss)
I0427 17:10:21.544945 13425 sgd_solver.cpp:106] Iteration 2100, lr = 5e-05
I0427 17:12:14.985316 13425 solver.cpp:228] Iteration 2200, loss = 2.44332
I0427 17:12:14.985523 13425 solver.cpp:244]     Train net output #0: loss = 0.964599 (* 1 = 0.964599 loss)
I0427 17:12:14.985532 13425 solver.cpp:244]     Train net output #1: loss = 0.661508 (* 1 = 0.661508 loss)
I0427 17:12:14.985538 13425 solver.cpp:244]     Train net output #2: loss = 0.81721 (* 1 = 0.81721 loss)
I0427 17:12:14.985543 13425 sgd_solver.cpp:106] Iteration 2200, lr = 5e-05
I0427 17:14:08.113167 13425 solver.cpp:228] Iteration 2300, loss = 1.97804
I0427 17:14:08.113335 13425 solver.cpp:244]     Train net output #0: loss = 0.962392 (* 1 = 0.962392 loss)
I0427 17:14:08.113344 13425 solver.cpp:244]     Train net output #1: loss = 0.386252 (* 1 = 0.386252 loss)
I0427 17:14:08.113349 13425 solver.cpp:244]     Train net output #2: loss = 0.629395 (* 1 = 0.629395 loss)
I0427 17:14:08.113356 13425 sgd_solver.cpp:106] Iteration 2300, lr = 5e-05
I0427 17:15:59.999337 13425 solver.cpp:228] Iteration 2400, loss = 1.98028
I0427 17:15:59.999547 13425 solver.cpp:244]     Train net output #0: loss = 0.978212 (* 1 = 0.978212 loss)
I0427 17:15:59.999555 13425 solver.cpp:244]     Train net output #1: loss = 0.401665 (* 1 = 0.401665 loss)
I0427 17:15:59.999562 13425 solver.cpp:244]     Train net output #2: loss = 0.600404 (* 1 = 0.600404 loss)
I0427 17:15:59.999567 13425 sgd_solver.cpp:106] Iteration 2400, lr = 5e-05
I0427 17:17:39.421545 13425 solver.cpp:228] Iteration 2500, loss = 1.935
I0427 17:17:39.421718 13425 solver.cpp:244]     Train net output #0: loss = 0.923389 (* 1 = 0.923389 loss)
I0427 17:17:39.421730 13425 solver.cpp:244]     Train net output #1: loss = 0.311875 (* 1 = 0.311875 loss)
I0427 17:17:39.421739 13425 solver.cpp:244]     Train net output #2: loss = 0.69974 (* 1 = 0.69974 loss)
I0427 17:17:39.421747 13425 sgd_solver.cpp:106] Iteration 2500, lr = 5e-05
I0427 17:19:18.930594 13425 solver.cpp:228] Iteration 2600, loss = 1.90495
I0427 17:19:18.930747 13425 solver.cpp:244]     Train net output #0: loss = 0.959663 (* 1 = 0.959663 loss)
I0427 17:19:18.930755 13425 solver.cpp:244]     Train net output #1: loss = 0.295578 (* 1 = 0.295578 loss)
I0427 17:19:18.930760 13425 solver.cpp:244]     Train net output #2: loss = 0.64971 (* 1 = 0.64971 loss)
I0427 17:19:18.930766 13425 sgd_solver.cpp:106] Iteration 2600, lr = 5e-05
I0427 17:20:57.086567 13425 solver.cpp:228] Iteration 2700, loss = 2.12953
I0427 17:20:57.086742 13425 solver.cpp:244]     Train net output #0: loss = 0.967697 (* 1 = 0.967697 loss)
I0427 17:20:57.086750 13425 solver.cpp:244]     Train net output #1: loss = 0.547987 (* 1 = 0.547987 loss)
I0427 17:20:57.086755 13425 solver.cpp:244]     Train net output #2: loss = 0.613842 (* 1 = 0.613842 loss)
I0427 17:20:57.086761 13425 sgd_solver.cpp:106] Iteration 2700, lr = 5e-05
I0427 17:22:36.784348 13425 solver.cpp:228] Iteration 2800, loss = 2.35672
I0427 17:22:36.784520 13425 solver.cpp:244]     Train net output #0: loss = 0.953143 (* 1 = 0.953143 loss)
I0427 17:22:36.784528 13425 solver.cpp:244]     Train net output #1: loss = 0.676119 (* 1 = 0.676119 loss)
I0427 17:22:36.784535 13425 solver.cpp:244]     Train net output #2: loss = 0.727459 (* 1 = 0.727459 loss)
I0427 17:22:36.784540 13425 sgd_solver.cpp:106] Iteration 2800, lr = 5e-05
I0427 17:24:16.637383 13425 solver.cpp:228] Iteration 2900, loss = 2.22253
I0427 17:24:16.637560 13425 solver.cpp:244]     Train net output #0: loss = 0.717105 (* 1 = 0.717105 loss)
I0427 17:24:16.637569 13425 solver.cpp:244]     Train net output #1: loss = 0.642252 (* 1 = 0.642252 loss)
I0427 17:24:16.637574 13425 solver.cpp:244]     Train net output #2: loss = 0.863178 (* 1 = 0.863178 loss)
I0427 17:24:16.637580 13425 sgd_solver.cpp:106] Iteration 2900, lr = 5e-05
I0427 17:25:55.690387 13425 solver.cpp:337] Iteration 3000, Testing net (#0)
I0427 17:25:55.690578 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 17:25:55.690583 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 17:25:55.690589 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 17:25:55.690608 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 17:25:55.690614 13425 net.cpp:693] Ignoring source layer visualize
I0427 17:25:55.690618 13425 net.cpp:693] Ignoring source layer fake
I0427 17:29:31.001426 13425 solver.cpp:404]     Test net output #0: loss = 0.944677 (* 1 = 0.944677 loss)
I0427 17:29:31.001626 13425 solver.cpp:404]     Test net output #1: loss = 0.553745 (* 1 = 0.553745 loss)
I0427 17:29:31.001638 13425 solver.cpp:404]     Test net output #2: loss = 0.745648 (* 1 = 0.745648 loss)
I0427 17:29:31.670430 13425 solver.cpp:228] Iteration 3000, loss = 2.50002
I0427 17:29:31.670480 13425 solver.cpp:244]     Train net output #0: loss = 0.972419 (* 1 = 0.972419 loss)
I0427 17:29:31.670490 13425 solver.cpp:244]     Train net output #1: loss = 0.699071 (* 1 = 0.699071 loss)
I0427 17:29:31.670498 13425 solver.cpp:244]     Train net output #2: loss = 0.828529 (* 1 = 0.828529 loss)
I0427 17:29:31.670506 13425 sgd_solver.cpp:106] Iteration 3000, lr = 5e-05
I0427 17:31:11.826694 13425 solver.cpp:228] Iteration 3100, loss = 2.54672
I0427 17:31:11.826889 13425 solver.cpp:244]     Train net output #0: loss = 0.967836 (* 1 = 0.967836 loss)
I0427 17:31:11.826897 13425 solver.cpp:244]     Train net output #1: loss = 0.761359 (* 1 = 0.761359 loss)
I0427 17:31:11.826902 13425 solver.cpp:244]     Train net output #2: loss = 0.817525 (* 1 = 0.817525 loss)
I0427 17:31:11.826908 13425 sgd_solver.cpp:106] Iteration 3100, lr = 5e-05
I0427 17:32:50.015900 13425 solver.cpp:228] Iteration 3200, loss = 2.36587
I0427 17:32:50.016093 13425 solver.cpp:244]     Train net output #0: loss = 0.938014 (* 1 = 0.938014 loss)
I0427 17:32:50.016100 13425 solver.cpp:244]     Train net output #1: loss = 0.660192 (* 1 = 0.660192 loss)
I0427 17:32:50.016105 13425 solver.cpp:244]     Train net output #2: loss = 0.767667 (* 1 = 0.767667 loss)
I0427 17:32:50.016111 13425 sgd_solver.cpp:106] Iteration 3200, lr = 5e-05
I0427 17:34:30.005398 13425 solver.cpp:228] Iteration 3300, loss = 2.56555
I0427 17:34:30.005573 13425 solver.cpp:244]     Train net output #0: loss = 0.965941 (* 1 = 0.965941 loss)
I0427 17:34:30.005581 13425 solver.cpp:244]     Train net output #1: loss = 0.708828 (* 1 = 0.708828 loss)
I0427 17:34:30.005587 13425 solver.cpp:244]     Train net output #2: loss = 0.890779 (* 1 = 0.890779 loss)
I0427 17:34:30.005594 13425 sgd_solver.cpp:106] Iteration 3300, lr = 5e-05
I0427 17:36:10.005928 13425 solver.cpp:228] Iteration 3400, loss = 2.30022
I0427 17:36:10.006129 13425 solver.cpp:244]     Train net output #0: loss = 0.979416 (* 1 = 0.979416 loss)
I0427 17:36:10.006137 13425 solver.cpp:244]     Train net output #1: loss = 0.61952 (* 1 = 0.61952 loss)
I0427 17:36:10.006144 13425 solver.cpp:244]     Train net output #2: loss = 0.701286 (* 1 = 0.701286 loss)
I0427 17:36:10.006148 13425 sgd_solver.cpp:106] Iteration 3400, lr = 5e-05
I0427 17:37:50.011407 13425 solver.cpp:228] Iteration 3500, loss = 2.55346
I0427 17:37:50.011564 13425 solver.cpp:244]     Train net output #0: loss = 0.961539 (* 1 = 0.961539 loss)
I0427 17:37:50.011574 13425 solver.cpp:244]     Train net output #1: loss = 0.696914 (* 1 = 0.696914 loss)
I0427 17:37:50.011579 13425 solver.cpp:244]     Train net output #2: loss = 0.895006 (* 1 = 0.895006 loss)
I0427 17:37:50.011584 13425 sgd_solver.cpp:106] Iteration 3500, lr = 5e-05
I0427 17:39:28.389997 13425 solver.cpp:228] Iteration 3600, loss = 2.38851
I0427 17:39:28.390175 13425 solver.cpp:244]     Train net output #0: loss = 0.978857 (* 1 = 0.978857 loss)
I0427 17:39:28.390183 13425 solver.cpp:244]     Train net output #1: loss = 0.648776 (* 1 = 0.648776 loss)
I0427 17:39:28.390188 13425 solver.cpp:244]     Train net output #2: loss = 0.760876 (* 1 = 0.760876 loss)
I0427 17:39:28.390194 13425 sgd_solver.cpp:106] Iteration 3600, lr = 5e-05
I0427 17:41:08.424635 13425 solver.cpp:228] Iteration 3700, loss = 2.09197
I0427 17:41:08.424801 13425 solver.cpp:244]     Train net output #0: loss = 0.974079 (* 1 = 0.974079 loss)
I0427 17:41:08.424809 13425 solver.cpp:244]     Train net output #1: loss = 0.407025 (* 1 = 0.407025 loss)
I0427 17:41:08.424814 13425 solver.cpp:244]     Train net output #2: loss = 0.710868 (* 1 = 0.710868 loss)
I0427 17:41:08.424820 13425 sgd_solver.cpp:106] Iteration 3700, lr = 5e-05
I0427 17:42:47.984011 13425 solver.cpp:228] Iteration 3800, loss = 1.98287
I0427 17:42:47.984194 13425 solver.cpp:244]     Train net output #0: loss = 0.950337 (* 1 = 0.950337 loss)
I0427 17:42:47.984202 13425 solver.cpp:244]     Train net output #1: loss = 0.242697 (* 1 = 0.242697 loss)
I0427 17:42:47.984210 13425 solver.cpp:244]     Train net output #2: loss = 0.78984 (* 1 = 0.78984 loss)
I0427 17:42:47.984215 13425 sgd_solver.cpp:106] Iteration 3800, lr = 5e-05
I0427 17:44:27.687857 13425 solver.cpp:228] Iteration 3900, loss = 2.31933
I0427 17:44:27.688086 13425 solver.cpp:244]     Train net output #0: loss = 0.968457 (* 1 = 0.968457 loss)
I0427 17:44:27.688098 13425 solver.cpp:244]     Train net output #1: loss = 0.593108 (* 1 = 0.593108 loss)
I0427 17:44:27.688107 13425 solver.cpp:244]     Train net output #2: loss = 0.757761 (* 1 = 0.757761 loss)
I0427 17:44:27.688114 13425 sgd_solver.cpp:106] Iteration 3900, lr = 5e-05
I0427 17:46:06.545167 13425 solver.cpp:337] Iteration 4000, Testing net (#0)
I0427 17:46:06.545320 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 17:46:06.545325 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 17:46:06.545327 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 17:46:06.545341 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 17:46:06.545346 13425 net.cpp:693] Ignoring source layer visualize
I0427 17:46:06.545347 13425 net.cpp:693] Ignoring source layer fake
I0427 17:49:41.997249 13425 solver.cpp:404]     Test net output #0: loss = 0.882776 (* 1 = 0.882776 loss)
I0427 17:49:41.997396 13425 solver.cpp:404]     Test net output #1: loss = 0.515996 (* 1 = 0.515996 loss)
I0427 17:49:41.997403 13425 solver.cpp:404]     Test net output #2: loss = 0.74832 (* 1 = 0.74832 loss)
I0427 17:49:42.655081 13425 solver.cpp:228] Iteration 4000, loss = 2.09323
I0427 17:49:42.655122 13425 solver.cpp:244]     Train net output #0: loss = 0.95695 (* 1 = 0.95695 loss)
I0427 17:49:42.655128 13425 solver.cpp:244]     Train net output #1: loss = 0.492974 (* 1 = 0.492974 loss)
I0427 17:49:42.655134 13425 solver.cpp:244]     Train net output #2: loss = 0.643311 (* 1 = 0.643311 loss)
I0427 17:49:42.655139 13425 sgd_solver.cpp:106] Iteration 4000, lr = 5e-05
I0427 17:51:22.810770 13425 solver.cpp:228] Iteration 4100, loss = 1.88267
I0427 17:51:22.810946 13425 solver.cpp:244]     Train net output #0: loss = 0.625806 (* 1 = 0.625806 loss)
I0427 17:51:22.810955 13425 solver.cpp:244]     Train net output #1: loss = 0.509807 (* 1 = 0.509807 loss)
I0427 17:51:22.810961 13425 solver.cpp:244]     Train net output #2: loss = 0.747051 (* 1 = 0.747051 loss)
I0427 17:51:22.810966 13425 sgd_solver.cpp:106] Iteration 4100, lr = 5e-05
I0427 17:53:01.162082 13425 solver.cpp:228] Iteration 4200, loss = 2.14593
I0427 17:53:01.162216 13425 solver.cpp:244]     Train net output #0: loss = 0.764906 (* 1 = 0.764906 loss)
I0427 17:53:01.162225 13425 solver.cpp:244]     Train net output #1: loss = 0.607526 (* 1 = 0.607526 loss)
I0427 17:53:01.162230 13425 solver.cpp:244]     Train net output #2: loss = 0.773501 (* 1 = 0.773501 loss)
I0427 17:53:01.162235 13425 sgd_solver.cpp:106] Iteration 4200, lr = 5e-05
I0427 17:54:41.405566 13425 solver.cpp:228] Iteration 4300, loss = 2.42514
I0427 17:54:41.405746 13425 solver.cpp:244]     Train net output #0: loss = 0.936091 (* 1 = 0.936091 loss)
I0427 17:54:41.405755 13425 solver.cpp:244]     Train net output #1: loss = 0.645475 (* 1 = 0.645475 loss)
I0427 17:54:41.405761 13425 solver.cpp:244]     Train net output #2: loss = 0.843576 (* 1 = 0.843576 loss)
I0427 17:54:41.405766 13425 sgd_solver.cpp:106] Iteration 4300, lr = 5e-05
I0427 17:56:21.625630 13425 solver.cpp:228] Iteration 4400, loss = 2.42094
I0427 17:56:21.625809 13425 solver.cpp:244]     Train net output #0: loss = 0.929028 (* 1 = 0.929028 loss)
I0427 17:56:21.625818 13425 solver.cpp:244]     Train net output #1: loss = 0.648046 (* 1 = 0.648046 loss)
I0427 17:56:21.625823 13425 solver.cpp:244]     Train net output #2: loss = 0.843866 (* 1 = 0.843866 loss)
I0427 17:56:21.625829 13425 sgd_solver.cpp:106] Iteration 4400, lr = 5e-05
I0427 17:58:01.765477 13425 solver.cpp:228] Iteration 4500, loss = 2.60245
I0427 17:58:01.765656 13425 solver.cpp:244]     Train net output #0: loss = 0.980745 (* 1 = 0.980745 loss)
I0427 17:58:01.765666 13425 solver.cpp:244]     Train net output #1: loss = 0.730788 (* 1 = 0.730788 loss)
I0427 17:58:01.765671 13425 solver.cpp:244]     Train net output #2: loss = 0.890921 (* 1 = 0.890921 loss)
I0427 17:58:01.765676 13425 sgd_solver.cpp:106] Iteration 4500, lr = 5e-05
I0427 17:59:40.152073 13425 solver.cpp:228] Iteration 4600, loss = 2.52268
I0427 17:59:40.152276 13425 solver.cpp:244]     Train net output #0: loss = 0.964003 (* 1 = 0.964003 loss)
I0427 17:59:40.152293 13425 solver.cpp:244]     Train net output #1: loss = 0.675034 (* 1 = 0.675034 loss)
I0427 17:59:40.152302 13425 solver.cpp:244]     Train net output #2: loss = 0.883639 (* 1 = 0.883639 loss)
I0427 17:59:40.152310 13425 sgd_solver.cpp:106] Iteration 4600, lr = 5e-05
I0427 18:01:19.966598 13425 solver.cpp:228] Iteration 4700, loss = 2.44865
I0427 18:01:19.966771 13425 solver.cpp:244]     Train net output #0: loss = 0.9682 (* 1 = 0.9682 loss)
I0427 18:01:19.966779 13425 solver.cpp:244]     Train net output #1: loss = 0.634746 (* 1 = 0.634746 loss)
I0427 18:01:19.966784 13425 solver.cpp:244]     Train net output #2: loss = 0.845707 (* 1 = 0.845707 loss)
I0427 18:01:19.966790 13425 sgd_solver.cpp:106] Iteration 4700, lr = 5e-05
I0427 18:02:59.779775 13425 solver.cpp:228] Iteration 4800, loss = 1.70537
I0427 18:02:59.779935 13425 solver.cpp:244]     Train net output #0: loss = 0.985149 (* 1 = 0.985149 loss)
I0427 18:02:59.779943 13425 solver.cpp:244]     Train net output #1: loss = 0.260324 (* 1 = 0.260324 loss)
I0427 18:02:59.779950 13425 solver.cpp:244]     Train net output #2: loss = 0.459896 (* 1 = 0.459896 loss)
I0427 18:02:59.779955 13425 sgd_solver.cpp:106] Iteration 4800, lr = 5e-05
I0427 18:04:39.412772 13425 solver.cpp:228] Iteration 4900, loss = 2.1685
I0427 18:04:39.412950 13425 solver.cpp:244]     Train net output #0: loss = 0.976243 (* 1 = 0.976243 loss)
I0427 18:04:39.412957 13425 solver.cpp:244]     Train net output #1: loss = 0.480925 (* 1 = 0.480925 loss)
I0427 18:04:39.412963 13425 solver.cpp:244]     Train net output #2: loss = 0.711335 (* 1 = 0.711335 loss)
I0427 18:04:39.412968 13425 sgd_solver.cpp:106] Iteration 4900, lr = 5e-05
I0427 18:06:17.670238 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_5000.caffemodel
I0427 18:06:18.402803 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_5000.solverstate
I0427 18:06:18.594367 13425 solver.cpp:337] Iteration 5000, Testing net (#0)
I0427 18:06:18.594405 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 18:06:18.594408 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 18:06:18.594411 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 18:06:18.594425 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 18:06:18.594427 13425 net.cpp:693] Ignoring source layer visualize
I0427 18:06:18.594429 13425 net.cpp:693] Ignoring source layer fake
I0427 18:09:51.530226 13425 solver.cpp:404]     Test net output #0: loss = 0.948225 (* 1 = 0.948225 loss)
I0427 18:09:51.530388 13425 solver.cpp:404]     Test net output #1: loss = 0.525682 (* 1 = 0.525682 loss)
I0427 18:09:51.530395 13425 solver.cpp:404]     Test net output #2: loss = 0.764015 (* 1 = 0.764015 loss)
I0427 18:09:52.179394 13425 solver.cpp:228] Iteration 5000, loss = 2.01753
I0427 18:09:52.179436 13425 solver.cpp:244]     Train net output #0: loss = 0.972734 (* 1 = 0.972734 loss)
I0427 18:09:52.179441 13425 solver.cpp:244]     Train net output #1: loss = 0.36036 (* 1 = 0.36036 loss)
I0427 18:09:52.179446 13425 solver.cpp:244]     Train net output #2: loss = 0.684435 (* 1 = 0.684435 loss)
I0427 18:09:52.179452 13425 sgd_solver.cpp:106] Iteration 5000, lr = 5e-05
I0427 18:11:31.583560 13425 solver.cpp:228] Iteration 5100, loss = 2.32928
I0427 18:11:31.583735 13425 solver.cpp:244]     Train net output #0: loss = 0.91811 (* 1 = 0.91811 loss)
I0427 18:11:31.583745 13425 solver.cpp:244]     Train net output #1: loss = 0.481988 (* 1 = 0.481988 loss)
I0427 18:11:31.583750 13425 solver.cpp:244]     Train net output #2: loss = 0.929184 (* 1 = 0.929184 loss)
I0427 18:11:31.583755 13425 sgd_solver.cpp:106] Iteration 5100, lr = 5e-05
I0427 18:13:09.820361 13425 solver.cpp:228] Iteration 5200, loss = 2.52078
I0427 18:13:09.820549 13425 solver.cpp:244]     Train net output #0: loss = 0.966802 (* 1 = 0.966802 loss)
I0427 18:13:09.820560 13425 solver.cpp:244]     Train net output #1: loss = 0.639775 (* 1 = 0.639775 loss)
I0427 18:13:09.820570 13425 solver.cpp:244]     Train net output #2: loss = 0.914202 (* 1 = 0.914202 loss)
I0427 18:13:09.820578 13425 sgd_solver.cpp:106] Iteration 5200, lr = 5e-05
I0427 18:14:49.326258 13425 solver.cpp:228] Iteration 5300, loss = 2.0949
I0427 18:14:49.326460 13425 solver.cpp:244]     Train net output #0: loss = 0.943978 (* 1 = 0.943978 loss)
I0427 18:14:49.326474 13425 solver.cpp:244]     Train net output #1: loss = 0.595902 (* 1 = 0.595902 loss)
I0427 18:14:49.326483 13425 solver.cpp:244]     Train net output #2: loss = 0.55502 (* 1 = 0.55502 loss)
I0427 18:14:49.326494 13425 sgd_solver.cpp:106] Iteration 5300, lr = 5e-05
I0427 18:16:29.032950 13425 solver.cpp:228] Iteration 5400, loss = 1.75955
I0427 18:16:29.033123 13425 solver.cpp:244]     Train net output #0: loss = 0.902634 (* 1 = 0.902634 loss)
I0427 18:16:29.033135 13425 solver.cpp:244]     Train net output #1: loss = 0.34402 (* 1 = 0.34402 loss)
I0427 18:16:29.033143 13425 solver.cpp:244]     Train net output #2: loss = 0.512892 (* 1 = 0.512892 loss)
I0427 18:16:29.033151 13425 sgd_solver.cpp:106] Iteration 5400, lr = 5e-05
I0427 18:18:08.837347 13425 solver.cpp:228] Iteration 5500, loss = 2.46335
I0427 18:18:08.837566 13425 solver.cpp:244]     Train net output #0: loss = 0.938984 (* 1 = 0.938984 loss)
I0427 18:18:08.837579 13425 solver.cpp:244]     Train net output #1: loss = 0.610479 (* 1 = 0.610479 loss)
I0427 18:18:08.837586 13425 solver.cpp:244]     Train net output #2: loss = 0.913889 (* 1 = 0.913889 loss)
I0427 18:18:08.837596 13425 sgd_solver.cpp:106] Iteration 5500, lr = 5e-05
I0427 18:19:48.702958 13425 solver.cpp:228] Iteration 5600, loss = 2.47635
I0427 18:19:48.703111 13425 solver.cpp:244]     Train net output #0: loss = 0.943112 (* 1 = 0.943112 loss)
I0427 18:19:48.703122 13425 solver.cpp:244]     Train net output #1: loss = 0.616882 (* 1 = 0.616882 loss)
I0427 18:19:48.703132 13425 solver.cpp:244]     Train net output #2: loss = 0.916354 (* 1 = 0.916354 loss)
I0427 18:19:48.703141 13425 sgd_solver.cpp:106] Iteration 5600, lr = 5e-05
I0427 18:21:26.869755 13425 solver.cpp:228] Iteration 5700, loss = 2.3953
I0427 18:21:26.869915 13425 solver.cpp:244]     Train net output #0: loss = 0.923988 (* 1 = 0.923988 loss)
I0427 18:21:26.869926 13425 solver.cpp:244]     Train net output #1: loss = 0.648102 (* 1 = 0.648102 loss)
I0427 18:21:26.869942 13425 solver.cpp:244]     Train net output #2: loss = 0.823215 (* 1 = 0.823215 loss)
I0427 18:21:26.869949 13425 sgd_solver.cpp:106] Iteration 5700, lr = 5e-05
I0427 18:23:06.711144 13425 solver.cpp:228] Iteration 5800, loss = 2.26324
I0427 18:23:06.711321 13425 solver.cpp:244]     Train net output #0: loss = 0.972935 (* 1 = 0.972935 loss)
I0427 18:23:06.711333 13425 solver.cpp:244]     Train net output #1: loss = 0.62294 (* 1 = 0.62294 loss)
I0427 18:23:06.711341 13425 solver.cpp:244]     Train net output #2: loss = 0.667367 (* 1 = 0.667367 loss)
I0427 18:23:06.711349 13425 sgd_solver.cpp:106] Iteration 5800, lr = 5e-05
I0427 18:24:46.546615 13425 solver.cpp:228] Iteration 5900, loss = 2.64162
I0427 18:24:46.546757 13425 solver.cpp:244]     Train net output #0: loss = 0.97981 (* 1 = 0.97981 loss)
I0427 18:24:46.546771 13425 solver.cpp:244]     Train net output #1: loss = 0.760497 (* 1 = 0.760497 loss)
I0427 18:24:46.546778 13425 solver.cpp:244]     Train net output #2: loss = 0.901314 (* 1 = 0.901314 loss)
I0427 18:24:46.546788 13425 sgd_solver.cpp:106] Iteration 5900, lr = 5e-05
I0427 18:26:25.298888 13425 solver.cpp:337] Iteration 6000, Testing net (#0)
I0427 18:26:25.299052 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 18:26:25.299057 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 18:26:25.299064 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 18:26:25.299083 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 18:26:25.299090 13425 net.cpp:693] Ignoring source layer visualize
I0427 18:26:25.299093 13425 net.cpp:693] Ignoring source layer fake
I0427 18:29:59.009246 13425 solver.cpp:404]     Test net output #0: loss = 0.943199 (* 1 = 0.943199 loss)
I0427 18:29:59.009428 13425 solver.cpp:404]     Test net output #1: loss = 0.550608 (* 1 = 0.550608 loss)
I0427 18:29:59.009449 13425 solver.cpp:404]     Test net output #2: loss = 0.783541 (* 1 = 0.783541 loss)
I0427 18:29:59.659631 13425 solver.cpp:228] Iteration 6000, loss = 2.37981
I0427 18:29:59.659660 13425 solver.cpp:244]     Train net output #0: loss = 0.976951 (* 1 = 0.976951 loss)
I0427 18:29:59.659668 13425 solver.cpp:244]     Train net output #1: loss = 0.594277 (* 1 = 0.594277 loss)
I0427 18:29:59.659675 13425 solver.cpp:244]     Train net output #2: loss = 0.808583 (* 1 = 0.808583 loss)
I0427 18:29:59.659698 13425 sgd_solver.cpp:106] Iteration 6000, lr = 5e-05
I0427 18:31:37.847831 13425 solver.cpp:228] Iteration 6100, loss = 2.26343
I0427 18:31:37.848034 13425 solver.cpp:244]     Train net output #0: loss = 0.979287 (* 1 = 0.979287 loss)
I0427 18:31:37.848045 13425 solver.cpp:244]     Train net output #1: loss = 0.500333 (* 1 = 0.500333 loss)
I0427 18:31:37.848054 13425 solver.cpp:244]     Train net output #2: loss = 0.783814 (* 1 = 0.783814 loss)
I0427 18:31:37.848063 13425 sgd_solver.cpp:106] Iteration 6100, lr = 5e-05
I0427 18:33:17.468248 13425 solver.cpp:228] Iteration 6200, loss = 2.31349
I0427 18:33:17.468406 13425 solver.cpp:244]     Train net output #0: loss = 0.963732 (* 1 = 0.963732 loss)
I0427 18:33:17.468418 13425 solver.cpp:244]     Train net output #1: loss = 0.463784 (* 1 = 0.463784 loss)
I0427 18:33:17.468428 13425 solver.cpp:244]     Train net output #2: loss = 0.885972 (* 1 = 0.885972 loss)
I0427 18:33:17.468436 13425 sgd_solver.cpp:106] Iteration 6200, lr = 5e-05
I0427 18:34:56.762764 13425 solver.cpp:228] Iteration 6300, loss = 2.22037
I0427 18:34:56.763887 13425 solver.cpp:244]     Train net output #0: loss = 0.936953 (* 1 = 0.936953 loss)
I0427 18:34:56.763913 13425 solver.cpp:244]     Train net output #1: loss = 0.46939 (* 1 = 0.46939 loss)
I0427 18:34:56.763936 13425 solver.cpp:244]     Train net output #2: loss = 0.814027 (* 1 = 0.814027 loss)
I0427 18:34:56.763958 13425 sgd_solver.cpp:106] Iteration 6300, lr = 5e-05
I0427 18:36:36.128111 13425 solver.cpp:228] Iteration 6400, loss = 2.36977
I0427 18:36:36.128288 13425 solver.cpp:244]     Train net output #0: loss = 0.939075 (* 1 = 0.939075 loss)
I0427 18:36:36.128299 13425 solver.cpp:244]     Train net output #1: loss = 0.670269 (* 1 = 0.670269 loss)
I0427 18:36:36.128309 13425 solver.cpp:244]     Train net output #2: loss = 0.760427 (* 1 = 0.760427 loss)
I0427 18:36:36.128315 13425 sgd_solver.cpp:106] Iteration 6400, lr = 5e-05
I0427 18:38:15.709967 13425 solver.cpp:228] Iteration 6500, loss = 2.3156
I0427 18:38:15.710167 13425 solver.cpp:244]     Train net output #0: loss = 0.940559 (* 1 = 0.940559 loss)
I0427 18:38:15.710180 13425 solver.cpp:244]     Train net output #1: loss = 0.617551 (* 1 = 0.617551 loss)
I0427 18:38:15.710188 13425 solver.cpp:244]     Train net output #2: loss = 0.757487 (* 1 = 0.757487 loss)
I0427 18:38:15.710197 13425 sgd_solver.cpp:106] Iteration 6500, lr = 5e-05
I0427 18:39:55.487277 13425 solver.cpp:228] Iteration 6600, loss = 2.04318
I0427 18:39:55.487416 13425 solver.cpp:244]     Train net output #0: loss = 0.590048 (* 1 = 0.590048 loss)
I0427 18:39:55.487426 13425 solver.cpp:244]     Train net output #1: loss = 0.646516 (* 1 = 0.646516 loss)
I0427 18:39:55.487437 13425 solver.cpp:244]     Train net output #2: loss = 0.806614 (* 1 = 0.806614 loss)
I0427 18:39:55.487444 13425 sgd_solver.cpp:106] Iteration 6600, lr = 5e-05
I0427 18:41:33.691691 13425 solver.cpp:228] Iteration 6700, loss = 2.17469
I0427 18:41:33.691844 13425 solver.cpp:244]     Train net output #0: loss = 0.7028 (* 1 = 0.7028 loss)
I0427 18:41:33.691857 13425 solver.cpp:244]     Train net output #1: loss = 0.60253 (* 1 = 0.60253 loss)
I0427 18:41:33.691865 13425 solver.cpp:244]     Train net output #2: loss = 0.869357 (* 1 = 0.869357 loss)
I0427 18:41:33.691874 13425 sgd_solver.cpp:106] Iteration 6700, lr = 5e-05
I0427 18:43:13.554083 13425 solver.cpp:228] Iteration 6800, loss = 2.47255
I0427 18:43:13.554280 13425 solver.cpp:244]     Train net output #0: loss = 0.944785 (* 1 = 0.944785 loss)
I0427 18:43:13.554291 13425 solver.cpp:244]     Train net output #1: loss = 0.80283 (* 1 = 0.80283 loss)
I0427 18:43:13.554306 13425 solver.cpp:244]     Train net output #2: loss = 0.724932 (* 1 = 0.724932 loss)
I0427 18:43:13.554313 13425 sgd_solver.cpp:106] Iteration 6800, lr = 5e-05
I0427 18:44:53.424088 13425 solver.cpp:228] Iteration 6900, loss = 2.58947
I0427 18:44:53.424258 13425 solver.cpp:244]     Train net output #0: loss = 0.960723 (* 1 = 0.960723 loss)
I0427 18:44:53.424269 13425 solver.cpp:244]     Train net output #1: loss = 0.790559 (* 1 = 0.790559 loss)
I0427 18:44:53.424279 13425 solver.cpp:244]     Train net output #2: loss = 0.838191 (* 1 = 0.838191 loss)
I0427 18:44:53.424288 13425 sgd_solver.cpp:106] Iteration 6900, lr = 5e-05
I0427 18:46:32.238850 13425 solver.cpp:337] Iteration 7000, Testing net (#0)
I0427 18:46:32.239023 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 18:46:32.239029 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 18:46:32.239035 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 18:46:32.239054 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 18:46:32.239063 13425 net.cpp:693] Ignoring source layer visualize
I0427 18:46:32.239066 13425 net.cpp:693] Ignoring source layer fake
I0427 18:50:06.181032 13425 solver.cpp:404]     Test net output #0: loss = 0.9447 (* 1 = 0.9447 loss)
I0427 18:50:06.181179 13425 solver.cpp:404]     Test net output #1: loss = 0.582216 (* 1 = 0.582216 loss)
I0427 18:50:06.181190 13425 solver.cpp:404]     Test net output #2: loss = 0.804618 (* 1 = 0.804618 loss)
I0427 18:50:06.834975 13425 solver.cpp:228] Iteration 7000, loss = 2.21937
I0427 18:50:06.835002 13425 solver.cpp:244]     Train net output #0: loss = 0.973742 (* 1 = 0.973742 loss)
I0427 18:50:06.835009 13425 solver.cpp:244]     Train net output #1: loss = 0.589175 (* 1 = 0.589175 loss)
I0427 18:50:06.835016 13425 solver.cpp:244]     Train net output #2: loss = 0.656449 (* 1 = 0.656449 loss)
I0427 18:50:06.835037 13425 sgd_solver.cpp:106] Iteration 7000, lr = 5e-05
I0427 18:51:45.044394 13425 solver.cpp:228] Iteration 7100, loss = 2.44316
I0427 18:51:45.046821 13425 solver.cpp:244]     Train net output #0: loss = 0.95333 (* 1 = 0.95333 loss)
I0427 18:51:45.046847 13425 solver.cpp:244]     Train net output #1: loss = 0.634591 (* 1 = 0.634591 loss)
I0427 18:51:45.046856 13425 solver.cpp:244]     Train net output #2: loss = 0.855236 (* 1 = 0.855236 loss)
I0427 18:51:45.046864 13425 sgd_solver.cpp:106] Iteration 7100, lr = 5e-05
I0427 18:53:24.800586 13425 solver.cpp:228] Iteration 7200, loss = 2.32704
I0427 18:53:24.800755 13425 solver.cpp:244]     Train net output #0: loss = 0.972593 (* 1 = 0.972593 loss)
I0427 18:53:24.800765 13425 solver.cpp:244]     Train net output #1: loss = 0.612943 (* 1 = 0.612943 loss)
I0427 18:53:24.800775 13425 solver.cpp:244]     Train net output #2: loss = 0.741504 (* 1 = 0.741504 loss)
I0427 18:53:24.800784 13425 sgd_solver.cpp:106] Iteration 7200, lr = 5e-05
I0427 18:55:04.621206 13425 solver.cpp:228] Iteration 7300, loss = 2.22755
I0427 18:55:04.621347 13425 solver.cpp:244]     Train net output #0: loss = 0.983845 (* 1 = 0.983845 loss)
I0427 18:55:04.621361 13425 solver.cpp:244]     Train net output #1: loss = 0.54095 (* 1 = 0.54095 loss)
I0427 18:55:04.621369 13425 solver.cpp:244]     Train net output #2: loss = 0.70275 (* 1 = 0.70275 loss)
I0427 18:55:04.621382 13425 sgd_solver.cpp:106] Iteration 7300, lr = 5e-05
I0427 18:56:44.207693 13425 solver.cpp:228] Iteration 7400, loss = 2.10596
I0427 18:56:44.207868 13425 solver.cpp:244]     Train net output #0: loss = 0.980269 (* 1 = 0.980269 loss)
I0427 18:56:44.207880 13425 solver.cpp:244]     Train net output #1: loss = 0.509776 (* 1 = 0.509776 loss)
I0427 18:56:44.207888 13425 solver.cpp:244]     Train net output #2: loss = 0.615914 (* 1 = 0.615914 loss)
I0427 18:56:44.207896 13425 sgd_solver.cpp:106] Iteration 7400, lr = 5e-05
I0427 18:58:23.454095 13425 solver.cpp:228] Iteration 7500, loss = 2.29811
I0427 18:58:23.454301 13425 solver.cpp:244]     Train net output #0: loss = 0.9629 (* 1 = 0.9629 loss)
I0427 18:58:23.454314 13425 solver.cpp:244]     Train net output #1: loss = 0.43979 (* 1 = 0.43979 loss)
I0427 18:58:23.454324 13425 solver.cpp:244]     Train net output #2: loss = 0.895422 (* 1 = 0.895422 loss)
I0427 18:58:23.454332 13425 sgd_solver.cpp:106] Iteration 7500, lr = 5e-05
I0427 19:00:02.691474 13425 solver.cpp:228] Iteration 7600, loss = 2.10014
I0427 19:00:02.691669 13425 solver.cpp:244]     Train net output #0: loss = 0.930611 (* 1 = 0.930611 loss)
I0427 19:00:02.691681 13425 solver.cpp:244]     Train net output #1: loss = 0.485572 (* 1 = 0.485572 loss)
I0427 19:00:02.691690 13425 solver.cpp:244]     Train net output #2: loss = 0.683957 (* 1 = 0.683957 loss)
I0427 19:00:02.691699 13425 sgd_solver.cpp:106] Iteration 7600, lr = 5e-05
I0427 19:01:40.882333 13425 solver.cpp:228] Iteration 7700, loss = 2.32558
I0427 19:01:40.882511 13425 solver.cpp:244]     Train net output #0: loss = 0.939033 (* 1 = 0.939033 loss)
I0427 19:01:40.882524 13425 solver.cpp:244]     Train net output #1: loss = 0.639179 (* 1 = 0.639179 loss)
I0427 19:01:40.882531 13425 solver.cpp:244]     Train net output #2: loss = 0.747371 (* 1 = 0.747371 loss)
I0427 19:01:40.882539 13425 sgd_solver.cpp:106] Iteration 7700, lr = 5e-05
I0427 19:03:20.379482 13425 solver.cpp:228] Iteration 7800, loss = 2.20879
I0427 19:03:20.379645 13425 solver.cpp:244]     Train net output #0: loss = 0.941049 (* 1 = 0.941049 loss)
I0427 19:03:20.379657 13425 solver.cpp:244]     Train net output #1: loss = 0.502012 (* 1 = 0.502012 loss)
I0427 19:03:20.379667 13425 solver.cpp:244]     Train net output #2: loss = 0.765724 (* 1 = 0.765724 loss)
I0427 19:03:20.379673 13425 sgd_solver.cpp:106] Iteration 7800, lr = 5e-05
I0427 19:05:00.157954 13425 solver.cpp:228] Iteration 7900, loss = 1.42303
I0427 19:05:00.158123 13425 solver.cpp:244]     Train net output #0: loss = 0.969188 (* 1 = 0.969188 loss)
I0427 19:05:00.158133 13425 solver.cpp:244]     Train net output #1: loss = 0.159605 (* 1 = 0.159605 loss)
I0427 19:05:00.158143 13425 solver.cpp:244]     Train net output #2: loss = 0.294241 (* 1 = 0.294241 loss)
I0427 19:05:00.158151 13425 sgd_solver.cpp:106] Iteration 7900, lr = 5e-05
I0427 19:06:39.088876 13425 solver.cpp:337] Iteration 8000, Testing net (#0)
I0427 19:06:39.089058 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 19:06:39.089063 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 19:06:39.089069 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 19:06:39.089089 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 19:06:39.089097 13425 net.cpp:693] Ignoring source layer visualize
I0427 19:06:39.089100 13425 net.cpp:693] Ignoring source layer fake
I0427 19:10:13.084553 13425 solver.cpp:404]     Test net output #0: loss = 0.929651 (* 1 = 0.929651 loss)
I0427 19:10:13.084715 13425 solver.cpp:404]     Test net output #1: loss = 0.575569 (* 1 = 0.575569 loss)
I0427 19:10:13.084725 13425 solver.cpp:404]     Test net output #2: loss = 0.79694 (* 1 = 0.79694 loss)
I0427 19:10:13.743906 13425 solver.cpp:228] Iteration 8000, loss = 2.438
I0427 19:10:13.743935 13425 solver.cpp:244]     Train net output #0: loss = 0.924032 (* 1 = 0.924032 loss)
I0427 19:10:13.743943 13425 solver.cpp:244]     Train net output #1: loss = 0.650926 (* 1 = 0.650926 loss)
I0427 19:10:13.743952 13425 solver.cpp:244]     Train net output #2: loss = 0.863044 (* 1 = 0.863044 loss)
I0427 19:10:13.743973 13425 sgd_solver.cpp:106] Iteration 8000, lr = 5e-05
I0427 19:11:53.608209 13425 solver.cpp:228] Iteration 8100, loss = 2.62843
I0427 19:11:53.608481 13425 solver.cpp:244]     Train net output #0: loss = 0.952099 (* 1 = 0.952099 loss)
I0427 19:11:53.608494 13425 solver.cpp:244]     Train net output #1: loss = 0.7372 (* 1 = 0.7372 loss)
I0427 19:11:53.608502 13425 solver.cpp:244]     Train net output #2: loss = 0.939127 (* 1 = 0.939127 loss)
I0427 19:11:53.608512 13425 sgd_solver.cpp:106] Iteration 8100, lr = 5e-05
I0427 19:13:31.808274 13425 solver.cpp:228] Iteration 8200, loss = 2.52961
I0427 19:13:31.808478 13425 solver.cpp:244]     Train net output #0: loss = 0.936817 (* 1 = 0.936817 loss)
I0427 19:13:31.808490 13425 solver.cpp:244]     Train net output #1: loss = 0.748358 (* 1 = 0.748358 loss)
I0427 19:13:31.808501 13425 solver.cpp:244]     Train net output #2: loss = 0.844434 (* 1 = 0.844434 loss)
I0427 19:13:31.808509 13425 sgd_solver.cpp:106] Iteration 8200, lr = 5e-05
I0427 19:15:11.654952 13425 solver.cpp:228] Iteration 8300, loss = 2.45927
I0427 19:15:11.655128 13425 solver.cpp:244]     Train net output #0: loss = 0.976841 (* 1 = 0.976841 loss)
I0427 19:15:11.655140 13425 solver.cpp:244]     Train net output #1: loss = 0.617909 (* 1 = 0.617909 loss)
I0427 19:15:11.655148 13425 solver.cpp:244]     Train net output #2: loss = 0.864519 (* 1 = 0.864519 loss)
I0427 19:15:11.655156 13425 sgd_solver.cpp:106] Iteration 8300, lr = 5e-05
I0427 19:16:51.715207 13425 solver.cpp:228] Iteration 8400, loss = 2.34769
I0427 19:16:51.715755 13425 solver.cpp:244]     Train net output #0: loss = 0.98362 (* 1 = 0.98362 loss)
I0427 19:16:51.715767 13425 solver.cpp:244]     Train net output #1: loss = 0.645472 (* 1 = 0.645472 loss)
I0427 19:16:51.715790 13425 solver.cpp:244]     Train net output #2: loss = 0.718598 (* 1 = 0.718598 loss)
I0427 19:16:51.715798 13425 sgd_solver.cpp:106] Iteration 8400, lr = 5e-05
I0427 19:18:31.538267 13425 solver.cpp:228] Iteration 8500, loss = 2.15284
I0427 19:18:31.538447 13425 solver.cpp:244]     Train net output #0: loss = 0.98538 (* 1 = 0.98538 loss)
I0427 19:18:31.538458 13425 solver.cpp:244]     Train net output #1: loss = 0.49587 (* 1 = 0.49587 loss)
I0427 19:18:31.538467 13425 solver.cpp:244]     Train net output #2: loss = 0.671585 (* 1 = 0.671585 loss)
I0427 19:18:31.538476 13425 sgd_solver.cpp:106] Iteration 8500, lr = 5e-05
I0427 19:20:09.733688 13425 solver.cpp:228] Iteration 8600, loss = 2.26807
I0427 19:20:09.733878 13425 solver.cpp:244]     Train net output #0: loss = 0.974647 (* 1 = 0.974647 loss)
I0427 19:20:09.733891 13425 solver.cpp:244]     Train net output #1: loss = 0.561734 (* 1 = 0.561734 loss)
I0427 19:20:09.733901 13425 solver.cpp:244]     Train net output #2: loss = 0.731691 (* 1 = 0.731691 loss)
I0427 19:20:09.733911 13425 sgd_solver.cpp:106] Iteration 8600, lr = 5e-05
I0427 19:21:49.389979 13425 solver.cpp:228] Iteration 8700, loss = 2.24606
I0427 19:21:49.390141 13425 solver.cpp:244]     Train net output #0: loss = 0.95868 (* 1 = 0.95868 loss)
I0427 19:21:49.390153 13425 solver.cpp:244]     Train net output #1: loss = 0.537464 (* 1 = 0.537464 loss)
I0427 19:21:49.390162 13425 solver.cpp:244]     Train net output #2: loss = 0.74992 (* 1 = 0.74992 loss)
I0427 19:21:49.390171 13425 sgd_solver.cpp:106] Iteration 8700, lr = 5e-05
I0427 19:23:28.702896 13425 solver.cpp:228] Iteration 8800, loss = 2.21328
I0427 19:23:28.703058 13425 solver.cpp:244]     Train net output #0: loss = 0.936896 (* 1 = 0.936896 loss)
I0427 19:23:28.703069 13425 solver.cpp:244]     Train net output #1: loss = 0.433547 (* 1 = 0.433547 loss)
I0427 19:23:28.703078 13425 solver.cpp:244]     Train net output #2: loss = 0.842835 (* 1 = 0.842835 loss)
I0427 19:23:28.703085 13425 sgd_solver.cpp:106] Iteration 8800, lr = 5e-05
I0427 19:25:08.041426 13425 solver.cpp:228] Iteration 8900, loss = 2.35873
I0427 19:25:08.041605 13425 solver.cpp:244]     Train net output #0: loss = 0.939435 (* 1 = 0.939435 loss)
I0427 19:25:08.041617 13425 solver.cpp:244]     Train net output #1: loss = 0.652778 (* 1 = 0.652778 loss)
I0427 19:25:08.041626 13425 solver.cpp:244]     Train net output #2: loss = 0.766517 (* 1 = 0.766517 loss)
I0427 19:25:08.041635 13425 sgd_solver.cpp:106] Iteration 8900, lr = 5e-05
I0427 19:26:46.657960 13425 solver.cpp:337] Iteration 9000, Testing net (#0)
I0427 19:26:46.658126 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 19:26:46.658131 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 19:26:46.658138 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 19:26:46.658159 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 19:26:46.658164 13425 net.cpp:693] Ignoring source layer visualize
I0427 19:26:46.658166 13425 net.cpp:693] Ignoring source layer fake
I0427 19:30:20.360129 13425 solver.cpp:404]     Test net output #0: loss = 0.908458 (* 1 = 0.908458 loss)
I0427 19:30:20.360327 13425 solver.cpp:404]     Test net output #1: loss = 0.555105 (* 1 = 0.555105 loss)
I0427 19:30:20.360338 13425 solver.cpp:404]     Test net output #2: loss = 0.789027 (* 1 = 0.789027 loss)
I0427 19:30:21.012794 13425 solver.cpp:228] Iteration 9000, loss = 2.19882
I0427 19:30:21.012823 13425 solver.cpp:244]     Train net output #0: loss = 0.950917 (* 1 = 0.950917 loss)
I0427 19:30:21.012831 13425 solver.cpp:244]     Train net output #1: loss = 0.671417 (* 1 = 0.671417 loss)
I0427 19:30:21.012838 13425 solver.cpp:244]     Train net output #2: loss = 0.57649 (* 1 = 0.57649 loss)
I0427 19:30:21.012861 13425 sgd_solver.cpp:106] Iteration 9000, lr = 5e-05
I0427 19:32:00.787843 13425 solver.cpp:228] Iteration 9100, loss = 2.395
I0427 19:32:00.788033 13425 solver.cpp:244]     Train net output #0: loss = 0.893107 (* 1 = 0.893107 loss)
I0427 19:32:00.788044 13425 solver.cpp:244]     Train net output #1: loss = 0.660729 (* 1 = 0.660729 loss)
I0427 19:32:00.788053 13425 solver.cpp:244]     Train net output #2: loss = 0.841168 (* 1 = 0.841168 loss)
I0427 19:32:00.788063 13425 sgd_solver.cpp:106] Iteration 9100, lr = 5e-05
I0427 19:33:40.620450 13425 solver.cpp:228] Iteration 9200, loss = 2.41572
I0427 19:33:40.620635 13425 solver.cpp:244]     Train net output #0: loss = 0.864488 (* 1 = 0.864488 loss)
I0427 19:33:40.620643 13425 solver.cpp:244]     Train net output #1: loss = 0.659271 (* 1 = 0.659271 loss)
I0427 19:33:40.620649 13425 solver.cpp:244]     Train net output #2: loss = 0.891961 (* 1 = 0.891961 loss)
I0427 19:33:40.620656 13425 sgd_solver.cpp:106] Iteration 9200, lr = 5e-05
I0427 19:35:18.816553 13425 solver.cpp:228] Iteration 9300, loss = 2.45481
I0427 19:35:18.817085 13425 solver.cpp:244]     Train net output #0: loss = 0.949488 (* 1 = 0.949488 loss)
I0427 19:35:18.817107 13425 solver.cpp:244]     Train net output #1: loss = 0.69746 (* 1 = 0.69746 loss)
I0427 19:35:18.817113 13425 solver.cpp:244]     Train net output #2: loss = 0.80786 (* 1 = 0.80786 loss)
I0427 19:35:18.817118 13425 sgd_solver.cpp:106] Iteration 9300, lr = 5e-05
I0427 19:36:58.686367 13425 solver.cpp:228] Iteration 9400, loss = 2.42724
I0427 19:36:58.686506 13425 solver.cpp:244]     Train net output #0: loss = 0.957007 (* 1 = 0.957007 loss)
I0427 19:36:58.686513 13425 solver.cpp:244]     Train net output #1: loss = 0.638992 (* 1 = 0.638992 loss)
I0427 19:36:58.686519 13425 solver.cpp:244]     Train net output #2: loss = 0.831239 (* 1 = 0.831239 loss)
I0427 19:36:58.686524 13425 sgd_solver.cpp:106] Iteration 9400, lr = 5e-05
I0427 19:38:38.530624 13425 solver.cpp:228] Iteration 9500, loss = 2.19336
I0427 19:38:38.530792 13425 solver.cpp:244]     Train net output #0: loss = 0.965005 (* 1 = 0.965005 loss)
I0427 19:38:38.530802 13425 solver.cpp:244]     Train net output #1: loss = 0.546963 (* 1 = 0.546963 loss)
I0427 19:38:38.530807 13425 solver.cpp:244]     Train net output #2: loss = 0.681397 (* 1 = 0.681397 loss)
I0427 19:38:38.530812 13425 sgd_solver.cpp:106] Iteration 9500, lr = 5e-05
I0427 19:40:16.770511 13425 solver.cpp:228] Iteration 9600, loss = 2.53814
I0427 19:40:16.770684 13425 solver.cpp:244]     Train net output #0: loss = 0.969579 (* 1 = 0.969579 loss)
I0427 19:40:16.770691 13425 solver.cpp:244]     Train net output #1: loss = 0.684429 (* 1 = 0.684429 loss)
I0427 19:40:16.770699 13425 solver.cpp:244]     Train net output #2: loss = 0.884134 (* 1 = 0.884134 loss)
I0427 19:40:16.770704 13425 sgd_solver.cpp:106] Iteration 9600, lr = 5e-05
I0427 19:41:56.604627 13425 solver.cpp:228] Iteration 9700, loss = 2.39999
I0427 19:41:56.604789 13425 solver.cpp:244]     Train net output #0: loss = 0.95451 (* 1 = 0.95451 loss)
I0427 19:41:56.604799 13425 solver.cpp:244]     Train net output #1: loss = 0.618513 (* 1 = 0.618513 loss)
I0427 19:41:56.604804 13425 solver.cpp:244]     Train net output #2: loss = 0.826967 (* 1 = 0.826967 loss)
I0427 19:41:56.604810 13425 sgd_solver.cpp:106] Iteration 9700, lr = 5e-05
I0427 19:43:36.361862 13425 solver.cpp:228] Iteration 9800, loss = 2.55604
I0427 19:43:36.362061 13425 solver.cpp:244]     Train net output #0: loss = 0.976259 (* 1 = 0.976259 loss)
I0427 19:43:36.362069 13425 solver.cpp:244]     Train net output #1: loss = 0.658601 (* 1 = 0.658601 loss)
I0427 19:43:36.362074 13425 solver.cpp:244]     Train net output #2: loss = 0.921184 (* 1 = 0.921184 loss)
I0427 19:43:36.362081 13425 sgd_solver.cpp:106] Iteration 9800, lr = 5e-05
I0427 19:45:15.990713 13425 solver.cpp:228] Iteration 9900, loss = 2.30832
I0427 19:45:15.990875 13425 solver.cpp:244]     Train net output #0: loss = 0.981263 (* 1 = 0.981263 loss)
I0427 19:45:15.990882 13425 solver.cpp:244]     Train net output #1: loss = 0.481054 (* 1 = 0.481054 loss)
I0427 19:45:15.990887 13425 solver.cpp:244]     Train net output #2: loss = 0.846004 (* 1 = 0.846004 loss)
I0427 19:45:15.990893 13425 sgd_solver.cpp:106] Iteration 9900, lr = 5e-05
I0427 19:46:54.309780 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_10000.caffemodel
I0427 19:46:55.025528 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_10000.solverstate
I0427 19:46:55.211314 13425 solver.cpp:337] Iteration 10000, Testing net (#0)
I0427 19:46:55.211354 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 19:46:55.211357 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 19:46:55.211360 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 19:46:55.211374 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 19:46:55.211377 13425 net.cpp:693] Ignoring source layer visualize
I0427 19:46:55.211380 13425 net.cpp:693] Ignoring source layer fake
I0427 19:50:28.553803 13425 solver.cpp:404]     Test net output #0: loss = 0.947709 (* 1 = 0.947709 loss)
I0427 19:50:28.553951 13425 solver.cpp:404]     Test net output #1: loss = 0.564888 (* 1 = 0.564888 loss)
I0427 19:50:28.553958 13425 solver.cpp:404]     Test net output #2: loss = 0.782864 (* 1 = 0.782864 loss)
I0427 19:50:29.208366 13425 solver.cpp:228] Iteration 10000, loss = 2.10897
I0427 19:50:29.208407 13425 solver.cpp:244]     Train net output #0: loss = 0.935051 (* 1 = 0.935051 loss)
I0427 19:50:29.208413 13425 solver.cpp:244]     Train net output #1: loss = 0.316891 (* 1 = 0.316891 loss)
I0427 19:50:29.208418 13425 solver.cpp:244]     Train net output #2: loss = 0.857026 (* 1 = 0.857026 loss)
I0427 19:50:29.208423 13425 sgd_solver.cpp:106] Iteration 10000, lr = 5e-05
I0427 19:52:08.563122 13425 solver.cpp:228] Iteration 10100, loss = 2.37952
I0427 19:52:08.563290 13425 solver.cpp:244]     Train net output #0: loss = 0.929468 (* 1 = 0.929468 loss)
I0427 19:52:08.563299 13425 solver.cpp:244]     Train net output #1: loss = 0.552118 (* 1 = 0.552118 loss)
I0427 19:52:08.563304 13425 solver.cpp:244]     Train net output #2: loss = 0.897933 (* 1 = 0.897933 loss)
I0427 19:52:08.563309 13425 sgd_solver.cpp:106] Iteration 10100, lr = 5e-05
I0427 19:53:46.636775 13425 solver.cpp:228] Iteration 10200, loss = 2.21512
I0427 19:53:46.636934 13425 solver.cpp:244]     Train net output #0: loss = 0.977862 (* 1 = 0.977862 loss)
I0427 19:53:46.636941 13425 solver.cpp:244]     Train net output #1: loss = 0.494868 (* 1 = 0.494868 loss)
I0427 19:53:46.636946 13425 solver.cpp:244]     Train net output #2: loss = 0.742391 (* 1 = 0.742391 loss)
I0427 19:53:46.636951 13425 sgd_solver.cpp:106] Iteration 10200, lr = 5e-05
I0427 19:55:26.125437 13425 solver.cpp:228] Iteration 10300, loss = 2.46948
I0427 19:55:26.125598 13425 solver.cpp:244]     Train net output #0: loss = 0.959475 (* 1 = 0.959475 loss)
I0427 19:55:26.125607 13425 solver.cpp:244]     Train net output #1: loss = 0.747073 (* 1 = 0.747073 loss)
I0427 19:55:26.125612 13425 solver.cpp:244]     Train net output #2: loss = 0.762933 (* 1 = 0.762933 loss)
I0427 19:55:26.125617 13425 sgd_solver.cpp:106] Iteration 10300, lr = 5e-05
I0427 19:57:05.826886 13425 solver.cpp:228] Iteration 10400, loss = 1.76318
I0427 19:57:05.827103 13425 solver.cpp:244]     Train net output #0: loss = 0.963377 (* 1 = 0.963377 loss)
I0427 19:57:05.827112 13425 solver.cpp:244]     Train net output #1: loss = 0.171328 (* 1 = 0.171328 loss)
I0427 19:57:05.827119 13425 solver.cpp:244]     Train net output #2: loss = 0.62848 (* 1 = 0.62848 loss)
I0427 19:57:05.827124 13425 sgd_solver.cpp:106] Iteration 10400, lr = 5e-05
I0427 19:58:45.684608 13425 solver.cpp:228] Iteration 10500, loss = 2.57966
I0427 19:58:45.684777 13425 solver.cpp:244]     Train net output #0: loss = 0.963281 (* 1 = 0.963281 loss)
I0427 19:58:45.684787 13425 solver.cpp:244]     Train net output #1: loss = 0.80819 (* 1 = 0.80819 loss)
I0427 19:58:45.684792 13425 solver.cpp:244]     Train net output #2: loss = 0.808187 (* 1 = 0.808187 loss)
I0427 19:58:45.684798 13425 sgd_solver.cpp:106] Iteration 10500, lr = 5e-05
I0427 20:00:25.608028 13425 solver.cpp:228] Iteration 10600, loss = 2.44148
I0427 20:00:25.608203 13425 solver.cpp:244]     Train net output #0: loss = 0.957345 (* 1 = 0.957345 loss)
I0427 20:00:25.608211 13425 solver.cpp:244]     Train net output #1: loss = 0.743156 (* 1 = 0.743156 loss)
I0427 20:00:25.608217 13425 solver.cpp:244]     Train net output #2: loss = 0.740981 (* 1 = 0.740981 loss)
I0427 20:00:25.608222 13425 sgd_solver.cpp:106] Iteration 10600, lr = 5e-05
I0427 20:02:03.803982 13425 solver.cpp:228] Iteration 10700, loss = 2.58845
I0427 20:02:03.804152 13425 solver.cpp:244]     Train net output #0: loss = 0.956661 (* 1 = 0.956661 loss)
I0427 20:02:03.804159 13425 solver.cpp:244]     Train net output #1: loss = 0.769754 (* 1 = 0.769754 loss)
I0427 20:02:03.804165 13425 solver.cpp:244]     Train net output #2: loss = 0.862039 (* 1 = 0.862039 loss)
I0427 20:02:03.804172 13425 sgd_solver.cpp:106] Iteration 10700, lr = 5e-05
I0427 20:03:43.654547 13425 solver.cpp:228] Iteration 10800, loss = 2.49628
I0427 20:03:43.654721 13425 solver.cpp:244]     Train net output #0: loss = 0.980886 (* 1 = 0.980886 loss)
I0427 20:03:43.654731 13425 solver.cpp:244]     Train net output #1: loss = 0.710636 (* 1 = 0.710636 loss)
I0427 20:03:43.654736 13425 solver.cpp:244]     Train net output #2: loss = 0.804756 (* 1 = 0.804756 loss)
I0427 20:03:43.654742 13425 sgd_solver.cpp:106] Iteration 10800, lr = 5e-05
I0427 20:05:23.412655 13425 solver.cpp:228] Iteration 10900, loss = 2.37187
I0427 20:05:23.412827 13425 solver.cpp:244]     Train net output #0: loss = 0.974718 (* 1 = 0.974718 loss)
I0427 20:05:23.412837 13425 solver.cpp:244]     Train net output #1: loss = 0.659622 (* 1 = 0.659622 loss)
I0427 20:05:23.412842 13425 solver.cpp:244]     Train net output #2: loss = 0.737532 (* 1 = 0.737532 loss)
I0427 20:05:23.412847 13425 sgd_solver.cpp:106] Iteration 10900, lr = 5e-05
I0427 20:07:02.182801 13425 solver.cpp:337] Iteration 11000, Testing net (#0)
I0427 20:07:02.182962 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 20:07:02.182966 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 20:07:02.182971 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 20:07:02.182984 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 20:07:02.182988 13425 net.cpp:693] Ignoring source layer visualize
I0427 20:07:02.182992 13425 net.cpp:693] Ignoring source layer fake
I0427 20:10:36.897085 13425 solver.cpp:404]     Test net output #0: loss = 0.942605 (* 1 = 0.942605 loss)
I0427 20:10:36.897230 13425 solver.cpp:404]     Test net output #1: loss = 0.574483 (* 1 = 0.574483 loss)
I0427 20:10:36.897238 13425 solver.cpp:404]     Test net output #2: loss = 0.806044 (* 1 = 0.806044 loss)
I0427 20:10:37.552415 13425 solver.cpp:228] Iteration 11000, loss = 2.4199
I0427 20:10:37.552459 13425 solver.cpp:244]     Train net output #0: loss = 0.975787 (* 1 = 0.975787 loss)
I0427 20:10:37.552465 13425 solver.cpp:244]     Train net output #1: loss = 0.68276 (* 1 = 0.68276 loss)
I0427 20:10:37.552471 13425 solver.cpp:244]     Train net output #2: loss = 0.761348 (* 1 = 0.761348 loss)
I0427 20:10:37.552476 13425 sgd_solver.cpp:106] Iteration 11000, lr = 5e-05
I0427 20:12:15.938962 13425 solver.cpp:228] Iteration 11100, loss = 2.68535
I0427 20:12:15.939149 13425 solver.cpp:244]     Train net output #0: loss = 0.97395 (* 1 = 0.97395 loss)
I0427 20:12:15.939158 13425 solver.cpp:244]     Train net output #1: loss = 0.762674 (* 1 = 0.762674 loss)
I0427 20:12:15.939163 13425 solver.cpp:244]     Train net output #2: loss = 0.948724 (* 1 = 0.948724 loss)
I0427 20:12:15.939168 13425 sgd_solver.cpp:106] Iteration 11100, lr = 5e-05
I0427 20:13:55.695652 13425 solver.cpp:228] Iteration 11200, loss = 2.32648
I0427 20:13:55.695832 13425 solver.cpp:244]     Train net output #0: loss = 0.976587 (* 1 = 0.976587 loss)
I0427 20:13:55.695840 13425 solver.cpp:244]     Train net output #1: loss = 0.55343 (* 1 = 0.55343 loss)
I0427 20:13:55.695845 13425 solver.cpp:244]     Train net output #2: loss = 0.796462 (* 1 = 0.796462 loss)
I0427 20:13:55.695850 13425 sgd_solver.cpp:106] Iteration 11200, lr = 5e-05
I0427 20:15:35.062296 13425 solver.cpp:228] Iteration 11300, loss = 2.19437
I0427 20:15:35.062458 13425 solver.cpp:244]     Train net output #0: loss = 0.948361 (* 1 = 0.948361 loss)
I0427 20:15:35.062465 13425 solver.cpp:244]     Train net output #1: loss = 0.362523 (* 1 = 0.362523 loss)
I0427 20:15:35.062471 13425 solver.cpp:244]     Train net output #2: loss = 0.883483 (* 1 = 0.883483 loss)
I0427 20:15:35.062477 13425 sgd_solver.cpp:106] Iteration 11300, lr = 5e-05
I0427 20:17:14.459923 13425 solver.cpp:228] Iteration 11400, loss = 1.96054
I0427 20:17:14.460095 13425 solver.cpp:244]     Train net output #0: loss = 0.955622 (* 1 = 0.955622 loss)
I0427 20:17:14.460103 13425 solver.cpp:244]     Train net output #1: loss = 0.430095 (* 1 = 0.430095 loss)
I0427 20:17:14.460109 13425 solver.cpp:244]     Train net output #2: loss = 0.574821 (* 1 = 0.574821 loss)
I0427 20:17:14.460114 13425 sgd_solver.cpp:106] Iteration 11400, lr = 5e-05
I0427 20:18:54.014647 13425 solver.cpp:228] Iteration 11500, loss = 2.20296
I0427 20:18:54.014814 13425 solver.cpp:244]     Train net output #0: loss = 0.963346 (* 1 = 0.963346 loss)
I0427 20:18:54.014823 13425 solver.cpp:244]     Train net output #1: loss = 0.681122 (* 1 = 0.681122 loss)
I0427 20:18:54.014828 13425 solver.cpp:244]     Train net output #2: loss = 0.558493 (* 1 = 0.558493 loss)
I0427 20:18:54.014834 13425 sgd_solver.cpp:106] Iteration 11500, lr = 5e-05
I0427 20:20:33.784912 13425 solver.cpp:228] Iteration 11600, loss = 2.00738
I0427 20:20:33.785091 13425 solver.cpp:244]     Train net output #0: loss = 0.948644 (* 1 = 0.948644 loss)
I0427 20:20:33.785099 13425 solver.cpp:244]     Train net output #1: loss = 0.381189 (* 1 = 0.381189 loss)
I0427 20:20:33.785105 13425 solver.cpp:244]     Train net output #2: loss = 0.677551 (* 1 = 0.677551 loss)
I0427 20:20:33.785110 13425 sgd_solver.cpp:106] Iteration 11600, lr = 5e-05
I0427 20:22:13.635938 13425 solver.cpp:228] Iteration 11700, loss = 2.34997
I0427 20:22:13.636111 13425 solver.cpp:244]     Train net output #0: loss = 0.876118 (* 1 = 0.876118 loss)
I0427 20:22:13.636117 13425 solver.cpp:244]     Train net output #1: loss = 0.616191 (* 1 = 0.616191 loss)
I0427 20:22:13.636123 13425 solver.cpp:244]     Train net output #2: loss = 0.857659 (* 1 = 0.857659 loss)
I0427 20:22:13.636131 13425 sgd_solver.cpp:106] Iteration 11700, lr = 5e-05
I0427 20:23:51.832489 13425 solver.cpp:228] Iteration 11800, loss = 2.43749
I0427 20:23:51.832655 13425 solver.cpp:244]     Train net output #0: loss = 0.950031 (* 1 = 0.950031 loss)
I0427 20:23:51.832664 13425 solver.cpp:244]     Train net output #1: loss = 0.627346 (* 1 = 0.627346 loss)
I0427 20:23:51.832670 13425 solver.cpp:244]     Train net output #2: loss = 0.860113 (* 1 = 0.860113 loss)
I0427 20:23:51.832675 13425 sgd_solver.cpp:106] Iteration 11800, lr = 5e-05
I0427 20:25:31.662948 13425 solver.cpp:228] Iteration 11900, loss = 2.50543
I0427 20:25:31.663137 13425 solver.cpp:244]     Train net output #0: loss = 0.965116 (* 1 = 0.965116 loss)
I0427 20:25:31.663146 13425 solver.cpp:244]     Train net output #1: loss = 0.676332 (* 1 = 0.676332 loss)
I0427 20:25:31.663152 13425 solver.cpp:244]     Train net output #2: loss = 0.863983 (* 1 = 0.863983 loss)
I0427 20:25:31.663156 13425 sgd_solver.cpp:106] Iteration 11900, lr = 5e-05
I0427 20:27:10.500490 13425 solver.cpp:337] Iteration 12000, Testing net (#0)
I0427 20:27:10.500648 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 20:27:10.500651 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 20:27:10.500655 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 20:27:10.500669 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 20:27:10.500674 13425 net.cpp:693] Ignoring source layer visualize
I0427 20:27:10.500675 13425 net.cpp:693] Ignoring source layer fake
I0427 20:30:44.455852 13425 solver.cpp:404]     Test net output #0: loss = 0.945496 (* 1 = 0.945496 loss)
I0427 20:30:44.455991 13425 solver.cpp:404]     Test net output #1: loss = 0.585597 (* 1 = 0.585597 loss)
I0427 20:30:44.455998 13425 solver.cpp:404]     Test net output #2: loss = 0.811152 (* 1 = 0.811152 loss)
I0427 20:30:45.109248 13425 solver.cpp:228] Iteration 12000, loss = 2.45931
I0427 20:30:45.109292 13425 solver.cpp:244]     Train net output #0: loss = 0.969613 (* 1 = 0.969613 loss)
I0427 20:30:45.109297 13425 solver.cpp:244]     Train net output #1: loss = 0.769047 (* 1 = 0.769047 loss)
I0427 20:30:45.109302 13425 solver.cpp:244]     Train net output #2: loss = 0.720647 (* 1 = 0.720647 loss)
I0427 20:30:45.109308 13425 sgd_solver.cpp:106] Iteration 12000, lr = 5e-05
I0427 20:32:23.348333 13425 solver.cpp:228] Iteration 12100, loss = 2.66431
I0427 20:32:23.348520 13425 solver.cpp:244]     Train net output #0: loss = 0.984912 (* 1 = 0.984912 loss)
I0427 20:32:23.348528 13425 solver.cpp:244]     Train net output #1: loss = 0.76723 (* 1 = 0.76723 loss)
I0427 20:32:23.348533 13425 solver.cpp:244]     Train net output #2: loss = 0.912173 (* 1 = 0.912173 loss)
I0427 20:32:23.348539 13425 sgd_solver.cpp:106] Iteration 12100, lr = 5e-05
I0427 20:34:03.147114 13425 solver.cpp:228] Iteration 12200, loss = 2.4132
I0427 20:34:03.147291 13425 solver.cpp:244]     Train net output #0: loss = 0.965631 (* 1 = 0.965631 loss)
I0427 20:34:03.147300 13425 solver.cpp:244]     Train net output #1: loss = 0.616466 (* 1 = 0.616466 loss)
I0427 20:34:03.147305 13425 solver.cpp:244]     Train net output #2: loss = 0.831104 (* 1 = 0.831104 loss)
I0427 20:34:03.147311 13425 sgd_solver.cpp:106] Iteration 12200, lr = 5e-05
I0427 20:35:42.954386 13425 solver.cpp:228] Iteration 12300, loss = 2.33483
I0427 20:35:42.954548 13425 solver.cpp:244]     Train net output #0: loss = 0.976927 (* 1 = 0.976927 loss)
I0427 20:35:42.954556 13425 solver.cpp:244]     Train net output #1: loss = 0.547269 (* 1 = 0.547269 loss)
I0427 20:35:42.954561 13425 solver.cpp:244]     Train net output #2: loss = 0.810633 (* 1 = 0.810633 loss)
I0427 20:35:42.954568 13425 sgd_solver.cpp:106] Iteration 12300, lr = 5e-05
I0427 20:37:22.605345 13425 solver.cpp:228] Iteration 12400, loss = 2.38098
I0427 20:37:22.605510 13425 solver.cpp:244]     Train net output #0: loss = 0.968517 (* 1 = 0.968517 loss)
I0427 20:37:22.605518 13425 solver.cpp:244]     Train net output #1: loss = 0.507174 (* 1 = 0.507174 loss)
I0427 20:37:22.605525 13425 solver.cpp:244]     Train net output #2: loss = 0.90529 (* 1 = 0.90529 loss)
I0427 20:37:22.605530 13425 sgd_solver.cpp:106] Iteration 12400, lr = 5e-05
I0427 20:39:01.922693 13425 solver.cpp:228] Iteration 12500, loss = 2.03149
I0427 20:39:01.922853 13425 solver.cpp:244]     Train net output #0: loss = 0.934224 (* 1 = 0.934224 loss)
I0427 20:39:01.922863 13425 solver.cpp:244]     Train net output #1: loss = 0.240579 (* 1 = 0.240579 loss)
I0427 20:39:01.922868 13425 solver.cpp:244]     Train net output #2: loss = 0.856686 (* 1 = 0.856686 loss)
I0427 20:39:01.922873 13425 sgd_solver.cpp:106] Iteration 12500, lr = 5e-05
I0427 20:40:41.316195 13425 solver.cpp:228] Iteration 12600, loss = 1.91017
I0427 20:40:41.316390 13425 solver.cpp:244]     Train net output #0: loss = 0.924907 (* 1 = 0.924907 loss)
I0427 20:40:41.316400 13425 solver.cpp:244]     Train net output #1: loss = 0.405593 (* 1 = 0.405593 loss)
I0427 20:40:41.316404 13425 solver.cpp:244]     Train net output #2: loss = 0.579674 (* 1 = 0.579674 loss)
I0427 20:40:41.316411 13425 sgd_solver.cpp:106] Iteration 12600, lr = 5e-05
I0427 20:42:19.503346 13425 solver.cpp:228] Iteration 12700, loss = 2.41422
I0427 20:42:19.503520 13425 solver.cpp:244]     Train net output #0: loss = 0.943222 (* 1 = 0.943222 loss)
I0427 20:42:19.503527 13425 solver.cpp:244]     Train net output #1: loss = 0.515619 (* 1 = 0.515619 loss)
I0427 20:42:19.503532 13425 solver.cpp:244]     Train net output #2: loss = 0.95538 (* 1 = 0.95538 loss)
I0427 20:42:19.503538 13425 sgd_solver.cpp:106] Iteration 12700, lr = 5e-05
I0427 20:43:59.072127 13425 solver.cpp:228] Iteration 12800, loss = 2.2132
I0427 20:43:59.072309 13425 solver.cpp:244]     Train net output #0: loss = 0.966813 (* 1 = 0.966813 loss)
I0427 20:43:59.072317 13425 solver.cpp:244]     Train net output #1: loss = 0.671964 (* 1 = 0.671964 loss)
I0427 20:43:59.072324 13425 solver.cpp:244]     Train net output #2: loss = 0.574428 (* 1 = 0.574428 loss)
I0427 20:43:59.072329 13425 sgd_solver.cpp:106] Iteration 12800, lr = 5e-05
I0427 20:45:38.771581 13425 solver.cpp:228] Iteration 12900, loss = 1.63467
I0427 20:45:38.771731 13425 solver.cpp:244]     Train net output #0: loss = 0.96132 (* 1 = 0.96132 loss)
I0427 20:45:38.771740 13425 solver.cpp:244]     Train net output #1: loss = 0.131052 (* 1 = 0.131052 loss)
I0427 20:45:38.771745 13425 solver.cpp:244]     Train net output #2: loss = 0.542296 (* 1 = 0.542296 loss)
I0427 20:45:38.771750 13425 sgd_solver.cpp:106] Iteration 12900, lr = 5e-05
I0427 20:47:17.682173 13425 solver.cpp:337] Iteration 13000, Testing net (#0)
I0427 20:47:17.682345 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 20:47:17.682349 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 20:47:17.682353 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 20:47:17.682368 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 20:47:17.682371 13425 net.cpp:693] Ignoring source layer visualize
I0427 20:47:17.682373 13425 net.cpp:693] Ignoring source layer fake
I0427 20:50:51.527503 13425 solver.cpp:404]     Test net output #0: loss = 0.931717 (* 1 = 0.931717 loss)
I0427 20:50:51.527636 13425 solver.cpp:404]     Test net output #1: loss = 0.585289 (* 1 = 0.585289 loss)
I0427 20:50:51.527643 13425 solver.cpp:404]     Test net output #2: loss = 0.816103 (* 1 = 0.816103 loss)
I0427 20:50:52.176125 13425 solver.cpp:228] Iteration 13000, loss = 2.44796
I0427 20:50:52.176167 13425 solver.cpp:244]     Train net output #0: loss = 0.955553 (* 1 = 0.955553 loss)
I0427 20:50:52.176173 13425 solver.cpp:244]     Train net output #1: loss = 0.683808 (* 1 = 0.683808 loss)
I0427 20:50:52.176179 13425 solver.cpp:244]     Train net output #2: loss = 0.808601 (* 1 = 0.808601 loss)
I0427 20:50:52.176184 13425 sgd_solver.cpp:106] Iteration 13000, lr = 5e-05
I0427 20:52:32.084714 13425 solver.cpp:228] Iteration 13100, loss = 2.39419
I0427 20:52:32.084880 13425 solver.cpp:244]     Train net output #0: loss = 0.95713 (* 1 = 0.95713 loss)
I0427 20:52:32.084889 13425 solver.cpp:244]     Train net output #1: loss = 0.5562 (* 1 = 0.5562 loss)
I0427 20:52:32.084895 13425 solver.cpp:244]     Train net output #2: loss = 0.880858 (* 1 = 0.880858 loss)
I0427 20:52:32.084900 13425 sgd_solver.cpp:106] Iteration 13100, lr = 5e-05
I0427 20:54:10.274464 13425 solver.cpp:228] Iteration 13200, loss = 2.50368
I0427 20:54:10.274648 13425 solver.cpp:244]     Train net output #0: loss = 0.943248 (* 1 = 0.943248 loss)
I0427 20:54:10.274657 13425 solver.cpp:244]     Train net output #1: loss = 0.672022 (* 1 = 0.672022 loss)
I0427 20:54:10.274662 13425 solver.cpp:244]     Train net output #2: loss = 0.888409 (* 1 = 0.888409 loss)
I0427 20:54:10.274667 13425 sgd_solver.cpp:106] Iteration 13200, lr = 5e-05
I0427 20:55:50.109998 13425 solver.cpp:228] Iteration 13300, loss = 2.24078
I0427 20:55:50.110188 13425 solver.cpp:244]     Train net output #0: loss = 0.973392 (* 1 = 0.973392 loss)
I0427 20:55:50.110196 13425 solver.cpp:244]     Train net output #1: loss = 0.612776 (* 1 = 0.612776 loss)
I0427 20:55:50.110201 13425 solver.cpp:244]     Train net output #2: loss = 0.654614 (* 1 = 0.654614 loss)
I0427 20:55:50.110208 13425 sgd_solver.cpp:106] Iteration 13300, lr = 5e-05
I0427 20:57:29.898313 13425 solver.cpp:228] Iteration 13400, loss = 2.43565
I0427 20:57:29.898490 13425 solver.cpp:244]     Train net output #0: loss = 0.979472 (* 1 = 0.979472 loss)
I0427 20:57:29.898499 13425 solver.cpp:244]     Train net output #1: loss = 0.746854 (* 1 = 0.746854 loss)
I0427 20:57:29.898505 13425 solver.cpp:244]     Train net output #2: loss = 0.709324 (* 1 = 0.709324 loss)
I0427 20:57:29.898519 13425 sgd_solver.cpp:106] Iteration 13400, lr = 5e-05
I0427 20:59:09.692149 13425 solver.cpp:228] Iteration 13500, loss = 2.49848
I0427 20:59:09.692329 13425 solver.cpp:244]     Train net output #0: loss = 0.96916 (* 1 = 0.96916 loss)
I0427 20:59:09.692339 13425 solver.cpp:244]     Train net output #1: loss = 0.609273 (* 1 = 0.609273 loss)
I0427 20:59:09.692344 13425 solver.cpp:244]     Train net output #2: loss = 0.920049 (* 1 = 0.920049 loss)
I0427 20:59:09.692350 13425 sgd_solver.cpp:106] Iteration 13500, lr = 5e-05
I0427 21:00:47.805511 13425 solver.cpp:228] Iteration 13600, loss = 2.47622
I0427 21:00:47.805671 13425 solver.cpp:244]     Train net output #0: loss = 0.969568 (* 1 = 0.969568 loss)
I0427 21:00:47.805680 13425 solver.cpp:244]     Train net output #1: loss = 0.62736 (* 1 = 0.62736 loss)
I0427 21:00:47.805685 13425 solver.cpp:244]     Train net output #2: loss = 0.879296 (* 1 = 0.879296 loss)
I0427 21:00:47.805691 13425 sgd_solver.cpp:106] Iteration 13600, lr = 5e-05
I0427 21:02:27.429734 13425 solver.cpp:228] Iteration 13700, loss = 2.39062
I0427 21:02:27.429903 13425 solver.cpp:244]     Train net output #0: loss = 0.9538 (* 1 = 0.9538 loss)
I0427 21:02:27.429910 13425 solver.cpp:244]     Train net output #1: loss = 0.597039 (* 1 = 0.597039 loss)
I0427 21:02:27.429915 13425 solver.cpp:244]     Train net output #2: loss = 0.839783 (* 1 = 0.839783 loss)
I0427 21:02:27.429921 13425 sgd_solver.cpp:106] Iteration 13700, lr = 5e-05
I0427 21:04:06.725584 13425 solver.cpp:228] Iteration 13800, loss = 2.20334
I0427 21:04:06.725751 13425 solver.cpp:244]     Train net output #0: loss = 0.957025 (* 1 = 0.957025 loss)
I0427 21:04:06.725759 13425 solver.cpp:244]     Train net output #1: loss = 0.35724 (* 1 = 0.35724 loss)
I0427 21:04:06.725765 13425 solver.cpp:244]     Train net output #2: loss = 0.88907 (* 1 = 0.88907 loss)
I0427 21:04:06.725770 13425 sgd_solver.cpp:106] Iteration 13800, lr = 5e-05
I0427 21:05:46.084967 13425 solver.cpp:228] Iteration 13900, loss = 2.19992
I0427 21:05:46.085135 13425 solver.cpp:244]     Train net output #0: loss = 0.960473 (* 1 = 0.960473 loss)
I0427 21:05:46.085144 13425 solver.cpp:244]     Train net output #1: loss = 0.597361 (* 1 = 0.597361 loss)
I0427 21:05:46.085150 13425 solver.cpp:244]     Train net output #2: loss = 0.642082 (* 1 = 0.642082 loss)
I0427 21:05:46.085155 13425 sgd_solver.cpp:106] Iteration 13900, lr = 5e-05
I0427 21:07:24.662489 13425 solver.cpp:337] Iteration 14000, Testing net (#0)
I0427 21:07:24.662619 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 21:07:24.662623 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 21:07:24.662627 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 21:07:24.662642 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 21:07:24.662645 13425 net.cpp:693] Ignoring source layer visualize
I0427 21:07:24.662648 13425 net.cpp:693] Ignoring source layer fake
I0427 21:10:58.399926 13425 solver.cpp:404]     Test net output #0: loss = 0.916981 (* 1 = 0.916981 loss)
I0427 21:10:58.400111 13425 solver.cpp:404]     Test net output #1: loss = 0.565213 (* 1 = 0.565213 loss)
I0427 21:10:58.400120 13425 solver.cpp:404]     Test net output #2: loss = 0.798521 (* 1 = 0.798521 loss)
I0427 21:10:59.053752 13425 solver.cpp:228] Iteration 14000, loss = 2.35422
I0427 21:10:59.053824 13425 solver.cpp:244]     Train net output #0: loss = 0.965888 (* 1 = 0.965888 loss)
I0427 21:10:59.053830 13425 solver.cpp:244]     Train net output #1: loss = 0.635687 (* 1 = 0.635687 loss)
I0427 21:10:59.053835 13425 solver.cpp:244]     Train net output #2: loss = 0.752647 (* 1 = 0.752647 loss)
I0427 21:10:59.053841 13425 sgd_solver.cpp:106] Iteration 14000, lr = 5e-05
I0427 21:12:38.886304 13425 solver.cpp:228] Iteration 14100, loss = 1.73115
I0427 21:12:38.886476 13425 solver.cpp:244]     Train net output #0: loss = 0.956423 (* 1 = 0.956423 loss)
I0427 21:12:38.886484 13425 solver.cpp:244]     Train net output #1: loss = 0.242665 (* 1 = 0.242665 loss)
I0427 21:12:38.886489 13425 solver.cpp:244]     Train net output #2: loss = 0.532062 (* 1 = 0.532062 loss)
I0427 21:12:38.886495 13425 sgd_solver.cpp:106] Iteration 14100, lr = 5e-05
I0427 21:14:18.692451 13425 solver.cpp:228] Iteration 14200, loss = 2.36602
I0427 21:14:18.692634 13425 solver.cpp:244]     Train net output #0: loss = 0.873741 (* 1 = 0.873741 loss)
I0427 21:14:18.692642 13425 solver.cpp:244]     Train net output #1: loss = 0.620416 (* 1 = 0.620416 loss)
I0427 21:14:18.692648 13425 solver.cpp:244]     Train net output #2: loss = 0.871866 (* 1 = 0.871866 loss)
I0427 21:14:18.692653 13425 sgd_solver.cpp:106] Iteration 14200, lr = 5e-05
I0427 21:15:56.877357 13425 solver.cpp:228] Iteration 14300, loss = 2.52232
I0427 21:15:56.877499 13425 solver.cpp:244]     Train net output #0: loss = 0.940107 (* 1 = 0.940107 loss)
I0427 21:15:56.877507 13425 solver.cpp:244]     Train net output #1: loss = 0.685466 (* 1 = 0.685466 loss)
I0427 21:15:56.877512 13425 solver.cpp:244]     Train net output #2: loss = 0.896742 (* 1 = 0.896742 loss)
I0427 21:15:56.877518 13425 sgd_solver.cpp:106] Iteration 14300, lr = 5e-05
I0427 21:17:36.733052 13425 solver.cpp:228] Iteration 14400, loss = 2.60039
I0427 21:17:36.733242 13425 solver.cpp:244]     Train net output #0: loss = 0.958307 (* 1 = 0.958307 loss)
I0427 21:17:36.733249 13425 solver.cpp:244]     Train net output #1: loss = 0.760531 (* 1 = 0.760531 loss)
I0427 21:17:36.733255 13425 solver.cpp:244]     Train net output #2: loss = 0.881555 (* 1 = 0.881555 loss)
I0427 21:17:36.733261 13425 sgd_solver.cpp:106] Iteration 14400, lr = 5e-05
I0427 21:19:16.532248 13425 solver.cpp:228] Iteration 14500, loss = 2.09548
I0427 21:19:16.532419 13425 solver.cpp:244]     Train net output #0: loss = 0.972441 (* 1 = 0.972441 loss)
I0427 21:19:16.532428 13425 solver.cpp:244]     Train net output #1: loss = 0.647888 (* 1 = 0.647888 loss)
I0427 21:19:16.532433 13425 solver.cpp:244]     Train net output #2: loss = 0.475152 (* 1 = 0.475152 loss)
I0427 21:19:16.532439 13425 sgd_solver.cpp:106] Iteration 14500, lr = 5e-05
I0427 21:20:54.754729 13425 solver.cpp:228] Iteration 14600, loss = 2.48201
I0427 21:20:54.754892 13425 solver.cpp:244]     Train net output #0: loss = 0.985005 (* 1 = 0.985005 loss)
I0427 21:20:54.754900 13425 solver.cpp:244]     Train net output #1: loss = 0.674421 (* 1 = 0.674421 loss)
I0427 21:20:54.754905 13425 solver.cpp:244]     Train net output #2: loss = 0.822581 (* 1 = 0.822581 loss)
I0427 21:20:54.754911 13425 sgd_solver.cpp:106] Iteration 14600, lr = 5e-05
I0427 21:22:34.528616 13425 solver.cpp:228] Iteration 14700, loss = 2.37872
I0427 21:22:34.528755 13425 solver.cpp:244]     Train net output #0: loss = 0.983746 (* 1 = 0.983746 loss)
I0427 21:22:34.528764 13425 solver.cpp:244]     Train net output #1: loss = 0.644737 (* 1 = 0.644737 loss)
I0427 21:22:34.528769 13425 solver.cpp:244]     Train net output #2: loss = 0.750235 (* 1 = 0.750235 loss)
I0427 21:22:34.528775 13425 sgd_solver.cpp:106] Iteration 14700, lr = 5e-05
I0427 21:24:14.251879 13425 solver.cpp:228] Iteration 14800, loss = 2.49018
I0427 21:24:14.252025 13425 solver.cpp:244]     Train net output #0: loss = 0.982271 (* 1 = 0.982271 loss)
I0427 21:24:14.252033 13425 solver.cpp:244]     Train net output #1: loss = 0.703826 (* 1 = 0.703826 loss)
I0427 21:24:14.252039 13425 solver.cpp:244]     Train net output #2: loss = 0.804081 (* 1 = 0.804081 loss)
I0427 21:24:14.252045 13425 sgd_solver.cpp:106] Iteration 14800, lr = 5e-05
I0427 21:25:53.899834 13425 solver.cpp:228] Iteration 14900, loss = 2.31281
I0427 21:25:53.900051 13425 solver.cpp:244]     Train net output #0: loss = 0.980296 (* 1 = 0.980296 loss)
I0427 21:25:53.900060 13425 solver.cpp:244]     Train net output #1: loss = 0.536274 (* 1 = 0.536274 loss)
I0427 21:25:53.900077 13425 solver.cpp:244]     Train net output #2: loss = 0.796245 (* 1 = 0.796245 loss)
I0427 21:25:53.900082 13425 sgd_solver.cpp:106] Iteration 14900, lr = 5e-05
I0427 21:27:32.117327 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_15000.caffemodel
I0427 21:27:32.824563 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_15000.solverstate
I0427 21:27:33.014084 13425 solver.cpp:337] Iteration 15000, Testing net (#0)
I0427 21:27:33.014125 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 21:27:33.014127 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 21:27:33.014132 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 21:27:33.014144 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 21:27:33.014147 13425 net.cpp:693] Ignoring source layer visualize
I0427 21:27:33.014148 13425 net.cpp:693] Ignoring source layer fake
I0427 21:31:06.475414 13425 solver.cpp:404]     Test net output #0: loss = 0.947771 (* 1 = 0.947771 loss)
I0427 21:31:06.475577 13425 solver.cpp:404]     Test net output #1: loss = 0.573924 (* 1 = 0.573924 loss)
I0427 21:31:06.475584 13425 solver.cpp:404]     Test net output #2: loss = 0.781042 (* 1 = 0.781042 loss)
I0427 21:31:07.127188 13425 solver.cpp:228] Iteration 15000, loss = 2.17504
I0427 21:31:07.127230 13425 solver.cpp:244]     Train net output #0: loss = 0.91688 (* 1 = 0.91688 loss)
I0427 21:31:07.127236 13425 solver.cpp:244]     Train net output #1: loss = 0.36255 (* 1 = 0.36255 loss)
I0427 21:31:07.127240 13425 solver.cpp:244]     Train net output #2: loss = 0.895608 (* 1 = 0.895608 loss)
I0427 21:31:07.127245 13425 sgd_solver.cpp:106] Iteration 15000, lr = 5e-05
I0427 21:32:46.478837 13425 solver.cpp:228] Iteration 15100, loss = 2.30387
I0427 21:32:46.479003 13425 solver.cpp:244]     Train net output #0: loss = 0.966493 (* 1 = 0.966493 loss)
I0427 21:32:46.479012 13425 solver.cpp:244]     Train net output #1: loss = 0.579684 (* 1 = 0.579684 loss)
I0427 21:32:46.479017 13425 solver.cpp:244]     Train net output #2: loss = 0.757694 (* 1 = 0.757694 loss)
I0427 21:32:46.479022 13425 sgd_solver.cpp:106] Iteration 15100, lr = 5e-05
I0427 21:34:24.597043 13425 solver.cpp:228] Iteration 15200, loss = 2.43925
I0427 21:34:24.597192 13425 solver.cpp:244]     Train net output #0: loss = 0.968283 (* 1 = 0.968283 loss)
I0427 21:34:24.597198 13425 solver.cpp:244]     Train net output #1: loss = 0.715513 (* 1 = 0.715513 loss)
I0427 21:34:24.597204 13425 solver.cpp:244]     Train net output #2: loss = 0.755452 (* 1 = 0.755452 loss)
I0427 21:34:24.597210 13425 sgd_solver.cpp:106] Iteration 15200, lr = 5e-05
I0427 21:36:04.146042 13425 solver.cpp:228] Iteration 15300, loss = 2.33793
I0427 21:36:04.146209 13425 solver.cpp:244]     Train net output #0: loss = 0.974934 (* 1 = 0.974934 loss)
I0427 21:36:04.146219 13425 solver.cpp:244]     Train net output #1: loss = 0.598215 (* 1 = 0.598215 loss)
I0427 21:36:04.146224 13425 solver.cpp:244]     Train net output #2: loss = 0.764778 (* 1 = 0.764778 loss)
I0427 21:36:04.146229 13425 sgd_solver.cpp:106] Iteration 15300, lr = 5e-05
I0427 21:37:43.900076 13425 solver.cpp:228] Iteration 15400, loss = 1.38981
I0427 21:37:43.900249 13425 solver.cpp:244]     Train net output #0: loss = 0.97669 (* 1 = 0.97669 loss)
I0427 21:37:43.900257 13425 solver.cpp:244]     Train net output #1: loss = 0.0749374 (* 1 = 0.0749374 loss)
I0427 21:37:43.900262 13425 solver.cpp:244]     Train net output #2: loss = 0.338184 (* 1 = 0.338184 loss)
I0427 21:37:43.900267 13425 sgd_solver.cpp:106] Iteration 15400, lr = 5e-05
I0427 21:39:23.796043 13425 solver.cpp:228] Iteration 15500, loss = 2.29045
I0427 21:39:23.796247 13425 solver.cpp:244]     Train net output #0: loss = 0.887456 (* 1 = 0.887456 loss)
I0427 21:39:23.796257 13425 solver.cpp:244]     Train net output #1: loss = 0.57671 (* 1 = 0.57671 loss)
I0427 21:39:23.796262 13425 solver.cpp:244]     Train net output #2: loss = 0.826279 (* 1 = 0.826279 loss)
I0427 21:39:23.796267 13425 sgd_solver.cpp:106] Iteration 15500, lr = 5e-05
I0427 21:41:03.634541 13425 solver.cpp:228] Iteration 15600, loss = 2.40753
I0427 21:41:03.634708 13425 solver.cpp:244]     Train net output #0: loss = 0.970631 (* 1 = 0.970631 loss)
I0427 21:41:03.634716 13425 solver.cpp:244]     Train net output #1: loss = 0.534568 (* 1 = 0.534568 loss)
I0427 21:41:03.634723 13425 solver.cpp:244]     Train net output #2: loss = 0.902331 (* 1 = 0.902331 loss)
I0427 21:41:03.634729 13425 sgd_solver.cpp:106] Iteration 15600, lr = 5e-05
I0427 21:42:41.788370 13425 solver.cpp:228] Iteration 15700, loss = 2.56853
I0427 21:42:41.788559 13425 solver.cpp:244]     Train net output #0: loss = 0.927444 (* 1 = 0.927444 loss)
I0427 21:42:41.788568 13425 solver.cpp:244]     Train net output #1: loss = 0.703822 (* 1 = 0.703822 loss)
I0427 21:42:41.788573 13425 solver.cpp:244]     Train net output #2: loss = 0.937266 (* 1 = 0.937266 loss)
I0427 21:42:41.788579 13425 sgd_solver.cpp:106] Iteration 15700, lr = 5e-05
I0427 21:44:21.592628 13425 solver.cpp:228] Iteration 15800, loss = 2.24113
I0427 21:44:21.592813 13425 solver.cpp:244]     Train net output #0: loss = 0.969005 (* 1 = 0.969005 loss)
I0427 21:44:21.592820 13425 solver.cpp:244]     Train net output #1: loss = 0.58064 (* 1 = 0.58064 loss)
I0427 21:44:21.592826 13425 solver.cpp:244]     Train net output #2: loss = 0.691481 (* 1 = 0.691481 loss)
I0427 21:44:21.592831 13425 sgd_solver.cpp:106] Iteration 15800, lr = 5e-05
I0427 21:46:01.348330 13425 solver.cpp:228] Iteration 15900, loss = 2.52029
I0427 21:46:01.348498 13425 solver.cpp:244]     Train net output #0: loss = 0.991996 (* 1 = 0.991996 loss)
I0427 21:46:01.348506 13425 solver.cpp:244]     Train net output #1: loss = 0.793965 (* 1 = 0.793965 loss)
I0427 21:46:01.348511 13425 solver.cpp:244]     Train net output #2: loss = 0.734332 (* 1 = 0.734332 loss)
I0427 21:46:01.348517 13425 sgd_solver.cpp:106] Iteration 15900, lr = 5e-05
I0427 21:47:40.135031 13425 solver.cpp:337] Iteration 16000, Testing net (#0)
I0427 21:47:40.135195 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 21:47:40.135200 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 21:47:40.135203 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 21:47:40.135228 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 21:47:40.135233 13425 net.cpp:693] Ignoring source layer visualize
I0427 21:47:40.135236 13425 net.cpp:693] Ignoring source layer fake
I0427 21:51:13.353662 13425 solver.cpp:404]     Test net output #0: loss = 0.94335 (* 1 = 0.94335 loss)
I0427 21:51:13.353826 13425 solver.cpp:404]     Test net output #1: loss = 0.59402 (* 1 = 0.59402 loss)
I0427 21:51:13.353833 13425 solver.cpp:404]     Test net output #2: loss = 0.814045 (* 1 = 0.814045 loss)
I0427 21:51:14.002005 13425 solver.cpp:228] Iteration 16000, loss = 2.41824
I0427 21:51:14.002063 13425 solver.cpp:244]     Train net output #0: loss = 0.971591 (* 1 = 0.971591 loss)
I0427 21:51:14.002068 13425 solver.cpp:244]     Train net output #1: loss = 0.528524 (* 1 = 0.528524 loss)
I0427 21:51:14.002074 13425 solver.cpp:244]     Train net output #2: loss = 0.918126 (* 1 = 0.918126 loss)
I0427 21:51:14.002094 13425 sgd_solver.cpp:106] Iteration 16000, lr = 5e-05
I0427 21:52:52.176741 13425 solver.cpp:228] Iteration 16100, loss = 2.27008
I0427 21:52:52.176909 13425 solver.cpp:244]     Train net output #0: loss = 0.97506 (* 1 = 0.97506 loss)
I0427 21:52:52.176918 13425 solver.cpp:244]     Train net output #1: loss = 0.550676 (* 1 = 0.550676 loss)
I0427 21:52:52.176923 13425 solver.cpp:244]     Train net output #2: loss = 0.744341 (* 1 = 0.744341 loss)
I0427 21:52:52.176929 13425 sgd_solver.cpp:106] Iteration 16100, lr = 5e-05
I0427 21:54:31.794765 13425 solver.cpp:228] Iteration 16200, loss = 2.30855
I0427 21:54:31.794956 13425 solver.cpp:244]     Train net output #0: loss = 0.916983 (* 1 = 0.916983 loss)
I0427 21:54:31.794965 13425 solver.cpp:244]     Train net output #1: loss = 0.548233 (* 1 = 0.548233 loss)
I0427 21:54:31.794971 13425 solver.cpp:244]     Train net output #2: loss = 0.843337 (* 1 = 0.843337 loss)
I0427 21:54:31.794977 13425 sgd_solver.cpp:106] Iteration 16200, lr = 5e-05
I0427 21:56:11.024783 13425 solver.cpp:228] Iteration 16300, loss = 2.20115
I0427 21:56:11.024940 13425 solver.cpp:244]     Train net output #0: loss = 0.954957 (* 1 = 0.954957 loss)
I0427 21:56:11.024950 13425 solver.cpp:244]     Train net output #1: loss = 0.343218 (* 1 = 0.343218 loss)
I0427 21:56:11.024955 13425 solver.cpp:244]     Train net output #2: loss = 0.902974 (* 1 = 0.902974 loss)
I0427 21:56:11.024960 13425 sgd_solver.cpp:106] Iteration 16300, lr = 5e-05
I0427 21:57:50.366598 13425 solver.cpp:228] Iteration 16400, loss = 2.58705
I0427 21:57:50.366777 13425 solver.cpp:244]     Train net output #0: loss = 0.929273 (* 1 = 0.929273 loss)
I0427 21:57:50.366785 13425 solver.cpp:244]     Train net output #1: loss = 0.700737 (* 1 = 0.700737 loss)
I0427 21:57:50.366791 13425 solver.cpp:244]     Train net output #2: loss = 0.957041 (* 1 = 0.957041 loss)
I0427 21:57:50.366796 13425 sgd_solver.cpp:106] Iteration 16400, lr = 5e-05
I0427 21:59:29.950170 13425 solver.cpp:228] Iteration 16500, loss = 2.16467
I0427 21:59:29.950332 13425 solver.cpp:244]     Train net output #0: loss = 0.962081 (* 1 = 0.962081 loss)
I0427 21:59:29.950340 13425 solver.cpp:244]     Train net output #1: loss = 0.624995 (* 1 = 0.624995 loss)
I0427 21:59:29.950346 13425 solver.cpp:244]     Train net output #2: loss = 0.577598 (* 1 = 0.577598 loss)
I0427 21:59:29.950352 13425 sgd_solver.cpp:106] Iteration 16500, lr = 5e-05
I0427 22:01:09.728641 13425 solver.cpp:228] Iteration 16600, loss = 1.66302
I0427 22:01:09.728814 13425 solver.cpp:244]     Train net output #0: loss = 0.972376 (* 1 = 0.972376 loss)
I0427 22:01:09.728822 13425 solver.cpp:244]     Train net output #1: loss = 0.146988 (* 1 = 0.146988 loss)
I0427 22:01:09.728828 13425 solver.cpp:244]     Train net output #2: loss = 0.543658 (* 1 = 0.543658 loss)
I0427 22:01:09.728833 13425 sgd_solver.cpp:106] Iteration 16600, lr = 5e-05
I0427 22:02:49.532701 13425 solver.cpp:228] Iteration 16700, loss = 2.42825
I0427 22:02:49.533915 13425 solver.cpp:244]     Train net output #0: loss = 0.936588 (* 1 = 0.936588 loss)
I0427 22:02:49.533923 13425 solver.cpp:244]     Train net output #1: loss = 0.710557 (* 1 = 0.710557 loss)
I0427 22:02:49.533928 13425 solver.cpp:244]     Train net output #2: loss = 0.781101 (* 1 = 0.781101 loss)
I0427 22:02:49.533933 13425 sgd_solver.cpp:106] Iteration 16700, lr = 5e-05
I0427 22:04:27.744432 13425 solver.cpp:228] Iteration 16800, loss = 2.56654
I0427 22:04:27.744621 13425 solver.cpp:244]     Train net output #0: loss = 0.935685 (* 1 = 0.935685 loss)
I0427 22:04:27.744629 13425 solver.cpp:244]     Train net output #1: loss = 0.692265 (* 1 = 0.692265 loss)
I0427 22:04:27.744634 13425 solver.cpp:244]     Train net output #2: loss = 0.938589 (* 1 = 0.938589 loss)
I0427 22:04:27.744640 13425 sgd_solver.cpp:106] Iteration 16800, lr = 5e-05
I0427 22:06:07.526849 13425 solver.cpp:228] Iteration 16900, loss = 2.51333
I0427 22:06:07.527036 13425 solver.cpp:244]     Train net output #0: loss = 0.946489 (* 1 = 0.946489 loss)
I0427 22:06:07.527045 13425 solver.cpp:244]     Train net output #1: loss = 0.738002 (* 1 = 0.738002 loss)
I0427 22:06:07.527050 13425 solver.cpp:244]     Train net output #2: loss = 0.828838 (* 1 = 0.828838 loss)
I0427 22:06:07.527056 13425 sgd_solver.cpp:106] Iteration 16900, lr = 5e-05
I0427 22:07:46.324710 13425 solver.cpp:337] Iteration 17000, Testing net (#0)
I0427 22:07:46.324903 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 22:07:46.324908 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 22:07:46.324913 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 22:07:46.324926 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 22:07:46.324929 13425 net.cpp:693] Ignoring source layer visualize
I0427 22:07:46.324931 13425 net.cpp:693] Ignoring source layer fake
I0427 22:11:20.265835 13425 solver.cpp:404]     Test net output #0: loss = 0.948036 (* 1 = 0.948036 loss)
I0427 22:11:20.265988 13425 solver.cpp:404]     Test net output #1: loss = 0.605037 (* 1 = 0.605037 loss)
I0427 22:11:20.265995 13425 solver.cpp:404]     Test net output #2: loss = 0.816254 (* 1 = 0.816254 loss)
I0427 22:11:20.923189 13425 solver.cpp:228] Iteration 17000, loss = 2.15897
I0427 22:11:20.923233 13425 solver.cpp:244]     Train net output #0: loss = 0.970949 (* 1 = 0.970949 loss)
I0427 22:11:20.923240 13425 solver.cpp:244]     Train net output #1: loss = 0.548619 (* 1 = 0.548619 loss)
I0427 22:11:20.923244 13425 solver.cpp:244]     Train net output #2: loss = 0.639401 (* 1 = 0.639401 loss)
I0427 22:11:20.923250 13425 sgd_solver.cpp:106] Iteration 17000, lr = 5e-05
I0427 22:12:59.143950 13425 solver.cpp:228] Iteration 17100, loss = 2.37707
I0427 22:12:59.144120 13425 solver.cpp:244]     Train net output #0: loss = 0.977075 (* 1 = 0.977075 loss)
I0427 22:12:59.144129 13425 solver.cpp:244]     Train net output #1: loss = 0.584019 (* 1 = 0.584019 loss)
I0427 22:12:59.144134 13425 solver.cpp:244]     Train net output #2: loss = 0.815973 (* 1 = 0.815973 loss)
I0427 22:12:59.144140 13425 sgd_solver.cpp:106] Iteration 17100, lr = 5e-05
I0427 22:14:38.905012 13425 solver.cpp:228] Iteration 17200, loss = 2.40713
I0427 22:14:38.905177 13425 solver.cpp:244]     Train net output #0: loss = 0.978843 (* 1 = 0.978843 loss)
I0427 22:14:38.905185 13425 solver.cpp:244]     Train net output #1: loss = 0.670547 (* 1 = 0.670547 loss)
I0427 22:14:38.905191 13425 solver.cpp:244]     Train net output #2: loss = 0.757736 (* 1 = 0.757736 loss)
I0427 22:14:38.905196 13425 sgd_solver.cpp:106] Iteration 17200, lr = 5e-05
I0427 22:16:18.648435 13425 solver.cpp:228] Iteration 17300, loss = 2.48249
I0427 22:16:18.648602 13425 solver.cpp:244]     Train net output #0: loss = 0.984297 (* 1 = 0.984297 loss)
I0427 22:16:18.648612 13425 solver.cpp:244]     Train net output #1: loss = 0.692669 (* 1 = 0.692669 loss)
I0427 22:16:18.648617 13425 solver.cpp:244]     Train net output #2: loss = 0.805525 (* 1 = 0.805525 loss)
I0427 22:16:18.648622 13425 sgd_solver.cpp:106] Iteration 17300, lr = 5e-05
I0427 22:17:58.281038 13425 solver.cpp:228] Iteration 17400, loss = 2.46564
I0427 22:17:58.281234 13425 solver.cpp:244]     Train net output #0: loss = 0.981343 (* 1 = 0.981343 loss)
I0427 22:17:58.281241 13425 solver.cpp:244]     Train net output #1: loss = 0.621088 (* 1 = 0.621088 loss)
I0427 22:17:58.281247 13425 solver.cpp:244]     Train net output #2: loss = 0.863212 (* 1 = 0.863212 loss)
I0427 22:17:58.281252 13425 sgd_solver.cpp:106] Iteration 17400, lr = 5e-05
I0427 22:19:37.512377 13425 solver.cpp:228] Iteration 17500, loss = 2.21091
I0427 22:19:37.512562 13425 solver.cpp:244]     Train net output #0: loss = 0.937984 (* 1 = 0.937984 loss)
I0427 22:19:37.512574 13425 solver.cpp:244]     Train net output #1: loss = 0.384563 (* 1 = 0.384563 loss)
I0427 22:19:37.512583 13425 solver.cpp:244]     Train net output #2: loss = 0.888358 (* 1 = 0.888358 loss)
I0427 22:19:37.512591 13425 sgd_solver.cpp:106] Iteration 17500, lr = 5e-05
I0427 22:21:16.779902 13425 solver.cpp:228] Iteration 17600, loss = 2.52919
I0427 22:21:16.780079 13425 solver.cpp:244]     Train net output #0: loss = 0.9402 (* 1 = 0.9402 loss)
I0427 22:21:16.780086 13425 solver.cpp:244]     Train net output #1: loss = 0.627208 (* 1 = 0.627208 loss)
I0427 22:21:16.780093 13425 solver.cpp:244]     Train net output #2: loss = 0.961786 (* 1 = 0.961786 loss)
I0427 22:21:16.780097 13425 sgd_solver.cpp:106] Iteration 17600, lr = 5e-05
I0427 22:22:56.336740 13425 solver.cpp:228] Iteration 17700, loss = 2.38544
I0427 22:22:56.336951 13425 solver.cpp:244]     Train net output #0: loss = 0.958692 (* 1 = 0.958692 loss)
I0427 22:22:56.336964 13425 solver.cpp:244]     Train net output #1: loss = 0.666247 (* 1 = 0.666247 loss)
I0427 22:22:56.336973 13425 solver.cpp:244]     Train net output #2: loss = 0.760505 (* 1 = 0.760505 loss)
I0427 22:22:56.336984 13425 sgd_solver.cpp:106] Iteration 17700, lr = 5e-05
I0427 22:24:34.525812 13425 solver.cpp:228] Iteration 17800, loss = 2.38067
I0427 22:24:34.526012 13425 solver.cpp:244]     Train net output #0: loss = 0.935347 (* 1 = 0.935347 loss)
I0427 22:24:34.526021 13425 solver.cpp:244]     Train net output #1: loss = 0.67891 (* 1 = 0.67891 loss)
I0427 22:24:34.526026 13425 solver.cpp:244]     Train net output #2: loss = 0.76641 (* 1 = 0.76641 loss)
I0427 22:24:34.526031 13425 sgd_solver.cpp:106] Iteration 17800, lr = 5e-05
I0427 22:26:14.317689 13425 solver.cpp:228] Iteration 17900, loss = 1.68863
I0427 22:26:14.317881 13425 solver.cpp:244]     Train net output #0: loss = 0.970378 (* 1 = 0.970378 loss)
I0427 22:26:14.317889 13425 solver.cpp:244]     Train net output #1: loss = 0.166136 (* 1 = 0.166136 loss)
I0427 22:26:14.317894 13425 solver.cpp:244]     Train net output #2: loss = 0.552119 (* 1 = 0.552119 loss)
I0427 22:26:14.317900 13425 sgd_solver.cpp:106] Iteration 17900, lr = 5e-05
I0427 22:27:53.155767 13425 solver.cpp:337] Iteration 18000, Testing net (#0)
I0427 22:27:53.155937 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 22:27:53.155941 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 22:27:53.155946 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 22:27:53.155959 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 22:27:53.155962 13425 net.cpp:693] Ignoring source layer visualize
I0427 22:27:53.155964 13425 net.cpp:693] Ignoring source layer fake
I0427 22:31:26.660979 13425 solver.cpp:404]     Test net output #0: loss = 0.934863 (* 1 = 0.934863 loss)
I0427 22:31:26.661144 13425 solver.cpp:404]     Test net output #1: loss = 0.586269 (* 1 = 0.586269 loss)
I0427 22:31:26.661152 13425 solver.cpp:404]     Test net output #2: loss = 0.814287 (* 1 = 0.814287 loss)
I0427 22:31:27.320978 13425 solver.cpp:228] Iteration 18000, loss = 2.36613
I0427 22:31:27.321022 13425 solver.cpp:244]     Train net output #0: loss = 0.93716 (* 1 = 0.93716 loss)
I0427 22:31:27.321027 13425 solver.cpp:244]     Train net output #1: loss = 0.71174 (* 1 = 0.71174 loss)
I0427 22:31:27.321032 13425 solver.cpp:244]     Train net output #2: loss = 0.717228 (* 1 = 0.717228 loss)
I0427 22:31:27.321036 13425 sgd_solver.cpp:106] Iteration 18000, lr = 5e-05
I0427 22:33:07.176798 13425 solver.cpp:228] Iteration 18100, loss = 2.60697
I0427 22:33:07.176965 13425 solver.cpp:244]     Train net output #0: loss = 0.964316 (* 1 = 0.964316 loss)
I0427 22:33:07.176975 13425 solver.cpp:244]     Train net output #1: loss = 0.713522 (* 1 = 0.713522 loss)
I0427 22:33:07.176980 13425 solver.cpp:244]     Train net output #2: loss = 0.929133 (* 1 = 0.929133 loss)
I0427 22:33:07.176985 13425 sgd_solver.cpp:106] Iteration 18100, lr = 5e-05
I0427 22:34:45.352335 13425 solver.cpp:228] Iteration 18200, loss = 2.6314
I0427 22:34:45.353659 13425 solver.cpp:244]     Train net output #0: loss = 0.947069 (* 1 = 0.947069 loss)
I0427 22:34:45.353667 13425 solver.cpp:244]     Train net output #1: loss = 0.766493 (* 1 = 0.766493 loss)
I0427 22:34:45.353672 13425 solver.cpp:244]     Train net output #2: loss = 0.917838 (* 1 = 0.917838 loss)
I0427 22:34:45.353678 13425 sgd_solver.cpp:106] Iteration 18200, lr = 5e-05
I0427 22:36:25.131480 13425 solver.cpp:228] Iteration 18300, loss = 2.61845
I0427 22:36:25.131660 13425 solver.cpp:244]     Train net output #0: loss = 0.97523 (* 1 = 0.97523 loss)
I0427 22:36:25.131669 13425 solver.cpp:244]     Train net output #1: loss = 0.767103 (* 1 = 0.767103 loss)
I0427 22:36:25.131675 13425 solver.cpp:244]     Train net output #2: loss = 0.876118 (* 1 = 0.876118 loss)
I0427 22:36:25.131680 13425 sgd_solver.cpp:106] Iteration 18300, lr = 5e-05
I0427 22:38:04.948977 13425 solver.cpp:228] Iteration 18400, loss = 2.53365
I0427 22:38:04.949160 13425 solver.cpp:244]     Train net output #0: loss = 0.985128 (* 1 = 0.985128 loss)
I0427 22:38:04.949168 13425 solver.cpp:244]     Train net output #1: loss = 0.796568 (* 1 = 0.796568 loss)
I0427 22:38:04.949174 13425 solver.cpp:244]     Train net output #2: loss = 0.751955 (* 1 = 0.751955 loss)
I0427 22:38:04.949179 13425 sgd_solver.cpp:106] Iteration 18400, lr = 5e-05
I0427 22:39:44.776918 13425 solver.cpp:228] Iteration 18500, loss = 2.60579
I0427 22:39:44.777079 13425 solver.cpp:244]     Train net output #0: loss = 0.978936 (* 1 = 0.978936 loss)
I0427 22:39:44.777087 13425 solver.cpp:244]     Train net output #1: loss = 0.68186 (* 1 = 0.68186 loss)
I0427 22:39:44.777092 13425 solver.cpp:244]     Train net output #2: loss = 0.944989 (* 1 = 0.944989 loss)
I0427 22:39:44.777098 13425 sgd_solver.cpp:106] Iteration 18500, lr = 5e-05
I0427 22:41:22.902523 13425 solver.cpp:228] Iteration 18600, loss = 2.42626
I0427 22:41:22.902683 13425 solver.cpp:244]     Train net output #0: loss = 0.984145 (* 1 = 0.984145 loss)
I0427 22:41:22.902691 13425 solver.cpp:244]     Train net output #1: loss = 0.692886 (* 1 = 0.692886 loss)
I0427 22:41:22.902698 13425 solver.cpp:244]     Train net output #2: loss = 0.749232 (* 1 = 0.749232 loss)
I0427 22:41:22.902703 13425 sgd_solver.cpp:106] Iteration 18600, lr = 5e-05
I0427 22:43:02.425173 13425 solver.cpp:228] Iteration 18700, loss = 2.12767
I0427 22:43:02.425339 13425 solver.cpp:244]     Train net output #0: loss = 0.975545 (* 1 = 0.975545 loss)
I0427 22:43:02.425348 13425 solver.cpp:244]     Train net output #1: loss = 0.654792 (* 1 = 0.654792 loss)
I0427 22:43:02.425354 13425 solver.cpp:244]     Train net output #2: loss = 0.497333 (* 1 = 0.497333 loss)
I0427 22:43:02.425359 13425 sgd_solver.cpp:106] Iteration 18700, lr = 5e-05
I0427 22:44:41.630803 13425 solver.cpp:228] Iteration 18800, loss = 2.38434
I0427 22:44:41.630975 13425 solver.cpp:244]     Train net output #0: loss = 0.936852 (* 1 = 0.936852 loss)
I0427 22:44:41.630982 13425 solver.cpp:244]     Train net output #1: loss = 0.539879 (* 1 = 0.539879 loss)
I0427 22:44:41.630987 13425 solver.cpp:244]     Train net output #2: loss = 0.907607 (* 1 = 0.907607 loss)
I0427 22:44:41.630992 13425 sgd_solver.cpp:106] Iteration 18800, lr = 5e-05
I0427 22:46:20.860618 13425 solver.cpp:228] Iteration 18900, loss = 2.56125
I0427 22:46:20.860787 13425 solver.cpp:244]     Train net output #0: loss = 0.925563 (* 1 = 0.925563 loss)
I0427 22:46:20.860795 13425 solver.cpp:244]     Train net output #1: loss = 0.695564 (* 1 = 0.695564 loss)
I0427 22:46:20.860800 13425 solver.cpp:244]     Train net output #2: loss = 0.94012 (* 1 = 0.94012 loss)
I0427 22:46:20.860806 13425 sgd_solver.cpp:106] Iteration 18900, lr = 5e-05
I0427 22:47:59.323379 13425 solver.cpp:337] Iteration 19000, Testing net (#0)
I0427 22:47:59.323537 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 22:47:59.323540 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 22:47:59.323545 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 22:47:59.323559 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 22:47:59.323562 13425 net.cpp:693] Ignoring source layer visualize
I0427 22:47:59.323565 13425 net.cpp:693] Ignoring source layer fake
I0427 22:51:32.545259 13425 solver.cpp:404]     Test net output #0: loss = 0.920628 (* 1 = 0.920628 loss)
I0427 22:51:32.546048 13425 solver.cpp:404]     Test net output #1: loss = 0.573838 (* 1 = 0.573838 loss)
I0427 22:51:32.546056 13425 solver.cpp:404]     Test net output #2: loss = 0.776932 (* 1 = 0.776932 loss)
I0427 22:51:33.201030 13425 solver.cpp:228] Iteration 19000, loss = 2.57674
I0427 22:51:33.201056 13425 solver.cpp:244]     Train net output #0: loss = 0.948598 (* 1 = 0.948598 loss)
I0427 22:51:33.201061 13425 solver.cpp:244]     Train net output #1: loss = 0.693751 (* 1 = 0.693751 loss)
I0427 22:51:33.201066 13425 solver.cpp:244]     Train net output #2: loss = 0.934387 (* 1 = 0.934387 loss)
I0427 22:51:33.201071 13425 sgd_solver.cpp:106] Iteration 19000, lr = 5e-05
I0427 22:53:12.877547 13425 solver.cpp:228] Iteration 19100, loss = 1.53446
I0427 22:53:12.877724 13425 solver.cpp:244]     Train net output #0: loss = 0.971206 (* 1 = 0.971206 loss)
I0427 22:53:12.877732 13425 solver.cpp:244]     Train net output #1: loss = 0.198917 (* 1 = 0.198917 loss)
I0427 22:53:12.877738 13425 solver.cpp:244]     Train net output #2: loss = 0.364342 (* 1 = 0.364342 loss)
I0427 22:53:12.877743 13425 sgd_solver.cpp:106] Iteration 19100, lr = 5e-05
I0427 22:54:52.599244 13425 solver.cpp:228] Iteration 19200, loss = 2.2283
I0427 22:54:52.599373 13425 solver.cpp:244]     Train net output #0: loss = 0.854533 (* 1 = 0.854533 loss)
I0427 22:54:52.599381 13425 solver.cpp:244]     Train net output #1: loss = 0.583455 (* 1 = 0.583455 loss)
I0427 22:54:52.599387 13425 solver.cpp:244]     Train net output #2: loss = 0.790309 (* 1 = 0.790309 loss)
I0427 22:54:52.599392 13425 sgd_solver.cpp:106] Iteration 19200, lr = 5e-05
I0427 22:56:30.747228 13425 solver.cpp:228] Iteration 19300, loss = 2.49878
I0427 22:56:30.747385 13425 solver.cpp:244]     Train net output #0: loss = 0.933987 (* 1 = 0.933987 loss)
I0427 22:56:30.747393 13425 solver.cpp:244]     Train net output #1: loss = 0.655022 (* 1 = 0.655022 loss)
I0427 22:56:30.747400 13425 solver.cpp:244]     Train net output #2: loss = 0.909773 (* 1 = 0.909773 loss)
I0427 22:56:30.747404 13425 sgd_solver.cpp:106] Iteration 19300, lr = 5e-05
I0427 22:58:10.546041 13425 solver.cpp:228] Iteration 19400, loss = 2.58093
I0427 22:58:10.546176 13425 solver.cpp:244]     Train net output #0: loss = 0.952991 (* 1 = 0.952991 loss)
I0427 22:58:10.546185 13425 solver.cpp:244]     Train net output #1: loss = 0.713798 (* 1 = 0.713798 loss)
I0427 22:58:10.546190 13425 solver.cpp:244]     Train net output #2: loss = 0.914138 (* 1 = 0.914138 loss)
I0427 22:58:10.546195 13425 sgd_solver.cpp:106] Iteration 19400, lr = 5e-05
I0427 22:59:50.252163 13425 solver.cpp:228] Iteration 19500, loss = 2.56487
I0427 22:59:50.252302 13425 solver.cpp:244]     Train net output #0: loss = 0.971313 (* 1 = 0.971313 loss)
I0427 22:59:50.252310 13425 solver.cpp:244]     Train net output #1: loss = 0.673416 (* 1 = 0.673416 loss)
I0427 22:59:50.252315 13425 solver.cpp:244]     Train net output #2: loss = 0.92014 (* 1 = 0.92014 loss)
I0427 22:59:50.252321 13425 sgd_solver.cpp:106] Iteration 19500, lr = 5e-05
I0427 23:01:28.400413 13425 solver.cpp:228] Iteration 19600, loss = 2.39753
I0427 23:01:28.400569 13425 solver.cpp:244]     Train net output #0: loss = 0.971143 (* 1 = 0.971143 loss)
I0427 23:01:28.400578 13425 solver.cpp:244]     Train net output #1: loss = 0.689575 (* 1 = 0.689575 loss)
I0427 23:01:28.400583 13425 solver.cpp:244]     Train net output #2: loss = 0.736812 (* 1 = 0.736812 loss)
I0427 23:01:28.400588 13425 sgd_solver.cpp:106] Iteration 19600, lr = 5e-05
I0427 23:03:08.011534 13425 solver.cpp:228] Iteration 19700, loss = 2.56001
I0427 23:03:08.011694 13425 solver.cpp:244]     Train net output #0: loss = 0.987748 (* 1 = 0.987748 loss)
I0427 23:03:08.011703 13425 solver.cpp:244]     Train net output #1: loss = 0.799383 (* 1 = 0.799383 loss)
I0427 23:03:08.011709 13425 solver.cpp:244]     Train net output #2: loss = 0.772879 (* 1 = 0.772879 loss)
I0427 23:03:08.011714 13425 sgd_solver.cpp:106] Iteration 19700, lr = 5e-05
I0427 23:04:47.619246 13425 solver.cpp:228] Iteration 19800, loss = 2.23886
I0427 23:04:47.619426 13425 solver.cpp:244]     Train net output #0: loss = 0.98151 (* 1 = 0.98151 loss)
I0427 23:04:47.619433 13425 solver.cpp:244]     Train net output #1: loss = 0.436838 (* 1 = 0.436838 loss)
I0427 23:04:47.619439 13425 solver.cpp:244]     Train net output #2: loss = 0.820508 (* 1 = 0.820508 loss)
I0427 23:04:47.619444 13425 sgd_solver.cpp:106] Iteration 19800, lr = 5e-05
I0427 23:06:27.151671 13425 solver.cpp:228] Iteration 19900, loss = 2.4392
I0427 23:06:27.151841 13425 solver.cpp:244]     Train net output #0: loss = 0.973539 (* 1 = 0.973539 loss)
I0427 23:06:27.151849 13425 solver.cpp:244]     Train net output #1: loss = 0.584311 (* 1 = 0.584311 loss)
I0427 23:06:27.151855 13425 solver.cpp:244]     Train net output #2: loss = 0.881347 (* 1 = 0.881347 loss)
I0427 23:06:27.151861 13425 sgd_solver.cpp:106] Iteration 19900, lr = 5e-05
I0427 23:08:05.318641 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_20000.caffemodel
I0427 23:08:06.007576 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_20000.solverstate
I0427 23:08:06.189218 13425 solver.cpp:337] Iteration 20000, Testing net (#0)
I0427 23:08:06.189244 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 23:08:06.189246 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 23:08:06.189249 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 23:08:06.189262 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 23:08:06.189265 13425 net.cpp:693] Ignoring source layer visualize
I0427 23:08:06.189267 13425 net.cpp:693] Ignoring source layer fake
I0427 23:11:38.841713 13425 solver.cpp:404]     Test net output #0: loss = 0.947597 (* 1 = 0.947597 loss)
I0427 23:11:38.841861 13425 solver.cpp:404]     Test net output #1: loss = 0.581949 (* 1 = 0.581949 loss)
I0427 23:11:38.841867 13425 solver.cpp:404]     Test net output #2: loss = 0.785789 (* 1 = 0.785789 loss)
I0427 23:11:39.495951 13425 solver.cpp:228] Iteration 20000, loss = 2.19768
I0427 23:11:39.495977 13425 solver.cpp:244]     Train net output #0: loss = 0.938263 (* 1 = 0.938263 loss)
I0427 23:11:39.495982 13425 solver.cpp:244]     Train net output #1: loss = 0.371279 (* 1 = 0.371279 loss)
I0427 23:11:39.495987 13425 solver.cpp:244]     Train net output #2: loss = 0.888142 (* 1 = 0.888142 loss)
I0427 23:11:39.495991 13425 sgd_solver.cpp:106] Iteration 20000, lr = 5e-06
I0427 23:13:18.702430 13425 solver.cpp:228] Iteration 20100, loss = 2.20165
I0427 23:13:18.702601 13425 solver.cpp:244]     Train net output #0: loss = 0.94419 (* 1 = 0.94419 loss)
I0427 23:13:18.702610 13425 solver.cpp:244]     Train net output #1: loss = 0.594931 (* 1 = 0.594931 loss)
I0427 23:13:18.702615 13425 solver.cpp:244]     Train net output #2: loss = 0.662531 (* 1 = 0.662531 loss)
I0427 23:13:18.702620 13425 sgd_solver.cpp:106] Iteration 20100, lr = 5e-06
I0427 23:14:58.148653 13425 solver.cpp:228] Iteration 20200, loss = 2.02466
I0427 23:14:58.148803 13425 solver.cpp:244]     Train net output #0: loss = 0.963238 (* 1 = 0.963238 loss)
I0427 23:14:58.148810 13425 solver.cpp:244]     Train net output #1: loss = 0.563243 (* 1 = 0.563243 loss)
I0427 23:14:58.148816 13425 solver.cpp:244]     Train net output #2: loss = 0.498176 (* 1 = 0.498176 loss)
I0427 23:14:58.148821 13425 sgd_solver.cpp:106] Iteration 20200, lr = 5e-06
I0427 23:16:36.179138 13425 solver.cpp:228] Iteration 20300, loss = 2.34982
I0427 23:16:36.179340 13425 solver.cpp:244]     Train net output #0: loss = 0.916322 (* 1 = 0.916322 loss)
I0427 23:16:36.179348 13425 solver.cpp:244]     Train net output #1: loss = 0.656496 (* 1 = 0.656496 loss)
I0427 23:16:36.179354 13425 solver.cpp:244]     Train net output #2: loss = 0.777005 (* 1 = 0.777005 loss)
I0427 23:16:36.179360 13425 sgd_solver.cpp:106] Iteration 20300, lr = 5e-06
I0427 23:18:15.777847 13425 solver.cpp:228] Iteration 20400, loss = 1.74439
I0427 23:18:15.778020 13425 solver.cpp:244]     Train net output #0: loss = 0.957062 (* 1 = 0.957062 loss)
I0427 23:18:15.778028 13425 solver.cpp:244]     Train net output #1: loss = 0.209619 (* 1 = 0.209619 loss)
I0427 23:18:15.778044 13425 solver.cpp:244]     Train net output #2: loss = 0.577706 (* 1 = 0.577706 loss)
I0427 23:18:15.778050 13425 sgd_solver.cpp:106] Iteration 20400, lr = 5e-06
I0427 23:19:55.459713 13425 solver.cpp:228] Iteration 20500, loss = 2.33811
I0427 23:19:55.459882 13425 solver.cpp:244]     Train net output #0: loss = 0.938036 (* 1 = 0.938036 loss)
I0427 23:19:55.459892 13425 solver.cpp:244]     Train net output #1: loss = 0.703035 (* 1 = 0.703035 loss)
I0427 23:19:55.459905 13425 solver.cpp:244]     Train net output #2: loss = 0.697042 (* 1 = 0.697042 loss)
I0427 23:19:55.459911 13425 sgd_solver.cpp:106] Iteration 20500, lr = 5e-06
I0427 23:21:35.234985 13425 solver.cpp:228] Iteration 20600, loss = 2.55835
I0427 23:21:35.235208 13425 solver.cpp:244]     Train net output #0: loss = 0.948223 (* 1 = 0.948223 loss)
I0427 23:21:35.235215 13425 solver.cpp:244]     Train net output #1: loss = 0.705898 (* 1 = 0.705898 loss)
I0427 23:21:35.235221 13425 solver.cpp:244]     Train net output #2: loss = 0.90423 (* 1 = 0.90423 loss)
I0427 23:21:35.235226 13425 sgd_solver.cpp:106] Iteration 20600, lr = 5e-06
I0427 23:23:13.376793 13425 solver.cpp:228] Iteration 20700, loss = 2.57259
I0427 23:23:13.376942 13425 solver.cpp:244]     Train net output #0: loss = 0.952314 (* 1 = 0.952314 loss)
I0427 23:23:13.376950 13425 solver.cpp:244]     Train net output #1: loss = 0.698024 (* 1 = 0.698024 loss)
I0427 23:23:13.376955 13425 solver.cpp:244]     Train net output #2: loss = 0.922251 (* 1 = 0.922251 loss)
I0427 23:23:13.376961 13425 sgd_solver.cpp:106] Iteration 20700, lr = 5e-06
I0427 23:24:53.136013 13425 solver.cpp:228] Iteration 20800, loss = 2.47363
I0427 23:24:53.136189 13425 solver.cpp:244]     Train net output #0: loss = 0.972508 (* 1 = 0.972508 loss)
I0427 23:24:53.136198 13425 solver.cpp:244]     Train net output #1: loss = 0.719718 (* 1 = 0.719718 loss)
I0427 23:24:53.136204 13425 solver.cpp:244]     Train net output #2: loss = 0.781409 (* 1 = 0.781409 loss)
I0427 23:24:53.136209 13425 sgd_solver.cpp:106] Iteration 20800, lr = 5e-06
I0427 23:26:33.111711 13425 solver.cpp:228] Iteration 20900, loss = 2.56488
I0427 23:26:33.111870 13425 solver.cpp:244]     Train net output #0: loss = 0.98213 (* 1 = 0.98213 loss)
I0427 23:26:33.111878 13425 solver.cpp:244]     Train net output #1: loss = 0.821493 (* 1 = 0.821493 loss)
I0427 23:26:33.111884 13425 solver.cpp:244]     Train net output #2: loss = 0.761262 (* 1 = 0.761262 loss)
I0427 23:26:33.111891 13425 sgd_solver.cpp:106] Iteration 20900, lr = 5e-06
I0427 23:28:11.841646 13425 solver.cpp:337] Iteration 21000, Testing net (#0)
I0427 23:28:11.841809 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 23:28:11.841812 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 23:28:11.841817 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 23:28:11.841831 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 23:28:11.841835 13425 net.cpp:693] Ignoring source layer visualize
I0427 23:28:11.841837 13425 net.cpp:693] Ignoring source layer fake
I0427 23:31:45.072068 13425 solver.cpp:404]     Test net output #0: loss = 0.943506 (* 1 = 0.943506 loss)
I0427 23:31:45.072240 13425 solver.cpp:404]     Test net output #1: loss = 0.611726 (* 1 = 0.611726 loss)
I0427 23:31:45.072248 13425 solver.cpp:404]     Test net output #2: loss = 0.812695 (* 1 = 0.812695 loss)
I0427 23:31:45.723693 13425 solver.cpp:228] Iteration 21000, loss = 2.27082
I0427 23:31:45.723717 13425 solver.cpp:244]     Train net output #0: loss = 0.987864 (* 1 = 0.987864 loss)
I0427 23:31:45.723723 13425 solver.cpp:244]     Train net output #1: loss = 0.512714 (* 1 = 0.512714 loss)
I0427 23:31:45.723727 13425 solver.cpp:244]     Train net output #2: loss = 0.770243 (* 1 = 0.770243 loss)
I0427 23:31:45.723732 13425 sgd_solver.cpp:106] Iteration 21000, lr = 5e-06
I0427 23:33:23.909860 13425 solver.cpp:228] Iteration 21100, loss = 2.25951
I0427 23:33:23.910006 13425 solver.cpp:244]     Train net output #0: loss = 0.975041 (* 1 = 0.975041 loss)
I0427 23:33:23.910014 13425 solver.cpp:244]     Train net output #1: loss = 0.504452 (* 1 = 0.504452 loss)
I0427 23:33:23.910019 13425 solver.cpp:244]     Train net output #2: loss = 0.780013 (* 1 = 0.780013 loss)
I0427 23:33:23.910025 13425 sgd_solver.cpp:106] Iteration 21100, lr = 5e-06
I0427 23:35:03.480823 13425 solver.cpp:228] Iteration 21200, loss = 2.23975
I0427 23:35:03.481009 13425 solver.cpp:244]     Train net output #0: loss = 0.987114 (* 1 = 0.987114 loss)
I0427 23:35:03.481017 13425 solver.cpp:244]     Train net output #1: loss = 0.708077 (* 1 = 0.708077 loss)
I0427 23:35:03.481022 13425 solver.cpp:244]     Train net output #2: loss = 0.544558 (* 1 = 0.544558 loss)
I0427 23:35:03.481029 13425 sgd_solver.cpp:106] Iteration 21200, lr = 5e-06
I0427 23:36:42.658982 13425 solver.cpp:228] Iteration 21300, loss = 2.05372
I0427 23:36:42.659171 13425 solver.cpp:244]     Train net output #0: loss = 0.961148 (* 1 = 0.961148 loss)
I0427 23:36:42.659179 13425 solver.cpp:244]     Train net output #1: loss = 0.34045 (* 1 = 0.34045 loss)
I0427 23:36:42.659184 13425 solver.cpp:244]     Train net output #2: loss = 0.752123 (* 1 = 0.752123 loss)
I0427 23:36:42.659190 13425 sgd_solver.cpp:106] Iteration 21300, lr = 5e-06
I0427 23:38:21.903833 13425 solver.cpp:228] Iteration 21400, loss = 2.34444
I0427 23:38:21.904036 13425 solver.cpp:244]     Train net output #0: loss = 0.933741 (* 1 = 0.933741 loss)
I0427 23:38:21.904043 13425 solver.cpp:244]     Train net output #1: loss = 0.521715 (* 1 = 0.521715 loss)
I0427 23:38:21.904049 13425 solver.cpp:244]     Train net output #2: loss = 0.888982 (* 1 = 0.888982 loss)
I0427 23:38:21.904055 13425 sgd_solver.cpp:106] Iteration 21400, lr = 5e-06
I0427 23:40:01.369534 13425 solver.cpp:228] Iteration 21500, loss = 1.97239
I0427 23:40:01.369688 13425 solver.cpp:244]     Train net output #0: loss = 0.966263 (* 1 = 0.966263 loss)
I0427 23:40:01.369696 13425 solver.cpp:244]     Train net output #1: loss = 0.424903 (* 1 = 0.424903 loss)
I0427 23:40:01.369701 13425 solver.cpp:244]     Train net output #2: loss = 0.581228 (* 1 = 0.581228 loss)
I0427 23:40:01.369707 13425 sgd_solver.cpp:106] Iteration 21500, lr = 5e-06
I0427 23:41:41.044255 13425 solver.cpp:228] Iteration 21600, loss = 1.91059
I0427 23:41:41.044433 13425 solver.cpp:244]     Train net output #0: loss = 0.953636 (* 1 = 0.953636 loss)
I0427 23:41:41.044441 13425 solver.cpp:244]     Train net output #1: loss = 0.225617 (* 1 = 0.225617 loss)
I0427 23:41:41.044446 13425 solver.cpp:244]     Train net output #2: loss = 0.731333 (* 1 = 0.731333 loss)
I0427 23:41:41.044451 13425 sgd_solver.cpp:106] Iteration 21600, lr = 5e-06
I0427 23:43:20.791147 13425 solver.cpp:228] Iteration 21700, loss = 2.48167
I0427 23:43:20.791322 13425 solver.cpp:244]     Train net output #0: loss = 0.937424 (* 1 = 0.937424 loss)
I0427 23:43:20.791330 13425 solver.cpp:244]     Train net output #1: loss = 0.671596 (* 1 = 0.671596 loss)
I0427 23:43:20.791337 13425 solver.cpp:244]     Train net output #2: loss = 0.872653 (* 1 = 0.872653 loss)
I0427 23:43:20.791342 13425 sgd_solver.cpp:106] Iteration 21700, lr = 5e-06
I0427 23:44:58.928650 13425 solver.cpp:228] Iteration 21800, loss = 2.53704
I0427 23:44:58.928817 13425 solver.cpp:244]     Train net output #0: loss = 0.931949 (* 1 = 0.931949 loss)
I0427 23:44:58.928825 13425 solver.cpp:244]     Train net output #1: loss = 0.711789 (* 1 = 0.711789 loss)
I0427 23:44:58.928831 13425 solver.cpp:244]     Train net output #2: loss = 0.893307 (* 1 = 0.893307 loss)
I0427 23:44:58.928836 13425 sgd_solver.cpp:106] Iteration 21800, lr = 5e-06
I0427 23:46:38.778038 13425 solver.cpp:228] Iteration 21900, loss = 2.42986
I0427 23:46:38.778215 13425 solver.cpp:244]     Train net output #0: loss = 0.961206 (* 1 = 0.961206 loss)
I0427 23:46:38.778224 13425 solver.cpp:244]     Train net output #1: loss = 0.740769 (* 1 = 0.740769 loss)
I0427 23:46:38.778229 13425 solver.cpp:244]     Train net output #2: loss = 0.727883 (* 1 = 0.727883 loss)
I0427 23:46:38.778235 13425 sgd_solver.cpp:106] Iteration 21900, lr = 5e-06
I0427 23:48:17.576273 13425 solver.cpp:337] Iteration 22000, Testing net (#0)
I0427 23:48:17.576448 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0427 23:48:17.576452 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0427 23:48:17.576463 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0427 23:48:17.576478 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0427 23:48:17.576481 13425 net.cpp:693] Ignoring source layer visualize
I0427 23:48:17.576483 13425 net.cpp:693] Ignoring source layer fake
I0427 23:51:50.663374 13425 solver.cpp:404]     Test net output #0: loss = 0.944279 (* 1 = 0.944279 loss)
I0427 23:51:50.663563 13425 solver.cpp:404]     Test net output #1: loss = 0.608314 (* 1 = 0.608314 loss)
I0427 23:51:50.663571 13425 solver.cpp:404]     Test net output #2: loss = 0.822627 (* 1 = 0.822627 loss)
I0427 23:51:51.320370 13425 solver.cpp:228] Iteration 22000, loss = 2.46575
I0427 23:51:51.320396 13425 solver.cpp:244]     Train net output #0: loss = 0.956457 (* 1 = 0.956457 loss)
I0427 23:51:51.320401 13425 solver.cpp:244]     Train net output #1: loss = 0.627557 (* 1 = 0.627557 loss)
I0427 23:51:51.320406 13425 solver.cpp:244]     Train net output #2: loss = 0.88174 (* 1 = 0.88174 loss)
I0427 23:51:51.320411 13425 sgd_solver.cpp:106] Iteration 22000, lr = 5e-06
I0427 23:53:29.486485 13425 solver.cpp:228] Iteration 22100, loss = 2.16926
I0427 23:53:29.486651 13425 solver.cpp:244]     Train net output #0: loss = 0.967255 (* 1 = 0.967255 loss)
I0427 23:53:29.486660 13425 solver.cpp:244]     Train net output #1: loss = 0.708916 (* 1 = 0.708916 loss)
I0427 23:53:29.486665 13425 solver.cpp:244]     Train net output #2: loss = 0.493085 (* 1 = 0.493085 loss)
I0427 23:53:29.486671 13425 sgd_solver.cpp:106] Iteration 22100, lr = 5e-06
I0427 23:55:09.090428 13425 solver.cpp:228] Iteration 22200, loss = 2.7911
I0427 23:55:09.090590 13425 solver.cpp:244]     Train net output #0: loss = 0.986309 (* 1 = 0.986309 loss)
I0427 23:55:09.090597 13425 solver.cpp:244]     Train net output #1: loss = 0.846127 (* 1 = 0.846127 loss)
I0427 23:55:09.090603 13425 solver.cpp:244]     Train net output #2: loss = 0.958659 (* 1 = 0.958659 loss)
I0427 23:55:09.090607 13425 sgd_solver.cpp:106] Iteration 22200, lr = 5e-06
I0427 23:56:48.720921 13425 solver.cpp:228] Iteration 22300, loss = 2.34448
I0427 23:56:48.721107 13425 solver.cpp:244]     Train net output #0: loss = 0.970531 (* 1 = 0.970531 loss)
I0427 23:56:48.721115 13425 solver.cpp:244]     Train net output #1: loss = 0.6099 (* 1 = 0.6099 loss)
I0427 23:56:48.721122 13425 solver.cpp:244]     Train net output #2: loss = 0.764052 (* 1 = 0.764052 loss)
I0427 23:56:48.721127 13425 sgd_solver.cpp:106] Iteration 22300, lr = 5e-06
I0427 23:58:28.283790 13425 solver.cpp:228] Iteration 22400, loss = 2.27719
I0427 23:58:28.283974 13425 solver.cpp:244]     Train net output #0: loss = 0.970889 (* 1 = 0.970889 loss)
I0427 23:58:28.283982 13425 solver.cpp:244]     Train net output #1: loss = 0.435918 (* 1 = 0.435918 loss)
I0427 23:58:28.283988 13425 solver.cpp:244]     Train net output #2: loss = 0.870379 (* 1 = 0.870379 loss)
I0427 23:58:28.283993 13425 sgd_solver.cpp:106] Iteration 22400, lr = 5e-06
I0428 00:00:07.492082 13425 solver.cpp:228] Iteration 22500, loss = 2.2752
I0428 00:00:07.492254 13425 solver.cpp:244]     Train net output #0: loss = 0.945816 (* 1 = 0.945816 loss)
I0428 00:00:07.492264 13425 solver.cpp:244]     Train net output #1: loss = 0.431838 (* 1 = 0.431838 loss)
I0428 00:00:07.492269 13425 solver.cpp:244]     Train net output #2: loss = 0.89755 (* 1 = 0.89755 loss)
I0428 00:00:07.492274 13425 sgd_solver.cpp:106] Iteration 22500, lr = 5e-06
I0428 00:01:46.780958 13425 solver.cpp:228] Iteration 22600, loss = 2.36352
I0428 00:01:46.782186 13425 solver.cpp:244]     Train net output #0: loss = 0.916449 (* 1 = 0.916449 loss)
I0428 00:01:46.782210 13425 solver.cpp:244]     Train net output #1: loss = 0.53763 (* 1 = 0.53763 loss)
I0428 00:01:46.782222 13425 solver.cpp:244]     Train net output #2: loss = 0.909439 (* 1 = 0.909439 loss)
I0428 00:01:46.782227 13425 sgd_solver.cpp:106] Iteration 22600, lr = 5e-06
I0428 00:03:26.219635 13425 solver.cpp:228] Iteration 22700, loss = 2.28053
I0428 00:03:26.219835 13425 solver.cpp:244]     Train net output #0: loss = 0.962432 (* 1 = 0.962432 loss)
I0428 00:03:26.219843 13425 solver.cpp:244]     Train net output #1: loss = 0.610801 (* 1 = 0.610801 loss)
I0428 00:03:26.219849 13425 solver.cpp:244]     Train net output #2: loss = 0.707298 (* 1 = 0.707298 loss)
I0428 00:03:26.219856 13425 sgd_solver.cpp:106] Iteration 22700, lr = 5e-06
I0428 00:05:04.264183 13425 solver.cpp:228] Iteration 22800, loss = 2.29909
I0428 00:05:04.264360 13425 solver.cpp:244]     Train net output #0: loss = 0.965625 (* 1 = 0.965625 loss)
I0428 00:05:04.264369 13425 solver.cpp:244]     Train net output #1: loss = 0.560335 (* 1 = 0.560335 loss)
I0428 00:05:04.264375 13425 solver.cpp:244]     Train net output #2: loss = 0.773127 (* 1 = 0.773127 loss)
I0428 00:05:04.264380 13425 sgd_solver.cpp:106] Iteration 22800, lr = 5e-06
I0428 00:06:43.913874 13425 solver.cpp:228] Iteration 22900, loss = 1.66419
I0428 00:06:43.914038 13425 solver.cpp:244]     Train net output #0: loss = 0.971825 (* 1 = 0.971825 loss)
I0428 00:06:43.914047 13425 solver.cpp:244]     Train net output #1: loss = 0.163696 (* 1 = 0.163696 loss)
I0428 00:06:43.914052 13425 solver.cpp:244]     Train net output #2: loss = 0.528673 (* 1 = 0.528673 loss)
I0428 00:06:43.914057 13425 sgd_solver.cpp:106] Iteration 22900, lr = 5e-06
I0428 00:08:22.730511 13425 solver.cpp:337] Iteration 23000, Testing net (#0)
I0428 00:08:22.730671 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 00:08:22.730675 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 00:08:22.730679 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 00:08:22.730693 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 00:08:22.730697 13425 net.cpp:693] Ignoring source layer visualize
I0428 00:08:22.730700 13425 net.cpp:693] Ignoring source layer fake
I0428 00:11:55.543939 13425 solver.cpp:404]     Test net output #0: loss = 0.944393 (* 1 = 0.944393 loss)
I0428 00:11:55.544095 13425 solver.cpp:404]     Test net output #1: loss = 0.610166 (* 1 = 0.610166 loss)
I0428 00:11:55.544106 13425 solver.cpp:404]     Test net output #2: loss = 0.823646 (* 1 = 0.823646 loss)
I0428 00:11:56.195323 13425 solver.cpp:228] Iteration 23000, loss = 2.45815
I0428 00:11:56.195365 13425 solver.cpp:244]     Train net output #0: loss = 0.928652 (* 1 = 0.928652 loss)
I0428 00:11:56.195371 13425 solver.cpp:244]     Train net output #1: loss = 0.689196 (* 1 = 0.689196 loss)
I0428 00:11:56.195377 13425 solver.cpp:244]     Train net output #2: loss = 0.8403 (* 1 = 0.8403 loss)
I0428 00:11:56.195381 13425 sgd_solver.cpp:106] Iteration 23000, lr = 5e-06
I0428 00:13:35.992349 13425 solver.cpp:228] Iteration 23100, loss = 2.62374
I0428 00:13:35.993479 13425 solver.cpp:244]     Train net output #0: loss = 0.969111 (* 1 = 0.969111 loss)
I0428 00:13:35.993489 13425 solver.cpp:244]     Train net output #1: loss = 0.726961 (* 1 = 0.726961 loss)
I0428 00:13:35.993495 13425 solver.cpp:244]     Train net output #2: loss = 0.927663 (* 1 = 0.927663 loss)
I0428 00:13:35.993500 13425 sgd_solver.cpp:106] Iteration 23100, lr = 5e-06
I0428 00:15:14.165302 13425 solver.cpp:228] Iteration 23200, loss = 2.50277
I0428 00:15:14.165484 13425 solver.cpp:244]     Train net output #0: loss = 0.956954 (* 1 = 0.956954 loss)
I0428 00:15:14.165493 13425 solver.cpp:244]     Train net output #1: loss = 0.617153 (* 1 = 0.617153 loss)
I0428 00:15:14.165498 13425 solver.cpp:244]     Train net output #2: loss = 0.928664 (* 1 = 0.928664 loss)
I0428 00:15:14.165503 13425 sgd_solver.cpp:106] Iteration 23200, lr = 5e-06
I0428 00:16:53.857642 13425 solver.cpp:228] Iteration 23300, loss = 2.32784
I0428 00:16:53.857811 13425 solver.cpp:244]     Train net output #0: loss = 0.963407 (* 1 = 0.963407 loss)
I0428 00:16:53.857820 13425 solver.cpp:244]     Train net output #1: loss = 0.563803 (* 1 = 0.563803 loss)
I0428 00:16:53.857825 13425 solver.cpp:244]     Train net output #2: loss = 0.800634 (* 1 = 0.800634 loss)
I0428 00:16:53.857831 13425 sgd_solver.cpp:106] Iteration 23300, lr = 5e-06
I0428 00:18:33.575489 13425 solver.cpp:228] Iteration 23400, loss = 2.58293
I0428 00:18:33.575628 13425 solver.cpp:244]     Train net output #0: loss = 0.988172 (* 1 = 0.988172 loss)
I0428 00:18:33.575636 13425 solver.cpp:244]     Train net output #1: loss = 0.823043 (* 1 = 0.823043 loss)
I0428 00:18:33.575642 13425 solver.cpp:244]     Train net output #2: loss = 0.771718 (* 1 = 0.771718 loss)
I0428 00:18:33.575647 13425 sgd_solver.cpp:106] Iteration 23400, lr = 5e-06
I0428 00:20:13.247966 13425 solver.cpp:228] Iteration 23500, loss = 1.94882
I0428 00:20:13.248153 13425 solver.cpp:244]     Train net output #0: loss = 0.984522 (* 1 = 0.984522 loss)
I0428 00:20:13.248162 13425 solver.cpp:244]     Train net output #1: loss = 0.388149 (* 1 = 0.388149 loss)
I0428 00:20:13.248168 13425 solver.cpp:244]     Train net output #2: loss = 0.576152 (* 1 = 0.576152 loss)
I0428 00:20:13.248173 13425 sgd_solver.cpp:106] Iteration 23500, lr = 5e-06
I0428 00:21:51.336525 13425 solver.cpp:228] Iteration 23600, loss = 2.2438
I0428 00:21:51.336688 13425 solver.cpp:244]     Train net output #0: loss = 0.973257 (* 1 = 0.973257 loss)
I0428 00:21:51.336696 13425 solver.cpp:244]     Train net output #1: loss = 0.618201 (* 1 = 0.618201 loss)
I0428 00:21:51.336702 13425 solver.cpp:244]     Train net output #2: loss = 0.652347 (* 1 = 0.652347 loss)
I0428 00:21:51.336707 13425 sgd_solver.cpp:106] Iteration 23600, lr = 5e-06
I0428 00:23:30.885834 13425 solver.cpp:228] Iteration 23700, loss = 2.59488
I0428 00:23:30.886005 13425 solver.cpp:244]     Train net output #0: loss = 0.972329 (* 1 = 0.972329 loss)
I0428 00:23:30.886013 13425 solver.cpp:244]     Train net output #1: loss = 0.695662 (* 1 = 0.695662 loss)
I0428 00:23:30.886019 13425 solver.cpp:244]     Train net output #2: loss = 0.926889 (* 1 = 0.926889 loss)
I0428 00:23:30.886025 13425 sgd_solver.cpp:106] Iteration 23700, lr = 5e-06
I0428 00:25:10.105631 13425 solver.cpp:228] Iteration 23800, loss = 2.28939
I0428 00:25:10.105780 13425 solver.cpp:244]     Train net output #0: loss = 0.962152 (* 1 = 0.962152 loss)
I0428 00:25:10.105788 13425 solver.cpp:244]     Train net output #1: loss = 0.388743 (* 1 = 0.388743 loss)
I0428 00:25:10.105794 13425 solver.cpp:244]     Train net output #2: loss = 0.938494 (* 1 = 0.938494 loss)
I0428 00:25:10.105800 13425 sgd_solver.cpp:106] Iteration 23800, lr = 5e-06
I0428 00:26:49.373785 13425 solver.cpp:228] Iteration 23900, loss = 2.16281
I0428 00:26:49.373958 13425 solver.cpp:244]     Train net output #0: loss = 0.940195 (* 1 = 0.940195 loss)
I0428 00:26:49.373966 13425 solver.cpp:244]     Train net output #1: loss = 0.493722 (* 1 = 0.493722 loss)
I0428 00:26:49.373972 13425 solver.cpp:244]     Train net output #2: loss = 0.72889 (* 1 = 0.72889 loss)
I0428 00:26:49.373977 13425 sgd_solver.cpp:106] Iteration 23900, lr = 5e-06
I0428 00:28:27.883561 13425 solver.cpp:337] Iteration 24000, Testing net (#0)
I0428 00:28:27.883736 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 00:28:27.883740 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 00:28:27.883744 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 00:28:27.883757 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 00:28:27.883762 13425 net.cpp:693] Ignoring source layer visualize
I0428 00:28:27.883765 13425 net.cpp:693] Ignoring source layer fake
I0428 00:32:01.219838 13425 solver.cpp:404]     Test net output #0: loss = 0.945497 (* 1 = 0.945497 loss)
I0428 00:32:01.219977 13425 solver.cpp:404]     Test net output #1: loss = 0.601687 (* 1 = 0.601687 loss)
I0428 00:32:01.219985 13425 solver.cpp:404]     Test net output #2: loss = 0.823284 (* 1 = 0.823284 loss)
I0428 00:32:01.869839 13425 solver.cpp:228] Iteration 24000, loss = 1.80715
I0428 00:32:01.869882 13425 solver.cpp:244]     Train net output #0: loss = 0.969454 (* 1 = 0.969454 loss)
I0428 00:32:01.869887 13425 solver.cpp:244]     Train net output #1: loss = 0.450139 (* 1 = 0.450139 loss)
I0428 00:32:01.869894 13425 solver.cpp:244]     Train net output #2: loss = 0.38756 (* 1 = 0.38756 loss)
I0428 00:32:01.869899 13425 sgd_solver.cpp:106] Iteration 24000, lr = 5e-06
I0428 00:33:41.511461 13425 solver.cpp:228] Iteration 24100, loss = 1.84893
I0428 00:33:41.511620 13425 solver.cpp:244]     Train net output #0: loss = 0.958826 (* 1 = 0.958826 loss)
I0428 00:33:41.511634 13425 solver.cpp:244]     Train net output #1: loss = 0.161881 (* 1 = 0.161881 loss)
I0428 00:33:41.511642 13425 solver.cpp:244]     Train net output #2: loss = 0.728223 (* 1 = 0.728223 loss)
I0428 00:33:41.511651 13425 sgd_solver.cpp:106] Iteration 24100, lr = 5e-06
I0428 00:35:21.242902 13425 solver.cpp:228] Iteration 24200, loss = 2.60252
I0428 00:35:21.243083 13425 solver.cpp:244]     Train net output #0: loss = 0.965946 (* 1 = 0.965946 loss)
I0428 00:35:21.243091 13425 solver.cpp:244]     Train net output #1: loss = 0.827458 (* 1 = 0.827458 loss)
I0428 00:35:21.243096 13425 solver.cpp:244]     Train net output #2: loss = 0.809118 (* 1 = 0.809118 loss)
I0428 00:35:21.243103 13425 sgd_solver.cpp:106] Iteration 24200, lr = 5e-06
I0428 00:36:59.382146 13425 solver.cpp:228] Iteration 24300, loss = 2.59028
I0428 00:36:59.382311 13425 solver.cpp:244]     Train net output #0: loss = 0.95551 (* 1 = 0.95551 loss)
I0428 00:36:59.382318 13425 solver.cpp:244]     Train net output #1: loss = 0.789522 (* 1 = 0.789522 loss)
I0428 00:36:59.382324 13425 solver.cpp:244]     Train net output #2: loss = 0.845249 (* 1 = 0.845249 loss)
I0428 00:36:59.382330 13425 sgd_solver.cpp:106] Iteration 24300, lr = 5e-06
I0428 00:38:39.191898 13425 solver.cpp:228] Iteration 24400, loss = 2.52667
I0428 00:38:39.192061 13425 solver.cpp:244]     Train net output #0: loss = 0.976226 (* 1 = 0.976226 loss)
I0428 00:38:39.192070 13425 solver.cpp:244]     Train net output #1: loss = 0.845808 (* 1 = 0.845808 loss)
I0428 00:38:39.192075 13425 solver.cpp:244]     Train net output #2: loss = 0.704632 (* 1 = 0.704632 loss)
I0428 00:38:39.192080 13425 sgd_solver.cpp:106] Iteration 24400, lr = 5e-06
I0428 00:40:18.943807 13425 solver.cpp:228] Iteration 24500, loss = 2.49724
I0428 00:40:18.944001 13425 solver.cpp:244]     Train net output #0: loss = 0.959077 (* 1 = 0.959077 loss)
I0428 00:40:18.944010 13425 solver.cpp:244]     Train net output #1: loss = 0.651796 (* 1 = 0.651796 loss)
I0428 00:40:18.944015 13425 solver.cpp:244]     Train net output #2: loss = 0.886366 (* 1 = 0.886366 loss)
I0428 00:40:18.944020 13425 sgd_solver.cpp:106] Iteration 24500, lr = 5e-06
I0428 00:41:57.070140 13425 solver.cpp:228] Iteration 24600, loss = 2.21511
I0428 00:41:57.070304 13425 solver.cpp:244]     Train net output #0: loss = 0.965069 (* 1 = 0.965069 loss)
I0428 00:41:57.070312 13425 solver.cpp:244]     Train net output #1: loss = 0.606395 (* 1 = 0.606395 loss)
I0428 00:41:57.070318 13425 solver.cpp:244]     Train net output #2: loss = 0.643641 (* 1 = 0.643641 loss)
I0428 00:41:57.070323 13425 sgd_solver.cpp:106] Iteration 24600, lr = 5e-06
I0428 00:43:36.780022 13425 solver.cpp:228] Iteration 24700, loss = 2.74376
I0428 00:43:36.780203 13425 solver.cpp:244]     Train net output #0: loss = 0.982059 (* 1 = 0.982059 loss)
I0428 00:43:36.780211 13425 solver.cpp:244]     Train net output #1: loss = 0.813249 (* 1 = 0.813249 loss)
I0428 00:43:36.780217 13425 solver.cpp:244]     Train net output #2: loss = 0.94845 (* 1 = 0.94845 loss)
I0428 00:43:36.780223 13425 sgd_solver.cpp:106] Iteration 24700, lr = 5e-06
I0428 00:45:16.484833 13425 solver.cpp:228] Iteration 24800, loss = 2.61763
I0428 00:45:16.485009 13425 solver.cpp:244]     Train net output #0: loss = 0.965396 (* 1 = 0.965396 loss)
I0428 00:45:16.485018 13425 solver.cpp:244]     Train net output #1: loss = 0.712889 (* 1 = 0.712889 loss)
I0428 00:45:16.485023 13425 solver.cpp:244]     Train net output #2: loss = 0.939342 (* 1 = 0.939342 loss)
I0428 00:45:16.485028 13425 sgd_solver.cpp:106] Iteration 24800, lr = 5e-06
I0428 00:46:56.087745 13425 solver.cpp:228] Iteration 24900, loss = 2.40219
I0428 00:46:56.087882 13425 solver.cpp:244]     Train net output #0: loss = 0.959029 (* 1 = 0.959029 loss)
I0428 00:46:56.087890 13425 solver.cpp:244]     Train net output #1: loss = 0.539372 (* 1 = 0.539372 loss)
I0428 00:46:56.087896 13425 solver.cpp:244]     Train net output #2: loss = 0.903787 (* 1 = 0.903787 loss)
I0428 00:46:56.087901 13425 sgd_solver.cpp:106] Iteration 24900, lr = 5e-06
I0428 00:48:34.316882 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_25000.caffemodel
I0428 00:48:35.007587 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_25000.solverstate
I0428 00:48:35.187121 13425 solver.cpp:337] Iteration 25000, Testing net (#0)
I0428 00:48:35.187147 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 00:48:35.187150 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 00:48:35.187153 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 00:48:35.187166 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 00:48:35.187168 13425 net.cpp:693] Ignoring source layer visualize
I0428 00:48:35.187170 13425 net.cpp:693] Ignoring source layer fake
I0428 00:52:07.904788 13425 solver.cpp:404]     Test net output #0: loss = 0.94596 (* 1 = 0.94596 loss)
I0428 00:52:07.904943 13425 solver.cpp:404]     Test net output #1: loss = 0.600858 (* 1 = 0.600858 loss)
I0428 00:52:07.904950 13425 solver.cpp:404]     Test net output #2: loss = 0.815796 (* 1 = 0.815796 loss)
I0428 00:52:08.554661 13425 solver.cpp:228] Iteration 25000, loss = 2.38951
I0428 00:52:08.554685 13425 solver.cpp:244]     Train net output #0: loss = 0.939715 (* 1 = 0.939715 loss)
I0428 00:52:08.554690 13425 solver.cpp:244]     Train net output #1: loss = 0.499333 (* 1 = 0.499333 loss)
I0428 00:52:08.554695 13425 solver.cpp:244]     Train net output #2: loss = 0.950465 (* 1 = 0.950465 loss)
I0428 00:52:08.554699 13425 sgd_solver.cpp:106] Iteration 25000, lr = 5e-06
I0428 00:53:47.788290 13425 solver.cpp:228] Iteration 25100, loss = 2.32045
I0428 00:53:47.788460 13425 solver.cpp:244]     Train net output #0: loss = 0.913522 (* 1 = 0.913522 loss)
I0428 00:53:47.788468 13425 solver.cpp:244]     Train net output #1: loss = 0.537245 (* 1 = 0.537245 loss)
I0428 00:53:47.788473 13425 solver.cpp:244]     Train net output #2: loss = 0.869682 (* 1 = 0.869682 loss)
I0428 00:53:47.788480 13425 sgd_solver.cpp:106] Iteration 25100, lr = 5e-06
I0428 00:55:27.165417 13425 solver.cpp:228] Iteration 25200, loss = 2.27859
I0428 00:55:27.165568 13425 solver.cpp:244]     Train net output #0: loss = 0.941342 (* 1 = 0.941342 loss)
I0428 00:55:27.165575 13425 solver.cpp:244]     Train net output #1: loss = 0.558692 (* 1 = 0.558692 loss)
I0428 00:55:27.165581 13425 solver.cpp:244]     Train net output #2: loss = 0.778555 (* 1 = 0.778555 loss)
I0428 00:55:27.165586 13425 sgd_solver.cpp:106] Iteration 25200, lr = 5e-06
I0428 00:57:05.141794 13425 solver.cpp:228] Iteration 25300, loss = 2.03135
I0428 00:57:05.141965 13425 solver.cpp:244]     Train net output #0: loss = 0.966751 (* 1 = 0.966751 loss)
I0428 00:57:05.141974 13425 solver.cpp:244]     Train net output #1: loss = 0.481285 (* 1 = 0.481285 loss)
I0428 00:57:05.141980 13425 solver.cpp:244]     Train net output #2: loss = 0.583319 (* 1 = 0.583319 loss)
I0428 00:57:05.141985 13425 sgd_solver.cpp:106] Iteration 25300, lr = 5e-06
I0428 00:58:44.725643 13425 solver.cpp:228] Iteration 25400, loss = 1.76176
I0428 00:58:44.725818 13425 solver.cpp:244]     Train net output #0: loss = 0.920237 (* 1 = 0.920237 loss)
I0428 00:58:44.725826 13425 solver.cpp:244]     Train net output #1: loss = 0.310044 (* 1 = 0.310044 loss)
I0428 00:58:44.725831 13425 solver.cpp:244]     Train net output #2: loss = 0.531476 (* 1 = 0.531476 loss)
I0428 00:58:44.725837 13425 sgd_solver.cpp:106] Iteration 25400, lr = 5e-06
I0428 01:00:24.441068 13425 solver.cpp:228] Iteration 25500, loss = 2.55064
I0428 01:00:24.441226 13425 solver.cpp:244]     Train net output #0: loss = 0.939467 (* 1 = 0.939467 loss)
I0428 01:00:24.441233 13425 solver.cpp:244]     Train net output #1: loss = 0.757021 (* 1 = 0.757021 loss)
I0428 01:00:24.441238 13425 solver.cpp:244]     Train net output #2: loss = 0.854156 (* 1 = 0.854156 loss)
I0428 01:00:24.441246 13425 sgd_solver.cpp:106] Iteration 25500, lr = 5e-06
I0428 01:02:04.171576 13425 solver.cpp:228] Iteration 25600, loss = 2.69079
I0428 01:02:04.171711 13425 solver.cpp:244]     Train net output #0: loss = 0.980898 (* 1 = 0.980898 loss)
I0428 01:02:04.171720 13425 solver.cpp:244]     Train net output #1: loss = 0.78128 (* 1 = 0.78128 loss)
I0428 01:02:04.171726 13425 solver.cpp:244]     Train net output #2: loss = 0.928614 (* 1 = 0.928614 loss)
I0428 01:02:04.171731 13425 sgd_solver.cpp:106] Iteration 25600, lr = 5e-06
I0428 01:03:42.255923 13425 solver.cpp:228] Iteration 25700, loss = 2.4357
I0428 01:03:42.256112 13425 solver.cpp:244]     Train net output #0: loss = 0.971485 (* 1 = 0.971485 loss)
I0428 01:03:42.256121 13425 solver.cpp:244]     Train net output #1: loss = 0.727153 (* 1 = 0.727153 loss)
I0428 01:03:42.256126 13425 solver.cpp:244]     Train net output #2: loss = 0.73706 (* 1 = 0.73706 loss)
I0428 01:03:42.256131 13425 sgd_solver.cpp:106] Iteration 25700, lr = 5e-06
I0428 01:05:21.943454 13425 solver.cpp:228] Iteration 25800, loss = 2.49542
I0428 01:05:21.943642 13425 solver.cpp:244]     Train net output #0: loss = 0.96741 (* 1 = 0.96741 loss)
I0428 01:05:21.943650 13425 solver.cpp:244]     Train net output #1: loss = 0.621239 (* 1 = 0.621239 loss)
I0428 01:05:21.943656 13425 solver.cpp:244]     Train net output #2: loss = 0.906769 (* 1 = 0.906769 loss)
I0428 01:05:21.943661 13425 sgd_solver.cpp:106] Iteration 25800, lr = 5e-06
I0428 01:07:01.603067 13425 solver.cpp:228] Iteration 25900, loss = 2.70762
I0428 01:07:01.603245 13425 solver.cpp:244]     Train net output #0: loss = 0.979543 (* 1 = 0.979543 loss)
I0428 01:07:01.603253 13425 solver.cpp:244]     Train net output #1: loss = 0.763174 (* 1 = 0.763174 loss)
I0428 01:07:01.603258 13425 solver.cpp:244]     Train net output #2: loss = 0.964907 (* 1 = 0.964907 loss)
I0428 01:07:01.603266 13425 sgd_solver.cpp:106] Iteration 25900, lr = 5e-06
I0428 01:08:40.242890 13425 solver.cpp:337] Iteration 26000, Testing net (#0)
I0428 01:08:40.243044 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 01:08:40.243048 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 01:08:40.243053 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 01:08:40.243067 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 01:08:40.243069 13425 net.cpp:693] Ignoring source layer visualize
I0428 01:08:40.243072 13425 net.cpp:693] Ignoring source layer fake
I0428 01:12:13.125749 13425 solver.cpp:404]     Test net output #0: loss = 0.945047 (* 1 = 0.945047 loss)
I0428 01:12:13.125891 13425 solver.cpp:404]     Test net output #1: loss = 0.618172 (* 1 = 0.618172 loss)
I0428 01:12:13.125898 13425 solver.cpp:404]     Test net output #2: loss = 0.820953 (* 1 = 0.820953 loss)
I0428 01:12:13.778827 13425 solver.cpp:228] Iteration 26000, loss = 2.33115
I0428 01:12:13.778854 13425 solver.cpp:244]     Train net output #0: loss = 0.978726 (* 1 = 0.978726 loss)
I0428 01:12:13.778859 13425 solver.cpp:244]     Train net output #1: loss = 0.619904 (* 1 = 0.619904 loss)
I0428 01:12:13.778863 13425 solver.cpp:244]     Train net output #2: loss = 0.732518 (* 1 = 0.732518 loss)
I0428 01:12:13.778868 13425 sgd_solver.cpp:106] Iteration 26000, lr = 5e-06
I0428 01:13:51.897780 13425 solver.cpp:228] Iteration 26100, loss = 2.4681
I0428 01:13:51.897938 13425 solver.cpp:244]     Train net output #0: loss = 0.978732 (* 1 = 0.978732 loss)
I0428 01:13:51.897946 13425 solver.cpp:244]     Train net output #1: loss = 0.739537 (* 1 = 0.739537 loss)
I0428 01:13:51.897951 13425 solver.cpp:244]     Train net output #2: loss = 0.749835 (* 1 = 0.749835 loss)
I0428 01:13:51.897958 13425 sgd_solver.cpp:106] Iteration 26100, lr = 5e-06
I0428 01:15:31.369770 13425 solver.cpp:228] Iteration 26200, loss = 2.35857
I0428 01:15:31.369968 13425 solver.cpp:244]     Train net output #0: loss = 0.956446 (* 1 = 0.956446 loss)
I0428 01:15:31.369976 13425 solver.cpp:244]     Train net output #1: loss = 0.615065 (* 1 = 0.615065 loss)
I0428 01:15:31.369982 13425 solver.cpp:244]     Train net output #2: loss = 0.787061 (* 1 = 0.787061 loss)
I0428 01:15:31.369988 13425 sgd_solver.cpp:106] Iteration 26200, lr = 5e-06
I0428 01:17:10.722808 13425 solver.cpp:228] Iteration 26300, loss = 2.41634
I0428 01:17:10.723022 13425 solver.cpp:244]     Train net output #0: loss = 0.938106 (* 1 = 0.938106 loss)
I0428 01:17:10.723034 13425 solver.cpp:244]     Train net output #1: loss = 0.521877 (* 1 = 0.521877 loss)
I0428 01:17:10.723042 13425 solver.cpp:244]     Train net output #2: loss = 0.956356 (* 1 = 0.956356 loss)
I0428 01:17:10.723050 13425 sgd_solver.cpp:106] Iteration 26300, lr = 5e-06
I0428 01:18:49.920688 13425 solver.cpp:228] Iteration 26400, loss = 2.14125
I0428 01:18:49.921591 13425 solver.cpp:244]     Train net output #0: loss = 0.956349 (* 1 = 0.956349 loss)
I0428 01:18:49.921599 13425 solver.cpp:244]     Train net output #1: loss = 0.431194 (* 1 = 0.431194 loss)
I0428 01:18:49.921604 13425 solver.cpp:244]     Train net output #2: loss = 0.753707 (* 1 = 0.753707 loss)
I0428 01:18:49.921610 13425 sgd_solver.cpp:106] Iteration 26400, lr = 5e-06
I0428 01:20:29.283520 13425 solver.cpp:228] Iteration 26500, loss = 2.33444
I0428 01:20:29.283699 13425 solver.cpp:244]     Train net output #0: loss = 0.965997 (* 1 = 0.965997 loss)
I0428 01:20:29.283706 13425 solver.cpp:244]     Train net output #1: loss = 0.607454 (* 1 = 0.607454 loss)
I0428 01:20:29.283712 13425 solver.cpp:244]     Train net output #2: loss = 0.76099 (* 1 = 0.76099 loss)
I0428 01:20:29.283718 13425 sgd_solver.cpp:106] Iteration 26500, lr = 5e-06
I0428 01:22:08.856113 13425 solver.cpp:228] Iteration 26600, loss = 1.53157
I0428 01:22:08.856302 13425 solver.cpp:244]     Train net output #0: loss = 0.966233 (* 1 = 0.966233 loss)
I0428 01:22:08.856312 13425 solver.cpp:244]     Train net output #1: loss = 0.181886 (* 1 = 0.181886 loss)
I0428 01:22:08.856317 13425 solver.cpp:244]     Train net output #2: loss = 0.383455 (* 1 = 0.383455 loss)
I0428 01:22:08.856323 13425 sgd_solver.cpp:106] Iteration 26600, lr = 5e-06
I0428 01:23:48.586120 13425 solver.cpp:228] Iteration 26700, loss = 2.38959
I0428 01:23:48.586307 13425 solver.cpp:244]     Train net output #0: loss = 0.959475 (* 1 = 0.959475 loss)
I0428 01:23:48.586315 13425 solver.cpp:244]     Train net output #1: loss = 0.653374 (* 1 = 0.653374 loss)
I0428 01:23:48.586321 13425 solver.cpp:244]     Train net output #2: loss = 0.776745 (* 1 = 0.776745 loss)
I0428 01:23:48.586326 13425 sgd_solver.cpp:106] Iteration 26700, lr = 5e-06
I0428 01:25:26.661866 13425 solver.cpp:228] Iteration 26800, loss = 2.40486
I0428 01:25:26.662012 13425 solver.cpp:244]     Train net output #0: loss = 0.922636 (* 1 = 0.922636 loss)
I0428 01:25:26.662020 13425 solver.cpp:244]     Train net output #1: loss = 0.661805 (* 1 = 0.661805 loss)
I0428 01:25:26.662025 13425 solver.cpp:244]     Train net output #2: loss = 0.820415 (* 1 = 0.820415 loss)
I0428 01:25:26.662030 13425 sgd_solver.cpp:106] Iteration 26800, lr = 5e-06
I0428 01:27:06.351282 13425 solver.cpp:228] Iteration 26900, loss = 2.46139
I0428 01:27:06.351446 13425 solver.cpp:244]     Train net output #0: loss = 0.953388 (* 1 = 0.953388 loss)
I0428 01:27:06.351454 13425 solver.cpp:244]     Train net output #1: loss = 0.607608 (* 1 = 0.607608 loss)
I0428 01:27:06.351459 13425 solver.cpp:244]     Train net output #2: loss = 0.900393 (* 1 = 0.900393 loss)
I0428 01:27:06.351464 13425 sgd_solver.cpp:106] Iteration 26900, lr = 5e-06
I0428 01:28:45.058748 13425 solver.cpp:337] Iteration 27000, Testing net (#0)
I0428 01:28:45.058923 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 01:28:45.058926 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 01:28:45.058930 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 01:28:45.058944 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 01:28:45.058948 13425 net.cpp:693] Ignoring source layer visualize
I0428 01:28:45.058950 13425 net.cpp:693] Ignoring source layer fake
I0428 01:32:18.014061 13425 solver.cpp:404]     Test net output #0: loss = 0.943446 (* 1 = 0.943446 loss)
I0428 01:32:18.014204 13425 solver.cpp:404]     Test net output #1: loss = 0.611475 (* 1 = 0.611475 loss)
I0428 01:32:18.014211 13425 solver.cpp:404]     Test net output #2: loss = 0.821788 (* 1 = 0.821788 loss)
I0428 01:32:18.671509 13425 solver.cpp:228] Iteration 27000, loss = 2.53795
I0428 01:32:18.671536 13425 solver.cpp:244]     Train net output #0: loss = 0.961855 (* 1 = 0.961855 loss)
I0428 01:32:18.671541 13425 solver.cpp:244]     Train net output #1: loss = 0.651518 (* 1 = 0.651518 loss)
I0428 01:32:18.671545 13425 solver.cpp:244]     Train net output #2: loss = 0.924578 (* 1 = 0.924578 loss)
I0428 01:32:18.671550 13425 sgd_solver.cpp:106] Iteration 27000, lr = 5e-06
I0428 01:33:56.849548 13425 solver.cpp:228] Iteration 27100, loss = 2.60174
I0428 01:33:56.849751 13425 solver.cpp:244]     Train net output #0: loss = 0.980024 (* 1 = 0.980024 loss)
I0428 01:33:56.849759 13425 solver.cpp:244]     Train net output #1: loss = 0.728695 (* 1 = 0.728695 loss)
I0428 01:33:56.849764 13425 solver.cpp:244]     Train net output #2: loss = 0.893018 (* 1 = 0.893018 loss)
I0428 01:33:56.849771 13425 sgd_solver.cpp:106] Iteration 27100, lr = 5e-06
I0428 01:35:36.494837 13425 solver.cpp:228] Iteration 27200, loss = 2.50121
I0428 01:35:36.495012 13425 solver.cpp:244]     Train net output #0: loss = 0.988901 (* 1 = 0.988901 loss)
I0428 01:35:36.495020 13425 solver.cpp:244]     Train net output #1: loss = 0.784749 (* 1 = 0.784749 loss)
I0428 01:35:36.495026 13425 solver.cpp:244]     Train net output #2: loss = 0.727565 (* 1 = 0.727565 loss)
I0428 01:35:36.495033 13425 sgd_solver.cpp:106] Iteration 27200, lr = 5e-06
I0428 01:37:16.116333 13425 solver.cpp:228] Iteration 27300, loss = 2.4574
I0428 01:37:16.116492 13425 solver.cpp:244]     Train net output #0: loss = 0.96776 (* 1 = 0.96776 loss)
I0428 01:37:16.116503 13425 solver.cpp:244]     Train net output #1: loss = 0.600712 (* 1 = 0.600712 loss)
I0428 01:37:16.116508 13425 solver.cpp:244]     Train net output #2: loss = 0.888927 (* 1 = 0.888927 loss)
I0428 01:37:16.116513 13425 sgd_solver.cpp:106] Iteration 27300, lr = 5e-06
I0428 01:38:55.639830 13425 solver.cpp:228] Iteration 27400, loss = 2.49384
I0428 01:38:55.640024 13425 solver.cpp:244]     Train net output #0: loss = 0.980687 (* 1 = 0.980687 loss)
I0428 01:38:55.640033 13425 solver.cpp:244]     Train net output #1: loss = 0.613113 (* 1 = 0.613113 loss)
I0428 01:38:55.640038 13425 solver.cpp:244]     Train net output #2: loss = 0.900037 (* 1 = 0.900037 loss)
I0428 01:38:55.640043 13425 sgd_solver.cpp:106] Iteration 27400, lr = 5e-06
I0428 01:40:34.840977 13425 solver.cpp:228] Iteration 27500, loss = 2.2813
I0428 01:40:34.841147 13425 solver.cpp:244]     Train net output #0: loss = 0.973221 (* 1 = 0.973221 loss)
I0428 01:40:34.841156 13425 solver.cpp:244]     Train net output #1: loss = 0.405985 (* 1 = 0.405985 loss)
I0428 01:40:34.841161 13425 solver.cpp:244]     Train net output #2: loss = 0.90209 (* 1 = 0.90209 loss)
I0428 01:40:34.841167 13425 sgd_solver.cpp:106] Iteration 27500, lr = 5e-06
I0428 01:42:14.026834 13425 solver.cpp:228] Iteration 27600, loss = 2.36044
I0428 01:42:14.027034 13425 solver.cpp:244]     Train net output #0: loss = 0.956324 (* 1 = 0.956324 loss)
I0428 01:42:14.027043 13425 solver.cpp:244]     Train net output #1: loss = 0.543147 (* 1 = 0.543147 loss)
I0428 01:42:14.027050 13425 solver.cpp:244]     Train net output #2: loss = 0.860967 (* 1 = 0.860967 loss)
I0428 01:42:14.027055 13425 sgd_solver.cpp:106] Iteration 27600, lr = 5e-06
I0428 01:43:53.363925 13425 solver.cpp:228] Iteration 27700, loss = 2.03975
I0428 01:43:53.364080 13425 solver.cpp:244]     Train net output #0: loss = 0.980172 (* 1 = 0.980172 loss)
I0428 01:43:53.364089 13425 solver.cpp:244]     Train net output #1: loss = 0.516114 (* 1 = 0.516114 loss)
I0428 01:43:53.364094 13425 solver.cpp:244]     Train net output #2: loss = 0.543467 (* 1 = 0.543467 loss)
I0428 01:43:53.364099 13425 sgd_solver.cpp:106] Iteration 27700, lr = 5e-06
I0428 01:45:31.396523 13425 solver.cpp:228] Iteration 27800, loss = 2.26658
I0428 01:45:31.396682 13425 solver.cpp:244]     Train net output #0: loss = 0.967104 (* 1 = 0.967104 loss)
I0428 01:45:31.396689 13425 solver.cpp:244]     Train net output #1: loss = 0.528638 (* 1 = 0.528638 loss)
I0428 01:45:31.396695 13425 solver.cpp:244]     Train net output #2: loss = 0.770836 (* 1 = 0.770836 loss)
I0428 01:45:31.396700 13425 sgd_solver.cpp:106] Iteration 27800, lr = 5e-06
I0428 01:47:11.059991 13425 solver.cpp:228] Iteration 27900, loss = 2.00042
I0428 01:47:11.060173 13425 solver.cpp:244]     Train net output #0: loss = 0.67712 (* 1 = 0.67712 loss)
I0428 01:47:11.060180 13425 solver.cpp:244]     Train net output #1: loss = 0.563916 (* 1 = 0.563916 loss)
I0428 01:47:11.060186 13425 solver.cpp:244]     Train net output #2: loss = 0.759388 (* 1 = 0.759388 loss)
I0428 01:47:11.060192 13425 sgd_solver.cpp:106] Iteration 27900, lr = 5e-06
I0428 01:48:49.812553 13425 solver.cpp:337] Iteration 28000, Testing net (#0)
I0428 01:48:49.812731 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 01:48:49.812736 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 01:48:49.812739 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 01:48:49.812753 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 01:48:49.812757 13425 net.cpp:693] Ignoring source layer visualize
I0428 01:48:49.812759 13425 net.cpp:693] Ignoring source layer fake
I0428 01:52:22.639766 13425 solver.cpp:404]     Test net output #0: loss = 0.942446 (* 1 = 0.942446 loss)
I0428 01:52:22.639902 13425 solver.cpp:404]     Test net output #1: loss = 0.609757 (* 1 = 0.609757 loss)
I0428 01:52:22.639909 13425 solver.cpp:404]     Test net output #2: loss = 0.824495 (* 1 = 0.824495 loss)
I0428 01:52:23.289654 13425 solver.cpp:228] Iteration 28000, loss = 2.61072
I0428 01:52:23.289680 13425 solver.cpp:244]     Train net output #0: loss = 0.960184 (* 1 = 0.960184 loss)
I0428 01:52:23.289685 13425 solver.cpp:244]     Train net output #1: loss = 0.805258 (* 1 = 0.805258 loss)
I0428 01:52:23.289688 13425 solver.cpp:244]     Train net output #2: loss = 0.845281 (* 1 = 0.845281 loss)
I0428 01:52:23.289692 13425 sgd_solver.cpp:106] Iteration 28000, lr = 5e-06
I0428 01:54:03.054800 13425 solver.cpp:228] Iteration 28100, loss = 2.58221
I0428 01:54:03.054950 13425 solver.cpp:244]     Train net output #0: loss = 0.974266 (* 1 = 0.974266 loss)
I0428 01:54:03.054958 13425 solver.cpp:244]     Train net output #1: loss = 0.754397 (* 1 = 0.754397 loss)
I0428 01:54:03.054963 13425 solver.cpp:244]     Train net output #2: loss = 0.853544 (* 1 = 0.853544 loss)
I0428 01:54:03.054970 13425 sgd_solver.cpp:106] Iteration 28100, lr = 5e-06
I0428 01:55:41.171172 13425 solver.cpp:228] Iteration 28200, loss = 2.39291
I0428 01:55:41.171360 13425 solver.cpp:244]     Train net output #0: loss = 0.945639 (* 1 = 0.945639 loss)
I0428 01:55:41.171367 13425 solver.cpp:244]     Train net output #1: loss = 0.549335 (* 1 = 0.549335 loss)
I0428 01:55:41.171375 13425 solver.cpp:244]     Train net output #2: loss = 0.897936 (* 1 = 0.897936 loss)
I0428 01:55:41.171380 13425 sgd_solver.cpp:106] Iteration 28200, lr = 5e-06
I0428 01:57:20.891594 13425 solver.cpp:228] Iteration 28300, loss = 2.69534
I0428 01:57:20.891782 13425 solver.cpp:244]     Train net output #0: loss = 0.975141 (* 1 = 0.975141 loss)
I0428 01:57:20.891791 13425 solver.cpp:244]     Train net output #1: loss = 0.778756 (* 1 = 0.778756 loss)
I0428 01:57:20.891796 13425 solver.cpp:244]     Train net output #2: loss = 0.941445 (* 1 = 0.941445 loss)
I0428 01:57:20.891803 13425 sgd_solver.cpp:106] Iteration 28300, lr = 5e-06
I0428 01:59:00.558538 13425 solver.cpp:228] Iteration 28400, loss = 2.52783
I0428 01:59:00.558717 13425 solver.cpp:244]     Train net output #0: loss = 0.977894 (* 1 = 0.977894 loss)
I0428 01:59:00.558725 13425 solver.cpp:244]     Train net output #1: loss = 0.786866 (* 1 = 0.786866 loss)
I0428 01:59:00.558730 13425 solver.cpp:244]     Train net output #2: loss = 0.763075 (* 1 = 0.763075 loss)
I0428 01:59:00.558735 13425 sgd_solver.cpp:106] Iteration 28400, lr = 5e-06
I0428 02:00:40.200712 13425 solver.cpp:228] Iteration 28500, loss = 2.54296
I0428 02:00:40.200889 13425 solver.cpp:244]     Train net output #0: loss = 0.978042 (* 1 = 0.978042 loss)
I0428 02:00:40.200897 13425 solver.cpp:244]     Train net output #1: loss = 0.685758 (* 1 = 0.685758 loss)
I0428 02:00:40.200903 13425 solver.cpp:244]     Train net output #2: loss = 0.879156 (* 1 = 0.879156 loss)
I0428 02:00:40.200909 13425 sgd_solver.cpp:106] Iteration 28500, lr = 5e-06
I0428 02:02:18.213421 13425 solver.cpp:228] Iteration 28600, loss = 2.24676
I0428 02:02:18.213609 13425 solver.cpp:244]     Train net output #0: loss = 0.982233 (* 1 = 0.982233 loss)
I0428 02:02:18.213618 13425 solver.cpp:244]     Train net output #1: loss = 0.57311 (* 1 = 0.57311 loss)
I0428 02:02:18.213624 13425 solver.cpp:244]     Train net output #2: loss = 0.691421 (* 1 = 0.691421 loss)
I0428 02:02:18.213629 13425 sgd_solver.cpp:106] Iteration 28600, lr = 5e-06
I0428 02:03:57.712453 13425 solver.cpp:228] Iteration 28700, loss = 2.27963
I0428 02:03:57.712632 13425 solver.cpp:244]     Train net output #0: loss = 0.957612 (* 1 = 0.957612 loss)
I0428 02:03:57.712641 13425 solver.cpp:244]     Train net output #1: loss = 0.61324 (* 1 = 0.61324 loss)
I0428 02:03:57.712646 13425 solver.cpp:244]     Train net output #2: loss = 0.708776 (* 1 = 0.708776 loss)
I0428 02:03:57.712651 13425 sgd_solver.cpp:106] Iteration 28700, lr = 5e-06
I0428 02:05:36.849473 13425 solver.cpp:228] Iteration 28800, loss = 2.34491
I0428 02:05:36.849634 13425 solver.cpp:244]     Train net output #0: loss = 0.938443 (* 1 = 0.938443 loss)
I0428 02:05:36.849642 13425 solver.cpp:244]     Train net output #1: loss = 0.457924 (* 1 = 0.457924 loss)
I0428 02:05:36.849648 13425 solver.cpp:244]     Train net output #2: loss = 0.948545 (* 1 = 0.948545 loss)
I0428 02:05:36.849653 13425 sgd_solver.cpp:106] Iteration 28800, lr = 5e-06
I0428 02:07:16.035073 13425 solver.cpp:228] Iteration 28900, loss = 2.44519
I0428 02:07:16.035245 13425 solver.cpp:244]     Train net output #0: loss = 0.952298 (* 1 = 0.952298 loss)
I0428 02:07:16.035254 13425 solver.cpp:244]     Train net output #1: loss = 0.552217 (* 1 = 0.552217 loss)
I0428 02:07:16.035259 13425 solver.cpp:244]     Train net output #2: loss = 0.940678 (* 1 = 0.940678 loss)
I0428 02:07:16.035264 13425 sgd_solver.cpp:106] Iteration 28900, lr = 5e-06
I0428 02:08:54.425927 13425 solver.cpp:337] Iteration 29000, Testing net (#0)
I0428 02:08:54.426105 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 02:08:54.426108 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 02:08:54.426113 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 02:08:54.426127 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 02:08:54.426131 13425 net.cpp:693] Ignoring source layer visualize
I0428 02:08:54.426132 13425 net.cpp:693] Ignoring source layer fake
I0428 02:12:27.351666 13425 solver.cpp:404]     Test net output #0: loss = 0.944475 (* 1 = 0.944475 loss)
I0428 02:12:27.351806 13425 solver.cpp:404]     Test net output #1: loss = 0.606603 (* 1 = 0.606603 loss)
I0428 02:12:27.351812 13425 solver.cpp:404]     Test net output #2: loss = 0.825323 (* 1 = 0.825323 loss)
I0428 02:12:28.003674 13425 solver.cpp:228] Iteration 29000, loss = 2.19058
I0428 02:12:28.003713 13425 solver.cpp:244]     Train net output #0: loss = 0.965476 (* 1 = 0.965476 loss)
I0428 02:12:28.003720 13425 solver.cpp:244]     Train net output #1: loss = 0.645863 (* 1 = 0.645863 loss)
I0428 02:12:28.003724 13425 solver.cpp:244]     Train net output #2: loss = 0.579244 (* 1 = 0.579244 loss)
I0428 02:12:28.003729 13425 sgd_solver.cpp:106] Iteration 29000, lr = 5e-06
I0428 02:14:07.662331 13425 solver.cpp:228] Iteration 29100, loss = 1.73174
I0428 02:14:07.662519 13425 solver.cpp:244]     Train net output #0: loss = 0.968239 (* 1 = 0.968239 loss)
I0428 02:14:07.662528 13425 solver.cpp:244]     Train net output #1: loss = 0.2196 (* 1 = 0.2196 loss)
I0428 02:14:07.662533 13425 solver.cpp:244]     Train net output #2: loss = 0.543905 (* 1 = 0.543905 loss)
I0428 02:14:07.662539 13425 sgd_solver.cpp:106] Iteration 29100, lr = 5e-06
I0428 02:15:47.382292 13425 solver.cpp:228] Iteration 29200, loss = 2.32826
I0428 02:15:47.382441 13425 solver.cpp:244]     Train net output #0: loss = 0.930427 (* 1 = 0.930427 loss)
I0428 02:15:47.382448 13425 solver.cpp:244]     Train net output #1: loss = 0.598705 (* 1 = 0.598705 loss)
I0428 02:15:47.382455 13425 solver.cpp:244]     Train net output #2: loss = 0.799123 (* 1 = 0.799123 loss)
I0428 02:15:47.382460 13425 sgd_solver.cpp:106] Iteration 29200, lr = 5e-06
I0428 02:17:25.479607 13425 solver.cpp:228] Iteration 29300, loss = 2.35292
I0428 02:17:25.479809 13425 solver.cpp:244]     Train net output #0: loss = 0.885847 (* 1 = 0.885847 loss)
I0428 02:17:25.479820 13425 solver.cpp:244]     Train net output #1: loss = 0.574575 (* 1 = 0.574575 loss)
I0428 02:17:25.479825 13425 solver.cpp:244]     Train net output #2: loss = 0.892494 (* 1 = 0.892494 loss)
I0428 02:17:25.479830 13425 sgd_solver.cpp:106] Iteration 29300, lr = 5e-06
I0428 02:19:05.190043 13425 solver.cpp:228] Iteration 29400, loss = 2.52262
I0428 02:19:05.190207 13425 solver.cpp:244]     Train net output #0: loss = 0.94596 (* 1 = 0.94596 loss)
I0428 02:19:05.190215 13425 solver.cpp:244]     Train net output #1: loss = 0.66077 (* 1 = 0.66077 loss)
I0428 02:19:05.190220 13425 solver.cpp:244]     Train net output #2: loss = 0.915888 (* 1 = 0.915888 loss)
I0428 02:19:05.190227 13425 sgd_solver.cpp:106] Iteration 29400, lr = 5e-06
I0428 02:20:44.890511 13425 solver.cpp:228] Iteration 29500, loss = 2.60347
I0428 02:20:44.890677 13425 solver.cpp:244]     Train net output #0: loss = 0.963093 (* 1 = 0.963093 loss)
I0428 02:20:44.890689 13425 solver.cpp:244]     Train net output #1: loss = 0.735198 (* 1 = 0.735198 loss)
I0428 02:20:44.890697 13425 solver.cpp:244]     Train net output #2: loss = 0.90518 (* 1 = 0.90518 loss)
I0428 02:20:44.890707 13425 sgd_solver.cpp:106] Iteration 29500, lr = 5e-06
I0428 02:22:22.960907 13425 solver.cpp:228] Iteration 29600, loss = 2.47833
I0428 02:22:22.961050 13425 solver.cpp:244]     Train net output #0: loss = 0.967902 (* 1 = 0.967902 loss)
I0428 02:22:22.961060 13425 solver.cpp:244]     Train net output #1: loss = 0.655936 (* 1 = 0.655936 loss)
I0428 02:22:22.961066 13425 solver.cpp:244]     Train net output #2: loss = 0.854497 (* 1 = 0.854497 loss)
I0428 02:22:22.961071 13425 sgd_solver.cpp:106] Iteration 29600, lr = 5e-06
I0428 02:24:02.574616 13425 solver.cpp:228] Iteration 29700, loss = 2.45698
I0428 02:24:02.574753 13425 solver.cpp:244]     Train net output #0: loss = 0.991286 (* 1 = 0.991286 loss)
I0428 02:24:02.574762 13425 solver.cpp:244]     Train net output #1: loss = 0.729872 (* 1 = 0.729872 loss)
I0428 02:24:02.574767 13425 solver.cpp:244]     Train net output #2: loss = 0.735822 (* 1 = 0.735822 loss)
I0428 02:24:02.574772 13425 sgd_solver.cpp:106] Iteration 29700, lr = 5e-06
I0428 02:25:42.219147 13425 solver.cpp:228] Iteration 29800, loss = 2.37029
I0428 02:25:42.219312 13425 solver.cpp:244]     Train net output #0: loss = 0.979627 (* 1 = 0.979627 loss)
I0428 02:25:42.219321 13425 solver.cpp:244]     Train net output #1: loss = 0.63598 (* 1 = 0.63598 loss)
I0428 02:25:42.219326 13425 solver.cpp:244]     Train net output #2: loss = 0.754682 (* 1 = 0.754682 loss)
I0428 02:25:42.219331 13425 sgd_solver.cpp:106] Iteration 29800, lr = 5e-06
I0428 02:27:21.711772 13425 solver.cpp:228] Iteration 29900, loss = 2.28932
I0428 02:27:21.711935 13425 solver.cpp:244]     Train net output #0: loss = 0.970154 (* 1 = 0.970154 loss)
I0428 02:27:21.711942 13425 solver.cpp:244]     Train net output #1: loss = 0.432247 (* 1 = 0.432247 loss)
I0428 02:27:21.711947 13425 solver.cpp:244]     Train net output #2: loss = 0.88692 (* 1 = 0.88692 loss)
I0428 02:27:21.711953 13425 sgd_solver.cpp:106] Iteration 29900, lr = 5e-06
I0428 02:28:59.887516 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_30000.caffemodel
I0428 02:29:00.574096 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_30000.solverstate
I0428 02:29:00.755905 13425 solver.cpp:337] Iteration 30000, Testing net (#0)
I0428 02:29:00.755929 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 02:29:00.755931 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 02:29:00.755934 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 02:29:00.755947 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 02:29:00.755950 13425 net.cpp:693] Ignoring source layer visualize
I0428 02:29:00.755952 13425 net.cpp:693] Ignoring source layer fake
I0428 02:32:33.290321 13425 solver.cpp:404]     Test net output #0: loss = 0.945435 (* 1 = 0.945435 loss)
I0428 02:32:33.290515 13425 solver.cpp:404]     Test net output #1: loss = 0.604012 (* 1 = 0.604012 loss)
I0428 02:32:33.290524 13425 solver.cpp:404]     Test net output #2: loss = 0.816033 (* 1 = 0.816033 loss)
I0428 02:32:33.939977 13425 solver.cpp:228] Iteration 30000, loss = 2.22125
I0428 02:32:33.940004 13425 solver.cpp:244]     Train net output #0: loss = 0.956567 (* 1 = 0.956567 loss)
I0428 02:32:33.940009 13425 solver.cpp:244]     Train net output #1: loss = 0.365063 (* 1 = 0.365063 loss)
I0428 02:32:33.940014 13425 solver.cpp:244]     Train net output #2: loss = 0.899621 (* 1 = 0.899621 loss)
I0428 02:32:33.940019 13425 sgd_solver.cpp:106] Iteration 30000, lr = 5e-06
I0428 02:34:13.200122 13425 solver.cpp:228] Iteration 30100, loss = 2.32809
I0428 02:34:13.200273 13425 solver.cpp:244]     Train net output #0: loss = 0.978644 (* 1 = 0.978644 loss)
I0428 02:34:13.200280 13425 solver.cpp:244]     Train net output #1: loss = 0.59479 (* 1 = 0.59479 loss)
I0428 02:34:13.200286 13425 solver.cpp:244]     Train net output #2: loss = 0.754652 (* 1 = 0.754652 loss)
I0428 02:34:13.200290 13425 sgd_solver.cpp:106] Iteration 30100, lr = 5e-06
I0428 02:35:52.557333 13425 solver.cpp:228] Iteration 30200, loss = 2.50691
I0428 02:35:52.557498 13425 solver.cpp:244]     Train net output #0: loss = 0.948931 (* 1 = 0.948931 loss)
I0428 02:35:52.557507 13425 solver.cpp:244]     Train net output #1: loss = 0.636533 (* 1 = 0.636533 loss)
I0428 02:35:52.557512 13425 solver.cpp:244]     Train net output #2: loss = 0.921448 (* 1 = 0.921448 loss)
I0428 02:35:52.557516 13425 sgd_solver.cpp:106] Iteration 30200, lr = 5e-06
I0428 02:37:30.578825 13425 solver.cpp:228] Iteration 30300, loss = 2.25814
I0428 02:37:30.579010 13425 solver.cpp:244]     Train net output #0: loss = 0.980874 (* 1 = 0.980874 loss)
I0428 02:37:30.579017 13425 solver.cpp:244]     Train net output #1: loss = 0.514976 (* 1 = 0.514976 loss)
I0428 02:37:30.579022 13425 solver.cpp:244]     Train net output #2: loss = 0.762292 (* 1 = 0.762292 loss)
I0428 02:37:30.579030 13425 sgd_solver.cpp:106] Iteration 30300, lr = 5e-06
I0428 02:39:10.233086 13425 solver.cpp:228] Iteration 30400, loss = 2.05391
I0428 02:39:10.233237 13425 solver.cpp:244]     Train net output #0: loss = 0.592511 (* 1 = 0.592511 loss)
I0428 02:39:10.233244 13425 solver.cpp:244]     Train net output #1: loss = 0.577857 (* 1 = 0.577857 loss)
I0428 02:39:10.233250 13425 solver.cpp:244]     Train net output #2: loss = 0.883542 (* 1 = 0.883542 loss)
I0428 02:39:10.233256 13425 sgd_solver.cpp:106] Iteration 30400, lr = 5e-06
I0428 02:40:49.928864 13425 solver.cpp:228] Iteration 30500, loss = 2.45599
I0428 02:40:49.929006 13425 solver.cpp:244]     Train net output #0: loss = 0.930512 (* 1 = 0.930512 loss)
I0428 02:40:49.929015 13425 solver.cpp:244]     Train net output #1: loss = 0.665678 (* 1 = 0.665678 loss)
I0428 02:40:49.929020 13425 solver.cpp:244]     Train net output #2: loss = 0.859795 (* 1 = 0.859795 loss)
I0428 02:40:49.929028 13425 sgd_solver.cpp:106] Iteration 30500, lr = 5e-06
I0428 02:42:29.697386 13425 solver.cpp:228] Iteration 30600, loss = 2.37468
I0428 02:42:29.698897 13425 solver.cpp:244]     Train net output #0: loss = 0.903007 (* 1 = 0.903007 loss)
I0428 02:42:29.698905 13425 solver.cpp:244]     Train net output #1: loss = 0.604028 (* 1 = 0.604028 loss)
I0428 02:42:29.698910 13425 solver.cpp:244]     Train net output #2: loss = 0.867642 (* 1 = 0.867642 loss)
I0428 02:42:29.698931 13425 sgd_solver.cpp:106] Iteration 30600, lr = 5e-06
I0428 02:44:07.832883 13425 solver.cpp:228] Iteration 30700, loss = 2.427
I0428 02:44:07.833056 13425 solver.cpp:244]     Train net output #0: loss = 0.957338 (* 1 = 0.957338 loss)
I0428 02:44:07.833065 13425 solver.cpp:244]     Train net output #1: loss = 0.564007 (* 1 = 0.564007 loss)
I0428 02:44:07.833070 13425 solver.cpp:244]     Train net output #2: loss = 0.905659 (* 1 = 0.905659 loss)
I0428 02:44:07.833076 13425 sgd_solver.cpp:106] Iteration 30700, lr = 5e-06
I0428 02:45:47.538398 13425 solver.cpp:228] Iteration 30800, loss = 2.6955
I0428 02:45:47.538585 13425 solver.cpp:244]     Train net output #0: loss = 0.971203 (* 1 = 0.971203 loss)
I0428 02:45:47.538594 13425 solver.cpp:244]     Train net output #1: loss = 0.788268 (* 1 = 0.788268 loss)
I0428 02:45:47.538599 13425 solver.cpp:244]     Train net output #2: loss = 0.93603 (* 1 = 0.93603 loss)
I0428 02:45:47.538605 13425 sgd_solver.cpp:106] Iteration 30800, lr = 5e-06
I0428 02:47:27.194041 13425 solver.cpp:228] Iteration 30900, loss = 2.48234
I0428 02:47:27.194193 13425 solver.cpp:244]     Train net output #0: loss = 0.988268 (* 1 = 0.988268 loss)
I0428 02:47:27.194202 13425 solver.cpp:244]     Train net output #1: loss = 0.7707 (* 1 = 0.7707 loss)
I0428 02:47:27.194208 13425 solver.cpp:244]     Train net output #2: loss = 0.723373 (* 1 = 0.723373 loss)
I0428 02:47:27.194213 13425 sgd_solver.cpp:106] Iteration 30900, lr = 5e-06
I0428 02:49:05.869128 13425 solver.cpp:337] Iteration 31000, Testing net (#0)
I0428 02:49:05.869298 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 02:49:05.869302 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 02:49:05.869307 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 02:49:05.869320 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 02:49:05.869324 13425 net.cpp:693] Ignoring source layer visualize
I0428 02:49:05.869328 13425 net.cpp:693] Ignoring source layer fake
I0428 02:52:38.932093 13425 solver.cpp:404]     Test net output #0: loss = 0.946233 (* 1 = 0.946233 loss)
I0428 02:52:38.932256 13425 solver.cpp:404]     Test net output #1: loss = 0.622358 (* 1 = 0.622358 loss)
I0428 02:52:38.932263 13425 solver.cpp:404]     Test net output #2: loss = 0.822898 (* 1 = 0.822898 loss)
I0428 02:52:39.586766 13425 solver.cpp:228] Iteration 31000, loss = 2.43648
I0428 02:52:39.586808 13425 solver.cpp:244]     Train net output #0: loss = 0.985073 (* 1 = 0.985073 loss)
I0428 02:52:39.586813 13425 solver.cpp:244]     Train net output #1: loss = 0.742973 (* 1 = 0.742973 loss)
I0428 02:52:39.586819 13425 solver.cpp:244]     Train net output #2: loss = 0.70843 (* 1 = 0.70843 loss)
I0428 02:52:39.586823 13425 sgd_solver.cpp:106] Iteration 31000, lr = 5e-06
I0428 02:54:17.659365 13425 solver.cpp:228] Iteration 31100, loss = 1.88116
I0428 02:54:17.660331 13425 solver.cpp:244]     Train net output #0: loss = 0.989354 (* 1 = 0.989354 loss)
I0428 02:54:17.660353 13425 solver.cpp:244]     Train net output #1: loss = 0.566502 (* 1 = 0.566502 loss)
I0428 02:54:17.660358 13425 solver.cpp:244]     Train net output #2: loss = 0.325308 (* 1 = 0.325308 loss)
I0428 02:54:17.660378 13425 sgd_solver.cpp:106] Iteration 31100, lr = 5e-06
I0428 02:55:57.154115 13425 solver.cpp:228] Iteration 31200, loss = 2.55595
I0428 02:55:57.154247 13425 solver.cpp:244]     Train net output #0: loss = 0.975803 (* 1 = 0.975803 loss)
I0428 02:55:57.154255 13425 solver.cpp:244]     Train net output #1: loss = 0.717399 (* 1 = 0.717399 loss)
I0428 02:55:57.154261 13425 solver.cpp:244]     Train net output #2: loss = 0.862746 (* 1 = 0.862746 loss)
I0428 02:55:57.154266 13425 sgd_solver.cpp:106] Iteration 31200, lr = 5e-06
I0428 02:57:36.300693 13425 solver.cpp:228] Iteration 31300, loss = 2.22541
I0428 02:57:36.300822 13425 solver.cpp:244]     Train net output #0: loss = 0.958538 (* 1 = 0.958538 loss)
I0428 02:57:36.300829 13425 solver.cpp:244]     Train net output #1: loss = 0.511327 (* 1 = 0.511327 loss)
I0428 02:57:36.300834 13425 solver.cpp:244]     Train net output #2: loss = 0.755549 (* 1 = 0.755549 loss)
I0428 02:57:36.300840 13425 sgd_solver.cpp:106] Iteration 31300, lr = 5e-06
I0428 02:59:15.486698 13425 solver.cpp:228] Iteration 31400, loss = 2.22062
I0428 02:59:15.486884 13425 solver.cpp:244]     Train net output #0: loss = 0.9656 (* 1 = 0.9656 loss)
I0428 02:59:15.486893 13425 solver.cpp:244]     Train net output #1: loss = 0.569381 (* 1 = 0.569381 loss)
I0428 02:59:15.486899 13425 solver.cpp:244]     Train net output #2: loss = 0.685642 (* 1 = 0.685642 loss)
I0428 02:59:15.486904 13425 sgd_solver.cpp:106] Iteration 31400, lr = 5e-06
I0428 03:00:54.897774 13425 solver.cpp:228] Iteration 31500, loss = 1.88845
I0428 03:00:54.897941 13425 solver.cpp:244]     Train net output #0: loss = 0.985633 (* 1 = 0.985633 loss)
I0428 03:00:54.897950 13425 solver.cpp:244]     Train net output #1: loss = 0.520975 (* 1 = 0.520975 loss)
I0428 03:00:54.897955 13425 solver.cpp:244]     Train net output #2: loss = 0.381841 (* 1 = 0.381841 loss)
I0428 03:00:54.897961 13425 sgd_solver.cpp:106] Iteration 31500, lr = 5e-06
I0428 03:02:34.479820 13425 solver.cpp:228] Iteration 31600, loss = 2.11058
I0428 03:02:34.479965 13425 solver.cpp:244]     Train net output #0: loss = 0.86555 (* 1 = 0.86555 loss)
I0428 03:02:34.479974 13425 solver.cpp:244]     Train net output #1: loss = 0.336187 (* 1 = 0.336187 loss)
I0428 03:02:34.479979 13425 solver.cpp:244]     Train net output #2: loss = 0.908845 (* 1 = 0.908845 loss)
I0428 03:02:34.479984 13425 sgd_solver.cpp:106] Iteration 31600, lr = 5e-06
I0428 03:04:14.220638 13425 solver.cpp:228] Iteration 31700, loss = 2.55475
I0428 03:04:14.221462 13425 solver.cpp:244]     Train net output #0: loss = 0.952647 (* 1 = 0.952647 loss)
I0428 03:04:14.221470 13425 solver.cpp:244]     Train net output #1: loss = 0.74578 (* 1 = 0.74578 loss)
I0428 03:04:14.221475 13425 solver.cpp:244]     Train net output #2: loss = 0.85632 (* 1 = 0.85632 loss)
I0428 03:04:14.221482 13425 sgd_solver.cpp:106] Iteration 31700, lr = 5e-06
I0428 03:05:52.339010 13425 solver.cpp:228] Iteration 31800, loss = 2.60198
I0428 03:05:52.339187 13425 solver.cpp:244]     Train net output #0: loss = 0.940195 (* 1 = 0.940195 loss)
I0428 03:05:52.339195 13425 solver.cpp:244]     Train net output #1: loss = 0.734214 (* 1 = 0.734214 loss)
I0428 03:05:52.339201 13425 solver.cpp:244]     Train net output #2: loss = 0.927572 (* 1 = 0.927572 loss)
I0428 03:05:52.339206 13425 sgd_solver.cpp:106] Iteration 31800, lr = 5e-06
I0428 03:07:32.083333 13425 solver.cpp:228] Iteration 31900, loss = 2.40048
I0428 03:07:32.083472 13425 solver.cpp:244]     Train net output #0: loss = 0.952426 (* 1 = 0.952426 loss)
I0428 03:07:32.083482 13425 solver.cpp:244]     Train net output #1: loss = 0.7263 (* 1 = 0.7263 loss)
I0428 03:07:32.083487 13425 solver.cpp:244]     Train net output #2: loss = 0.721751 (* 1 = 0.721751 loss)
I0428 03:07:32.083492 13425 sgd_solver.cpp:106] Iteration 31900, lr = 5e-06
I0428 03:09:10.825513 13425 solver.cpp:337] Iteration 32000, Testing net (#0)
I0428 03:09:10.825680 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 03:09:10.825685 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 03:09:10.825687 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 03:09:10.825702 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 03:09:10.825707 13425 net.cpp:693] Ignoring source layer visualize
I0428 03:09:10.825709 13425 net.cpp:693] Ignoring source layer fake
I0428 03:12:43.730794 13425 solver.cpp:404]     Test net output #0: loss = 0.943856 (* 1 = 0.943856 loss)
I0428 03:12:43.730953 13425 solver.cpp:404]     Test net output #1: loss = 0.613252 (* 1 = 0.613252 loss)
I0428 03:12:43.730962 13425 solver.cpp:404]     Test net output #2: loss = 0.821144 (* 1 = 0.821144 loss)
I0428 03:12:44.385996 13425 solver.cpp:228] Iteration 32000, loss = 2.63841
I0428 03:12:44.386021 13425 solver.cpp:244]     Train net output #0: loss = 0.952812 (* 1 = 0.952812 loss)
I0428 03:12:44.386026 13425 solver.cpp:244]     Train net output #1: loss = 0.760649 (* 1 = 0.760649 loss)
I0428 03:12:44.386031 13425 solver.cpp:244]     Train net output #2: loss = 0.924949 (* 1 = 0.924949 loss)
I0428 03:12:44.386035 13425 sgd_solver.cpp:106] Iteration 32000, lr = 5e-06
I0428 03:14:22.541321 13425 solver.cpp:228] Iteration 32100, loss = 2.39005
I0428 03:14:22.541532 13425 solver.cpp:244]     Train net output #0: loss = 0.955073 (* 1 = 0.955073 loss)
I0428 03:14:22.541541 13425 solver.cpp:244]     Train net output #1: loss = 0.553109 (* 1 = 0.553109 loss)
I0428 03:14:22.541546 13425 solver.cpp:244]     Train net output #2: loss = 0.881867 (* 1 = 0.881867 loss)
I0428 03:14:22.541551 13425 sgd_solver.cpp:106] Iteration 32100, lr = 5e-06
I0428 03:16:02.126181 13425 solver.cpp:228] Iteration 32200, loss = 2.51301
I0428 03:16:02.126358 13425 solver.cpp:244]     Train net output #0: loss = 0.984796 (* 1 = 0.984796 loss)
I0428 03:16:02.126365 13425 solver.cpp:244]     Train net output #1: loss = 0.752891 (* 1 = 0.752891 loss)
I0428 03:16:02.126371 13425 solver.cpp:244]     Train net output #2: loss = 0.775324 (* 1 = 0.775324 loss)
I0428 03:16:02.126376 13425 sgd_solver.cpp:106] Iteration 32200, lr = 5e-06
I0428 03:17:41.774716 13425 solver.cpp:228] Iteration 32300, loss = 2.38852
I0428 03:17:41.774868 13425 solver.cpp:244]     Train net output #0: loss = 0.977463 (* 1 = 0.977463 loss)
I0428 03:17:41.774874 13425 solver.cpp:244]     Train net output #1: loss = 0.697945 (* 1 = 0.697945 loss)
I0428 03:17:41.774880 13425 solver.cpp:244]     Train net output #2: loss = 0.713111 (* 1 = 0.713111 loss)
I0428 03:17:41.774888 13425 sgd_solver.cpp:106] Iteration 32300, lr = 5e-06
I0428 03:19:21.216969 13425 solver.cpp:228] Iteration 32400, loss = 2.11218
I0428 03:19:21.217140 13425 solver.cpp:244]     Train net output #0: loss = 0.945457 (* 1 = 0.945457 loss)
I0428 03:19:21.217147 13425 solver.cpp:244]     Train net output #1: loss = 0.396307 (* 1 = 0.396307 loss)
I0428 03:19:21.217154 13425 solver.cpp:244]     Train net output #2: loss = 0.770412 (* 1 = 0.770412 loss)
I0428 03:19:21.217159 13425 sgd_solver.cpp:106] Iteration 32400, lr = 5e-06
I0428 03:21:00.377879 13425 solver.cpp:228] Iteration 32500, loss = 2.30745
I0428 03:21:00.378021 13425 solver.cpp:244]     Train net output #0: loss = 0.95772 (* 1 = 0.95772 loss)
I0428 03:21:00.378028 13425 solver.cpp:244]     Train net output #1: loss = 0.40929 (* 1 = 0.40929 loss)
I0428 03:21:00.378034 13425 solver.cpp:244]     Train net output #2: loss = 0.940438 (* 1 = 0.940438 loss)
I0428 03:21:00.378039 13425 sgd_solver.cpp:106] Iteration 32500, lr = 5e-06
I0428 03:22:39.597190 13425 solver.cpp:228] Iteration 32600, loss = 2.29511
I0428 03:22:39.597369 13425 solver.cpp:244]     Train net output #0: loss = 0.936072 (* 1 = 0.936072 loss)
I0428 03:22:39.597378 13425 solver.cpp:244]     Train net output #1: loss = 0.605466 (* 1 = 0.605466 loss)
I0428 03:22:39.597383 13425 solver.cpp:244]     Train net output #2: loss = 0.753578 (* 1 = 0.753578 loss)
I0428 03:22:39.597389 13425 sgd_solver.cpp:106] Iteration 32600, lr = 5e-06
I0428 03:24:18.987833 13425 solver.cpp:228] Iteration 32700, loss = 2.27812
I0428 03:24:18.987990 13425 solver.cpp:244]     Train net output #0: loss = 0.963971 (* 1 = 0.963971 loss)
I0428 03:24:18.987998 13425 solver.cpp:244]     Train net output #1: loss = 0.556107 (* 1 = 0.556107 loss)
I0428 03:24:18.988003 13425 solver.cpp:244]     Train net output #2: loss = 0.758046 (* 1 = 0.758046 loss)
I0428 03:24:18.988010 13425 sgd_solver.cpp:106] Iteration 32700, lr = 5e-06
I0428 03:25:56.997293 13425 solver.cpp:228] Iteration 32800, loss = 2.37896
I0428 03:25:56.997496 13425 solver.cpp:244]     Train net output #0: loss = 0.974885 (* 1 = 0.974885 loss)
I0428 03:25:56.997509 13425 solver.cpp:244]     Train net output #1: loss = 0.648427 (* 1 = 0.648427 loss)
I0428 03:25:56.997519 13425 solver.cpp:244]     Train net output #2: loss = 0.755651 (* 1 = 0.755651 loss)
I0428 03:25:56.997526 13425 sgd_solver.cpp:106] Iteration 32800, lr = 5e-06
I0428 03:27:36.614805 13425 solver.cpp:228] Iteration 32900, loss = 2.21105
I0428 03:27:36.614948 13425 solver.cpp:244]     Train net output #0: loss = 0.888786 (* 1 = 0.888786 loss)
I0428 03:27:36.614958 13425 solver.cpp:244]     Train net output #1: loss = 0.752692 (* 1 = 0.752692 loss)
I0428 03:27:36.614964 13425 solver.cpp:244]     Train net output #2: loss = 0.569572 (* 1 = 0.569572 loss)
I0428 03:27:36.614969 13425 sgd_solver.cpp:106] Iteration 32900, lr = 5e-06
I0428 03:29:15.351156 13425 solver.cpp:337] Iteration 33000, Testing net (#0)
I0428 03:29:15.351341 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 03:29:15.351346 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 03:29:15.351349 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 03:29:15.351363 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 03:29:15.351366 13425 net.cpp:693] Ignoring source layer visualize
I0428 03:29:15.351368 13425 net.cpp:693] Ignoring source layer fake
I0428 03:32:48.453600 13425 solver.cpp:404]     Test net output #0: loss = 0.941867 (* 1 = 0.941867 loss)
I0428 03:32:48.453757 13425 solver.cpp:404]     Test net output #1: loss = 0.607802 (* 1 = 0.607802 loss)
I0428 03:32:48.453763 13425 solver.cpp:404]     Test net output #2: loss = 0.823976 (* 1 = 0.823976 loss)
I0428 03:32:49.112051 13425 solver.cpp:228] Iteration 33000, loss = 2.50697
I0428 03:32:49.112092 13425 solver.cpp:244]     Train net output #0: loss = 0.911409 (* 1 = 0.911409 loss)
I0428 03:32:49.112098 13425 solver.cpp:244]     Train net output #1: loss = 0.679621 (* 1 = 0.679621 loss)
I0428 03:32:49.112103 13425 solver.cpp:244]     Train net output #2: loss = 0.915944 (* 1 = 0.915944 loss)
I0428 03:32:49.112108 13425 sgd_solver.cpp:106] Iteration 33000, lr = 5e-06
I0428 03:34:28.904032 13425 solver.cpp:228] Iteration 33100, loss = 2.54223
I0428 03:34:28.904193 13425 solver.cpp:244]     Train net output #0: loss = 0.93724 (* 1 = 0.93724 loss)
I0428 03:34:28.904202 13425 solver.cpp:244]     Train net output #1: loss = 0.743114 (* 1 = 0.743114 loss)
I0428 03:34:28.904208 13425 solver.cpp:244]     Train net output #2: loss = 0.861878 (* 1 = 0.861878 loss)
I0428 03:34:28.904214 13425 sgd_solver.cpp:106] Iteration 33100, lr = 5e-06
I0428 03:36:07.051300 13425 solver.cpp:228] Iteration 33200, loss = 2.51225
I0428 03:36:07.051461 13425 solver.cpp:244]     Train net output #0: loss = 0.976778 (* 1 = 0.976778 loss)
I0428 03:36:07.051468 13425 solver.cpp:244]     Train net output #1: loss = 0.793251 (* 1 = 0.793251 loss)
I0428 03:36:07.051475 13425 solver.cpp:244]     Train net output #2: loss = 0.742218 (* 1 = 0.742218 loss)
I0428 03:36:07.051479 13425 sgd_solver.cpp:106] Iteration 33200, lr = 5e-06
I0428 03:37:46.731266 13425 solver.cpp:228] Iteration 33300, loss = 2.59427
I0428 03:37:46.731410 13425 solver.cpp:244]     Train net output #0: loss = 0.971265 (* 1 = 0.971265 loss)
I0428 03:37:46.731418 13425 solver.cpp:244]     Train net output #1: loss = 0.705695 (* 1 = 0.705695 loss)
I0428 03:37:46.731425 13425 solver.cpp:244]     Train net output #2: loss = 0.917311 (* 1 = 0.917311 loss)
I0428 03:37:46.731429 13425 sgd_solver.cpp:106] Iteration 33300, lr = 5e-06
I0428 03:39:26.369544 13425 solver.cpp:228] Iteration 33400, loss = 2.376
I0428 03:39:26.369727 13425 solver.cpp:244]     Train net output #0: loss = 0.986386 (* 1 = 0.986386 loss)
I0428 03:39:26.369738 13425 solver.cpp:244]     Train net output #1: loss = 0.616738 (* 1 = 0.616738 loss)
I0428 03:39:26.369747 13425 solver.cpp:244]     Train net output #2: loss = 0.772874 (* 1 = 0.772874 loss)
I0428 03:39:26.369755 13425 sgd_solver.cpp:106] Iteration 33400, lr = 5e-06
I0428 03:41:06.114405 13425 solver.cpp:228] Iteration 33500, loss = 2.22421
I0428 03:41:06.114573 13425 solver.cpp:244]     Train net output #0: loss = 0.978587 (* 1 = 0.978587 loss)
I0428 03:41:06.114583 13425 solver.cpp:244]     Train net output #1: loss = 0.673929 (* 1 = 0.673929 loss)
I0428 03:41:06.114588 13425 solver.cpp:244]     Train net output #2: loss = 0.571692 (* 1 = 0.571692 loss)
I0428 03:41:06.114593 13425 sgd_solver.cpp:106] Iteration 33500, lr = 5e-06
I0428 03:42:44.153471 13425 solver.cpp:228] Iteration 33600, loss = 2.17473
I0428 03:42:44.153640 13425 solver.cpp:244]     Train net output #0: loss = 0.979031 (* 1 = 0.979031 loss)
I0428 03:42:44.153646 13425 solver.cpp:244]     Train net output #1: loss = 0.649146 (* 1 = 0.649146 loss)
I0428 03:42:44.153652 13425 solver.cpp:244]     Train net output #2: loss = 0.546555 (* 1 = 0.546555 loss)
I0428 03:42:44.153657 13425 sgd_solver.cpp:106] Iteration 33600, lr = 5e-06
I0428 03:44:23.760077 13425 solver.cpp:228] Iteration 33700, loss = 2.52363
I0428 03:44:23.760278 13425 solver.cpp:244]     Train net output #0: loss = 0.984702 (* 1 = 0.984702 loss)
I0428 03:44:23.760287 13425 solver.cpp:244]     Train net output #1: loss = 0.710176 (* 1 = 0.710176 loss)
I0428 03:44:23.760291 13425 solver.cpp:244]     Train net output #2: loss = 0.828749 (* 1 = 0.828749 loss)
I0428 03:44:23.760298 13425 sgd_solver.cpp:106] Iteration 33700, lr = 5e-06
I0428 03:46:02.973875 13425 solver.cpp:228] Iteration 33800, loss = 2.27965
I0428 03:46:02.974026 13425 solver.cpp:244]     Train net output #0: loss = 0.964465 (* 1 = 0.964465 loss)
I0428 03:46:02.974035 13425 solver.cpp:244]     Train net output #1: loss = 0.55752 (* 1 = 0.55752 loss)
I0428 03:46:02.974040 13425 solver.cpp:244]     Train net output #2: loss = 0.757661 (* 1 = 0.757661 loss)
I0428 03:46:02.974045 13425 sgd_solver.cpp:106] Iteration 33800, lr = 5e-06
I0428 03:47:42.146330 13425 solver.cpp:228] Iteration 33900, loss = 2.36089
I0428 03:47:42.146482 13425 solver.cpp:244]     Train net output #0: loss = 0.9442 (* 1 = 0.9442 loss)
I0428 03:47:42.146492 13425 solver.cpp:244]     Train net output #1: loss = 0.539643 (* 1 = 0.539643 loss)
I0428 03:47:42.146497 13425 solver.cpp:244]     Train net output #2: loss = 0.877045 (* 1 = 0.877045 loss)
I0428 03:47:42.146502 13425 sgd_solver.cpp:106] Iteration 33900, lr = 5e-06
I0428 03:49:20.541904 13425 solver.cpp:337] Iteration 34000, Testing net (#0)
I0428 03:49:20.542048 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 03:49:20.542052 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 03:49:20.542055 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 03:49:20.542069 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 03:49:20.542074 13425 net.cpp:693] Ignoring source layer visualize
I0428 03:49:20.542076 13425 net.cpp:693] Ignoring source layer fake
I0428 03:52:53.285200 13425 solver.cpp:404]     Test net output #0: loss = 0.943968 (* 1 = 0.943968 loss)
I0428 03:52:53.285362 13425 solver.cpp:404]     Test net output #1: loss = 0.60815 (* 1 = 0.60815 loss)
I0428 03:52:53.285370 13425 solver.cpp:404]     Test net output #2: loss = 0.824094 (* 1 = 0.824094 loss)
I0428 03:52:53.938218 13425 solver.cpp:228] Iteration 34000, loss = 2.27351
I0428 03:52:53.938242 13425 solver.cpp:244]     Train net output #0: loss = 0.964979 (* 1 = 0.964979 loss)
I0428 03:52:53.938247 13425 solver.cpp:244]     Train net output #1: loss = 0.551143 (* 1 = 0.551143 loss)
I0428 03:52:53.938252 13425 solver.cpp:244]     Train net output #2: loss = 0.757388 (* 1 = 0.757388 loss)
I0428 03:52:53.938256 13425 sgd_solver.cpp:106] Iteration 34000, lr = 5e-06
I0428 03:54:33.596721 13425 solver.cpp:228] Iteration 34100, loss = 2.24358
I0428 03:54:33.596902 13425 solver.cpp:244]     Train net output #0: loss = 0.711797 (* 1 = 0.711797 loss)
I0428 03:54:33.596911 13425 solver.cpp:244]     Train net output #1: loss = 0.622877 (* 1 = 0.622877 loss)
I0428 03:54:33.596917 13425 solver.cpp:244]     Train net output #2: loss = 0.908901 (* 1 = 0.908901 loss)
I0428 03:54:33.596922 13425 sgd_solver.cpp:106] Iteration 34100, lr = 5e-06
I0428 03:56:13.292374 13425 solver.cpp:228] Iteration 34200, loss = 2.55695
I0428 03:56:13.292526 13425 solver.cpp:244]     Train net output #0: loss = 0.945439 (* 1 = 0.945439 loss)
I0428 03:56:13.292533 13425 solver.cpp:244]     Train net output #1: loss = 0.721483 (* 1 = 0.721483 loss)
I0428 03:56:13.292538 13425 solver.cpp:244]     Train net output #2: loss = 0.890032 (* 1 = 0.890032 loss)
I0428 03:56:13.292544 13425 sgd_solver.cpp:106] Iteration 34200, lr = 5e-06
I0428 03:57:51.376473 13425 solver.cpp:228] Iteration 34300, loss = 2.47246
I0428 03:57:51.376653 13425 solver.cpp:244]     Train net output #0: loss = 0.951423 (* 1 = 0.951423 loss)
I0428 03:57:51.376673 13425 solver.cpp:244]     Train net output #1: loss = 0.644561 (* 1 = 0.644561 loss)
I0428 03:57:51.376678 13425 solver.cpp:244]     Train net output #2: loss = 0.876472 (* 1 = 0.876472 loss)
I0428 03:57:51.376684 13425 sgd_solver.cpp:106] Iteration 34300, lr = 5e-06
I0428 03:59:31.154573 13425 solver.cpp:228] Iteration 34400, loss = 2.46921
I0428 03:59:31.154768 13425 solver.cpp:244]     Train net output #0: loss = 0.956553 (* 1 = 0.956553 loss)
I0428 03:59:31.154777 13425 solver.cpp:244]     Train net output #1: loss = 0.631041 (* 1 = 0.631041 loss)
I0428 03:59:31.154783 13425 solver.cpp:244]     Train net output #2: loss = 0.881621 (* 1 = 0.881621 loss)
I0428 03:59:31.154788 13425 sgd_solver.cpp:106] Iteration 34400, lr = 5e-06
I0428 04:01:10.913297 13425 solver.cpp:228] Iteration 34500, loss = 2.5516
I0428 04:01:10.913480 13425 solver.cpp:244]     Train net output #0: loss = 0.958385 (* 1 = 0.958385 loss)
I0428 04:01:10.913489 13425 solver.cpp:244]     Train net output #1: loss = 0.681861 (* 1 = 0.681861 loss)
I0428 04:01:10.913494 13425 solver.cpp:244]     Train net output #2: loss = 0.911353 (* 1 = 0.911353 loss)
I0428 04:01:10.913501 13425 sgd_solver.cpp:106] Iteration 34500, lr = 5e-06
I0428 04:02:49.086704 13425 solver.cpp:228] Iteration 34600, loss = 2.65509
I0428 04:02:49.086875 13425 solver.cpp:244]     Train net output #0: loss = 0.976426 (* 1 = 0.976426 loss)
I0428 04:02:49.086884 13425 solver.cpp:244]     Train net output #1: loss = 0.746539 (* 1 = 0.746539 loss)
I0428 04:02:49.086889 13425 solver.cpp:244]     Train net output #2: loss = 0.932122 (* 1 = 0.932122 loss)
I0428 04:02:49.086894 13425 sgd_solver.cpp:106] Iteration 34600, lr = 5e-06
I0428 04:04:28.731868 13425 solver.cpp:228] Iteration 34700, loss = 2.6507
I0428 04:04:28.732025 13425 solver.cpp:244]     Train net output #0: loss = 0.9829 (* 1 = 0.9829 loss)
I0428 04:04:28.732033 13425 solver.cpp:244]     Train net output #1: loss = 0.755125 (* 1 = 0.755125 loss)
I0428 04:04:28.732038 13425 solver.cpp:244]     Train net output #2: loss = 0.912678 (* 1 = 0.912678 loss)
I0428 04:04:28.732044 13425 sgd_solver.cpp:106] Iteration 34700, lr = 5e-06
I0428 04:06:08.403446 13425 solver.cpp:228] Iteration 34800, loss = 2.21329
I0428 04:06:08.403594 13425 solver.cpp:244]     Train net output #0: loss = 0.970359 (* 1 = 0.970359 loss)
I0428 04:06:08.403600 13425 solver.cpp:244]     Train net output #1: loss = 0.533342 (* 1 = 0.533342 loss)
I0428 04:06:08.403609 13425 solver.cpp:244]     Train net output #2: loss = 0.709587 (* 1 = 0.709587 loss)
I0428 04:06:08.403614 13425 sgd_solver.cpp:106] Iteration 34800, lr = 5e-06
I0428 04:07:47.904031 13425 solver.cpp:228] Iteration 34900, loss = 2.34228
I0428 04:07:47.904193 13425 solver.cpp:244]     Train net output #0: loss = 0.966925 (* 1 = 0.966925 loss)
I0428 04:07:47.904202 13425 solver.cpp:244]     Train net output #1: loss = 0.606688 (* 1 = 0.606688 loss)
I0428 04:07:47.904207 13425 solver.cpp:244]     Train net output #2: loss = 0.768663 (* 1 = 0.768663 loss)
I0428 04:07:47.904212 13425 sgd_solver.cpp:106] Iteration 34900, lr = 5e-06
I0428 04:09:26.094985 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_35000.caffemodel
I0428 04:09:26.783941 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_35000.solverstate
I0428 04:09:26.963556 13425 solver.cpp:337] Iteration 35000, Testing net (#0)
I0428 04:09:26.963580 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 04:09:26.963583 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 04:09:26.963587 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 04:09:26.963599 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 04:09:26.963601 13425 net.cpp:693] Ignoring source layer visualize
I0428 04:09:26.963603 13425 net.cpp:693] Ignoring source layer fake
I0428 04:12:59.410341 13425 solver.cpp:404]     Test net output #0: loss = 0.944719 (* 1 = 0.944719 loss)
I0428 04:12:59.410519 13425 solver.cpp:404]     Test net output #1: loss = 0.607221 (* 1 = 0.607221 loss)
I0428 04:12:59.410526 13425 solver.cpp:404]     Test net output #2: loss = 0.817057 (* 1 = 0.817057 loss)
I0428 04:13:00.063489 13425 solver.cpp:228] Iteration 35000, loss = 2.212
I0428 04:13:00.063513 13425 solver.cpp:244]     Train net output #0: loss = 0.929723 (* 1 = 0.929723 loss)
I0428 04:13:00.063519 13425 solver.cpp:244]     Train net output #1: loss = 0.517444 (* 1 = 0.517444 loss)
I0428 04:13:00.063524 13425 solver.cpp:244]     Train net output #2: loss = 0.764837 (* 1 = 0.764837 loss)
I0428 04:13:00.063527 13425 sgd_solver.cpp:106] Iteration 35000, lr = 5e-06
I0428 04:14:39.518930 13425 solver.cpp:228] Iteration 35100, loss = 2.3539
I0428 04:14:39.519106 13425 solver.cpp:244]     Train net output #0: loss = 0.944987 (* 1 = 0.944987 loss)
I0428 04:14:39.519114 13425 solver.cpp:244]     Train net output #1: loss = 0.464292 (* 1 = 0.464292 loss)
I0428 04:14:39.519120 13425 solver.cpp:244]     Train net output #2: loss = 0.944625 (* 1 = 0.944625 loss)
I0428 04:14:39.519126 13425 sgd_solver.cpp:106] Iteration 35100, lr = 5e-06
I0428 04:16:18.942256 13425 solver.cpp:228] Iteration 35200, loss = 2.70478
I0428 04:16:18.942402 13425 solver.cpp:244]     Train net output #0: loss = 0.973282 (* 1 = 0.973282 loss)
I0428 04:16:18.942410 13425 solver.cpp:244]     Train net output #1: loss = 0.775472 (* 1 = 0.775472 loss)
I0428 04:16:18.942417 13425 solver.cpp:244]     Train net output #2: loss = 0.956024 (* 1 = 0.956024 loss)
I0428 04:16:18.942422 13425 sgd_solver.cpp:106] Iteration 35200, lr = 5e-06
I0428 04:17:56.957376 13425 solver.cpp:228] Iteration 35300, loss = 2.33625
I0428 04:17:56.959110 13425 solver.cpp:244]     Train net output #0: loss = 0.973881 (* 1 = 0.973881 loss)
I0428 04:17:56.959120 13425 solver.cpp:244]     Train net output #1: loss = 0.604123 (* 1 = 0.604123 loss)
I0428 04:17:56.959125 13425 solver.cpp:244]     Train net output #2: loss = 0.758248 (* 1 = 0.758248 loss)
I0428 04:17:56.959130 13425 sgd_solver.cpp:106] Iteration 35300, lr = 5e-06
I0428 04:19:36.533017 13425 solver.cpp:228] Iteration 35400, loss = 2.25364
I0428 04:19:36.533229 13425 solver.cpp:244]     Train net output #0: loss = 0.920002 (* 1 = 0.920002 loss)
I0428 04:19:36.533237 13425 solver.cpp:244]     Train net output #1: loss = 0.749937 (* 1 = 0.749937 loss)
I0428 04:19:36.533242 13425 solver.cpp:244]     Train net output #2: loss = 0.583696 (* 1 = 0.583696 loss)
I0428 04:19:36.533248 13425 sgd_solver.cpp:106] Iteration 35400, lr = 5e-06
I0428 04:21:16.244575 13425 solver.cpp:228] Iteration 35500, loss = 2.57936
I0428 04:21:16.244756 13425 solver.cpp:244]     Train net output #0: loss = 0.943138 (* 1 = 0.943138 loss)
I0428 04:21:16.244765 13425 solver.cpp:244]     Train net output #1: loss = 0.738936 (* 1 = 0.738936 loss)
I0428 04:21:16.244771 13425 solver.cpp:244]     Train net output #2: loss = 0.897284 (* 1 = 0.897284 loss)
I0428 04:21:16.244777 13425 sgd_solver.cpp:106] Iteration 35500, lr = 5e-06
I0428 04:22:56.000519 13425 solver.cpp:228] Iteration 35600, loss = 2.57445
I0428 04:22:56.000653 13425 solver.cpp:244]     Train net output #0: loss = 0.941402 (* 1 = 0.941402 loss)
I0428 04:22:56.000660 13425 solver.cpp:244]     Train net output #1: loss = 0.752559 (* 1 = 0.752559 loss)
I0428 04:22:56.000666 13425 solver.cpp:244]     Train net output #2: loss = 0.880488 (* 1 = 0.880488 loss)
I0428 04:22:56.000672 13425 sgd_solver.cpp:106] Iteration 35600, lr = 5e-06
I0428 04:24:34.074919 13425 solver.cpp:228] Iteration 35700, loss = 2.3373
I0428 04:24:34.075096 13425 solver.cpp:244]     Train net output #0: loss = 0.967858 (* 1 = 0.967858 loss)
I0428 04:24:34.075104 13425 solver.cpp:244]     Train net output #1: loss = 0.653153 (* 1 = 0.653153 loss)
I0428 04:24:34.075110 13425 solver.cpp:244]     Train net output #2: loss = 0.716286 (* 1 = 0.716286 loss)
I0428 04:24:34.075115 13425 sgd_solver.cpp:106] Iteration 35700, lr = 5e-06
I0428 04:26:13.772488 13425 solver.cpp:228] Iteration 35800, loss = 2.57882
I0428 04:26:13.772931 13425 solver.cpp:244]     Train net output #0: loss = 0.975038 (* 1 = 0.975038 loss)
I0428 04:26:13.772938 13425 solver.cpp:244]     Train net output #1: loss = 0.695549 (* 1 = 0.695549 loss)
I0428 04:26:13.772958 13425 solver.cpp:244]     Train net output #2: loss = 0.90823 (* 1 = 0.90823 loss)
I0428 04:26:13.772964 13425 sgd_solver.cpp:106] Iteration 35800, lr = 5e-06
I0428 04:27:53.407508 13425 solver.cpp:228] Iteration 35900, loss = 2.48634
I0428 04:27:53.407699 13425 solver.cpp:244]     Train net output #0: loss = 0.979089 (* 1 = 0.979089 loss)
I0428 04:27:53.407707 13425 solver.cpp:244]     Train net output #1: loss = 0.741206 (* 1 = 0.741206 loss)
I0428 04:27:53.407712 13425 solver.cpp:244]     Train net output #2: loss = 0.766049 (* 1 = 0.766049 loss)
I0428 04:27:53.407718 13425 sgd_solver.cpp:106] Iteration 35900, lr = 5e-06
I0428 04:29:32.075649 13425 solver.cpp:337] Iteration 36000, Testing net (#0)
I0428 04:29:32.075806 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 04:29:32.075810 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 04:29:32.075815 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 04:29:32.075830 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 04:29:32.075834 13425 net.cpp:693] Ignoring source layer visualize
I0428 04:29:32.075835 13425 net.cpp:693] Ignoring source layer fake
I0428 04:33:05.023696 13425 solver.cpp:404]     Test net output #0: loss = 0.947916 (* 1 = 0.947916 loss)
I0428 04:33:05.023865 13425 solver.cpp:404]     Test net output #1: loss = 0.625115 (* 1 = 0.625115 loss)
I0428 04:33:05.023871 13425 solver.cpp:404]     Test net output #2: loss = 0.823435 (* 1 = 0.823435 loss)
I0428 04:33:05.674351 13425 solver.cpp:228] Iteration 36000, loss = 2.40724
I0428 04:33:05.674376 13425 solver.cpp:244]     Train net output #0: loss = 0.968906 (* 1 = 0.968906 loss)
I0428 04:33:05.674381 13425 solver.cpp:244]     Train net output #1: loss = 0.53236 (* 1 = 0.53236 loss)
I0428 04:33:05.674386 13425 solver.cpp:244]     Train net output #2: loss = 0.90597 (* 1 = 0.90597 loss)
I0428 04:33:05.674391 13425 sgd_solver.cpp:106] Iteration 36000, lr = 5e-06
I0428 04:34:43.772572 13425 solver.cpp:228] Iteration 36100, loss = 2.5451
I0428 04:34:43.772763 13425 solver.cpp:244]     Train net output #0: loss = 0.976941 (* 1 = 0.976941 loss)
I0428 04:34:43.772769 13425 solver.cpp:244]     Train net output #1: loss = 0.644511 (* 1 = 0.644511 loss)
I0428 04:34:43.772778 13425 solver.cpp:244]     Train net output #2: loss = 0.923645 (* 1 = 0.923645 loss)
I0428 04:34:43.772783 13425 sgd_solver.cpp:106] Iteration 36100, lr = 5e-06
I0428 04:36:23.272326 13425 solver.cpp:228] Iteration 36200, loss = 2.38598
I0428 04:36:23.272503 13425 solver.cpp:244]     Train net output #0: loss = 0.990122 (* 1 = 0.990122 loss)
I0428 04:36:23.272511 13425 solver.cpp:244]     Train net output #1: loss = 0.611227 (* 1 = 0.611227 loss)
I0428 04:36:23.272517 13425 solver.cpp:244]     Train net output #2: loss = 0.784636 (* 1 = 0.784636 loss)
I0428 04:36:23.272522 13425 sgd_solver.cpp:106] Iteration 36200, lr = 5e-06
I0428 04:38:02.448493 13425 solver.cpp:228] Iteration 36300, loss = 2.50606
I0428 04:38:02.448675 13425 solver.cpp:244]     Train net output #0: loss = 0.958084 (* 1 = 0.958084 loss)
I0428 04:38:02.448684 13425 solver.cpp:244]     Train net output #1: loss = 0.596592 (* 1 = 0.596592 loss)
I0428 04:38:02.448689 13425 solver.cpp:244]     Train net output #2: loss = 0.951388 (* 1 = 0.951388 loss)
I0428 04:38:02.448695 13425 sgd_solver.cpp:106] Iteration 36300, lr = 5e-06
I0428 04:39:41.657655 13425 solver.cpp:228] Iteration 36400, loss = 2.03267
I0428 04:39:41.657797 13425 solver.cpp:244]     Train net output #0: loss = 0.92319 (* 1 = 0.92319 loss)
I0428 04:39:41.657805 13425 solver.cpp:244]     Train net output #1: loss = 0.485281 (* 1 = 0.485281 loss)
I0428 04:39:41.657811 13425 solver.cpp:244]     Train net output #2: loss = 0.624198 (* 1 = 0.624198 loss)
I0428 04:39:41.657816 13425 sgd_solver.cpp:106] Iteration 36400, lr = 5e-06
I0428 04:41:21.045364 13425 solver.cpp:228] Iteration 36500, loss = 2.17302
I0428 04:41:21.045584 13425 solver.cpp:244]     Train net output #0: loss = 0.973505 (* 1 = 0.973505 loss)
I0428 04:41:21.045593 13425 solver.cpp:244]     Train net output #1: loss = 0.631142 (* 1 = 0.631142 loss)
I0428 04:41:21.045598 13425 solver.cpp:244]     Train net output #2: loss = 0.568377 (* 1 = 0.568377 loss)
I0428 04:41:21.045604 13425 sgd_solver.cpp:106] Iteration 36500, lr = 5e-06
I0428 04:43:00.635483 13425 solver.cpp:228] Iteration 36600, loss = 2.29815
I0428 04:43:00.635619 13425 solver.cpp:244]     Train net output #0: loss = 0.762973 (* 1 = 0.762973 loss)
I0428 04:43:00.635627 13425 solver.cpp:244]     Train net output #1: loss = 0.661294 (* 1 = 0.661294 loss)
I0428 04:43:00.635633 13425 solver.cpp:244]     Train net output #2: loss = 0.873884 (* 1 = 0.873884 loss)
I0428 04:43:00.635638 13425 sgd_solver.cpp:106] Iteration 36600, lr = 5e-06
I0428 04:44:40.340943 13425 solver.cpp:228] Iteration 36700, loss = 2.52367
I0428 04:44:40.341135 13425 solver.cpp:244]     Train net output #0: loss = 0.932778 (* 1 = 0.932778 loss)
I0428 04:44:40.341145 13425 solver.cpp:244]     Train net output #1: loss = 0.693628 (* 1 = 0.693628 loss)
I0428 04:44:40.341150 13425 solver.cpp:244]     Train net output #2: loss = 0.897262 (* 1 = 0.897262 loss)
I0428 04:44:40.341154 13425 sgd_solver.cpp:106] Iteration 36700, lr = 5e-06
I0428 04:46:18.405267 13425 solver.cpp:228] Iteration 36800, loss = 2.34919
I0428 04:46:18.405428 13425 solver.cpp:244]     Train net output #0: loss = 0.93797 (* 1 = 0.93797 loss)
I0428 04:46:18.405445 13425 solver.cpp:244]     Train net output #1: loss = 0.614567 (* 1 = 0.614567 loss)
I0428 04:46:18.405452 13425 solver.cpp:244]     Train net output #2: loss = 0.796649 (* 1 = 0.796649 loss)
I0428 04:46:18.405457 13425 sgd_solver.cpp:106] Iteration 36800, lr = 5e-06
I0428 04:47:58.131438 13425 solver.cpp:228] Iteration 36900, loss = 2.47533
I0428 04:47:58.131597 13425 solver.cpp:244]     Train net output #0: loss = 0.978301 (* 1 = 0.978301 loss)
I0428 04:47:58.131604 13425 solver.cpp:244]     Train net output #1: loss = 0.613367 (* 1 = 0.613367 loss)
I0428 04:47:58.131610 13425 solver.cpp:244]     Train net output #2: loss = 0.883663 (* 1 = 0.883663 loss)
I0428 04:47:58.131616 13425 sgd_solver.cpp:106] Iteration 36900, lr = 5e-06
I0428 04:49:36.845669 13425 solver.cpp:337] Iteration 37000, Testing net (#0)
I0428 04:49:36.845811 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 04:49:36.845815 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 04:49:36.845819 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 04:49:36.845834 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 04:49:36.845836 13425 net.cpp:693] Ignoring source layer visualize
I0428 04:49:36.845839 13425 net.cpp:693] Ignoring source layer fake
I0428 04:53:09.816920 13425 solver.cpp:404]     Test net output #0: loss = 0.945066 (* 1 = 0.945066 loss)
I0428 04:53:09.817067 13425 solver.cpp:404]     Test net output #1: loss = 0.616795 (* 1 = 0.616795 loss)
I0428 04:53:09.817075 13425 solver.cpp:404]     Test net output #2: loss = 0.822076 (* 1 = 0.822076 loss)
I0428 04:53:10.470101 13425 solver.cpp:228] Iteration 37000, loss = 2.48385
I0428 04:53:10.470127 13425 solver.cpp:244]     Train net output #0: loss = 0.971802 (* 1 = 0.971802 loss)
I0428 04:53:10.470132 13425 solver.cpp:244]     Train net output #1: loss = 0.65036 (* 1 = 0.65036 loss)
I0428 04:53:10.470136 13425 solver.cpp:244]     Train net output #2: loss = 0.861684 (* 1 = 0.861684 loss)
I0428 04:53:10.470141 13425 sgd_solver.cpp:106] Iteration 37000, lr = 5e-06
I0428 04:54:48.646972 13425 solver.cpp:228] Iteration 37100, loss = 2.71728
I0428 04:54:48.647121 13425 solver.cpp:244]     Train net output #0: loss = 0.982386 (* 1 = 0.982386 loss)
I0428 04:54:48.647128 13425 solver.cpp:244]     Train net output #1: loss = 0.809921 (* 1 = 0.809921 loss)
I0428 04:54:48.647135 13425 solver.cpp:244]     Train net output #2: loss = 0.924974 (* 1 = 0.924974 loss)
I0428 04:54:48.647140 13425 sgd_solver.cpp:106] Iteration 37100, lr = 5e-06
I0428 04:56:28.277411 13425 solver.cpp:228] Iteration 37200, loss = 2.55355
I0428 04:56:28.277593 13425 solver.cpp:244]     Train net output #0: loss = 0.98863 (* 1 = 0.98863 loss)
I0428 04:56:28.277602 13425 solver.cpp:244]     Train net output #1: loss = 0.654146 (* 1 = 0.654146 loss)
I0428 04:56:28.277608 13425 solver.cpp:244]     Train net output #2: loss = 0.910774 (* 1 = 0.910774 loss)
I0428 04:56:28.277613 13425 sgd_solver.cpp:106] Iteration 37200, lr = 5e-06
I0428 04:58:07.897364 13425 solver.cpp:228] Iteration 37300, loss = 2.20081
I0428 04:58:07.897523 13425 solver.cpp:244]     Train net output #0: loss = 0.973273 (* 1 = 0.973273 loss)
I0428 04:58:07.897532 13425 solver.cpp:244]     Train net output #1: loss = 0.632983 (* 1 = 0.632983 loss)
I0428 04:58:07.897537 13425 solver.cpp:244]     Train net output #2: loss = 0.594554 (* 1 = 0.594554 loss)
I0428 04:58:07.897543 13425 sgd_solver.cpp:106] Iteration 37300, lr = 5e-06
I0428 04:59:47.394896 13425 solver.cpp:228] Iteration 37400, loss = 2.32706
I0428 04:59:47.395072 13425 solver.cpp:244]     Train net output #0: loss = 0.975805 (* 1 = 0.975805 loss)
I0428 04:59:47.395083 13425 solver.cpp:244]     Train net output #1: loss = 0.602716 (* 1 = 0.602716 loss)
I0428 04:59:47.395092 13425 solver.cpp:244]     Train net output #2: loss = 0.748538 (* 1 = 0.748538 loss)
I0428 04:59:47.395098 13425 sgd_solver.cpp:106] Iteration 37400, lr = 5e-06
I0428 05:01:26.540151 13425 solver.cpp:228] Iteration 37500, loss = 2.22218
I0428 05:01:26.540334 13425 solver.cpp:244]     Train net output #0: loss = 0.943763 (* 1 = 0.943763 loss)
I0428 05:01:26.540343 13425 solver.cpp:244]     Train net output #1: loss = 0.511073 (* 1 = 0.511073 loss)
I0428 05:01:26.540349 13425 solver.cpp:244]     Train net output #2: loss = 0.767344 (* 1 = 0.767344 loss)
I0428 05:01:26.540354 13425 sgd_solver.cpp:106] Iteration 37500, lr = 5e-06
I0428 05:03:05.811758 13425 solver.cpp:228] Iteration 37600, loss = 2.18208
I0428 05:03:05.811933 13425 solver.cpp:244]     Train net output #0: loss = 0.956387 (* 1 = 0.956387 loss)
I0428 05:03:05.811940 13425 solver.cpp:244]     Train net output #1: loss = 0.466422 (* 1 = 0.466422 loss)
I0428 05:03:05.811946 13425 solver.cpp:244]     Train net output #2: loss = 0.759267 (* 1 = 0.759267 loss)
I0428 05:03:05.811951 13425 sgd_solver.cpp:106] Iteration 37600, lr = 5e-06
I0428 05:04:45.280953 13425 solver.cpp:228] Iteration 37700, loss = 2.1011
I0428 05:04:45.281133 13425 solver.cpp:244]     Train net output #0: loss = 0.982927 (* 1 = 0.982927 loss)
I0428 05:04:45.281142 13425 solver.cpp:244]     Train net output #1: loss = 0.542216 (* 1 = 0.542216 loss)
I0428 05:04:45.281148 13425 solver.cpp:244]     Train net output #2: loss = 0.57596 (* 1 = 0.57596 loss)
I0428 05:04:45.281153 13425 sgd_solver.cpp:106] Iteration 37700, lr = 5e-06
I0428 05:06:23.310274 13425 solver.cpp:228] Iteration 37800, loss = 2.37342
I0428 05:06:23.310407 13425 solver.cpp:244]     Train net output #0: loss = 0.97524 (* 1 = 0.97524 loss)
I0428 05:06:23.310415 13425 solver.cpp:244]     Train net output #1: loss = 0.637233 (* 1 = 0.637233 loss)
I0428 05:06:23.310420 13425 solver.cpp:244]     Train net output #2: loss = 0.760948 (* 1 = 0.760948 loss)
I0428 05:06:23.310425 13425 sgd_solver.cpp:106] Iteration 37800, lr = 5e-06
I0428 05:08:02.947592 13425 solver.cpp:228] Iteration 37900, loss = 2.34325
I0428 05:08:02.947741 13425 solver.cpp:244]     Train net output #0: loss = 0.779678 (* 1 = 0.779678 loss)
I0428 05:08:02.947748 13425 solver.cpp:244]     Train net output #1: loss = 0.705914 (* 1 = 0.705914 loss)
I0428 05:08:02.947753 13425 solver.cpp:244]     Train net output #2: loss = 0.857661 (* 1 = 0.857661 loss)
I0428 05:08:02.947759 13425 sgd_solver.cpp:106] Iteration 37900, lr = 5e-06
I0428 05:09:41.711894 13425 solver.cpp:337] Iteration 38000, Testing net (#0)
I0428 05:09:41.712072 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 05:09:41.712076 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 05:09:41.712080 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 05:09:41.712095 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 05:09:41.712097 13425 net.cpp:693] Ignoring source layer visualize
I0428 05:09:41.712100 13425 net.cpp:693] Ignoring source layer fake
I0428 05:13:14.872829 13425 solver.cpp:404]     Test net output #0: loss = 0.941478 (* 1 = 0.941478 loss)
I0428 05:13:14.873010 13425 solver.cpp:404]     Test net output #1: loss = 0.60709 (* 1 = 0.60709 loss)
I0428 05:13:14.873021 13425 solver.cpp:404]     Test net output #2: loss = 0.82321 (* 1 = 0.82321 loss)
I0428 05:13:15.529124 13425 solver.cpp:228] Iteration 38000, loss = 2.50267
I0428 05:13:15.529151 13425 solver.cpp:244]     Train net output #0: loss = 0.940595 (* 1 = 0.940595 loss)
I0428 05:13:15.529156 13425 solver.cpp:244]     Train net output #1: loss = 0.6563 (* 1 = 0.6563 loss)
I0428 05:13:15.529160 13425 solver.cpp:244]     Train net output #2: loss = 0.905776 (* 1 = 0.905776 loss)
I0428 05:13:15.529165 13425 sgd_solver.cpp:106] Iteration 38000, lr = 5e-06
I0428 05:14:55.362347 13425 solver.cpp:228] Iteration 38100, loss = 2.54061
I0428 05:14:55.362534 13425 solver.cpp:244]     Train net output #0: loss = 0.944481 (* 1 = 0.944481 loss)
I0428 05:14:55.362541 13425 solver.cpp:244]     Train net output #1: loss = 0.717132 (* 1 = 0.717132 loss)
I0428 05:14:55.362546 13425 solver.cpp:244]     Train net output #2: loss = 0.878998 (* 1 = 0.878998 loss)
I0428 05:14:55.362553 13425 sgd_solver.cpp:106] Iteration 38100, lr = 5e-06
I0428 05:16:33.452129 13425 solver.cpp:228] Iteration 38200, loss = 2.46393
I0428 05:16:33.452280 13425 solver.cpp:244]     Train net output #0: loss = 0.968046 (* 1 = 0.968046 loss)
I0428 05:16:33.452287 13425 solver.cpp:244]     Train net output #1: loss = 0.593359 (* 1 = 0.593359 loss)
I0428 05:16:33.452294 13425 solver.cpp:244]     Train net output #2: loss = 0.902521 (* 1 = 0.902521 loss)
I0428 05:16:33.452299 13425 sgd_solver.cpp:106] Iteration 38200, lr = 5e-06
I0428 05:18:13.129819 13425 solver.cpp:228] Iteration 38300, loss = 2.66686
I0428 05:18:13.129979 13425 solver.cpp:244]     Train net output #0: loss = 0.975863 (* 1 = 0.975863 loss)
I0428 05:18:13.129988 13425 solver.cpp:244]     Train net output #1: loss = 0.759359 (* 1 = 0.759359 loss)
I0428 05:18:13.129993 13425 solver.cpp:244]     Train net output #2: loss = 0.931637 (* 1 = 0.931637 loss)
I0428 05:18:13.129999 13425 sgd_solver.cpp:106] Iteration 38300, lr = 5e-06
I0428 05:19:52.783502 13425 solver.cpp:228] Iteration 38400, loss = 2.6836
I0428 05:19:52.783677 13425 solver.cpp:244]     Train net output #0: loss = 0.98629 (* 1 = 0.98629 loss)
I0428 05:19:52.783685 13425 solver.cpp:244]     Train net output #1: loss = 0.789557 (* 1 = 0.789557 loss)
I0428 05:19:52.783691 13425 solver.cpp:244]     Train net output #2: loss = 0.907753 (* 1 = 0.907753 loss)
I0428 05:19:52.783696 13425 sgd_solver.cpp:106] Iteration 38400, lr = 5e-06
I0428 05:21:32.404588 13425 solver.cpp:228] Iteration 38500, loss = 2.3403
I0428 05:21:32.404726 13425 solver.cpp:244]     Train net output #0: loss = 0.980383 (* 1 = 0.980383 loss)
I0428 05:21:32.404734 13425 solver.cpp:244]     Train net output #1: loss = 0.628062 (* 1 = 0.628062 loss)
I0428 05:21:32.404739 13425 solver.cpp:244]     Train net output #2: loss = 0.731858 (* 1 = 0.731858 loss)
I0428 05:21:32.404745 13425 sgd_solver.cpp:106] Iteration 38500, lr = 5e-06
I0428 05:23:10.492879 13425 solver.cpp:228] Iteration 38600, loss = 2.13911
I0428 05:23:10.493069 13425 solver.cpp:244]     Train net output #0: loss = 0.987597 (* 1 = 0.987597 loss)
I0428 05:23:10.493077 13425 solver.cpp:244]     Train net output #1: loss = 0.582059 (* 1 = 0.582059 loss)
I0428 05:23:10.493083 13425 solver.cpp:244]     Train net output #2: loss = 0.56945 (* 1 = 0.56945 loss)
I0428 05:23:10.493089 13425 sgd_solver.cpp:106] Iteration 38600, lr = 5e-06
I0428 05:24:49.969413 13425 solver.cpp:228] Iteration 38700, loss = 2.34863
I0428 05:24:49.969583 13425 solver.cpp:244]     Train net output #0: loss = 0.982532 (* 1 = 0.982532 loss)
I0428 05:24:49.969593 13425 solver.cpp:244]     Train net output #1: loss = 0.52053 (* 1 = 0.52053 loss)
I0428 05:24:49.969599 13425 solver.cpp:244]     Train net output #2: loss = 0.845573 (* 1 = 0.845573 loss)
I0428 05:24:49.969604 13425 sgd_solver.cpp:106] Iteration 38700, lr = 5e-06
I0428 05:26:29.155220 13425 solver.cpp:228] Iteration 38800, loss = 2.22903
I0428 05:26:29.155436 13425 solver.cpp:244]     Train net output #0: loss = 0.962391 (* 1 = 0.962391 loss)
I0428 05:26:29.155443 13425 solver.cpp:244]     Train net output #1: loss = 0.516655 (* 1 = 0.516655 loss)
I0428 05:26:29.155449 13425 solver.cpp:244]     Train net output #2: loss = 0.749983 (* 1 = 0.749983 loss)
I0428 05:26:29.155455 13425 sgd_solver.cpp:106] Iteration 38800, lr = 5e-06
I0428 05:28:08.572585 13425 solver.cpp:228] Iteration 38900, loss = 2.03116
I0428 05:28:08.572791 13425 solver.cpp:244]     Train net output #0: loss = 0.964083 (* 1 = 0.964083 loss)
I0428 05:28:08.572799 13425 solver.cpp:244]     Train net output #1: loss = 0.466654 (* 1 = 0.466654 loss)
I0428 05:28:08.572804 13425 solver.cpp:244]     Train net output #2: loss = 0.600424 (* 1 = 0.600424 loss)
I0428 05:28:08.572811 13425 sgd_solver.cpp:106] Iteration 38900, lr = 5e-06
I0428 05:29:46.936728 13425 solver.cpp:337] Iteration 39000, Testing net (#0)
I0428 05:29:46.936859 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 05:29:46.936863 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 05:29:46.936867 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 05:29:46.936882 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 05:29:46.936884 13425 net.cpp:693] Ignoring source layer visualize
I0428 05:29:46.936887 13425 net.cpp:693] Ignoring source layer fake
I0428 05:33:19.489363 13425 solver.cpp:404]     Test net output #0: loss = 0.944005 (* 1 = 0.944005 loss)
I0428 05:33:19.489531 13425 solver.cpp:404]     Test net output #1: loss = 0.612317 (* 1 = 0.612317 loss)
I0428 05:33:19.489538 13425 solver.cpp:404]     Test net output #2: loss = 0.825923 (* 1 = 0.825923 loss)
I0428 05:33:20.141240 13425 solver.cpp:228] Iteration 39000, loss = 2.44539
I0428 05:33:20.141266 13425 solver.cpp:244]     Train net output #0: loss = 0.98098 (* 1 = 0.98098 loss)
I0428 05:33:20.141271 13425 solver.cpp:244]     Train net output #1: loss = 0.711129 (* 1 = 0.711129 loss)
I0428 05:33:20.141276 13425 solver.cpp:244]     Train net output #2: loss = 0.753281 (* 1 = 0.753281 loss)
I0428 05:33:20.141280 13425 sgd_solver.cpp:106] Iteration 39000, lr = 5e-06
I0428 05:34:59.783550 13425 solver.cpp:228] Iteration 39100, loss = 2.22875
I0428 05:34:59.783680 13425 solver.cpp:244]     Train net output #0: loss = 0.858837 (* 1 = 0.858837 loss)
I0428 05:34:59.783689 13425 solver.cpp:244]     Train net output #1: loss = 0.719802 (* 1 = 0.719802 loss)
I0428 05:34:59.783694 13425 solver.cpp:244]     Train net output #2: loss = 0.650111 (* 1 = 0.650111 loss)
I0428 05:34:59.783699 13425 sgd_solver.cpp:106] Iteration 39100, lr = 5e-06
I0428 05:36:39.454483 13425 solver.cpp:228] Iteration 39200, loss = 2.64967
I0428 05:36:39.454658 13425 solver.cpp:244]     Train net output #0: loss = 0.944766 (* 1 = 0.944766 loss)
I0428 05:36:39.454666 13425 solver.cpp:244]     Train net output #1: loss = 0.80029 (* 1 = 0.80029 loss)
I0428 05:36:39.454672 13425 solver.cpp:244]     Train net output #2: loss = 0.904611 (* 1 = 0.904611 loss)
I0428 05:36:39.454687 13425 sgd_solver.cpp:106] Iteration 39200, lr = 5e-06
I0428 05:38:17.542140 13425 solver.cpp:228] Iteration 39300, loss = 2.53547
I0428 05:38:17.542291 13425 solver.cpp:244]     Train net output #0: loss = 0.963387 (* 1 = 0.963387 loss)
I0428 05:38:17.542299 13425 solver.cpp:244]     Train net output #1: loss = 0.747313 (* 1 = 0.747313 loss)
I0428 05:38:17.542305 13425 solver.cpp:244]     Train net output #2: loss = 0.824769 (* 1 = 0.824769 loss)
I0428 05:38:17.542310 13425 sgd_solver.cpp:106] Iteration 39300, lr = 5e-06
I0428 05:39:57.260917 13425 solver.cpp:228] Iteration 39400, loss = 2.65216
I0428 05:39:57.261068 13425 solver.cpp:244]     Train net output #0: loss = 0.980449 (* 1 = 0.980449 loss)
I0428 05:39:57.261076 13425 solver.cpp:244]     Train net output #1: loss = 0.760812 (* 1 = 0.760812 loss)
I0428 05:39:57.261081 13425 solver.cpp:244]     Train net output #2: loss = 0.910897 (* 1 = 0.910897 loss)
I0428 05:39:57.261086 13425 sgd_solver.cpp:106] Iteration 39400, lr = 5e-06
I0428 05:41:36.959300 13425 solver.cpp:228] Iteration 39500, loss = 2.6687
I0428 05:41:36.959480 13425 solver.cpp:244]     Train net output #0: loss = 0.972196 (* 1 = 0.972196 loss)
I0428 05:41:36.959488 13425 solver.cpp:244]     Train net output #1: loss = 0.768503 (* 1 = 0.768503 loss)
I0428 05:41:36.959493 13425 solver.cpp:244]     Train net output #2: loss = 0.928003 (* 1 = 0.928003 loss)
I0428 05:41:36.959501 13425 sgd_solver.cpp:106] Iteration 39500, lr = 5e-06
I0428 05:43:15.081651 13425 solver.cpp:228] Iteration 39600, loss = 2.68743
I0428 05:43:15.081825 13425 solver.cpp:244]     Train net output #0: loss = 0.968436 (* 1 = 0.968436 loss)
I0428 05:43:15.081833 13425 solver.cpp:244]     Train net output #1: loss = 0.785379 (* 1 = 0.785379 loss)
I0428 05:43:15.081840 13425 solver.cpp:244]     Train net output #2: loss = 0.933616 (* 1 = 0.933616 loss)
I0428 05:43:15.081845 13425 sgd_solver.cpp:106] Iteration 39600, lr = 5e-06
I0428 05:44:54.685355 13425 solver.cpp:228] Iteration 39700, loss = 2.35045
I0428 05:44:54.685711 13425 solver.cpp:244]     Train net output #0: loss = 0.989035 (* 1 = 0.989035 loss)
I0428 05:44:54.685720 13425 solver.cpp:244]     Train net output #1: loss = 0.603296 (* 1 = 0.603296 loss)
I0428 05:44:54.685725 13425 solver.cpp:244]     Train net output #2: loss = 0.758118 (* 1 = 0.758118 loss)
I0428 05:44:54.685731 13425 sgd_solver.cpp:106] Iteration 39700, lr = 5e-06
I0428 05:46:34.369036 13425 solver.cpp:228] Iteration 39800, loss = 2.35478
I0428 05:46:34.369207 13425 solver.cpp:244]     Train net output #0: loss = 0.963362 (* 1 = 0.963362 loss)
I0428 05:46:34.369215 13425 solver.cpp:244]     Train net output #1: loss = 0.627352 (* 1 = 0.627352 loss)
I0428 05:46:34.369221 13425 solver.cpp:244]     Train net output #2: loss = 0.764062 (* 1 = 0.764062 loss)
I0428 05:46:34.369227 13425 sgd_solver.cpp:106] Iteration 39800, lr = 5e-06
I0428 05:48:13.880110 13425 solver.cpp:228] Iteration 39900, loss = 2.22596
I0428 05:48:13.880244 13425 solver.cpp:244]     Train net output #0: loss = 0.939726 (* 1 = 0.939726 loss)
I0428 05:48:13.880251 13425 solver.cpp:244]     Train net output #1: loss = 0.468305 (* 1 = 0.468305 loss)
I0428 05:48:13.880257 13425 solver.cpp:244]     Train net output #2: loss = 0.817933 (* 1 = 0.817933 loss)
I0428 05:48:13.880264 13425 sgd_solver.cpp:106] Iteration 39900, lr = 5e-06
I0428 05:49:52.168948 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_40000.caffemodel
I0428 05:49:52.867101 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_40000.solverstate
I0428 05:49:53.054088 13425 solver.cpp:337] Iteration 40000, Testing net (#0)
I0428 05:49:53.054127 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 05:49:53.054129 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 05:49:53.054133 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 05:49:53.054146 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 05:49:53.054149 13425 net.cpp:693] Ignoring source layer visualize
I0428 05:49:53.054150 13425 net.cpp:693] Ignoring source layer fake
I0428 05:53:26.019407 13425 solver.cpp:404]     Test net output #0: loss = 0.944289 (* 1 = 0.944289 loss)
I0428 05:53:26.019529 13425 solver.cpp:404]     Test net output #1: loss = 0.61126 (* 1 = 0.61126 loss)
I0428 05:53:26.019537 13425 solver.cpp:404]     Test net output #2: loss = 0.817985 (* 1 = 0.817985 loss)
I0428 05:53:26.672272 13425 solver.cpp:228] Iteration 40000, loss = 2.5316
I0428 05:53:26.672297 13425 solver.cpp:244]     Train net output #0: loss = 0.93286 (* 1 = 0.93286 loss)
I0428 05:53:26.672302 13425 solver.cpp:244]     Train net output #1: loss = 0.634685 (* 1 = 0.634685 loss)
I0428 05:53:26.672307 13425 solver.cpp:244]     Train net output #2: loss = 0.964052 (* 1 = 0.964052 loss)
I0428 05:53:26.672312 13425 sgd_solver.cpp:106] Iteration 40000, lr = 5e-07
I0428 05:55:05.947974 13425 solver.cpp:228] Iteration 40100, loss = 2.59134
I0428 05:55:05.948163 13425 solver.cpp:244]     Train net output #0: loss = 0.959456 (* 1 = 0.959456 loss)
I0428 05:55:05.948171 13425 solver.cpp:244]     Train net output #1: loss = 0.698525 (* 1 = 0.698525 loss)
I0428 05:55:05.948176 13425 solver.cpp:244]     Train net output #2: loss = 0.933356 (* 1 = 0.933356 loss)
I0428 05:55:05.948182 13425 sgd_solver.cpp:106] Iteration 40100, lr = 5e-07
I0428 05:56:45.316838 13425 solver.cpp:228] Iteration 40200, loss = 2.45226
I0428 05:56:45.316987 13425 solver.cpp:244]     Train net output #0: loss = 0.97837 (* 1 = 0.97837 loss)
I0428 05:56:45.316994 13425 solver.cpp:244]     Train net output #1: loss = 0.707213 (* 1 = 0.707213 loss)
I0428 05:56:45.317000 13425 solver.cpp:244]     Train net output #2: loss = 0.766673 (* 1 = 0.766673 loss)
I0428 05:56:45.317005 13425 sgd_solver.cpp:106] Iteration 40200, lr = 5e-07
I0428 05:58:23.335017 13425 solver.cpp:228] Iteration 40300, loss = 2.54086
I0428 05:58:23.335170 13425 solver.cpp:244]     Train net output #0: loss = 0.95036 (* 1 = 0.95036 loss)
I0428 05:58:23.335178 13425 solver.cpp:244]     Train net output #1: loss = 0.641772 (* 1 = 0.641772 loss)
I0428 05:58:23.335183 13425 solver.cpp:244]     Train net output #2: loss = 0.948733 (* 1 = 0.948733 loss)
I0428 05:58:23.335188 13425 sgd_solver.cpp:106] Iteration 40300, lr = 5e-07
I0428 06:00:02.956480 13425 solver.cpp:228] Iteration 40400, loss = 2.43128
I0428 06:00:02.956645 13425 solver.cpp:244]     Train net output #0: loss = 0.885614 (* 1 = 0.885614 loss)
I0428 06:00:02.956653 13425 solver.cpp:244]     Train net output #1: loss = 0.73119 (* 1 = 0.73119 loss)
I0428 06:00:02.956660 13425 solver.cpp:244]     Train net output #2: loss = 0.814476 (* 1 = 0.814476 loss)
I0428 06:00:02.956665 13425 sgd_solver.cpp:106] Iteration 40400, lr = 5e-07
I0428 06:01:42.663465 13425 solver.cpp:228] Iteration 40500, loss = 2.55009
I0428 06:01:42.664814 13425 solver.cpp:244]     Train net output #0: loss = 0.954238 (* 1 = 0.954238 loss)
I0428 06:01:42.664824 13425 solver.cpp:244]     Train net output #1: loss = 0.695877 (* 1 = 0.695877 loss)
I0428 06:01:42.664829 13425 solver.cpp:244]     Train net output #2: loss = 0.899978 (* 1 = 0.899978 loss)
I0428 06:01:42.664834 13425 sgd_solver.cpp:106] Iteration 40500, lr = 5e-07
I0428 06:03:22.386890 13425 solver.cpp:228] Iteration 40600, loss = 2.65062
I0428 06:03:22.387064 13425 solver.cpp:244]     Train net output #0: loss = 0.96711 (* 1 = 0.96711 loss)
I0428 06:03:22.387075 13425 solver.cpp:244]     Train net output #1: loss = 0.796717 (* 1 = 0.796717 loss)
I0428 06:03:22.387084 13425 solver.cpp:244]     Train net output #2: loss = 0.88679 (* 1 = 0.88679 loss)
I0428 06:03:22.387091 13425 sgd_solver.cpp:106] Iteration 40600, lr = 5e-07
I0428 06:05:00.487731 13425 solver.cpp:228] Iteration 40700, loss = 2.65006
I0428 06:05:00.488981 13425 solver.cpp:244]     Train net output #0: loss = 0.978091 (* 1 = 0.978091 loss)
I0428 06:05:00.488987 13425 solver.cpp:244]     Train net output #1: loss = 0.744197 (* 1 = 0.744197 loss)
I0428 06:05:00.488992 13425 solver.cpp:244]     Train net output #2: loss = 0.92777 (* 1 = 0.92777 loss)
I0428 06:05:00.488999 13425 sgd_solver.cpp:106] Iteration 40700, lr = 5e-07
I0428 06:06:40.158810 13425 solver.cpp:228] Iteration 40800, loss = 2.64468
I0428 06:06:40.158954 13425 solver.cpp:244]     Train net output #0: loss = 0.983691 (* 1 = 0.983691 loss)
I0428 06:06:40.158962 13425 solver.cpp:244]     Train net output #1: loss = 0.766191 (* 1 = 0.766191 loss)
I0428 06:06:40.158969 13425 solver.cpp:244]     Train net output #2: loss = 0.894796 (* 1 = 0.894796 loss)
I0428 06:06:40.158974 13425 sgd_solver.cpp:106] Iteration 40800, lr = 5e-07
I0428 06:08:19.825780 13425 solver.cpp:228] Iteration 40900, loss = 2.57105
I0428 06:08:19.825912 13425 solver.cpp:244]     Train net output #0: loss = 0.981535 (* 1 = 0.981535 loss)
I0428 06:08:19.825920 13425 solver.cpp:244]     Train net output #1: loss = 0.6739 (* 1 = 0.6739 loss)
I0428 06:08:19.825927 13425 solver.cpp:244]     Train net output #2: loss = 0.915613 (* 1 = 0.915613 loss)
I0428 06:08:19.825932 13425 sgd_solver.cpp:106] Iteration 40900, lr = 5e-07
I0428 06:09:58.458820 13425 solver.cpp:337] Iteration 41000, Testing net (#0)
I0428 06:09:58.458998 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 06:09:58.459002 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 06:09:58.459007 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 06:09:58.459020 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 06:09:58.459024 13425 net.cpp:693] Ignoring source layer visualize
I0428 06:09:58.459026 13425 net.cpp:693] Ignoring source layer fake
I0428 06:13:30.920476 13425 solver.cpp:404]     Test net output #0: loss = 0.947662 (* 1 = 0.947662 loss)
I0428 06:13:30.920631 13425 solver.cpp:404]     Test net output #1: loss = 0.629921 (* 1 = 0.629921 loss)
I0428 06:13:30.920639 13425 solver.cpp:404]     Test net output #2: loss = 0.830342 (* 1 = 0.830342 loss)
I0428 06:13:31.576182 13425 solver.cpp:228] Iteration 41000, loss = 2.33959
I0428 06:13:31.576208 13425 solver.cpp:244]     Train net output #0: loss = 0.97376 (* 1 = 0.97376 loss)
I0428 06:13:31.576213 13425 solver.cpp:244]     Train net output #1: loss = 0.596163 (* 1 = 0.596163 loss)
I0428 06:13:31.576218 13425 solver.cpp:244]     Train net output #2: loss = 0.76967 (* 1 = 0.76967 loss)
I0428 06:13:31.576222 13425 sgd_solver.cpp:106] Iteration 41000, lr = 5e-07
I0428 06:15:09.638917 13425 solver.cpp:228] Iteration 41100, loss = 2.00503
I0428 06:15:09.639055 13425 solver.cpp:244]     Train net output #0: loss = 0.984622 (* 1 = 0.984622 loss)
I0428 06:15:09.639063 13425 solver.cpp:244]     Train net output #1: loss = 0.452468 (* 1 = 0.452468 loss)
I0428 06:15:09.639070 13425 solver.cpp:244]     Train net output #2: loss = 0.567943 (* 1 = 0.567943 loss)
I0428 06:15:09.639073 13425 sgd_solver.cpp:106] Iteration 41100, lr = 5e-07
I0428 06:16:49.141465 13425 solver.cpp:228] Iteration 41200, loss = 2.62319
I0428 06:16:49.141603 13425 solver.cpp:244]     Train net output #0: loss = 0.975584 (* 1 = 0.975584 loss)
I0428 06:16:49.141611 13425 solver.cpp:244]     Train net output #1: loss = 0.70767 (* 1 = 0.70767 loss)
I0428 06:16:49.141616 13425 solver.cpp:244]     Train net output #2: loss = 0.939939 (* 1 = 0.939939 loss)
I0428 06:16:49.141621 13425 sgd_solver.cpp:106] Iteration 41200, lr = 5e-07
I0428 06:18:28.309147 13425 solver.cpp:228] Iteration 41300, loss = 2.40845
I0428 06:18:28.309293 13425 solver.cpp:244]     Train net output #0: loss = 0.949818 (* 1 = 0.949818 loss)
I0428 06:18:28.309300 13425 solver.cpp:244]     Train net output #1: loss = 0.526956 (* 1 = 0.526956 loss)
I0428 06:18:28.309305 13425 solver.cpp:244]     Train net output #2: loss = 0.931679 (* 1 = 0.931679 loss)
I0428 06:18:28.309312 13425 sgd_solver.cpp:106] Iteration 41300, lr = 5e-07
I0428 06:20:07.463063 13425 solver.cpp:228] Iteration 41400, loss = 2.19435
I0428 06:20:07.463217 13425 solver.cpp:244]     Train net output #0: loss = 0.938195 (* 1 = 0.938195 loss)
I0428 06:20:07.463225 13425 solver.cpp:244]     Train net output #1: loss = 0.505183 (* 1 = 0.505183 loss)
I0428 06:20:07.463232 13425 solver.cpp:244]     Train net output #2: loss = 0.750976 (* 1 = 0.750976 loss)
I0428 06:20:07.463237 13425 sgd_solver.cpp:106] Iteration 41400, lr = 5e-07
I0428 06:21:46.888097 13425 solver.cpp:228] Iteration 41500, loss = 2.12754
I0428 06:21:46.888265 13425 solver.cpp:244]     Train net output #0: loss = 0.981217 (* 1 = 0.981217 loss)
I0428 06:21:46.888274 13425 solver.cpp:244]     Train net output #1: loss = 0.572097 (* 1 = 0.572097 loss)
I0428 06:21:46.888279 13425 solver.cpp:244]     Train net output #2: loss = 0.574225 (* 1 = 0.574225 loss)
I0428 06:21:46.888293 13425 sgd_solver.cpp:106] Iteration 41500, lr = 5e-07
I0428 06:23:26.481626 13425 solver.cpp:228] Iteration 41600, loss = 2.05854
I0428 06:23:26.481824 13425 solver.cpp:244]     Train net output #0: loss = 0.703385 (* 1 = 0.703385 loss)
I0428 06:23:26.481832 13425 solver.cpp:244]     Train net output #1: loss = 0.609427 (* 1 = 0.609427 loss)
I0428 06:23:26.481837 13425 solver.cpp:244]     Train net output #2: loss = 0.745726 (* 1 = 0.745726 loss)
I0428 06:23:26.481843 13425 sgd_solver.cpp:106] Iteration 41600, lr = 5e-07
I0428 06:25:06.159888 13425 solver.cpp:228] Iteration 41700, loss = 2.63734
I0428 06:25:06.161114 13425 solver.cpp:244]     Train net output #0: loss = 0.959402 (* 1 = 0.959402 loss)
I0428 06:25:06.161121 13425 solver.cpp:244]     Train net output #1: loss = 0.791356 (* 1 = 0.791356 loss)
I0428 06:25:06.161126 13425 solver.cpp:244]     Train net output #2: loss = 0.886578 (* 1 = 0.886578 loss)
I0428 06:25:06.161131 13425 sgd_solver.cpp:106] Iteration 41700, lr = 5e-07
I0428 06:26:44.302055 13425 solver.cpp:228] Iteration 41800, loss = 2.54427
I0428 06:26:44.302239 13425 solver.cpp:244]     Train net output #0: loss = 0.957655 (* 1 = 0.957655 loss)
I0428 06:26:44.302248 13425 solver.cpp:244]     Train net output #1: loss = 0.665339 (* 1 = 0.665339 loss)
I0428 06:26:44.302254 13425 solver.cpp:244]     Train net output #2: loss = 0.921281 (* 1 = 0.921281 loss)
I0428 06:26:44.302259 13425 sgd_solver.cpp:106] Iteration 41800, lr = 5e-07
I0428 06:28:24.126497 13425 solver.cpp:228] Iteration 41900, loss = 2.48114
I0428 06:28:24.126744 13425 solver.cpp:244]     Train net output #0: loss = 0.925204 (* 1 = 0.925204 loss)
I0428 06:28:24.126752 13425 solver.cpp:244]     Train net output #1: loss = 0.638859 (* 1 = 0.638859 loss)
I0428 06:28:24.126758 13425 solver.cpp:244]     Train net output #2: loss = 0.917078 (* 1 = 0.917078 loss)
I0428 06:28:24.126763 13425 sgd_solver.cpp:106] Iteration 41900, lr = 5e-07
I0428 06:30:02.887785 13425 solver.cpp:337] Iteration 42000, Testing net (#0)
I0428 06:30:02.887920 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 06:30:02.887924 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 06:30:02.887928 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 06:30:02.887941 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 06:30:02.887945 13425 net.cpp:693] Ignoring source layer visualize
I0428 06:30:02.887948 13425 net.cpp:693] Ignoring source layer fake
I0428 06:33:35.962505 13425 solver.cpp:404]     Test net output #0: loss = 0.947781 (* 1 = 0.947781 loss)
I0428 06:33:35.962664 13425 solver.cpp:404]     Test net output #1: loss = 0.621967 (* 1 = 0.621967 loss)
I0428 06:33:35.962672 13425 solver.cpp:404]     Test net output #2: loss = 0.820799 (* 1 = 0.820799 loss)
I0428 06:33:36.613801 13425 solver.cpp:228] Iteration 42000, loss = 2.66374
I0428 06:33:36.613826 13425 solver.cpp:244]     Train net output #0: loss = 0.978919 (* 1 = 0.978919 loss)
I0428 06:33:36.613831 13425 solver.cpp:244]     Train net output #1: loss = 0.768946 (* 1 = 0.768946 loss)
I0428 06:33:36.613836 13425 solver.cpp:244]     Train net output #2: loss = 0.915879 (* 1 = 0.915879 loss)
I0428 06:33:36.613839 13425 sgd_solver.cpp:106] Iteration 42000, lr = 5e-07
I0428 06:35:14.758469 13425 solver.cpp:228] Iteration 42100, loss = 2.5659
I0428 06:35:14.758644 13425 solver.cpp:244]     Train net output #0: loss = 0.960563 (* 1 = 0.960563 loss)
I0428 06:35:14.758653 13425 solver.cpp:244]     Train net output #1: loss = 0.683369 (* 1 = 0.683369 loss)
I0428 06:35:14.758658 13425 solver.cpp:244]     Train net output #2: loss = 0.92197 (* 1 = 0.92197 loss)
I0428 06:35:14.758663 13425 sgd_solver.cpp:106] Iteration 42100, lr = 5e-07
I0428 06:36:54.326911 13425 solver.cpp:228] Iteration 42200, loss = 2.70488
I0428 06:36:54.327057 13425 solver.cpp:244]     Train net output #0: loss = 0.983882 (* 1 = 0.983882 loss)
I0428 06:36:54.327065 13425 solver.cpp:244]     Train net output #1: loss = 0.80897 (* 1 = 0.80897 loss)
I0428 06:36:54.327070 13425 solver.cpp:244]     Train net output #2: loss = 0.91203 (* 1 = 0.91203 loss)
I0428 06:36:54.327075 13425 sgd_solver.cpp:106] Iteration 42200, lr = 5e-07
I0428 06:38:33.887097 13425 solver.cpp:228] Iteration 42300, loss = 2.62115
I0428 06:38:33.887428 13425 solver.cpp:244]     Train net output #0: loss = 0.97795 (* 1 = 0.97795 loss)
I0428 06:38:33.887436 13425 solver.cpp:244]     Train net output #1: loss = 0.713161 (* 1 = 0.713161 loss)
I0428 06:38:33.887442 13425 solver.cpp:244]     Train net output #2: loss = 0.930038 (* 1 = 0.930038 loss)
I0428 06:38:33.887449 13425 sgd_solver.cpp:106] Iteration 42300, lr = 5e-07
I0428 06:40:13.415065 13425 solver.cpp:228] Iteration 42400, loss = 2.29455
I0428 06:40:13.415210 13425 solver.cpp:244]     Train net output #0: loss = 0.952915 (* 1 = 0.952915 loss)
I0428 06:40:13.415218 13425 solver.cpp:244]     Train net output #1: loss = 0.615401 (* 1 = 0.615401 loss)
I0428 06:40:13.415225 13425 solver.cpp:244]     Train net output #2: loss = 0.726237 (* 1 = 0.726237 loss)
I0428 06:40:13.415230 13425 sgd_solver.cpp:106] Iteration 42400, lr = 5e-07
I0428 06:41:52.552222 13425 solver.cpp:228] Iteration 42500, loss = 2.42708
I0428 06:41:52.552350 13425 solver.cpp:244]     Train net output #0: loss = 0.945931 (* 1 = 0.945931 loss)
I0428 06:41:52.552357 13425 solver.cpp:244]     Train net output #1: loss = 0.543206 (* 1 = 0.543206 loss)
I0428 06:41:52.552363 13425 solver.cpp:244]     Train net output #2: loss = 0.937947 (* 1 = 0.937947 loss)
I0428 06:41:52.552368 13425 sgd_solver.cpp:106] Iteration 42500, lr = 5e-07
I0428 06:43:31.760490 13425 solver.cpp:228] Iteration 42600, loss = 2.51553
I0428 06:43:31.760627 13425 solver.cpp:244]     Train net output #0: loss = 0.962508 (* 1 = 0.962508 loss)
I0428 06:43:31.760635 13425 solver.cpp:244]     Train net output #1: loss = 0.625394 (* 1 = 0.625394 loss)
I0428 06:43:31.760640 13425 solver.cpp:244]     Train net output #2: loss = 0.927628 (* 1 = 0.927628 loss)
I0428 06:43:31.760646 13425 sgd_solver.cpp:106] Iteration 42600, lr = 5e-07
I0428 06:45:11.116943 13425 solver.cpp:228] Iteration 42700, loss = 2.41517
I0428 06:45:11.117084 13425 solver.cpp:244]     Train net output #0: loss = 0.957497 (* 1 = 0.957497 loss)
I0428 06:45:11.117092 13425 solver.cpp:244]     Train net output #1: loss = 0.686737 (* 1 = 0.686737 loss)
I0428 06:45:11.117097 13425 solver.cpp:244]     Train net output #2: loss = 0.770933 (* 1 = 0.770933 loss)
I0428 06:45:11.117105 13425 sgd_solver.cpp:106] Iteration 42700, lr = 5e-07
I0428 06:46:49.149850 13425 solver.cpp:228] Iteration 42800, loss = 2.06551
I0428 06:46:49.150027 13425 solver.cpp:244]     Train net output #0: loss = 0.957384 (* 1 = 0.957384 loss)
I0428 06:46:49.150035 13425 solver.cpp:244]     Train net output #1: loss = 0.534045 (* 1 = 0.534045 loss)
I0428 06:46:49.150041 13425 solver.cpp:244]     Train net output #2: loss = 0.574079 (* 1 = 0.574079 loss)
I0428 06:46:49.150048 13425 sgd_solver.cpp:106] Iteration 42800, lr = 5e-07
I0428 06:48:28.728485 13425 solver.cpp:228] Iteration 42900, loss = 2.34158
I0428 06:48:28.728660 13425 solver.cpp:244]     Train net output #0: loss = 0.836093 (* 1 = 0.836093 loss)
I0428 06:48:28.728669 13425 solver.cpp:244]     Train net output #1: loss = 0.692778 (* 1 = 0.692778 loss)
I0428 06:48:28.728674 13425 solver.cpp:244]     Train net output #2: loss = 0.812713 (* 1 = 0.812713 loss)
I0428 06:48:28.728680 13425 sgd_solver.cpp:106] Iteration 42900, lr = 5e-07
I0428 06:50:07.480742 13425 solver.cpp:337] Iteration 43000, Testing net (#0)
I0428 06:50:07.480886 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 06:50:07.480890 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 06:50:07.480895 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 06:50:07.480907 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 06:50:07.480911 13425 net.cpp:693] Ignoring source layer visualize
I0428 06:50:07.480913 13425 net.cpp:693] Ignoring source layer fake
I0428 06:53:40.467856 13425 solver.cpp:404]     Test net output #0: loss = 0.94855 (* 1 = 0.94855 loss)
I0428 06:53:40.468020 13425 solver.cpp:404]     Test net output #1: loss = 0.618818 (* 1 = 0.618818 loss)
I0428 06:53:40.468029 13425 solver.cpp:404]     Test net output #2: loss = 0.824962 (* 1 = 0.824962 loss)
I0428 06:53:41.119282 13425 solver.cpp:228] Iteration 43000, loss = 2.64495
I0428 06:53:41.119323 13425 solver.cpp:244]     Train net output #0: loss = 0.969432 (* 1 = 0.969432 loss)
I0428 06:53:41.119329 13425 solver.cpp:244]     Train net output #1: loss = 0.774483 (* 1 = 0.774483 loss)
I0428 06:53:41.119335 13425 solver.cpp:244]     Train net output #2: loss = 0.901038 (* 1 = 0.901038 loss)
I0428 06:53:41.119339 13425 sgd_solver.cpp:106] Iteration 43000, lr = 5e-07
I0428 06:55:21.030403 13425 solver.cpp:228] Iteration 43100, loss = 2.59453
I0428 06:55:21.030601 13425 solver.cpp:244]     Train net output #0: loss = 0.955767 (* 1 = 0.955767 loss)
I0428 06:55:21.030609 13425 solver.cpp:244]     Train net output #1: loss = 0.717767 (* 1 = 0.717767 loss)
I0428 06:55:21.030614 13425 solver.cpp:244]     Train net output #2: loss = 0.920993 (* 1 = 0.920993 loss)
I0428 06:55:21.030620 13425 sgd_solver.cpp:106] Iteration 43100, lr = 5e-07
I0428 06:56:59.189904 13425 solver.cpp:228] Iteration 43200, loss = 2.59738
I0428 06:56:59.190070 13425 solver.cpp:244]     Train net output #0: loss = 0.950532 (* 1 = 0.950532 loss)
I0428 06:56:59.190078 13425 solver.cpp:244]     Train net output #1: loss = 0.728329 (* 1 = 0.728329 loss)
I0428 06:56:59.190084 13425 solver.cpp:244]     Train net output #2: loss = 0.91852 (* 1 = 0.91852 loss)
I0428 06:56:59.190089 13425 sgd_solver.cpp:106] Iteration 43200, lr = 5e-07
I0428 06:58:38.950850 13425 solver.cpp:228] Iteration 43300, loss = 2.60356
I0428 06:58:38.951026 13425 solver.cpp:244]     Train net output #0: loss = 0.976527 (* 1 = 0.976527 loss)
I0428 06:58:38.951035 13425 solver.cpp:244]     Train net output #1: loss = 0.750235 (* 1 = 0.750235 loss)
I0428 06:58:38.951040 13425 solver.cpp:244]     Train net output #2: loss = 0.876803 (* 1 = 0.876803 loss)
I0428 06:58:38.951046 13425 sgd_solver.cpp:106] Iteration 43300, lr = 5e-07
I0428 07:00:18.564443 13425 solver.cpp:228] Iteration 43400, loss = 2.65967
I0428 07:00:18.564617 13425 solver.cpp:244]     Train net output #0: loss = 0.980021 (* 1 = 0.980021 loss)
I0428 07:00:18.564625 13425 solver.cpp:244]     Train net output #1: loss = 0.736556 (* 1 = 0.736556 loss)
I0428 07:00:18.564632 13425 solver.cpp:244]     Train net output #2: loss = 0.943091 (* 1 = 0.943091 loss)
I0428 07:00:18.564637 13425 sgd_solver.cpp:106] Iteration 43400, lr = 5e-07
I0428 07:01:58.189707 13425 solver.cpp:228] Iteration 43500, loss = 2.44975
I0428 07:01:58.189857 13425 solver.cpp:244]     Train net output #0: loss = 0.98121 (* 1 = 0.98121 loss)
I0428 07:01:58.189865 13425 solver.cpp:244]     Train net output #1: loss = 0.540827 (* 1 = 0.540827 loss)
I0428 07:01:58.189870 13425 solver.cpp:244]     Train net output #2: loss = 0.927715 (* 1 = 0.927715 loss)
I0428 07:01:58.189875 13425 sgd_solver.cpp:106] Iteration 43500, lr = 5e-07
I0428 07:03:36.251312 13425 solver.cpp:228] Iteration 43600, loss = 2.49015
I0428 07:03:36.251456 13425 solver.cpp:244]     Train net output #0: loss = 0.965082 (* 1 = 0.965082 loss)
I0428 07:03:36.251464 13425 solver.cpp:244]     Train net output #1: loss = 0.591376 (* 1 = 0.591376 loss)
I0428 07:03:36.251476 13425 solver.cpp:244]     Train net output #2: loss = 0.933691 (* 1 = 0.933691 loss)
I0428 07:03:36.251480 13425 sgd_solver.cpp:106] Iteration 43600, lr = 5e-07
I0428 07:05:15.751678 13425 solver.cpp:228] Iteration 43700, loss = 2.3123
I0428 07:05:15.751833 13425 solver.cpp:244]     Train net output #0: loss = 0.978685 (* 1 = 0.978685 loss)
I0428 07:05:15.751842 13425 solver.cpp:244]     Train net output #1: loss = 0.570529 (* 1 = 0.570529 loss)
I0428 07:05:15.751847 13425 solver.cpp:244]     Train net output #2: loss = 0.763088 (* 1 = 0.763088 loss)
I0428 07:05:15.751853 13425 sgd_solver.cpp:106] Iteration 43700, lr = 5e-07
I0428 07:06:54.905186 13425 solver.cpp:228] Iteration 43800, loss = 2.22111
I0428 07:06:54.905346 13425 solver.cpp:244]     Train net output #0: loss = 0.941225 (* 1 = 0.941225 loss)
I0428 07:06:54.905354 13425 solver.cpp:244]     Train net output #1: loss = 0.530687 (* 1 = 0.530687 loss)
I0428 07:06:54.905360 13425 solver.cpp:244]     Train net output #2: loss = 0.749199 (* 1 = 0.749199 loss)
I0428 07:06:54.905365 13425 sgd_solver.cpp:106] Iteration 43800, lr = 5e-07
I0428 07:08:34.111079 13425 solver.cpp:228] Iteration 43900, loss = 2.35433
I0428 07:08:34.111284 13425 solver.cpp:244]     Train net output #0: loss = 0.971889 (* 1 = 0.971889 loss)
I0428 07:08:34.111294 13425 solver.cpp:244]     Train net output #1: loss = 0.652571 (* 1 = 0.652571 loss)
I0428 07:08:34.111299 13425 solver.cpp:244]     Train net output #2: loss = 0.72987 (* 1 = 0.72987 loss)
I0428 07:08:34.111304 13425 sgd_solver.cpp:106] Iteration 43900, lr = 5e-07
I0428 07:10:12.518623 13425 solver.cpp:337] Iteration 44000, Testing net (#0)
I0428 07:10:12.518781 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 07:10:12.518785 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 07:10:12.518790 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 07:10:12.518805 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 07:10:12.518808 13425 net.cpp:693] Ignoring source layer visualize
I0428 07:10:12.518810 13425 net.cpp:693] Ignoring source layer fake
I0428 07:13:45.709962 13425 solver.cpp:404]     Test net output #0: loss = 0.947218 (* 1 = 0.947218 loss)
I0428 07:13:45.710119 13425 solver.cpp:404]     Test net output #1: loss = 0.611943 (* 1 = 0.611943 loss)
I0428 07:13:45.710126 13425 solver.cpp:404]     Test net output #2: loss = 0.822557 (* 1 = 0.822557 loss)
I0428 07:13:46.364106 13425 solver.cpp:228] Iteration 44000, loss = 2.16977
I0428 07:13:46.364147 13425 solver.cpp:244]     Train net output #0: loss = 0.981613 (* 1 = 0.981613 loss)
I0428 07:13:46.364153 13425 solver.cpp:244]     Train net output #1: loss = 0.630805 (* 1 = 0.630805 loss)
I0428 07:13:46.364158 13425 solver.cpp:244]     Train net output #2: loss = 0.55735 (* 1 = 0.55735 loss)
I0428 07:13:46.364162 13425 sgd_solver.cpp:106] Iteration 44000, lr = 5e-07
I0428 07:15:26.078372 13425 solver.cpp:228] Iteration 44100, loss = 2.09726
I0428 07:15:26.078533 13425 solver.cpp:244]     Train net output #0: loss = 0.619731 (* 1 = 0.619731 loss)
I0428 07:15:26.078542 13425 solver.cpp:244]     Train net output #1: loss = 0.607632 (* 1 = 0.607632 loss)
I0428 07:15:26.078547 13425 solver.cpp:244]     Train net output #2: loss = 0.869901 (* 1 = 0.869901 loss)
I0428 07:15:26.078553 13425 sgd_solver.cpp:106] Iteration 44100, lr = 5e-07
I0428 07:17:05.794695 13425 solver.cpp:228] Iteration 44200, loss = 2.57811
I0428 07:17:05.794843 13425 solver.cpp:244]     Train net output #0: loss = 0.952561 (* 1 = 0.952561 loss)
I0428 07:17:05.794852 13425 solver.cpp:244]     Train net output #1: loss = 0.733064 (* 1 = 0.733064 loss)
I0428 07:17:05.794857 13425 solver.cpp:244]     Train net output #2: loss = 0.892484 (* 1 = 0.892484 loss)
I0428 07:17:05.794872 13425 sgd_solver.cpp:106] Iteration 44200, lr = 5e-07
I0428 07:18:43.909615 13425 solver.cpp:228] Iteration 44300, loss = 2.47483
I0428 07:18:43.909772 13425 solver.cpp:244]     Train net output #0: loss = 0.934186 (* 1 = 0.934186 loss)
I0428 07:18:43.909780 13425 solver.cpp:244]     Train net output #1: loss = 0.625826 (* 1 = 0.625826 loss)
I0428 07:18:43.909785 13425 solver.cpp:244]     Train net output #2: loss = 0.914813 (* 1 = 0.914813 loss)
I0428 07:18:43.909792 13425 sgd_solver.cpp:106] Iteration 44300, lr = 5e-07
I0428 07:20:23.624914 13425 solver.cpp:228] Iteration 44400, loss = 2.49492
I0428 07:20:23.625095 13425 solver.cpp:244]     Train net output #0: loss = 0.930343 (* 1 = 0.930343 loss)
I0428 07:20:23.625103 13425 solver.cpp:244]     Train net output #1: loss = 0.673158 (* 1 = 0.673158 loss)
I0428 07:20:23.625109 13425 solver.cpp:244]     Train net output #2: loss = 0.891415 (* 1 = 0.891415 loss)
I0428 07:20:23.625114 13425 sgd_solver.cpp:106] Iteration 44400, lr = 5e-07
I0428 07:22:03.295264 13425 solver.cpp:228] Iteration 44500, loss = 2.62957
I0428 07:22:03.295410 13425 solver.cpp:244]     Train net output #0: loss = 0.984258 (* 1 = 0.984258 loss)
I0428 07:22:03.295419 13425 solver.cpp:244]     Train net output #1: loss = 0.760374 (* 1 = 0.760374 loss)
I0428 07:22:03.295424 13425 solver.cpp:244]     Train net output #2: loss = 0.884935 (* 1 = 0.884935 loss)
I0428 07:22:03.295430 13425 sgd_solver.cpp:106] Iteration 44500, lr = 5e-07
I0428 07:23:41.388759 13425 solver.cpp:228] Iteration 44600, loss = 2.51233
I0428 07:23:41.388952 13425 solver.cpp:244]     Train net output #0: loss = 0.973584 (* 1 = 0.973584 loss)
I0428 07:23:41.388960 13425 solver.cpp:244]     Train net output #1: loss = 0.673333 (* 1 = 0.673333 loss)
I0428 07:23:41.388967 13425 solver.cpp:244]     Train net output #2: loss = 0.865414 (* 1 = 0.865414 loss)
I0428 07:23:41.388972 13425 sgd_solver.cpp:106] Iteration 44600, lr = 5e-07
I0428 07:25:21.011147 13425 solver.cpp:228] Iteration 44700, loss = 2.68567
I0428 07:25:21.011291 13425 solver.cpp:244]     Train net output #0: loss = 0.984617 (* 1 = 0.984617 loss)
I0428 07:25:21.011299 13425 solver.cpp:244]     Train net output #1: loss = 0.793476 (* 1 = 0.793476 loss)
I0428 07:25:21.011304 13425 solver.cpp:244]     Train net output #2: loss = 0.907575 (* 1 = 0.907575 loss)
I0428 07:25:21.011310 13425 sgd_solver.cpp:106] Iteration 44700, lr = 5e-07
I0428 07:27:00.630815 13425 solver.cpp:228] Iteration 44800, loss = 2.0779
I0428 07:27:00.630990 13425 solver.cpp:244]     Train net output #0: loss = 0.97898 (* 1 = 0.97898 loss)
I0428 07:27:00.630998 13425 solver.cpp:244]     Train net output #1: loss = 0.551918 (* 1 = 0.551918 loss)
I0428 07:27:00.631012 13425 solver.cpp:244]     Train net output #2: loss = 0.547003 (* 1 = 0.547003 loss)
I0428 07:27:00.631019 13425 sgd_solver.cpp:106] Iteration 44800, lr = 5e-07
I0428 07:28:40.150274 13425 solver.cpp:228] Iteration 44900, loss = 2.42416
I0428 07:28:40.150449 13425 solver.cpp:244]     Train net output #0: loss = 0.981053 (* 1 = 0.981053 loss)
I0428 07:28:40.150457 13425 solver.cpp:244]     Train net output #1: loss = 0.688803 (* 1 = 0.688803 loss)
I0428 07:28:40.150463 13425 solver.cpp:244]     Train net output #2: loss = 0.754307 (* 1 = 0.754307 loss)
I0428 07:28:40.150468 13425 sgd_solver.cpp:106] Iteration 44900, lr = 5e-07
I0428 07:30:18.319839 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_45000.caffemodel
I0428 07:30:19.007205 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_45000.solverstate
I0428 07:30:19.190068 13425 solver.cpp:337] Iteration 45000, Testing net (#0)
I0428 07:30:19.190107 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 07:30:19.190109 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 07:30:19.190114 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 07:30:19.190126 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 07:30:19.190129 13425 net.cpp:693] Ignoring source layer visualize
I0428 07:30:19.190130 13425 net.cpp:693] Ignoring source layer fake
I0428 07:33:51.824730 13425 solver.cpp:404]     Test net output #0: loss = 0.943271 (* 1 = 0.943271 loss)
I0428 07:33:51.824858 13425 solver.cpp:404]     Test net output #1: loss = 0.6201 (* 1 = 0.6201 loss)
I0428 07:33:51.824864 13425 solver.cpp:404]     Test net output #2: loss = 0.819609 (* 1 = 0.819609 loss)
I0428 07:33:52.478360 13425 solver.cpp:228] Iteration 45000, loss = 2.24035
I0428 07:33:52.478386 13425 solver.cpp:244]     Train net output #0: loss = 0.957717 (* 1 = 0.957717 loss)
I0428 07:33:52.478391 13425 solver.cpp:244]     Train net output #1: loss = 0.529638 (* 1 = 0.529638 loss)
I0428 07:33:52.478396 13425 solver.cpp:244]     Train net output #2: loss = 0.753 (* 1 = 0.753 loss)
I0428 07:33:52.478400 13425 sgd_solver.cpp:106] Iteration 45000, lr = 5e-07
I0428 07:35:31.731760 13425 solver.cpp:228] Iteration 45100, loss = 2.28965
I0428 07:35:31.731912 13425 solver.cpp:244]     Train net output #0: loss = 0.950334 (* 1 = 0.950334 loss)
I0428 07:35:31.731920 13425 solver.cpp:244]     Train net output #1: loss = 0.586998 (* 1 = 0.586998 loss)
I0428 07:35:31.731925 13425 solver.cpp:244]     Train net output #2: loss = 0.752315 (* 1 = 0.752315 loss)
I0428 07:35:31.731932 13425 sgd_solver.cpp:106] Iteration 45100, lr = 5e-07
I0428 07:37:11.117966 13425 solver.cpp:228] Iteration 45200, loss = 2.10663
I0428 07:37:11.118141 13425 solver.cpp:244]     Train net output #0: loss = 0.96212 (* 1 = 0.96212 loss)
I0428 07:37:11.118149 13425 solver.cpp:244]     Train net output #1: loss = 0.567917 (* 1 = 0.567917 loss)
I0428 07:37:11.118155 13425 solver.cpp:244]     Train net output #2: loss = 0.576597 (* 1 = 0.576597 loss)
I0428 07:37:11.118161 13425 sgd_solver.cpp:106] Iteration 45200, lr = 5e-07
I0428 07:38:49.127749 13425 solver.cpp:228] Iteration 45300, loss = 2.10842
I0428 07:38:49.127923 13425 solver.cpp:244]     Train net output #0: loss = 0.97509 (* 1 = 0.97509 loss)
I0428 07:38:49.127931 13425 solver.cpp:244]     Train net output #1: loss = 0.560689 (* 1 = 0.560689 loss)
I0428 07:38:49.127938 13425 solver.cpp:244]     Train net output #2: loss = 0.572646 (* 1 = 0.572646 loss)
I0428 07:38:49.127943 13425 sgd_solver.cpp:106] Iteration 45300, lr = 5e-07
I0428 07:40:28.740751 13425 solver.cpp:228] Iteration 45400, loss = 2.10303
I0428 07:40:28.740943 13425 solver.cpp:244]     Train net output #0: loss = 0.642808 (* 1 = 0.642808 loss)
I0428 07:40:28.740957 13425 solver.cpp:244]     Train net output #1: loss = 0.624076 (* 1 = 0.624076 loss)
I0428 07:40:28.740964 13425 solver.cpp:244]     Train net output #2: loss = 0.836142 (* 1 = 0.836142 loss)
I0428 07:40:28.740972 13425 sgd_solver.cpp:106] Iteration 45400, lr = 5e-07
I0428 07:42:08.438880 13425 solver.cpp:228] Iteration 45500, loss = 2.52281
I0428 07:42:08.439049 13425 solver.cpp:244]     Train net output #0: loss = 0.945921 (* 1 = 0.945921 loss)
I0428 07:42:08.439060 13425 solver.cpp:244]     Train net output #1: loss = 0.651669 (* 1 = 0.651669 loss)
I0428 07:42:08.439070 13425 solver.cpp:244]     Train net output #2: loss = 0.925221 (* 1 = 0.925221 loss)
I0428 07:42:08.439079 13425 sgd_solver.cpp:106] Iteration 45500, lr = 5e-07
I0428 07:43:48.145141 13425 solver.cpp:228] Iteration 45600, loss = 2.48705
I0428 07:43:48.145282 13425 solver.cpp:244]     Train net output #0: loss = 0.906051 (* 1 = 0.906051 loss)
I0428 07:43:48.145289 13425 solver.cpp:244]     Train net output #1: loss = 0.656231 (* 1 = 0.656231 loss)
I0428 07:43:48.145297 13425 solver.cpp:244]     Train net output #2: loss = 0.924766 (* 1 = 0.924766 loss)
I0428 07:43:48.145300 13425 sgd_solver.cpp:106] Iteration 45600, lr = 5e-07
I0428 07:45:26.274420 13425 solver.cpp:228] Iteration 45700, loss = 2.5061
I0428 07:45:26.274585 13425 solver.cpp:244]     Train net output #0: loss = 0.919485 (* 1 = 0.919485 loss)
I0428 07:45:26.274595 13425 solver.cpp:244]     Train net output #1: loss = 0.682628 (* 1 = 0.682628 loss)
I0428 07:45:26.274600 13425 solver.cpp:244]     Train net output #2: loss = 0.903991 (* 1 = 0.903991 loss)
I0428 07:45:26.274605 13425 sgd_solver.cpp:106] Iteration 45700, lr = 5e-07
I0428 07:47:05.971405 13425 solver.cpp:228] Iteration 45800, loss = 2.60089
I0428 07:47:05.971562 13425 solver.cpp:244]     Train net output #0: loss = 0.95021 (* 1 = 0.95021 loss)
I0428 07:47:05.971570 13425 solver.cpp:244]     Train net output #1: loss = 0.732236 (* 1 = 0.732236 loss)
I0428 07:47:05.971576 13425 solver.cpp:244]     Train net output #2: loss = 0.918441 (* 1 = 0.918441 loss)
I0428 07:47:05.971581 13425 sgd_solver.cpp:106] Iteration 45800, lr = 5e-07
I0428 07:48:45.630885 13425 solver.cpp:228] Iteration 45900, loss = 2.72518
I0428 07:48:45.631011 13425 solver.cpp:244]     Train net output #0: loss = 0.983412 (* 1 = 0.983412 loss)
I0428 07:48:45.631018 13425 solver.cpp:244]     Train net output #1: loss = 0.812973 (* 1 = 0.812973 loss)
I0428 07:48:45.631024 13425 solver.cpp:244]     Train net output #2: loss = 0.928794 (* 1 = 0.928794 loss)
I0428 07:48:45.631031 13425 sgd_solver.cpp:106] Iteration 45900, lr = 5e-07
I0428 07:50:24.297989 13425 solver.cpp:337] Iteration 46000, Testing net (#0)
I0428 07:50:24.298262 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 07:50:24.298266 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 07:50:24.298270 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 07:50:24.298285 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 07:50:24.298287 13425 net.cpp:693] Ignoring source layer visualize
I0428 07:50:24.298290 13425 net.cpp:693] Ignoring source layer fake
I0428 07:53:57.346480 13425 solver.cpp:404]     Test net output #0: loss = 0.946963 (* 1 = 0.946963 loss)
I0428 07:53:57.346634 13425 solver.cpp:404]     Test net output #1: loss = 0.631346 (* 1 = 0.631346 loss)
I0428 07:53:57.346642 13425 solver.cpp:404]     Test net output #2: loss = 0.83197 (* 1 = 0.83197 loss)
I0428 07:53:57.999124 13425 solver.cpp:228] Iteration 46000, loss = 2.5088
I0428 07:53:57.999148 13425 solver.cpp:244]     Train net output #0: loss = 0.979559 (* 1 = 0.979559 loss)
I0428 07:53:57.999153 13425 solver.cpp:244]     Train net output #1: loss = 0.625476 (* 1 = 0.625476 loss)
I0428 07:53:57.999158 13425 solver.cpp:244]     Train net output #2: loss = 0.903767 (* 1 = 0.903767 loss)
I0428 07:53:57.999162 13425 sgd_solver.cpp:106] Iteration 46000, lr = 5e-07
I0428 07:55:36.150902 13425 solver.cpp:228] Iteration 46100, loss = 2.50806
I0428 07:55:36.151058 13425 solver.cpp:244]     Train net output #0: loss = 0.973528 (* 1 = 0.973528 loss)
I0428 07:55:36.151067 13425 solver.cpp:244]     Train net output #1: loss = 0.660601 (* 1 = 0.660601 loss)
I0428 07:55:36.151072 13425 solver.cpp:244]     Train net output #2: loss = 0.873935 (* 1 = 0.873935 loss)
I0428 07:55:36.151078 13425 sgd_solver.cpp:106] Iteration 46100, lr = 5e-07
I0428 07:57:15.637578 13425 solver.cpp:228] Iteration 46200, loss = 2.25665
I0428 07:57:15.637732 13425 solver.cpp:244]     Train net output #0: loss = 0.981945 (* 1 = 0.981945 loss)
I0428 07:57:15.637739 13425 solver.cpp:244]     Train net output #1: loss = 0.525672 (* 1 = 0.525672 loss)
I0428 07:57:15.637747 13425 solver.cpp:244]     Train net output #2: loss = 0.749034 (* 1 = 0.749034 loss)
I0428 07:57:15.637751 13425 sgd_solver.cpp:106] Iteration 46200, lr = 5e-07
I0428 07:58:54.775583 13425 solver.cpp:228] Iteration 46300, loss = 2.36947
I0428 07:58:54.775765 13425 solver.cpp:244]     Train net output #0: loss = 0.954482 (* 1 = 0.954482 loss)
I0428 07:58:54.775774 13425 solver.cpp:244]     Train net output #1: loss = 0.52214 (* 1 = 0.52214 loss)
I0428 07:58:54.775779 13425 solver.cpp:244]     Train net output #2: loss = 0.892847 (* 1 = 0.892847 loss)
I0428 07:58:54.775784 13425 sgd_solver.cpp:106] Iteration 46300, lr = 5e-07
I0428 08:00:33.977706 13425 solver.cpp:228] Iteration 46400, loss = 2.3917
I0428 08:00:33.977862 13425 solver.cpp:244]     Train net output #0: loss = 0.961061 (* 1 = 0.961061 loss)
I0428 08:00:33.977870 13425 solver.cpp:244]     Train net output #1: loss = 0.660742 (* 1 = 0.660742 loss)
I0428 08:00:33.977875 13425 solver.cpp:244]     Train net output #2: loss = 0.769895 (* 1 = 0.769895 loss)
I0428 08:00:33.977880 13425 sgd_solver.cpp:106] Iteration 46400, lr = 5e-07
I0428 08:02:13.417378 13425 solver.cpp:228] Iteration 46500, loss = 2.42774
I0428 08:02:13.417565 13425 solver.cpp:244]     Train net output #0: loss = 0.980371 (* 1 = 0.980371 loss)
I0428 08:02:13.417584 13425 solver.cpp:244]     Train net output #1: loss = 0.693139 (* 1 = 0.693139 loss)
I0428 08:02:13.417589 13425 solver.cpp:244]     Train net output #2: loss = 0.75423 (* 1 = 0.75423 loss)
I0428 08:02:13.417595 13425 sgd_solver.cpp:106] Iteration 46500, lr = 5e-07
I0428 08:03:53.044598 13425 solver.cpp:228] Iteration 46600, loss = 2.33882
I0428 08:03:53.044766 13425 solver.cpp:244]     Train net output #0: loss = 0.892661 (* 1 = 0.892661 loss)
I0428 08:03:53.044775 13425 solver.cpp:244]     Train net output #1: loss = 0.758132 (* 1 = 0.758132 loss)
I0428 08:03:53.044780 13425 solver.cpp:244]     Train net output #2: loss = 0.688026 (* 1 = 0.688026 loss)
I0428 08:03:53.044786 13425 sgd_solver.cpp:106] Iteration 46600, lr = 5e-07
I0428 08:05:32.809381 13425 solver.cpp:228] Iteration 46700, loss = 2.6096
I0428 08:05:32.809597 13425 solver.cpp:244]     Train net output #0: loss = 0.935152 (* 1 = 0.935152 loss)
I0428 08:05:32.809607 13425 solver.cpp:244]     Train net output #1: loss = 0.741274 (* 1 = 0.741274 loss)
I0428 08:05:32.809612 13425 solver.cpp:244]     Train net output #2: loss = 0.933177 (* 1 = 0.933177 loss)
I0428 08:05:32.809617 13425 sgd_solver.cpp:106] Iteration 46700, lr = 5e-07
I0428 08:07:10.956626 13425 solver.cpp:228] Iteration 46800, loss = 2.6804
I0428 08:07:10.956810 13425 solver.cpp:244]     Train net output #0: loss = 0.958924 (* 1 = 0.958924 loss)
I0428 08:07:10.956818 13425 solver.cpp:244]     Train net output #1: loss = 0.838672 (* 1 = 0.838672 loss)
I0428 08:07:10.956825 13425 solver.cpp:244]     Train net output #2: loss = 0.8828 (* 1 = 0.8828 loss)
I0428 08:07:10.956830 13425 sgd_solver.cpp:106] Iteration 46800, lr = 5e-07
I0428 08:08:50.701596 13425 solver.cpp:228] Iteration 46900, loss = 2.59334
I0428 08:08:50.701736 13425 solver.cpp:244]     Train net output #0: loss = 0.965881 (* 1 = 0.965881 loss)
I0428 08:08:50.701745 13425 solver.cpp:244]     Train net output #1: loss = 0.800524 (* 1 = 0.800524 loss)
I0428 08:08:50.701758 13425 solver.cpp:244]     Train net output #2: loss = 0.82693 (* 1 = 0.82693 loss)
I0428 08:08:50.701764 13425 sgd_solver.cpp:106] Iteration 46900, lr = 5e-07
I0428 08:10:29.423509 13425 solver.cpp:337] Iteration 47000, Testing net (#0)
I0428 08:10:29.423663 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 08:10:29.423667 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 08:10:29.423671 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 08:10:29.423692 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 08:10:29.423696 13425 net.cpp:693] Ignoring source layer visualize
I0428 08:10:29.423697 13425 net.cpp:693] Ignoring source layer fake
I0428 08:14:02.144556 13425 solver.cpp:404]     Test net output #0: loss = 0.947367 (* 1 = 0.947367 loss)
I0428 08:14:02.144721 13425 solver.cpp:404]     Test net output #1: loss = 0.622589 (* 1 = 0.622589 loss)
I0428 08:14:02.144727 13425 solver.cpp:404]     Test net output #2: loss = 0.821911 (* 1 = 0.821911 loss)
I0428 08:14:02.797955 13425 solver.cpp:228] Iteration 47000, loss = 2.59528
I0428 08:14:02.797997 13425 solver.cpp:244]     Train net output #0: loss = 0.952691 (* 1 = 0.952691 loss)
I0428 08:14:02.798002 13425 solver.cpp:244]     Train net output #1: loss = 0.733382 (* 1 = 0.733382 loss)
I0428 08:14:02.798007 13425 solver.cpp:244]     Train net output #2: loss = 0.909203 (* 1 = 0.909203 loss)
I0428 08:14:02.798012 13425 sgd_solver.cpp:106] Iteration 47000, lr = 5e-07
I0428 08:15:40.924607 13425 solver.cpp:228] Iteration 47100, loss = 2.66646
I0428 08:15:40.924774 13425 solver.cpp:244]     Train net output #0: loss = 0.977466 (* 1 = 0.977466 loss)
I0428 08:15:40.924782 13425 solver.cpp:244]     Train net output #1: loss = 0.765962 (* 1 = 0.765962 loss)
I0428 08:15:40.924787 13425 solver.cpp:244]     Train net output #2: loss = 0.923036 (* 1 = 0.923036 loss)
I0428 08:15:40.924793 13425 sgd_solver.cpp:106] Iteration 47100, lr = 5e-07
I0428 08:17:20.555809 13425 solver.cpp:228] Iteration 47200, loss = 2.71421
I0428 08:17:20.555963 13425 solver.cpp:244]     Train net output #0: loss = 0.973978 (* 1 = 0.973978 loss)
I0428 08:17:20.555970 13425 solver.cpp:244]     Train net output #1: loss = 0.804804 (* 1 = 0.804804 loss)
I0428 08:17:20.555977 13425 solver.cpp:244]     Train net output #2: loss = 0.935427 (* 1 = 0.935427 loss)
I0428 08:17:20.555982 13425 sgd_solver.cpp:106] Iteration 47200, lr = 5e-07
I0428 08:19:00.205651 13425 solver.cpp:228] Iteration 47300, loss = 2.2941
I0428 08:19:00.205839 13425 solver.cpp:244]     Train net output #0: loss = 0.970838 (* 1 = 0.970838 loss)
I0428 08:19:00.205848 13425 solver.cpp:244]     Train net output #1: loss = 0.561993 (* 1 = 0.561993 loss)
I0428 08:19:00.205853 13425 solver.cpp:244]     Train net output #2: loss = 0.76127 (* 1 = 0.76127 loss)
I0428 08:19:00.205859 13425 sgd_solver.cpp:106] Iteration 47300, lr = 5e-07
I0428 08:20:39.631178 13425 solver.cpp:228] Iteration 47400, loss = 2.5741
I0428 08:20:39.631383 13425 solver.cpp:244]     Train net output #0: loss = 0.968201 (* 1 = 0.968201 loss)
I0428 08:20:39.631392 13425 solver.cpp:244]     Train net output #1: loss = 0.6546 (* 1 = 0.6546 loss)
I0428 08:20:39.631397 13425 solver.cpp:244]     Train net output #2: loss = 0.9513 (* 1 = 0.9513 loss)
I0428 08:20:39.631403 13425 sgd_solver.cpp:106] Iteration 47400, lr = 5e-07
I0428 08:22:18.802691 13425 solver.cpp:228] Iteration 47500, loss = 2.22315
I0428 08:22:18.802876 13425 solver.cpp:244]     Train net output #0: loss = 0.926684 (* 1 = 0.926684 loss)
I0428 08:22:18.802884 13425 solver.cpp:244]     Train net output #1: loss = 0.526395 (* 1 = 0.526395 loss)
I0428 08:22:18.802889 13425 solver.cpp:244]     Train net output #2: loss = 0.770068 (* 1 = 0.770068 loss)
I0428 08:22:18.802896 13425 sgd_solver.cpp:106] Iteration 47500, lr = 5e-07
I0428 08:23:58.123298 13425 solver.cpp:228] Iteration 47600, loss = 2.20336
I0428 08:23:58.123486 13425 solver.cpp:244]     Train net output #0: loss = 0.944142 (* 1 = 0.944142 loss)
I0428 08:23:58.123494 13425 solver.cpp:244]     Train net output #1: loss = 0.49698 (* 1 = 0.49698 loss)
I0428 08:23:58.123500 13425 solver.cpp:244]     Train net output #2: loss = 0.762236 (* 1 = 0.762236 loss)
I0428 08:23:58.123507 13425 sgd_solver.cpp:106] Iteration 47600, lr = 5e-07
I0428 08:25:37.514415 13425 solver.cpp:228] Iteration 47700, loss = 1.95491
I0428 08:25:37.514590 13425 solver.cpp:244]     Train net output #0: loss = 0.976734 (* 1 = 0.976734 loss)
I0428 08:25:37.514600 13425 solver.cpp:244]     Train net output #1: loss = 0.401431 (* 1 = 0.401431 loss)
I0428 08:25:37.514605 13425 solver.cpp:244]     Train net output #2: loss = 0.576747 (* 1 = 0.576747 loss)
I0428 08:25:37.514611 13425 sgd_solver.cpp:106] Iteration 47700, lr = 5e-07
I0428 08:27:15.521559 13425 solver.cpp:228] Iteration 47800, loss = 2.23851
I0428 08:27:15.521721 13425 solver.cpp:244]     Train net output #0: loss = 0.95591 (* 1 = 0.95591 loss)
I0428 08:27:15.521729 13425 solver.cpp:244]     Train net output #1: loss = 0.513591 (* 1 = 0.513591 loss)
I0428 08:27:15.521734 13425 solver.cpp:244]     Train net output #2: loss = 0.769013 (* 1 = 0.769013 loss)
I0428 08:27:15.521739 13425 sgd_solver.cpp:106] Iteration 47800, lr = 5e-07
I0428 08:28:55.174898 13425 solver.cpp:228] Iteration 47900, loss = 2.41818
I0428 08:28:55.175082 13425 solver.cpp:244]     Train net output #0: loss = 0.799033 (* 1 = 0.799033 loss)
I0428 08:28:55.175089 13425 solver.cpp:244]     Train net output #1: loss = 0.73402 (* 1 = 0.73402 loss)
I0428 08:28:55.175096 13425 solver.cpp:244]     Train net output #2: loss = 0.885131 (* 1 = 0.885131 loss)
I0428 08:28:55.175101 13425 sgd_solver.cpp:106] Iteration 47900, lr = 5e-07
I0428 08:30:33.881021 13425 solver.cpp:337] Iteration 48000, Testing net (#0)
I0428 08:30:33.881204 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 08:30:33.881208 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 08:30:33.881213 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 08:30:33.881227 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 08:30:33.881230 13425 net.cpp:693] Ignoring source layer visualize
I0428 08:30:33.881232 13425 net.cpp:693] Ignoring source layer fake
I0428 08:34:06.727514 13425 solver.cpp:404]     Test net output #0: loss = 0.948105 (* 1 = 0.948105 loss)
I0428 08:34:06.727635 13425 solver.cpp:404]     Test net output #1: loss = 0.616618 (* 1 = 0.616618 loss)
I0428 08:34:06.727641 13425 solver.cpp:404]     Test net output #2: loss = 0.825452 (* 1 = 0.825452 loss)
I0428 08:34:07.381278 13425 solver.cpp:228] Iteration 48000, loss = 2.58425
I0428 08:34:07.381305 13425 solver.cpp:244]     Train net output #0: loss = 0.955897 (* 1 = 0.955897 loss)
I0428 08:34:07.381310 13425 solver.cpp:244]     Train net output #1: loss = 0.742179 (* 1 = 0.742179 loss)
I0428 08:34:07.381315 13425 solver.cpp:244]     Train net output #2: loss = 0.886178 (* 1 = 0.886178 loss)
I0428 08:34:07.381319 13425 sgd_solver.cpp:106] Iteration 48000, lr = 5e-07
I0428 08:35:47.127480 13425 solver.cpp:228] Iteration 48100, loss = 2.52106
I0428 08:35:47.127656 13425 solver.cpp:244]     Train net output #0: loss = 0.910257 (* 1 = 0.910257 loss)
I0428 08:35:47.127665 13425 solver.cpp:244]     Train net output #1: loss = 0.742089 (* 1 = 0.742089 loss)
I0428 08:35:47.127670 13425 solver.cpp:244]     Train net output #2: loss = 0.868716 (* 1 = 0.868716 loss)
I0428 08:35:47.127676 13425 sgd_solver.cpp:106] Iteration 48100, lr = 5e-07
I0428 08:37:25.255597 13425 solver.cpp:228] Iteration 48200, loss = 2.61066
I0428 08:37:25.255769 13425 solver.cpp:244]     Train net output #0: loss = 0.952108 (* 1 = 0.952108 loss)
I0428 08:37:25.255777 13425 solver.cpp:244]     Train net output #1: loss = 0.803614 (* 1 = 0.803614 loss)
I0428 08:37:25.255784 13425 solver.cpp:244]     Train net output #2: loss = 0.85494 (* 1 = 0.85494 loss)
I0428 08:37:25.255789 13425 sgd_solver.cpp:106] Iteration 48200, lr = 5e-07
I0428 08:39:05.001165 13425 solver.cpp:228] Iteration 48300, loss = 2.61943
I0428 08:39:05.001317 13425 solver.cpp:244]     Train net output #0: loss = 0.962699 (* 1 = 0.962699 loss)
I0428 08:39:05.001327 13425 solver.cpp:244]     Train net output #1: loss = 0.722651 (* 1 = 0.722651 loss)
I0428 08:39:05.001332 13425 solver.cpp:244]     Train net output #2: loss = 0.934085 (* 1 = 0.934085 loss)
I0428 08:39:05.001338 13425 sgd_solver.cpp:106] Iteration 48300, lr = 5e-07
I0428 08:40:44.672245 13425 solver.cpp:228] Iteration 48400, loss = 2.69925
I0428 08:40:44.672407 13425 solver.cpp:244]     Train net output #0: loss = 0.973435 (* 1 = 0.973435 loss)
I0428 08:40:44.672415 13425 solver.cpp:244]     Train net output #1: loss = 0.793116 (* 1 = 0.793116 loss)
I0428 08:40:44.672420 13425 solver.cpp:244]     Train net output #2: loss = 0.932703 (* 1 = 0.932703 loss)
I0428 08:40:44.672425 13425 sgd_solver.cpp:106] Iteration 48400, lr = 5e-07
I0428 08:42:24.302865 13425 solver.cpp:228] Iteration 48500, loss = 2.56355
I0428 08:42:24.303009 13425 solver.cpp:244]     Train net output #0: loss = 0.977475 (* 1 = 0.977475 loss)
I0428 08:42:24.303016 13425 solver.cpp:244]     Train net output #1: loss = 0.666079 (* 1 = 0.666079 loss)
I0428 08:42:24.303021 13425 solver.cpp:244]     Train net output #2: loss = 0.92 (* 1 = 0.92 loss)
I0428 08:42:24.303027 13425 sgd_solver.cpp:106] Iteration 48500, lr = 5e-07
I0428 08:44:02.351641 13425 solver.cpp:228] Iteration 48600, loss = 2.41849
I0428 08:44:02.351791 13425 solver.cpp:244]     Train net output #0: loss = 0.977902 (* 1 = 0.977902 loss)
I0428 08:44:02.351799 13425 solver.cpp:244]     Train net output #1: loss = 0.561718 (* 1 = 0.561718 loss)
I0428 08:44:02.351805 13425 solver.cpp:244]     Train net output #2: loss = 0.878874 (* 1 = 0.878874 loss)
I0428 08:44:02.351810 13425 sgd_solver.cpp:106] Iteration 48600, lr = 5e-07
I0428 08:45:41.970058 13425 solver.cpp:228] Iteration 48700, loss = 2.54064
I0428 08:45:41.970237 13425 solver.cpp:244]     Train net output #0: loss = 0.97398 (* 1 = 0.97398 loss)
I0428 08:45:41.970247 13425 solver.cpp:244]     Train net output #1: loss = 0.602064 (* 1 = 0.602064 loss)
I0428 08:45:41.970252 13425 solver.cpp:244]     Train net output #2: loss = 0.964599 (* 1 = 0.964599 loss)
I0428 08:45:41.970257 13425 sgd_solver.cpp:106] Iteration 48700, lr = 5e-07
I0428 08:47:21.169082 13425 solver.cpp:228] Iteration 48800, loss = 2.30134
I0428 08:47:21.169268 13425 solver.cpp:244]     Train net output #0: loss = 0.941693 (* 1 = 0.941693 loss)
I0428 08:47:21.169276 13425 solver.cpp:244]     Train net output #1: loss = 0.477916 (* 1 = 0.477916 loss)
I0428 08:47:21.169281 13425 solver.cpp:244]     Train net output #2: loss = 0.88173 (* 1 = 0.88173 loss)
I0428 08:47:21.169287 13425 sgd_solver.cpp:106] Iteration 48800, lr = 5e-07
I0428 08:49:00.391507 13425 solver.cpp:228] Iteration 48900, loss = 2.17625
I0428 08:49:00.391698 13425 solver.cpp:244]     Train net output #0: loss = 0.977374 (* 1 = 0.977374 loss)
I0428 08:49:00.391706 13425 solver.cpp:244]     Train net output #1: loss = 0.647774 (* 1 = 0.647774 loss)
I0428 08:49:00.391711 13425 solver.cpp:244]     Train net output #2: loss = 0.551104 (* 1 = 0.551104 loss)
I0428 08:49:00.391718 13425 sgd_solver.cpp:106] Iteration 48900, lr = 5e-07
I0428 08:50:38.872200 13425 solver.cpp:337] Iteration 49000, Testing net (#0)
I0428 08:50:38.872366 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 08:50:38.872370 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 08:50:38.872375 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 08:50:38.872390 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 08:50:38.872392 13425 net.cpp:693] Ignoring source layer visualize
I0428 08:50:38.872395 13425 net.cpp:693] Ignoring source layer fake
I0428 08:54:12.092531 13425 solver.cpp:404]     Test net output #0: loss = 0.947048 (* 1 = 0.947048 loss)
I0428 08:54:12.092700 13425 solver.cpp:404]     Test net output #1: loss = 0.614028 (* 1 = 0.614028 loss)
I0428 08:54:12.092707 13425 solver.cpp:404]     Test net output #2: loss = 0.821158 (* 1 = 0.821158 loss)
I0428 08:54:12.743533 13425 solver.cpp:228] Iteration 49000, loss = 2.09325
I0428 08:54:12.743562 13425 solver.cpp:244]     Train net output #0: loss = 0.954695 (* 1 = 0.954695 loss)
I0428 08:54:12.743567 13425 solver.cpp:244]     Train net output #1: loss = 0.558029 (* 1 = 0.558029 loss)
I0428 08:54:12.743572 13425 solver.cpp:244]     Train net output #2: loss = 0.580521 (* 1 = 0.580521 loss)
I0428 08:54:12.743577 13425 sgd_solver.cpp:106] Iteration 49000, lr = 5e-07
I0428 08:55:52.378595 13425 solver.cpp:228] Iteration 49100, loss = 2.32599
I0428 08:55:52.378763 13425 solver.cpp:244]     Train net output #0: loss = 0.916798 (* 1 = 0.916798 loss)
I0428 08:55:52.378772 13425 solver.cpp:244]     Train net output #1: loss = 0.741206 (* 1 = 0.741206 loss)
I0428 08:55:52.378777 13425 solver.cpp:244]     Train net output #2: loss = 0.667983 (* 1 = 0.667983 loss)
I0428 08:55:52.378782 13425 sgd_solver.cpp:106] Iteration 49100, lr = 5e-07
I0428 08:57:32.072304 13425 solver.cpp:228] Iteration 49200, loss = 2.57426
I0428 08:57:32.072463 13425 solver.cpp:244]     Train net output #0: loss = 0.944586 (* 1 = 0.944586 loss)
I0428 08:57:32.072470 13425 solver.cpp:244]     Train net output #1: loss = 0.743869 (* 1 = 0.743869 loss)
I0428 08:57:32.072477 13425 solver.cpp:244]     Train net output #2: loss = 0.885804 (* 1 = 0.885804 loss)
I0428 08:57:32.072482 13425 sgd_solver.cpp:106] Iteration 49200, lr = 5e-07
I0428 08:59:10.205163 13425 solver.cpp:228] Iteration 49300, loss = 2.54062
I0428 08:59:10.205353 13425 solver.cpp:244]     Train net output #0: loss = 0.952856 (* 1 = 0.952856 loss)
I0428 08:59:10.205363 13425 solver.cpp:244]     Train net output #1: loss = 0.726705 (* 1 = 0.726705 loss)
I0428 08:59:10.205368 13425 solver.cpp:244]     Train net output #2: loss = 0.861057 (* 1 = 0.861057 loss)
I0428 08:59:10.205374 13425 sgd_solver.cpp:106] Iteration 49300, lr = 5e-07
I0428 09:00:49.929886 13425 solver.cpp:228] Iteration 49400, loss = 2.48811
I0428 09:00:49.930069 13425 solver.cpp:244]     Train net output #0: loss = 0.959086 (* 1 = 0.959086 loss)
I0428 09:00:49.930078 13425 solver.cpp:244]     Train net output #1: loss = 0.70887 (* 1 = 0.70887 loss)
I0428 09:00:49.930083 13425 solver.cpp:244]     Train net output #2: loss = 0.820155 (* 1 = 0.820155 loss)
I0428 09:00:49.930089 13425 sgd_solver.cpp:106] Iteration 49400, lr = 5e-07
I0428 09:02:29.642557 13425 solver.cpp:228] Iteration 49500, loss = 2.59552
I0428 09:02:29.642725 13425 solver.cpp:244]     Train net output #0: loss = 0.962699 (* 1 = 0.962699 loss)
I0428 09:02:29.642734 13425 solver.cpp:244]     Train net output #1: loss = 0.724561 (* 1 = 0.724561 loss)
I0428 09:02:29.642738 13425 solver.cpp:244]     Train net output #2: loss = 0.908256 (* 1 = 0.908256 loss)
I0428 09:02:29.642745 13425 sgd_solver.cpp:106] Iteration 49500, lr = 5e-07
I0428 09:04:07.782491 13425 solver.cpp:228] Iteration 49600, loss = 2.63832
I0428 09:04:07.782660 13425 solver.cpp:244]     Train net output #0: loss = 0.98133 (* 1 = 0.98133 loss)
I0428 09:04:07.782668 13425 solver.cpp:244]     Train net output #1: loss = 0.744278 (* 1 = 0.744278 loss)
I0428 09:04:07.782675 13425 solver.cpp:244]     Train net output #2: loss = 0.912711 (* 1 = 0.912711 loss)
I0428 09:04:07.782680 13425 sgd_solver.cpp:106] Iteration 49600, lr = 5e-07
I0428 09:05:47.421247 13425 solver.cpp:228] Iteration 49700, loss = 2.73797
I0428 09:05:47.421422 13425 solver.cpp:244]     Train net output #0: loss = 0.985163 (* 1 = 0.985163 loss)
I0428 09:05:47.421432 13425 solver.cpp:244]     Train net output #1: loss = 0.835891 (* 1 = 0.835891 loss)
I0428 09:05:47.421447 13425 solver.cpp:244]     Train net output #2: loss = 0.916915 (* 1 = 0.916915 loss)
I0428 09:05:47.421453 13425 sgd_solver.cpp:106] Iteration 49700, lr = 5e-07
I0428 09:07:27.376171 13425 solver.cpp:228] Iteration 49800, loss = 2.51539
I0428 09:07:27.376333 13425 solver.cpp:244]     Train net output #0: loss = 0.979601 (* 1 = 0.979601 loss)
I0428 09:07:27.376341 13425 solver.cpp:244]     Train net output #1: loss = 0.614543 (* 1 = 0.614543 loss)
I0428 09:07:27.376348 13425 solver.cpp:244]     Train net output #2: loss = 0.921245 (* 1 = 0.921245 loss)
I0428 09:07:27.376353 13425 sgd_solver.cpp:106] Iteration 49800, lr = 5e-07
I0428 09:09:06.876391 13425 solver.cpp:228] Iteration 49900, loss = 2.32546
I0428 09:09:06.876543 13425 solver.cpp:244]     Train net output #0: loss = 0.952405 (* 1 = 0.952405 loss)
I0428 09:09:06.876550 13425 solver.cpp:244]     Train net output #1: loss = 0.60605 (* 1 = 0.60605 loss)
I0428 09:09:06.876556 13425 solver.cpp:244]     Train net output #2: loss = 0.767006 (* 1 = 0.767006 loss)
I0428 09:09:06.876564 13425 sgd_solver.cpp:106] Iteration 49900, lr = 5e-07
I0428 09:10:45.121335 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_50000.caffemodel
I0428 09:10:45.806876 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_50000.solverstate
I0428 09:10:45.992918 13425 solver.cpp:337] Iteration 50000, Testing net (#0)
I0428 09:10:45.992959 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 09:10:45.992962 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 09:10:45.992965 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 09:10:45.992979 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 09:10:45.992982 13425 net.cpp:693] Ignoring source layer visualize
I0428 09:10:45.992983 13425 net.cpp:693] Ignoring source layer fake
I0428 09:14:18.796947 13425 solver.cpp:404]     Test net output #0: loss = 0.943177 (* 1 = 0.943177 loss)
I0428 09:14:18.797085 13425 solver.cpp:404]     Test net output #1: loss = 0.622132 (* 1 = 0.622132 loss)
I0428 09:14:18.797096 13425 solver.cpp:404]     Test net output #2: loss = 0.821808 (* 1 = 0.821808 loss)
I0428 09:14:19.452180 13425 solver.cpp:228] Iteration 50000, loss = 2.36344
I0428 09:14:19.452208 13425 solver.cpp:244]     Train net output #0: loss = 0.96122 (* 1 = 0.96122 loss)
I0428 09:14:19.452213 13425 solver.cpp:244]     Train net output #1: loss = 0.480267 (* 1 = 0.480267 loss)
I0428 09:14:19.452217 13425 solver.cpp:244]     Train net output #2: loss = 0.921949 (* 1 = 0.921949 loss)
I0428 09:14:19.452221 13425 sgd_solver.cpp:106] Iteration 50000, lr = 5e-07
I0428 09:15:58.700062 13425 solver.cpp:228] Iteration 50100, loss = 2.18334
I0428 09:15:58.700217 13425 solver.cpp:244]     Train net output #0: loss = 0.924499 (* 1 = 0.924499 loss)
I0428 09:15:58.700227 13425 solver.cpp:244]     Train net output #1: loss = 0.488335 (* 1 = 0.488335 loss)
I0428 09:15:58.700232 13425 solver.cpp:244]     Train net output #2: loss = 0.770501 (* 1 = 0.770501 loss)
I0428 09:15:58.700237 13425 sgd_solver.cpp:106] Iteration 50100, lr = 5e-07
I0428 09:17:38.053391 13425 solver.cpp:228] Iteration 50200, loss = 1.74947
I0428 09:17:38.053580 13425 solver.cpp:244]     Train net output #0: loss = 0.986368 (* 1 = 0.986368 loss)
I0428 09:17:38.053587 13425 solver.cpp:244]     Train net output #1: loss = 0.374994 (* 1 = 0.374994 loss)
I0428 09:17:38.053592 13425 solver.cpp:244]     Train net output #2: loss = 0.388113 (* 1 = 0.388113 loss)
I0428 09:17:38.053598 13425 sgd_solver.cpp:106] Iteration 50200, lr = 5e-07
I0428 09:19:16.125161 13425 solver.cpp:228] Iteration 50300, loss = 2.2565
I0428 09:19:16.125341 13425 solver.cpp:244]     Train net output #0: loss = 0.953249 (* 1 = 0.953249 loss)
I0428 09:19:16.125349 13425 solver.cpp:244]     Train net output #1: loss = 0.528528 (* 1 = 0.528528 loss)
I0428 09:19:16.125355 13425 solver.cpp:244]     Train net output #2: loss = 0.774726 (* 1 = 0.774726 loss)
I0428 09:19:16.125361 13425 sgd_solver.cpp:106] Iteration 50300, lr = 5e-07
I0428 09:20:55.784804 13425 solver.cpp:228] Iteration 50400, loss = 2.31894
I0428 09:20:55.784992 13425 solver.cpp:244]     Train net output #0: loss = 0.89099 (* 1 = 0.89099 loss)
I0428 09:20:55.785001 13425 solver.cpp:244]     Train net output #1: loss = 0.738372 (* 1 = 0.738372 loss)
I0428 09:20:55.785006 13425 solver.cpp:244]     Train net output #2: loss = 0.689575 (* 1 = 0.689575 loss)
I0428 09:20:55.785012 13425 sgd_solver.cpp:106] Iteration 50400, lr = 5e-07
I0428 09:22:35.502349 13425 solver.cpp:228] Iteration 50500, loss = 2.57133
I0428 09:22:35.502521 13425 solver.cpp:244]     Train net output #0: loss = 0.965668 (* 1 = 0.965668 loss)
I0428 09:22:35.502529 13425 solver.cpp:244]     Train net output #1: loss = 0.816815 (* 1 = 0.816815 loss)
I0428 09:22:35.502534 13425 solver.cpp:244]     Train net output #2: loss = 0.788847 (* 1 = 0.788847 loss)
I0428 09:22:35.502539 13425 sgd_solver.cpp:106] Iteration 50500, lr = 5e-07
I0428 09:24:15.240761 13425 solver.cpp:228] Iteration 50600, loss = 2.53118
I0428 09:24:15.240947 13425 solver.cpp:244]     Train net output #0: loss = 0.940413 (* 1 = 0.940413 loss)
I0428 09:24:15.240955 13425 solver.cpp:244]     Train net output #1: loss = 0.727289 (* 1 = 0.727289 loss)
I0428 09:24:15.240960 13425 solver.cpp:244]     Train net output #2: loss = 0.863478 (* 1 = 0.863478 loss)
I0428 09:24:15.240967 13425 sgd_solver.cpp:106] Iteration 50600, lr = 5e-07
I0428 09:25:53.396456 13425 solver.cpp:228] Iteration 50700, loss = 2.61534
I0428 09:25:53.396597 13425 solver.cpp:244]     Train net output #0: loss = 0.961672 (* 1 = 0.961672 loss)
I0428 09:25:53.396605 13425 solver.cpp:244]     Train net output #1: loss = 0.795689 (* 1 = 0.795689 loss)
I0428 09:25:53.396611 13425 solver.cpp:244]     Train net output #2: loss = 0.857978 (* 1 = 0.857978 loss)
I0428 09:25:53.396617 13425 sgd_solver.cpp:106] Iteration 50700, lr = 5e-07
I0428 09:27:33.100121 13425 solver.cpp:228] Iteration 50800, loss = 2.56881
I0428 09:27:33.100301 13425 solver.cpp:244]     Train net output #0: loss = 0.960004 (* 1 = 0.960004 loss)
I0428 09:27:33.100308 13425 solver.cpp:244]     Train net output #1: loss = 0.717863 (* 1 = 0.717863 loss)
I0428 09:27:33.100314 13425 solver.cpp:244]     Train net output #2: loss = 0.890943 (* 1 = 0.890943 loss)
I0428 09:27:33.100319 13425 sgd_solver.cpp:106] Iteration 50800, lr = 5e-07
I0428 09:29:12.785302 13425 solver.cpp:228] Iteration 50900, loss = 2.72497
I0428 09:29:12.785516 13425 solver.cpp:244]     Train net output #0: loss = 0.972669 (* 1 = 0.972669 loss)
I0428 09:29:12.785526 13425 solver.cpp:244]     Train net output #1: loss = 0.813745 (* 1 = 0.813745 loss)
I0428 09:29:12.785531 13425 solver.cpp:244]     Train net output #2: loss = 0.938552 (* 1 = 0.938552 loss)
I0428 09:29:12.785536 13425 sgd_solver.cpp:106] Iteration 50900, lr = 5e-07
I0428 09:30:51.449847 13425 solver.cpp:337] Iteration 51000, Testing net (#0)
I0428 09:30:51.450009 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 09:30:51.450013 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 09:30:51.450016 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 09:30:51.450031 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 09:30:51.450034 13425 net.cpp:693] Ignoring source layer visualize
I0428 09:30:51.450037 13425 net.cpp:693] Ignoring source layer fake
I0428 09:34:24.518463 13425 solver.cpp:404]     Test net output #0: loss = 0.946991 (* 1 = 0.946991 loss)
I0428 09:34:24.518635 13425 solver.cpp:404]     Test net output #1: loss = 0.632073 (* 1 = 0.632073 loss)
I0428 09:34:24.518643 13425 solver.cpp:404]     Test net output #2: loss = 0.832436 (* 1 = 0.832436 loss)
I0428 09:34:25.168843 13425 solver.cpp:228] Iteration 51000, loss = 2.58518
I0428 09:34:25.168869 13425 solver.cpp:244]     Train net output #0: loss = 0.980519 (* 1 = 0.980519 loss)
I0428 09:34:25.168874 13425 solver.cpp:244]     Train net output #1: loss = 0.671772 (* 1 = 0.671772 loss)
I0428 09:34:25.168879 13425 solver.cpp:244]     Train net output #2: loss = 0.932888 (* 1 = 0.932888 loss)
I0428 09:34:25.168882 13425 sgd_solver.cpp:106] Iteration 51000, lr = 5e-07
I0428 09:36:03.324980 13425 solver.cpp:228] Iteration 51100, loss = 2.49428
I0428 09:36:03.325150 13425 solver.cpp:244]     Train net output #0: loss = 0.981812 (* 1 = 0.981812 loss)
I0428 09:36:03.325158 13425 solver.cpp:244]     Train net output #1: loss = 0.591433 (* 1 = 0.591433 loss)
I0428 09:36:03.325165 13425 solver.cpp:244]     Train net output #2: loss = 0.92104 (* 1 = 0.92104 loss)
I0428 09:36:03.325170 13425 sgd_solver.cpp:106] Iteration 51100, lr = 5e-07
I0428 09:37:42.839637 13425 solver.cpp:228] Iteration 51200, loss = 2.40172
I0428 09:37:42.839797 13425 solver.cpp:244]     Train net output #0: loss = 0.977594 (* 1 = 0.977594 loss)
I0428 09:37:42.839804 13425 solver.cpp:244]     Train net output #1: loss = 0.55242 (* 1 = 0.55242 loss)
I0428 09:37:42.839809 13425 solver.cpp:244]     Train net output #2: loss = 0.871702 (* 1 = 0.871702 loss)
I0428 09:37:42.839815 13425 sgd_solver.cpp:106] Iteration 51200, lr = 5e-07
I0428 09:39:22.029793 13425 solver.cpp:228] Iteration 51300, loss = 2.1328
I0428 09:39:22.029968 13425 solver.cpp:244]     Train net output #0: loss = 0.951819 (* 1 = 0.951819 loss)
I0428 09:39:22.029974 13425 solver.cpp:244]     Train net output #1: loss = 0.323529 (* 1 = 0.323529 loss)
I0428 09:39:22.029980 13425 solver.cpp:244]     Train net output #2: loss = 0.857452 (* 1 = 0.857452 loss)
I0428 09:39:22.029986 13425 sgd_solver.cpp:106] Iteration 51300, lr = 5e-07
I0428 09:41:01.255424 13425 solver.cpp:228] Iteration 51400, loss = 2.29439
I0428 09:41:01.255560 13425 solver.cpp:244]     Train net output #0: loss = 0.960993 (* 1 = 0.960993 loss)
I0428 09:41:01.255568 13425 solver.cpp:244]     Train net output #1: loss = 0.583142 (* 1 = 0.583142 loss)
I0428 09:41:01.255574 13425 solver.cpp:244]     Train net output #2: loss = 0.75026 (* 1 = 0.75026 loss)
I0428 09:41:01.255579 13425 sgd_solver.cpp:106] Iteration 51400, lr = 5e-07
I0428 09:42:40.653847 13425 solver.cpp:228] Iteration 51500, loss = 2.04582
I0428 09:42:40.653996 13425 solver.cpp:244]     Train net output #0: loss = 0.964003 (* 1 = 0.964003 loss)
I0428 09:42:40.654005 13425 solver.cpp:244]     Train net output #1: loss = 0.609152 (* 1 = 0.609152 loss)
I0428 09:42:40.654011 13425 solver.cpp:244]     Train net output #2: loss = 0.472662 (* 1 = 0.472662 loss)
I0428 09:42:40.654016 13425 sgd_solver.cpp:106] Iteration 51500, lr = 5e-07
I0428 09:44:20.274936 13425 solver.cpp:228] Iteration 51600, loss = 2.31441
I0428 09:44:20.275104 13425 solver.cpp:244]     Train net output #0: loss = 0.79996 (* 1 = 0.79996 loss)
I0428 09:44:20.275112 13425 solver.cpp:244]     Train net output #1: loss = 0.669756 (* 1 = 0.669756 loss)
I0428 09:44:20.275118 13425 solver.cpp:244]     Train net output #2: loss = 0.844696 (* 1 = 0.844696 loss)
I0428 09:44:20.275123 13425 sgd_solver.cpp:106] Iteration 51600, lr = 5e-07
I0428 09:46:00.001339 13425 solver.cpp:228] Iteration 51700, loss = 2.50142
I0428 09:46:00.001823 13425 solver.cpp:244]     Train net output #0: loss = 0.948462 (* 1 = 0.948462 loss)
I0428 09:46:00.001837 13425 solver.cpp:244]     Train net output #1: loss = 0.653188 (* 1 = 0.653188 loss)
I0428 09:46:00.001843 13425 solver.cpp:244]     Train net output #2: loss = 0.899766 (* 1 = 0.899766 loss)
I0428 09:46:00.001849 13425 sgd_solver.cpp:106] Iteration 51700, lr = 5e-07
I0428 09:47:38.081275 13425 solver.cpp:228] Iteration 51800, loss = 2.47451
I0428 09:47:38.081459 13425 solver.cpp:244]     Train net output #0: loss = 0.948934 (* 1 = 0.948934 loss)
I0428 09:47:38.081466 13425 solver.cpp:244]     Train net output #1: loss = 0.63978 (* 1 = 0.63978 loss)
I0428 09:47:38.081473 13425 solver.cpp:244]     Train net output #2: loss = 0.885798 (* 1 = 0.885798 loss)
I0428 09:47:38.081478 13425 sgd_solver.cpp:106] Iteration 51800, lr = 5e-07
I0428 09:49:17.753746 13425 solver.cpp:228] Iteration 51900, loss = 2.45246
I0428 09:49:17.753957 13425 solver.cpp:244]     Train net output #0: loss = 0.93568 (* 1 = 0.93568 loss)
I0428 09:49:17.753973 13425 solver.cpp:244]     Train net output #1: loss = 0.666187 (* 1 = 0.666187 loss)
I0428 09:49:17.753978 13425 solver.cpp:244]     Train net output #2: loss = 0.850588 (* 1 = 0.850588 loss)
I0428 09:49:17.753983 13425 sgd_solver.cpp:106] Iteration 51900, lr = 5e-07
I0428 09:50:56.582594 13425 solver.cpp:337] Iteration 52000, Testing net (#0)
I0428 09:50:56.582757 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 09:50:56.582762 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 09:50:56.582764 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 09:50:56.582778 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 09:50:56.582782 13425 net.cpp:693] Ignoring source layer visualize
I0428 09:50:56.582784 13425 net.cpp:693] Ignoring source layer fake
I0428 09:54:29.495726 13425 solver.cpp:404]     Test net output #0: loss = 0.947334 (* 1 = 0.947334 loss)
I0428 09:54:29.495887 13425 solver.cpp:404]     Test net output #1: loss = 0.621639 (* 1 = 0.621639 loss)
I0428 09:54:29.495894 13425 solver.cpp:404]     Test net output #2: loss = 0.820367 (* 1 = 0.820367 loss)
I0428 09:54:30.147024 13425 solver.cpp:228] Iteration 52000, loss = 2.6301
I0428 09:54:30.147066 13425 solver.cpp:244]     Train net output #0: loss = 0.978064 (* 1 = 0.978064 loss)
I0428 09:54:30.147073 13425 solver.cpp:244]     Train net output #1: loss = 0.758412 (* 1 = 0.758412 loss)
I0428 09:54:30.147078 13425 solver.cpp:244]     Train net output #2: loss = 0.893626 (* 1 = 0.893626 loss)
I0428 09:54:30.147083 13425 sgd_solver.cpp:106] Iteration 52000, lr = 5e-07
I0428 09:56:08.342285 13425 solver.cpp:228] Iteration 52100, loss = 2.65086
I0428 09:56:08.342439 13425 solver.cpp:244]     Train net output #0: loss = 0.980849 (* 1 = 0.980849 loss)
I0428 09:56:08.342448 13425 solver.cpp:244]     Train net output #1: loss = 0.755753 (* 1 = 0.755753 loss)
I0428 09:56:08.342454 13425 solver.cpp:244]     Train net output #2: loss = 0.914257 (* 1 = 0.914257 loss)
I0428 09:56:08.342459 13425 sgd_solver.cpp:106] Iteration 52100, lr = 5e-07
I0428 09:57:47.966106 13425 solver.cpp:228] Iteration 52200, loss = 2.70329
I0428 09:57:47.966253 13425 solver.cpp:244]     Train net output #0: loss = 0.977855 (* 1 = 0.977855 loss)
I0428 09:57:47.966261 13425 solver.cpp:244]     Train net output #1: loss = 0.810436 (* 1 = 0.810436 loss)
I0428 09:57:47.966267 13425 solver.cpp:244]     Train net output #2: loss = 0.915002 (* 1 = 0.915002 loss)
I0428 09:57:47.966272 13425 sgd_solver.cpp:106] Iteration 52200, lr = 5e-07
I0428 09:59:27.626330 13425 solver.cpp:228] Iteration 52300, loss = 2.26656
I0428 09:59:27.626482 13425 solver.cpp:244]     Train net output #0: loss = 0.983825 (* 1 = 0.983825 loss)
I0428 09:59:27.626489 13425 solver.cpp:244]     Train net output #1: loss = 0.578854 (* 1 = 0.578854 loss)
I0428 09:59:27.626494 13425 solver.cpp:244]     Train net output #2: loss = 0.703883 (* 1 = 0.703883 loss)
I0428 09:59:27.626500 13425 sgd_solver.cpp:106] Iteration 52300, lr = 5e-07
I0428 10:01:07.101080 13425 solver.cpp:228] Iteration 52400, loss = 2.17619
I0428 10:01:07.101248 13425 solver.cpp:244]     Train net output #0: loss = 0.951521 (* 1 = 0.951521 loss)
I0428 10:01:07.101256 13425 solver.cpp:244]     Train net output #1: loss = 0.547026 (* 1 = 0.547026 loss)
I0428 10:01:07.101263 13425 solver.cpp:244]     Train net output #2: loss = 0.677641 (* 1 = 0.677641 loss)
I0428 10:01:07.101267 13425 sgd_solver.cpp:106] Iteration 52400, lr = 5e-07
I0428 10:02:46.243005 13425 solver.cpp:228] Iteration 52500, loss = 2.36502
I0428 10:02:46.243207 13425 solver.cpp:244]     Train net output #0: loss = 0.959962 (* 1 = 0.959962 loss)
I0428 10:02:46.243216 13425 solver.cpp:244]     Train net output #1: loss = 0.481205 (* 1 = 0.481205 loss)
I0428 10:02:46.243222 13425 solver.cpp:244]     Train net output #2: loss = 0.923857 (* 1 = 0.923857 loss)
I0428 10:02:46.243227 13425 sgd_solver.cpp:106] Iteration 52500, lr = 5e-07
I0428 10:04:25.416667 13425 solver.cpp:228] Iteration 52600, loss = 2.01678
I0428 10:04:25.416847 13425 solver.cpp:244]     Train net output #0: loss = 0.962657 (* 1 = 0.962657 loss)
I0428 10:04:25.416856 13425 solver.cpp:244]     Train net output #1: loss = 0.460638 (* 1 = 0.460638 loss)
I0428 10:04:25.416860 13425 solver.cpp:244]     Train net output #2: loss = 0.593488 (* 1 = 0.593488 loss)
I0428 10:04:25.416867 13425 sgd_solver.cpp:106] Iteration 52600, lr = 5e-07
I0428 10:06:04.815623 13425 solver.cpp:228] Iteration 52700, loss = 2.08747
I0428 10:06:04.815753 13425 solver.cpp:244]     Train net output #0: loss = 0.975931 (* 1 = 0.975931 loss)
I0428 10:06:04.815762 13425 solver.cpp:244]     Train net output #1: loss = 0.547637 (* 1 = 0.547637 loss)
I0428 10:06:04.815767 13425 solver.cpp:244]     Train net output #2: loss = 0.563903 (* 1 = 0.563903 loss)
I0428 10:06:04.815773 13425 sgd_solver.cpp:106] Iteration 52700, lr = 5e-07
I0428 10:07:42.862077 13425 solver.cpp:228] Iteration 52800, loss = 2.31748
I0428 10:07:42.862206 13425 solver.cpp:244]     Train net output #0: loss = 0.975476 (* 1 = 0.975476 loss)
I0428 10:07:42.862215 13425 solver.cpp:244]     Train net output #1: loss = 0.583857 (* 1 = 0.583857 loss)
I0428 10:07:42.862221 13425 solver.cpp:244]     Train net output #2: loss = 0.758146 (* 1 = 0.758146 loss)
I0428 10:07:42.862226 13425 sgd_solver.cpp:106] Iteration 52800, lr = 5e-07
I0428 10:09:22.464562 13425 solver.cpp:228] Iteration 52900, loss = 2.10396
I0428 10:09:22.464748 13425 solver.cpp:244]     Train net output #0: loss = 0.639832 (* 1 = 0.639832 loss)
I0428 10:09:22.464757 13425 solver.cpp:244]     Train net output #1: loss = 0.580986 (* 1 = 0.580986 loss)
I0428 10:09:22.464762 13425 solver.cpp:244]     Train net output #2: loss = 0.883146 (* 1 = 0.883146 loss)
I0428 10:09:22.464767 13425 sgd_solver.cpp:106] Iteration 52900, lr = 5e-07
I0428 10:11:01.208664 13425 solver.cpp:337] Iteration 53000, Testing net (#0)
I0428 10:11:01.208798 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 10:11:01.208802 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 10:11:01.208806 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 10:11:01.208820 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 10:11:01.208827 13425 net.cpp:693] Ignoring source layer visualize
I0428 10:11:01.208828 13425 net.cpp:693] Ignoring source layer fake
I0428 10:14:33.921619 13425 solver.cpp:404]     Test net output #0: loss = 0.947948 (* 1 = 0.947948 loss)
I0428 10:14:33.921736 13425 solver.cpp:404]     Test net output #1: loss = 0.617283 (* 1 = 0.617283 loss)
I0428 10:14:33.921742 13425 solver.cpp:404]     Test net output #2: loss = 0.827166 (* 1 = 0.827166 loss)
I0428 10:14:34.574888 13425 solver.cpp:228] Iteration 53000, loss = 2.39821
I0428 10:14:34.574930 13425 solver.cpp:244]     Train net output #0: loss = 0.961793 (* 1 = 0.961793 loss)
I0428 10:14:34.574935 13425 solver.cpp:244]     Train net output #1: loss = 0.648996 (* 1 = 0.648996 loss)
I0428 10:14:34.574940 13425 solver.cpp:244]     Train net output #2: loss = 0.787419 (* 1 = 0.787419 loss)
I0428 10:14:34.574945 13425 sgd_solver.cpp:106] Iteration 53000, lr = 5e-07
I0428 10:16:14.328747 13425 solver.cpp:228] Iteration 53100, loss = 2.37147
I0428 10:16:14.329004 13425 solver.cpp:244]     Train net output #0: loss = 0.906672 (* 1 = 0.906672 loss)
I0428 10:16:14.329012 13425 solver.cpp:244]     Train net output #1: loss = 0.566509 (* 1 = 0.566509 loss)
I0428 10:16:14.329017 13425 solver.cpp:244]     Train net output #2: loss = 0.898288 (* 1 = 0.898288 loss)
I0428 10:16:14.329023 13425 sgd_solver.cpp:106] Iteration 53100, lr = 5e-07
I0428 10:17:52.397512 13425 solver.cpp:228] Iteration 53200, loss = 2.49629
I0428 10:17:52.397725 13425 solver.cpp:244]     Train net output #0: loss = 0.921815 (* 1 = 0.921815 loss)
I0428 10:17:52.397733 13425 solver.cpp:244]     Train net output #1: loss = 0.676332 (* 1 = 0.676332 loss)
I0428 10:17:52.397739 13425 solver.cpp:244]     Train net output #2: loss = 0.898147 (* 1 = 0.898147 loss)
I0428 10:17:52.397744 13425 sgd_solver.cpp:106] Iteration 53200, lr = 5e-07
I0428 10:19:32.073961 13425 solver.cpp:228] Iteration 53300, loss = 2.48044
I0428 10:19:32.074174 13425 solver.cpp:244]     Train net output #0: loss = 0.94352 (* 1 = 0.94352 loss)
I0428 10:19:32.074182 13425 solver.cpp:244]     Train net output #1: loss = 0.639036 (* 1 = 0.639036 loss)
I0428 10:19:32.074188 13425 solver.cpp:244]     Train net output #2: loss = 0.897885 (* 1 = 0.897885 loss)
I0428 10:19:32.074194 13425 sgd_solver.cpp:106] Iteration 53300, lr = 5e-07
I0428 10:21:11.712290 13425 solver.cpp:228] Iteration 53400, loss = 2.64238
I0428 10:21:11.712471 13425 solver.cpp:244]     Train net output #0: loss = 0.981304 (* 1 = 0.981304 loss)
I0428 10:21:11.712478 13425 solver.cpp:244]     Train net output #1: loss = 0.730697 (* 1 = 0.730697 loss)
I0428 10:21:11.712484 13425 solver.cpp:244]     Train net output #2: loss = 0.930377 (* 1 = 0.930377 loss)
I0428 10:21:11.712489 13425 sgd_solver.cpp:106] Iteration 53400, lr = 5e-07
I0428 10:22:51.322500 13425 solver.cpp:228] Iteration 53500, loss = 2.62089
I0428 10:22:51.322701 13425 solver.cpp:244]     Train net output #0: loss = 0.981093 (* 1 = 0.981093 loss)
I0428 10:22:51.322710 13425 solver.cpp:244]     Train net output #1: loss = 0.70504 (* 1 = 0.70504 loss)
I0428 10:22:51.322715 13425 solver.cpp:244]     Train net output #2: loss = 0.934757 (* 1 = 0.934757 loss)
I0428 10:22:51.322721 13425 sgd_solver.cpp:106] Iteration 53500, lr = 5e-07
I0428 10:24:29.451020 13425 solver.cpp:228] Iteration 53600, loss = 2.58601
I0428 10:24:29.451172 13425 solver.cpp:244]     Train net output #0: loss = 0.960093 (* 1 = 0.960093 loss)
I0428 10:24:29.451179 13425 solver.cpp:244]     Train net output #1: loss = 0.707952 (* 1 = 0.707952 loss)
I0428 10:24:29.451185 13425 solver.cpp:244]     Train net output #2: loss = 0.91796 (* 1 = 0.91796 loss)
I0428 10:24:29.451190 13425 sgd_solver.cpp:106] Iteration 53600, lr = 5e-07
I0428 10:26:08.962524 13425 solver.cpp:228] Iteration 53700, loss = 2.27845
I0428 10:26:08.962661 13425 solver.cpp:244]     Train net output #0: loss = 0.982489 (* 1 = 0.982489 loss)
I0428 10:26:08.962669 13425 solver.cpp:244]     Train net output #1: loss = 0.469825 (* 1 = 0.469825 loss)
I0428 10:26:08.962674 13425 solver.cpp:244]     Train net output #2: loss = 0.826135 (* 1 = 0.826135 loss)
I0428 10:26:08.962680 13425 sgd_solver.cpp:106] Iteration 53700, lr = 5e-07
I0428 10:27:48.110638 13425 solver.cpp:228] Iteration 53800, loss = 2.32478
I0428 10:27:48.110806 13425 solver.cpp:244]     Train net output #0: loss = 0.972027 (* 1 = 0.972027 loss)
I0428 10:27:48.110815 13425 solver.cpp:244]     Train net output #1: loss = 0.483566 (* 1 = 0.483566 loss)
I0428 10:27:48.110821 13425 solver.cpp:244]     Train net output #2: loss = 0.869188 (* 1 = 0.869188 loss)
I0428 10:27:48.110826 13425 sgd_solver.cpp:106] Iteration 53800, lr = 5e-07
I0428 10:29:27.305359 13425 solver.cpp:228] Iteration 53900, loss = 2.32764
I0428 10:29:27.305596 13425 solver.cpp:244]     Train net output #0: loss = 0.960219 (* 1 = 0.960219 loss)
I0428 10:29:27.305605 13425 solver.cpp:244]     Train net output #1: loss = 0.591022 (* 1 = 0.591022 loss)
I0428 10:29:27.305611 13425 solver.cpp:244]     Train net output #2: loss = 0.776398 (* 1 = 0.776398 loss)
I0428 10:29:27.305616 13425 sgd_solver.cpp:106] Iteration 53900, lr = 5e-07
I0428 10:31:05.734652 13425 solver.cpp:337] Iteration 54000, Testing net (#0)
I0428 10:31:05.734820 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 10:31:05.734824 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 10:31:05.734828 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 10:31:05.734843 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 10:31:05.734846 13425 net.cpp:693] Ignoring source layer visualize
I0428 10:31:05.734848 13425 net.cpp:693] Ignoring source layer fake
I0428 10:34:38.455165 13425 solver.cpp:404]     Test net output #0: loss = 0.947031 (* 1 = 0.947031 loss)
I0428 10:34:38.455308 13425 solver.cpp:404]     Test net output #1: loss = 0.615154 (* 1 = 0.615154 loss)
I0428 10:34:38.455317 13425 solver.cpp:404]     Test net output #2: loss = 0.820796 (* 1 = 0.820796 loss)
I0428 10:34:39.108114 13425 solver.cpp:228] Iteration 54000, loss = 2.25894
I0428 10:34:39.108139 13425 solver.cpp:244]     Train net output #0: loss = 0.972566 (* 1 = 0.972566 loss)
I0428 10:34:39.108144 13425 solver.cpp:244]     Train net output #1: loss = 0.629531 (* 1 = 0.629531 loss)
I0428 10:34:39.108150 13425 solver.cpp:244]     Train net output #2: loss = 0.65684 (* 1 = 0.65684 loss)
I0428 10:34:39.108153 13425 sgd_solver.cpp:106] Iteration 54000, lr = 5e-07
I0428 10:36:18.730959 13425 solver.cpp:228] Iteration 54100, loss = 2.24703
I0428 10:36:18.731096 13425 solver.cpp:244]     Train net output #0: loss = 0.882926 (* 1 = 0.882926 loss)
I0428 10:36:18.731104 13425 solver.cpp:244]     Train net output #1: loss = 0.6642 (* 1 = 0.6642 loss)
I0428 10:36:18.731109 13425 solver.cpp:244]     Train net output #2: loss = 0.699907 (* 1 = 0.699907 loss)
I0428 10:36:18.731114 13425 sgd_solver.cpp:106] Iteration 54100, lr = 5e-07
I0428 10:37:58.414257 13425 solver.cpp:228] Iteration 54200, loss = 2.5883
I0428 10:37:58.414430 13425 solver.cpp:244]     Train net output #0: loss = 0.964279 (* 1 = 0.964279 loss)
I0428 10:37:58.414438 13425 solver.cpp:244]     Train net output #1: loss = 0.740156 (* 1 = 0.740156 loss)
I0428 10:37:58.414443 13425 solver.cpp:244]     Train net output #2: loss = 0.883861 (* 1 = 0.883861 loss)
I0428 10:37:58.414448 13425 sgd_solver.cpp:106] Iteration 54200, lr = 5e-07
I0428 10:39:36.495117 13425 solver.cpp:228] Iteration 54300, loss = 2.5802
I0428 10:39:36.495259 13425 solver.cpp:244]     Train net output #0: loss = 0.938396 (* 1 = 0.938396 loss)
I0428 10:39:36.495266 13425 solver.cpp:244]     Train net output #1: loss = 0.727049 (* 1 = 0.727049 loss)
I0428 10:39:36.495271 13425 solver.cpp:244]     Train net output #2: loss = 0.914756 (* 1 = 0.914756 loss)
I0428 10:39:36.495277 13425 sgd_solver.cpp:106] Iteration 54300, lr = 5e-07
I0428 10:41:16.214341 13425 solver.cpp:228] Iteration 54400, loss = 2.56437
I0428 10:41:16.214479 13425 solver.cpp:244]     Train net output #0: loss = 0.950851 (* 1 = 0.950851 loss)
I0428 10:41:16.214488 13425 solver.cpp:244]     Train net output #1: loss = 0.730755 (* 1 = 0.730755 loss)
I0428 10:41:16.214495 13425 solver.cpp:244]     Train net output #2: loss = 0.882762 (* 1 = 0.882762 loss)
I0428 10:41:16.214500 13425 sgd_solver.cpp:106] Iteration 54400, lr = 5e-07
I0428 10:42:55.870800 13425 solver.cpp:228] Iteration 54500, loss = 2.28097
I0428 10:42:55.870967 13425 solver.cpp:244]     Train net output #0: loss = 0.881496 (* 1 = 0.881496 loss)
I0428 10:42:55.870976 13425 solver.cpp:244]     Train net output #1: loss = 0.505249 (* 1 = 0.505249 loss)
I0428 10:42:55.870981 13425 solver.cpp:244]     Train net output #2: loss = 0.894224 (* 1 = 0.894224 loss)
I0428 10:42:55.870986 13425 sgd_solver.cpp:106] Iteration 54500, lr = 5e-07
I0428 10:44:33.982609 13425 solver.cpp:228] Iteration 54600, loss = 2.59049
I0428 10:44:33.982746 13425 solver.cpp:244]     Train net output #0: loss = 0.949894 (* 1 = 0.949894 loss)
I0428 10:44:33.982754 13425 solver.cpp:244]     Train net output #1: loss = 0.718696 (* 1 = 0.718696 loss)
I0428 10:44:33.982759 13425 solver.cpp:244]     Train net output #2: loss = 0.921899 (* 1 = 0.921899 loss)
I0428 10:44:33.982765 13425 sgd_solver.cpp:106] Iteration 54600, lr = 5e-07
I0428 10:46:13.583034 13425 solver.cpp:228] Iteration 54700, loss = 2.72161
I0428 10:46:13.583216 13425 solver.cpp:244]     Train net output #0: loss = 0.969137 (* 1 = 0.969137 loss)
I0428 10:46:13.583225 13425 solver.cpp:244]     Train net output #1: loss = 0.803783 (* 1 = 0.803783 loss)
I0428 10:46:13.583230 13425 solver.cpp:244]     Train net output #2: loss = 0.948693 (* 1 = 0.948693 loss)
I0428 10:46:13.583235 13425 sgd_solver.cpp:106] Iteration 54700, lr = 5e-07
I0428 10:47:53.171167 13425 solver.cpp:228] Iteration 54800, loss = 2.42121
I0428 10:47:53.171346 13425 solver.cpp:244]     Train net output #0: loss = 0.968541 (* 1 = 0.968541 loss)
I0428 10:47:53.171355 13425 solver.cpp:244]     Train net output #1: loss = 0.547204 (* 1 = 0.547204 loss)
I0428 10:47:53.171361 13425 solver.cpp:244]     Train net output #2: loss = 0.905468 (* 1 = 0.905468 loss)
I0428 10:47:53.171366 13425 sgd_solver.cpp:106] Iteration 54800, lr = 5e-07
I0428 10:49:32.649667 13425 solver.cpp:228] Iteration 54900, loss = 2.48734
I0428 10:49:32.649824 13425 solver.cpp:244]     Train net output #0: loss = 0.973912 (* 1 = 0.973912 loss)
I0428 10:49:32.649833 13425 solver.cpp:244]     Train net output #1: loss = 0.656126 (* 1 = 0.656126 loss)
I0428 10:49:32.649838 13425 solver.cpp:244]     Train net output #2: loss = 0.857299 (* 1 = 0.857299 loss)
I0428 10:49:32.649843 13425 sgd_solver.cpp:106] Iteration 54900, lr = 5e-07
I0428 10:51:10.817704 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_55000.caffemodel
I0428 10:51:11.723575 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_55000.solverstate
I0428 10:51:11.900889 13425 solver.cpp:337] Iteration 55000, Testing net (#0)
I0428 10:51:11.900929 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 10:51:11.900933 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 10:51:11.900936 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 10:51:11.900949 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 10:51:11.900952 13425 net.cpp:693] Ignoring source layer visualize
I0428 10:51:11.900954 13425 net.cpp:693] Ignoring source layer fake
I0428 10:54:44.428133 13425 solver.cpp:404]     Test net output #0: loss = 0.94312 (* 1 = 0.94312 loss)
I0428 10:54:44.429322 13425 solver.cpp:404]     Test net output #1: loss = 0.623691 (* 1 = 0.623691 loss)
I0428 10:54:44.429327 13425 solver.cpp:404]     Test net output #2: loss = 0.821917 (* 1 = 0.821917 loss)
I0428 10:54:45.080250 13425 solver.cpp:228] Iteration 55000, loss = 2.21459
I0428 10:54:45.080274 13425 solver.cpp:244]     Train net output #0: loss = 0.973259 (* 1 = 0.973259 loss)
I0428 10:54:45.080279 13425 solver.cpp:244]     Train net output #1: loss = 0.368614 (* 1 = 0.368614 loss)
I0428 10:54:45.080283 13425 solver.cpp:244]     Train net output #2: loss = 0.872721 (* 1 = 0.872721 loss)
I0428 10:54:45.080288 13425 sgd_solver.cpp:106] Iteration 55000, lr = 5e-07
I0428 10:56:24.312794 13425 solver.cpp:228] Iteration 55100, loss = 2.41354
I0428 10:56:24.312940 13425 solver.cpp:244]     Train net output #0: loss = 0.923845 (* 1 = 0.923845 loss)
I0428 10:56:24.312948 13425 solver.cpp:244]     Train net output #1: loss = 0.533575 (* 1 = 0.533575 loss)
I0428 10:56:24.312953 13425 solver.cpp:244]     Train net output #2: loss = 0.95612 (* 1 = 0.95612 loss)
I0428 10:56:24.312959 13425 sgd_solver.cpp:106] Iteration 55100, lr = 5e-07
I0428 10:58:03.697633 13425 solver.cpp:228] Iteration 55200, loss = 2.57973
I0428 10:58:03.697827 13425 solver.cpp:244]     Train net output #0: loss = 0.961946 (* 1 = 0.961946 loss)
I0428 10:58:03.697834 13425 solver.cpp:244]     Train net output #1: loss = 0.663845 (* 1 = 0.663845 loss)
I0428 10:58:03.697841 13425 solver.cpp:244]     Train net output #2: loss = 0.953935 (* 1 = 0.953935 loss)
I0428 10:58:03.697846 13425 sgd_solver.cpp:106] Iteration 55200, lr = 5e-07
I0428 10:59:41.719962 13425 solver.cpp:228] Iteration 55300, loss = 2.30527
I0428 10:59:41.720129 13425 solver.cpp:244]     Train net output #0: loss = 0.965645 (* 1 = 0.965645 loss)
I0428 10:59:41.720139 13425 solver.cpp:244]     Train net output #1: loss = 0.583223 (* 1 = 0.583223 loss)
I0428 10:59:41.720144 13425 solver.cpp:244]     Train net output #2: loss = 0.756404 (* 1 = 0.756404 loss)
I0428 10:59:41.720149 13425 sgd_solver.cpp:106] Iteration 55300, lr = 5e-07
I0428 11:01:21.436017 13425 solver.cpp:228] Iteration 55400, loss = 2.05754
I0428 11:01:21.436203 13425 solver.cpp:244]     Train net output #0: loss = 0.597196 (* 1 = 0.597196 loss)
I0428 11:01:21.436211 13425 solver.cpp:244]     Train net output #1: loss = 0.528689 (* 1 = 0.528689 loss)
I0428 11:01:21.436216 13425 solver.cpp:244]     Train net output #2: loss = 0.931659 (* 1 = 0.931659 loss)
I0428 11:01:21.436223 13425 sgd_solver.cpp:106] Iteration 55400, lr = 5e-07
I0428 11:03:01.254673 13425 solver.cpp:228] Iteration 55500, loss = 2.49677
I0428 11:03:01.254843 13425 solver.cpp:244]     Train net output #0: loss = 0.961474 (* 1 = 0.961474 loss)
I0428 11:03:01.254851 13425 solver.cpp:244]     Train net output #1: loss = 0.674807 (* 1 = 0.674807 loss)
I0428 11:03:01.254858 13425 solver.cpp:244]     Train net output #2: loss = 0.860485 (* 1 = 0.860485 loss)
I0428 11:03:01.254863 13425 sgd_solver.cpp:106] Iteration 55500, lr = 5e-07
I0428 11:04:41.195343 13425 solver.cpp:228] Iteration 55600, loss = 2.45325
I0428 11:04:41.195498 13425 solver.cpp:244]     Train net output #0: loss = 0.92555 (* 1 = 0.92555 loss)
I0428 11:04:41.195507 13425 solver.cpp:244]     Train net output #1: loss = 0.665281 (* 1 = 0.665281 loss)
I0428 11:04:41.195513 13425 solver.cpp:244]     Train net output #2: loss = 0.862416 (* 1 = 0.862416 loss)
I0428 11:04:41.195518 13425 sgd_solver.cpp:106] Iteration 55600, lr = 5e-07
I0428 11:06:19.398957 13425 solver.cpp:228] Iteration 55700, loss = 2.5044
I0428 11:06:19.399117 13425 solver.cpp:244]     Train net output #0: loss = 0.901663 (* 1 = 0.901663 loss)
I0428 11:06:19.399127 13425 solver.cpp:244]     Train net output #1: loss = 0.666731 (* 1 = 0.666731 loss)
I0428 11:06:19.399132 13425 solver.cpp:244]     Train net output #2: loss = 0.936008 (* 1 = 0.936008 loss)
I0428 11:06:19.399137 13425 sgd_solver.cpp:106] Iteration 55700, lr = 5e-07
I0428 11:07:59.101209 13425 solver.cpp:228] Iteration 55800, loss = 2.4952
I0428 11:07:59.101349 13425 solver.cpp:244]     Train net output #0: loss = 0.969504 (* 1 = 0.969504 loss)
I0428 11:07:59.101356 13425 solver.cpp:244]     Train net output #1: loss = 0.626867 (* 1 = 0.626867 loss)
I0428 11:07:59.101362 13425 solver.cpp:244]     Train net output #2: loss = 0.898829 (* 1 = 0.898829 loss)
I0428 11:07:59.101367 13425 sgd_solver.cpp:106] Iteration 55800, lr = 5e-07
I0428 11:09:38.771811 13425 solver.cpp:228] Iteration 55900, loss = 2.75417
I0428 11:09:38.771965 13425 solver.cpp:244]     Train net output #0: loss = 0.982022 (* 1 = 0.982022 loss)
I0428 11:09:38.771972 13425 solver.cpp:244]     Train net output #1: loss = 0.818845 (* 1 = 0.818845 loss)
I0428 11:09:38.771977 13425 solver.cpp:244]     Train net output #2: loss = 0.953305 (* 1 = 0.953305 loss)
I0428 11:09:38.771983 13425 sgd_solver.cpp:106] Iteration 55900, lr = 5e-07
I0428 11:11:17.492100 13425 solver.cpp:337] Iteration 56000, Testing net (#0)
I0428 11:11:17.492231 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 11:11:17.492235 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 11:11:17.492239 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 11:11:17.492254 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 11:11:17.492257 13425 net.cpp:693] Ignoring source layer visualize
I0428 11:11:17.492259 13425 net.cpp:693] Ignoring source layer fake
I0428 11:14:51.720656 13425 solver.cpp:404]     Test net output #0: loss = 0.947156 (* 1 = 0.947156 loss)
I0428 11:14:51.720794 13425 solver.cpp:404]     Test net output #1: loss = 0.632669 (* 1 = 0.632669 loss)
I0428 11:14:51.720801 13425 solver.cpp:404]     Test net output #2: loss = 0.832696 (* 1 = 0.832696 loss)
I0428 11:14:52.373612 13425 solver.cpp:228] Iteration 56000, loss = 2.63254
I0428 11:14:52.373654 13425 solver.cpp:244]     Train net output #0: loss = 0.958089 (* 1 = 0.958089 loss)
I0428 11:14:52.373661 13425 solver.cpp:244]     Train net output #1: loss = 0.752838 (* 1 = 0.752838 loss)
I0428 11:14:52.373666 13425 solver.cpp:244]     Train net output #2: loss = 0.921612 (* 1 = 0.921612 loss)
I0428 11:14:52.373669 13425 sgd_solver.cpp:106] Iteration 56000, lr = 5e-07
I0428 11:16:30.640414 13425 solver.cpp:228] Iteration 56100, loss = 2.6508
I0428 11:16:30.640596 13425 solver.cpp:244]     Train net output #0: loss = 0.962178 (* 1 = 0.962178 loss)
I0428 11:16:30.640605 13425 solver.cpp:244]     Train net output #1: loss = 0.774856 (* 1 = 0.774856 loss)
I0428 11:16:30.640610 13425 solver.cpp:244]     Train net output #2: loss = 0.913765 (* 1 = 0.913765 loss)
I0428 11:16:30.640617 13425 sgd_solver.cpp:106] Iteration 56100, lr = 5e-07
I0428 11:18:10.440907 13425 solver.cpp:228] Iteration 56200, loss = 2.54833
I0428 11:18:10.441054 13425 solver.cpp:244]     Train net output #0: loss = 0.976736 (* 1 = 0.976736 loss)
I0428 11:18:10.441061 13425 solver.cpp:244]     Train net output #1: loss = 0.668705 (* 1 = 0.668705 loss)
I0428 11:18:10.441068 13425 solver.cpp:244]     Train net output #2: loss = 0.902893 (* 1 = 0.902893 loss)
I0428 11:18:10.441073 13425 sgd_solver.cpp:106] Iteration 56200, lr = 5e-07
I0428 11:19:49.787711 13425 solver.cpp:228] Iteration 56300, loss = 2.35484
I0428 11:19:49.787858 13425 solver.cpp:244]     Train net output #0: loss = 0.946836 (* 1 = 0.946836 loss)
I0428 11:19:49.787866 13425 solver.cpp:244]     Train net output #1: loss = 0.493262 (* 1 = 0.493262 loss)
I0428 11:19:49.787871 13425 solver.cpp:244]     Train net output #2: loss = 0.914741 (* 1 = 0.914741 loss)
I0428 11:19:49.787878 13425 sgd_solver.cpp:106] Iteration 56300, lr = 5e-07
I0428 11:21:29.226500 13425 solver.cpp:228] Iteration 56400, loss = 2.17349
I0428 11:21:29.226630 13425 solver.cpp:244]     Train net output #0: loss = 0.982543 (* 1 = 0.982543 loss)
I0428 11:21:29.226639 13425 solver.cpp:244]     Train net output #1: loss = 0.657114 (* 1 = 0.657114 loss)
I0428 11:21:29.226644 13425 solver.cpp:244]     Train net output #2: loss = 0.53383 (* 1 = 0.53383 loss)
I0428 11:21:29.226649 13425 sgd_solver.cpp:106] Iteration 56400, lr = 5e-07
I0428 11:23:08.836447 13425 solver.cpp:228] Iteration 56500, loss = 2.22173
I0428 11:23:08.836591 13425 solver.cpp:244]     Train net output #0: loss = 0.94584 (* 1 = 0.94584 loss)
I0428 11:23:08.836598 13425 solver.cpp:244]     Train net output #1: loss = 0.506891 (* 1 = 0.506891 loss)
I0428 11:23:08.836604 13425 solver.cpp:244]     Train net output #2: loss = 0.769001 (* 1 = 0.769001 loss)
I0428 11:23:08.836611 13425 sgd_solver.cpp:106] Iteration 56500, lr = 5e-07
I0428 11:24:48.613555 13425 solver.cpp:228] Iteration 56600, loss = 2.19386
I0428 11:24:48.613708 13425 solver.cpp:244]     Train net output #0: loss = 0.83532 (* 1 = 0.83532 loss)
I0428 11:24:48.613715 13425 solver.cpp:244]     Train net output #1: loss = 0.658295 (* 1 = 0.658295 loss)
I0428 11:24:48.613723 13425 solver.cpp:244]     Train net output #2: loss = 0.700246 (* 1 = 0.700246 loss)
I0428 11:24:48.613728 13425 sgd_solver.cpp:106] Iteration 56600, lr = 5e-07
I0428 11:26:28.521500 13425 solver.cpp:228] Iteration 56700, loss = 2.56128
I0428 11:26:28.521646 13425 solver.cpp:244]     Train net output #0: loss = 0.976354 (* 1 = 0.976354 loss)
I0428 11:26:28.521656 13425 solver.cpp:244]     Train net output #1: loss = 0.805258 (* 1 = 0.805258 loss)
I0428 11:26:28.521661 13425 solver.cpp:244]     Train net output #2: loss = 0.779667 (* 1 = 0.779667 loss)
I0428 11:26:28.521677 13425 sgd_solver.cpp:106] Iteration 56700, lr = 5e-07
I0428 11:28:06.768921 13425 solver.cpp:228] Iteration 56800, loss = 2.57835
I0428 11:28:06.769069 13425 solver.cpp:244]     Train net output #0: loss = 0.94074 (* 1 = 0.94074 loss)
I0428 11:28:06.769078 13425 solver.cpp:244]     Train net output #1: loss = 0.705755 (* 1 = 0.705755 loss)
I0428 11:28:06.769083 13425 solver.cpp:244]     Train net output #2: loss = 0.931855 (* 1 = 0.931855 loss)
I0428 11:28:06.769088 13425 sgd_solver.cpp:106] Iteration 56800, lr = 5e-07
I0428 11:29:46.778919 13425 solver.cpp:228] Iteration 56900, loss = 2.53666
I0428 11:29:46.779080 13425 solver.cpp:244]     Train net output #0: loss = 0.932777 (* 1 = 0.932777 loss)
I0428 11:29:46.779088 13425 solver.cpp:244]     Train net output #1: loss = 0.690658 (* 1 = 0.690658 loss)
I0428 11:29:46.779094 13425 solver.cpp:244]     Train net output #2: loss = 0.913223 (* 1 = 0.913223 loss)
I0428 11:29:46.779101 13425 sgd_solver.cpp:106] Iteration 56900, lr = 5e-07
I0428 11:31:25.661607 13425 solver.cpp:337] Iteration 57000, Testing net (#0)
I0428 11:31:25.661787 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 11:31:25.661792 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 11:31:25.661798 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 11:31:25.661816 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 11:31:25.661821 13425 net.cpp:693] Ignoring source layer visualize
I0428 11:31:25.661824 13425 net.cpp:693] Ignoring source layer fake
I0428 11:35:00.022672 13425 solver.cpp:404]     Test net output #0: loss = 0.94738 (* 1 = 0.94738 loss)
I0428 11:35:00.022802 13425 solver.cpp:404]     Test net output #1: loss = 0.62138 (* 1 = 0.62138 loss)
I0428 11:35:00.022809 13425 solver.cpp:404]     Test net output #2: loss = 0.820958 (* 1 = 0.820958 loss)
I0428 11:35:00.673954 13425 solver.cpp:228] Iteration 57000, loss = 2.36055
I0428 11:35:00.673980 13425 solver.cpp:244]     Train net output #0: loss = 0.903296 (* 1 = 0.903296 loss)
I0428 11:35:00.673986 13425 solver.cpp:244]     Train net output #1: loss = 0.550053 (* 1 = 0.550053 loss)
I0428 11:35:00.673990 13425 solver.cpp:244]     Train net output #2: loss = 0.907204 (* 1 = 0.907204 loss)
I0428 11:35:00.673995 13425 sgd_solver.cpp:106] Iteration 57000, lr = 5e-07
I0428 11:36:38.938273 13425 solver.cpp:228] Iteration 57100, loss = 2.63202
I0428 11:36:38.938467 13425 solver.cpp:244]     Train net output #0: loss = 0.959442 (* 1 = 0.959442 loss)
I0428 11:36:38.938474 13425 solver.cpp:244]     Train net output #1: loss = 0.764425 (* 1 = 0.764425 loss)
I0428 11:36:38.938480 13425 solver.cpp:244]     Train net output #2: loss = 0.908149 (* 1 = 0.908149 loss)
I0428 11:36:38.938486 13425 sgd_solver.cpp:106] Iteration 57100, lr = 5e-07
I0428 11:38:18.741912 13425 solver.cpp:228] Iteration 57200, loss = 2.61831
I0428 11:38:18.742066 13425 solver.cpp:244]     Train net output #0: loss = 0.98979 (* 1 = 0.98979 loss)
I0428 11:38:18.742074 13425 solver.cpp:244]     Train net output #1: loss = 0.715237 (* 1 = 0.715237 loss)
I0428 11:38:18.742080 13425 solver.cpp:244]     Train net output #2: loss = 0.913281 (* 1 = 0.913281 loss)
I0428 11:38:18.742085 13425 sgd_solver.cpp:106] Iteration 57200, lr = 5e-07
I0428 11:39:58.598403 13425 solver.cpp:228] Iteration 57300, loss = 2.53064
I0428 11:39:58.598574 13425 solver.cpp:244]     Train net output #0: loss = 0.97502 (* 1 = 0.97502 loss)
I0428 11:39:58.598583 13425 solver.cpp:244]     Train net output #1: loss = 0.627718 (* 1 = 0.627718 loss)
I0428 11:39:58.598589 13425 solver.cpp:244]     Train net output #2: loss = 0.927899 (* 1 = 0.927899 loss)
I0428 11:39:58.598594 13425 sgd_solver.cpp:106] Iteration 57300, lr = 5e-07
I0428 11:41:38.379012 13425 solver.cpp:228] Iteration 57400, loss = 2.37595
I0428 11:41:38.379165 13425 solver.cpp:244]     Train net output #0: loss = 0.984731 (* 1 = 0.984731 loss)
I0428 11:41:38.379174 13425 solver.cpp:244]     Train net output #1: loss = 0.677009 (* 1 = 0.677009 loss)
I0428 11:41:38.379179 13425 solver.cpp:244]     Train net output #2: loss = 0.714212 (* 1 = 0.714212 loss)
I0428 11:41:38.379184 13425 sgd_solver.cpp:106] Iteration 57400, lr = 5e-07
I0428 11:43:17.966140 13425 solver.cpp:228] Iteration 57500, loss = 2.3554
I0428 11:43:17.966315 13425 solver.cpp:244]     Train net output #0: loss = 0.954297 (* 1 = 0.954297 loss)
I0428 11:43:17.966325 13425 solver.cpp:244]     Train net output #1: loss = 0.52026 (* 1 = 0.52026 loss)
I0428 11:43:17.966331 13425 solver.cpp:244]     Train net output #2: loss = 0.880843 (* 1 = 0.880843 loss)
I0428 11:43:17.966336 13425 sgd_solver.cpp:106] Iteration 57500, lr = 5e-07
I0428 11:44:57.547508 13425 solver.cpp:228] Iteration 57600, loss = 2.12454
I0428 11:44:57.547715 13425 solver.cpp:244]     Train net output #0: loss = 0.925425 (* 1 = 0.925425 loss)
I0428 11:44:57.547726 13425 solver.cpp:244]     Train net output #1: loss = 0.462236 (* 1 = 0.462236 loss)
I0428 11:44:57.547735 13425 solver.cpp:244]     Train net output #2: loss = 0.736876 (* 1 = 0.736876 loss)
I0428 11:44:57.547744 13425 sgd_solver.cpp:106] Iteration 57600, lr = 5e-07
I0428 11:46:37.091533 13425 solver.cpp:228] Iteration 57700, loss = 2.20673
I0428 11:46:37.091676 13425 solver.cpp:244]     Train net output #0: loss = 0.982452 (* 1 = 0.982452 loss)
I0428 11:46:37.091686 13425 solver.cpp:244]     Train net output #1: loss = 0.6411 (* 1 = 0.6411 loss)
I0428 11:46:37.091691 13425 solver.cpp:244]     Train net output #2: loss = 0.583174 (* 1 = 0.583174 loss)
I0428 11:46:37.091696 13425 sgd_solver.cpp:106] Iteration 57700, lr = 5e-07
I0428 11:48:15.270922 13425 solver.cpp:228] Iteration 57800, loss = 2.0745
I0428 11:48:15.271090 13425 solver.cpp:244]     Train net output #0: loss = 0.968503 (* 1 = 0.968503 loss)
I0428 11:48:15.271101 13425 solver.cpp:244]     Train net output #1: loss = 0.525546 (* 1 = 0.525546 loss)
I0428 11:48:15.271111 13425 solver.cpp:244]     Train net output #2: loss = 0.580448 (* 1 = 0.580448 loss)
I0428 11:48:15.271117 13425 sgd_solver.cpp:106] Iteration 57800, lr = 5e-07
I0428 11:49:55.128175 13425 solver.cpp:228] Iteration 57900, loss = 2.38475
I0428 11:49:55.128330 13425 solver.cpp:244]     Train net output #0: loss = 0.807384 (* 1 = 0.807384 loss)
I0428 11:49:55.128341 13425 solver.cpp:244]     Train net output #1: loss = 0.633113 (* 1 = 0.633113 loss)
I0428 11:49:55.128350 13425 solver.cpp:244]     Train net output #2: loss = 0.944253 (* 1 = 0.944253 loss)
I0428 11:49:55.128360 13425 sgd_solver.cpp:106] Iteration 57900, lr = 5e-07
I0428 11:51:34.155903 13425 solver.cpp:337] Iteration 58000, Testing net (#0)
I0428 11:51:34.156036 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 11:51:34.156040 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 11:51:34.156045 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 11:51:34.156059 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 11:51:34.156062 13425 net.cpp:693] Ignoring source layer visualize
I0428 11:51:34.156065 13425 net.cpp:693] Ignoring source layer fake
I0428 11:55:08.231076 13425 solver.cpp:404]     Test net output #0: loss = 0.947785 (* 1 = 0.947785 loss)
I0428 11:55:08.231217 13425 solver.cpp:404]     Test net output #1: loss = 0.61695 (* 1 = 0.61695 loss)
I0428 11:55:08.231225 13425 solver.cpp:404]     Test net output #2: loss = 0.827116 (* 1 = 0.827116 loss)
I0428 11:55:08.883157 13425 solver.cpp:228] Iteration 58000, loss = 2.63012
I0428 11:55:08.883183 13425 solver.cpp:244]     Train net output #0: loss = 0.960833 (* 1 = 0.960833 loss)
I0428 11:55:08.883188 13425 solver.cpp:244]     Train net output #1: loss = 0.772321 (* 1 = 0.772321 loss)
I0428 11:55:08.883193 13425 solver.cpp:244]     Train net output #2: loss = 0.896967 (* 1 = 0.896967 loss)
I0428 11:55:08.883196 13425 sgd_solver.cpp:106] Iteration 58000, lr = 5e-07
I0428 11:56:48.880950 13425 solver.cpp:228] Iteration 58100, loss = 2.65029
I0428 11:56:48.881094 13425 solver.cpp:244]     Train net output #0: loss = 0.955325 (* 1 = 0.955325 loss)
I0428 11:56:48.881103 13425 solver.cpp:244]     Train net output #1: loss = 0.766847 (* 1 = 0.766847 loss)
I0428 11:56:48.881108 13425 solver.cpp:244]     Train net output #2: loss = 0.928121 (* 1 = 0.928121 loss)
I0428 11:56:48.881114 13425 sgd_solver.cpp:106] Iteration 58100, lr = 5e-07
I0428 11:58:27.074165 13425 solver.cpp:228] Iteration 58200, loss = 2.60196
I0428 11:58:27.074308 13425 solver.cpp:244]     Train net output #0: loss = 0.934298 (* 1 = 0.934298 loss)
I0428 11:58:27.074316 13425 solver.cpp:244]     Train net output #1: loss = 0.725993 (* 1 = 0.725993 loss)
I0428 11:58:27.074323 13425 solver.cpp:244]     Train net output #2: loss = 0.94167 (* 1 = 0.94167 loss)
I0428 11:58:27.074329 13425 sgd_solver.cpp:106] Iteration 58200, lr = 5e-07
I0428 12:00:07.059381 13425 solver.cpp:228] Iteration 58300, loss = 2.53783
I0428 12:00:07.059541 13425 solver.cpp:244]     Train net output #0: loss = 0.977224 (* 1 = 0.977224 loss)
I0428 12:00:07.059551 13425 solver.cpp:244]     Train net output #1: loss = 0.751052 (* 1 = 0.751052 loss)
I0428 12:00:07.059556 13425 solver.cpp:244]     Train net output #2: loss = 0.809549 (* 1 = 0.809549 loss)
I0428 12:00:07.059561 13425 sgd_solver.cpp:106] Iteration 58300, lr = 5e-07
I0428 12:01:47.036499 13425 solver.cpp:228] Iteration 58400, loss = 2.73767
I0428 12:01:47.036679 13425 solver.cpp:244]     Train net output #0: loss = 0.984569 (* 1 = 0.984569 loss)
I0428 12:01:47.036687 13425 solver.cpp:244]     Train net output #1: loss = 0.799512 (* 1 = 0.799512 loss)
I0428 12:01:47.036692 13425 solver.cpp:244]     Train net output #2: loss = 0.953586 (* 1 = 0.953586 loss)
I0428 12:01:47.036698 13425 sgd_solver.cpp:106] Iteration 58400, lr = 5e-07
I0428 12:03:27.112900 13425 solver.cpp:228] Iteration 58500, loss = 2.51081
I0428 12:03:27.113061 13425 solver.cpp:244]     Train net output #0: loss = 0.981897 (* 1 = 0.981897 loss)
I0428 12:03:27.113070 13425 solver.cpp:244]     Train net output #1: loss = 0.647957 (* 1 = 0.647957 loss)
I0428 12:03:27.113075 13425 solver.cpp:244]     Train net output #2: loss = 0.880955 (* 1 = 0.880955 loss)
I0428 12:03:27.113080 13425 sgd_solver.cpp:106] Iteration 58500, lr = 5e-07
I0428 12:05:05.575021 13425 solver.cpp:228] Iteration 58600, loss = 2.53024
I0428 12:05:05.575178 13425 solver.cpp:244]     Train net output #0: loss = 0.985325 (* 1 = 0.985325 loss)
I0428 12:05:05.575191 13425 solver.cpp:244]     Train net output #1: loss = 0.650432 (* 1 = 0.650432 loss)
I0428 12:05:05.575199 13425 solver.cpp:244]     Train net output #2: loss = 0.894487 (* 1 = 0.894487 loss)
I0428 12:05:05.575207 13425 sgd_solver.cpp:106] Iteration 58600, lr = 5e-07
I0428 12:06:45.525782 13425 solver.cpp:228] Iteration 58700, loss = 2.48645
I0428 12:06:45.525925 13425 solver.cpp:244]     Train net output #0: loss = 0.976985 (* 1 = 0.976985 loss)
I0428 12:06:45.525934 13425 solver.cpp:244]     Train net output #1: loss = 0.600657 (* 1 = 0.600657 loss)
I0428 12:06:45.525939 13425 solver.cpp:244]     Train net output #2: loss = 0.908805 (* 1 = 0.908805 loss)
I0428 12:06:45.525944 13425 sgd_solver.cpp:106] Iteration 58700, lr = 5e-07
I0428 12:08:25.014380 13425 solver.cpp:228] Iteration 58800, loss = 2.07641
I0428 12:08:25.014531 13425 solver.cpp:244]     Train net output #0: loss = 0.94191 (* 1 = 0.94191 loss)
I0428 12:08:25.014539 13425 solver.cpp:244]     Train net output #1: loss = 0.344539 (* 1 = 0.344539 loss)
I0428 12:08:25.014544 13425 solver.cpp:244]     Train net output #2: loss = 0.789957 (* 1 = 0.789957 loss)
I0428 12:08:25.014549 13425 sgd_solver.cpp:106] Iteration 58800, lr = 5e-07
I0428 12:10:04.431782 13425 solver.cpp:228] Iteration 58900, loss = 2.54566
I0428 12:10:04.432644 13425 solver.cpp:244]     Train net output #0: loss = 0.958011 (* 1 = 0.958011 loss)
I0428 12:10:04.432651 13425 solver.cpp:244]     Train net output #1: loss = 0.670872 (* 1 = 0.670872 loss)
I0428 12:10:04.432657 13425 solver.cpp:244]     Train net output #2: loss = 0.91678 (* 1 = 0.91678 loss)
I0428 12:10:04.432662 13425 sgd_solver.cpp:106] Iteration 58900, lr = 5e-07
I0428 12:11:43.082650 13425 solver.cpp:337] Iteration 59000, Testing net (#0)
I0428 12:11:43.082797 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 12:11:43.082800 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 12:11:43.082804 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 12:11:43.082818 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 12:11:43.082821 13425 net.cpp:693] Ignoring source layer visualize
I0428 12:11:43.082823 13425 net.cpp:693] Ignoring source layer fake
I0428 12:15:17.529589 13425 solver.cpp:404]     Test net output #0: loss = 0.947167 (* 1 = 0.947167 loss)
I0428 12:15:17.529748 13425 solver.cpp:404]     Test net output #1: loss = 0.615788 (* 1 = 0.615788 loss)
I0428 12:15:17.529758 13425 solver.cpp:404]     Test net output #2: loss = 0.817675 (* 1 = 0.817675 loss)
I0428 12:15:18.179704 13425 solver.cpp:228] Iteration 59000, loss = 1.97597
I0428 12:15:18.179745 13425 solver.cpp:244]     Train net output #0: loss = 0.94614 (* 1 = 0.94614 loss)
I0428 12:15:18.179751 13425 solver.cpp:244]     Train net output #1: loss = 0.452367 (* 1 = 0.452367 loss)
I0428 12:15:18.179756 13425 solver.cpp:244]     Train net output #2: loss = 0.577459 (* 1 = 0.577459 loss)
I0428 12:15:18.179760 13425 sgd_solver.cpp:106] Iteration 59000, lr = 5e-07
I0428 12:16:58.125403 13425 solver.cpp:228] Iteration 59100, loss = 2.12451
I0428 12:16:58.125571 13425 solver.cpp:244]     Train net output #0: loss = 0.651798 (* 1 = 0.651798 loss)
I0428 12:16:58.125578 13425 solver.cpp:244]     Train net output #1: loss = 0.634585 (* 1 = 0.634585 loss)
I0428 12:16:58.125583 13425 solver.cpp:244]     Train net output #2: loss = 0.838123 (* 1 = 0.838123 loss)
I0428 12:16:58.125591 13425 sgd_solver.cpp:106] Iteration 59100, lr = 5e-07
I0428 12:18:38.526341 13425 solver.cpp:228] Iteration 59200, loss = 2.56869
I0428 12:18:38.526510 13425 solver.cpp:244]     Train net output #0: loss = 0.949372 (* 1 = 0.949372 loss)
I0428 12:18:38.526518 13425 solver.cpp:244]     Train net output #1: loss = 0.684436 (* 1 = 0.684436 loss)
I0428 12:18:38.526525 13425 solver.cpp:244]     Train net output #2: loss = 0.934884 (* 1 = 0.934884 loss)
I0428 12:18:38.526530 13425 sgd_solver.cpp:106] Iteration 59200, lr = 5e-07
I0428 12:20:16.912375 13425 solver.cpp:228] Iteration 59300, loss = 2.52956
I0428 12:20:16.912518 13425 solver.cpp:244]     Train net output #0: loss = 0.937334 (* 1 = 0.937334 loss)
I0428 12:20:16.912528 13425 solver.cpp:244]     Train net output #1: loss = 0.680663 (* 1 = 0.680663 loss)
I0428 12:20:16.912533 13425 solver.cpp:244]     Train net output #2: loss = 0.911561 (* 1 = 0.911561 loss)
I0428 12:20:16.912539 13425 sgd_solver.cpp:106] Iteration 59300, lr = 5e-07
I0428 12:21:57.065207 13425 solver.cpp:228] Iteration 59400, loss = 2.43519
I0428 12:21:57.065353 13425 solver.cpp:244]     Train net output #0: loss = 0.90797 (* 1 = 0.90797 loss)
I0428 12:21:57.065361 13425 solver.cpp:244]     Train net output #1: loss = 0.656949 (* 1 = 0.656949 loss)
I0428 12:21:57.065367 13425 solver.cpp:244]     Train net output #2: loss = 0.870275 (* 1 = 0.870275 loss)
I0428 12:21:57.065372 13425 sgd_solver.cpp:106] Iteration 59400, lr = 5e-07
I0428 12:23:37.169713 13425 solver.cpp:228] Iteration 59500, loss = 2.51435
I0428 12:23:37.169886 13425 solver.cpp:244]     Train net output #0: loss = 0.973922 (* 1 = 0.973922 loss)
I0428 12:23:37.169894 13425 solver.cpp:244]     Train net output #1: loss = 0.807332 (* 1 = 0.807332 loss)
I0428 12:23:37.169900 13425 solver.cpp:244]     Train net output #2: loss = 0.733093 (* 1 = 0.733093 loss)
I0428 12:23:37.169906 13425 sgd_solver.cpp:106] Iteration 59500, lr = 5e-07
I0428 12:25:17.265100 13425 solver.cpp:228] Iteration 59600, loss = 2.70662
I0428 12:25:17.265244 13425 solver.cpp:244]     Train net output #0: loss = 0.990493 (* 1 = 0.990493 loss)
I0428 12:25:17.265252 13425 solver.cpp:244]     Train net output #1: loss = 0.838311 (* 1 = 0.838311 loss)
I0428 12:25:17.265259 13425 solver.cpp:244]     Train net output #2: loss = 0.877812 (* 1 = 0.877812 loss)
I0428 12:25:17.265264 13425 sgd_solver.cpp:106] Iteration 59600, lr = 5e-07
I0428 12:26:55.675621 13425 solver.cpp:228] Iteration 59700, loss = 2.52503
I0428 12:26:55.675770 13425 solver.cpp:244]     Train net output #0: loss = 0.990387 (* 1 = 0.990387 loss)
I0428 12:26:55.675779 13425 solver.cpp:244]     Train net output #1: loss = 0.674399 (* 1 = 0.674399 loss)
I0428 12:26:55.675784 13425 solver.cpp:244]     Train net output #2: loss = 0.860246 (* 1 = 0.860246 loss)
I0428 12:26:55.675791 13425 sgd_solver.cpp:106] Iteration 59700, lr = 5e-07
I0428 12:28:35.697221 13425 solver.cpp:228] Iteration 59800, loss = 2.64356
I0428 12:28:35.697387 13425 solver.cpp:244]     Train net output #0: loss = 0.975316 (* 1 = 0.975316 loss)
I0428 12:28:35.697398 13425 solver.cpp:244]     Train net output #1: loss = 0.762638 (* 1 = 0.762638 loss)
I0428 12:28:35.697407 13425 solver.cpp:244]     Train net output #2: loss = 0.905605 (* 1 = 0.905605 loss)
I0428 12:28:35.697414 13425 sgd_solver.cpp:106] Iteration 59800, lr = 5e-07
I0428 12:30:21.680025 13425 solver.cpp:228] Iteration 59900, loss = 2.20971
I0428 12:30:21.680212 13425 solver.cpp:244]     Train net output #0: loss = 0.987654 (* 1 = 0.987654 loss)
I0428 12:30:21.680223 13425 solver.cpp:244]     Train net output #1: loss = 0.578176 (* 1 = 0.578176 loss)
I0428 12:30:21.680232 13425 solver.cpp:244]     Train net output #2: loss = 0.643876 (* 1 = 0.643876 loss)
I0428 12:30:21.680239 13425 sgd_solver.cpp:106] Iteration 59900, lr = 5e-07
I0428 12:32:00.099179 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_60000.caffemodel
I0428 12:32:35.242174 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_60000.solverstate
I0428 12:32:35.428197 13425 solver.cpp:337] Iteration 60000, Testing net (#0)
I0428 12:32:35.428241 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 12:32:35.428243 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 12:32:35.428246 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 12:32:35.428259 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 12:32:35.428263 13425 net.cpp:693] Ignoring source layer visualize
I0428 12:32:35.428264 13425 net.cpp:693] Ignoring source layer fake
I0428 12:36:09.686131 13425 solver.cpp:404]     Test net output #0: loss = 0.94304 (* 1 = 0.94304 loss)
I0428 12:36:09.686276 13425 solver.cpp:404]     Test net output #1: loss = 0.626505 (* 1 = 0.626505 loss)
I0428 12:36:09.686287 13425 solver.cpp:404]     Test net output #2: loss = 0.824776 (* 1 = 0.824776 loss)
I0428 12:36:10.343042 13425 solver.cpp:228] Iteration 60000, loss = 2.50649
I0428 12:36:10.343086 13425 solver.cpp:244]     Train net output #0: loss = 0.929245 (* 1 = 0.929245 loss)
I0428 12:36:10.343091 13425 solver.cpp:244]     Train net output #1: loss = 0.625724 (* 1 = 0.625724 loss)
I0428 12:36:10.343096 13425 solver.cpp:244]     Train net output #2: loss = 0.951522 (* 1 = 0.951522 loss)
I0428 12:36:10.343101 13425 sgd_solver.cpp:106] Iteration 60000, lr = 5e-08
I0428 12:37:55.097105 13425 solver.cpp:228] Iteration 60100, loss = 2.37581
I0428 12:37:55.097251 13425 solver.cpp:244]     Train net output #0: loss = 0.927137 (* 1 = 0.927137 loss)
I0428 12:37:55.097260 13425 solver.cpp:244]     Train net output #1: loss = 0.548275 (* 1 = 0.548275 loss)
I0428 12:37:55.097266 13425 solver.cpp:244]     Train net output #2: loss = 0.900402 (* 1 = 0.900402 loss)
I0428 12:37:55.097271 13425 sgd_solver.cpp:106] Iteration 60100, lr = 5e-08
I0428 12:39:35.126394 13425 solver.cpp:228] Iteration 60200, loss = 2.39145
I0428 12:39:35.126534 13425 solver.cpp:244]     Train net output #0: loss = 0.969457 (* 1 = 0.969457 loss)
I0428 12:39:35.126543 13425 solver.cpp:244]     Train net output #1: loss = 0.663321 (* 1 = 0.663321 loss)
I0428 12:39:35.126549 13425 solver.cpp:244]     Train net output #2: loss = 0.758668 (* 1 = 0.758668 loss)
I0428 12:39:35.126554 13425 sgd_solver.cpp:106] Iteration 60200, lr = 5e-08
I0428 12:41:13.161999 13425 solver.cpp:228] Iteration 60300, loss = 2.22601
I0428 12:41:13.162143 13425 solver.cpp:244]     Train net output #0: loss = 0.974898 (* 1 = 0.974898 loss)
I0428 12:41:13.162150 13425 solver.cpp:244]     Train net output #1: loss = 0.501834 (* 1 = 0.501834 loss)
I0428 12:41:13.162156 13425 solver.cpp:244]     Train net output #2: loss = 0.749277 (* 1 = 0.749277 loss)
I0428 12:41:13.162163 13425 sgd_solver.cpp:106] Iteration 60300, lr = 5e-08
I0428 12:42:52.886168 13425 solver.cpp:228] Iteration 60400, loss = 2.35574
I0428 12:42:52.886314 13425 solver.cpp:244]     Train net output #0: loss = 0.786858 (* 1 = 0.786858 loss)
I0428 12:42:52.886322 13425 solver.cpp:244]     Train net output #1: loss = 0.653275 (* 1 = 0.653275 loss)
I0428 12:42:52.886327 13425 solver.cpp:244]     Train net output #2: loss = 0.915606 (* 1 = 0.915606 loss)
I0428 12:42:52.886333 13425 sgd_solver.cpp:106] Iteration 60400, lr = 5e-08
I0428 12:44:32.636075 13425 solver.cpp:228] Iteration 60500, loss = 2.54186
I0428 12:44:32.636253 13425 solver.cpp:244]     Train net output #0: loss = 0.942662 (* 1 = 0.942662 loss)
I0428 12:44:32.636262 13425 solver.cpp:244]     Train net output #1: loss = 0.680162 (* 1 = 0.680162 loss)
I0428 12:44:32.636268 13425 solver.cpp:244]     Train net output #2: loss = 0.919036 (* 1 = 0.919036 loss)
I0428 12:44:32.636274 13425 sgd_solver.cpp:106] Iteration 60500, lr = 5e-08
I0428 12:46:12.519714 13425 solver.cpp:228] Iteration 60600, loss = 2.48513
I0428 12:46:12.519861 13425 solver.cpp:244]     Train net output #0: loss = 0.913962 (* 1 = 0.913962 loss)
I0428 12:46:12.519870 13425 solver.cpp:244]     Train net output #1: loss = 0.651634 (* 1 = 0.651634 loss)
I0428 12:46:12.519876 13425 solver.cpp:244]     Train net output #2: loss = 0.919532 (* 1 = 0.919532 loss)
I0428 12:46:12.519881 13425 sgd_solver.cpp:106] Iteration 60600, lr = 5e-08
I0428 12:47:50.624315 13425 solver.cpp:228] Iteration 60700, loss = 2.5073
I0428 12:47:50.624471 13425 solver.cpp:244]     Train net output #0: loss = 0.938422 (* 1 = 0.938422 loss)
I0428 12:47:50.624480 13425 solver.cpp:244]     Train net output #1: loss = 0.67075 (* 1 = 0.67075 loss)
I0428 12:47:50.624485 13425 solver.cpp:244]     Train net output #2: loss = 0.898126 (* 1 = 0.898126 loss)
I0428 12:47:50.624491 13425 sgd_solver.cpp:106] Iteration 60700, lr = 5e-08
I0428 12:49:30.524670 13425 solver.cpp:228] Iteration 60800, loss = 2.32962
I0428 12:49:30.524843 13425 solver.cpp:244]     Train net output #0: loss = 0.910448 (* 1 = 0.910448 loss)
I0428 12:49:30.524852 13425 solver.cpp:244]     Train net output #1: loss = 0.519541 (* 1 = 0.519541 loss)
I0428 12:49:30.524858 13425 solver.cpp:244]     Train net output #2: loss = 0.899629 (* 1 = 0.899629 loss)
I0428 12:49:30.524864 13425 sgd_solver.cpp:106] Iteration 60800, lr = 5e-08
I0428 12:51:10.330428 13425 solver.cpp:228] Iteration 60900, loss = 2.70566
I0428 12:51:10.330580 13425 solver.cpp:244]     Train net output #0: loss = 0.990045 (* 1 = 0.990045 loss)
I0428 12:51:10.330590 13425 solver.cpp:244]     Train net output #1: loss = 0.79682 (* 1 = 0.79682 loss)
I0428 12:51:10.330595 13425 solver.cpp:244]     Train net output #2: loss = 0.918799 (* 1 = 0.918799 loss)
I0428 12:51:10.330600 13425 sgd_solver.cpp:106] Iteration 60900, lr = 5e-08
I0428 12:52:48.976358 13425 solver.cpp:337] Iteration 61000, Testing net (#0)
I0428 12:52:48.976496 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 12:52:48.976500 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 12:52:48.976503 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 12:52:48.976518 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 12:52:48.976522 13425 net.cpp:693] Ignoring source layer visualize
I0428 12:52:48.976524 13425 net.cpp:693] Ignoring source layer fake
I0428 12:56:23.420089 13425 solver.cpp:404]     Test net output #0: loss = 0.947661 (* 1 = 0.947661 loss)
I0428 12:56:23.420228 13425 solver.cpp:404]     Test net output #1: loss = 0.633029 (* 1 = 0.633029 loss)
I0428 12:56:23.420236 13425 solver.cpp:404]     Test net output #2: loss = 0.832708 (* 1 = 0.832708 loss)
I0428 12:56:24.075521 13425 solver.cpp:228] Iteration 61000, loss = 2.07684
I0428 12:56:24.075547 13425 solver.cpp:244]     Train net output #0: loss = 0.988965 (* 1 = 0.988965 loss)
I0428 12:56:24.075553 13425 solver.cpp:244]     Train net output #1: loss = 0.434155 (* 1 = 0.434155 loss)
I0428 12:56:24.075558 13425 solver.cpp:244]     Train net output #2: loss = 0.653719 (* 1 = 0.653719 loss)
I0428 12:56:24.075563 13425 sgd_solver.cpp:106] Iteration 61000, lr = 5e-08
I0428 12:58:02.394094 13425 solver.cpp:228] Iteration 61100, loss = 2.18441
I0428 12:58:02.394239 13425 solver.cpp:244]     Train net output #0: loss = 0.981634 (* 1 = 0.981634 loss)
I0428 12:58:02.394248 13425 solver.cpp:244]     Train net output #1: loss = 0.495168 (* 1 = 0.495168 loss)
I0428 12:58:02.394253 13425 solver.cpp:244]     Train net output #2: loss = 0.707612 (* 1 = 0.707612 loss)
I0428 12:58:02.394259 13425 sgd_solver.cpp:106] Iteration 61100, lr = 5e-08
I0428 12:59:42.127477 13425 solver.cpp:228] Iteration 61200, loss = 2.35262
I0428 12:59:42.127645 13425 solver.cpp:244]     Train net output #0: loss = 0.963711 (* 1 = 0.963711 loss)
I0428 12:59:42.127651 13425 solver.cpp:244]     Train net output #1: loss = 0.478857 (* 1 = 0.478857 loss)
I0428 12:59:42.127657 13425 solver.cpp:244]     Train net output #2: loss = 0.910055 (* 1 = 0.910055 loss)
I0428 12:59:42.127662 13425 sgd_solver.cpp:106] Iteration 61200, lr = 5e-08
I0428 13:01:21.435756 13425 solver.cpp:228] Iteration 61300, loss = 2.29832
I0428 13:01:21.435916 13425 solver.cpp:244]     Train net output #0: loss = 0.929248 (* 1 = 0.929248 loss)
I0428 13:01:21.435925 13425 solver.cpp:244]     Train net output #1: loss = 0.441261 (* 1 = 0.441261 loss)
I0428 13:01:21.435930 13425 solver.cpp:244]     Train net output #2: loss = 0.927811 (* 1 = 0.927811 loss)
I0428 13:01:21.435936 13425 sgd_solver.cpp:106] Iteration 61300, lr = 5e-08
I0428 13:03:00.817080 13425 solver.cpp:228] Iteration 61400, loss = 2.57317
I0428 13:03:00.817230 13425 solver.cpp:244]     Train net output #0: loss = 0.932287 (* 1 = 0.932287 loss)
I0428 13:03:00.817239 13425 solver.cpp:244]     Train net output #1: loss = 0.682549 (* 1 = 0.682549 loss)
I0428 13:03:00.817245 13425 solver.cpp:244]     Train net output #2: loss = 0.958339 (* 1 = 0.958339 loss)
I0428 13:03:00.817250 13425 sgd_solver.cpp:106] Iteration 61400, lr = 5e-08
I0428 13:04:40.468030 13425 solver.cpp:228] Iteration 61500, loss = 2.16733
I0428 13:04:40.468186 13425 solver.cpp:244]     Train net output #0: loss = 0.972898 (* 1 = 0.972898 loss)
I0428 13:04:40.468195 13425 solver.cpp:244]     Train net output #1: loss = 0.462194 (* 1 = 0.462194 loss)
I0428 13:04:40.468200 13425 solver.cpp:244]     Train net output #2: loss = 0.732242 (* 1 = 0.732242 loss)
I0428 13:04:40.468206 13425 sgd_solver.cpp:106] Iteration 61500, lr = 5e-08
I0428 13:06:20.352634 13425 solver.cpp:228] Iteration 61600, loss = 2.42783
I0428 13:06:20.352779 13425 solver.cpp:244]     Train net output #0: loss = 0.808315 (* 1 = 0.808315 loss)
I0428 13:06:20.352787 13425 solver.cpp:244]     Train net output #1: loss = 0.743594 (* 1 = 0.743594 loss)
I0428 13:06:20.352792 13425 solver.cpp:244]     Train net output #2: loss = 0.875922 (* 1 = 0.875922 loss)
I0428 13:06:20.352798 13425 sgd_solver.cpp:106] Iteration 61600, lr = 5e-08
I0428 13:08:00.403353 13425 solver.cpp:228] Iteration 61700, loss = 2.5624
I0428 13:08:00.403488 13425 solver.cpp:244]     Train net output #0: loss = 0.954427 (* 1 = 0.954427 loss)
I0428 13:08:00.403496 13425 solver.cpp:244]     Train net output #1: loss = 0.746384 (* 1 = 0.746384 loss)
I0428 13:08:00.403502 13425 solver.cpp:244]     Train net output #2: loss = 0.861593 (* 1 = 0.861593 loss)
I0428 13:08:00.403508 13425 sgd_solver.cpp:106] Iteration 61700, lr = 5e-08
I0428 13:09:38.710590 13425 solver.cpp:228] Iteration 61800, loss = 2.60833
I0428 13:09:38.710719 13425 solver.cpp:244]     Train net output #0: loss = 0.939144 (* 1 = 0.939144 loss)
I0428 13:09:38.710727 13425 solver.cpp:244]     Train net output #1: loss = 0.765882 (* 1 = 0.765882 loss)
I0428 13:09:38.710734 13425 solver.cpp:244]     Train net output #2: loss = 0.903308 (* 1 = 0.903308 loss)
I0428 13:09:38.710741 13425 sgd_solver.cpp:106] Iteration 61800, lr = 5e-08
I0428 13:11:18.751929 13425 solver.cpp:228] Iteration 61900, loss = 2.59594
I0428 13:11:18.752064 13425 solver.cpp:244]     Train net output #0: loss = 0.953961 (* 1 = 0.953961 loss)
I0428 13:11:18.752074 13425 solver.cpp:244]     Train net output #1: loss = 0.824729 (* 1 = 0.824729 loss)
I0428 13:11:18.752079 13425 solver.cpp:244]     Train net output #2: loss = 0.817246 (* 1 = 0.817246 loss)
I0428 13:11:18.752084 13425 sgd_solver.cpp:106] Iteration 61900, lr = 5e-08
I0428 13:12:57.763419 13425 solver.cpp:337] Iteration 62000, Testing net (#0)
I0428 13:12:57.763591 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 13:12:57.763595 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 13:12:57.763598 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 13:12:57.763612 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 13:12:57.763617 13425 net.cpp:693] Ignoring source layer visualize
I0428 13:12:57.763618 13425 net.cpp:693] Ignoring source layer fake
I0428 13:16:32.889493 13425 solver.cpp:404]     Test net output #0: loss = 0.949541 (* 1 = 0.949541 loss)
I0428 13:16:32.889621 13425 solver.cpp:404]     Test net output #1: loss = 0.631096 (* 1 = 0.631096 loss)
I0428 13:16:32.889629 13425 solver.cpp:404]     Test net output #2: loss = 0.828777 (* 1 = 0.828777 loss)
I0428 13:16:33.544018 13425 solver.cpp:228] Iteration 62000, loss = 2.28511
I0428 13:16:33.544061 13425 solver.cpp:244]     Train net output #0: loss = 0.956203 (* 1 = 0.956203 loss)
I0428 13:16:33.544067 13425 solver.cpp:244]     Train net output #1: loss = 0.626658 (* 1 = 0.626658 loss)
I0428 13:16:33.544073 13425 solver.cpp:244]     Train net output #2: loss = 0.702252 (* 1 = 0.702252 loss)
I0428 13:16:33.544080 13425 sgd_solver.cpp:106] Iteration 62000, lr = 5e-08
I0428 13:18:13.713388 13425 solver.cpp:228] Iteration 62100, loss = 2.73636
I0428 13:18:13.713554 13425 solver.cpp:244]     Train net output #0: loss = 0.98784 (* 1 = 0.98784 loss)
I0428 13:18:13.713563 13425 solver.cpp:244]     Train net output #1: loss = 0.852208 (* 1 = 0.852208 loss)
I0428 13:18:13.713568 13425 solver.cpp:244]     Train net output #2: loss = 0.896311 (* 1 = 0.896311 loss)
I0428 13:18:13.713574 13425 sgd_solver.cpp:106] Iteration 62100, lr = 5e-08
I0428 13:19:51.936909 13425 solver.cpp:228] Iteration 62200, loss = 2.71797
I0428 13:19:51.937062 13425 solver.cpp:244]     Train net output #0: loss = 0.987446 (* 1 = 0.987446 loss)
I0428 13:19:51.937069 13425 solver.cpp:244]     Train net output #1: loss = 0.833104 (* 1 = 0.833104 loss)
I0428 13:19:51.937074 13425 solver.cpp:244]     Train net output #2: loss = 0.897418 (* 1 = 0.897418 loss)
I0428 13:19:51.937080 13425 sgd_solver.cpp:106] Iteration 62200, lr = 5e-08
I0428 13:21:31.893201 13425 solver.cpp:228] Iteration 62300, loss = 2.68689
I0428 13:21:31.893369 13425 solver.cpp:244]     Train net output #0: loss = 0.97058 (* 1 = 0.97058 loss)
I0428 13:21:31.893378 13425 solver.cpp:244]     Train net output #1: loss = 0.798186 (* 1 = 0.798186 loss)
I0428 13:21:31.893383 13425 solver.cpp:244]     Train net output #2: loss = 0.91812 (* 1 = 0.91812 loss)
I0428 13:21:31.893389 13425 sgd_solver.cpp:106] Iteration 62300, lr = 5e-08
I0428 13:23:11.754063 13425 solver.cpp:228] Iteration 62400, loss = 2.28493
I0428 13:23:11.754221 13425 solver.cpp:244]     Train net output #0: loss = 0.98053 (* 1 = 0.98053 loss)
I0428 13:23:11.754230 13425 solver.cpp:244]     Train net output #1: loss = 0.497588 (* 1 = 0.497588 loss)
I0428 13:23:11.754236 13425 solver.cpp:244]     Train net output #2: loss = 0.806817 (* 1 = 0.806817 loss)
I0428 13:23:11.754242 13425 sgd_solver.cpp:106] Iteration 62400, lr = 5e-08
I0428 13:24:51.326381 13425 solver.cpp:228] Iteration 62500, loss = 2.40661
I0428 13:24:51.326560 13425 solver.cpp:244]     Train net output #0: loss = 0.922929 (* 1 = 0.922929 loss)
I0428 13:24:51.326572 13425 solver.cpp:244]     Train net output #1: loss = 0.534889 (* 1 = 0.534889 loss)
I0428 13:24:51.326581 13425 solver.cpp:244]     Train net output #2: loss = 0.948793 (* 1 = 0.948793 loss)
I0428 13:24:51.326589 13425 sgd_solver.cpp:106] Iteration 62500, lr = 5e-08
I0428 13:26:30.968072 13425 solver.cpp:228] Iteration 62600, loss = 2.26232
I0428 13:26:30.968243 13425 solver.cpp:244]     Train net output #0: loss = 0.946591 (* 1 = 0.946591 loss)
I0428 13:26:30.968255 13425 solver.cpp:244]     Train net output #1: loss = 0.582604 (* 1 = 0.582604 loss)
I0428 13:26:30.968263 13425 solver.cpp:244]     Train net output #2: loss = 0.733126 (* 1 = 0.733126 loss)
I0428 13:26:30.968271 13425 sgd_solver.cpp:106] Iteration 62600, lr = 5e-08
I0428 13:28:10.720861 13425 solver.cpp:228] Iteration 62700, loss = 2.36847
I0428 13:28:10.721043 13425 solver.cpp:244]     Train net output #0: loss = 0.975785 (* 1 = 0.975785 loss)
I0428 13:28:10.721052 13425 solver.cpp:244]     Train net output #1: loss = 0.634203 (* 1 = 0.634203 loss)
I0428 13:28:10.721057 13425 solver.cpp:244]     Train net output #2: loss = 0.758477 (* 1 = 0.758477 loss)
I0428 13:28:10.721065 13425 sgd_solver.cpp:106] Iteration 62700, lr = 5e-08
I0428 13:29:48.979009 13425 solver.cpp:228] Iteration 62800, loss = 2.36591
I0428 13:29:48.979161 13425 solver.cpp:244]     Train net output #0: loss = 0.962866 (* 1 = 0.962866 loss)
I0428 13:29:48.979168 13425 solver.cpp:244]     Train net output #1: loss = 0.643459 (* 1 = 0.643459 loss)
I0428 13:29:48.979176 13425 solver.cpp:244]     Train net output #2: loss = 0.759582 (* 1 = 0.759582 loss)
I0428 13:29:48.979182 13425 sgd_solver.cpp:106] Iteration 62800, lr = 5e-08
I0428 13:31:28.831106 13425 solver.cpp:228] Iteration 62900, loss = 2.36813
I0428 13:31:28.831252 13425 solver.cpp:244]     Train net output #0: loss = 0.816868 (* 1 = 0.816868 loss)
I0428 13:31:28.831260 13425 solver.cpp:244]     Train net output #1: loss = 0.666193 (* 1 = 0.666193 loss)
I0428 13:31:28.831266 13425 solver.cpp:244]     Train net output #2: loss = 0.885069 (* 1 = 0.885069 loss)
I0428 13:31:28.831272 13425 sgd_solver.cpp:106] Iteration 62900, lr = 5e-08
I0428 13:33:08.136390 13425 solver.cpp:337] Iteration 63000, Testing net (#0)
I0428 13:33:08.136545 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 13:33:08.136550 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 13:33:08.136554 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 13:33:08.136567 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 13:33:08.136571 13425 net.cpp:693] Ignoring source layer visualize
I0428 13:33:08.136574 13425 net.cpp:693] Ignoring source layer fake
I0428 13:36:43.770364 13425 solver.cpp:404]     Test net output #0: loss = 0.948595 (* 1 = 0.948595 loss)
I0428 13:36:43.770491 13425 solver.cpp:404]     Test net output #1: loss = 0.618495 (* 1 = 0.618495 loss)
I0428 13:36:43.770499 13425 solver.cpp:404]     Test net output #2: loss = 0.829306 (* 1 = 0.829306 loss)
I0428 13:36:44.421512 13425 solver.cpp:228] Iteration 63000, loss = 2.48786
I0428 13:36:44.421555 13425 solver.cpp:244]     Train net output #0: loss = 0.937768 (* 1 = 0.937768 loss)
I0428 13:36:44.421561 13425 solver.cpp:244]     Train net output #1: loss = 0.664826 (* 1 = 0.664826 loss)
I0428 13:36:44.421566 13425 solver.cpp:244]     Train net output #2: loss = 0.885269 (* 1 = 0.885269 loss)
I0428 13:36:44.421571 13425 sgd_solver.cpp:106] Iteration 63000, lr = 5e-08
I0428 13:38:24.399940 13425 solver.cpp:228] Iteration 63100, loss = 2.43226
I0428 13:38:24.400074 13425 solver.cpp:244]     Train net output #0: loss = 0.910233 (* 1 = 0.910233 loss)
I0428 13:38:24.400084 13425 solver.cpp:244]     Train net output #1: loss = 0.662892 (* 1 = 0.662892 loss)
I0428 13:38:24.400089 13425 solver.cpp:244]     Train net output #2: loss = 0.859135 (* 1 = 0.859135 loss)
I0428 13:38:24.400096 13425 sgd_solver.cpp:106] Iteration 63100, lr = 5e-08
I0428 13:40:02.693670 13425 solver.cpp:228] Iteration 63200, loss = 2.54384
I0428 13:40:02.693831 13425 solver.cpp:244]     Train net output #0: loss = 0.960274 (* 1 = 0.960274 loss)
I0428 13:40:02.693840 13425 solver.cpp:244]     Train net output #1: loss = 0.738477 (* 1 = 0.738477 loss)
I0428 13:40:02.693845 13425 solver.cpp:244]     Train net output #2: loss = 0.845085 (* 1 = 0.845085 loss)
I0428 13:40:02.693851 13425 sgd_solver.cpp:106] Iteration 63200, lr = 5e-08
I0428 13:41:42.726166 13425 solver.cpp:228] Iteration 63300, loss = 2.39476
I0428 13:41:42.726336 13425 solver.cpp:244]     Train net output #0: loss = 0.924741 (* 1 = 0.924741 loss)
I0428 13:41:42.726344 13425 solver.cpp:244]     Train net output #1: loss = 0.566818 (* 1 = 0.566818 loss)
I0428 13:41:42.726351 13425 solver.cpp:244]     Train net output #2: loss = 0.9032 (* 1 = 0.9032 loss)
I0428 13:41:42.726366 13425 sgd_solver.cpp:106] Iteration 63300, lr = 5e-08
I0428 13:43:22.669101 13425 solver.cpp:228] Iteration 63400, loss = 2.75969
I0428 13:43:22.669292 13425 solver.cpp:244]     Train net output #0: loss = 0.981482 (* 1 = 0.981482 loss)
I0428 13:43:22.669301 13425 solver.cpp:244]     Train net output #1: loss = 0.835684 (* 1 = 0.835684 loss)
I0428 13:43:22.669306 13425 solver.cpp:244]     Train net output #2: loss = 0.942522 (* 1 = 0.942522 loss)
I0428 13:43:22.669312 13425 sgd_solver.cpp:106] Iteration 63400, lr = 5e-08
I0428 13:45:02.733294 13425 solver.cpp:228] Iteration 63500, loss = 2.12934
I0428 13:45:02.733453 13425 solver.cpp:244]     Train net output #0: loss = 0.9672 (* 1 = 0.9672 loss)
I0428 13:45:02.733464 13425 solver.cpp:244]     Train net output #1: loss = 0.468042 (* 1 = 0.468042 loss)
I0428 13:45:02.733469 13425 solver.cpp:244]     Train net output #2: loss = 0.694098 (* 1 = 0.694098 loss)
I0428 13:45:02.733475 13425 sgd_solver.cpp:106] Iteration 63500, lr = 5e-08
I0428 13:46:41.072353 13425 solver.cpp:228] Iteration 63600, loss = 2.37048
I0428 13:46:41.072540 13425 solver.cpp:244]     Train net output #0: loss = 0.962935 (* 1 = 0.962935 loss)
I0428 13:46:41.072547 13425 solver.cpp:244]     Train net output #1: loss = 0.651226 (* 1 = 0.651226 loss)
I0428 13:46:41.072553 13425 solver.cpp:244]     Train net output #2: loss = 0.756319 (* 1 = 0.756319 loss)
I0428 13:46:41.072558 13425 sgd_solver.cpp:106] Iteration 63600, lr = 5e-08
I0428 13:48:21.014194 13425 solver.cpp:228] Iteration 63700, loss = 2.5456
I0428 13:48:21.014350 13425 solver.cpp:244]     Train net output #0: loss = 0.964978 (* 1 = 0.964978 loss)
I0428 13:48:21.014358 13425 solver.cpp:244]     Train net output #1: loss = 0.634956 (* 1 = 0.634956 loss)
I0428 13:48:21.014364 13425 solver.cpp:244]     Train net output #2: loss = 0.945662 (* 1 = 0.945662 loss)
I0428 13:48:21.014370 13425 sgd_solver.cpp:106] Iteration 63700, lr = 5e-08
I0428 13:50:00.730332 13425 solver.cpp:228] Iteration 63800, loss = 2.34535
I0428 13:50:00.737484 13425 solver.cpp:244]     Train net output #0: loss = 0.952676 (* 1 = 0.952676 loss)
I0428 13:50:00.737493 13425 solver.cpp:244]     Train net output #1: loss = 0.46744 (* 1 = 0.46744 loss)
I0428 13:50:00.737499 13425 solver.cpp:244]     Train net output #2: loss = 0.925232 (* 1 = 0.925232 loss)
I0428 13:50:00.737505 13425 sgd_solver.cpp:106] Iteration 63800, lr = 5e-08
I0428 13:51:40.284942 13425 solver.cpp:228] Iteration 63900, loss = 2.47554
I0428 13:51:40.285075 13425 solver.cpp:244]     Train net output #0: loss = 0.941764 (* 1 = 0.941764 loss)
I0428 13:51:40.285084 13425 solver.cpp:244]     Train net output #1: loss = 0.577753 (* 1 = 0.577753 loss)
I0428 13:51:40.285090 13425 solver.cpp:244]     Train net output #2: loss = 0.956022 (* 1 = 0.956022 loss)
I0428 13:51:40.285096 13425 sgd_solver.cpp:106] Iteration 63900, lr = 5e-08
I0428 13:53:19.210733 13425 solver.cpp:337] Iteration 64000, Testing net (#0)
I0428 13:53:19.212035 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 13:53:19.212055 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 13:53:19.212060 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 13:53:19.212079 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 13:53:19.212098 13425 net.cpp:693] Ignoring source layer visualize
I0428 13:53:19.212101 13425 net.cpp:693] Ignoring source layer fake
I0428 13:56:55.030724 13425 solver.cpp:404]     Test net output #0: loss = 0.947533 (* 1 = 0.947533 loss)
I0428 13:56:55.030853 13425 solver.cpp:404]     Test net output #1: loss = 0.618171 (* 1 = 0.618171 loss)
I0428 13:56:55.030861 13425 solver.cpp:404]     Test net output #2: loss = 0.817838 (* 1 = 0.817838 loss)
I0428 13:56:55.695032 13425 solver.cpp:228] Iteration 64000, loss = 2.13294
I0428 13:56:55.695086 13425 solver.cpp:244]     Train net output #0: loss = 0.952657 (* 1 = 0.952657 loss)
I0428 13:56:55.695094 13425 solver.cpp:244]     Train net output #1: loss = 0.428564 (* 1 = 0.428564 loss)
I0428 13:56:55.695102 13425 solver.cpp:244]     Train net output #2: loss = 0.751714 (* 1 = 0.751714 loss)
I0428 13:56:55.695109 13425 sgd_solver.cpp:106] Iteration 64000, lr = 5e-08
I0428 13:58:35.699421 13425 solver.cpp:228] Iteration 64100, loss = 2.49659
I0428 13:58:35.700498 13425 solver.cpp:244]     Train net output #0: loss = 0.897035 (* 1 = 0.897035 loss)
I0428 13:58:35.700526 13425 solver.cpp:244]     Train net output #1: loss = 0.773821 (* 1 = 0.773821 loss)
I0428 13:58:35.700533 13425 solver.cpp:244]     Train net output #2: loss = 0.825737 (* 1 = 0.825737 loss)
I0428 13:58:35.700541 13425 sgd_solver.cpp:106] Iteration 64100, lr = 5e-08
I0428 14:00:15.843809 13425 solver.cpp:228] Iteration 64200, loss = 2.46722
I0428 14:00:15.843996 13425 solver.cpp:244]     Train net output #0: loss = 0.969864 (* 1 = 0.969864 loss)
I0428 14:00:15.844003 13425 solver.cpp:244]     Train net output #1: loss = 0.813279 (* 1 = 0.813279 loss)
I0428 14:00:15.844008 13425 solver.cpp:244]     Train net output #2: loss = 0.684082 (* 1 = 0.684082 loss)
I0428 14:00:15.844014 13425 sgd_solver.cpp:106] Iteration 64200, lr = 5e-08
I0428 14:01:54.472084 13425 solver.cpp:228] Iteration 64300, loss = 2.60817
I0428 14:01:54.472241 13425 solver.cpp:244]     Train net output #0: loss = 0.960476 (* 1 = 0.960476 loss)
I0428 14:01:54.472249 13425 solver.cpp:244]     Train net output #1: loss = 0.803971 (* 1 = 0.803971 loss)
I0428 14:01:54.472255 13425 solver.cpp:244]     Train net output #2: loss = 0.843725 (* 1 = 0.843725 loss)
I0428 14:01:54.472262 13425 sgd_solver.cpp:106] Iteration 64300, lr = 5e-08
I0428 14:03:34.621009 13425 solver.cpp:228] Iteration 64400, loss = 2.57885
I0428 14:03:34.621208 13425 solver.cpp:244]     Train net output #0: loss = 0.96161 (* 1 = 0.96161 loss)
I0428 14:03:34.621217 13425 solver.cpp:244]     Train net output #1: loss = 0.797723 (* 1 = 0.797723 loss)
I0428 14:03:34.621223 13425 solver.cpp:244]     Train net output #2: loss = 0.819513 (* 1 = 0.819513 loss)
I0428 14:03:34.621230 13425 sgd_solver.cpp:106] Iteration 64400, lr = 5e-08
I0428 14:05:14.695019 13425 solver.cpp:228] Iteration 64500, loss = 2.38219
I0428 14:05:14.695202 13425 solver.cpp:244]     Train net output #0: loss = 0.92609 (* 1 = 0.92609 loss)
I0428 14:05:14.695214 13425 solver.cpp:244]     Train net output #1: loss = 0.543693 (* 1 = 0.543693 loss)
I0428 14:05:14.695222 13425 solver.cpp:244]     Train net output #2: loss = 0.912409 (* 1 = 0.912409 loss)
I0428 14:05:14.695230 13425 sgd_solver.cpp:106] Iteration 64500, lr = 5e-08
I0428 14:06:54.869668 13425 solver.cpp:228] Iteration 64600, loss = 2.75128
I0428 14:06:54.869803 13425 solver.cpp:244]     Train net output #0: loss = 0.988335 (* 1 = 0.988335 loss)
I0428 14:06:54.869812 13425 solver.cpp:244]     Train net output #1: loss = 0.820512 (* 1 = 0.820512 loss)
I0428 14:06:54.869817 13425 solver.cpp:244]     Train net output #2: loss = 0.942434 (* 1 = 0.942434 loss)
I0428 14:06:54.869823 13425 sgd_solver.cpp:106] Iteration 64600, lr = 5e-08
I0428 14:08:33.222098 13425 solver.cpp:228] Iteration 64700, loss = 2.69443
I0428 14:08:33.222257 13425 solver.cpp:244]     Train net output #0: loss = 0.987991 (* 1 = 0.987991 loss)
I0428 14:08:33.222265 13425 solver.cpp:244]     Train net output #1: loss = 0.796603 (* 1 = 0.796603 loss)
I0428 14:08:33.222271 13425 solver.cpp:244]     Train net output #2: loss = 0.909832 (* 1 = 0.909832 loss)
I0428 14:08:33.222277 13425 sgd_solver.cpp:106] Iteration 64700, lr = 5e-08
I0428 14:10:13.583489 13425 solver.cpp:228] Iteration 64800, loss = 2.62369
I0428 14:10:13.587393 13425 solver.cpp:244]     Train net output #0: loss = 0.975414 (* 1 = 0.975414 loss)
I0428 14:10:13.587401 13425 solver.cpp:244]     Train net output #1: loss = 0.700589 (* 1 = 0.700589 loss)
I0428 14:10:13.587407 13425 solver.cpp:244]     Train net output #2: loss = 0.947689 (* 1 = 0.947689 loss)
I0428 14:10:13.587412 13425 sgd_solver.cpp:106] Iteration 64800, lr = 5e-08
I0428 14:11:53.572141 13425 solver.cpp:228] Iteration 64900, loss = 2.61373
I0428 14:11:53.572319 13425 solver.cpp:244]     Train net output #0: loss = 0.974362 (* 1 = 0.974362 loss)
I0428 14:11:53.572327 13425 solver.cpp:244]     Train net output #1: loss = 0.698628 (* 1 = 0.698628 loss)
I0428 14:11:53.572332 13425 solver.cpp:244]     Train net output #2: loss = 0.940738 (* 1 = 0.940738 loss)
I0428 14:11:53.572338 13425 sgd_solver.cpp:106] Iteration 64900, lr = 5e-08
I0428 14:13:32.186578 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_65000.caffemodel
I0428 14:13:50.333268 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_65000.solverstate
I0428 14:13:50.523171 13425 solver.cpp:337] Iteration 65000, Testing net (#0)
I0428 14:13:50.523211 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 14:13:50.523213 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 14:13:50.523217 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 14:13:50.523231 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 14:13:50.523233 13425 net.cpp:693] Ignoring source layer visualize
I0428 14:13:50.523234 13425 net.cpp:693] Ignoring source layer fake
I0428 14:17:24.650940 13425 solver.cpp:404]     Test net output #0: loss = 0.941878 (* 1 = 0.941878 loss)
I0428 14:17:24.651084 13425 solver.cpp:404]     Test net output #1: loss = 0.623063 (* 1 = 0.623063 loss)
I0428 14:17:24.651091 13425 solver.cpp:404]     Test net output #2: loss = 0.825737 (* 1 = 0.825737 loss)
I0428 14:17:25.302098 13425 solver.cpp:228] Iteration 65000, loss = 2.34667
I0428 14:17:25.302150 13425 solver.cpp:244]     Train net output #0: loss = 0.931224 (* 1 = 0.931224 loss)
I0428 14:17:25.302157 13425 solver.cpp:244]     Train net output #1: loss = 0.491564 (* 1 = 0.491564 loss)
I0428 14:17:25.302161 13425 solver.cpp:244]     Train net output #2: loss = 0.923887 (* 1 = 0.923887 loss)
I0428 14:17:25.302167 13425 sgd_solver.cpp:106] Iteration 65000, lr = 5e-08
I0428 14:19:04.962201 13425 solver.cpp:228] Iteration 65100, loss = 2.23597
I0428 14:19:04.962355 13425 solver.cpp:244]     Train net output #0: loss = 0.962941 (* 1 = 0.962941 loss)
I0428 14:19:04.962363 13425 solver.cpp:244]     Train net output #1: loss = 0.531366 (* 1 = 0.531366 loss)
I0428 14:19:04.962368 13425 solver.cpp:244]     Train net output #2: loss = 0.741667 (* 1 = 0.741667 loss)
I0428 14:19:04.962375 13425 sgd_solver.cpp:106] Iteration 65100, lr = 5e-08
I0428 14:20:44.901213 13425 solver.cpp:228] Iteration 65200, loss = 2.14685
I0428 14:20:44.901387 13425 solver.cpp:244]     Train net output #0: loss = 0.973204 (* 1 = 0.973204 loss)
I0428 14:20:44.901396 13425 solver.cpp:244]     Train net output #1: loss = 0.603075 (* 1 = 0.603075 loss)
I0428 14:20:44.901402 13425 solver.cpp:244]     Train net output #2: loss = 0.57057 (* 1 = 0.57057 loss)
I0428 14:20:44.901409 13425 sgd_solver.cpp:106] Iteration 65200, lr = 5e-08
I0428 14:22:23.317298 13425 solver.cpp:228] Iteration 65300, loss = 2.04097
I0428 14:22:23.317466 13425 solver.cpp:244]     Train net output #0: loss = 0.976184 (* 1 = 0.976184 loss)
I0428 14:22:23.317478 13425 solver.cpp:244]     Train net output #1: loss = 0.5143 (* 1 = 0.5143 loss)
I0428 14:22:23.317487 13425 solver.cpp:244]     Train net output #2: loss = 0.550491 (* 1 = 0.550491 loss)
I0428 14:22:23.317494 13425 sgd_solver.cpp:106] Iteration 65300, lr = 5e-08
I0428 14:24:03.842391 13425 solver.cpp:228] Iteration 65400, loss = 2.47902
I0428 14:24:03.842545 13425 solver.cpp:244]     Train net output #0: loss = 0.904375 (* 1 = 0.904375 loss)
I0428 14:24:03.842553 13425 solver.cpp:244]     Train net output #1: loss = 0.72594 (* 1 = 0.72594 loss)
I0428 14:24:03.842559 13425 solver.cpp:244]     Train net output #2: loss = 0.848702 (* 1 = 0.848702 loss)
I0428 14:24:03.842564 13425 sgd_solver.cpp:106] Iteration 65400, lr = 5e-08
I0428 14:25:44.072365 13425 solver.cpp:228] Iteration 65500, loss = 2.47383
I0428 14:25:44.072515 13425 solver.cpp:244]     Train net output #0: loss = 0.950981 (* 1 = 0.950981 loss)
I0428 14:25:44.072525 13425 solver.cpp:244]     Train net output #1: loss = 0.790431 (* 1 = 0.790431 loss)
I0428 14:25:44.072530 13425 solver.cpp:244]     Train net output #2: loss = 0.732418 (* 1 = 0.732418 loss)
I0428 14:25:44.072536 13425 sgd_solver.cpp:106] Iteration 65500, lr = 5e-08
I0428 14:27:24.212317 13425 solver.cpp:228] Iteration 65600, loss = 2.6144
I0428 14:27:24.212498 13425 solver.cpp:244]     Train net output #0: loss = 0.961975 (* 1 = 0.961975 loss)
I0428 14:27:24.212507 13425 solver.cpp:244]     Train net output #1: loss = 0.795424 (* 1 = 0.795424 loss)
I0428 14:27:24.212513 13425 solver.cpp:244]     Train net output #2: loss = 0.857001 (* 1 = 0.857001 loss)
I0428 14:27:24.212518 13425 sgd_solver.cpp:106] Iteration 65600, lr = 5e-08
I0428 14:29:02.687808 13425 solver.cpp:228] Iteration 65700, loss = 2.63632
I0428 14:29:02.687970 13425 solver.cpp:244]     Train net output #0: loss = 0.974932 (* 1 = 0.974932 loss)
I0428 14:29:02.687978 13425 solver.cpp:244]     Train net output #1: loss = 0.798046 (* 1 = 0.798046 loss)
I0428 14:29:02.687984 13425 solver.cpp:244]     Train net output #2: loss = 0.863341 (* 1 = 0.863341 loss)
I0428 14:29:02.687991 13425 sgd_solver.cpp:106] Iteration 65700, lr = 5e-08
I0428 14:30:42.801959 13425 solver.cpp:228] Iteration 65800, loss = 2.6968
I0428 14:30:42.802117 13425 solver.cpp:244]     Train net output #0: loss = 0.977242 (* 1 = 0.977242 loss)
I0428 14:30:42.802125 13425 solver.cpp:244]     Train net output #1: loss = 0.813557 (* 1 = 0.813557 loss)
I0428 14:30:42.802130 13425 solver.cpp:244]     Train net output #2: loss = 0.906 (* 1 = 0.906 loss)
I0428 14:30:42.802136 13425 sgd_solver.cpp:106] Iteration 65800, lr = 5e-08
I0428 14:32:25.721005 13425 solver.cpp:228] Iteration 65900, loss = 2.68215
I0428 14:32:25.721184 13425 solver.cpp:244]     Train net output #0: loss = 0.972068 (* 1 = 0.972068 loss)
I0428 14:32:25.721194 13425 solver.cpp:244]     Train net output #1: loss = 0.764467 (* 1 = 0.764467 loss)
I0428 14:32:25.721204 13425 solver.cpp:244]     Train net output #2: loss = 0.945612 (* 1 = 0.945612 loss)
I0428 14:32:25.721212 13425 sgd_solver.cpp:106] Iteration 65900, lr = 5e-08
I0428 14:34:18.088157 13425 solver.cpp:337] Iteration 66000, Testing net (#0)
I0428 14:34:18.088291 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 14:34:18.088296 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 14:34:18.088300 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 14:34:18.088315 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 14:34:18.088318 13425 net.cpp:693] Ignoring source layer visualize
I0428 14:34:18.088320 13425 net.cpp:693] Ignoring source layer fake
I0428 14:37:53.355545 13425 solver.cpp:404]     Test net output #0: loss = 0.947124 (* 1 = 0.947124 loss)
I0428 14:37:53.355684 13425 solver.cpp:404]     Test net output #1: loss = 0.63001 (* 1 = 0.63001 loss)
I0428 14:37:53.355691 13425 solver.cpp:404]     Test net output #2: loss = 0.830315 (* 1 = 0.830315 loss)
I0428 14:37:54.005720 13425 solver.cpp:228] Iteration 66000, loss = 2.37032
I0428 14:37:54.005764 13425 solver.cpp:244]     Train net output #0: loss = 0.964465 (* 1 = 0.964465 loss)
I0428 14:37:54.005769 13425 solver.cpp:244]     Train net output #1: loss = 0.567637 (* 1 = 0.567637 loss)
I0428 14:37:54.005774 13425 solver.cpp:244]     Train net output #2: loss = 0.83822 (* 1 = 0.83822 loss)
I0428 14:37:54.005779 13425 sgd_solver.cpp:106] Iteration 66000, lr = 5e-08
I0428 14:39:32.427358 13425 solver.cpp:228] Iteration 66100, loss = 2.48077
I0428 14:39:32.427491 13425 solver.cpp:244]     Train net output #0: loss = 0.960234 (* 1 = 0.960234 loss)
I0428 14:39:32.427500 13425 solver.cpp:244]     Train net output #1: loss = 0.59549 (* 1 = 0.59549 loss)
I0428 14:39:32.427505 13425 solver.cpp:244]     Train net output #2: loss = 0.925042 (* 1 = 0.925042 loss)
I0428 14:39:32.427512 13425 sgd_solver.cpp:106] Iteration 66100, lr = 5e-08
I0428 14:41:16.669425 13425 solver.cpp:228] Iteration 66200, loss = 2.48178
I0428 14:41:16.669598 13425 solver.cpp:244]     Train net output #0: loss = 0.974144 (* 1 = 0.974144 loss)
I0428 14:41:16.669607 13425 solver.cpp:244]     Train net output #1: loss = 0.614198 (* 1 = 0.614198 loss)
I0428 14:41:16.669613 13425 solver.cpp:244]     Train net output #2: loss = 0.893442 (* 1 = 0.893442 loss)
I0428 14:41:16.669620 13425 sgd_solver.cpp:106] Iteration 66200, lr = 5e-08
I0428 14:42:56.109607 13425 solver.cpp:228] Iteration 66300, loss = 2.28018
I0428 14:42:56.109807 13425 solver.cpp:244]     Train net output #0: loss = 0.965137 (* 1 = 0.965137 loss)
I0428 14:42:56.109817 13425 solver.cpp:244]     Train net output #1: loss = 0.411177 (* 1 = 0.411177 loss)
I0428 14:42:56.109822 13425 solver.cpp:244]     Train net output #2: loss = 0.903869 (* 1 = 0.903869 loss)
I0428 14:42:56.109828 13425 sgd_solver.cpp:106] Iteration 66300, lr = 5e-08
I0428 14:44:35.592192 13425 solver.cpp:228] Iteration 66400, loss = 2.1927
I0428 14:44:35.592329 13425 solver.cpp:244]     Train net output #0: loss = 0.950166 (* 1 = 0.950166 loss)
I0428 14:44:35.592337 13425 solver.cpp:244]     Train net output #1: loss = 0.477527 (* 1 = 0.477527 loss)
I0428 14:44:35.592342 13425 solver.cpp:244]     Train net output #2: loss = 0.765005 (* 1 = 0.765005 loss)
I0428 14:44:35.592348 13425 sgd_solver.cpp:106] Iteration 66400, lr = 5e-08
I0428 14:46:15.823824 13425 solver.cpp:228] Iteration 66500, loss = 2.37493
I0428 14:46:15.823989 13425 solver.cpp:244]     Train net output #0: loss = 0.96918 (* 1 = 0.96918 loss)
I0428 14:46:15.823997 13425 solver.cpp:244]     Train net output #1: loss = 0.635113 (* 1 = 0.635113 loss)
I0428 14:46:15.824003 13425 solver.cpp:244]     Train net output #2: loss = 0.770638 (* 1 = 0.770638 loss)
I0428 14:46:15.824010 13425 sgd_solver.cpp:106] Iteration 66500, lr = 5e-08
I0428 14:47:55.879509 13425 solver.cpp:228] Iteration 66600, loss = 2.19205
I0428 14:47:55.879783 13425 solver.cpp:244]     Train net output #0: loss = 0.673346 (* 1 = 0.673346 loss)
I0428 14:47:55.879808 13425 solver.cpp:244]     Train net output #1: loss = 0.61493 (* 1 = 0.61493 loss)
I0428 14:47:55.879827 13425 solver.cpp:244]     Train net output #2: loss = 0.903776 (* 1 = 0.903776 loss)
I0428 14:47:55.879844 13425 sgd_solver.cpp:106] Iteration 66600, lr = 5e-08
I0428 14:49:36.165465 13425 solver.cpp:228] Iteration 66700, loss = 2.3493
I0428 14:49:36.165616 13425 solver.cpp:244]     Train net output #0: loss = 0.965524 (* 1 = 0.965524 loss)
I0428 14:49:36.165626 13425 solver.cpp:244]     Train net output #1: loss = 0.662801 (* 1 = 0.662801 loss)
I0428 14:49:36.165632 13425 solver.cpp:244]     Train net output #2: loss = 0.720977 (* 1 = 0.720977 loss)
I0428 14:49:36.165638 13425 sgd_solver.cpp:106] Iteration 66700, lr = 5e-08
I0428 14:51:14.329747 13425 solver.cpp:228] Iteration 66800, loss = 2.52295
I0428 14:51:14.329905 13425 solver.cpp:244]     Train net output #0: loss = 0.964527 (* 1 = 0.964527 loss)
I0428 14:51:14.329913 13425 solver.cpp:244]     Train net output #1: loss = 0.685581 (* 1 = 0.685581 loss)
I0428 14:51:14.329918 13425 solver.cpp:244]     Train net output #2: loss = 0.872845 (* 1 = 0.872845 loss)
I0428 14:51:14.329924 13425 sgd_solver.cpp:106] Iteration 66800, lr = 5e-08
I0428 14:52:54.207356 13425 solver.cpp:228] Iteration 66900, loss = 2.45758
I0428 14:52:54.207525 13425 solver.cpp:244]     Train net output #0: loss = 0.90867 (* 1 = 0.90867 loss)
I0428 14:52:54.207533 13425 solver.cpp:244]     Train net output #1: loss = 0.644992 (* 1 = 0.644992 loss)
I0428 14:52:54.207538 13425 solver.cpp:244]     Train net output #2: loss = 0.903922 (* 1 = 0.903922 loss)
I0428 14:52:54.207545 13425 sgd_solver.cpp:106] Iteration 66900, lr = 5e-08
I0428 14:54:33.160897 13425 solver.cpp:337] Iteration 67000, Testing net (#0)
I0428 14:54:33.161053 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 14:54:33.161057 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 14:54:33.161062 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 14:54:33.161077 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 14:54:33.161079 13425 net.cpp:693] Ignoring source layer visualize
I0428 14:54:33.161082 13425 net.cpp:693] Ignoring source layer fake
I0428 14:58:08.210474 13425 solver.cpp:404]     Test net output #0: loss = 0.94937 (* 1 = 0.94937 loss)
I0428 14:58:08.210667 13425 solver.cpp:404]     Test net output #1: loss = 0.628707 (* 1 = 0.628707 loss)
I0428 14:58:08.210675 13425 solver.cpp:404]     Test net output #2: loss = 0.826221 (* 1 = 0.826221 loss)
I0428 14:58:08.865167 13425 solver.cpp:228] Iteration 67000, loss = 2.63084
I0428 14:58:08.865195 13425 solver.cpp:244]     Train net output #0: loss = 0.975237 (* 1 = 0.975237 loss)
I0428 14:58:08.865200 13425 solver.cpp:244]     Train net output #1: loss = 0.74641 (* 1 = 0.74641 loss)
I0428 14:58:08.865206 13425 solver.cpp:244]     Train net output #2: loss = 0.909188 (* 1 = 0.909188 loss)
I0428 14:58:08.865209 13425 sgd_solver.cpp:106] Iteration 67000, lr = 5e-08
I0428 14:59:48.921994 13425 solver.cpp:228] Iteration 67100, loss = 2.71123
I0428 14:59:48.922147 13425 solver.cpp:244]     Train net output #0: loss = 0.987313 (* 1 = 0.987313 loss)
I0428 14:59:48.922155 13425 solver.cpp:244]     Train net output #1: loss = 0.789437 (* 1 = 0.789437 loss)
I0428 14:59:48.922161 13425 solver.cpp:244]     Train net output #2: loss = 0.93448 (* 1 = 0.93448 loss)
I0428 14:59:48.922168 13425 sgd_solver.cpp:106] Iteration 67100, lr = 5e-08
I0428 15:01:27.143489 13425 solver.cpp:228] Iteration 67200, loss = 2.71575
I0428 15:01:27.143647 13425 solver.cpp:244]     Train net output #0: loss = 0.986735 (* 1 = 0.986735 loss)
I0428 15:01:27.143656 13425 solver.cpp:244]     Train net output #1: loss = 0.807221 (* 1 = 0.807221 loss)
I0428 15:01:27.143661 13425 solver.cpp:244]     Train net output #2: loss = 0.921791 (* 1 = 0.921791 loss)
I0428 15:01:27.143667 13425 sgd_solver.cpp:106] Iteration 67200, lr = 5e-08
I0428 15:03:07.224594 13425 solver.cpp:228] Iteration 67300, loss = 2.56989
I0428 15:03:07.224753 13425 solver.cpp:244]     Train net output #0: loss = 0.972728 (* 1 = 0.972728 loss)
I0428 15:03:07.224762 13425 solver.cpp:244]     Train net output #1: loss = 0.673134 (* 1 = 0.673134 loss)
I0428 15:03:07.224768 13425 solver.cpp:244]     Train net output #2: loss = 0.924029 (* 1 = 0.924029 loss)
I0428 15:03:07.224774 13425 sgd_solver.cpp:106] Iteration 67300, lr = 5e-08
I0428 15:04:47.094024 13425 solver.cpp:228] Iteration 67400, loss = 2.33672
I0428 15:04:47.094200 13425 solver.cpp:244]     Train net output #0: loss = 0.975339 (* 1 = 0.975339 loss)
I0428 15:04:47.094209 13425 solver.cpp:244]     Train net output #1: loss = 0.582759 (* 1 = 0.582759 loss)
I0428 15:04:47.094214 13425 solver.cpp:244]     Train net output #2: loss = 0.778625 (* 1 = 0.778625 loss)
I0428 15:04:47.094220 13425 sgd_solver.cpp:106] Iteration 67400, lr = 5e-08
I0428 15:06:26.631731 13425 solver.cpp:228] Iteration 67500, loss = 2.15163
I0428 15:06:26.631894 13425 solver.cpp:244]     Train net output #0: loss = 0.939615 (* 1 = 0.939615 loss)
I0428 15:06:26.631902 13425 solver.cpp:244]     Train net output #1: loss = 0.321578 (* 1 = 0.321578 loss)
I0428 15:06:26.631907 13425 solver.cpp:244]     Train net output #2: loss = 0.890436 (* 1 = 0.890436 loss)
I0428 15:06:26.631914 13425 sgd_solver.cpp:106] Iteration 67500, lr = 5e-08
I0428 15:08:06.109151 13425 solver.cpp:228] Iteration 67600, loss = 2.21981
I0428 15:08:06.109292 13425 solver.cpp:244]     Train net output #0: loss = 0.933947 (* 1 = 0.933947 loss)
I0428 15:08:06.109299 13425 solver.cpp:244]     Train net output #1: loss = 0.510788 (* 1 = 0.510788 loss)
I0428 15:08:06.109305 13425 solver.cpp:244]     Train net output #2: loss = 0.775075 (* 1 = 0.775075 loss)
I0428 15:08:06.109311 13425 sgd_solver.cpp:106] Iteration 67600, lr = 5e-08
I0428 15:09:45.954294 13425 solver.cpp:228] Iteration 67700, loss = 2.59112
I0428 15:09:45.954445 13425 solver.cpp:244]     Train net output #0: loss = 0.966665 (* 1 = 0.966665 loss)
I0428 15:09:45.954454 13425 solver.cpp:244]     Train net output #1: loss = 0.694622 (* 1 = 0.694622 loss)
I0428 15:09:45.954460 13425 solver.cpp:244]     Train net output #2: loss = 0.929831 (* 1 = 0.929831 loss)
I0428 15:09:45.954466 13425 sgd_solver.cpp:106] Iteration 67700, lr = 5e-08
I0428 15:11:24.329113 13425 solver.cpp:228] Iteration 67800, loss = 2.16502
I0428 15:11:24.329334 13425 solver.cpp:244]     Train net output #0: loss = 0.962739 (* 1 = 0.962739 loss)
I0428 15:11:24.329342 13425 solver.cpp:244]     Train net output #1: loss = 0.459998 (* 1 = 0.459998 loss)
I0428 15:11:24.329349 13425 solver.cpp:244]     Train net output #2: loss = 0.742281 (* 1 = 0.742281 loss)
I0428 15:11:24.329355 13425 sgd_solver.cpp:106] Iteration 67800, lr = 5e-08
I0428 15:13:04.399592 13425 solver.cpp:228] Iteration 67900, loss = 2.19395
I0428 15:13:04.399770 13425 solver.cpp:244]     Train net output #0: loss = 0.74143 (* 1 = 0.74143 loss)
I0428 15:13:04.399777 13425 solver.cpp:244]     Train net output #1: loss = 0.570204 (* 1 = 0.570204 loss)
I0428 15:13:04.399782 13425 solver.cpp:244]     Train net output #2: loss = 0.882315 (* 1 = 0.882315 loss)
I0428 15:13:04.399790 13425 sgd_solver.cpp:106] Iteration 67900, lr = 5e-08
I0428 15:14:43.569386 13425 solver.cpp:337] Iteration 68000, Testing net (#0)
I0428 15:14:43.571239 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 15:14:43.571244 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 15:14:43.571249 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 15:14:43.571261 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 15:14:43.571264 13425 net.cpp:693] Ignoring source layer visualize
I0428 15:14:43.571266 13425 net.cpp:693] Ignoring source layer fake
I0428 15:18:19.213099 13425 solver.cpp:404]     Test net output #0: loss = 0.948188 (* 1 = 0.948188 loss)
I0428 15:18:19.213254 13425 solver.cpp:404]     Test net output #1: loss = 0.617694 (* 1 = 0.617694 loss)
I0428 15:18:19.213261 13425 solver.cpp:404]     Test net output #2: loss = 0.82996 (* 1 = 0.82996 loss)
I0428 15:18:19.864217 13425 solver.cpp:228] Iteration 68000, loss = 2.48914
I0428 15:18:19.864262 13425 solver.cpp:244]     Train net output #0: loss = 0.964766 (* 1 = 0.964766 loss)
I0428 15:18:19.864269 13425 solver.cpp:244]     Train net output #1: loss = 0.780346 (* 1 = 0.780346 loss)
I0428 15:18:19.864272 13425 solver.cpp:244]     Train net output #2: loss = 0.744033 (* 1 = 0.744033 loss)
I0428 15:18:19.864279 13425 sgd_solver.cpp:106] Iteration 68000, lr = 5e-08
I0428 15:19:59.947023 13425 solver.cpp:228] Iteration 68100, loss = 2.59015
I0428 15:19:59.947196 13425 solver.cpp:244]     Train net output #0: loss = 0.97712 (* 1 = 0.97712 loss)
I0428 15:19:59.947204 13425 solver.cpp:244]     Train net output #1: loss = 0.754348 (* 1 = 0.754348 loss)
I0428 15:19:59.947209 13425 solver.cpp:244]     Train net output #2: loss = 0.858684 (* 1 = 0.858684 loss)
I0428 15:19:59.947216 13425 sgd_solver.cpp:106] Iteration 68100, lr = 5e-08
I0428 15:21:38.278380 13425 solver.cpp:228] Iteration 68200, loss = 2.43481
I0428 15:21:38.278522 13425 solver.cpp:244]     Train net output #0: loss = 0.908161 (* 1 = 0.908161 loss)
I0428 15:21:38.278530 13425 solver.cpp:244]     Train net output #1: loss = 0.603779 (* 1 = 0.603779 loss)
I0428 15:21:38.278537 13425 solver.cpp:244]     Train net output #2: loss = 0.922875 (* 1 = 0.922875 loss)
I0428 15:21:38.278542 13425 sgd_solver.cpp:106] Iteration 68200, lr = 5e-08
I0428 15:23:18.291584 13425 solver.cpp:228] Iteration 68300, loss = 2.45901
I0428 15:23:18.291733 13425 solver.cpp:244]     Train net output #0: loss = 0.960723 (* 1 = 0.960723 loss)
I0428 15:23:18.291740 13425 solver.cpp:244]     Train net output #1: loss = 0.617138 (* 1 = 0.617138 loss)
I0428 15:23:18.291746 13425 solver.cpp:244]     Train net output #2: loss = 0.881145 (* 1 = 0.881145 loss)
I0428 15:23:18.291752 13425 sgd_solver.cpp:106] Iteration 68300, lr = 5e-08
I0428 15:24:58.280158 13425 solver.cpp:228] Iteration 68400, loss = 2.62798
I0428 15:24:58.280310 13425 solver.cpp:244]     Train net output #0: loss = 0.98059 (* 1 = 0.98059 loss)
I0428 15:24:58.280319 13425 solver.cpp:244]     Train net output #1: loss = 0.735225 (* 1 = 0.735225 loss)
I0428 15:24:58.280325 13425 solver.cpp:244]     Train net output #2: loss = 0.912164 (* 1 = 0.912164 loss)
I0428 15:24:58.280331 13425 sgd_solver.cpp:106] Iteration 68400, lr = 5e-08
I0428 15:26:38.262934 13425 solver.cpp:228] Iteration 68500, loss = 2.26538
I0428 15:26:38.263105 13425 solver.cpp:244]     Train net output #0: loss = 0.981436 (* 1 = 0.981436 loss)
I0428 15:26:38.263114 13425 solver.cpp:244]     Train net output #1: loss = 0.58443 (* 1 = 0.58443 loss)
I0428 15:26:38.263119 13425 solver.cpp:244]     Train net output #2: loss = 0.699515 (* 1 = 0.699515 loss)
I0428 15:26:38.263126 13425 sgd_solver.cpp:106] Iteration 68500, lr = 5e-08
I0428 15:28:16.761857 13425 solver.cpp:228] Iteration 68600, loss = 2.05769
I0428 15:28:16.762897 13425 solver.cpp:244]     Train net output #0: loss = 0.974321 (* 1 = 0.974321 loss)
I0428 15:28:16.762903 13425 solver.cpp:244]     Train net output #1: loss = 0.492919 (* 1 = 0.492919 loss)
I0428 15:28:16.762909 13425 solver.cpp:244]     Train net output #2: loss = 0.590451 (* 1 = 0.590451 loss)
I0428 15:28:16.762915 13425 sgd_solver.cpp:106] Iteration 68600, lr = 5e-08
I0428 15:29:56.631860 13425 solver.cpp:228] Iteration 68700, loss = 2.4324
I0428 15:29:56.632002 13425 solver.cpp:244]     Train net output #0: loss = 0.958559 (* 1 = 0.958559 loss)
I0428 15:29:56.632012 13425 solver.cpp:244]     Train net output #1: loss = 0.57575 (* 1 = 0.57575 loss)
I0428 15:29:56.632017 13425 solver.cpp:244]     Train net output #2: loss = 0.898094 (* 1 = 0.898094 loss)
I0428 15:29:56.632024 13425 sgd_solver.cpp:106] Iteration 68700, lr = 5e-08
I0428 15:31:36.133257 13425 solver.cpp:228] Iteration 68800, loss = 2.27328
I0428 15:31:36.133405 13425 solver.cpp:244]     Train net output #0: loss = 0.948047 (* 1 = 0.948047 loss)
I0428 15:31:36.133414 13425 solver.cpp:244]     Train net output #1: loss = 0.43382 (* 1 = 0.43382 loss)
I0428 15:31:36.133419 13425 solver.cpp:244]     Train net output #2: loss = 0.891415 (* 1 = 0.891415 loss)
I0428 15:31:36.133425 13425 sgd_solver.cpp:106] Iteration 68800, lr = 5e-08
I0428 15:33:15.633612 13425 solver.cpp:228] Iteration 68900, loss = 2.19941
I0428 15:33:15.633764 13425 solver.cpp:244]     Train net output #0: loss = 0.933827 (* 1 = 0.933827 loss)
I0428 15:33:15.633771 13425 solver.cpp:244]     Train net output #1: loss = 0.496932 (* 1 = 0.496932 loss)
I0428 15:33:15.633777 13425 solver.cpp:244]     Train net output #2: loss = 0.768654 (* 1 = 0.768654 loss)
I0428 15:33:15.633785 13425 sgd_solver.cpp:106] Iteration 68900, lr = 5e-08
I0428 15:34:54.372629 13425 solver.cpp:337] Iteration 69000, Testing net (#0)
I0428 15:34:54.372795 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 15:34:54.372799 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 15:34:54.372803 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 15:34:54.372817 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 15:34:54.372822 13425 net.cpp:693] Ignoring source layer visualize
I0428 15:34:54.372823 13425 net.cpp:693] Ignoring source layer fake
I0428 15:38:29.145265 13425 solver.cpp:404]     Test net output #0: loss = 0.946577 (* 1 = 0.946577 loss)
I0428 15:38:29.145406 13425 solver.cpp:404]     Test net output #1: loss = 0.617438 (* 1 = 0.617438 loss)
I0428 15:38:29.145412 13425 solver.cpp:404]     Test net output #2: loss = 0.817181 (* 1 = 0.817181 loss)
I0428 15:38:29.796376 13425 solver.cpp:228] Iteration 69000, loss = 2.15113
I0428 15:38:29.796404 13425 solver.cpp:244]     Train net output #0: loss = 0.972339 (* 1 = 0.972339 loss)
I0428 15:38:29.796411 13425 solver.cpp:244]     Train net output #1: loss = 0.595799 (* 1 = 0.595799 loss)
I0428 15:38:29.796416 13425 solver.cpp:244]     Train net output #2: loss = 0.582988 (* 1 = 0.582988 loss)
I0428 15:38:29.796419 13425 sgd_solver.cpp:106] Iteration 69000, lr = 5e-08
I0428 15:40:09.762121 13425 solver.cpp:228] Iteration 69100, loss = 2.09959
I0428 15:40:09.762274 13425 solver.cpp:244]     Train net output #0: loss = 0.629137 (* 1 = 0.629137 loss)
I0428 15:40:09.762282 13425 solver.cpp:244]     Train net output #1: loss = 0.568918 (* 1 = 0.568918 loss)
I0428 15:40:09.762287 13425 solver.cpp:244]     Train net output #2: loss = 0.901538 (* 1 = 0.901538 loss)
I0428 15:40:09.762295 13425 sgd_solver.cpp:106] Iteration 69100, lr = 5e-08
I0428 15:41:50.977378 13425 solver.cpp:228] Iteration 69200, loss = 2.50902
I0428 15:41:50.977625 13425 solver.cpp:244]     Train net output #0: loss = 0.969383 (* 1 = 0.969383 loss)
I0428 15:41:50.977640 13425 solver.cpp:244]     Train net output #1: loss = 0.672939 (* 1 = 0.672939 loss)
I0428 15:41:50.977649 13425 solver.cpp:244]     Train net output #2: loss = 0.866695 (* 1 = 0.866695 loss)
I0428 15:41:50.977659 13425 sgd_solver.cpp:106] Iteration 69200, lr = 5e-08
I0428 15:43:29.353940 13425 solver.cpp:228] Iteration 69300, loss = 2.55417
I0428 15:43:29.354106 13425 solver.cpp:244]     Train net output #0: loss = 0.951027 (* 1 = 0.951027 loss)
I0428 15:43:29.354115 13425 solver.cpp:244]     Train net output #1: loss = 0.684856 (* 1 = 0.684856 loss)
I0428 15:43:29.354120 13425 solver.cpp:244]     Train net output #2: loss = 0.91829 (* 1 = 0.91829 loss)
I0428 15:43:29.354126 13425 sgd_solver.cpp:106] Iteration 69300, lr = 5e-08
I0428 15:45:09.420265 13425 solver.cpp:228] Iteration 69400, loss = 2.51766
I0428 15:45:09.420430 13425 solver.cpp:244]     Train net output #0: loss = 0.89391 (* 1 = 0.89391 loss)
I0428 15:45:09.420439 13425 solver.cpp:244]     Train net output #1: loss = 0.691855 (* 1 = 0.691855 loss)
I0428 15:45:09.420444 13425 solver.cpp:244]     Train net output #2: loss = 0.931894 (* 1 = 0.931894 loss)
I0428 15:45:09.420450 13425 sgd_solver.cpp:106] Iteration 69400, lr = 5e-08
I0428 15:46:49.443452 13425 solver.cpp:228] Iteration 69500, loss = 2.57083
I0428 15:46:49.443619 13425 solver.cpp:244]     Train net output #0: loss = 0.950024 (* 1 = 0.950024 loss)
I0428 15:46:49.443626 13425 solver.cpp:244]     Train net output #1: loss = 0.707274 (* 1 = 0.707274 loss)
I0428 15:46:49.443632 13425 solver.cpp:244]     Train net output #2: loss = 0.913532 (* 1 = 0.913532 loss)
I0428 15:46:49.443639 13425 sgd_solver.cpp:106] Iteration 69500, lr = 5e-08
I0428 15:48:29.469996 13425 solver.cpp:228] Iteration 69600, loss = 2.76762
I0428 15:48:29.470142 13425 solver.cpp:244]     Train net output #0: loss = 0.980203 (* 1 = 0.980203 loss)
I0428 15:48:29.470150 13425 solver.cpp:244]     Train net output #1: loss = 0.836564 (* 1 = 0.836564 loss)
I0428 15:48:29.470156 13425 solver.cpp:244]     Train net output #2: loss = 0.950851 (* 1 = 0.950851 loss)
I0428 15:48:29.470162 13425 sgd_solver.cpp:106] Iteration 69600, lr = 5e-08
I0428 15:50:07.820078 13425 solver.cpp:228] Iteration 69700, loss = 2.7408
I0428 15:50:07.820225 13425 solver.cpp:244]     Train net output #0: loss = 0.976573 (* 1 = 0.976573 loss)
I0428 15:50:07.820235 13425 solver.cpp:244]     Train net output #1: loss = 0.831518 (* 1 = 0.831518 loss)
I0428 15:50:07.820240 13425 solver.cpp:244]     Train net output #2: loss = 0.932711 (* 1 = 0.932711 loss)
I0428 15:50:07.820246 13425 sgd_solver.cpp:106] Iteration 69700, lr = 5e-08
I0428 15:51:47.837376 13425 solver.cpp:228] Iteration 69800, loss = 2.58912
I0428 15:51:47.837528 13425 solver.cpp:244]     Train net output #0: loss = 0.962574 (* 1 = 0.962574 loss)
I0428 15:51:47.837535 13425 solver.cpp:244]     Train net output #1: loss = 0.699497 (* 1 = 0.699497 loss)
I0428 15:51:47.837541 13425 solver.cpp:244]     Train net output #2: loss = 0.927051 (* 1 = 0.927051 loss)
I0428 15:51:47.837546 13425 sgd_solver.cpp:106] Iteration 69800, lr = 5e-08
I0428 15:53:27.761478 13425 solver.cpp:228] Iteration 69900, loss = 2.24544
I0428 15:53:27.761629 13425 solver.cpp:244]     Train net output #0: loss = 0.980631 (* 1 = 0.980631 loss)
I0428 15:53:27.761637 13425 solver.cpp:244]     Train net output #1: loss = 0.540464 (* 1 = 0.540464 loss)
I0428 15:53:27.761643 13425 solver.cpp:244]     Train net output #2: loss = 0.724346 (* 1 = 0.724346 loss)
I0428 15:53:27.761651 13425 sgd_solver.cpp:106] Iteration 69900, lr = 5e-08
I0428 15:55:06.214898 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_70000.caffemodel
I0428 15:55:14.499553 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_70000.solverstate
I0428 15:55:14.700189 13425 solver.cpp:337] Iteration 70000, Testing net (#0)
I0428 15:55:14.700232 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 15:55:14.700234 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 15:55:14.700237 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 15:55:14.700250 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 15:55:14.700254 13425 net.cpp:693] Ignoring source layer visualize
I0428 15:55:14.700255 13425 net.cpp:693] Ignoring source layer fake
I0428 15:58:50.098285 13425 solver.cpp:404]     Test net output #0: loss = 0.942605 (* 1 = 0.942605 loss)
I0428 15:58:50.098433 13425 solver.cpp:404]     Test net output #1: loss = 0.625875 (* 1 = 0.625875 loss)
I0428 15:58:50.098441 13425 solver.cpp:404]     Test net output #2: loss = 0.826868 (* 1 = 0.826868 loss)
I0428 15:58:50.753201 13425 solver.cpp:228] Iteration 70000, loss = 2.33549
I0428 15:58:50.753231 13425 solver.cpp:244]     Train net output #0: loss = 0.937626 (* 1 = 0.937626 loss)
I0428 15:58:50.753252 13425 solver.cpp:244]     Train net output #1: loss = 0.452459 (* 1 = 0.452459 loss)
I0428 15:58:50.753257 13425 solver.cpp:244]     Train net output #2: loss = 0.945409 (* 1 = 0.945409 loss)
I0428 15:58:50.753262 13425 sgd_solver.cpp:106] Iteration 70000, lr = 5e-08
I0428 16:00:30.165881 13425 solver.cpp:228] Iteration 70100, loss = 2.13875
I0428 16:00:30.166049 13425 solver.cpp:244]     Train net output #0: loss = 0.983581 (* 1 = 0.983581 loss)
I0428 16:00:30.166057 13425 solver.cpp:244]     Train net output #1: loss = 0.598567 (* 1 = 0.598567 loss)
I0428 16:00:30.166062 13425 solver.cpp:244]     Train net output #2: loss = 0.5566 (* 1 = 0.5566 loss)
I0428 16:00:30.166069 13425 sgd_solver.cpp:106] Iteration 70100, lr = 5e-08
I0428 16:02:09.746086 13425 solver.cpp:228] Iteration 70200, loss = 2.13336
I0428 16:02:09.747135 13425 solver.cpp:244]     Train net output #0: loss = 0.979832 (* 1 = 0.979832 loss)
I0428 16:02:09.747141 13425 solver.cpp:244]     Train net output #1: loss = 0.576694 (* 1 = 0.576694 loss)
I0428 16:02:09.747146 13425 solver.cpp:244]     Train net output #2: loss = 0.576839 (* 1 = 0.576839 loss)
I0428 16:02:09.747153 13425 sgd_solver.cpp:106] Iteration 70200, lr = 5e-08
I0428 16:03:47.879756 13425 solver.cpp:228] Iteration 70300, loss = 2.29342
I0428 16:03:47.879897 13425 solver.cpp:244]     Train net output #0: loss = 0.955175 (* 1 = 0.955175 loss)
I0428 16:03:47.879905 13425 solver.cpp:244]     Train net output #1: loss = 0.572739 (* 1 = 0.572739 loss)
I0428 16:03:47.879910 13425 solver.cpp:244]     Train net output #2: loss = 0.765503 (* 1 = 0.765503 loss)
I0428 16:03:47.879917 13425 sgd_solver.cpp:106] Iteration 70300, lr = 5e-08
I0428 16:05:27.700395 13425 solver.cpp:228] Iteration 70400, loss = 2.11374
I0428 16:05:27.700552 13425 solver.cpp:244]     Train net output #0: loss = 0.662413 (* 1 = 0.662413 loss)
I0428 16:05:27.700561 13425 solver.cpp:244]     Train net output #1: loss = 0.558224 (* 1 = 0.558224 loss)
I0428 16:05:27.700567 13425 solver.cpp:244]     Train net output #2: loss = 0.893102 (* 1 = 0.893102 loss)
I0428 16:05:27.700572 13425 sgd_solver.cpp:106] Iteration 70400, lr = 5e-08
I0428 16:07:07.739864 13425 solver.cpp:228] Iteration 70500, loss = 2.5423
I0428 16:07:07.740008 13425 solver.cpp:244]     Train net output #0: loss = 0.955846 (* 1 = 0.955846 loss)
I0428 16:07:07.740017 13425 solver.cpp:244]     Train net output #1: loss = 0.690251 (* 1 = 0.690251 loss)
I0428 16:07:07.740022 13425 solver.cpp:244]     Train net output #2: loss = 0.896199 (* 1 = 0.896199 loss)
I0428 16:07:07.740030 13425 sgd_solver.cpp:106] Iteration 70500, lr = 5e-08
I0428 16:08:47.671345 13425 solver.cpp:228] Iteration 70600, loss = 2.45345
I0428 16:08:47.671495 13425 solver.cpp:244]     Train net output #0: loss = 0.932467 (* 1 = 0.932467 loss)
I0428 16:08:47.671504 13425 solver.cpp:244]     Train net output #1: loss = 0.641966 (* 1 = 0.641966 loss)
I0428 16:08:47.671509 13425 solver.cpp:244]     Train net output #2: loss = 0.879012 (* 1 = 0.879012 loss)
I0428 16:08:47.671514 13425 sgd_solver.cpp:106] Iteration 70600, lr = 5e-08
I0428 16:10:25.856173 13425 solver.cpp:228] Iteration 70700, loss = 2.46927
I0428 16:10:25.856899 13425 solver.cpp:244]     Train net output #0: loss = 0.918449 (* 1 = 0.918449 loss)
I0428 16:10:25.856922 13425 solver.cpp:244]     Train net output #1: loss = 0.684172 (* 1 = 0.684172 loss)
I0428 16:10:25.856927 13425 solver.cpp:244]     Train net output #2: loss = 0.866648 (* 1 = 0.866648 loss)
I0428 16:10:25.856935 13425 sgd_solver.cpp:106] Iteration 70700, lr = 5e-08
I0428 16:12:06.300663 13425 solver.cpp:228] Iteration 70800, loss = 2.36474
I0428 16:12:06.300818 13425 solver.cpp:244]     Train net output #0: loss = 0.925984 (* 1 = 0.925984 loss)
I0428 16:12:06.300827 13425 solver.cpp:244]     Train net output #1: loss = 0.541925 (* 1 = 0.541925 loss)
I0428 16:12:06.300833 13425 solver.cpp:244]     Train net output #2: loss = 0.896828 (* 1 = 0.896828 loss)
I0428 16:12:06.300839 13425 sgd_solver.cpp:106] Iteration 70800, lr = 5e-08
I0428 16:13:46.152122 13425 solver.cpp:228] Iteration 70900, loss = 2.41344
I0428 16:13:46.152287 13425 solver.cpp:244]     Train net output #0: loss = 0.984212 (* 1 = 0.984212 loss)
I0428 16:13:46.152297 13425 solver.cpp:244]     Train net output #1: loss = 0.69079 (* 1 = 0.69079 loss)
I0428 16:13:46.152303 13425 solver.cpp:244]     Train net output #2: loss = 0.738435 (* 1 = 0.738435 loss)
I0428 16:13:46.152308 13425 sgd_solver.cpp:106] Iteration 70900, lr = 5e-08
I0428 16:15:25.074872 13425 solver.cpp:337] Iteration 71000, Testing net (#0)
I0428 16:15:25.075013 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 16:15:25.075018 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 16:15:25.075021 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 16:15:25.075036 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 16:15:25.075039 13425 net.cpp:693] Ignoring source layer visualize
I0428 16:15:25.075042 13425 net.cpp:693] Ignoring source layer fake
I0428 16:18:59.366719 13425 solver.cpp:404]     Test net output #0: loss = 0.947347 (* 1 = 0.947347 loss)
I0428 16:18:59.366866 13425 solver.cpp:404]     Test net output #1: loss = 0.630345 (* 1 = 0.630345 loss)
I0428 16:18:59.366874 13425 solver.cpp:404]     Test net output #2: loss = 0.830559 (* 1 = 0.830559 loss)
I0428 16:19:00.024713 13425 solver.cpp:228] Iteration 71000, loss = 2.49832
I0428 16:19:00.024756 13425 solver.cpp:244]     Train net output #0: loss = 0.976696 (* 1 = 0.976696 loss)
I0428 16:19:00.024762 13425 solver.cpp:244]     Train net output #1: loss = 0.706606 (* 1 = 0.706606 loss)
I0428 16:19:00.024768 13425 solver.cpp:244]     Train net output #2: loss = 0.815014 (* 1 = 0.815014 loss)
I0428 16:19:00.024773 13425 sgd_solver.cpp:106] Iteration 71000, lr = 5e-08
I0428 16:20:38.213536 13425 solver.cpp:228] Iteration 71100, loss = 2.26201
I0428 16:20:38.213693 13425 solver.cpp:244]     Train net output #0: loss = 0.985895 (* 1 = 0.985895 loss)
I0428 16:20:38.213702 13425 solver.cpp:244]     Train net output #1: loss = 0.66604 (* 1 = 0.66604 loss)
I0428 16:20:38.213707 13425 solver.cpp:244]     Train net output #2: loss = 0.610078 (* 1 = 0.610078 loss)
I0428 16:20:38.213713 13425 sgd_solver.cpp:106] Iteration 71100, lr = 5e-08
I0428 16:22:17.939468 13425 solver.cpp:228] Iteration 71200, loss = 2.43188
I0428 16:22:17.939528 13425 solver.cpp:244]     Train net output #0: loss = 0.942273 (* 1 = 0.942273 loss)
I0428 16:22:17.939535 13425 solver.cpp:244]     Train net output #1: loss = 0.596399 (* 1 = 0.596399 loss)
I0428 16:22:17.939539 13425 solver.cpp:244]     Train net output #2: loss = 0.893209 (* 1 = 0.893209 loss)
I0428 16:22:17.939544 13425 sgd_solver.cpp:106] Iteration 71200, lr = 5e-08
I0428 16:23:57.334897 13425 solver.cpp:228] Iteration 71300, loss = 2.23134
I0428 16:23:57.335063 13425 solver.cpp:244]     Train net output #0: loss = 0.945888 (* 1 = 0.945888 loss)
I0428 16:23:57.335072 13425 solver.cpp:244]     Train net output #1: loss = 0.384844 (* 1 = 0.384844 loss)
I0428 16:23:57.335078 13425 solver.cpp:244]     Train net output #2: loss = 0.900609 (* 1 = 0.900609 loss)
I0428 16:23:57.335083 13425 sgd_solver.cpp:106] Iteration 71300, lr = 5e-08
I0428 16:25:36.976646 13425 solver.cpp:228] Iteration 71400, loss = 2.49548
I0428 16:25:36.976840 13425 solver.cpp:244]     Train net output #0: loss = 0.943649 (* 1 = 0.943649 loss)
I0428 16:25:36.976848 13425 solver.cpp:244]     Train net output #1: loss = 0.597423 (* 1 = 0.597423 loss)
I0428 16:25:36.976855 13425 solver.cpp:244]     Train net output #2: loss = 0.954411 (* 1 = 0.954411 loss)
I0428 16:25:36.976861 13425 sgd_solver.cpp:106] Iteration 71400, lr = 5e-08
I0428 16:27:16.610951 13425 solver.cpp:228] Iteration 71500, loss = 2.15471
I0428 16:27:16.611129 13425 solver.cpp:244]     Train net output #0: loss = 0.984655 (* 1 = 0.984655 loss)
I0428 16:27:16.611137 13425 solver.cpp:244]     Train net output #1: loss = 0.616716 (* 1 = 0.616716 loss)
I0428 16:27:16.611143 13425 solver.cpp:244]     Train net output #2: loss = 0.553334 (* 1 = 0.553334 loss)
I0428 16:27:16.611150 13425 sgd_solver.cpp:106] Iteration 71500, lr = 5e-08
I0428 16:28:56.459859 13425 solver.cpp:228] Iteration 71600, loss = 2.35479
I0428 16:28:56.460019 13425 solver.cpp:244]     Train net output #0: loss = 0.823907 (* 1 = 0.823907 loss)
I0428 16:28:56.460028 13425 solver.cpp:244]     Train net output #1: loss = 0.653835 (* 1 = 0.653835 loss)
I0428 16:28:56.460033 13425 solver.cpp:244]     Train net output #2: loss = 0.87705 (* 1 = 0.87705 loss)
I0428 16:28:56.460039 13425 sgd_solver.cpp:106] Iteration 71600, lr = 5e-08
I0428 16:30:36.422631 13425 solver.cpp:228] Iteration 71700, loss = 2.58927
I0428 16:30:36.422782 13425 solver.cpp:244]     Train net output #0: loss = 0.960625 (* 1 = 0.960625 loss)
I0428 16:30:36.422791 13425 solver.cpp:244]     Train net output #1: loss = 0.744169 (* 1 = 0.744169 loss)
I0428 16:30:36.422796 13425 solver.cpp:244]     Train net output #2: loss = 0.884473 (* 1 = 0.884473 loss)
I0428 16:30:36.422803 13425 sgd_solver.cpp:106] Iteration 71700, lr = 5e-08
I0428 16:32:14.647191 13425 solver.cpp:228] Iteration 71800, loss = 2.54796
I0428 16:32:14.647325 13425 solver.cpp:244]     Train net output #0: loss = 0.959124 (* 1 = 0.959124 loss)
I0428 16:32:14.647332 13425 solver.cpp:244]     Train net output #1: loss = 0.793191 (* 1 = 0.793191 loss)
I0428 16:32:14.647339 13425 solver.cpp:244]     Train net output #2: loss = 0.79565 (* 1 = 0.79565 loss)
I0428 16:32:14.647346 13425 sgd_solver.cpp:106] Iteration 71800, lr = 5e-08
I0428 16:33:54.588925 13425 solver.cpp:228] Iteration 71900, loss = 2.6339
I0428 16:33:54.589076 13425 solver.cpp:244]     Train net output #0: loss = 0.943067 (* 1 = 0.943067 loss)
I0428 16:33:54.589087 13425 solver.cpp:244]     Train net output #1: loss = 0.770159 (* 1 = 0.770159 loss)
I0428 16:33:54.589092 13425 solver.cpp:244]     Train net output #2: loss = 0.920677 (* 1 = 0.920677 loss)
I0428 16:33:54.589098 13425 sgd_solver.cpp:106] Iteration 71900, lr = 5e-08
I0428 16:35:33.557801 13425 solver.cpp:337] Iteration 72000, Testing net (#0)
I0428 16:35:33.557952 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 16:35:33.557956 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 16:35:33.557960 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 16:35:33.557974 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 16:35:33.557978 13425 net.cpp:693] Ignoring source layer visualize
I0428 16:35:33.557981 13425 net.cpp:693] Ignoring source layer fake
I0428 16:39:07.405028 13425 solver.cpp:404]     Test net output #0: loss = 0.949242 (* 1 = 0.949242 loss)
I0428 16:39:07.405143 13425 solver.cpp:404]     Test net output #1: loss = 0.627315 (* 1 = 0.627315 loss)
I0428 16:39:07.405150 13425 solver.cpp:404]     Test net output #2: loss = 0.826132 (* 1 = 0.826132 loss)
I0428 16:39:08.057988 13425 solver.cpp:228] Iteration 72000, loss = 2.45376
I0428 16:39:08.058037 13425 solver.cpp:244]     Train net output #0: loss = 0.890705 (* 1 = 0.890705 loss)
I0428 16:39:08.058043 13425 solver.cpp:244]     Train net output #1: loss = 0.629816 (* 1 = 0.629816 loss)
I0428 16:39:08.058048 13425 solver.cpp:244]     Train net output #2: loss = 0.933241 (* 1 = 0.933241 loss)
I0428 16:39:08.058054 13425 sgd_solver.cpp:106] Iteration 72000, lr = 5e-08
I0428 16:40:48.621098 13425 solver.cpp:228] Iteration 72100, loss = 2.64995
I0428 16:40:48.621284 13425 solver.cpp:244]     Train net output #0: loss = 0.974006 (* 1 = 0.974006 loss)
I0428 16:40:48.621296 13425 solver.cpp:244]     Train net output #1: loss = 0.772821 (* 1 = 0.772821 loss)
I0428 16:40:48.621302 13425 solver.cpp:244]     Train net output #2: loss = 0.903123 (* 1 = 0.903123 loss)
I0428 16:40:48.621309 13425 sgd_solver.cpp:106] Iteration 72100, lr = 5e-08
I0428 16:42:26.805917 13425 solver.cpp:228] Iteration 72200, loss = 2.72397
I0428 16:42:26.806054 13425 solver.cpp:244]     Train net output #0: loss = 0.982938 (* 1 = 0.982938 loss)
I0428 16:42:26.806062 13425 solver.cpp:244]     Train net output #1: loss = 0.797704 (* 1 = 0.797704 loss)
I0428 16:42:26.806067 13425 solver.cpp:244]     Train net output #2: loss = 0.943326 (* 1 = 0.943326 loss)
I0428 16:42:26.806073 13425 sgd_solver.cpp:106] Iteration 72200, lr = 5e-08
I0428 16:44:12.623709 13425 solver.cpp:228] Iteration 72300, loss = 2.3082
I0428 16:44:12.623872 13425 solver.cpp:244]     Train net output #0: loss = 0.971548 (* 1 = 0.971548 loss)
I0428 16:44:12.623880 13425 solver.cpp:244]     Train net output #1: loss = 0.512824 (* 1 = 0.512824 loss)
I0428 16:44:12.623886 13425 solver.cpp:244]     Train net output #2: loss = 0.82383 (* 1 = 0.82383 loss)
I0428 16:44:12.623893 13425 sgd_solver.cpp:106] Iteration 72300, lr = 5e-08
I0428 16:45:52.476894 13425 solver.cpp:228] Iteration 72400, loss = 2.5076
I0428 16:45:52.477042 13425 solver.cpp:244]     Train net output #0: loss = 0.970619 (* 1 = 0.970619 loss)
I0428 16:45:52.477051 13425 solver.cpp:244]     Train net output #1: loss = 0.585591 (* 1 = 0.585591 loss)
I0428 16:45:52.477056 13425 solver.cpp:244]     Train net output #2: loss = 0.951395 (* 1 = 0.951395 loss)
I0428 16:45:52.477062 13425 sgd_solver.cpp:106] Iteration 72400, lr = 5e-08
I0428 16:47:31.901959 13425 solver.cpp:228] Iteration 72500, loss = 2.352
I0428 16:47:31.902134 13425 solver.cpp:244]     Train net output #0: loss = 0.952448 (* 1 = 0.952448 loss)
I0428 16:47:31.902143 13425 solver.cpp:244]     Train net output #1: loss = 0.476617 (* 1 = 0.476617 loss)
I0428 16:47:31.902148 13425 solver.cpp:244]     Train net output #2: loss = 0.922932 (* 1 = 0.922932 loss)
I0428 16:47:31.902154 13425 sgd_solver.cpp:106] Iteration 72500, lr = 5e-08
I0428 16:49:11.134785 13425 solver.cpp:228] Iteration 72600, loss = 2.4653
I0428 16:49:11.134943 13425 solver.cpp:244]     Train net output #0: loss = 0.932482 (* 1 = 0.932482 loss)
I0428 16:49:11.134950 13425 solver.cpp:244]     Train net output #1: loss = 0.593103 (* 1 = 0.593103 loss)
I0428 16:49:11.134956 13425 solver.cpp:244]     Train net output #2: loss = 0.939715 (* 1 = 0.939715 loss)
I0428 16:49:11.134961 13425 sgd_solver.cpp:106] Iteration 72600, lr = 5e-08
I0428 16:50:50.533262 13425 solver.cpp:228] Iteration 72700, loss = 2.18324
I0428 16:50:50.533423 13425 solver.cpp:244]     Train net output #0: loss = 0.982125 (* 1 = 0.982125 loss)
I0428 16:50:50.533432 13425 solver.cpp:244]     Train net output #1: loss = 0.644062 (* 1 = 0.644062 loss)
I0428 16:50:50.533454 13425 solver.cpp:244]     Train net output #2: loss = 0.557053 (* 1 = 0.557053 loss)
I0428 16:50:50.533462 13425 sgd_solver.cpp:106] Iteration 72700, lr = 5e-08
I0428 16:52:28.491039 13425 solver.cpp:228] Iteration 72800, loss = 2.37726
I0428 16:52:28.491189 13425 solver.cpp:244]     Train net output #0: loss = 0.97899 (* 1 = 0.97899 loss)
I0428 16:52:28.491197 13425 solver.cpp:244]     Train net output #1: loss = 0.645463 (* 1 = 0.645463 loss)
I0428 16:52:28.491204 13425 solver.cpp:244]     Train net output #2: loss = 0.752809 (* 1 = 0.752809 loss)
I0428 16:52:28.491209 13425 sgd_solver.cpp:106] Iteration 72800, lr = 5e-08
I0428 16:54:08.175663 13425 solver.cpp:228] Iteration 72900, loss = 2.38641
I0428 16:54:08.175880 13425 solver.cpp:244]     Train net output #0: loss = 0.879925 (* 1 = 0.879925 loss)
I0428 16:54:08.175890 13425 solver.cpp:244]     Train net output #1: loss = 0.602104 (* 1 = 0.602104 loss)
I0428 16:54:08.175895 13425 solver.cpp:244]     Train net output #2: loss = 0.904385 (* 1 = 0.904385 loss)
I0428 16:54:08.175902 13425 sgd_solver.cpp:106] Iteration 72900, lr = 5e-08
I0428 16:55:47.142025 13425 solver.cpp:337] Iteration 73000, Testing net (#0)
I0428 16:55:47.142190 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 16:55:47.142195 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 16:55:47.142199 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 16:55:47.142212 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 16:55:47.142216 13425 net.cpp:693] Ignoring source layer visualize
I0428 16:55:47.142218 13425 net.cpp:693] Ignoring source layer fake
I0428 16:59:21.769870 13425 solver.cpp:404]     Test net output #0: loss = 0.948018 (* 1 = 0.948018 loss)
I0428 16:59:21.770005 13425 solver.cpp:404]     Test net output #1: loss = 0.61784 (* 1 = 0.61784 loss)
I0428 16:59:21.770014 13425 solver.cpp:404]     Test net output #2: loss = 0.829203 (* 1 = 0.829203 loss)
I0428 16:59:22.419268 13425 solver.cpp:228] Iteration 73000, loss = 2.54294
I0428 16:59:22.419312 13425 solver.cpp:244]     Train net output #0: loss = 0.937447 (* 1 = 0.937447 loss)
I0428 16:59:22.419317 13425 solver.cpp:244]     Train net output #1: loss = 0.697639 (* 1 = 0.697639 loss)
I0428 16:59:22.419322 13425 solver.cpp:244]     Train net output #2: loss = 0.907853 (* 1 = 0.907853 loss)
I0428 16:59:22.419327 13425 sgd_solver.cpp:106] Iteration 73000, lr = 5e-08
I0428 17:01:02.358171 13425 solver.cpp:228] Iteration 73100, loss = 2.63463
I0428 17:01:02.358322 13425 solver.cpp:244]     Train net output #0: loss = 0.952144 (* 1 = 0.952144 loss)
I0428 17:01:02.358331 13425 solver.cpp:244]     Train net output #1: loss = 0.791849 (* 1 = 0.791849 loss)
I0428 17:01:02.358336 13425 solver.cpp:244]     Train net output #2: loss = 0.890637 (* 1 = 0.890637 loss)
I0428 17:01:02.358342 13425 sgd_solver.cpp:106] Iteration 73100, lr = 5e-08
I0428 17:02:40.555266 13425 solver.cpp:228] Iteration 73200, loss = 2.66659
I0428 17:02:40.555409 13425 solver.cpp:244]     Train net output #0: loss = 0.967843 (* 1 = 0.967843 loss)
I0428 17:02:40.555418 13425 solver.cpp:244]     Train net output #1: loss = 0.840917 (* 1 = 0.840917 loss)
I0428 17:02:40.555423 13425 solver.cpp:244]     Train net output #2: loss = 0.857829 (* 1 = 0.857829 loss)
I0428 17:02:40.555429 13425 sgd_solver.cpp:106] Iteration 73200, lr = 5e-08
I0428 17:04:20.489568 13425 solver.cpp:228] Iteration 73300, loss = 2.5993
I0428 17:04:20.489727 13425 solver.cpp:244]     Train net output #0: loss = 0.973157 (* 1 = 0.973157 loss)
I0428 17:04:20.489735 13425 solver.cpp:244]     Train net output #1: loss = 0.713281 (* 1 = 0.713281 loss)
I0428 17:04:20.489740 13425 solver.cpp:244]     Train net output #2: loss = 0.912862 (* 1 = 0.912862 loss)
I0428 17:04:20.489748 13425 sgd_solver.cpp:106] Iteration 73300, lr = 5e-08
I0428 17:06:00.386167 13425 solver.cpp:228] Iteration 73400, loss = 2.47237
I0428 17:06:00.386313 13425 solver.cpp:244]     Train net output #0: loss = 0.979977 (* 1 = 0.979977 loss)
I0428 17:06:00.386322 13425 solver.cpp:244]     Train net output #1: loss = 0.72861 (* 1 = 0.72861 loss)
I0428 17:06:00.386328 13425 solver.cpp:244]     Train net output #2: loss = 0.763788 (* 1 = 0.763788 loss)
I0428 17:06:00.386334 13425 sgd_solver.cpp:106] Iteration 73400, lr = 5e-08
I0428 17:07:40.513922 13425 solver.cpp:228] Iteration 73500, loss = 2.64784
I0428 17:07:40.514076 13425 solver.cpp:244]     Train net output #0: loss = 0.980932 (* 1 = 0.980932 loss)
I0428 17:07:40.514086 13425 solver.cpp:244]     Train net output #1: loss = 0.75439 (* 1 = 0.75439 loss)
I0428 17:07:40.514091 13425 solver.cpp:244]     Train net output #2: loss = 0.912522 (* 1 = 0.912522 loss)
I0428 17:07:40.514097 13425 sgd_solver.cpp:106] Iteration 73500, lr = 5e-08
I0428 17:09:19.278424 13425 solver.cpp:228] Iteration 73600, loss = 2.46535
I0428 17:09:19.278599 13425 solver.cpp:244]     Train net output #0: loss = 0.982282 (* 1 = 0.982282 loss)
I0428 17:09:19.278607 13425 solver.cpp:244]     Train net output #1: loss = 0.609657 (* 1 = 0.609657 loss)
I0428 17:09:19.278614 13425 solver.cpp:244]     Train net output #2: loss = 0.87341 (* 1 = 0.87341 loss)
I0428 17:09:19.278620 13425 sgd_solver.cpp:106] Iteration 73600, lr = 5e-08
I0428 17:10:58.975421 13425 solver.cpp:228] Iteration 73700, loss = 2.35249
I0428 17:10:58.975576 13425 solver.cpp:244]     Train net output #0: loss = 0.966095 (* 1 = 0.966095 loss)
I0428 17:10:58.975584 13425 solver.cpp:244]     Train net output #1: loss = 0.588453 (* 1 = 0.588453 loss)
I0428 17:10:58.975590 13425 solver.cpp:244]     Train net output #2: loss = 0.797942 (* 1 = 0.797942 loss)
I0428 17:10:58.975597 13425 sgd_solver.cpp:106] Iteration 73700, lr = 5e-08
I0428 17:12:38.326264 13425 solver.cpp:228] Iteration 73800, loss = 2.30817
I0428 17:12:38.326432 13425 solver.cpp:244]     Train net output #0: loss = 0.946201 (* 1 = 0.946201 loss)
I0428 17:12:38.326441 13425 solver.cpp:244]     Train net output #1: loss = 0.423696 (* 1 = 0.423696 loss)
I0428 17:12:38.326447 13425 solver.cpp:244]     Train net output #2: loss = 0.938275 (* 1 = 0.938275 loss)
I0428 17:12:38.326452 13425 sgd_solver.cpp:106] Iteration 73800, lr = 5e-08
I0428 17:14:17.700197 13425 solver.cpp:228] Iteration 73900, loss = 2.19966
I0428 17:14:17.700350 13425 solver.cpp:244]     Train net output #0: loss = 0.949989 (* 1 = 0.949989 loss)
I0428 17:14:17.700358 13425 solver.cpp:244]     Train net output #1: loss = 0.50746 (* 1 = 0.50746 loss)
I0428 17:14:17.700364 13425 solver.cpp:244]     Train net output #2: loss = 0.742214 (* 1 = 0.742214 loss)
I0428 17:14:17.700369 13425 sgd_solver.cpp:106] Iteration 73900, lr = 5e-08
I0428 17:15:56.356040 13425 solver.cpp:337] Iteration 74000, Testing net (#0)
I0428 17:15:56.356187 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 17:15:56.356191 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 17:15:56.356195 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 17:15:56.356209 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 17:15:56.356214 13425 net.cpp:693] Ignoring source layer visualize
I0428 17:15:56.356216 13425 net.cpp:693] Ignoring source layer fake
I0428 17:19:30.424240 13425 solver.cpp:404]     Test net output #0: loss = 0.944896 (* 1 = 0.944896 loss)
I0428 17:19:30.424383 13425 solver.cpp:404]     Test net output #1: loss = 0.617042 (* 1 = 0.617042 loss)
I0428 17:19:30.424391 13425 solver.cpp:404]     Test net output #2: loss = 0.816413 (* 1 = 0.816413 loss)
I0428 17:19:31.081482 13425 solver.cpp:228] Iteration 74000, loss = 2.33552
I0428 17:19:31.081506 13425 solver.cpp:244]     Train net output #0: loss = 0.976405 (* 1 = 0.976405 loss)
I0428 17:19:31.081526 13425 solver.cpp:244]     Train net output #1: loss = 0.610763 (* 1 = 0.610763 loss)
I0428 17:19:31.081532 13425 solver.cpp:244]     Train net output #2: loss = 0.748346 (* 1 = 0.748346 loss)
I0428 17:19:31.081537 13425 sgd_solver.cpp:106] Iteration 74000, lr = 5e-08
I0428 17:21:11.022331 13425 solver.cpp:228] Iteration 74100, loss = 2.34128
I0428 17:21:11.022488 13425 solver.cpp:244]     Train net output #0: loss = 0.775243 (* 1 = 0.775243 loss)
I0428 17:21:11.022497 13425 solver.cpp:244]     Train net output #1: loss = 0.640059 (* 1 = 0.640059 loss)
I0428 17:21:11.022503 13425 solver.cpp:244]     Train net output #2: loss = 0.925974 (* 1 = 0.925974 loss)
I0428 17:21:11.022509 13425 sgd_solver.cpp:106] Iteration 74100, lr = 5e-08
I0428 17:22:51.030227 13425 solver.cpp:228] Iteration 74200, loss = 2.5361
I0428 17:22:51.030412 13425 solver.cpp:244]     Train net output #0: loss = 0.94055 (* 1 = 0.94055 loss)
I0428 17:22:51.030421 13425 solver.cpp:244]     Train net output #1: loss = 0.684214 (* 1 = 0.684214 loss)
I0428 17:22:51.030426 13425 solver.cpp:244]     Train net output #2: loss = 0.911334 (* 1 = 0.911334 loss)
I0428 17:22:51.030432 13425 sgd_solver.cpp:106] Iteration 74200, lr = 5e-08
I0428 17:24:29.221048 13425 solver.cpp:228] Iteration 74300, loss = 2.3975
I0428 17:24:29.221230 13425 solver.cpp:244]     Train net output #0: loss = 0.961383 (* 1 = 0.961383 loss)
I0428 17:24:29.221238 13425 solver.cpp:244]     Train net output #1: loss = 0.683171 (* 1 = 0.683171 loss)
I0428 17:24:29.221243 13425 solver.cpp:244]     Train net output #2: loss = 0.752949 (* 1 = 0.752949 loss)
I0428 17:24:29.221251 13425 sgd_solver.cpp:106] Iteration 74300, lr = 5e-08
I0428 17:26:09.157284 13425 solver.cpp:228] Iteration 74400, loss = 2.48766
I0428 17:26:09.157454 13425 solver.cpp:244]     Train net output #0: loss = 0.93914 (* 1 = 0.93914 loss)
I0428 17:26:09.157462 13425 solver.cpp:244]     Train net output #1: loss = 0.665215 (* 1 = 0.665215 loss)
I0428 17:26:09.157469 13425 solver.cpp:244]     Train net output #2: loss = 0.883309 (* 1 = 0.883309 loss)
I0428 17:26:09.157482 13425 sgd_solver.cpp:106] Iteration 74400, lr = 5e-08
I0428 17:27:49.052671 13425 solver.cpp:228] Iteration 74500, loss = 2.67245
I0428 17:27:49.052831 13425 solver.cpp:244]     Train net output #0: loss = 0.980161 (* 1 = 0.980161 loss)
I0428 17:27:49.052840 13425 solver.cpp:244]     Train net output #1: loss = 0.790692 (* 1 = 0.790692 loss)
I0428 17:27:49.052845 13425 solver.cpp:244]     Train net output #2: loss = 0.901592 (* 1 = 0.901592 loss)
I0428 17:27:49.052850 13425 sgd_solver.cpp:106] Iteration 74500, lr = 5e-08
I0428 17:29:28.925896 13425 solver.cpp:228] Iteration 74600, loss = 2.6205
I0428 17:29:28.926045 13425 solver.cpp:244]     Train net output #0: loss = 0.975501 (* 1 = 0.975501 loss)
I0428 17:29:28.926054 13425 solver.cpp:244]     Train net output #1: loss = 0.739664 (* 1 = 0.739664 loss)
I0428 17:29:28.926059 13425 solver.cpp:244]     Train net output #2: loss = 0.905332 (* 1 = 0.905332 loss)
I0428 17:29:28.926065 13425 sgd_solver.cpp:106] Iteration 74600, lr = 5e-08
I0428 17:31:07.087775 13425 solver.cpp:228] Iteration 74700, loss = 2.6986
I0428 17:31:07.087918 13425 solver.cpp:244]     Train net output #0: loss = 0.987147 (* 1 = 0.987147 loss)
I0428 17:31:07.087925 13425 solver.cpp:244]     Train net output #1: loss = 0.765947 (* 1 = 0.765947 loss)
I0428 17:31:07.087930 13425 solver.cpp:244]     Train net output #2: loss = 0.945502 (* 1 = 0.945502 loss)
I0428 17:31:07.087937 13425 sgd_solver.cpp:106] Iteration 74700, lr = 5e-08
I0428 17:32:47.161841 13425 solver.cpp:228] Iteration 74800, loss = 2.10751
I0428 17:32:47.161990 13425 solver.cpp:244]     Train net output #0: loss = 0.982014 (* 1 = 0.982014 loss)
I0428 17:32:47.161998 13425 solver.cpp:244]     Train net output #1: loss = 0.454738 (* 1 = 0.454738 loss)
I0428 17:32:47.162004 13425 solver.cpp:244]     Train net output #2: loss = 0.67076 (* 1 = 0.67076 loss)
I0428 17:32:47.162009 13425 sgd_solver.cpp:106] Iteration 74800, lr = 5e-08
I0428 17:34:26.834120 13425 solver.cpp:228] Iteration 74900, loss = 2.34343
I0428 17:34:26.834286 13425 solver.cpp:244]     Train net output #0: loss = 0.974082 (* 1 = 0.974082 loss)
I0428 17:34:26.834295 13425 solver.cpp:244]     Train net output #1: loss = 0.542336 (* 1 = 0.542336 loss)
I0428 17:34:26.834300 13425 solver.cpp:244]     Train net output #2: loss = 0.827012 (* 1 = 0.827012 loss)
I0428 17:34:26.834306 13425 sgd_solver.cpp:106] Iteration 74900, lr = 5e-08
I0428 17:36:05.185734 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_75000.caffemodel
I0428 17:36:18.139852 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_75000.solverstate
I0428 17:36:18.341294 13425 solver.cpp:337] Iteration 75000, Testing net (#0)
I0428 17:36:18.341333 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 17:36:18.341336 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 17:36:18.341339 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 17:36:18.341352 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 17:36:18.341356 13425 net.cpp:693] Ignoring source layer visualize
I0428 17:36:18.341357 13425 net.cpp:693] Ignoring source layer fake
I0428 17:39:52.148710 13425 solver.cpp:404]     Test net output #0: loss = 0.944069 (* 1 = 0.944069 loss)
I0428 17:39:52.148866 13425 solver.cpp:404]     Test net output #1: loss = 0.627665 (* 1 = 0.627665 loss)
I0428 17:39:52.148874 13425 solver.cpp:404]     Test net output #2: loss = 0.828515 (* 1 = 0.828515 loss)
I0428 17:39:52.799891 13425 solver.cpp:228] Iteration 75000, loss = 2.29663
I0428 17:39:52.799934 13425 solver.cpp:244]     Train net output #0: loss = 0.961766 (* 1 = 0.961766 loss)
I0428 17:39:52.799940 13425 solver.cpp:244]     Train net output #1: loss = 0.42306 (* 1 = 0.42306 loss)
I0428 17:39:52.799944 13425 solver.cpp:244]     Train net output #2: loss = 0.9118 (* 1 = 0.9118 loss)
I0428 17:39:52.799950 13425 sgd_solver.cpp:106] Iteration 75000, lr = 5e-08
I0428 17:41:32.223924 13425 solver.cpp:228] Iteration 75100, loss = 2.43243
I0428 17:41:32.224089 13425 solver.cpp:244]     Train net output #0: loss = 0.917915 (* 1 = 0.917915 loss)
I0428 17:41:32.224097 13425 solver.cpp:244]     Train net output #1: loss = 0.592406 (* 1 = 0.592406 loss)
I0428 17:41:32.224103 13425 solver.cpp:244]     Train net output #2: loss = 0.922105 (* 1 = 0.922105 loss)
I0428 17:41:32.224110 13425 sgd_solver.cpp:106] Iteration 75100, lr = 5e-08
I0428 17:43:11.856451 13425 solver.cpp:228] Iteration 75200, loss = 2.56611
I0428 17:43:11.856621 13425 solver.cpp:244]     Train net output #0: loss = 0.978832 (* 1 = 0.978832 loss)
I0428 17:43:11.856629 13425 solver.cpp:244]     Train net output #1: loss = 0.648029 (* 1 = 0.648029 loss)
I0428 17:43:11.856636 13425 solver.cpp:244]     Train net output #2: loss = 0.939247 (* 1 = 0.939247 loss)
I0428 17:43:11.856642 13425 sgd_solver.cpp:106] Iteration 75200, lr = 5e-08
I0428 17:44:51.683085 13425 solver.cpp:228] Iteration 75300, loss = 1.85021
I0428 17:44:51.683240 13425 solver.cpp:244]     Train net output #0: loss = 0.971553 (* 1 = 0.971553 loss)
I0428 17:44:51.683249 13425 solver.cpp:244]     Train net output #1: loss = 0.316352 (* 1 = 0.316352 loss)
I0428 17:44:51.683255 13425 solver.cpp:244]     Train net output #2: loss = 0.562303 (* 1 = 0.562303 loss)
I0428 17:44:51.683261 13425 sgd_solver.cpp:106] Iteration 75300, lr = 5e-08
I0428 17:46:29.833844 13425 solver.cpp:228] Iteration 75400, loss = 1.85223
I0428 17:46:29.833997 13425 solver.cpp:244]     Train net output #0: loss = 0.963748 (* 1 = 0.963748 loss)
I0428 17:46:29.834005 13425 solver.cpp:244]     Train net output #1: loss = 0.31994 (* 1 = 0.31994 loss)
I0428 17:46:29.834012 13425 solver.cpp:244]     Train net output #2: loss = 0.568537 (* 1 = 0.568537 loss)
I0428 17:46:29.834017 13425 sgd_solver.cpp:106] Iteration 75400, lr = 5e-08
I0428 17:48:09.767910 13425 solver.cpp:228] Iteration 75500, loss = 2.62015
I0428 17:48:09.768050 13425 solver.cpp:244]     Train net output #0: loss = 0.943609 (* 1 = 0.943609 loss)
I0428 17:48:09.768059 13425 solver.cpp:244]     Train net output #1: loss = 0.749168 (* 1 = 0.749168 loss)
I0428 17:48:09.768064 13425 solver.cpp:244]     Train net output #2: loss = 0.927369 (* 1 = 0.927369 loss)
I0428 17:48:09.768070 13425 sgd_solver.cpp:106] Iteration 75500, lr = 5e-08
I0428 17:49:49.764377 13425 solver.cpp:228] Iteration 75600, loss = 2.66018
I0428 17:49:49.764519 13425 solver.cpp:244]     Train net output #0: loss = 0.953777 (* 1 = 0.953777 loss)
I0428 17:49:49.764528 13425 solver.cpp:244]     Train net output #1: loss = 0.807684 (* 1 = 0.807684 loss)
I0428 17:49:49.764534 13425 solver.cpp:244]     Train net output #2: loss = 0.898723 (* 1 = 0.898723 loss)
I0428 17:49:49.764539 13425 sgd_solver.cpp:106] Iteration 75600, lr = 5e-08
I0428 17:51:28.123497 13425 solver.cpp:228] Iteration 75700, loss = 2.53912
I0428 17:51:28.123634 13425 solver.cpp:244]     Train net output #0: loss = 0.959983 (* 1 = 0.959983 loss)
I0428 17:51:28.123642 13425 solver.cpp:244]     Train net output #1: loss = 0.706717 (* 1 = 0.706717 loss)
I0428 17:51:28.123648 13425 solver.cpp:244]     Train net output #2: loss = 0.872423 (* 1 = 0.872423 loss)
I0428 17:51:28.123653 13425 sgd_solver.cpp:106] Iteration 75700, lr = 5e-08
I0428 17:53:08.081428 13425 solver.cpp:228] Iteration 75800, loss = 2.472
I0428 17:53:08.081605 13425 solver.cpp:244]     Train net output #0: loss = 0.966176 (* 1 = 0.966176 loss)
I0428 17:53:08.081614 13425 solver.cpp:244]     Train net output #1: loss = 0.713144 (* 1 = 0.713144 loss)
I0428 17:53:08.081619 13425 solver.cpp:244]     Train net output #2: loss = 0.79268 (* 1 = 0.79268 loss)
I0428 17:53:08.081626 13425 sgd_solver.cpp:106] Iteration 75800, lr = 5e-08
I0428 17:54:48.007035 13425 solver.cpp:228] Iteration 75900, loss = 2.59427
I0428 17:54:48.007192 13425 solver.cpp:244]     Train net output #0: loss = 0.966213 (* 1 = 0.966213 loss)
I0428 17:54:48.007200 13425 solver.cpp:244]     Train net output #1: loss = 0.705335 (* 1 = 0.705335 loss)
I0428 17:54:48.007206 13425 solver.cpp:244]     Train net output #2: loss = 0.922718 (* 1 = 0.922718 loss)
I0428 17:54:48.007212 13425 sgd_solver.cpp:106] Iteration 75900, lr = 5e-08
I0428 17:56:27.208204 13425 solver.cpp:337] Iteration 76000, Testing net (#0)
I0428 17:56:27.208351 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 17:56:27.208355 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 17:56:27.208359 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 17:56:27.208374 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 17:56:27.208379 13425 net.cpp:693] Ignoring source layer visualize
I0428 17:56:27.208380 13425 net.cpp:693] Ignoring source layer fake
I0428 18:00:01.447686 13425 solver.cpp:404]     Test net output #0: loss = 0.947586 (* 1 = 0.947586 loss)
I0428 18:00:01.447823 13425 solver.cpp:404]     Test net output #1: loss = 0.6308 (* 1 = 0.6308 loss)
I0428 18:00:01.447829 13425 solver.cpp:404]     Test net output #2: loss = 0.830185 (* 1 = 0.830185 loss)
I0428 18:00:02.098268 13425 solver.cpp:228] Iteration 76000, loss = 2.38482
I0428 18:00:02.098312 13425 solver.cpp:244]     Train net output #0: loss = 0.981538 (* 1 = 0.981538 loss)
I0428 18:00:02.098317 13425 solver.cpp:244]     Train net output #1: loss = 0.540656 (* 1 = 0.540656 loss)
I0428 18:00:02.098322 13425 solver.cpp:244]     Train net output #2: loss = 0.862623 (* 1 = 0.862623 loss)
I0428 18:00:02.098327 13425 sgd_solver.cpp:106] Iteration 76000, lr = 5e-08
I0428 18:01:40.302171 13425 solver.cpp:228] Iteration 76100, loss = 2.23866
I0428 18:01:40.302320 13425 solver.cpp:244]     Train net output #0: loss = 0.981604 (* 1 = 0.981604 loss)
I0428 18:01:40.302328 13425 solver.cpp:244]     Train net output #1: loss = 0.569852 (* 1 = 0.569852 loss)
I0428 18:01:40.302333 13425 solver.cpp:244]     Train net output #2: loss = 0.687207 (* 1 = 0.687207 loss)
I0428 18:01:40.302340 13425 sgd_solver.cpp:106] Iteration 76100, lr = 5e-08
I0428 18:03:20.050657 13425 solver.cpp:228] Iteration 76200, loss = 2.35566
I0428 18:03:20.050802 13425 solver.cpp:244]     Train net output #0: loss = 0.959316 (* 1 = 0.959316 loss)
I0428 18:03:20.050810 13425 solver.cpp:244]     Train net output #1: loss = 0.581272 (* 1 = 0.581272 loss)
I0428 18:03:20.050817 13425 solver.cpp:244]     Train net output #2: loss = 0.815069 (* 1 = 0.815069 loss)
I0428 18:03:20.050822 13425 sgd_solver.cpp:106] Iteration 76200, lr = 5e-08
I0428 18:04:59.607249 13425 solver.cpp:228] Iteration 76300, loss = 2.35657
I0428 18:04:59.607421 13425 solver.cpp:244]     Train net output #0: loss = 0.973257 (* 1 = 0.973257 loss)
I0428 18:04:59.607430 13425 solver.cpp:244]     Train net output #1: loss = 0.461846 (* 1 = 0.461846 loss)
I0428 18:04:59.607436 13425 solver.cpp:244]     Train net output #2: loss = 0.921469 (* 1 = 0.921469 loss)
I0428 18:04:59.607442 13425 sgd_solver.cpp:106] Iteration 76300, lr = 5e-08
I0428 18:06:39.011929 13425 solver.cpp:228] Iteration 76400, loss = 2.12807
I0428 18:06:39.012107 13425 solver.cpp:244]     Train net output #0: loss = 0.970213 (* 1 = 0.970213 loss)
I0428 18:06:39.012116 13425 solver.cpp:244]     Train net output #1: loss = 0.436414 (* 1 = 0.436414 loss)
I0428 18:06:39.012121 13425 solver.cpp:244]     Train net output #2: loss = 0.721443 (* 1 = 0.721443 loss)
I0428 18:06:39.012127 13425 sgd_solver.cpp:106] Iteration 76400, lr = 5e-08
I0428 18:08:18.636127 13425 solver.cpp:228] Iteration 76500, loss = 2.14552
I0428 18:08:18.636293 13425 solver.cpp:244]     Train net output #0: loss = 0.970867 (* 1 = 0.970867 loss)
I0428 18:08:18.636302 13425 solver.cpp:244]     Train net output #1: loss = 0.597532 (* 1 = 0.597532 loss)
I0428 18:08:18.636307 13425 solver.cpp:244]     Train net output #2: loss = 0.577117 (* 1 = 0.577117 loss)
I0428 18:08:18.636314 13425 sgd_solver.cpp:106] Iteration 76500, lr = 5e-08
I0428 18:09:58.454684 13425 solver.cpp:228] Iteration 76600, loss = 2.3402
I0428 18:09:58.454836 13425 solver.cpp:244]     Train net output #0: loss = 0.795557 (* 1 = 0.795557 loss)
I0428 18:09:58.454844 13425 solver.cpp:244]     Train net output #1: loss = 0.648221 (* 1 = 0.648221 loss)
I0428 18:09:58.454850 13425 solver.cpp:244]     Train net output #2: loss = 0.896424 (* 1 = 0.896424 loss)
I0428 18:09:58.454856 13425 sgd_solver.cpp:106] Iteration 76600, lr = 5e-08
I0428 18:11:38.406230 13425 solver.cpp:228] Iteration 76700, loss = 2.52826
I0428 18:11:38.406379 13425 solver.cpp:244]     Train net output #0: loss = 0.941609 (* 1 = 0.941609 loss)
I0428 18:11:38.406388 13425 solver.cpp:244]     Train net output #1: loss = 0.684978 (* 1 = 0.684978 loss)
I0428 18:11:38.406394 13425 solver.cpp:244]     Train net output #2: loss = 0.901678 (* 1 = 0.901678 loss)
I0428 18:11:38.406399 13425 sgd_solver.cpp:106] Iteration 76700, lr = 5e-08
I0428 18:13:16.617966 13425 solver.cpp:228] Iteration 76800, loss = 2.47113
I0428 18:13:16.618137 13425 solver.cpp:244]     Train net output #0: loss = 0.958621 (* 1 = 0.958621 loss)
I0428 18:13:16.618145 13425 solver.cpp:244]     Train net output #1: loss = 0.682414 (* 1 = 0.682414 loss)
I0428 18:13:16.618151 13425 solver.cpp:244]     Train net output #2: loss = 0.830094 (* 1 = 0.830094 loss)
I0428 18:13:16.618156 13425 sgd_solver.cpp:106] Iteration 76800, lr = 5e-08
I0428 18:14:56.518163 13425 solver.cpp:228] Iteration 76900, loss = 2.50082
I0428 18:14:56.518331 13425 solver.cpp:244]     Train net output #0: loss = 0.952886 (* 1 = 0.952886 loss)
I0428 18:14:56.518338 13425 solver.cpp:244]     Train net output #1: loss = 0.695921 (* 1 = 0.695921 loss)
I0428 18:14:56.518343 13425 solver.cpp:244]     Train net output #2: loss = 0.85201 (* 1 = 0.85201 loss)
I0428 18:14:56.518350 13425 sgd_solver.cpp:106] Iteration 76900, lr = 5e-08
I0428 18:16:35.448568 13425 solver.cpp:337] Iteration 77000, Testing net (#0)
I0428 18:16:35.449792 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 18:16:35.449796 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 18:16:35.449801 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 18:16:35.449815 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 18:16:35.449817 13425 net.cpp:693] Ignoring source layer visualize
I0428 18:16:35.449820 13425 net.cpp:693] Ignoring source layer fake
I0428 18:20:10.275823 13425 solver.cpp:404]     Test net output #0: loss = 0.949054 (* 1 = 0.949054 loss)
I0428 18:20:10.275959 13425 solver.cpp:404]     Test net output #1: loss = 0.625949 (* 1 = 0.625949 loss)
I0428 18:20:10.275966 13425 solver.cpp:404]     Test net output #2: loss = 0.826372 (* 1 = 0.826372 loss)
I0428 18:20:10.930639 13425 solver.cpp:228] Iteration 77000, loss = 2.65874
I0428 18:20:10.930680 13425 solver.cpp:244]     Train net output #0: loss = 0.98366 (* 1 = 0.98366 loss)
I0428 18:20:10.930686 13425 solver.cpp:244]     Train net output #1: loss = 0.823675 (* 1 = 0.823675 loss)
I0428 18:20:10.930691 13425 solver.cpp:244]     Train net output #2: loss = 0.851408 (* 1 = 0.851408 loss)
I0428 18:20:10.930697 13425 sgd_solver.cpp:106] Iteration 77000, lr = 5e-08
I0428 18:21:50.792382 13425 solver.cpp:228] Iteration 77100, loss = 2.41712
I0428 18:21:50.792572 13425 solver.cpp:244]     Train net output #0: loss = 0.975166 (* 1 = 0.975166 loss)
I0428 18:21:50.792580 13425 solver.cpp:244]     Train net output #1: loss = 0.679101 (* 1 = 0.679101 loss)
I0428 18:21:50.792585 13425 solver.cpp:244]     Train net output #2: loss = 0.762857 (* 1 = 0.762857 loss)
I0428 18:21:50.792593 13425 sgd_solver.cpp:106] Iteration 77100, lr = 5e-08
I0428 18:23:28.983494 13425 solver.cpp:228] Iteration 77200, loss = 2.67918
I0428 18:23:28.983644 13425 solver.cpp:244]     Train net output #0: loss = 0.975918 (* 1 = 0.975918 loss)
I0428 18:23:28.983665 13425 solver.cpp:244]     Train net output #1: loss = 0.765259 (* 1 = 0.765259 loss)
I0428 18:23:28.983671 13425 solver.cpp:244]     Train net output #2: loss = 0.938006 (* 1 = 0.938006 loss)
I0428 18:23:28.983677 13425 sgd_solver.cpp:106] Iteration 77200, lr = 5e-08
I0428 18:25:08.846920 13425 solver.cpp:228] Iteration 77300, loss = 2.43747
I0428 18:25:08.847084 13425 solver.cpp:244]     Train net output #0: loss = 0.967837 (* 1 = 0.967837 loss)
I0428 18:25:08.847092 13425 solver.cpp:244]     Train net output #1: loss = 0.710009 (* 1 = 0.710009 loss)
I0428 18:25:08.847097 13425 solver.cpp:244]     Train net output #2: loss = 0.759626 (* 1 = 0.759626 loss)
I0428 18:25:08.847103 13425 sgd_solver.cpp:106] Iteration 77300, lr = 5e-08
I0428 18:26:48.535208 13425 solver.cpp:228] Iteration 77400, loss = 2.21122
I0428 18:26:48.535377 13425 solver.cpp:244]     Train net output #0: loss = 0.981329 (* 1 = 0.981329 loss)
I0428 18:26:48.535384 13425 solver.cpp:244]     Train net output #1: loss = 0.464006 (* 1 = 0.464006 loss)
I0428 18:26:48.535389 13425 solver.cpp:244]     Train net output #2: loss = 0.765884 (* 1 = 0.765884 loss)
I0428 18:26:48.535395 13425 sgd_solver.cpp:106] Iteration 77400, lr = 5e-08
I0428 18:28:27.880827 13425 solver.cpp:228] Iteration 77500, loss = 2.25365
I0428 18:28:27.880987 13425 solver.cpp:244]     Train net output #0: loss = 0.955637 (* 1 = 0.955637 loss)
I0428 18:28:27.880995 13425 solver.cpp:244]     Train net output #1: loss = 0.406255 (* 1 = 0.406255 loss)
I0428 18:28:27.881000 13425 solver.cpp:244]     Train net output #2: loss = 0.891763 (* 1 = 0.891763 loss)
I0428 18:28:27.881007 13425 sgd_solver.cpp:106] Iteration 77500, lr = 5e-08
I0428 18:30:07.273579 13425 solver.cpp:228] Iteration 77600, loss = 2.43727
I0428 18:30:07.273743 13425 solver.cpp:244]     Train net output #0: loss = 0.950577 (* 1 = 0.950577 loss)
I0428 18:30:07.273751 13425 solver.cpp:244]     Train net output #1: loss = 0.585743 (* 1 = 0.585743 loss)
I0428 18:30:07.273757 13425 solver.cpp:244]     Train net output #2: loss = 0.900951 (* 1 = 0.900951 loss)
I0428 18:30:07.273762 13425 sgd_solver.cpp:106] Iteration 77600, lr = 5e-08
I0428 18:31:46.960078 13425 solver.cpp:228] Iteration 77700, loss = 2.28627
I0428 18:31:46.960223 13425 solver.cpp:244]     Train net output #0: loss = 0.96155 (* 1 = 0.96155 loss)
I0428 18:31:46.960232 13425 solver.cpp:244]     Train net output #1: loss = 0.55424 (* 1 = 0.55424 loss)
I0428 18:31:46.960237 13425 solver.cpp:244]     Train net output #2: loss = 0.770478 (* 1 = 0.770478 loss)
I0428 18:31:46.960243 13425 sgd_solver.cpp:106] Iteration 77700, lr = 5e-08
I0428 18:33:26.912318 13425 solver.cpp:228] Iteration 77800, loss = 1.47627
I0428 18:33:26.912473 13425 solver.cpp:244]     Train net output #0: loss = 0.966778 (* 1 = 0.966778 loss)
I0428 18:33:26.912482 13425 solver.cpp:244]     Train net output #1: loss = 0.13721 (* 1 = 0.13721 loss)
I0428 18:33:26.912487 13425 solver.cpp:244]     Train net output #2: loss = 0.372282 (* 1 = 0.372282 loss)
I0428 18:33:26.912494 13425 sgd_solver.cpp:106] Iteration 77800, lr = 5e-08
I0428 18:35:05.146282 13425 solver.cpp:228] Iteration 77900, loss = 1.9278
I0428 18:35:05.146442 13425 solver.cpp:244]     Train net output #0: loss = 0.944042 (* 1 = 0.944042 loss)
I0428 18:35:05.146450 13425 solver.cpp:244]     Train net output #1: loss = 0.230797 (* 1 = 0.230797 loss)
I0428 18:35:05.146456 13425 solver.cpp:244]     Train net output #2: loss = 0.752963 (* 1 = 0.752963 loss)
I0428 18:35:05.146462 13425 sgd_solver.cpp:106] Iteration 77900, lr = 5e-08
I0428 18:36:44.135336 13425 solver.cpp:337] Iteration 78000, Testing net (#0)
I0428 18:36:44.135525 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 18:36:44.135530 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 18:36:44.135535 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 18:36:44.135550 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 18:36:44.135552 13425 net.cpp:693] Ignoring source layer visualize
I0428 18:36:44.135555 13425 net.cpp:693] Ignoring source layer fake
I0428 18:40:18.544468 13425 solver.cpp:404]     Test net output #0: loss = 0.947808 (* 1 = 0.947808 loss)
I0428 18:40:18.544602 13425 solver.cpp:404]     Test net output #1: loss = 0.617773 (* 1 = 0.617773 loss)
I0428 18:40:18.544610 13425 solver.cpp:404]     Test net output #2: loss = 0.828451 (* 1 = 0.828451 loss)
I0428 18:40:19.201102 13425 solver.cpp:228] Iteration 78000, loss = 2.50658
I0428 18:40:19.201133 13425 solver.cpp:244]     Train net output #0: loss = 0.941186 (* 1 = 0.941186 loss)
I0428 18:40:19.201154 13425 solver.cpp:244]     Train net output #1: loss = 0.651266 (* 1 = 0.651266 loss)
I0428 18:40:19.201159 13425 solver.cpp:244]     Train net output #2: loss = 0.91413 (* 1 = 0.91413 loss)
I0428 18:40:19.201165 13425 sgd_solver.cpp:106] Iteration 78000, lr = 5e-08
I0428 18:41:59.240615 13425 solver.cpp:228] Iteration 78100, loss = 2.55696
I0428 18:41:59.240759 13425 solver.cpp:244]     Train net output #0: loss = 0.956172 (* 1 = 0.956172 loss)
I0428 18:41:59.240767 13425 solver.cpp:244]     Train net output #1: loss = 0.6856 (* 1 = 0.6856 loss)
I0428 18:41:59.240772 13425 solver.cpp:244]     Train net output #2: loss = 0.915184 (* 1 = 0.915184 loss)
I0428 18:41:59.240782 13425 sgd_solver.cpp:106] Iteration 78100, lr = 5e-08
I0428 18:43:37.432999 13425 solver.cpp:228] Iteration 78200, loss = 2.37089
I0428 18:43:37.433162 13425 solver.cpp:244]     Train net output #0: loss = 0.917485 (* 1 = 0.917485 loss)
I0428 18:43:37.433171 13425 solver.cpp:244]     Train net output #1: loss = 0.615383 (* 1 = 0.615383 loss)
I0428 18:43:37.433177 13425 solver.cpp:244]     Train net output #2: loss = 0.83802 (* 1 = 0.83802 loss)
I0428 18:43:37.433189 13425 sgd_solver.cpp:106] Iteration 78200, lr = 5e-08
I0428 18:45:17.319190 13425 solver.cpp:228] Iteration 78300, loss = 2.48099
I0428 18:45:17.319329 13425 solver.cpp:244]     Train net output #0: loss = 0.966012 (* 1 = 0.966012 loss)
I0428 18:45:17.319337 13425 solver.cpp:244]     Train net output #1: loss = 0.70563 (* 1 = 0.70563 loss)
I0428 18:45:17.319342 13425 solver.cpp:244]     Train net output #2: loss = 0.809347 (* 1 = 0.809347 loss)
I0428 18:45:17.319350 13425 sgd_solver.cpp:106] Iteration 78300, lr = 5e-08
I0428 18:46:57.315742 13425 solver.cpp:228] Iteration 78400, loss = 2.7431
I0428 18:46:57.315901 13425 solver.cpp:244]     Train net output #0: loss = 0.982975 (* 1 = 0.982975 loss)
I0428 18:46:57.315908 13425 solver.cpp:244]     Train net output #1: loss = 0.81455 (* 1 = 0.81455 loss)
I0428 18:46:57.315914 13425 solver.cpp:244]     Train net output #2: loss = 0.945578 (* 1 = 0.945578 loss)
I0428 18:46:57.315920 13425 sgd_solver.cpp:106] Iteration 78400, lr = 5e-08
I0428 18:48:37.497439 13425 solver.cpp:228] Iteration 78500, loss = 2.4196
I0428 18:48:37.497611 13425 solver.cpp:244]     Train net output #0: loss = 0.97755 (* 1 = 0.97755 loss)
I0428 18:48:37.497619 13425 solver.cpp:244]     Train net output #1: loss = 0.693592 (* 1 = 0.693592 loss)
I0428 18:48:37.497624 13425 solver.cpp:244]     Train net output #2: loss = 0.748462 (* 1 = 0.748462 loss)
I0428 18:48:37.497632 13425 sgd_solver.cpp:106] Iteration 78500, lr = 5e-08
I0428 18:50:15.690220 13425 solver.cpp:228] Iteration 78600, loss = 2.49992
I0428 18:50:15.691790 13425 solver.cpp:244]     Train net output #0: loss = 0.981068 (* 1 = 0.981068 loss)
I0428 18:50:15.691799 13425 solver.cpp:244]     Train net output #1: loss = 0.766901 (* 1 = 0.766901 loss)
I0428 18:50:15.691807 13425 solver.cpp:244]     Train net output #2: loss = 0.751948 (* 1 = 0.751948 loss)
I0428 18:50:15.691812 13425 sgd_solver.cpp:106] Iteration 78600, lr = 5e-08
I0428 18:51:55.413712 13425 solver.cpp:228] Iteration 78700, loss = 2.37019
I0428 18:51:55.413887 13425 solver.cpp:244]     Train net output #0: loss = 0.927539 (* 1 = 0.927539 loss)
I0428 18:51:55.413897 13425 solver.cpp:244]     Train net output #1: loss = 0.582686 (* 1 = 0.582686 loss)
I0428 18:51:55.413902 13425 solver.cpp:244]     Train net output #2: loss = 0.859967 (* 1 = 0.859967 loss)
I0428 18:51:55.413908 13425 sgd_solver.cpp:106] Iteration 78700, lr = 5e-08
I0428 18:53:34.778057 13425 solver.cpp:228] Iteration 78800, loss = 2.40983
I0428 18:53:34.778209 13425 solver.cpp:244]     Train net output #0: loss = 0.951092 (* 1 = 0.951092 loss)
I0428 18:53:34.778218 13425 solver.cpp:244]     Train net output #1: loss = 0.524929 (* 1 = 0.524929 loss)
I0428 18:53:34.778223 13425 solver.cpp:244]     Train net output #2: loss = 0.933809 (* 1 = 0.933809 loss)
I0428 18:53:34.778229 13425 sgd_solver.cpp:106] Iteration 78800, lr = 5e-08
I0428 18:55:14.222918 13425 solver.cpp:228] Iteration 78900, loss = 2.13352
I0428 18:55:14.223057 13425 solver.cpp:244]     Train net output #0: loss = 0.932155 (* 1 = 0.932155 loss)
I0428 18:55:14.223065 13425 solver.cpp:244]     Train net output #1: loss = 0.454329 (* 1 = 0.454329 loss)
I0428 18:55:14.223071 13425 solver.cpp:244]     Train net output #2: loss = 0.747032 (* 1 = 0.747032 loss)
I0428 18:55:14.223078 13425 sgd_solver.cpp:106] Iteration 78900, lr = 5e-08
I0428 18:56:52.887996 13425 solver.cpp:337] Iteration 79000, Testing net (#0)
I0428 18:56:52.888135 13425 net.cpp:693] Ignoring source layer dropout_d3c
I0428 18:56:52.888139 13425 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0428 18:56:52.888144 13425 net.cpp:693] Ignoring source layer dropout_d4c
I0428 18:56:52.888157 13425 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 18:56:52.888160 13425 net.cpp:693] Ignoring source layer visualize
I0428 18:56:52.888162 13425 net.cpp:693] Ignoring source layer fake
I0428 19:00:27.588119 13425 solver.cpp:404]     Test net output #0: loss = 0.944089 (* 1 = 0.944089 loss)
I0428 19:00:27.588367 13425 solver.cpp:404]     Test net output #1: loss = 0.616289 (* 1 = 0.616289 loss)
I0428 19:00:27.588376 13425 solver.cpp:404]     Test net output #2: loss = 0.81629 (* 1 = 0.81629 loss)
I0428 19:00:28.256649 13425 solver.cpp:228] Iteration 79000, loss = 2.64691
I0428 19:00:28.256700 13425 solver.cpp:244]     Train net output #0: loss = 0.96527 (* 1 = 0.96527 loss)
I0428 19:00:28.256709 13425 solver.cpp:244]     Train net output #1: loss = 0.724914 (* 1 = 0.724914 loss)
I0428 19:00:28.256719 13425 solver.cpp:244]     Train net output #2: loss = 0.956725 (* 1 = 0.956725 loss)
I0428 19:00:28.256731 13425 sgd_solver.cpp:106] Iteration 79000, lr = 5e-08
I0428 19:02:08.159500 13425 solver.cpp:228] Iteration 79100, loss = 2.30585
I0428 19:02:08.159653 13425 solver.cpp:244]     Train net output #0: loss = 0.903543 (* 1 = 0.903543 loss)
I0428 19:02:08.159662 13425 solver.cpp:244]     Train net output #1: loss = 0.478646 (* 1 = 0.478646 loss)
I0428 19:02:08.159667 13425 solver.cpp:244]     Train net output #2: loss = 0.92366 (* 1 = 0.92366 loss)
I0428 19:02:08.159674 13425 sgd_solver.cpp:106] Iteration 79100, lr = 5e-08
I0428 19:03:48.166103 13425 solver.cpp:228] Iteration 79200, loss = 2.58246
I0428 19:03:48.166249 13425 solver.cpp:244]     Train net output #0: loss = 0.944608 (* 1 = 0.944608 loss)
I0428 19:03:48.166259 13425 solver.cpp:244]     Train net output #1: loss = 0.772378 (* 1 = 0.772378 loss)
I0428 19:03:48.166265 13425 solver.cpp:244]     Train net output #2: loss = 0.865471 (* 1 = 0.865471 loss)
I0428 19:03:48.166270 13425 sgd_solver.cpp:106] Iteration 79200, lr = 5e-08
I0428 19:05:26.403620 13425 solver.cpp:228] Iteration 79300, loss = 2.487
I0428 19:05:26.403766 13425 solver.cpp:244]     Train net output #0: loss = 0.981939 (* 1 = 0.981939 loss)
I0428 19:05:26.403775 13425 solver.cpp:244]     Train net output #1: loss = 0.807065 (* 1 = 0.807065 loss)
I0428 19:05:26.403780 13425 solver.cpp:244]     Train net output #2: loss = 0.697996 (* 1 = 0.697996 loss)
I0428 19:05:26.403787 13425 sgd_solver.cpp:106] Iteration 79300, lr = 5e-08
I0428 19:07:06.370384 13425 solver.cpp:228] Iteration 79400, loss = 2.6238
I0428 19:07:06.370578 13425 solver.cpp:244]     Train net output #0: loss = 0.96977 (* 1 = 0.96977 loss)
I0428 19:07:06.370586 13425 solver.cpp:244]     Train net output #1: loss = 0.761567 (* 1 = 0.761567 loss)
I0428 19:07:06.370592 13425 solver.cpp:244]     Train net output #2: loss = 0.892458 (* 1 = 0.892458 loss)
I0428 19:07:06.370597 13425 sgd_solver.cpp:106] Iteration 79400, lr = 5e-08
I0428 19:08:46.265269 13425 solver.cpp:228] Iteration 79500, loss = 2.48147
I0428 19:08:46.265425 13425 solver.cpp:244]     Train net output #0: loss = 0.972076 (* 1 = 0.972076 loss)
I0428 19:08:46.265439 13425 solver.cpp:244]     Train net output #1: loss = 0.64237 (* 1 = 0.64237 loss)
I0428 19:08:46.265446 13425 solver.cpp:244]     Train net output #2: loss = 0.867025 (* 1 = 0.867025 loss)
I0428 19:08:46.265453 13425 sgd_solver.cpp:106] Iteration 79500, lr = 5e-08
I0428 19:10:26.117211 13425 solver.cpp:228] Iteration 79600, loss = 2.49939
I0428 19:10:26.117358 13425 solver.cpp:244]     Train net output #0: loss = 0.954558 (* 1 = 0.954558 loss)
I0428 19:10:26.117367 13425 solver.cpp:244]     Train net output #1: loss = 0.668994 (* 1 = 0.668994 loss)
I0428 19:10:26.117372 13425 solver.cpp:244]     Train net output #2: loss = 0.875836 (* 1 = 0.875836 loss)
I0428 19:10:26.117377 13425 sgd_solver.cpp:106] Iteration 79600, lr = 5e-08
I0428 19:12:04.293679 13425 solver.cpp:228] Iteration 79700, loss = 2.51168
I0428 19:12:04.293864 13425 solver.cpp:244]     Train net output #0: loss = 0.96722 (* 1 = 0.96722 loss)
I0428 19:12:04.293874 13425 solver.cpp:244]     Train net output #1: loss = 0.682581 (* 1 = 0.682581 loss)
I0428 19:12:04.293879 13425 solver.cpp:244]     Train net output #2: loss = 0.861884 (* 1 = 0.861884 loss)
I0428 19:12:04.293885 13425 sgd_solver.cpp:106] Iteration 79700, lr = 5e-08
I0428 19:13:44.152961 13425 solver.cpp:228] Iteration 79800, loss = 2.55902
I0428 19:13:44.153101 13425 solver.cpp:244]     Train net output #0: loss = 0.968149 (* 1 = 0.968149 loss)
I0428 19:13:44.153110 13425 solver.cpp:244]     Train net output #1: loss = 0.692914 (* 1 = 0.692914 loss)
I0428 19:13:44.153115 13425 solver.cpp:244]     Train net output #2: loss = 0.897957 (* 1 = 0.897957 loss)
I0428 19:13:44.153120 13425 sgd_solver.cpp:106] Iteration 79800, lr = 5e-08
I0428 19:15:23.978943 13425 solver.cpp:228] Iteration 79900, loss = 2.52386
I0428 19:15:23.979097 13425 solver.cpp:244]     Train net output #0: loss = 0.977057 (* 1 = 0.977057 loss)
I0428 19:15:23.979105 13425 solver.cpp:244]     Train net output #1: loss = 0.67043 (* 1 = 0.67043 loss)
I0428 19:15:23.979110 13425 solver.cpp:244]     Train net output #2: loss = 0.876368 (* 1 = 0.876368 loss)
I0428 19:15:23.979117 13425 sgd_solver.cpp:106] Iteration 79900, lr = 5e-08
I0428 19:17:02.392740 13425 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_80000.caffemodel
I0428 19:17:23.498370 13425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_80000.solverstate
