I0428 15:09:07.784373  5145 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3456
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.99
stepsize: 7500
snapshot: 1000
snapshot_prefix: "./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4"
solver_mode: GPU
net: "./unet_weighted_batchnorm_4/unet_weighted_batchnorm_4.prototxt"
regularization_type: "L2"
test_initialization: true
iter_size: 1
I0428 15:09:07.794414  5145 solver.cpp:91] Creating training net from net file: ./unet_weighted_batchnorm_4/unet_weighted_batchnorm_4.prototxt
I0428 15:09:07.795377  5145 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./unet_weighted_batchnorm_4/unet_weighted_batchnorm_4.prototxt
I0428 15:09:07.795409  5145 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0428 15:09:07.795608  5145 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer loaddata
I0428 15:09:07.796699  5145 net.cpp:58] Initializing net from parameters: 
name: "unet_weighted_batchnorm_4"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  top: "weights"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "caffeHDF5_4.txt"
    batch_size: 2
  }
}
layer {
  name: "conv_d0a-b"
  type: "Convolution"
  bottom: "data"
  top: "d0b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d0b"
  type: "BatchNorm"
  bottom: "d0b"
  top: "d0b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d0b"
  type: "Scale"
  bottom: "d0b"
  top: "d0b"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d0b"
  type: "ReLU"
  bottom: "d0b"
  top: "d0b"
}
layer {
  name: "conv_d0b-c"
  type: "Convolution"
  bottom: "d0b"
  top: "d0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d0c"
  type: "BatchNorm"
  bottom: "d0c"
  top: "d0c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d0c"
  type: "Scale"
  bottom: "d0c"
  top: "d0c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d0c"
  type: "ReLU"
  bottom: "d0c"
  top: "d0c"
}
layer {
  name: "pool_d0c-1a"
  type: "Pooling"
  bottom: "d0c"
  top: "d1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d1a-b"
  type: "Convolution"
  bottom: "d1a"
  top: "d1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d1b"
  type: "BatchNorm"
  bottom: "d1b"
  top: "d1b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d1b"
  type: "Scale"
  bottom: "d1b"
  top: "d1b"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d1b"
  type: "ReLU"
  bottom: "d1b"
  top: "d1b"
}
layer {
  name: "conv_d1b-c"
  type: "Convolution"
  bottom: "d1b"
  top: "d1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d1c"
  type: "BatchNorm"
  bottom: "d1c"
  top: "d1c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d1c"
  type: "Scale"
  bottom: "d1c"
  top: "d1c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d1c"
  type: "ReLU"
  bottom: "d1c"
  top: "d1c"
}
layer {
  name: "pool_d1c-2a"
  type: "Pooling"
  bottom: "d1c"
  top: "d2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d2a-b"
  type: "Convolution"
  bottom: "d2a"
  top: "d2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d2b"
  type: "BatchNorm"
  bottom: "d2b"
  top: "d2b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d2b"
  type: "Scale"
  bottom: "d2b"
  top: "d2b"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d2b"
  type: "ReLU"
  bottom: "d2b"
  top: "d2b"
}
layer {
  name: "conv_d2b-c"
  type: "Convolution"
  bottom: "d2b"
  top: "d2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d2c"
  type: "BatchNorm"
  bottom: "d2c"
  top: "d2c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d2c"
  type: "Scale"
  bottom: "d2c"
  top: "d2c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d2c"
  type: "ReLU"
  bottom: "d2c"
  top: "d2c"
}
layer {
  name: "pool_d2c-3a"
  type: "Pooling"
  bottom: "d2c"
  top: "d3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d3a-b"
  type: "Convolution"
  bottom: "d3a"
  top: "d3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d3b"
  type: "BatchNorm"
  bottom: "d3b"
  top: "d3b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d3b"
  type: "Scale"
  bottom: "d3b"
  top: "d3b"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d3b"
  type: "ReLU"
  bottom: "d3b"
  top: "d3b"
}
layer {
  name: "conv_d3b-c"
  type: "Convolution"
  bottom: "d3b"
  top: "d3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d3c"
  type: "BatchNorm"
  bottom: "d3c"
  top: "d3c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d3c"
  type: "Scale"
  bottom: "d3c"
  top: "d3c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d3c"
  type: "ReLU"
  bottom: "d3c"
  top: "d3c"
}
layer {
  name: "pool_d3c-4a"
  type: "Pooling"
  bottom: "d3c"
  top: "d4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d4a-b"
  type: "Convolution"
  bottom: "d4a"
  top: "d4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d4b"
  type: "BatchNorm"
  bottom: "d4b"
  top: "d4b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d4b"
  type: "Scale"
  bottom: "d4b"
  top: "d4b"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d4b"
  type: "ReLU"
  bottom: "d4b"
  top: "d4b"
}
layer {
  name: "conv_d4b-c"
  type: "Convolution"
  bottom: "d4b"
  top: "d4c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d4c"
  type: "BatchNorm"
  bottom: "d4c"
  top: "d4c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d4c"
  type: "Scale"
  bottom: "d4c"
  top: "d4c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d4c"
  type: "ReLU"
  bottom: "d4c"
  top: "d4c"
}
layer {
  name: "upconv_d4c_u3a"
  type: "Deconvolution"
  bottom: "d4c"
  top: "u3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_u3a"
  type: "BatchNorm"
  bottom: "u3a"
  top: "u3a"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u3a"
  type: "Scale"
  bottom: "u3a"
  top: "u3a"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u3a"
  type: "ReLU"
  bottom: "u3a"
  top: "u3a"
}
layer {
  name: "crop_d3c-d3cc"
  type: "Crop"
  bottom: "d3c"
  bottom: "u3a"
  top: "d3cc"
  crop_param {
    axis: 2
    offset: 4
  }
}
layer {
  name: "concat_d3cc_u3a-b"
  type: "Concat"
  bottom: "u3a"
  bottom: "d3cc"
  top: "u3b"
}
layer {
  name: "conv_u3b-c"
  type: "Convolution"
  bottom: "u3b"
  top: "u3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u3c"
  type: "BatchNorm"
  bottom: "u3c"
  top: "u3c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u3c"
  type: "Scale"
  bottom: "u3c"
  top: "u3c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u3c"
  type: "ReLU"
  bottom: "u3c"
  top: "u3c"
}
layer {
  name: "conv_u3c-d"
  type: "Convolution"
  bottom: "u3c"
  top: "u3d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u3d"
  type: "BatchNorm"
  bottom: "u3d"
  top: "u3d"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u3d"
  type: "Scale"
  bottom: "u3d"
  top: "u3d"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u3d"
  type: "ReLU"
  bottom: "u3d"
  top: "u3d"
}
layer {
  name: "upconv_u3d_u2a"
  type: "Deconvolution"
  bottom: "u3d"
  top: "u2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_u2a"
  type: "BatchNorm"
  bottom: "u2a"
  top: "u2a"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u2a"
  type: "Scale"
  bottom: "u2a"
  top: "u2a"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u2a"
  type: "ReLU"
  bottom: "u2a"
  top: "u2a"
}
layer {
  name: "crop_d2c-d2cc"
  type: "Crop"
  bottom: "d2c"
  bottom: "u2a"
  top: "d2cc"
  crop_param {
    axis: 2
    offset: 16
  }
}
layer {
  name: "concat_d2cc_u2a-b"
  type: "Concat"
  bottom: "u2a"
  bottom: "d2cc"
  top: "u2b"
}
layer {
  name: "conv_u2b-c"
  type: "Convolution"
  bottom: "u2b"
  top: "u2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u2c"
  type: "BatchNorm"
  bottom: "u2c"
  top: "u2c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u2c"
  type: "Scale"
  bottom: "u2c"
  top: "u2c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u2c"
  type: "ReLU"
  bottom: "u2c"
  top: "u2c"
}
layer {
  name: "conv_u2c-d"
  type: "Convolution"
  bottom: "u2c"
  top: "u2d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u2d"
  type: "BatchNorm"
  bottom: "u2d"
  top: "u2d"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u2d"
  type: "Scale"
  bottom: "u2d"
  top: "u2d"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u2d"
  type: "ReLU"
  bottom: "u2d"
  top: "u2d"
}
layer {
  name: "upconv_u2d_u1a"
  type: "Deconvolution"
  bottom: "u2d"
  top: "u1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_u1a"
  type: "BatchNorm"
  bottom: "u1a"
  top: "u1a"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u1a"
  type: "Scale"
  bottom: "u1a"
  top: "u1a"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u1a"
  type: "ReLU"
  bottom: "u1a"
  top: "u1a"
}
layer {
  name: "crop_d1c-d1cc"
  type: "Crop"
  bottom: "d1c"
  bottom: "u1a"
  top: "d1cc"
  crop_param {
    axis: 2
    offset: 40
  }
}
layer {
  name: "concat_d1cc_u1a-b"
  type: "Concat"
  bottom: "u1a"
  bottom: "d1cc"
  top: "u1b"
}
layer {
  name: "conv_u1b-c"
  type: "Convolution"
  bottom: "u1b"
  top: "u1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u1c"
  type: "BatchNorm"
  bottom: "u1c"
  top: "u1c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u1c"
  type: "Scale"
  bottom: "u1c"
  top: "u1c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u1c"
  type: "ReLU"
  bottom: "u1c"
  top: "u1c"
}
layer {
  name: "conv_u1c-d"
  type: "Convolution"
  bottom: "u1c"
  top: "u1d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u1d"
  type: "BatchNorm"
  bottom: "u1d"
  top: "u1d"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u1d"
  type: "Scale"
  bottom: "u1d"
  top: "u1d"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u1d"
  type: "ReLU"
  bottom: "u1d"
  top: "u1d"
}
layer {
  name: "upconv_u1d_u0a"
  type: "Deconvolution"
  bottom: "u1d"
  top: "u0a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_u0a"
  type: "BatchNorm"
  bottom: "u0a"
  top: "u0a"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u0a"
  type: "Scale"
  bottom: "u0a"
  top: "u0a"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u0a"
  type: "ReLU"
  bottom: "u0a"
  top: "u0a"
}
layer {
  name: "crop_d0c-d0cc"
  type: "Crop"
  bottom: "d0c"
  bottom: "u0a"
  top: "d0cc"
  crop_param {
    axis: 2
    offset: 88
  }
}
layer {
  name: "concat_d0cc_u0a-b"
  type: "Concat"
  bottom: "u0a"
  bottom: "d0cc"
  top: "u0b"
}
layer {
  name: "conv_u0b-c"
  type: "Convolution"
  bottom: "u0b"
  top: "u0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u0c"
  type: "BatchNorm"
  bottom: "u0c"
  top: "u0c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u0c"
  type: "Scale"
  bottom: "u0c"
  top: "u0c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u0c"
  type: "ReLU"
  bottom: "u0c"
  top: "u0c"
}
layer {
  name: "conv_u0c-d"
  type: "Convolution"
  bottom: "u0c"
  top: "u0d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u0d"
  type: "BatchNorm"
  bottom: "u0d"
  top: "u0d"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u0d"
  type: "Scale"
  bottom: "u0d"
  top: "u0d"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u0d"
  type: "ReLU"
  bottom: "u0d"
  top: "u0d"
}
layer {
  name: "conv_u0d-score"
  type: "Convolution"
  bottom: "u0d"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  bottom: "weights"
  top: "loss"
  loss_weight: 1
}
layer {
  name: "visualize"
  type: "Softmax"
  bottom: "score"
  top: "visualize_out"
  include {
    phase: TRAIN
  }
}
layer {
  name: "fake"
  type: "Silence"
  bottom: "visualize_out"
  include {
    phase: TRAIN
  }
}
I0428 15:09:07.797288  5145 layer_factory.hpp:77] Creating layer loaddata
I0428 15:09:07.797307  5145 net.cpp:100] Creating Layer loaddata
I0428 15:09:07.797317  5145 net.cpp:408] loaddata -> data
I0428 15:09:07.797335  5145 net.cpp:408] loaddata -> label
I0428 15:09:07.797348  5145 net.cpp:408] loaddata -> weights
I0428 15:09:07.797366  5145 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: caffeHDF5_4.txt
I0428 15:09:07.797411  5145 hdf5_data_layer.cpp:93] Number of HDF5 files: 20
I0428 15:09:07.798665  5145 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0428 15:09:08.733546  5145 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0428 15:09:08.961132  5145 net.cpp:150] Setting up loaddata
I0428 15:09:08.961158  5145 net.cpp:157] Top shape: 2 3 428 428 (1099104)
I0428 15:09:08.961163  5145 net.cpp:157] Top shape: 2 244 244 (119072)
I0428 15:09:08.961166  5145 net.cpp:157] Top shape: 2 244 244 (119072)
I0428 15:09:08.961169  5145 net.cpp:165] Memory required for data: 5348992
I0428 15:09:08.961190  5145 layer_factory.hpp:77] Creating layer conv_d0a-b
I0428 15:09:08.961206  5145 net.cpp:100] Creating Layer conv_d0a-b
I0428 15:09:08.961210  5145 net.cpp:434] conv_d0a-b <- data
I0428 15:09:08.961216  5145 net.cpp:408] conv_d0a-b -> d0b
I0428 15:09:08.963788  5145 net.cpp:150] Setting up conv_d0a-b
I0428 15:09:08.963804  5145 net.cpp:157] Top shape: 2 64 426 426 (23228928)
I0428 15:09:08.963805  5145 net.cpp:165] Memory required for data: 98264704
I0428 15:09:08.963831  5145 layer_factory.hpp:77] Creating layer bn_d0b
I0428 15:09:08.963840  5145 net.cpp:100] Creating Layer bn_d0b
I0428 15:09:08.963842  5145 net.cpp:434] bn_d0b <- d0b
I0428 15:09:08.963845  5145 net.cpp:395] bn_d0b -> d0b (in-place)
I0428 15:09:08.964145  5145 net.cpp:150] Setting up bn_d0b
I0428 15:09:08.964154  5145 net.cpp:157] Top shape: 2 64 426 426 (23228928)
I0428 15:09:08.964156  5145 net.cpp:165] Memory required for data: 191180416
I0428 15:09:08.964179  5145 layer_factory.hpp:77] Creating layer sc_d0b
I0428 15:09:08.964203  5145 net.cpp:100] Creating Layer sc_d0b
I0428 15:09:08.964207  5145 net.cpp:434] sc_d0b <- d0b
I0428 15:09:08.964212  5145 net.cpp:395] sc_d0b -> d0b (in-place)
I0428 15:09:08.964246  5145 layer_factory.hpp:77] Creating layer sc_d0b
I0428 15:09:08.965476  5145 net.cpp:150] Setting up sc_d0b
I0428 15:09:08.965488  5145 net.cpp:157] Top shape: 2 64 426 426 (23228928)
I0428 15:09:08.965492  5145 net.cpp:165] Memory required for data: 284096128
I0428 15:09:08.965497  5145 layer_factory.hpp:77] Creating layer relu_d0b
I0428 15:09:08.965504  5145 net.cpp:100] Creating Layer relu_d0b
I0428 15:09:08.965507  5145 net.cpp:434] relu_d0b <- d0b
I0428 15:09:08.965528  5145 net.cpp:395] relu_d0b -> d0b (in-place)
I0428 15:09:12.818254  5145 net.cpp:150] Setting up relu_d0b
I0428 15:09:12.818295  5145 net.cpp:157] Top shape: 2 64 426 426 (23228928)
I0428 15:09:12.818298  5145 net.cpp:165] Memory required for data: 377011840
I0428 15:09:12.818303  5145 layer_factory.hpp:77] Creating layer conv_d0b-c
I0428 15:09:12.818318  5145 net.cpp:100] Creating Layer conv_d0b-c
I0428 15:09:12.818321  5145 net.cpp:434] conv_d0b-c <- d0b
I0428 15:09:12.818328  5145 net.cpp:408] conv_d0b-c -> d0c
I0428 15:09:12.820538  5145 net.cpp:150] Setting up conv_d0b-c
I0428 15:09:12.820554  5145 net.cpp:157] Top shape: 2 64 424 424 (23011328)
I0428 15:09:12.820556  5145 net.cpp:165] Memory required for data: 469057152
I0428 15:09:12.820566  5145 layer_factory.hpp:77] Creating layer bn_d0c
I0428 15:09:12.820574  5145 net.cpp:100] Creating Layer bn_d0c
I0428 15:09:12.829242  5145 net.cpp:434] bn_d0c <- d0c
I0428 15:09:12.829269  5145 net.cpp:395] bn_d0c -> d0c (in-place)
I0428 15:09:12.829597  5145 net.cpp:150] Setting up bn_d0c
I0428 15:09:12.829608  5145 net.cpp:157] Top shape: 2 64 424 424 (23011328)
I0428 15:09:12.829610  5145 net.cpp:165] Memory required for data: 561102464
I0428 15:09:12.829625  5145 layer_factory.hpp:77] Creating layer sc_d0c
I0428 15:09:12.829635  5145 net.cpp:100] Creating Layer sc_d0c
I0428 15:09:12.829640  5145 net.cpp:434] sc_d0c <- d0c
I0428 15:09:12.829644  5145 net.cpp:395] sc_d0c -> d0c (in-place)
I0428 15:09:12.829680  5145 layer_factory.hpp:77] Creating layer sc_d0c
I0428 15:09:12.830932  5145 net.cpp:150] Setting up sc_d0c
I0428 15:09:12.830956  5145 net.cpp:157] Top shape: 2 64 424 424 (23011328)
I0428 15:09:12.830958  5145 net.cpp:165] Memory required for data: 653147776
I0428 15:09:12.830965  5145 layer_factory.hpp:77] Creating layer relu_d0c
I0428 15:09:12.830983  5145 net.cpp:100] Creating Layer relu_d0c
I0428 15:09:12.830986  5145 net.cpp:434] relu_d0c <- d0c
I0428 15:09:12.830991  5145 net.cpp:395] relu_d0c -> d0c (in-place)
I0428 15:09:12.831785  5145 net.cpp:150] Setting up relu_d0c
I0428 15:09:12.831799  5145 net.cpp:157] Top shape: 2 64 424 424 (23011328)
I0428 15:09:12.831801  5145 net.cpp:165] Memory required for data: 745193088
I0428 15:09:12.831804  5145 layer_factory.hpp:77] Creating layer d0c_relu_d0c_0_split
I0428 15:09:12.831810  5145 net.cpp:100] Creating Layer d0c_relu_d0c_0_split
I0428 15:09:12.831814  5145 net.cpp:434] d0c_relu_d0c_0_split <- d0c
I0428 15:09:12.831818  5145 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_0
I0428 15:09:12.831840  5145 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_1
I0428 15:09:12.831878  5145 net.cpp:150] Setting up d0c_relu_d0c_0_split
I0428 15:09:12.831885  5145 net.cpp:157] Top shape: 2 64 424 424 (23011328)
I0428 15:09:12.831889  5145 net.cpp:157] Top shape: 2 64 424 424 (23011328)
I0428 15:09:12.831892  5145 net.cpp:165] Memory required for data: 929283712
I0428 15:09:12.831894  5145 layer_factory.hpp:77] Creating layer pool_d0c-1a
I0428 15:09:12.831900  5145 net.cpp:100] Creating Layer pool_d0c-1a
I0428 15:09:12.831903  5145 net.cpp:434] pool_d0c-1a <- d0c_relu_d0c_0_split_0
I0428 15:09:12.831907  5145 net.cpp:408] pool_d0c-1a -> d1a
I0428 15:09:12.831939  5145 net.cpp:150] Setting up pool_d0c-1a
I0428 15:09:12.831946  5145 net.cpp:157] Top shape: 2 64 212 212 (5752832)
I0428 15:09:12.831949  5145 net.cpp:165] Memory required for data: 952295040
I0428 15:09:12.831951  5145 layer_factory.hpp:77] Creating layer conv_d1a-b
I0428 15:09:12.831959  5145 net.cpp:100] Creating Layer conv_d1a-b
I0428 15:09:12.831961  5145 net.cpp:434] conv_d1a-b <- d1a
I0428 15:09:12.831966  5145 net.cpp:408] conv_d1a-b -> d1b
I0428 15:09:12.832614  5145 net.cpp:150] Setting up conv_d1a-b
I0428 15:09:12.832623  5145 net.cpp:157] Top shape: 2 128 210 210 (11289600)
I0428 15:09:12.832625  5145 net.cpp:165] Memory required for data: 997453440
I0428 15:09:12.832631  5145 layer_factory.hpp:77] Creating layer bn_d1b
I0428 15:09:12.832636  5145 net.cpp:100] Creating Layer bn_d1b
I0428 15:09:12.832654  5145 net.cpp:434] bn_d1b <- d1b
I0428 15:09:12.832659  5145 net.cpp:395] bn_d1b -> d1b (in-place)
I0428 15:09:12.832850  5145 net.cpp:150] Setting up bn_d1b
I0428 15:09:12.832857  5145 net.cpp:157] Top shape: 2 128 210 210 (11289600)
I0428 15:09:12.832860  5145 net.cpp:165] Memory required for data: 1042611840
I0428 15:09:12.832870  5145 layer_factory.hpp:77] Creating layer sc_d1b
I0428 15:09:12.832878  5145 net.cpp:100] Creating Layer sc_d1b
I0428 15:09:12.832881  5145 net.cpp:434] sc_d1b <- d1b
I0428 15:09:12.832885  5145 net.cpp:395] sc_d1b -> d1b (in-place)
I0428 15:09:12.832919  5145 layer_factory.hpp:77] Creating layer sc_d1b
I0428 15:09:12.833071  5145 net.cpp:150] Setting up sc_d1b
I0428 15:09:12.833079  5145 net.cpp:157] Top shape: 2 128 210 210 (11289600)
I0428 15:09:12.833081  5145 net.cpp:165] Memory required for data: 1087770240
I0428 15:09:12.833086  5145 layer_factory.hpp:77] Creating layer relu_d1b
I0428 15:09:12.833106  5145 net.cpp:100] Creating Layer relu_d1b
I0428 15:09:12.833108  5145 net.cpp:434] relu_d1b <- d1b
I0428 15:09:12.833112  5145 net.cpp:395] relu_d1b -> d1b (in-place)
I0428 15:09:12.833276  5145 net.cpp:150] Setting up relu_d1b
I0428 15:09:12.833286  5145 net.cpp:157] Top shape: 2 128 210 210 (11289600)
I0428 15:09:12.833287  5145 net.cpp:165] Memory required for data: 1132928640
I0428 15:09:12.833290  5145 layer_factory.hpp:77] Creating layer conv_d1b-c
I0428 15:09:12.833297  5145 net.cpp:100] Creating Layer conv_d1b-c
I0428 15:09:12.833302  5145 net.cpp:434] conv_d1b-c <- d1b
I0428 15:09:12.833305  5145 net.cpp:408] conv_d1b-c -> d1c
I0428 15:09:12.834461  5145 net.cpp:150] Setting up conv_d1b-c
I0428 15:09:12.834470  5145 net.cpp:157] Top shape: 2 128 208 208 (11075584)
I0428 15:09:12.834472  5145 net.cpp:165] Memory required for data: 1177230976
I0428 15:09:12.834478  5145 layer_factory.hpp:77] Creating layer bn_d1c
I0428 15:09:12.834486  5145 net.cpp:100] Creating Layer bn_d1c
I0428 15:09:12.834488  5145 net.cpp:434] bn_d1c <- d1c
I0428 15:09:12.834493  5145 net.cpp:395] bn_d1c -> d1c (in-place)
I0428 15:09:12.834673  5145 net.cpp:150] Setting up bn_d1c
I0428 15:09:12.834681  5145 net.cpp:157] Top shape: 2 128 208 208 (11075584)
I0428 15:09:12.834683  5145 net.cpp:165] Memory required for data: 1221533312
I0428 15:09:12.834691  5145 layer_factory.hpp:77] Creating layer sc_d1c
I0428 15:09:12.834697  5145 net.cpp:100] Creating Layer sc_d1c
I0428 15:09:12.834698  5145 net.cpp:434] sc_d1c <- d1c
I0428 15:09:12.834702  5145 net.cpp:395] sc_d1c -> d1c (in-place)
I0428 15:09:12.834735  5145 layer_factory.hpp:77] Creating layer sc_d1c
I0428 15:09:12.834873  5145 net.cpp:150] Setting up sc_d1c
I0428 15:09:12.834880  5145 net.cpp:157] Top shape: 2 128 208 208 (11075584)
I0428 15:09:12.834882  5145 net.cpp:165] Memory required for data: 1265835648
I0428 15:09:12.834888  5145 layer_factory.hpp:77] Creating layer relu_d1c
I0428 15:09:12.834893  5145 net.cpp:100] Creating Layer relu_d1c
I0428 15:09:12.834895  5145 net.cpp:434] relu_d1c <- d1c
I0428 15:09:12.834899  5145 net.cpp:395] relu_d1c -> d1c (in-place)
I0428 15:09:12.835060  5145 net.cpp:150] Setting up relu_d1c
I0428 15:09:12.835068  5145 net.cpp:157] Top shape: 2 128 208 208 (11075584)
I0428 15:09:12.835072  5145 net.cpp:165] Memory required for data: 1310137984
I0428 15:09:12.835074  5145 layer_factory.hpp:77] Creating layer d1c_relu_d1c_0_split
I0428 15:09:12.835079  5145 net.cpp:100] Creating Layer d1c_relu_d1c_0_split
I0428 15:09:12.835083  5145 net.cpp:434] d1c_relu_d1c_0_split <- d1c
I0428 15:09:12.835086  5145 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_0
I0428 15:09:12.835093  5145 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_1
I0428 15:09:12.835127  5145 net.cpp:150] Setting up d1c_relu_d1c_0_split
I0428 15:09:12.835134  5145 net.cpp:157] Top shape: 2 128 208 208 (11075584)
I0428 15:09:12.835137  5145 net.cpp:157] Top shape: 2 128 208 208 (11075584)
I0428 15:09:12.835139  5145 net.cpp:165] Memory required for data: 1398742656
I0428 15:09:12.835142  5145 layer_factory.hpp:77] Creating layer pool_d1c-2a
I0428 15:09:12.835147  5145 net.cpp:100] Creating Layer pool_d1c-2a
I0428 15:09:12.835150  5145 net.cpp:434] pool_d1c-2a <- d1c_relu_d1c_0_split_0
I0428 15:09:12.835155  5145 net.cpp:408] pool_d1c-2a -> d2a
I0428 15:09:12.835185  5145 net.cpp:150] Setting up pool_d1c-2a
I0428 15:09:12.835191  5145 net.cpp:157] Top shape: 2 128 104 104 (2768896)
I0428 15:09:12.835193  5145 net.cpp:165] Memory required for data: 1409818240
I0428 15:09:12.835196  5145 layer_factory.hpp:77] Creating layer conv_d2a-b
I0428 15:09:12.835202  5145 net.cpp:100] Creating Layer conv_d2a-b
I0428 15:09:12.835206  5145 net.cpp:434] conv_d2a-b <- d2a
I0428 15:09:12.835209  5145 net.cpp:408] conv_d2a-b -> d2b
I0428 15:09:12.838680  5145 net.cpp:150] Setting up conv_d2a-b
I0428 15:09:12.838692  5145 net.cpp:157] Top shape: 2 256 102 102 (5326848)
I0428 15:09:12.838696  5145 net.cpp:165] Memory required for data: 1431125632
I0428 15:09:12.838727  5145 layer_factory.hpp:77] Creating layer bn_d2b
I0428 15:09:12.838734  5145 net.cpp:100] Creating Layer bn_d2b
I0428 15:09:12.838738  5145 net.cpp:434] bn_d2b <- d2b
I0428 15:09:12.838755  5145 net.cpp:395] bn_d2b -> d2b (in-place)
I0428 15:09:12.838932  5145 net.cpp:150] Setting up bn_d2b
I0428 15:09:12.838939  5145 net.cpp:157] Top shape: 2 256 102 102 (5326848)
I0428 15:09:12.838943  5145 net.cpp:165] Memory required for data: 1452433024
I0428 15:09:12.838953  5145 layer_factory.hpp:77] Creating layer sc_d2b
I0428 15:09:12.838959  5145 net.cpp:100] Creating Layer sc_d2b
I0428 15:09:12.838961  5145 net.cpp:434] sc_d2b <- d2b
I0428 15:09:12.838968  5145 net.cpp:395] sc_d2b -> d2b (in-place)
I0428 15:09:12.839001  5145 layer_factory.hpp:77] Creating layer sc_d2b
I0428 15:09:12.839105  5145 net.cpp:150] Setting up sc_d2b
I0428 15:09:12.839112  5145 net.cpp:157] Top shape: 2 256 102 102 (5326848)
I0428 15:09:12.839115  5145 net.cpp:165] Memory required for data: 1473740416
I0428 15:09:12.839120  5145 layer_factory.hpp:77] Creating layer relu_d2b
I0428 15:09:12.839125  5145 net.cpp:100] Creating Layer relu_d2b
I0428 15:09:12.839128  5145 net.cpp:434] relu_d2b <- d2b
I0428 15:09:12.839133  5145 net.cpp:395] relu_d2b -> d2b (in-place)
I0428 15:09:12.839306  5145 net.cpp:150] Setting up relu_d2b
I0428 15:09:12.839315  5145 net.cpp:157] Top shape: 2 256 102 102 (5326848)
I0428 15:09:12.839318  5145 net.cpp:165] Memory required for data: 1495047808
I0428 15:09:12.839321  5145 layer_factory.hpp:77] Creating layer conv_d2b-c
I0428 15:09:12.839329  5145 net.cpp:100] Creating Layer conv_d2b-c
I0428 15:09:12.839331  5145 net.cpp:434] conv_d2b-c <- d2b
I0428 15:09:12.839336  5145 net.cpp:408] conv_d2b-c -> d2c
I0428 15:09:12.843608  5145 net.cpp:150] Setting up conv_d2b-c
I0428 15:09:12.843621  5145 net.cpp:157] Top shape: 2 256 100 100 (5120000)
I0428 15:09:12.843624  5145 net.cpp:165] Memory required for data: 1515527808
I0428 15:09:12.843629  5145 layer_factory.hpp:77] Creating layer bn_d2c
I0428 15:09:12.843639  5145 net.cpp:100] Creating Layer bn_d2c
I0428 15:09:12.843642  5145 net.cpp:434] bn_d2c <- d2c
I0428 15:09:12.843647  5145 net.cpp:395] bn_d2c -> d2c (in-place)
I0428 15:09:12.843823  5145 net.cpp:150] Setting up bn_d2c
I0428 15:09:12.843832  5145 net.cpp:157] Top shape: 2 256 100 100 (5120000)
I0428 15:09:12.843833  5145 net.cpp:165] Memory required for data: 1536007808
I0428 15:09:12.843855  5145 layer_factory.hpp:77] Creating layer sc_d2c
I0428 15:09:12.843860  5145 net.cpp:100] Creating Layer sc_d2c
I0428 15:09:12.843864  5145 net.cpp:434] sc_d2c <- d2c
I0428 15:09:12.843869  5145 net.cpp:395] sc_d2c -> d2c (in-place)
I0428 15:09:12.843902  5145 layer_factory.hpp:77] Creating layer sc_d2c
I0428 15:09:12.844033  5145 net.cpp:150] Setting up sc_d2c
I0428 15:09:12.844040  5145 net.cpp:157] Top shape: 2 256 100 100 (5120000)
I0428 15:09:12.844043  5145 net.cpp:165] Memory required for data: 1556487808
I0428 15:09:12.844048  5145 layer_factory.hpp:77] Creating layer relu_d2c
I0428 15:09:12.844053  5145 net.cpp:100] Creating Layer relu_d2c
I0428 15:09:12.844056  5145 net.cpp:434] relu_d2c <- d2c
I0428 15:09:12.844059  5145 net.cpp:395] relu_d2c -> d2c (in-place)
I0428 15:09:12.846228  5145 net.cpp:150] Setting up relu_d2c
I0428 15:09:12.846245  5145 net.cpp:157] Top shape: 2 256 100 100 (5120000)
I0428 15:09:12.846248  5145 net.cpp:165] Memory required for data: 1576967808
I0428 15:09:12.846251  5145 layer_factory.hpp:77] Creating layer d2c_relu_d2c_0_split
I0428 15:09:12.846257  5145 net.cpp:100] Creating Layer d2c_relu_d2c_0_split
I0428 15:09:12.846259  5145 net.cpp:434] d2c_relu_d2c_0_split <- d2c
I0428 15:09:12.846269  5145 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_0
I0428 15:09:12.846276  5145 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_1
I0428 15:09:12.846331  5145 net.cpp:150] Setting up d2c_relu_d2c_0_split
I0428 15:09:12.846339  5145 net.cpp:157] Top shape: 2 256 100 100 (5120000)
I0428 15:09:12.846343  5145 net.cpp:157] Top shape: 2 256 100 100 (5120000)
I0428 15:09:12.846359  5145 net.cpp:165] Memory required for data: 1617927808
I0428 15:09:12.846361  5145 layer_factory.hpp:77] Creating layer pool_d2c-3a
I0428 15:09:12.846366  5145 net.cpp:100] Creating Layer pool_d2c-3a
I0428 15:09:12.846386  5145 net.cpp:434] pool_d2c-3a <- d2c_relu_d2c_0_split_0
I0428 15:09:12.846392  5145 net.cpp:408] pool_d2c-3a -> d3a
I0428 15:09:12.846427  5145 net.cpp:150] Setting up pool_d2c-3a
I0428 15:09:12.846434  5145 net.cpp:157] Top shape: 2 256 50 50 (1280000)
I0428 15:09:12.846437  5145 net.cpp:165] Memory required for data: 1623047808
I0428 15:09:12.846439  5145 layer_factory.hpp:77] Creating layer conv_d3a-b
I0428 15:09:12.846448  5145 net.cpp:100] Creating Layer conv_d3a-b
I0428 15:09:12.846451  5145 net.cpp:434] conv_d3a-b <- d3a
I0428 15:09:12.846457  5145 net.cpp:408] conv_d3a-b -> d3b
I0428 15:09:12.856940  5145 net.cpp:150] Setting up conv_d3a-b
I0428 15:09:12.856956  5145 net.cpp:157] Top shape: 2 512 48 48 (2359296)
I0428 15:09:12.856958  5145 net.cpp:165] Memory required for data: 1632484992
I0428 15:09:12.856976  5145 layer_factory.hpp:77] Creating layer bn_d3b
I0428 15:09:12.856987  5145 net.cpp:100] Creating Layer bn_d3b
I0428 15:09:12.856992  5145 net.cpp:434] bn_d3b <- d3b
I0428 15:09:12.856997  5145 net.cpp:395] bn_d3b -> d3b (in-place)
I0428 15:09:12.857200  5145 net.cpp:150] Setting up bn_d3b
I0428 15:09:12.857208  5145 net.cpp:157] Top shape: 2 512 48 48 (2359296)
I0428 15:09:12.857210  5145 net.cpp:165] Memory required for data: 1641922176
I0428 15:09:12.857216  5145 layer_factory.hpp:77] Creating layer sc_d3b
I0428 15:09:12.857223  5145 net.cpp:100] Creating Layer sc_d3b
I0428 15:09:12.857225  5145 net.cpp:434] sc_d3b <- d3b
I0428 15:09:12.857230  5145 net.cpp:395] sc_d3b -> d3b (in-place)
I0428 15:09:12.857264  5145 layer_factory.hpp:77] Creating layer sc_d3b
I0428 15:09:12.857367  5145 net.cpp:150] Setting up sc_d3b
I0428 15:09:12.857374  5145 net.cpp:157] Top shape: 2 512 48 48 (2359296)
I0428 15:09:12.857376  5145 net.cpp:165] Memory required for data: 1651359360
I0428 15:09:12.857381  5145 layer_factory.hpp:77] Creating layer relu_d3b
I0428 15:09:12.857386  5145 net.cpp:100] Creating Layer relu_d3b
I0428 15:09:12.857389  5145 net.cpp:434] relu_d3b <- d3b
I0428 15:09:12.857394  5145 net.cpp:395] relu_d3b -> d3b (in-place)
I0428 15:09:12.857587  5145 net.cpp:150] Setting up relu_d3b
I0428 15:09:12.857599  5145 net.cpp:157] Top shape: 2 512 48 48 (2359296)
I0428 15:09:12.857600  5145 net.cpp:165] Memory required for data: 1660796544
I0428 15:09:12.857604  5145 layer_factory.hpp:77] Creating layer conv_d3b-c
I0428 15:09:12.857612  5145 net.cpp:100] Creating Layer conv_d3b-c
I0428 15:09:12.857615  5145 net.cpp:434] conv_d3b-c <- d3b
I0428 15:09:12.857620  5145 net.cpp:408] conv_d3b-c -> d3c
I0428 15:09:12.873353  5145 net.cpp:150] Setting up conv_d3b-c
I0428 15:09:12.873366  5145 net.cpp:157] Top shape: 2 512 46 46 (2166784)
I0428 15:09:12.873369  5145 net.cpp:165] Memory required for data: 1669463680
I0428 15:09:12.873374  5145 layer_factory.hpp:77] Creating layer bn_d3c
I0428 15:09:12.873380  5145 net.cpp:100] Creating Layer bn_d3c
I0428 15:09:12.873383  5145 net.cpp:434] bn_d3c <- d3c
I0428 15:09:12.873389  5145 net.cpp:395] bn_d3c -> d3c (in-place)
I0428 15:09:12.873606  5145 net.cpp:150] Setting up bn_d3c
I0428 15:09:12.873615  5145 net.cpp:157] Top shape: 2 512 46 46 (2166784)
I0428 15:09:12.873616  5145 net.cpp:165] Memory required for data: 1678130816
I0428 15:09:12.873623  5145 layer_factory.hpp:77] Creating layer sc_d3c
I0428 15:09:12.873630  5145 net.cpp:100] Creating Layer sc_d3c
I0428 15:09:12.873631  5145 net.cpp:434] sc_d3c <- d3c
I0428 15:09:12.873637  5145 net.cpp:395] sc_d3c -> d3c (in-place)
I0428 15:09:12.873670  5145 layer_factory.hpp:77] Creating layer sc_d3c
I0428 15:09:12.873782  5145 net.cpp:150] Setting up sc_d3c
I0428 15:09:12.873790  5145 net.cpp:157] Top shape: 2 512 46 46 (2166784)
I0428 15:09:12.873792  5145 net.cpp:165] Memory required for data: 1686797952
I0428 15:09:12.873798  5145 layer_factory.hpp:77] Creating layer relu_d3c
I0428 15:09:12.873816  5145 net.cpp:100] Creating Layer relu_d3c
I0428 15:09:12.873819  5145 net.cpp:434] relu_d3c <- d3c
I0428 15:09:12.873823  5145 net.cpp:395] relu_d3c -> d3c (in-place)
I0428 15:09:12.874053  5145 net.cpp:150] Setting up relu_d3c
I0428 15:09:12.874064  5145 net.cpp:157] Top shape: 2 512 46 46 (2166784)
I0428 15:09:12.874066  5145 net.cpp:165] Memory required for data: 1695465088
I0428 15:09:12.874069  5145 layer_factory.hpp:77] Creating layer d3c_relu_d3c_0_split
I0428 15:09:12.874074  5145 net.cpp:100] Creating Layer d3c_relu_d3c_0_split
I0428 15:09:12.874078  5145 net.cpp:434] d3c_relu_d3c_0_split <- d3c
I0428 15:09:12.874083  5145 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_0
I0428 15:09:12.874104  5145 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_1
I0428 15:09:12.874146  5145 net.cpp:150] Setting up d3c_relu_d3c_0_split
I0428 15:09:12.874155  5145 net.cpp:157] Top shape: 2 512 46 46 (2166784)
I0428 15:09:12.874158  5145 net.cpp:157] Top shape: 2 512 46 46 (2166784)
I0428 15:09:12.874161  5145 net.cpp:165] Memory required for data: 1712799360
I0428 15:09:12.874164  5145 layer_factory.hpp:77] Creating layer pool_d3c-4a
I0428 15:09:12.874168  5145 net.cpp:100] Creating Layer pool_d3c-4a
I0428 15:09:12.874171  5145 net.cpp:434] pool_d3c-4a <- d3c_relu_d3c_0_split_0
I0428 15:09:12.874176  5145 net.cpp:408] pool_d3c-4a -> d4a
I0428 15:09:12.874210  5145 net.cpp:150] Setting up pool_d3c-4a
I0428 15:09:12.874217  5145 net.cpp:157] Top shape: 2 512 23 23 (541696)
I0428 15:09:12.874218  5145 net.cpp:165] Memory required for data: 1714966144
I0428 15:09:12.874220  5145 layer_factory.hpp:77] Creating layer conv_d4a-b
I0428 15:09:12.874230  5145 net.cpp:100] Creating Layer conv_d4a-b
I0428 15:09:12.874233  5145 net.cpp:434] conv_d4a-b <- d4a
I0428 15:09:12.874238  5145 net.cpp:408] conv_d4a-b -> d4b
I0428 15:09:12.904083  5145 net.cpp:150] Setting up conv_d4a-b
I0428 15:09:12.904098  5145 net.cpp:157] Top shape: 2 1024 21 21 (903168)
I0428 15:09:12.904099  5145 net.cpp:165] Memory required for data: 1718578816
I0428 15:09:12.904104  5145 layer_factory.hpp:77] Creating layer bn_d4b
I0428 15:09:12.904111  5145 net.cpp:100] Creating Layer bn_d4b
I0428 15:09:12.904114  5145 net.cpp:434] bn_d4b <- d4b
I0428 15:09:12.904119  5145 net.cpp:395] bn_d4b -> d4b (in-place)
I0428 15:09:12.904337  5145 net.cpp:150] Setting up bn_d4b
I0428 15:09:12.904348  5145 net.cpp:157] Top shape: 2 1024 21 21 (903168)
I0428 15:09:12.904351  5145 net.cpp:165] Memory required for data: 1722191488
I0428 15:09:12.904358  5145 layer_factory.hpp:77] Creating layer sc_d4b
I0428 15:09:12.904366  5145 net.cpp:100] Creating Layer sc_d4b
I0428 15:09:12.904369  5145 net.cpp:434] sc_d4b <- d4b
I0428 15:09:12.904374  5145 net.cpp:395] sc_d4b -> d4b (in-place)
I0428 15:09:12.904415  5145 layer_factory.hpp:77] Creating layer sc_d4b
I0428 15:09:12.904520  5145 net.cpp:150] Setting up sc_d4b
I0428 15:09:12.904527  5145 net.cpp:157] Top shape: 2 1024 21 21 (903168)
I0428 15:09:12.904531  5145 net.cpp:165] Memory required for data: 1725804160
I0428 15:09:12.904536  5145 layer_factory.hpp:77] Creating layer relu_d4b
I0428 15:09:12.904539  5145 net.cpp:100] Creating Layer relu_d4b
I0428 15:09:12.904542  5145 net.cpp:434] relu_d4b <- d4b
I0428 15:09:12.904548  5145 net.cpp:395] relu_d4b -> d4b (in-place)
I0428 15:09:12.910553  5145 net.cpp:150] Setting up relu_d4b
I0428 15:09:12.910569  5145 net.cpp:157] Top shape: 2 1024 21 21 (903168)
I0428 15:09:12.910588  5145 net.cpp:165] Memory required for data: 1729416832
I0428 15:09:12.910591  5145 layer_factory.hpp:77] Creating layer conv_d4b-c
I0428 15:09:12.910603  5145 net.cpp:100] Creating Layer conv_d4b-c
I0428 15:09:12.910605  5145 net.cpp:434] conv_d4b-c <- d4b
I0428 15:09:12.910611  5145 net.cpp:408] conv_d4b-c -> d4c
I0428 15:09:12.972100  5145 net.cpp:150] Setting up conv_d4b-c
I0428 15:09:12.972121  5145 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0428 15:09:12.972124  5145 net.cpp:165] Memory required for data: 1732374144
I0428 15:09:12.972144  5145 layer_factory.hpp:77] Creating layer bn_d4c
I0428 15:09:12.972172  5145 net.cpp:100] Creating Layer bn_d4c
I0428 15:09:12.972177  5145 net.cpp:434] bn_d4c <- d4c
I0428 15:09:12.972183  5145 net.cpp:395] bn_d4c -> d4c (in-place)
I0428 15:09:12.972406  5145 net.cpp:150] Setting up bn_d4c
I0428 15:09:12.972414  5145 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0428 15:09:12.972417  5145 net.cpp:165] Memory required for data: 1735331456
I0428 15:09:12.972424  5145 layer_factory.hpp:77] Creating layer sc_d4c
I0428 15:09:12.972429  5145 net.cpp:100] Creating Layer sc_d4c
I0428 15:09:12.972432  5145 net.cpp:434] sc_d4c <- d4c
I0428 15:09:12.972451  5145 net.cpp:395] sc_d4c -> d4c (in-place)
I0428 15:09:12.972496  5145 layer_factory.hpp:77] Creating layer sc_d4c
I0428 15:09:12.972623  5145 net.cpp:150] Setting up sc_d4c
I0428 15:09:12.972631  5145 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0428 15:09:12.972633  5145 net.cpp:165] Memory required for data: 1738288768
I0428 15:09:12.972638  5145 layer_factory.hpp:77] Creating layer relu_d4c
I0428 15:09:12.972643  5145 net.cpp:100] Creating Layer relu_d4c
I0428 15:09:12.972646  5145 net.cpp:434] relu_d4c <- d4c
I0428 15:09:12.972654  5145 net.cpp:395] relu_d4c -> d4c (in-place)
I0428 15:09:12.972861  5145 net.cpp:150] Setting up relu_d4c
I0428 15:09:12.972869  5145 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0428 15:09:12.972872  5145 net.cpp:165] Memory required for data: 1741246080
I0428 15:09:12.972874  5145 layer_factory.hpp:77] Creating layer upconv_d4c_u3a
I0428 15:09:12.972888  5145 net.cpp:100] Creating Layer upconv_d4c_u3a
I0428 15:09:12.972890  5145 net.cpp:434] upconv_d4c_u3a <- d4c
I0428 15:09:12.972898  5145 net.cpp:408] upconv_d4c_u3a -> u3a
I0428 15:09:12.986681  5145 net.cpp:150] Setting up upconv_d4c_u3a
I0428 15:09:12.986696  5145 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0428 15:09:12.986697  5145 net.cpp:165] Memory required for data: 1747160704
I0428 15:09:12.986703  5145 layer_factory.hpp:77] Creating layer bn_u3a
I0428 15:09:12.986711  5145 net.cpp:100] Creating Layer bn_u3a
I0428 15:09:12.986713  5145 net.cpp:434] bn_u3a <- u3a
I0428 15:09:12.986718  5145 net.cpp:395] bn_u3a -> u3a (in-place)
I0428 15:09:12.986905  5145 net.cpp:150] Setting up bn_u3a
I0428 15:09:12.986912  5145 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0428 15:09:12.986914  5145 net.cpp:165] Memory required for data: 1753075328
I0428 15:09:12.986920  5145 layer_factory.hpp:77] Creating layer sc_u3a
I0428 15:09:12.986943  5145 net.cpp:100] Creating Layer sc_u3a
I0428 15:09:12.986946  5145 net.cpp:434] sc_u3a <- u3a
I0428 15:09:12.986966  5145 net.cpp:395] sc_u3a -> u3a (in-place)
I0428 15:09:12.987002  5145 layer_factory.hpp:77] Creating layer sc_u3a
I0428 15:09:12.987118  5145 net.cpp:150] Setting up sc_u3a
I0428 15:09:12.987124  5145 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0428 15:09:12.987126  5145 net.cpp:165] Memory required for data: 1758989952
I0428 15:09:12.987131  5145 layer_factory.hpp:77] Creating layer relu_u3a
I0428 15:09:12.987136  5145 net.cpp:100] Creating Layer relu_u3a
I0428 15:09:12.987139  5145 net.cpp:434] relu_u3a <- u3a
I0428 15:09:12.987154  5145 net.cpp:395] relu_u3a -> u3a (in-place)
I0428 15:09:12.987354  5145 net.cpp:150] Setting up relu_u3a
I0428 15:09:12.987365  5145 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0428 15:09:12.987367  5145 net.cpp:165] Memory required for data: 1764904576
I0428 15:09:12.987370  5145 layer_factory.hpp:77] Creating layer u3a_relu_u3a_0_split
I0428 15:09:12.987375  5145 net.cpp:100] Creating Layer u3a_relu_u3a_0_split
I0428 15:09:12.987377  5145 net.cpp:434] u3a_relu_u3a_0_split <- u3a
I0428 15:09:12.987385  5145 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_0
I0428 15:09:12.987390  5145 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_1
I0428 15:09:12.987447  5145 net.cpp:150] Setting up u3a_relu_u3a_0_split
I0428 15:09:12.987454  5145 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0428 15:09:12.987457  5145 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0428 15:09:12.987459  5145 net.cpp:165] Memory required for data: 1776733824
I0428 15:09:12.987473  5145 layer_factory.hpp:77] Creating layer crop_d3c-d3cc
I0428 15:09:12.987480  5145 net.cpp:100] Creating Layer crop_d3c-d3cc
I0428 15:09:12.987485  5145 net.cpp:434] crop_d3c-d3cc <- d3c_relu_d3c_0_split_1
I0428 15:09:12.987489  5145 net.cpp:434] crop_d3c-d3cc <- u3a_relu_u3a_0_split_0
I0428 15:09:12.987493  5145 net.cpp:408] crop_d3c-d3cc -> d3cc
I0428 15:09:12.987519  5145 net.cpp:150] Setting up crop_d3c-d3cc
I0428 15:09:12.987526  5145 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0428 15:09:12.987529  5145 net.cpp:165] Memory required for data: 1782648448
I0428 15:09:12.987531  5145 layer_factory.hpp:77] Creating layer concat_d3cc_u3a-b
I0428 15:09:12.987536  5145 net.cpp:100] Creating Layer concat_d3cc_u3a-b
I0428 15:09:12.987538  5145 net.cpp:434] concat_d3cc_u3a-b <- u3a_relu_u3a_0_split_1
I0428 15:09:12.987541  5145 net.cpp:434] concat_d3cc_u3a-b <- d3cc
I0428 15:09:12.987546  5145 net.cpp:408] concat_d3cc_u3a-b -> u3b
I0428 15:09:12.987567  5145 net.cpp:150] Setting up concat_d3cc_u3a-b
I0428 15:09:12.987571  5145 net.cpp:157] Top shape: 2 1024 38 38 (2957312)
I0428 15:09:12.987573  5145 net.cpp:165] Memory required for data: 1794477696
I0428 15:09:12.987576  5145 layer_factory.hpp:77] Creating layer conv_u3b-c
I0428 15:09:12.987586  5145 net.cpp:100] Creating Layer conv_u3b-c
I0428 15:09:12.987588  5145 net.cpp:434] conv_u3b-c <- u3b
I0428 15:09:12.987594  5145 net.cpp:408] conv_u3b-c -> u3c
I0428 15:09:13.017392  5145 net.cpp:150] Setting up conv_u3b-c
I0428 15:09:13.017408  5145 net.cpp:157] Top shape: 2 512 36 36 (1327104)
I0428 15:09:13.017427  5145 net.cpp:165] Memory required for data: 1799786112
I0428 15:09:13.017432  5145 layer_factory.hpp:77] Creating layer bn_u3c
I0428 15:09:13.017442  5145 net.cpp:100] Creating Layer bn_u3c
I0428 15:09:13.017462  5145 net.cpp:434] bn_u3c <- u3c
I0428 15:09:13.017467  5145 net.cpp:395] bn_u3c -> u3c (in-place)
I0428 15:09:13.017669  5145 net.cpp:150] Setting up bn_u3c
I0428 15:09:13.017678  5145 net.cpp:157] Top shape: 2 512 36 36 (1327104)
I0428 15:09:13.017680  5145 net.cpp:165] Memory required for data: 1805094528
I0428 15:09:13.017686  5145 layer_factory.hpp:77] Creating layer sc_u3c
I0428 15:09:13.017691  5145 net.cpp:100] Creating Layer sc_u3c
I0428 15:09:13.017694  5145 net.cpp:434] sc_u3c <- u3c
I0428 15:09:13.017699  5145 net.cpp:395] sc_u3c -> u3c (in-place)
I0428 15:09:13.017735  5145 layer_factory.hpp:77] Creating layer sc_u3c
I0428 15:09:13.017859  5145 net.cpp:150] Setting up sc_u3c
I0428 15:09:13.017868  5145 net.cpp:157] Top shape: 2 512 36 36 (1327104)
I0428 15:09:13.017870  5145 net.cpp:165] Memory required for data: 1810402944
I0428 15:09:13.017875  5145 layer_factory.hpp:77] Creating layer relu_u3c
I0428 15:09:13.017879  5145 net.cpp:100] Creating Layer relu_u3c
I0428 15:09:13.017882  5145 net.cpp:434] relu_u3c <- u3c
I0428 15:09:13.017887  5145 net.cpp:395] relu_u3c -> u3c (in-place)
I0428 15:09:13.018090  5145 net.cpp:150] Setting up relu_u3c
I0428 15:09:13.018098  5145 net.cpp:157] Top shape: 2 512 36 36 (1327104)
I0428 15:09:13.018101  5145 net.cpp:165] Memory required for data: 1815711360
I0428 15:09:13.018105  5145 layer_factory.hpp:77] Creating layer conv_u3c-d
I0428 15:09:13.018113  5145 net.cpp:100] Creating Layer conv_u3c-d
I0428 15:09:13.018116  5145 net.cpp:434] conv_u3c-d <- u3c
I0428 15:09:13.018121  5145 net.cpp:408] conv_u3c-d -> u3d
I0428 15:09:13.033520  5145 net.cpp:150] Setting up conv_u3c-d
I0428 15:09:13.033535  5145 net.cpp:157] Top shape: 2 512 34 34 (1183744)
I0428 15:09:13.033552  5145 net.cpp:165] Memory required for data: 1820446336
I0428 15:09:13.033558  5145 layer_factory.hpp:77] Creating layer bn_u3d
I0428 15:09:13.033566  5145 net.cpp:100] Creating Layer bn_u3d
I0428 15:09:13.033571  5145 net.cpp:434] bn_u3d <- u3d
I0428 15:09:13.033576  5145 net.cpp:395] bn_u3d -> u3d (in-place)
I0428 15:09:13.033762  5145 net.cpp:150] Setting up bn_u3d
I0428 15:09:13.033778  5145 net.cpp:157] Top shape: 2 512 34 34 (1183744)
I0428 15:09:13.033780  5145 net.cpp:165] Memory required for data: 1825181312
I0428 15:09:13.033799  5145 layer_factory.hpp:77] Creating layer sc_u3d
I0428 15:09:13.033805  5145 net.cpp:100] Creating Layer sc_u3d
I0428 15:09:13.033808  5145 net.cpp:434] sc_u3d <- u3d
I0428 15:09:13.033814  5145 net.cpp:395] sc_u3d -> u3d (in-place)
I0428 15:09:13.033849  5145 layer_factory.hpp:77] Creating layer sc_u3d
I0428 15:09:13.033967  5145 net.cpp:150] Setting up sc_u3d
I0428 15:09:13.033975  5145 net.cpp:157] Top shape: 2 512 34 34 (1183744)
I0428 15:09:13.033977  5145 net.cpp:165] Memory required for data: 1829916288
I0428 15:09:13.033982  5145 layer_factory.hpp:77] Creating layer relu_u3d
I0428 15:09:13.033987  5145 net.cpp:100] Creating Layer relu_u3d
I0428 15:09:13.033990  5145 net.cpp:434] relu_u3d <- u3d
I0428 15:09:13.033994  5145 net.cpp:395] relu_u3d -> u3d (in-place)
I0428 15:09:13.034904  5145 net.cpp:150] Setting up relu_u3d
I0428 15:09:13.034917  5145 net.cpp:157] Top shape: 2 512 34 34 (1183744)
I0428 15:09:13.034922  5145 net.cpp:165] Memory required for data: 1834651264
I0428 15:09:13.034925  5145 layer_factory.hpp:77] Creating layer upconv_u3d_u2a
I0428 15:09:13.034960  5145 net.cpp:100] Creating Layer upconv_u3d_u2a
I0428 15:09:13.034963  5145 net.cpp:434] upconv_u3d_u2a <- u3d
I0428 15:09:13.034970  5145 net.cpp:408] upconv_u3d_u2a -> u2a
I0428 15:09:13.038831  5145 net.cpp:150] Setting up upconv_u3d_u2a
I0428 15:09:13.038844  5145 net.cpp:157] Top shape: 2 256 68 68 (2367488)
I0428 15:09:13.038847  5145 net.cpp:165] Memory required for data: 1844121216
I0428 15:09:13.038853  5145 layer_factory.hpp:77] Creating layer bn_u2a
I0428 15:09:13.038861  5145 net.cpp:100] Creating Layer bn_u2a
I0428 15:09:13.038863  5145 net.cpp:434] bn_u2a <- u2a
I0428 15:09:13.038868  5145 net.cpp:395] bn_u2a -> u2a (in-place)
I0428 15:09:13.039077  5145 net.cpp:150] Setting up bn_u2a
I0428 15:09:13.039085  5145 net.cpp:157] Top shape: 2 256 68 68 (2367488)
I0428 15:09:13.039088  5145 net.cpp:165] Memory required for data: 1853591168
I0428 15:09:13.039094  5145 layer_factory.hpp:77] Creating layer sc_u2a
I0428 15:09:13.039119  5145 net.cpp:100] Creating Layer sc_u2a
I0428 15:09:13.039120  5145 net.cpp:434] sc_u2a <- u2a
I0428 15:09:13.039124  5145 net.cpp:395] sc_u2a -> u2a (in-place)
I0428 15:09:13.039161  5145 layer_factory.hpp:77] Creating layer sc_u2a
I0428 15:09:13.039283  5145 net.cpp:150] Setting up sc_u2a
I0428 15:09:13.039290  5145 net.cpp:157] Top shape: 2 256 68 68 (2367488)
I0428 15:09:13.039293  5145 net.cpp:165] Memory required for data: 1863061120
I0428 15:09:13.039297  5145 layer_factory.hpp:77] Creating layer relu_u2a
I0428 15:09:13.039302  5145 net.cpp:100] Creating Layer relu_u2a
I0428 15:09:13.039305  5145 net.cpp:434] relu_u2a <- u2a
I0428 15:09:13.039309  5145 net.cpp:395] relu_u2a -> u2a (in-place)
I0428 15:09:13.039515  5145 net.cpp:150] Setting up relu_u2a
I0428 15:09:13.039523  5145 net.cpp:157] Top shape: 2 256 68 68 (2367488)
I0428 15:09:13.039526  5145 net.cpp:165] Memory required for data: 1872531072
I0428 15:09:13.039530  5145 layer_factory.hpp:77] Creating layer u2a_relu_u2a_0_split
I0428 15:09:13.039533  5145 net.cpp:100] Creating Layer u2a_relu_u2a_0_split
I0428 15:09:13.039536  5145 net.cpp:434] u2a_relu_u2a_0_split <- u2a
I0428 15:09:13.039543  5145 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_0
I0428 15:09:13.039549  5145 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_1
I0428 15:09:13.039588  5145 net.cpp:150] Setting up u2a_relu_u2a_0_split
I0428 15:09:13.039593  5145 net.cpp:157] Top shape: 2 256 68 68 (2367488)
I0428 15:09:13.039597  5145 net.cpp:157] Top shape: 2 256 68 68 (2367488)
I0428 15:09:13.039598  5145 net.cpp:165] Memory required for data: 1891470976
I0428 15:09:13.039600  5145 layer_factory.hpp:77] Creating layer crop_d2c-d2cc
I0428 15:09:13.039607  5145 net.cpp:100] Creating Layer crop_d2c-d2cc
I0428 15:09:13.039610  5145 net.cpp:434] crop_d2c-d2cc <- d2c_relu_d2c_0_split_1
I0428 15:09:13.039613  5145 net.cpp:434] crop_d2c-d2cc <- u2a_relu_u2a_0_split_0
I0428 15:09:13.039618  5145 net.cpp:408] crop_d2c-d2cc -> d2cc
I0428 15:09:13.039669  5145 net.cpp:150] Setting up crop_d2c-d2cc
I0428 15:09:13.039674  5145 net.cpp:157] Top shape: 2 256 68 68 (2367488)
I0428 15:09:13.039675  5145 net.cpp:165] Memory required for data: 1900940928
I0428 15:09:13.039677  5145 layer_factory.hpp:77] Creating layer concat_d2cc_u2a-b
I0428 15:09:13.039683  5145 net.cpp:100] Creating Layer concat_d2cc_u2a-b
I0428 15:09:13.039685  5145 net.cpp:434] concat_d2cc_u2a-b <- u2a_relu_u2a_0_split_1
I0428 15:09:13.039688  5145 net.cpp:434] concat_d2cc_u2a-b <- d2cc
I0428 15:09:13.039693  5145 net.cpp:408] concat_d2cc_u2a-b -> u2b
I0428 15:09:13.039713  5145 net.cpp:150] Setting up concat_d2cc_u2a-b
I0428 15:09:13.039717  5145 net.cpp:157] Top shape: 2 512 68 68 (4734976)
I0428 15:09:13.039719  5145 net.cpp:165] Memory required for data: 1919880832
I0428 15:09:13.039721  5145 layer_factory.hpp:77] Creating layer conv_u2b-c
I0428 15:09:13.039731  5145 net.cpp:100] Creating Layer conv_u2b-c
I0428 15:09:13.039733  5145 net.cpp:434] conv_u2b-c <- u2b
I0428 15:09:13.039738  5145 net.cpp:408] conv_u2b-c -> u2c
I0428 15:09:13.047582  5145 net.cpp:150] Setting up conv_u2b-c
I0428 15:09:13.047596  5145 net.cpp:157] Top shape: 2 256 66 66 (2230272)
I0428 15:09:13.047600  5145 net.cpp:165] Memory required for data: 1928801920
I0428 15:09:13.047605  5145 layer_factory.hpp:77] Creating layer bn_u2c
I0428 15:09:13.047610  5145 net.cpp:100] Creating Layer bn_u2c
I0428 15:09:13.047613  5145 net.cpp:434] bn_u2c <- u2c
I0428 15:09:13.047617  5145 net.cpp:395] bn_u2c -> u2c (in-place)
I0428 15:09:13.047804  5145 net.cpp:150] Setting up bn_u2c
I0428 15:09:13.047811  5145 net.cpp:157] Top shape: 2 256 66 66 (2230272)
I0428 15:09:13.047814  5145 net.cpp:165] Memory required for data: 1937723008
I0428 15:09:13.047821  5145 layer_factory.hpp:77] Creating layer sc_u2c
I0428 15:09:13.047825  5145 net.cpp:100] Creating Layer sc_u2c
I0428 15:09:13.047827  5145 net.cpp:434] sc_u2c <- u2c
I0428 15:09:13.047832  5145 net.cpp:395] sc_u2c -> u2c (in-place)
I0428 15:09:13.047868  5145 layer_factory.hpp:77] Creating layer sc_u2c
I0428 15:09:13.047987  5145 net.cpp:150] Setting up sc_u2c
I0428 15:09:13.047994  5145 net.cpp:157] Top shape: 2 256 66 66 (2230272)
I0428 15:09:13.047997  5145 net.cpp:165] Memory required for data: 1946644096
I0428 15:09:13.048002  5145 layer_factory.hpp:77] Creating layer relu_u2c
I0428 15:09:13.048007  5145 net.cpp:100] Creating Layer relu_u2c
I0428 15:09:13.048008  5145 net.cpp:434] relu_u2c <- u2c
I0428 15:09:13.048013  5145 net.cpp:395] relu_u2c -> u2c (in-place)
I0428 15:09:13.048195  5145 net.cpp:150] Setting up relu_u2c
I0428 15:09:13.048204  5145 net.cpp:157] Top shape: 2 256 66 66 (2230272)
I0428 15:09:13.048207  5145 net.cpp:165] Memory required for data: 1955565184
I0428 15:09:13.048210  5145 layer_factory.hpp:77] Creating layer conv_u2c-d
I0428 15:09:13.048218  5145 net.cpp:100] Creating Layer conv_u2c-d
I0428 15:09:13.048221  5145 net.cpp:434] conv_u2c-d <- u2c
I0428 15:09:13.048241  5145 net.cpp:408] conv_u2c-d -> u2d
I0428 15:09:13.052510  5145 net.cpp:150] Setting up conv_u2c-d
I0428 15:09:13.052523  5145 net.cpp:157] Top shape: 2 256 64 64 (2097152)
I0428 15:09:13.052525  5145 net.cpp:165] Memory required for data: 1963953792
I0428 15:09:13.052546  5145 layer_factory.hpp:77] Creating layer bn_u2d
I0428 15:09:13.052554  5145 net.cpp:100] Creating Layer bn_u2d
I0428 15:09:13.052556  5145 net.cpp:434] bn_u2d <- u2d
I0428 15:09:13.052563  5145 net.cpp:395] bn_u2d -> u2d (in-place)
I0428 15:09:13.052773  5145 net.cpp:150] Setting up bn_u2d
I0428 15:09:13.052781  5145 net.cpp:157] Top shape: 2 256 64 64 (2097152)
I0428 15:09:13.052784  5145 net.cpp:165] Memory required for data: 1972342400
I0428 15:09:13.052790  5145 layer_factory.hpp:77] Creating layer sc_u2d
I0428 15:09:13.052795  5145 net.cpp:100] Creating Layer sc_u2d
I0428 15:09:13.052798  5145 net.cpp:434] sc_u2d <- u2d
I0428 15:09:13.052803  5145 net.cpp:395] sc_u2d -> u2d (in-place)
I0428 15:09:13.052840  5145 layer_factory.hpp:77] Creating layer sc_u2d
I0428 15:09:13.052944  5145 net.cpp:150] Setting up sc_u2d
I0428 15:09:13.052963  5145 net.cpp:157] Top shape: 2 256 64 64 (2097152)
I0428 15:09:13.052965  5145 net.cpp:165] Memory required for data: 1980731008
I0428 15:09:13.052970  5145 layer_factory.hpp:77] Creating layer relu_u2d
I0428 15:09:13.052975  5145 net.cpp:100] Creating Layer relu_u2d
I0428 15:09:13.052978  5145 net.cpp:434] relu_u2d <- u2d
I0428 15:09:13.052983  5145 net.cpp:395] relu_u2d -> u2d (in-place)
I0428 15:09:13.053186  5145 net.cpp:150] Setting up relu_u2d
I0428 15:09:13.053196  5145 net.cpp:157] Top shape: 2 256 64 64 (2097152)
I0428 15:09:13.053200  5145 net.cpp:165] Memory required for data: 1989119616
I0428 15:09:13.053201  5145 layer_factory.hpp:77] Creating layer upconv_u2d_u1a
I0428 15:09:13.053208  5145 net.cpp:100] Creating Layer upconv_u2d_u1a
I0428 15:09:13.053211  5145 net.cpp:434] upconv_u2d_u1a <- u2d
I0428 15:09:13.053218  5145 net.cpp:408] upconv_u2d_u1a -> u1a
I0428 15:09:13.054237  5145 net.cpp:150] Setting up upconv_u2d_u1a
I0428 15:09:13.054246  5145 net.cpp:157] Top shape: 2 128 128 128 (4194304)
I0428 15:09:13.054250  5145 net.cpp:165] Memory required for data: 2005896832
I0428 15:09:13.054255  5145 layer_factory.hpp:77] Creating layer bn_u1a
I0428 15:09:13.054260  5145 net.cpp:100] Creating Layer bn_u1a
I0428 15:09:13.054262  5145 net.cpp:434] bn_u1a <- u1a
I0428 15:09:13.054267  5145 net.cpp:395] bn_u1a -> u1a (in-place)
I0428 15:09:13.054455  5145 net.cpp:150] Setting up bn_u1a
I0428 15:09:13.054463  5145 net.cpp:157] Top shape: 2 128 128 128 (4194304)
I0428 15:09:13.054466  5145 net.cpp:165] Memory required for data: 2022674048
I0428 15:09:13.054471  5145 layer_factory.hpp:77] Creating layer sc_u1a
I0428 15:09:13.054477  5145 net.cpp:100] Creating Layer sc_u1a
I0428 15:09:13.054479  5145 net.cpp:434] sc_u1a <- u1a
I0428 15:09:13.054483  5145 net.cpp:395] sc_u1a -> u1a (in-place)
I0428 15:09:13.054538  5145 layer_factory.hpp:77] Creating layer sc_u1a
I0428 15:09:13.054664  5145 net.cpp:150] Setting up sc_u1a
I0428 15:09:13.054672  5145 net.cpp:157] Top shape: 2 128 128 128 (4194304)
I0428 15:09:13.054674  5145 net.cpp:165] Memory required for data: 2039451264
I0428 15:09:13.054679  5145 layer_factory.hpp:77] Creating layer relu_u1a
I0428 15:09:13.054684  5145 net.cpp:100] Creating Layer relu_u1a
I0428 15:09:13.054687  5145 net.cpp:434] relu_u1a <- u1a
I0428 15:09:13.054692  5145 net.cpp:395] relu_u1a -> u1a (in-place)
I0428 15:09:13.055467  5145 net.cpp:150] Setting up relu_u1a
I0428 15:09:13.055496  5145 net.cpp:157] Top shape: 2 128 128 128 (4194304)
I0428 15:09:13.055498  5145 net.cpp:165] Memory required for data: 2056228480
I0428 15:09:13.055501  5145 layer_factory.hpp:77] Creating layer u1a_relu_u1a_0_split
I0428 15:09:13.055510  5145 net.cpp:100] Creating Layer u1a_relu_u1a_0_split
I0428 15:09:13.055513  5145 net.cpp:434] u1a_relu_u1a_0_split <- u1a
I0428 15:09:13.055518  5145 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_0
I0428 15:09:13.055524  5145 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_1
I0428 15:09:13.055567  5145 net.cpp:150] Setting up u1a_relu_u1a_0_split
I0428 15:09:13.055575  5145 net.cpp:157] Top shape: 2 128 128 128 (4194304)
I0428 15:09:13.055578  5145 net.cpp:157] Top shape: 2 128 128 128 (4194304)
I0428 15:09:13.055580  5145 net.cpp:165] Memory required for data: 2089782912
I0428 15:09:13.055583  5145 layer_factory.hpp:77] Creating layer crop_d1c-d1cc
I0428 15:09:13.055588  5145 net.cpp:100] Creating Layer crop_d1c-d1cc
I0428 15:09:13.055591  5145 net.cpp:434] crop_d1c-d1cc <- d1c_relu_d1c_0_split_1
I0428 15:09:13.055594  5145 net.cpp:434] crop_d1c-d1cc <- u1a_relu_u1a_0_split_0
I0428 15:09:13.055599  5145 net.cpp:408] crop_d1c-d1cc -> d1cc
I0428 15:09:13.055624  5145 net.cpp:150] Setting up crop_d1c-d1cc
I0428 15:09:13.055627  5145 net.cpp:157] Top shape: 2 128 128 128 (4194304)
I0428 15:09:13.055629  5145 net.cpp:165] Memory required for data: 2106560128
I0428 15:09:13.055631  5145 layer_factory.hpp:77] Creating layer concat_d1cc_u1a-b
I0428 15:09:13.055636  5145 net.cpp:100] Creating Layer concat_d1cc_u1a-b
I0428 15:09:13.055639  5145 net.cpp:434] concat_d1cc_u1a-b <- u1a_relu_u1a_0_split_1
I0428 15:09:13.055652  5145 net.cpp:434] concat_d1cc_u1a-b <- d1cc
I0428 15:09:13.055658  5145 net.cpp:408] concat_d1cc_u1a-b -> u1b
I0428 15:09:13.055681  5145 net.cpp:150] Setting up concat_d1cc_u1a-b
I0428 15:09:13.055686  5145 net.cpp:157] Top shape: 2 256 128 128 (8388608)
I0428 15:09:13.055688  5145 net.cpp:165] Memory required for data: 2140114560
I0428 15:09:13.055691  5145 layer_factory.hpp:77] Creating layer conv_u1b-c
I0428 15:09:13.055698  5145 net.cpp:100] Creating Layer conv_u1b-c
I0428 15:09:13.055701  5145 net.cpp:434] conv_u1b-c <- u1b
I0428 15:09:13.055706  5145 net.cpp:408] conv_u1b-c -> u1c
I0428 15:09:13.058487  5145 net.cpp:150] Setting up conv_u1b-c
I0428 15:09:13.058501  5145 net.cpp:157] Top shape: 2 128 126 126 (4064256)
I0428 15:09:13.058503  5145 net.cpp:165] Memory required for data: 2156371584
I0428 15:09:13.058509  5145 layer_factory.hpp:77] Creating layer bn_u1c
I0428 15:09:13.058516  5145 net.cpp:100] Creating Layer bn_u1c
I0428 15:09:13.058521  5145 net.cpp:434] bn_u1c <- u1c
I0428 15:09:13.058526  5145 net.cpp:395] bn_u1c -> u1c (in-place)
I0428 15:09:13.058758  5145 net.cpp:150] Setting up bn_u1c
I0428 15:09:13.058765  5145 net.cpp:157] Top shape: 2 128 126 126 (4064256)
I0428 15:09:13.058768  5145 net.cpp:165] Memory required for data: 2172628608
I0428 15:09:13.058774  5145 layer_factory.hpp:77] Creating layer sc_u1c
I0428 15:09:13.058780  5145 net.cpp:100] Creating Layer sc_u1c
I0428 15:09:13.058784  5145 net.cpp:434] sc_u1c <- u1c
I0428 15:09:13.058789  5145 net.cpp:395] sc_u1c -> u1c (in-place)
I0428 15:09:13.058825  5145 layer_factory.hpp:77] Creating layer sc_u1c
I0428 15:09:13.058964  5145 net.cpp:150] Setting up sc_u1c
I0428 15:09:13.058971  5145 net.cpp:157] Top shape: 2 128 126 126 (4064256)
I0428 15:09:13.058975  5145 net.cpp:165] Memory required for data: 2188885632
I0428 15:09:13.058979  5145 layer_factory.hpp:77] Creating layer relu_u1c
I0428 15:09:13.058985  5145 net.cpp:100] Creating Layer relu_u1c
I0428 15:09:13.058987  5145 net.cpp:434] relu_u1c <- u1c
I0428 15:09:13.058995  5145 net.cpp:395] relu_u1c -> u1c (in-place)
I0428 15:09:13.059187  5145 net.cpp:150] Setting up relu_u1c
I0428 15:09:13.059197  5145 net.cpp:157] Top shape: 2 128 126 126 (4064256)
I0428 15:09:13.059200  5145 net.cpp:165] Memory required for data: 2205142656
I0428 15:09:13.059202  5145 layer_factory.hpp:77] Creating layer conv_u1c-d
I0428 15:09:13.059211  5145 net.cpp:100] Creating Layer conv_u1c-d
I0428 15:09:13.059213  5145 net.cpp:434] conv_u1c-d <- u1c
I0428 15:09:13.059219  5145 net.cpp:408] conv_u1c-d -> u1d
I0428 15:09:13.060330  5145 net.cpp:150] Setting up conv_u1c-d
I0428 15:09:13.060338  5145 net.cpp:157] Top shape: 2 128 124 124 (3936256)
I0428 15:09:13.060340  5145 net.cpp:165] Memory required for data: 2220887680
I0428 15:09:13.060345  5145 layer_factory.hpp:77] Creating layer bn_u1d
I0428 15:09:13.060353  5145 net.cpp:100] Creating Layer bn_u1d
I0428 15:09:13.060355  5145 net.cpp:434] bn_u1d <- u1d
I0428 15:09:13.060359  5145 net.cpp:395] bn_u1d -> u1d (in-place)
I0428 15:09:13.060564  5145 net.cpp:150] Setting up bn_u1d
I0428 15:09:13.060572  5145 net.cpp:157] Top shape: 2 128 124 124 (3936256)
I0428 15:09:13.060575  5145 net.cpp:165] Memory required for data: 2236632704
I0428 15:09:13.060595  5145 layer_factory.hpp:77] Creating layer sc_u1d
I0428 15:09:13.060605  5145 net.cpp:100] Creating Layer sc_u1d
I0428 15:09:13.060608  5145 net.cpp:434] sc_u1d <- u1d
I0428 15:09:13.060613  5145 net.cpp:395] sc_u1d -> u1d (in-place)
I0428 15:09:13.060652  5145 layer_factory.hpp:77] Creating layer sc_u1d
I0428 15:09:13.060778  5145 net.cpp:150] Setting up sc_u1d
I0428 15:09:13.060786  5145 net.cpp:157] Top shape: 2 128 124 124 (3936256)
I0428 15:09:13.060788  5145 net.cpp:165] Memory required for data: 2252377728
I0428 15:09:13.060793  5145 layer_factory.hpp:77] Creating layer relu_u1d
I0428 15:09:13.060797  5145 net.cpp:100] Creating Layer relu_u1d
I0428 15:09:13.060801  5145 net.cpp:434] relu_u1d <- u1d
I0428 15:09:13.060806  5145 net.cpp:395] relu_u1d -> u1d (in-place)
I0428 15:09:13.061015  5145 net.cpp:150] Setting up relu_u1d
I0428 15:09:13.061025  5145 net.cpp:157] Top shape: 2 128 124 124 (3936256)
I0428 15:09:13.061028  5145 net.cpp:165] Memory required for data: 2268122752
I0428 15:09:13.061031  5145 layer_factory.hpp:77] Creating layer upconv_u1d_u0a
I0428 15:09:13.061038  5145 net.cpp:100] Creating Layer upconv_u1d_u0a
I0428 15:09:13.061041  5145 net.cpp:434] upconv_u1d_u0a <- u1d
I0428 15:09:13.061048  5145 net.cpp:408] upconv_u1d_u0a -> u0a
I0428 15:09:13.061738  5145 net.cpp:150] Setting up upconv_u1d_u0a
I0428 15:09:13.061746  5145 net.cpp:157] Top shape: 2 128 248 248 (15745024)
I0428 15:09:13.061749  5145 net.cpp:165] Memory required for data: 2331102848
I0428 15:09:13.061754  5145 layer_factory.hpp:77] Creating layer bn_u0a
I0428 15:09:13.061759  5145 net.cpp:100] Creating Layer bn_u0a
I0428 15:09:13.061763  5145 net.cpp:434] bn_u0a <- u0a
I0428 15:09:13.061766  5145 net.cpp:395] bn_u0a -> u0a (in-place)
I0428 15:09:13.062836  5145 net.cpp:150] Setting up bn_u0a
I0428 15:09:13.062849  5145 net.cpp:157] Top shape: 2 128 248 248 (15745024)
I0428 15:09:13.062851  5145 net.cpp:165] Memory required for data: 2394082944
I0428 15:09:13.062860  5145 layer_factory.hpp:77] Creating layer sc_u0a
I0428 15:09:13.062865  5145 net.cpp:100] Creating Layer sc_u0a
I0428 15:09:13.062868  5145 net.cpp:434] sc_u0a <- u0a
I0428 15:09:13.062875  5145 net.cpp:395] sc_u0a -> u0a (in-place)
I0428 15:09:13.062916  5145 layer_factory.hpp:77] Creating layer sc_u0a
I0428 15:09:13.063122  5145 net.cpp:150] Setting up sc_u0a
I0428 15:09:13.063130  5145 net.cpp:157] Top shape: 2 128 248 248 (15745024)
I0428 15:09:13.063133  5145 net.cpp:165] Memory required for data: 2457063040
I0428 15:09:13.063138  5145 layer_factory.hpp:77] Creating layer relu_u0a
I0428 15:09:13.063144  5145 net.cpp:100] Creating Layer relu_u0a
I0428 15:09:13.063146  5145 net.cpp:434] relu_u0a <- u0a
I0428 15:09:13.063150  5145 net.cpp:395] relu_u0a -> u0a (in-place)
I0428 15:09:13.063338  5145 net.cpp:150] Setting up relu_u0a
I0428 15:09:13.063349  5145 net.cpp:157] Top shape: 2 128 248 248 (15745024)
I0428 15:09:13.063351  5145 net.cpp:165] Memory required for data: 2520043136
I0428 15:09:13.063354  5145 layer_factory.hpp:77] Creating layer u0a_relu_u0a_0_split
I0428 15:09:13.063359  5145 net.cpp:100] Creating Layer u0a_relu_u0a_0_split
I0428 15:09:13.063362  5145 net.cpp:434] u0a_relu_u0a_0_split <- u0a
I0428 15:09:13.063366  5145 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_0
I0428 15:09:13.063374  5145 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_1
I0428 15:09:13.063416  5145 net.cpp:150] Setting up u0a_relu_u0a_0_split
I0428 15:09:13.063424  5145 net.cpp:157] Top shape: 2 128 248 248 (15745024)
I0428 15:09:13.063427  5145 net.cpp:157] Top shape: 2 128 248 248 (15745024)
I0428 15:09:13.063429  5145 net.cpp:165] Memory required for data: 2646003328
I0428 15:09:13.063432  5145 layer_factory.hpp:77] Creating layer crop_d0c-d0cc
I0428 15:09:13.063439  5145 net.cpp:100] Creating Layer crop_d0c-d0cc
I0428 15:09:13.063442  5145 net.cpp:434] crop_d0c-d0cc <- d0c_relu_d0c_0_split_1
I0428 15:09:13.063460  5145 net.cpp:434] crop_d0c-d0cc <- u0a_relu_u0a_0_split_0
I0428 15:09:13.063464  5145 net.cpp:408] crop_d0c-d0cc -> d0cc
I0428 15:09:13.063488  5145 net.cpp:150] Setting up crop_d0c-d0cc
I0428 15:09:13.063493  5145 net.cpp:157] Top shape: 2 64 248 248 (7872512)
I0428 15:09:13.063494  5145 net.cpp:165] Memory required for data: 2677493376
I0428 15:09:13.063496  5145 layer_factory.hpp:77] Creating layer concat_d0cc_u0a-b
I0428 15:09:13.063501  5145 net.cpp:100] Creating Layer concat_d0cc_u0a-b
I0428 15:09:13.063503  5145 net.cpp:434] concat_d0cc_u0a-b <- u0a_relu_u0a_0_split_1
I0428 15:09:13.063506  5145 net.cpp:434] concat_d0cc_u0a-b <- d0cc
I0428 15:09:13.063513  5145 net.cpp:408] concat_d0cc_u0a-b -> u0b
I0428 15:09:13.063534  5145 net.cpp:150] Setting up concat_d0cc_u0a-b
I0428 15:09:13.063539  5145 net.cpp:157] Top shape: 2 192 248 248 (23617536)
I0428 15:09:13.063550  5145 net.cpp:165] Memory required for data: 2771963520
I0428 15:09:13.063554  5145 layer_factory.hpp:77] Creating layer conv_u0b-c
I0428 15:09:13.063562  5145 net.cpp:100] Creating Layer conv_u0b-c
I0428 15:09:13.063565  5145 net.cpp:434] conv_u0b-c <- u0b
I0428 15:09:13.063570  5145 net.cpp:408] conv_u0b-c -> u0c
I0428 15:09:13.064527  5145 net.cpp:150] Setting up conv_u0b-c
I0428 15:09:13.064537  5145 net.cpp:157] Top shape: 2 64 246 246 (7746048)
I0428 15:09:13.064538  5145 net.cpp:165] Memory required for data: 2802947712
I0428 15:09:13.064543  5145 layer_factory.hpp:77] Creating layer bn_u0c
I0428 15:09:13.064550  5145 net.cpp:100] Creating Layer bn_u0c
I0428 15:09:13.064553  5145 net.cpp:434] bn_u0c <- u0c
I0428 15:09:13.064559  5145 net.cpp:395] bn_u0c -> u0c (in-place)
I0428 15:09:13.064810  5145 net.cpp:150] Setting up bn_u0c
I0428 15:09:13.064820  5145 net.cpp:157] Top shape: 2 64 246 246 (7746048)
I0428 15:09:13.064823  5145 net.cpp:165] Memory required for data: 2833931904
I0428 15:09:13.064829  5145 layer_factory.hpp:77] Creating layer sc_u0c
I0428 15:09:13.064833  5145 net.cpp:100] Creating Layer sc_u0c
I0428 15:09:13.064836  5145 net.cpp:434] sc_u0c <- u0c
I0428 15:09:13.064841  5145 net.cpp:395] sc_u0c -> u0c (in-place)
I0428 15:09:13.064879  5145 layer_factory.hpp:77] Creating layer sc_u0c
I0428 15:09:13.065071  5145 net.cpp:150] Setting up sc_u0c
I0428 15:09:13.065078  5145 net.cpp:157] Top shape: 2 64 246 246 (7746048)
I0428 15:09:13.065081  5145 net.cpp:165] Memory required for data: 2864916096
I0428 15:09:13.065086  5145 layer_factory.hpp:77] Creating layer relu_u0c
I0428 15:09:13.065093  5145 net.cpp:100] Creating Layer relu_u0c
I0428 15:09:13.065094  5145 net.cpp:434] relu_u0c <- u0c
I0428 15:09:13.065099  5145 net.cpp:395] relu_u0c -> u0c (in-place)
I0428 15:09:13.065867  5145 net.cpp:150] Setting up relu_u0c
I0428 15:09:13.065881  5145 net.cpp:157] Top shape: 2 64 246 246 (7746048)
I0428 15:09:13.065883  5145 net.cpp:165] Memory required for data: 2895900288
I0428 15:09:13.065887  5145 layer_factory.hpp:77] Creating layer conv_u0c-d
I0428 15:09:13.065896  5145 net.cpp:100] Creating Layer conv_u0c-d
I0428 15:09:13.065899  5145 net.cpp:434] conv_u0c-d <- u0c
I0428 15:09:13.065906  5145 net.cpp:408] conv_u0c-d -> u0d
I0428 15:09:13.066445  5145 net.cpp:150] Setting up conv_u0c-d
I0428 15:09:13.066454  5145 net.cpp:157] Top shape: 2 64 244 244 (7620608)
I0428 15:09:13.066457  5145 net.cpp:165] Memory required for data: 2926382720
I0428 15:09:13.066462  5145 layer_factory.hpp:77] Creating layer bn_u0d
I0428 15:09:13.066468  5145 net.cpp:100] Creating Layer bn_u0d
I0428 15:09:13.066469  5145 net.cpp:434] bn_u0d <- u0d
I0428 15:09:13.066474  5145 net.cpp:395] bn_u0d -> u0d (in-place)
I0428 15:09:13.067492  5145 net.cpp:150] Setting up bn_u0d
I0428 15:09:13.067505  5145 net.cpp:157] Top shape: 2 64 244 244 (7620608)
I0428 15:09:13.067507  5145 net.cpp:165] Memory required for data: 2956865152
I0428 15:09:13.067514  5145 layer_factory.hpp:77] Creating layer sc_u0d
I0428 15:09:13.067520  5145 net.cpp:100] Creating Layer sc_u0d
I0428 15:09:13.067524  5145 net.cpp:434] sc_u0d <- u0d
I0428 15:09:13.067529  5145 net.cpp:395] sc_u0d -> u0d (in-place)
I0428 15:09:13.067572  5145 layer_factory.hpp:77] Creating layer sc_u0d
I0428 15:09:13.067761  5145 net.cpp:150] Setting up sc_u0d
I0428 15:09:13.067770  5145 net.cpp:157] Top shape: 2 64 244 244 (7620608)
I0428 15:09:13.067772  5145 net.cpp:165] Memory required for data: 2987347584
I0428 15:09:13.067776  5145 layer_factory.hpp:77] Creating layer relu_u0d
I0428 15:09:13.067782  5145 net.cpp:100] Creating Layer relu_u0d
I0428 15:09:13.067785  5145 net.cpp:434] relu_u0d <- u0d
I0428 15:09:13.067790  5145 net.cpp:395] relu_u0d -> u0d (in-place)
I0428 15:09:13.067961  5145 net.cpp:150] Setting up relu_u0d
I0428 15:09:13.067970  5145 net.cpp:157] Top shape: 2 64 244 244 (7620608)
I0428 15:09:13.067973  5145 net.cpp:165] Memory required for data: 3017830016
I0428 15:09:13.067976  5145 layer_factory.hpp:77] Creating layer conv_u0d-score
I0428 15:09:13.067983  5145 net.cpp:100] Creating Layer conv_u0d-score
I0428 15:09:13.067996  5145 net.cpp:434] conv_u0d-score <- u0d
I0428 15:09:13.068004  5145 net.cpp:408] conv_u0d-score -> score
I0428 15:09:13.068274  5145 net.cpp:150] Setting up conv_u0d-score
I0428 15:09:13.068282  5145 net.cpp:157] Top shape: 2 4 244 244 (476288)
I0428 15:09:13.068285  5145 net.cpp:165] Memory required for data: 3019735168
I0428 15:09:13.068290  5145 layer_factory.hpp:77] Creating layer score_conv_u0d-score_0_split
I0428 15:09:13.068295  5145 net.cpp:100] Creating Layer score_conv_u0d-score_0_split
I0428 15:09:13.068297  5145 net.cpp:434] score_conv_u0d-score_0_split <- score
I0428 15:09:13.068303  5145 net.cpp:408] score_conv_u0d-score_0_split -> score_conv_u0d-score_0_split_0
I0428 15:09:13.068310  5145 net.cpp:408] score_conv_u0d-score_0_split -> score_conv_u0d-score_0_split_1
I0428 15:09:13.068347  5145 net.cpp:150] Setting up score_conv_u0d-score_0_split
I0428 15:09:13.068353  5145 net.cpp:157] Top shape: 2 4 244 244 (476288)
I0428 15:09:13.068357  5145 net.cpp:157] Top shape: 2 4 244 244 (476288)
I0428 15:09:13.068359  5145 net.cpp:165] Memory required for data: 3023545472
I0428 15:09:13.068361  5145 layer_factory.hpp:77] Creating layer loss
I0428 15:09:13.068367  5145 net.cpp:100] Creating Layer loss
I0428 15:09:13.068369  5145 net.cpp:434] loss <- score_conv_u0d-score_0_split_0
I0428 15:09:13.068373  5145 net.cpp:434] loss <- label
I0428 15:09:13.068377  5145 net.cpp:434] loss <- weights
I0428 15:09:13.068380  5145 net.cpp:408] loss -> loss
I0428 15:09:13.068387  5145 layer_factory.hpp:77] Creating layer loss
I0428 15:09:13.071249  5145 net.cpp:150] Setting up loss
I0428 15:09:13.071264  5145 net.cpp:157] Top shape: (1)
I0428 15:09:13.071267  5145 net.cpp:160]     with loss weight 1
I0428 15:09:13.071276  5145 net.cpp:165] Memory required for data: 3023545476
I0428 15:09:13.071280  5145 layer_factory.hpp:77] Creating layer visualize
I0428 15:09:13.071286  5145 net.cpp:100] Creating Layer visualize
I0428 15:09:13.071291  5145 net.cpp:434] visualize <- score_conv_u0d-score_0_split_1
I0428 15:09:13.071296  5145 net.cpp:408] visualize -> visualize_out
I0428 15:09:13.072079  5145 net.cpp:150] Setting up visualize
I0428 15:09:13.072093  5145 net.cpp:157] Top shape: 2 4 244 244 (476288)
I0428 15:09:13.072096  5145 net.cpp:165] Memory required for data: 3025450628
I0428 15:09:13.072098  5145 layer_factory.hpp:77] Creating layer fake
I0428 15:09:13.072105  5145 net.cpp:100] Creating Layer fake
I0428 15:09:13.072108  5145 net.cpp:434] fake <- visualize_out
I0428 15:09:13.072113  5145 net.cpp:150] Setting up fake
I0428 15:09:13.072114  5145 net.cpp:165] Memory required for data: 3025450628
I0428 15:09:13.072118  5145 net.cpp:228] fake does not need backward computation.
I0428 15:09:13.072119  5145 net.cpp:228] visualize does not need backward computation.
I0428 15:09:13.072123  5145 net.cpp:226] loss needs backward computation.
I0428 15:09:13.072125  5145 net.cpp:226] score_conv_u0d-score_0_split needs backward computation.
I0428 15:09:13.072129  5145 net.cpp:226] conv_u0d-score needs backward computation.
I0428 15:09:13.072130  5145 net.cpp:226] relu_u0d needs backward computation.
I0428 15:09:13.072134  5145 net.cpp:226] sc_u0d needs backward computation.
I0428 15:09:13.072135  5145 net.cpp:226] bn_u0d needs backward computation.
I0428 15:09:13.072137  5145 net.cpp:226] conv_u0c-d needs backward computation.
I0428 15:09:13.072144  5145 net.cpp:226] relu_u0c needs backward computation.
I0428 15:09:13.072145  5145 net.cpp:226] sc_u0c needs backward computation.
I0428 15:09:13.072147  5145 net.cpp:226] bn_u0c needs backward computation.
I0428 15:09:13.072150  5145 net.cpp:226] conv_u0b-c needs backward computation.
I0428 15:09:13.072152  5145 net.cpp:226] concat_d0cc_u0a-b needs backward computation.
I0428 15:09:13.072154  5145 net.cpp:226] crop_d0c-d0cc needs backward computation.
I0428 15:09:13.072157  5145 net.cpp:226] u0a_relu_u0a_0_split needs backward computation.
I0428 15:09:13.072160  5145 net.cpp:226] relu_u0a needs backward computation.
I0428 15:09:13.072173  5145 net.cpp:226] sc_u0a needs backward computation.
I0428 15:09:13.072175  5145 net.cpp:226] bn_u0a needs backward computation.
I0428 15:09:13.072177  5145 net.cpp:226] upconv_u1d_u0a needs backward computation.
I0428 15:09:13.072180  5145 net.cpp:226] relu_u1d needs backward computation.
I0428 15:09:13.072182  5145 net.cpp:226] sc_u1d needs backward computation.
I0428 15:09:13.072185  5145 net.cpp:226] bn_u1d needs backward computation.
I0428 15:09:13.072186  5145 net.cpp:226] conv_u1c-d needs backward computation.
I0428 15:09:13.072190  5145 net.cpp:226] relu_u1c needs backward computation.
I0428 15:09:13.072191  5145 net.cpp:226] sc_u1c needs backward computation.
I0428 15:09:13.072193  5145 net.cpp:226] bn_u1c needs backward computation.
I0428 15:09:13.072196  5145 net.cpp:226] conv_u1b-c needs backward computation.
I0428 15:09:13.072198  5145 net.cpp:226] concat_d1cc_u1a-b needs backward computation.
I0428 15:09:13.072201  5145 net.cpp:226] crop_d1c-d1cc needs backward computation.
I0428 15:09:13.072203  5145 net.cpp:226] u1a_relu_u1a_0_split needs backward computation.
I0428 15:09:13.072206  5145 net.cpp:226] relu_u1a needs backward computation.
I0428 15:09:13.072208  5145 net.cpp:226] sc_u1a needs backward computation.
I0428 15:09:13.072211  5145 net.cpp:226] bn_u1a needs backward computation.
I0428 15:09:13.072212  5145 net.cpp:226] upconv_u2d_u1a needs backward computation.
I0428 15:09:13.072214  5145 net.cpp:226] relu_u2d needs backward computation.
I0428 15:09:13.072217  5145 net.cpp:226] sc_u2d needs backward computation.
I0428 15:09:13.072219  5145 net.cpp:226] bn_u2d needs backward computation.
I0428 15:09:13.072221  5145 net.cpp:226] conv_u2c-d needs backward computation.
I0428 15:09:13.072223  5145 net.cpp:226] relu_u2c needs backward computation.
I0428 15:09:13.072227  5145 net.cpp:226] sc_u2c needs backward computation.
I0428 15:09:13.072228  5145 net.cpp:226] bn_u2c needs backward computation.
I0428 15:09:13.072230  5145 net.cpp:226] conv_u2b-c needs backward computation.
I0428 15:09:13.072232  5145 net.cpp:226] concat_d2cc_u2a-b needs backward computation.
I0428 15:09:13.072235  5145 net.cpp:226] crop_d2c-d2cc needs backward computation.
I0428 15:09:13.072239  5145 net.cpp:226] u2a_relu_u2a_0_split needs backward computation.
I0428 15:09:13.072242  5145 net.cpp:226] relu_u2a needs backward computation.
I0428 15:09:13.072244  5145 net.cpp:226] sc_u2a needs backward computation.
I0428 15:09:13.072247  5145 net.cpp:226] bn_u2a needs backward computation.
I0428 15:09:13.072248  5145 net.cpp:226] upconv_u3d_u2a needs backward computation.
I0428 15:09:13.072252  5145 net.cpp:226] relu_u3d needs backward computation.
I0428 15:09:13.072253  5145 net.cpp:226] sc_u3d needs backward computation.
I0428 15:09:13.072255  5145 net.cpp:226] bn_u3d needs backward computation.
I0428 15:09:13.072257  5145 net.cpp:226] conv_u3c-d needs backward computation.
I0428 15:09:13.072259  5145 net.cpp:226] relu_u3c needs backward computation.
I0428 15:09:13.072263  5145 net.cpp:226] sc_u3c needs backward computation.
I0428 15:09:13.072264  5145 net.cpp:226] bn_u3c needs backward computation.
I0428 15:09:13.072266  5145 net.cpp:226] conv_u3b-c needs backward computation.
I0428 15:09:13.072269  5145 net.cpp:226] concat_d3cc_u3a-b needs backward computation.
I0428 15:09:13.072271  5145 net.cpp:226] crop_d3c-d3cc needs backward computation.
I0428 15:09:13.072275  5145 net.cpp:226] u3a_relu_u3a_0_split needs backward computation.
I0428 15:09:13.072278  5145 net.cpp:226] relu_u3a needs backward computation.
I0428 15:09:13.072279  5145 net.cpp:226] sc_u3a needs backward computation.
I0428 15:09:13.072281  5145 net.cpp:226] bn_u3a needs backward computation.
I0428 15:09:13.072284  5145 net.cpp:226] upconv_d4c_u3a needs backward computation.
I0428 15:09:13.072288  5145 net.cpp:226] relu_d4c needs backward computation.
I0428 15:09:13.072289  5145 net.cpp:226] sc_d4c needs backward computation.
I0428 15:09:13.072291  5145 net.cpp:226] bn_d4c needs backward computation.
I0428 15:09:13.072294  5145 net.cpp:226] conv_d4b-c needs backward computation.
I0428 15:09:13.072301  5145 net.cpp:226] relu_d4b needs backward computation.
I0428 15:09:13.072304  5145 net.cpp:226] sc_d4b needs backward computation.
I0428 15:09:13.072306  5145 net.cpp:226] bn_d4b needs backward computation.
I0428 15:09:13.072309  5145 net.cpp:226] conv_d4a-b needs backward computation.
I0428 15:09:13.072311  5145 net.cpp:226] pool_d3c-4a needs backward computation.
I0428 15:09:13.072314  5145 net.cpp:226] d3c_relu_d3c_0_split needs backward computation.
I0428 15:09:13.072316  5145 net.cpp:226] relu_d3c needs backward computation.
I0428 15:09:13.072319  5145 net.cpp:226] sc_d3c needs backward computation.
I0428 15:09:13.072321  5145 net.cpp:226] bn_d3c needs backward computation.
I0428 15:09:13.072324  5145 net.cpp:226] conv_d3b-c needs backward computation.
I0428 15:09:13.072325  5145 net.cpp:226] relu_d3b needs backward computation.
I0428 15:09:13.072329  5145 net.cpp:226] sc_d3b needs backward computation.
I0428 15:09:13.072331  5145 net.cpp:226] bn_d3b needs backward computation.
I0428 15:09:13.072334  5145 net.cpp:226] conv_d3a-b needs backward computation.
I0428 15:09:13.072335  5145 net.cpp:226] pool_d2c-3a needs backward computation.
I0428 15:09:13.072338  5145 net.cpp:226] d2c_relu_d2c_0_split needs backward computation.
I0428 15:09:13.072340  5145 net.cpp:226] relu_d2c needs backward computation.
I0428 15:09:13.072343  5145 net.cpp:226] sc_d2c needs backward computation.
I0428 15:09:13.072345  5145 net.cpp:226] bn_d2c needs backward computation.
I0428 15:09:13.072347  5145 net.cpp:226] conv_d2b-c needs backward computation.
I0428 15:09:13.072350  5145 net.cpp:226] relu_d2b needs backward computation.
I0428 15:09:13.072352  5145 net.cpp:226] sc_d2b needs backward computation.
I0428 15:09:13.072355  5145 net.cpp:226] bn_d2b needs backward computation.
I0428 15:09:13.072357  5145 net.cpp:226] conv_d2a-b needs backward computation.
I0428 15:09:13.072360  5145 net.cpp:226] pool_d1c-2a needs backward computation.
I0428 15:09:13.072362  5145 net.cpp:226] d1c_relu_d1c_0_split needs backward computation.
I0428 15:09:13.072365  5145 net.cpp:226] relu_d1c needs backward computation.
I0428 15:09:13.072367  5145 net.cpp:226] sc_d1c needs backward computation.
I0428 15:09:13.072369  5145 net.cpp:226] bn_d1c needs backward computation.
I0428 15:09:13.072371  5145 net.cpp:226] conv_d1b-c needs backward computation.
I0428 15:09:13.072373  5145 net.cpp:226] relu_d1b needs backward computation.
I0428 15:09:13.072376  5145 net.cpp:226] sc_d1b needs backward computation.
I0428 15:09:13.072378  5145 net.cpp:226] bn_d1b needs backward computation.
I0428 15:09:13.072381  5145 net.cpp:226] conv_d1a-b needs backward computation.
I0428 15:09:13.072384  5145 net.cpp:226] pool_d0c-1a needs backward computation.
I0428 15:09:13.072387  5145 net.cpp:226] d0c_relu_d0c_0_split needs backward computation.
I0428 15:09:13.072391  5145 net.cpp:226] relu_d0c needs backward computation.
I0428 15:09:13.072392  5145 net.cpp:226] sc_d0c needs backward computation.
I0428 15:09:13.072394  5145 net.cpp:226] bn_d0c needs backward computation.
I0428 15:09:13.072397  5145 net.cpp:226] conv_d0b-c needs backward computation.
I0428 15:09:13.072399  5145 net.cpp:226] relu_d0b needs backward computation.
I0428 15:09:13.072402  5145 net.cpp:226] sc_d0b needs backward computation.
I0428 15:09:13.072404  5145 net.cpp:226] bn_d0b needs backward computation.
I0428 15:09:13.072407  5145 net.cpp:226] conv_d0a-b needs backward computation.
I0428 15:09:13.072410  5145 net.cpp:228] loaddata does not need backward computation.
I0428 15:09:13.072420  5145 net.cpp:270] This network produces output loss
I0428 15:09:13.072479  5145 net.cpp:283] Network initialization done.
I0428 15:09:13.073317  5145 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./unet_weighted_batchnorm_4/unet_weighted_batchnorm_4.prototxt
I0428 15:09:13.073328  5145 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0428 15:09:13.073333  5145 solver.cpp:181] Creating test net (#0) specified by net file: ./unet_weighted_batchnorm_4/unet_weighted_batchnorm_4.prototxt
I0428 15:09:13.073416  5145 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer loaddata
I0428 15:09:13.073483  5145 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer visualize
I0428 15:09:13.073489  5145 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer fake
I0428 15:09:13.073967  5145 net.cpp:58] Initializing net from parameters: 
name: "unet_weighted_batchnorm_4"
force_backward: true
state {
  phase: TEST
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  top: "weights"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "caffeHDF5_validation_4.txt"
    batch_size: 1
  }
}
layer {
  name: "conv_d0a-b"
  type: "Convolution"
  bottom: "data"
  top: "d0b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d0b"
  type: "BatchNorm"
  bottom: "d0b"
  top: "d0b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d0b"
  type: "Scale"
  bottom: "d0b"
  top: "d0b"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d0b"
  type: "ReLU"
  bottom: "d0b"
  top: "d0b"
}
layer {
  name: "conv_d0b-c"
  type: "Convolution"
  bottom: "d0b"
  top: "d0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d0c"
  type: "BatchNorm"
  bottom: "d0c"
  top: "d0c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d0c"
  type: "Scale"
  bottom: "d0c"
  top: "d0c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d0c"
  type: "ReLU"
  bottom: "d0c"
  top: "d0c"
}
layer {
  name: "pool_d0c-1a"
  type: "Pooling"
  bottom: "d0c"
  top: "d1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d1a-b"
  type: "Convolution"
  bottom: "d1a"
  top: "d1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d1b"
  type: "BatchNorm"
  bottom: "d1b"
  top: "d1b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d1b"
  type: "Scale"
  bottom: "d1b"
  top: "d1b"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d1b"
  type: "ReLU"
  bottom: "d1b"
  top: "d1b"
}
layer {
  name: "conv_d1b-c"
  type: "Convolution"
  bottom: "d1b"
  top: "d1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d1c"
  type: "BatchNorm"
  bottom: "d1c"
  top: "d1c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d1c"
  type: "Scale"
  bottom: "d1c"
  top: "d1c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d1c"
  type: "ReLU"
  bottom: "d1c"
  top: "d1c"
}
layer {
  name: "pool_d1c-2a"
  type: "Pooling"
  bottom: "d1c"
  top: "d2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d2a-b"
  type: "Convolution"
  bottom: "d2a"
  top: "d2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d2b"
  type: "BatchNorm"
  bottom: "d2b"
  top: "d2b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d2b"
  type: "Scale"
  bottom: "d2b"
  top: "d2b"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d2b"
  type: "ReLU"
  bottom: "d2b"
  top: "d2b"
}
layer {
  name: "conv_d2b-c"
  type: "Convolution"
  bottom: "d2b"
  top: "d2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d2c"
  type: "BatchNorm"
  bottom: "d2c"
  top: "d2c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d2c"
  type: "Scale"
  bottom: "d2c"
  top: "d2c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d2c"
  type: "ReLU"
  bottom: "d2c"
  top: "d2c"
}
layer {
  name: "pool_d2c-3a"
  type: "Pooling"
  bottom: "d2c"
  top: "d3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d3a-b"
  type: "Convolution"
  bottom: "d3a"
  top: "d3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d3b"
  type: "BatchNorm"
  bottom: "d3b"
  top: "d3b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d3b"
  type: "Scale"
  bottom: "d3b"
  top: "d3b"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d3b"
  type: "ReLU"
  bottom: "d3b"
  top: "d3b"
}
layer {
  name: "conv_d3b-c"
  type: "Convolution"
  bottom: "d3b"
  top: "d3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d3c"
  type: "BatchNorm"
  bottom: "d3c"
  top: "d3c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d3c"
  type: "Scale"
  bottom: "d3c"
  top: "d3c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d3c"
  type: "ReLU"
  bottom: "d3c"
  top: "d3c"
}
layer {
  name: "pool_d3c-4a"
  type: "Pooling"
  bottom: "d3c"
  top: "d4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d4a-b"
  type: "Convolution"
  bottom: "d4a"
  top: "d4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d4b"
  type: "BatchNorm"
  bottom: "d4b"
  top: "d4b"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d4b"
  type: "Scale"
  bottom: "d4b"
  top: "d4b"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d4b"
  type: "ReLU"
  bottom: "d4b"
  top: "d4b"
}
layer {
  name: "conv_d4b-c"
  type: "Convolution"
  bottom: "d4b"
  top: "d4c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_d4c"
  type: "BatchNorm"
  bottom: "d4c"
  top: "d4c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_d4c"
  type: "Scale"
  bottom: "d4c"
  top: "d4c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_d4c"
  type: "ReLU"
  bottom: "d4c"
  top: "d4c"
}
layer {
  name: "upconv_d4c_u3a"
  type: "Deconvolution"
  bottom: "d4c"
  top: "u3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_u3a"
  type: "BatchNorm"
  bottom: "u3a"
  top: "u3a"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u3a"
  type: "Scale"
  bottom: "u3a"
  top: "u3a"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u3a"
  type: "ReLU"
  bottom: "u3a"
  top: "u3a"
}
layer {
  name: "crop_d3c-d3cc"
  type: "Crop"
  bottom: "d3c"
  bottom: "u3a"
  top: "d3cc"
  crop_param {
    axis: 2
    offset: 4
  }
}
layer {
  name: "concat_d3cc_u3a-b"
  type: "Concat"
  bottom: "u3a"
  bottom: "d3cc"
  top: "u3b"
}
layer {
  name: "conv_u3b-c"
  type: "Convolution"
  bottom: "u3b"
  top: "u3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u3c"
  type: "BatchNorm"
  bottom: "u3c"
  top: "u3c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u3c"
  type: "Scale"
  bottom: "u3c"
  top: "u3c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u3c"
  type: "ReLU"
  bottom: "u3c"
  top: "u3c"
}
layer {
  name: "conv_u3c-d"
  type: "Convolution"
  bottom: "u3c"
  top: "u3d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u3d"
  type: "BatchNorm"
  bottom: "u3d"
  top: "u3d"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u3d"
  type: "Scale"
  bottom: "u3d"
  top: "u3d"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u3d"
  type: "ReLU"
  bottom: "u3d"
  top: "u3d"
}
layer {
  name: "upconv_u3d_u2a"
  type: "Deconvolution"
  bottom: "u3d"
  top: "u2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_u2a"
  type: "BatchNorm"
  bottom: "u2a"
  top: "u2a"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u2a"
  type: "Scale"
  bottom: "u2a"
  top: "u2a"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u2a"
  type: "ReLU"
  bottom: "u2a"
  top: "u2a"
}
layer {
  name: "crop_d2c-d2cc"
  type: "Crop"
  bottom: "d2c"
  bottom: "u2a"
  top: "d2cc"
  crop_param {
    axis: 2
    offset: 16
  }
}
layer {
  name: "concat_d2cc_u2a-b"
  type: "Concat"
  bottom: "u2a"
  bottom: "d2cc"
  top: "u2b"
}
layer {
  name: "conv_u2b-c"
  type: "Convolution"
  bottom: "u2b"
  top: "u2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u2c"
  type: "BatchNorm"
  bottom: "u2c"
  top: "u2c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u2c"
  type: "Scale"
  bottom: "u2c"
  top: "u2c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u2c"
  type: "ReLU"
  bottom: "u2c"
  top: "u2c"
}
layer {
  name: "conv_u2c-d"
  type: "Convolution"
  bottom: "u2c"
  top: "u2d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u2d"
  type: "BatchNorm"
  bottom: "u2d"
  top: "u2d"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u2d"
  type: "Scale"
  bottom: "u2d"
  top: "u2d"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u2d"
  type: "ReLU"
  bottom: "u2d"
  top: "u2d"
}
layer {
  name: "upconv_u2d_u1a"
  type: "Deconvolution"
  bottom: "u2d"
  top: "u1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_u1a"
  type: "BatchNorm"
  bottom: "u1a"
  top: "u1a"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u1a"
  type: "Scale"
  bottom: "u1a"
  top: "u1a"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u1a"
  type: "ReLU"
  bottom: "u1a"
  top: "u1a"
}
layer {
  name: "crop_d1c-d1cc"
  type: "Crop"
  bottom: "d1c"
  bottom: "u1a"
  top: "d1cc"
  crop_param {
    axis: 2
    offset: 40
  }
}
layer {
  name: "concat_d1cc_u1a-b"
  type: "Concat"
  bottom: "u1a"
  bottom: "d1cc"
  top: "u1b"
}
layer {
  name: "conv_u1b-c"
  type: "Convolution"
  bottom: "u1b"
  top: "u1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u1c"
  type: "BatchNorm"
  bottom: "u1c"
  top: "u1c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u1c"
  type: "Scale"
  bottom: "u1c"
  top: "u1c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u1c"
  type: "ReLU"
  bottom: "u1c"
  top: "u1c"
}
layer {
  name: "conv_u1c-d"
  type: "Convolution"
  bottom: "u1c"
  top: "u1d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u1d"
  type: "BatchNorm"
  bottom: "u1d"
  top: "u1d"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u1d"
  type: "Scale"
  bottom: "u1d"
  top: "u1d"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u1d"
  type: "ReLU"
  bottom: "u1d"
  top: "u1d"
}
layer {
  name: "upconv_u1d_u0a"
  type: "Deconvolution"
  bottom: "u1d"
  top: "u0a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_u0a"
  type: "BatchNorm"
  bottom: "u0a"
  top: "u0a"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u0a"
  type: "Scale"
  bottom: "u0a"
  top: "u0a"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u0a"
  type: "ReLU"
  bottom: "u0a"
  top: "u0a"
}
layer {
  name: "crop_d0c-d0cc"
  type: "Crop"
  bottom: "d0c"
  bottom: "u0a"
  top: "d0cc"
  crop_param {
    axis: 2
    offset: 88
  }
}
layer {
  name: "concat_d0cc_u0a-b"
  type: "Concat"
  bottom: "u0a"
  bottom: "d0cc"
  top: "u0b"
}
layer {
  name: "conv_u0b-c"
  type: "Convolution"
  bottom: "u0b"
  top: "u0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u0c"
  type: "BatchNorm"
  bottom: "u0c"
  top: "u0c"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u0c"
  type: "Scale"
  bottom: "u0c"
  top: "u0c"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u0c"
  type: "ReLU"
  bottom: "u0c"
  top: "u0c"
}
layer {
  name: "conv_u0c-d"
  type: "Convolution"
  bottom: "u0c"
  top: "u0d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_u0d"
  type: "BatchNorm"
  bottom: "u0d"
  top: "u0d"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.999
    eps: 1e-05
  }
}
layer {
  name: "sc_u0d"
  type: "Scale"
  bottom: "u0d"
  top: "u0d"
  scale_param {
    axis: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_u0d"
  type: "ReLU"
  bottom: "u0d"
  top: "u0d"
}
layer {
  name: "conv_u0d-score"
  type: "Convolution"
  bottom: "u0d"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  bottom: "weights"
  top: "loss"
  loss_weight: 1
}
I0428 15:09:13.074257  5145 layer_factory.hpp:77] Creating layer loaddata
I0428 15:09:13.074266  5145 net.cpp:100] Creating Layer loaddata
I0428 15:09:13.074270  5145 net.cpp:408] loaddata -> data
I0428 15:09:13.074276  5145 net.cpp:408] loaddata -> label
I0428 15:09:13.074281  5145 net.cpp:408] loaddata -> weights
I0428 15:09:13.074286  5145 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: caffeHDF5_validation_4.txt
I0428 15:09:13.074309  5145 hdf5_data_layer.cpp:93] Number of HDF5 files: 10
I0428 15:09:13.377009  5145 net.cpp:150] Setting up loaddata
I0428 15:09:13.377053  5145 net.cpp:157] Top shape: 1 3 428 428 (549552)
I0428 15:09:13.377058  5145 net.cpp:157] Top shape: 1 244 244 (59536)
I0428 15:09:13.377060  5145 net.cpp:157] Top shape: 1 244 244 (59536)
I0428 15:09:13.377063  5145 net.cpp:165] Memory required for data: 2674496
I0428 15:09:13.377068  5145 layer_factory.hpp:77] Creating layer conv_d0a-b
I0428 15:09:13.377085  5145 net.cpp:100] Creating Layer conv_d0a-b
I0428 15:09:13.377089  5145 net.cpp:434] conv_d0a-b <- data
I0428 15:09:13.377095  5145 net.cpp:408] conv_d0a-b -> d0b
I0428 15:09:13.378625  5145 net.cpp:150] Setting up conv_d0a-b
I0428 15:09:13.378640  5145 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0428 15:09:13.378659  5145 net.cpp:165] Memory required for data: 49132352
I0428 15:09:13.378669  5145 layer_factory.hpp:77] Creating layer bn_d0b
I0428 15:09:13.378676  5145 net.cpp:100] Creating Layer bn_d0b
I0428 15:09:13.378680  5145 net.cpp:434] bn_d0b <- d0b
I0428 15:09:13.378684  5145 net.cpp:395] bn_d0b -> d0b (in-place)
I0428 15:09:13.379109  5145 net.cpp:150] Setting up bn_d0b
I0428 15:09:13.379117  5145 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0428 15:09:13.379120  5145 net.cpp:165] Memory required for data: 95590208
I0428 15:09:13.379129  5145 layer_factory.hpp:77] Creating layer sc_d0b
I0428 15:09:13.379153  5145 net.cpp:100] Creating Layer sc_d0b
I0428 15:09:13.379156  5145 net.cpp:434] sc_d0b <- d0b
I0428 15:09:13.379163  5145 net.cpp:395] sc_d0b -> d0b (in-place)
I0428 15:09:13.379204  5145 layer_factory.hpp:77] Creating layer sc_d0b
I0428 15:09:13.380511  5145 net.cpp:150] Setting up sc_d0b
I0428 15:09:13.380522  5145 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0428 15:09:13.380525  5145 net.cpp:165] Memory required for data: 142048064
I0428 15:09:13.380547  5145 layer_factory.hpp:77] Creating layer relu_d0b
I0428 15:09:13.380553  5145 net.cpp:100] Creating Layer relu_d0b
I0428 15:09:13.380556  5145 net.cpp:434] relu_d0b <- d0b
I0428 15:09:13.380563  5145 net.cpp:395] relu_d0b -> d0b (in-place)
I0428 15:09:13.380820  5145 net.cpp:150] Setting up relu_d0b
I0428 15:09:13.380830  5145 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0428 15:09:13.380833  5145 net.cpp:165] Memory required for data: 188505920
I0428 15:09:13.380836  5145 layer_factory.hpp:77] Creating layer conv_d0b-c
I0428 15:09:13.380844  5145 net.cpp:100] Creating Layer conv_d0b-c
I0428 15:09:13.380847  5145 net.cpp:434] conv_d0b-c <- d0b
I0428 15:09:13.380852  5145 net.cpp:408] conv_d0b-c -> d0c
I0428 15:09:13.382452  5145 net.cpp:150] Setting up conv_d0b-c
I0428 15:09:13.382467  5145 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0428 15:09:13.382469  5145 net.cpp:165] Memory required for data: 234528576
I0428 15:09:13.382478  5145 layer_factory.hpp:77] Creating layer bn_d0c
I0428 15:09:13.382484  5145 net.cpp:100] Creating Layer bn_d0c
I0428 15:09:13.382488  5145 net.cpp:434] bn_d0c <- d0c
I0428 15:09:13.382508  5145 net.cpp:395] bn_d0c -> d0c (in-place)
I0428 15:09:13.382845  5145 net.cpp:150] Setting up bn_d0c
I0428 15:09:13.382855  5145 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0428 15:09:13.382858  5145 net.cpp:165] Memory required for data: 280551232
I0428 15:09:13.382864  5145 layer_factory.hpp:77] Creating layer sc_d0c
I0428 15:09:13.382870  5145 net.cpp:100] Creating Layer sc_d0c
I0428 15:09:13.382887  5145 net.cpp:434] sc_d0c <- d0c
I0428 15:09:13.382894  5145 net.cpp:395] sc_d0c -> d0c (in-place)
I0428 15:09:13.382936  5145 layer_factory.hpp:77] Creating layer sc_d0c
I0428 15:09:13.384235  5145 net.cpp:150] Setting up sc_d0c
I0428 15:09:13.384249  5145 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0428 15:09:13.384253  5145 net.cpp:165] Memory required for data: 326573888
I0428 15:09:13.384259  5145 layer_factory.hpp:77] Creating layer relu_d0c
I0428 15:09:13.384266  5145 net.cpp:100] Creating Layer relu_d0c
I0428 15:09:13.384270  5145 net.cpp:434] relu_d0c <- d0c
I0428 15:09:13.384274  5145 net.cpp:395] relu_d0c -> d0c (in-place)
I0428 15:09:13.384469  5145 net.cpp:150] Setting up relu_d0c
I0428 15:09:13.384479  5145 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0428 15:09:13.384482  5145 net.cpp:165] Memory required for data: 372596544
I0428 15:09:13.384485  5145 layer_factory.hpp:77] Creating layer d0c_relu_d0c_0_split
I0428 15:09:13.384490  5145 net.cpp:100] Creating Layer d0c_relu_d0c_0_split
I0428 15:09:13.384492  5145 net.cpp:434] d0c_relu_d0c_0_split <- d0c
I0428 15:09:13.384497  5145 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_0
I0428 15:09:13.384503  5145 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_1
I0428 15:09:13.384546  5145 net.cpp:150] Setting up d0c_relu_d0c_0_split
I0428 15:09:13.384553  5145 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0428 15:09:13.384558  5145 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0428 15:09:13.384560  5145 net.cpp:165] Memory required for data: 464641856
I0428 15:09:13.384562  5145 layer_factory.hpp:77] Creating layer pool_d0c-1a
I0428 15:09:13.384567  5145 net.cpp:100] Creating Layer pool_d0c-1a
I0428 15:09:13.384572  5145 net.cpp:434] pool_d0c-1a <- d0c_relu_d0c_0_split_0
I0428 15:09:13.384575  5145 net.cpp:408] pool_d0c-1a -> d1a
I0428 15:09:13.384613  5145 net.cpp:150] Setting up pool_d0c-1a
I0428 15:09:13.384616  5145 net.cpp:157] Top shape: 1 64 212 212 (2876416)
I0428 15:09:13.384619  5145 net.cpp:165] Memory required for data: 476147520
I0428 15:09:13.384623  5145 layer_factory.hpp:77] Creating layer conv_d1a-b
I0428 15:09:13.384629  5145 net.cpp:100] Creating Layer conv_d1a-b
I0428 15:09:13.384631  5145 net.cpp:434] conv_d1a-b <- d1a
I0428 15:09:13.384637  5145 net.cpp:408] conv_d1a-b -> d1b
I0428 15:09:13.385350  5145 net.cpp:150] Setting up conv_d1a-b
I0428 15:09:13.385360  5145 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0428 15:09:13.385361  5145 net.cpp:165] Memory required for data: 498726720
I0428 15:09:13.385367  5145 layer_factory.hpp:77] Creating layer bn_d1b
I0428 15:09:13.385372  5145 net.cpp:100] Creating Layer bn_d1b
I0428 15:09:13.385375  5145 net.cpp:434] bn_d1b <- d1b
I0428 15:09:13.385380  5145 net.cpp:395] bn_d1b -> d1b (in-place)
I0428 15:09:13.385624  5145 net.cpp:150] Setting up bn_d1b
I0428 15:09:13.385632  5145 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0428 15:09:13.385635  5145 net.cpp:165] Memory required for data: 521305920
I0428 15:09:13.385645  5145 layer_factory.hpp:77] Creating layer sc_d1b
I0428 15:09:13.385651  5145 net.cpp:100] Creating Layer sc_d1b
I0428 15:09:13.385654  5145 net.cpp:434] sc_d1b <- d1b
I0428 15:09:13.385659  5145 net.cpp:395] sc_d1b -> d1b (in-place)
I0428 15:09:13.385695  5145 layer_factory.hpp:77] Creating layer sc_d1b
I0428 15:09:13.385879  5145 net.cpp:150] Setting up sc_d1b
I0428 15:09:13.385887  5145 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0428 15:09:13.385890  5145 net.cpp:165] Memory required for data: 543885120
I0428 15:09:13.385895  5145 layer_factory.hpp:77] Creating layer relu_d1b
I0428 15:09:13.385900  5145 net.cpp:100] Creating Layer relu_d1b
I0428 15:09:13.385902  5145 net.cpp:434] relu_d1b <- d1b
I0428 15:09:13.385906  5145 net.cpp:395] relu_d1b -> d1b (in-place)
I0428 15:09:13.386087  5145 net.cpp:150] Setting up relu_d1b
I0428 15:09:13.386097  5145 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0428 15:09:13.386101  5145 net.cpp:165] Memory required for data: 566464320
I0428 15:09:13.386114  5145 layer_factory.hpp:77] Creating layer conv_d1b-c
I0428 15:09:13.386122  5145 net.cpp:100] Creating Layer conv_d1b-c
I0428 15:09:13.386126  5145 net.cpp:434] conv_d1b-c <- d1b
I0428 15:09:13.386132  5145 net.cpp:408] conv_d1b-c -> d1c
I0428 15:09:13.387276  5145 net.cpp:150] Setting up conv_d1b-c
I0428 15:09:13.387285  5145 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0428 15:09:13.387289  5145 net.cpp:165] Memory required for data: 588615488
I0428 15:09:13.387293  5145 layer_factory.hpp:77] Creating layer bn_d1c
I0428 15:09:13.387300  5145 net.cpp:100] Creating Layer bn_d1c
I0428 15:09:13.387303  5145 net.cpp:434] bn_d1c <- d1c
I0428 15:09:13.387308  5145 net.cpp:395] bn_d1c -> d1c (in-place)
I0428 15:09:13.388434  5145 net.cpp:150] Setting up bn_d1c
I0428 15:09:13.388447  5145 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0428 15:09:13.388449  5145 net.cpp:165] Memory required for data: 610766656
I0428 15:09:13.388458  5145 layer_factory.hpp:77] Creating layer sc_d1c
I0428 15:09:13.388464  5145 net.cpp:100] Creating Layer sc_d1c
I0428 15:09:13.388468  5145 net.cpp:434] sc_d1c <- d1c
I0428 15:09:13.388473  5145 net.cpp:395] sc_d1c -> d1c (in-place)
I0428 15:09:13.388514  5145 layer_factory.hpp:77] Creating layer sc_d1c
I0428 15:09:13.388670  5145 net.cpp:150] Setting up sc_d1c
I0428 15:09:13.388679  5145 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0428 15:09:13.388681  5145 net.cpp:165] Memory required for data: 632917824
I0428 15:09:13.388687  5145 layer_factory.hpp:77] Creating layer relu_d1c
I0428 15:09:13.388692  5145 net.cpp:100] Creating Layer relu_d1c
I0428 15:09:13.388695  5145 net.cpp:434] relu_d1c <- d1c
I0428 15:09:13.388698  5145 net.cpp:395] relu_d1c -> d1c (in-place)
I0428 15:09:13.389488  5145 net.cpp:150] Setting up relu_d1c
I0428 15:09:13.389503  5145 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0428 15:09:13.389505  5145 net.cpp:165] Memory required for data: 655068992
I0428 15:09:13.389508  5145 layer_factory.hpp:77] Creating layer d1c_relu_d1c_0_split
I0428 15:09:13.389514  5145 net.cpp:100] Creating Layer d1c_relu_d1c_0_split
I0428 15:09:13.389518  5145 net.cpp:434] d1c_relu_d1c_0_split <- d1c
I0428 15:09:13.389523  5145 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_0
I0428 15:09:13.389530  5145 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_1
I0428 15:09:13.389575  5145 net.cpp:150] Setting up d1c_relu_d1c_0_split
I0428 15:09:13.389583  5145 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0428 15:09:13.389586  5145 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0428 15:09:13.389588  5145 net.cpp:165] Memory required for data: 699371328
I0428 15:09:13.389592  5145 layer_factory.hpp:77] Creating layer pool_d1c-2a
I0428 15:09:13.389597  5145 net.cpp:100] Creating Layer pool_d1c-2a
I0428 15:09:13.389600  5145 net.cpp:434] pool_d1c-2a <- d1c_relu_d1c_0_split_0
I0428 15:09:13.389605  5145 net.cpp:408] pool_d1c-2a -> d2a
I0428 15:09:13.389641  5145 net.cpp:150] Setting up pool_d1c-2a
I0428 15:09:13.389647  5145 net.cpp:157] Top shape: 1 128 104 104 (1384448)
I0428 15:09:13.389649  5145 net.cpp:165] Memory required for data: 704909120
I0428 15:09:13.389652  5145 layer_factory.hpp:77] Creating layer conv_d2a-b
I0428 15:09:13.389659  5145 net.cpp:100] Creating Layer conv_d2a-b
I0428 15:09:13.389662  5145 net.cpp:434] conv_d2a-b <- d2a
I0428 15:09:13.389667  5145 net.cpp:408] conv_d2a-b -> d2b
I0428 15:09:13.392489  5145 net.cpp:150] Setting up conv_d2a-b
I0428 15:09:13.392503  5145 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0428 15:09:13.392506  5145 net.cpp:165] Memory required for data: 715562816
I0428 15:09:13.392527  5145 layer_factory.hpp:77] Creating layer bn_d2b
I0428 15:09:13.392534  5145 net.cpp:100] Creating Layer bn_d2b
I0428 15:09:13.392537  5145 net.cpp:434] bn_d2b <- d2b
I0428 15:09:13.392542  5145 net.cpp:395] bn_d2b -> d2b (in-place)
I0428 15:09:13.392748  5145 net.cpp:150] Setting up bn_d2b
I0428 15:09:13.392756  5145 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0428 15:09:13.392760  5145 net.cpp:165] Memory required for data: 726216512
I0428 15:09:13.392782  5145 layer_factory.hpp:77] Creating layer sc_d2b
I0428 15:09:13.392788  5145 net.cpp:100] Creating Layer sc_d2b
I0428 15:09:13.392791  5145 net.cpp:434] sc_d2b <- d2b
I0428 15:09:13.392796  5145 net.cpp:395] sc_d2b -> d2b (in-place)
I0428 15:09:13.392838  5145 layer_factory.hpp:77] Creating layer sc_d2b
I0428 15:09:13.392966  5145 net.cpp:150] Setting up sc_d2b
I0428 15:09:13.392974  5145 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0428 15:09:13.392977  5145 net.cpp:165] Memory required for data: 736870208
I0428 15:09:13.392982  5145 layer_factory.hpp:77] Creating layer relu_d2b
I0428 15:09:13.392987  5145 net.cpp:100] Creating Layer relu_d2b
I0428 15:09:13.392989  5145 net.cpp:434] relu_d2b <- d2b
I0428 15:09:13.392994  5145 net.cpp:395] relu_d2b -> d2b (in-place)
I0428 15:09:13.393174  5145 net.cpp:150] Setting up relu_d2b
I0428 15:09:13.393183  5145 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0428 15:09:13.393187  5145 net.cpp:165] Memory required for data: 747523904
I0428 15:09:13.393189  5145 layer_factory.hpp:77] Creating layer conv_d2b-c
I0428 15:09:13.393198  5145 net.cpp:100] Creating Layer conv_d2b-c
I0428 15:09:13.393200  5145 net.cpp:434] conv_d2b-c <- d2b
I0428 15:09:13.393206  5145 net.cpp:408] conv_d2b-c -> d2c
I0428 15:09:13.397699  5145 net.cpp:150] Setting up conv_d2b-c
I0428 15:09:13.397713  5145 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0428 15:09:13.397716  5145 net.cpp:165] Memory required for data: 757763904
I0428 15:09:13.397722  5145 layer_factory.hpp:77] Creating layer bn_d2c
I0428 15:09:13.397728  5145 net.cpp:100] Creating Layer bn_d2c
I0428 15:09:13.397732  5145 net.cpp:434] bn_d2c <- d2c
I0428 15:09:13.397737  5145 net.cpp:395] bn_d2c -> d2c (in-place)
I0428 15:09:13.397940  5145 net.cpp:150] Setting up bn_d2c
I0428 15:09:13.397948  5145 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0428 15:09:13.397950  5145 net.cpp:165] Memory required for data: 768003904
I0428 15:09:13.397958  5145 layer_factory.hpp:77] Creating layer sc_d2c
I0428 15:09:13.397965  5145 net.cpp:100] Creating Layer sc_d2c
I0428 15:09:13.397969  5145 net.cpp:434] sc_d2c <- d2c
I0428 15:09:13.397974  5145 net.cpp:395] sc_d2c -> d2c (in-place)
I0428 15:09:13.398010  5145 layer_factory.hpp:77] Creating layer sc_d2c
I0428 15:09:13.398139  5145 net.cpp:150] Setting up sc_d2c
I0428 15:09:13.398147  5145 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0428 15:09:13.398150  5145 net.cpp:165] Memory required for data: 778243904
I0428 15:09:13.398155  5145 layer_factory.hpp:77] Creating layer relu_d2c
I0428 15:09:13.398159  5145 net.cpp:100] Creating Layer relu_d2c
I0428 15:09:13.398162  5145 net.cpp:434] relu_d2c <- d2c
I0428 15:09:13.398166  5145 net.cpp:395] relu_d2c -> d2c (in-place)
I0428 15:09:13.398349  5145 net.cpp:150] Setting up relu_d2c
I0428 15:09:13.398357  5145 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0428 15:09:13.398360  5145 net.cpp:165] Memory required for data: 788483904
I0428 15:09:13.398363  5145 layer_factory.hpp:77] Creating layer d2c_relu_d2c_0_split
I0428 15:09:13.398368  5145 net.cpp:100] Creating Layer d2c_relu_d2c_0_split
I0428 15:09:13.398371  5145 net.cpp:434] d2c_relu_d2c_0_split <- d2c
I0428 15:09:13.398377  5145 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_0
I0428 15:09:13.398383  5145 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_1
I0428 15:09:13.398429  5145 net.cpp:150] Setting up d2c_relu_d2c_0_split
I0428 15:09:13.398437  5145 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0428 15:09:13.398440  5145 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0428 15:09:13.398442  5145 net.cpp:165] Memory required for data: 808963904
I0428 15:09:13.398445  5145 layer_factory.hpp:77] Creating layer pool_d2c-3a
I0428 15:09:13.398450  5145 net.cpp:100] Creating Layer pool_d2c-3a
I0428 15:09:13.398453  5145 net.cpp:434] pool_d2c-3a <- d2c_relu_d2c_0_split_0
I0428 15:09:13.398458  5145 net.cpp:408] pool_d2c-3a -> d3a
I0428 15:09:13.398494  5145 net.cpp:150] Setting up pool_d2c-3a
I0428 15:09:13.398499  5145 net.cpp:157] Top shape: 1 256 50 50 (640000)
I0428 15:09:13.398514  5145 net.cpp:165] Memory required for data: 811523904
I0428 15:09:13.398516  5145 layer_factory.hpp:77] Creating layer conv_d3a-b
I0428 15:09:13.398524  5145 net.cpp:100] Creating Layer conv_d3a-b
I0428 15:09:13.398527  5145 net.cpp:434] conv_d3a-b <- d3a
I0428 15:09:13.398533  5145 net.cpp:408] conv_d3a-b -> d3b
I0428 15:09:13.406949  5145 net.cpp:150] Setting up conv_d3a-b
I0428 15:09:13.406962  5145 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0428 15:09:13.406981  5145 net.cpp:165] Memory required for data: 816242496
I0428 15:09:13.406988  5145 layer_factory.hpp:77] Creating layer bn_d3b
I0428 15:09:13.406997  5145 net.cpp:100] Creating Layer bn_d3b
I0428 15:09:13.407001  5145 net.cpp:434] bn_d3b <- d3b
I0428 15:09:13.407006  5145 net.cpp:395] bn_d3b -> d3b (in-place)
I0428 15:09:13.407202  5145 net.cpp:150] Setting up bn_d3b
I0428 15:09:13.407209  5145 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0428 15:09:13.407212  5145 net.cpp:165] Memory required for data: 820961088
I0428 15:09:13.407219  5145 layer_factory.hpp:77] Creating layer sc_d3b
I0428 15:09:13.407225  5145 net.cpp:100] Creating Layer sc_d3b
I0428 15:09:13.407228  5145 net.cpp:434] sc_d3b <- d3b
I0428 15:09:13.407232  5145 net.cpp:395] sc_d3b -> d3b (in-place)
I0428 15:09:13.407270  5145 layer_factory.hpp:77] Creating layer sc_d3b
I0428 15:09:13.407382  5145 net.cpp:150] Setting up sc_d3b
I0428 15:09:13.407389  5145 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0428 15:09:13.407392  5145 net.cpp:165] Memory required for data: 825679680
I0428 15:09:13.407397  5145 layer_factory.hpp:77] Creating layer relu_d3b
I0428 15:09:13.407402  5145 net.cpp:100] Creating Layer relu_d3b
I0428 15:09:13.407404  5145 net.cpp:434] relu_d3b <- d3b
I0428 15:09:13.407408  5145 net.cpp:395] relu_d3b -> d3b (in-place)
I0428 15:09:13.407595  5145 net.cpp:150] Setting up relu_d3b
I0428 15:09:13.407605  5145 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0428 15:09:13.407608  5145 net.cpp:165] Memory required for data: 830398272
I0428 15:09:13.407610  5145 layer_factory.hpp:77] Creating layer conv_d3b-c
I0428 15:09:13.407618  5145 net.cpp:100] Creating Layer conv_d3b-c
I0428 15:09:13.407621  5145 net.cpp:434] conv_d3b-c <- d3b
I0428 15:09:13.407626  5145 net.cpp:408] conv_d3b-c -> d3c
I0428 15:09:13.423346  5145 net.cpp:150] Setting up conv_d3b-c
I0428 15:09:13.423359  5145 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0428 15:09:13.423362  5145 net.cpp:165] Memory required for data: 834731840
I0428 15:09:13.423368  5145 layer_factory.hpp:77] Creating layer bn_d3c
I0428 15:09:13.423373  5145 net.cpp:100] Creating Layer bn_d3c
I0428 15:09:13.423377  5145 net.cpp:434] bn_d3c <- d3c
I0428 15:09:13.423382  5145 net.cpp:395] bn_d3c -> d3c (in-place)
I0428 15:09:13.423609  5145 net.cpp:150] Setting up bn_d3c
I0428 15:09:13.423616  5145 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0428 15:09:13.423619  5145 net.cpp:165] Memory required for data: 839065408
I0428 15:09:13.423626  5145 layer_factory.hpp:77] Creating layer sc_d3c
I0428 15:09:13.423631  5145 net.cpp:100] Creating Layer sc_d3c
I0428 15:09:13.423635  5145 net.cpp:434] sc_d3c <- d3c
I0428 15:09:13.423638  5145 net.cpp:395] sc_d3c -> d3c (in-place)
I0428 15:09:13.423676  5145 layer_factory.hpp:77] Creating layer sc_d3c
I0428 15:09:13.423800  5145 net.cpp:150] Setting up sc_d3c
I0428 15:09:13.423807  5145 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0428 15:09:13.423810  5145 net.cpp:165] Memory required for data: 843398976
I0428 15:09:13.423815  5145 layer_factory.hpp:77] Creating layer relu_d3c
I0428 15:09:13.423820  5145 net.cpp:100] Creating Layer relu_d3c
I0428 15:09:13.423822  5145 net.cpp:434] relu_d3c <- d3c
I0428 15:09:13.423826  5145 net.cpp:395] relu_d3c -> d3c (in-place)
I0428 15:09:13.424671  5145 net.cpp:150] Setting up relu_d3c
I0428 15:09:13.424685  5145 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0428 15:09:13.424687  5145 net.cpp:165] Memory required for data: 847732544
I0428 15:09:13.424690  5145 layer_factory.hpp:77] Creating layer d3c_relu_d3c_0_split
I0428 15:09:13.424726  5145 net.cpp:100] Creating Layer d3c_relu_d3c_0_split
I0428 15:09:13.424729  5145 net.cpp:434] d3c_relu_d3c_0_split <- d3c
I0428 15:09:13.424736  5145 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_0
I0428 15:09:13.424746  5145 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_1
I0428 15:09:13.424793  5145 net.cpp:150] Setting up d3c_relu_d3c_0_split
I0428 15:09:13.424801  5145 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0428 15:09:13.424804  5145 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0428 15:09:13.424808  5145 net.cpp:165] Memory required for data: 856399680
I0428 15:09:13.424810  5145 layer_factory.hpp:77] Creating layer pool_d3c-4a
I0428 15:09:13.424815  5145 net.cpp:100] Creating Layer pool_d3c-4a
I0428 15:09:13.424818  5145 net.cpp:434] pool_d3c-4a <- d3c_relu_d3c_0_split_0
I0428 15:09:13.424823  5145 net.cpp:408] pool_d3c-4a -> d4a
I0428 15:09:13.424861  5145 net.cpp:150] Setting up pool_d3c-4a
I0428 15:09:13.424868  5145 net.cpp:157] Top shape: 1 512 23 23 (270848)
I0428 15:09:13.424870  5145 net.cpp:165] Memory required for data: 857483072
I0428 15:09:13.424872  5145 layer_factory.hpp:77] Creating layer conv_d4a-b
I0428 15:09:13.424880  5145 net.cpp:100] Creating Layer conv_d4a-b
I0428 15:09:13.424883  5145 net.cpp:434] conv_d4a-b <- d4a
I0428 15:09:13.424888  5145 net.cpp:408] conv_d4a-b -> d4b
I0428 15:09:13.456377  5145 net.cpp:150] Setting up conv_d4a-b
I0428 15:09:13.456393  5145 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0428 15:09:13.456411  5145 net.cpp:165] Memory required for data: 859289408
I0428 15:09:13.456418  5145 layer_factory.hpp:77] Creating layer bn_d4b
I0428 15:09:13.456423  5145 net.cpp:100] Creating Layer bn_d4b
I0428 15:09:13.456429  5145 net.cpp:434] bn_d4b <- d4b
I0428 15:09:13.456432  5145 net.cpp:395] bn_d4b -> d4b (in-place)
I0428 15:09:13.456645  5145 net.cpp:150] Setting up bn_d4b
I0428 15:09:13.456652  5145 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0428 15:09:13.456655  5145 net.cpp:165] Memory required for data: 861095744
I0428 15:09:13.456662  5145 layer_factory.hpp:77] Creating layer sc_d4b
I0428 15:09:13.456667  5145 net.cpp:100] Creating Layer sc_d4b
I0428 15:09:13.456670  5145 net.cpp:434] sc_d4b <- d4b
I0428 15:09:13.456676  5145 net.cpp:395] sc_d4b -> d4b (in-place)
I0428 15:09:13.456715  5145 layer_factory.hpp:77] Creating layer sc_d4b
I0428 15:09:13.456828  5145 net.cpp:150] Setting up sc_d4b
I0428 15:09:13.456835  5145 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0428 15:09:13.456838  5145 net.cpp:165] Memory required for data: 862902080
I0428 15:09:13.456843  5145 layer_factory.hpp:77] Creating layer relu_d4b
I0428 15:09:13.456848  5145 net.cpp:100] Creating Layer relu_d4b
I0428 15:09:13.456851  5145 net.cpp:434] relu_d4b <- d4b
I0428 15:09:13.456856  5145 net.cpp:395] relu_d4b -> d4b (in-place)
I0428 15:09:13.457048  5145 net.cpp:150] Setting up relu_d4b
I0428 15:09:13.457058  5145 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0428 15:09:13.457060  5145 net.cpp:165] Memory required for data: 864708416
I0428 15:09:13.457064  5145 layer_factory.hpp:77] Creating layer conv_d4b-c
I0428 15:09:13.457072  5145 net.cpp:100] Creating Layer conv_d4b-c
I0428 15:09:13.457075  5145 net.cpp:434] conv_d4b-c <- d4b
I0428 15:09:13.457080  5145 net.cpp:408] conv_d4b-c -> d4c
I0428 15:09:13.519680  5145 net.cpp:150] Setting up conv_d4b-c
I0428 15:09:13.519701  5145 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0428 15:09:13.519703  5145 net.cpp:165] Memory required for data: 866187072
I0428 15:09:13.519721  5145 layer_factory.hpp:77] Creating layer bn_d4c
I0428 15:09:13.519729  5145 net.cpp:100] Creating Layer bn_d4c
I0428 15:09:13.519733  5145 net.cpp:434] bn_d4c <- d4c
I0428 15:09:13.519738  5145 net.cpp:395] bn_d4c -> d4c (in-place)
I0428 15:09:13.519964  5145 net.cpp:150] Setting up bn_d4c
I0428 15:09:13.519973  5145 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0428 15:09:13.519975  5145 net.cpp:165] Memory required for data: 867665728
I0428 15:09:13.519981  5145 layer_factory.hpp:77] Creating layer sc_d4c
I0428 15:09:13.520001  5145 net.cpp:100] Creating Layer sc_d4c
I0428 15:09:13.520005  5145 net.cpp:434] sc_d4c <- d4c
I0428 15:09:13.520011  5145 net.cpp:395] sc_d4c -> d4c (in-place)
I0428 15:09:13.520057  5145 layer_factory.hpp:77] Creating layer sc_d4c
I0428 15:09:13.520182  5145 net.cpp:150] Setting up sc_d4c
I0428 15:09:13.520190  5145 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0428 15:09:13.520192  5145 net.cpp:165] Memory required for data: 869144384
I0428 15:09:13.520197  5145 layer_factory.hpp:77] Creating layer relu_d4c
I0428 15:09:13.520202  5145 net.cpp:100] Creating Layer relu_d4c
I0428 15:09:13.520206  5145 net.cpp:434] relu_d4c <- d4c
I0428 15:09:13.520210  5145 net.cpp:395] relu_d4c -> d4c (in-place)
I0428 15:09:13.520431  5145 net.cpp:150] Setting up relu_d4c
I0428 15:09:13.520440  5145 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0428 15:09:13.520443  5145 net.cpp:165] Memory required for data: 870623040
I0428 15:09:13.520447  5145 layer_factory.hpp:77] Creating layer upconv_d4c_u3a
I0428 15:09:13.520453  5145 net.cpp:100] Creating Layer upconv_d4c_u3a
I0428 15:09:13.520457  5145 net.cpp:434] upconv_d4c_u3a <- d4c
I0428 15:09:13.520462  5145 net.cpp:408] upconv_d4c_u3a -> u3a
I0428 15:09:13.534492  5145 net.cpp:150] Setting up upconv_d4c_u3a
I0428 15:09:13.534504  5145 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0428 15:09:13.534523  5145 net.cpp:165] Memory required for data: 873580352
I0428 15:09:13.534529  5145 layer_factory.hpp:77] Creating layer bn_u3a
I0428 15:09:13.534535  5145 net.cpp:100] Creating Layer bn_u3a
I0428 15:09:13.534539  5145 net.cpp:434] bn_u3a <- u3a
I0428 15:09:13.534544  5145 net.cpp:395] bn_u3a -> u3a (in-place)
I0428 15:09:13.534770  5145 net.cpp:150] Setting up bn_u3a
I0428 15:09:13.534777  5145 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0428 15:09:13.534780  5145 net.cpp:165] Memory required for data: 876537664
I0428 15:09:13.534785  5145 layer_factory.hpp:77] Creating layer sc_u3a
I0428 15:09:13.534792  5145 net.cpp:100] Creating Layer sc_u3a
I0428 15:09:13.534795  5145 net.cpp:434] sc_u3a <- u3a
I0428 15:09:13.534799  5145 net.cpp:395] sc_u3a -> u3a (in-place)
I0428 15:09:13.534835  5145 layer_factory.hpp:77] Creating layer sc_u3a
I0428 15:09:13.534963  5145 net.cpp:150] Setting up sc_u3a
I0428 15:09:13.534970  5145 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0428 15:09:13.534973  5145 net.cpp:165] Memory required for data: 879494976
I0428 15:09:13.534977  5145 layer_factory.hpp:77] Creating layer relu_u3a
I0428 15:09:13.534983  5145 net.cpp:100] Creating Layer relu_u3a
I0428 15:09:13.534986  5145 net.cpp:434] relu_u3a <- u3a
I0428 15:09:13.534991  5145 net.cpp:395] relu_u3a -> u3a (in-place)
I0428 15:09:13.535184  5145 net.cpp:150] Setting up relu_u3a
I0428 15:09:13.535194  5145 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0428 15:09:13.535197  5145 net.cpp:165] Memory required for data: 882452288
I0428 15:09:13.535199  5145 layer_factory.hpp:77] Creating layer u3a_relu_u3a_0_split
I0428 15:09:13.535205  5145 net.cpp:100] Creating Layer u3a_relu_u3a_0_split
I0428 15:09:13.535208  5145 net.cpp:434] u3a_relu_u3a_0_split <- u3a
I0428 15:09:13.535213  5145 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_0
I0428 15:09:13.535219  5145 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_1
I0428 15:09:13.535264  5145 net.cpp:150] Setting up u3a_relu_u3a_0_split
I0428 15:09:13.535272  5145 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0428 15:09:13.535276  5145 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0428 15:09:13.535279  5145 net.cpp:165] Memory required for data: 888366912
I0428 15:09:13.535280  5145 layer_factory.hpp:77] Creating layer crop_d3c-d3cc
I0428 15:09:13.535287  5145 net.cpp:100] Creating Layer crop_d3c-d3cc
I0428 15:09:13.535290  5145 net.cpp:434] crop_d3c-d3cc <- d3c_relu_d3c_0_split_1
I0428 15:09:13.535295  5145 net.cpp:434] crop_d3c-d3cc <- u3a_relu_u3a_0_split_0
I0428 15:09:13.535300  5145 net.cpp:408] crop_d3c-d3cc -> d3cc
I0428 15:09:13.535325  5145 net.cpp:150] Setting up crop_d3c-d3cc
I0428 15:09:13.535329  5145 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0428 15:09:13.535343  5145 net.cpp:165] Memory required for data: 891324224
I0428 15:09:13.535346  5145 layer_factory.hpp:77] Creating layer concat_d3cc_u3a-b
I0428 15:09:13.535352  5145 net.cpp:100] Creating Layer concat_d3cc_u3a-b
I0428 15:09:13.535354  5145 net.cpp:434] concat_d3cc_u3a-b <- u3a_relu_u3a_0_split_1
I0428 15:09:13.535358  5145 net.cpp:434] concat_d3cc_u3a-b <- d3cc
I0428 15:09:13.535363  5145 net.cpp:408] concat_d3cc_u3a-b -> u3b
I0428 15:09:13.535389  5145 net.cpp:150] Setting up concat_d3cc_u3a-b
I0428 15:09:13.535394  5145 net.cpp:157] Top shape: 1 1024 38 38 (1478656)
I0428 15:09:13.535396  5145 net.cpp:165] Memory required for data: 897238848
I0428 15:09:13.535398  5145 layer_factory.hpp:77] Creating layer conv_u3b-c
I0428 15:09:13.535408  5145 net.cpp:100] Creating Layer conv_u3b-c
I0428 15:09:13.535409  5145 net.cpp:434] conv_u3b-c <- u3b
I0428 15:09:13.535415  5145 net.cpp:408] conv_u3b-c -> u3c
I0428 15:09:13.566300  5145 net.cpp:150] Setting up conv_u3b-c
I0428 15:09:13.566318  5145 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0428 15:09:13.566336  5145 net.cpp:165] Memory required for data: 899893056
I0428 15:09:13.566344  5145 layer_factory.hpp:77] Creating layer bn_u3c
I0428 15:09:13.566350  5145 net.cpp:100] Creating Layer bn_u3c
I0428 15:09:13.566354  5145 net.cpp:434] bn_u3c <- u3c
I0428 15:09:13.566359  5145 net.cpp:395] bn_u3c -> u3c (in-place)
I0428 15:09:13.566586  5145 net.cpp:150] Setting up bn_u3c
I0428 15:09:13.566593  5145 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0428 15:09:13.566597  5145 net.cpp:165] Memory required for data: 902547264
I0428 15:09:13.566604  5145 layer_factory.hpp:77] Creating layer sc_u3c
I0428 15:09:13.566611  5145 net.cpp:100] Creating Layer sc_u3c
I0428 15:09:13.566613  5145 net.cpp:434] sc_u3c <- u3c
I0428 15:09:13.566619  5145 net.cpp:395] sc_u3c -> u3c (in-place)
I0428 15:09:13.566658  5145 layer_factory.hpp:77] Creating layer sc_u3c
I0428 15:09:13.566783  5145 net.cpp:150] Setting up sc_u3c
I0428 15:09:13.566790  5145 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0428 15:09:13.566793  5145 net.cpp:165] Memory required for data: 905201472
I0428 15:09:13.566798  5145 layer_factory.hpp:77] Creating layer relu_u3c
I0428 15:09:13.566803  5145 net.cpp:100] Creating Layer relu_u3c
I0428 15:09:13.566807  5145 net.cpp:434] relu_u3c <- u3c
I0428 15:09:13.566812  5145 net.cpp:395] relu_u3c -> u3c (in-place)
I0428 15:09:13.567658  5145 net.cpp:150] Setting up relu_u3c
I0428 15:09:13.567672  5145 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0428 15:09:13.567674  5145 net.cpp:165] Memory required for data: 907855680
I0428 15:09:13.567678  5145 layer_factory.hpp:77] Creating layer conv_u3c-d
I0428 15:09:13.567688  5145 net.cpp:100] Creating Layer conv_u3c-d
I0428 15:09:13.567692  5145 net.cpp:434] conv_u3c-d <- u3c
I0428 15:09:13.567697  5145 net.cpp:408] conv_u3c-d -> u3d
I0428 15:09:13.584086  5145 net.cpp:150] Setting up conv_u3c-d
I0428 15:09:13.584123  5145 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0428 15:09:13.584126  5145 net.cpp:165] Memory required for data: 910223168
I0428 15:09:13.584134  5145 layer_factory.hpp:77] Creating layer bn_u3d
I0428 15:09:13.584142  5145 net.cpp:100] Creating Layer bn_u3d
I0428 15:09:13.584146  5145 net.cpp:434] bn_u3d <- u3d
I0428 15:09:13.584153  5145 net.cpp:395] bn_u3d -> u3d (in-place)
I0428 15:09:13.584378  5145 net.cpp:150] Setting up bn_u3d
I0428 15:09:13.584386  5145 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0428 15:09:13.584389  5145 net.cpp:165] Memory required for data: 912590656
I0428 15:09:13.584395  5145 layer_factory.hpp:77] Creating layer sc_u3d
I0428 15:09:13.584403  5145 net.cpp:100] Creating Layer sc_u3d
I0428 15:09:13.584405  5145 net.cpp:434] sc_u3d <- u3d
I0428 15:09:13.584411  5145 net.cpp:395] sc_u3d -> u3d (in-place)
I0428 15:09:13.584450  5145 layer_factory.hpp:77] Creating layer sc_u3d
I0428 15:09:13.584573  5145 net.cpp:150] Setting up sc_u3d
I0428 15:09:13.584580  5145 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0428 15:09:13.584583  5145 net.cpp:165] Memory required for data: 914958144
I0428 15:09:13.584606  5145 layer_factory.hpp:77] Creating layer relu_u3d
I0428 15:09:13.584612  5145 net.cpp:100] Creating Layer relu_u3d
I0428 15:09:13.584615  5145 net.cpp:434] relu_u3d <- u3d
I0428 15:09:13.584620  5145 net.cpp:395] relu_u3d -> u3d (in-place)
I0428 15:09:13.584837  5145 net.cpp:150] Setting up relu_u3d
I0428 15:09:13.584847  5145 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0428 15:09:13.584851  5145 net.cpp:165] Memory required for data: 917325632
I0428 15:09:13.584853  5145 layer_factory.hpp:77] Creating layer upconv_u3d_u2a
I0428 15:09:13.584870  5145 net.cpp:100] Creating Layer upconv_u3d_u2a
I0428 15:09:13.584873  5145 net.cpp:434] upconv_u3d_u2a <- u3d
I0428 15:09:13.584880  5145 net.cpp:408] upconv_u3d_u2a -> u2a
I0428 15:09:13.589058  5145 net.cpp:150] Setting up upconv_u3d_u2a
I0428 15:09:13.589073  5145 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0428 15:09:13.589076  5145 net.cpp:165] Memory required for data: 922060608
I0428 15:09:13.589083  5145 layer_factory.hpp:77] Creating layer bn_u2a
I0428 15:09:13.589089  5145 net.cpp:100] Creating Layer bn_u2a
I0428 15:09:13.589092  5145 net.cpp:434] bn_u2a <- u2a
I0428 15:09:13.589097  5145 net.cpp:395] bn_u2a -> u2a (in-place)
I0428 15:09:13.589318  5145 net.cpp:150] Setting up bn_u2a
I0428 15:09:13.589326  5145 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0428 15:09:13.589329  5145 net.cpp:165] Memory required for data: 926795584
I0428 15:09:13.589335  5145 layer_factory.hpp:77] Creating layer sc_u2a
I0428 15:09:13.589341  5145 net.cpp:100] Creating Layer sc_u2a
I0428 15:09:13.589344  5145 net.cpp:434] sc_u2a <- u2a
I0428 15:09:13.589349  5145 net.cpp:395] sc_u2a -> u2a (in-place)
I0428 15:09:13.589390  5145 layer_factory.hpp:77] Creating layer sc_u2a
I0428 15:09:13.589532  5145 net.cpp:150] Setting up sc_u2a
I0428 15:09:13.589540  5145 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0428 15:09:13.589542  5145 net.cpp:165] Memory required for data: 931530560
I0428 15:09:13.589547  5145 layer_factory.hpp:77] Creating layer relu_u2a
I0428 15:09:13.589552  5145 net.cpp:100] Creating Layer relu_u2a
I0428 15:09:13.589555  5145 net.cpp:434] relu_u2a <- u2a
I0428 15:09:13.589560  5145 net.cpp:395] relu_u2a -> u2a (in-place)
I0428 15:09:13.589757  5145 net.cpp:150] Setting up relu_u2a
I0428 15:09:13.589768  5145 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0428 15:09:13.589771  5145 net.cpp:165] Memory required for data: 936265536
I0428 15:09:13.589773  5145 layer_factory.hpp:77] Creating layer u2a_relu_u2a_0_split
I0428 15:09:13.589778  5145 net.cpp:100] Creating Layer u2a_relu_u2a_0_split
I0428 15:09:13.589781  5145 net.cpp:434] u2a_relu_u2a_0_split <- u2a
I0428 15:09:13.589787  5145 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_0
I0428 15:09:13.589793  5145 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_1
I0428 15:09:13.589838  5145 net.cpp:150] Setting up u2a_relu_u2a_0_split
I0428 15:09:13.589846  5145 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0428 15:09:13.589849  5145 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0428 15:09:13.589851  5145 net.cpp:165] Memory required for data: 945735488
I0428 15:09:13.589854  5145 layer_factory.hpp:77] Creating layer crop_d2c-d2cc
I0428 15:09:13.589860  5145 net.cpp:100] Creating Layer crop_d2c-d2cc
I0428 15:09:13.589864  5145 net.cpp:434] crop_d2c-d2cc <- d2c_relu_d2c_0_split_1
I0428 15:09:13.589867  5145 net.cpp:434] crop_d2c-d2cc <- u2a_relu_u2a_0_split_0
I0428 15:09:13.589872  5145 net.cpp:408] crop_d2c-d2cc -> d2cc
I0428 15:09:13.589897  5145 net.cpp:150] Setting up crop_d2c-d2cc
I0428 15:09:13.589901  5145 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0428 15:09:13.589903  5145 net.cpp:165] Memory required for data: 950470464
I0428 15:09:13.589906  5145 layer_factory.hpp:77] Creating layer concat_d2cc_u2a-b
I0428 15:09:13.589911  5145 net.cpp:100] Creating Layer concat_d2cc_u2a-b
I0428 15:09:13.589913  5145 net.cpp:434] concat_d2cc_u2a-b <- u2a_relu_u2a_0_split_1
I0428 15:09:13.589917  5145 net.cpp:434] concat_d2cc_u2a-b <- d2cc
I0428 15:09:13.589934  5145 net.cpp:408] concat_d2cc_u2a-b -> u2b
I0428 15:09:13.589962  5145 net.cpp:150] Setting up concat_d2cc_u2a-b
I0428 15:09:13.589965  5145 net.cpp:157] Top shape: 1 512 68 68 (2367488)
I0428 15:09:13.589968  5145 net.cpp:165] Memory required for data: 959940416
I0428 15:09:13.589970  5145 layer_factory.hpp:77] Creating layer conv_u2b-c
I0428 15:09:13.589979  5145 net.cpp:100] Creating Layer conv_u2b-c
I0428 15:09:13.589982  5145 net.cpp:434] conv_u2b-c <- u2b
I0428 15:09:13.589988  5145 net.cpp:408] conv_u2b-c -> u2c
I0428 15:09:13.598250  5145 net.cpp:150] Setting up conv_u2b-c
I0428 15:09:13.598263  5145 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0428 15:09:13.598266  5145 net.cpp:165] Memory required for data: 964400960
I0428 15:09:13.598273  5145 layer_factory.hpp:77] Creating layer bn_u2c
I0428 15:09:13.598278  5145 net.cpp:100] Creating Layer bn_u2c
I0428 15:09:13.598281  5145 net.cpp:434] bn_u2c <- u2c
I0428 15:09:13.598286  5145 net.cpp:395] bn_u2c -> u2c (in-place)
I0428 15:09:13.598520  5145 net.cpp:150] Setting up bn_u2c
I0428 15:09:13.598527  5145 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0428 15:09:13.598531  5145 net.cpp:165] Memory required for data: 968861504
I0428 15:09:13.598536  5145 layer_factory.hpp:77] Creating layer sc_u2c
I0428 15:09:13.598542  5145 net.cpp:100] Creating Layer sc_u2c
I0428 15:09:13.598546  5145 net.cpp:434] sc_u2c <- u2c
I0428 15:09:13.598551  5145 net.cpp:395] sc_u2c -> u2c (in-place)
I0428 15:09:13.598589  5145 layer_factory.hpp:77] Creating layer sc_u2c
I0428 15:09:13.598713  5145 net.cpp:150] Setting up sc_u2c
I0428 15:09:13.598719  5145 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0428 15:09:13.598723  5145 net.cpp:165] Memory required for data: 973322048
I0428 15:09:13.598728  5145 layer_factory.hpp:77] Creating layer relu_u2c
I0428 15:09:13.598733  5145 net.cpp:100] Creating Layer relu_u2c
I0428 15:09:13.598736  5145 net.cpp:434] relu_u2c <- u2c
I0428 15:09:13.598740  5145 net.cpp:395] relu_u2c -> u2c (in-place)
I0428 15:09:13.599617  5145 net.cpp:150] Setting up relu_u2c
I0428 15:09:13.599630  5145 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0428 15:09:13.599632  5145 net.cpp:165] Memory required for data: 977782592
I0428 15:09:13.599651  5145 layer_factory.hpp:77] Creating layer conv_u2c-d
I0428 15:09:13.599660  5145 net.cpp:100] Creating Layer conv_u2c-d
I0428 15:09:13.599668  5145 net.cpp:434] conv_u2c-d <- u2c
I0428 15:09:13.599673  5145 net.cpp:408] conv_u2c-d -> u2d
I0428 15:09:13.604208  5145 net.cpp:150] Setting up conv_u2c-d
I0428 15:09:13.604223  5145 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0428 15:09:13.604224  5145 net.cpp:165] Memory required for data: 981976896
I0428 15:09:13.604230  5145 layer_factory.hpp:77] Creating layer bn_u2d
I0428 15:09:13.604236  5145 net.cpp:100] Creating Layer bn_u2d
I0428 15:09:13.604239  5145 net.cpp:434] bn_u2d <- u2d
I0428 15:09:13.604243  5145 net.cpp:395] bn_u2d -> u2d (in-place)
I0428 15:09:13.604472  5145 net.cpp:150] Setting up bn_u2d
I0428 15:09:13.604480  5145 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0428 15:09:13.604482  5145 net.cpp:165] Memory required for data: 986171200
I0428 15:09:13.604490  5145 layer_factory.hpp:77] Creating layer sc_u2d
I0428 15:09:13.604496  5145 net.cpp:100] Creating Layer sc_u2d
I0428 15:09:13.604498  5145 net.cpp:434] sc_u2d <- u2d
I0428 15:09:13.604503  5145 net.cpp:395] sc_u2d -> u2d (in-place)
I0428 15:09:13.604542  5145 layer_factory.hpp:77] Creating layer sc_u2d
I0428 15:09:13.604656  5145 net.cpp:150] Setting up sc_u2d
I0428 15:09:13.604665  5145 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0428 15:09:13.604666  5145 net.cpp:165] Memory required for data: 990365504
I0428 15:09:13.604672  5145 layer_factory.hpp:77] Creating layer relu_u2d
I0428 15:09:13.604676  5145 net.cpp:100] Creating Layer relu_u2d
I0428 15:09:13.604679  5145 net.cpp:434] relu_u2d <- u2d
I0428 15:09:13.604684  5145 net.cpp:395] relu_u2d -> u2d (in-place)
I0428 15:09:13.604868  5145 net.cpp:150] Setting up relu_u2d
I0428 15:09:13.604877  5145 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0428 15:09:13.604894  5145 net.cpp:165] Memory required for data: 994559808
I0428 15:09:13.604897  5145 layer_factory.hpp:77] Creating layer upconv_u2d_u1a
I0428 15:09:13.604904  5145 net.cpp:100] Creating Layer upconv_u2d_u1a
I0428 15:09:13.604907  5145 net.cpp:434] upconv_u2d_u1a <- u2d
I0428 15:09:13.604913  5145 net.cpp:408] upconv_u2d_u1a -> u1a
I0428 15:09:13.605986  5145 net.cpp:150] Setting up upconv_u2d_u1a
I0428 15:09:13.605995  5145 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0428 15:09:13.605998  5145 net.cpp:165] Memory required for data: 1002948416
I0428 15:09:13.606003  5145 layer_factory.hpp:77] Creating layer bn_u1a
I0428 15:09:13.606009  5145 net.cpp:100] Creating Layer bn_u1a
I0428 15:09:13.606010  5145 net.cpp:434] bn_u1a <- u1a
I0428 15:09:13.606015  5145 net.cpp:395] bn_u1a -> u1a (in-place)
I0428 15:09:13.606226  5145 net.cpp:150] Setting up bn_u1a
I0428 15:09:13.606233  5145 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0428 15:09:13.606236  5145 net.cpp:165] Memory required for data: 1011337024
I0428 15:09:13.606242  5145 layer_factory.hpp:77] Creating layer sc_u1a
I0428 15:09:13.606248  5145 net.cpp:100] Creating Layer sc_u1a
I0428 15:09:13.606251  5145 net.cpp:434] sc_u1a <- u1a
I0428 15:09:13.606256  5145 net.cpp:395] sc_u1a -> u1a (in-place)
I0428 15:09:13.606294  5145 layer_factory.hpp:77] Creating layer sc_u1a
I0428 15:09:13.606433  5145 net.cpp:150] Setting up sc_u1a
I0428 15:09:13.606441  5145 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0428 15:09:13.606443  5145 net.cpp:165] Memory required for data: 1019725632
I0428 15:09:13.606448  5145 layer_factory.hpp:77] Creating layer relu_u1a
I0428 15:09:13.606453  5145 net.cpp:100] Creating Layer relu_u1a
I0428 15:09:13.606456  5145 net.cpp:434] relu_u1a <- u1a
I0428 15:09:13.606461  5145 net.cpp:395] relu_u1a -> u1a (in-place)
I0428 15:09:13.606642  5145 net.cpp:150] Setting up relu_u1a
I0428 15:09:13.606652  5145 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0428 15:09:13.606655  5145 net.cpp:165] Memory required for data: 1028114240
I0428 15:09:13.606657  5145 layer_factory.hpp:77] Creating layer u1a_relu_u1a_0_split
I0428 15:09:13.606663  5145 net.cpp:100] Creating Layer u1a_relu_u1a_0_split
I0428 15:09:13.606667  5145 net.cpp:434] u1a_relu_u1a_0_split <- u1a
I0428 15:09:13.606673  5145 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_0
I0428 15:09:13.606679  5145 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_1
I0428 15:09:13.606724  5145 net.cpp:150] Setting up u1a_relu_u1a_0_split
I0428 15:09:13.606731  5145 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0428 15:09:13.606734  5145 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0428 15:09:13.606736  5145 net.cpp:165] Memory required for data: 1044891456
I0428 15:09:13.606739  5145 layer_factory.hpp:77] Creating layer crop_d1c-d1cc
I0428 15:09:13.606745  5145 net.cpp:100] Creating Layer crop_d1c-d1cc
I0428 15:09:13.606748  5145 net.cpp:434] crop_d1c-d1cc <- d1c_relu_d1c_0_split_1
I0428 15:09:13.606752  5145 net.cpp:434] crop_d1c-d1cc <- u1a_relu_u1a_0_split_0
I0428 15:09:13.606757  5145 net.cpp:408] crop_d1c-d1cc -> d1cc
I0428 15:09:13.606782  5145 net.cpp:150] Setting up crop_d1c-d1cc
I0428 15:09:13.606786  5145 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0428 15:09:13.606789  5145 net.cpp:165] Memory required for data: 1053280064
I0428 15:09:13.606791  5145 layer_factory.hpp:77] Creating layer concat_d1cc_u1a-b
I0428 15:09:13.606796  5145 net.cpp:100] Creating Layer concat_d1cc_u1a-b
I0428 15:09:13.606799  5145 net.cpp:434] concat_d1cc_u1a-b <- u1a_relu_u1a_0_split_1
I0428 15:09:13.606802  5145 net.cpp:434] concat_d1cc_u1a-b <- d1cc
I0428 15:09:13.606807  5145 net.cpp:408] concat_d1cc_u1a-b -> u1b
I0428 15:09:13.606830  5145 net.cpp:150] Setting up concat_d1cc_u1a-b
I0428 15:09:13.606834  5145 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0428 15:09:13.606837  5145 net.cpp:165] Memory required for data: 1070057280
I0428 15:09:13.606838  5145 layer_factory.hpp:77] Creating layer conv_u1b-c
I0428 15:09:13.606848  5145 net.cpp:100] Creating Layer conv_u1b-c
I0428 15:09:13.606860  5145 net.cpp:434] conv_u1b-c <- u1b
I0428 15:09:13.606866  5145 net.cpp:408] conv_u1b-c -> u1c
I0428 15:09:13.609771  5145 net.cpp:150] Setting up conv_u1b-c
I0428 15:09:13.609786  5145 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0428 15:09:13.609787  5145 net.cpp:165] Memory required for data: 1078185792
I0428 15:09:13.609793  5145 layer_factory.hpp:77] Creating layer bn_u1c
I0428 15:09:13.609799  5145 net.cpp:100] Creating Layer bn_u1c
I0428 15:09:13.609803  5145 net.cpp:434] bn_u1c <- u1c
I0428 15:09:13.609808  5145 net.cpp:395] bn_u1c -> u1c (in-place)
I0428 15:09:13.611327  5145 net.cpp:150] Setting up bn_u1c
I0428 15:09:13.611343  5145 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0428 15:09:13.611346  5145 net.cpp:165] Memory required for data: 1086314304
I0428 15:09:13.611356  5145 layer_factory.hpp:77] Creating layer sc_u1c
I0428 15:09:13.611362  5145 net.cpp:100] Creating Layer sc_u1c
I0428 15:09:13.611366  5145 net.cpp:434] sc_u1c <- u1c
I0428 15:09:13.611372  5145 net.cpp:395] sc_u1c -> u1c (in-place)
I0428 15:09:13.611418  5145 layer_factory.hpp:77] Creating layer sc_u1c
I0428 15:09:13.611554  5145 net.cpp:150] Setting up sc_u1c
I0428 15:09:13.611562  5145 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0428 15:09:13.611565  5145 net.cpp:165] Memory required for data: 1094442816
I0428 15:09:13.611572  5145 layer_factory.hpp:77] Creating layer relu_u1c
I0428 15:09:13.611575  5145 net.cpp:100] Creating Layer relu_u1c
I0428 15:09:13.611578  5145 net.cpp:434] relu_u1c <- u1c
I0428 15:09:13.611583  5145 net.cpp:395] relu_u1c -> u1c (in-place)
I0428 15:09:13.611780  5145 net.cpp:150] Setting up relu_u1c
I0428 15:09:13.611789  5145 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0428 15:09:13.611793  5145 net.cpp:165] Memory required for data: 1102571328
I0428 15:09:13.611795  5145 layer_factory.hpp:77] Creating layer conv_u1c-d
I0428 15:09:13.611804  5145 net.cpp:100] Creating Layer conv_u1c-d
I0428 15:09:13.611806  5145 net.cpp:434] conv_u1c-d <- u1c
I0428 15:09:13.611812  5145 net.cpp:408] conv_u1c-d -> u1d
I0428 15:09:13.612920  5145 net.cpp:150] Setting up conv_u1c-d
I0428 15:09:13.612928  5145 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0428 15:09:13.612931  5145 net.cpp:165] Memory required for data: 1110443840
I0428 15:09:13.612936  5145 layer_factory.hpp:77] Creating layer bn_u1d
I0428 15:09:13.612942  5145 net.cpp:100] Creating Layer bn_u1d
I0428 15:09:13.612946  5145 net.cpp:434] bn_u1d <- u1d
I0428 15:09:13.612949  5145 net.cpp:395] bn_u1d -> u1d (in-place)
I0428 15:09:13.613163  5145 net.cpp:150] Setting up bn_u1d
I0428 15:09:13.613171  5145 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0428 15:09:13.613174  5145 net.cpp:165] Memory required for data: 1118316352
I0428 15:09:13.613193  5145 layer_factory.hpp:77] Creating layer sc_u1d
I0428 15:09:13.613200  5145 net.cpp:100] Creating Layer sc_u1d
I0428 15:09:13.613204  5145 net.cpp:434] sc_u1d <- u1d
I0428 15:09:13.613209  5145 net.cpp:395] sc_u1d -> u1d (in-place)
I0428 15:09:13.613250  5145 layer_factory.hpp:77] Creating layer sc_u1d
I0428 15:09:13.613385  5145 net.cpp:150] Setting up sc_u1d
I0428 15:09:13.613394  5145 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0428 15:09:13.613395  5145 net.cpp:165] Memory required for data: 1126188864
I0428 15:09:13.613401  5145 layer_factory.hpp:77] Creating layer relu_u1d
I0428 15:09:13.613405  5145 net.cpp:100] Creating Layer relu_u1d
I0428 15:09:13.613409  5145 net.cpp:434] relu_u1d <- u1d
I0428 15:09:13.613412  5145 net.cpp:395] relu_u1d -> u1d (in-place)
I0428 15:09:13.614248  5145 net.cpp:150] Setting up relu_u1d
I0428 15:09:13.614262  5145 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0428 15:09:13.614265  5145 net.cpp:165] Memory required for data: 1134061376
I0428 15:09:13.614269  5145 layer_factory.hpp:77] Creating layer upconv_u1d_u0a
I0428 15:09:13.614276  5145 net.cpp:100] Creating Layer upconv_u1d_u0a
I0428 15:09:13.614279  5145 net.cpp:434] upconv_u1d_u0a <- u1d
I0428 15:09:13.614286  5145 net.cpp:408] upconv_u1d_u0a -> u0a
I0428 15:09:13.614998  5145 net.cpp:150] Setting up upconv_u1d_u0a
I0428 15:09:13.615008  5145 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0428 15:09:13.615010  5145 net.cpp:165] Memory required for data: 1165551424
I0428 15:09:13.615017  5145 layer_factory.hpp:77] Creating layer bn_u0a
I0428 15:09:13.615022  5145 net.cpp:100] Creating Layer bn_u0a
I0428 15:09:13.615025  5145 net.cpp:434] bn_u0a <- u0a
I0428 15:09:13.615030  5145 net.cpp:395] bn_u0a -> u0a (in-place)
I0428 15:09:13.615289  5145 net.cpp:150] Setting up bn_u0a
I0428 15:09:13.615298  5145 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0428 15:09:13.615299  5145 net.cpp:165] Memory required for data: 1197041472
I0428 15:09:13.615306  5145 layer_factory.hpp:77] Creating layer sc_u0a
I0428 15:09:13.615312  5145 net.cpp:100] Creating Layer sc_u0a
I0428 15:09:13.615315  5145 net.cpp:434] sc_u0a <- u0a
I0428 15:09:13.615319  5145 net.cpp:395] sc_u0a -> u0a (in-place)
I0428 15:09:13.615358  5145 layer_factory.hpp:77] Creating layer sc_u0a
I0428 15:09:13.615577  5145 net.cpp:150] Setting up sc_u0a
I0428 15:09:13.615586  5145 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0428 15:09:13.615588  5145 net.cpp:165] Memory required for data: 1228531520
I0428 15:09:13.615593  5145 layer_factory.hpp:77] Creating layer relu_u0a
I0428 15:09:13.615599  5145 net.cpp:100] Creating Layer relu_u0a
I0428 15:09:13.615602  5145 net.cpp:434] relu_u0a <- u0a
I0428 15:09:13.615607  5145 net.cpp:395] relu_u0a -> u0a (in-place)
I0428 15:09:13.615787  5145 net.cpp:150] Setting up relu_u0a
I0428 15:09:13.615797  5145 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0428 15:09:13.615799  5145 net.cpp:165] Memory required for data: 1260021568
I0428 15:09:13.615802  5145 layer_factory.hpp:77] Creating layer u0a_relu_u0a_0_split
I0428 15:09:13.615806  5145 net.cpp:100] Creating Layer u0a_relu_u0a_0_split
I0428 15:09:13.615810  5145 net.cpp:434] u0a_relu_u0a_0_split <- u0a
I0428 15:09:13.615815  5145 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_0
I0428 15:09:13.615821  5145 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_1
I0428 15:09:13.615865  5145 net.cpp:150] Setting up u0a_relu_u0a_0_split
I0428 15:09:13.615875  5145 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0428 15:09:13.615878  5145 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0428 15:09:13.615880  5145 net.cpp:165] Memory required for data: 1323001664
I0428 15:09:13.615882  5145 layer_factory.hpp:77] Creating layer crop_d0c-d0cc
I0428 15:09:13.615888  5145 net.cpp:100] Creating Layer crop_d0c-d0cc
I0428 15:09:13.615891  5145 net.cpp:434] crop_d0c-d0cc <- d0c_relu_d0c_0_split_1
I0428 15:09:13.615895  5145 net.cpp:434] crop_d0c-d0cc <- u0a_relu_u0a_0_split_0
I0428 15:09:13.615900  5145 net.cpp:408] crop_d0c-d0cc -> d0cc
I0428 15:09:13.615926  5145 net.cpp:150] Setting up crop_d0c-d0cc
I0428 15:09:13.615932  5145 net.cpp:157] Top shape: 1 64 248 248 (3936256)
I0428 15:09:13.615934  5145 net.cpp:165] Memory required for data: 1338746688
I0428 15:09:13.615936  5145 layer_factory.hpp:77] Creating layer concat_d0cc_u0a-b
I0428 15:09:13.615942  5145 net.cpp:100] Creating Layer concat_d0cc_u0a-b
I0428 15:09:13.615944  5145 net.cpp:434] concat_d0cc_u0a-b <- u0a_relu_u0a_0_split_1
I0428 15:09:13.615948  5145 net.cpp:434] concat_d0cc_u0a-b <- d0cc
I0428 15:09:13.615953  5145 net.cpp:408] concat_d0cc_u0a-b -> u0b
I0428 15:09:13.615978  5145 net.cpp:150] Setting up concat_d0cc_u0a-b
I0428 15:09:13.615983  5145 net.cpp:157] Top shape: 1 192 248 248 (11808768)
I0428 15:09:13.615986  5145 net.cpp:165] Memory required for data: 1385981760
I0428 15:09:13.615988  5145 layer_factory.hpp:77] Creating layer conv_u0b-c
I0428 15:09:13.615996  5145 net.cpp:100] Creating Layer conv_u0b-c
I0428 15:09:13.615999  5145 net.cpp:434] conv_u0b-c <- u0b
I0428 15:09:13.616004  5145 net.cpp:408] conv_u0b-c -> u0c
I0428 15:09:13.616967  5145 net.cpp:150] Setting up conv_u0b-c
I0428 15:09:13.616976  5145 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0428 15:09:13.616978  5145 net.cpp:165] Memory required for data: 1401473856
I0428 15:09:13.616994  5145 layer_factory.hpp:77] Creating layer bn_u0c
I0428 15:09:13.616999  5145 net.cpp:100] Creating Layer bn_u0c
I0428 15:09:13.617003  5145 net.cpp:434] bn_u0c <- u0c
I0428 15:09:13.617008  5145 net.cpp:395] bn_u0c -> u0c (in-place)
I0428 15:09:13.618252  5145 net.cpp:150] Setting up bn_u0c
I0428 15:09:13.618266  5145 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0428 15:09:13.618269  5145 net.cpp:165] Memory required for data: 1416965952
I0428 15:09:13.618278  5145 layer_factory.hpp:77] Creating layer sc_u0c
I0428 15:09:13.618284  5145 net.cpp:100] Creating Layer sc_u0c
I0428 15:09:13.618288  5145 net.cpp:434] sc_u0c <- u0c
I0428 15:09:13.618294  5145 net.cpp:395] sc_u0c -> u0c (in-place)
I0428 15:09:13.618338  5145 layer_factory.hpp:77] Creating layer sc_u0c
I0428 15:09:13.618547  5145 net.cpp:150] Setting up sc_u0c
I0428 15:09:13.618556  5145 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0428 15:09:13.618559  5145 net.cpp:165] Memory required for data: 1432458048
I0428 15:09:13.618564  5145 layer_factory.hpp:77] Creating layer relu_u0c
I0428 15:09:13.618569  5145 net.cpp:100] Creating Layer relu_u0c
I0428 15:09:13.618572  5145 net.cpp:434] relu_u0c <- u0c
I0428 15:09:13.618577  5145 net.cpp:395] relu_u0c -> u0c (in-place)
I0428 15:09:13.618767  5145 net.cpp:150] Setting up relu_u0c
I0428 15:09:13.618777  5145 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0428 15:09:13.618779  5145 net.cpp:165] Memory required for data: 1447950144
I0428 15:09:13.618783  5145 layer_factory.hpp:77] Creating layer conv_u0c-d
I0428 15:09:13.618790  5145 net.cpp:100] Creating Layer conv_u0c-d
I0428 15:09:13.618794  5145 net.cpp:434] conv_u0c-d <- u0c
I0428 15:09:13.618799  5145 net.cpp:408] conv_u0c-d -> u0d
I0428 15:09:13.619326  5145 net.cpp:150] Setting up conv_u0c-d
I0428 15:09:13.619334  5145 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0428 15:09:13.619338  5145 net.cpp:165] Memory required for data: 1463191360
I0428 15:09:13.619354  5145 layer_factory.hpp:77] Creating layer bn_u0d
I0428 15:09:13.619359  5145 net.cpp:100] Creating Layer bn_u0d
I0428 15:09:13.619362  5145 net.cpp:434] bn_u0d <- u0d
I0428 15:09:13.619366  5145 net.cpp:395] bn_u0d -> u0d (in-place)
I0428 15:09:13.619618  5145 net.cpp:150] Setting up bn_u0d
I0428 15:09:13.619626  5145 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0428 15:09:13.619628  5145 net.cpp:165] Memory required for data: 1478432576
I0428 15:09:13.619634  5145 layer_factory.hpp:77] Creating layer sc_u0d
I0428 15:09:13.619640  5145 net.cpp:100] Creating Layer sc_u0d
I0428 15:09:13.619643  5145 net.cpp:434] sc_u0d <- u0d
I0428 15:09:13.619647  5145 net.cpp:395] sc_u0d -> u0d (in-place)
I0428 15:09:13.619686  5145 layer_factory.hpp:77] Creating layer sc_u0d
I0428 15:09:13.619889  5145 net.cpp:150] Setting up sc_u0d
I0428 15:09:13.619897  5145 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0428 15:09:13.619900  5145 net.cpp:165] Memory required for data: 1493673792
I0428 15:09:13.619905  5145 layer_factory.hpp:77] Creating layer relu_u0d
I0428 15:09:13.619910  5145 net.cpp:100] Creating Layer relu_u0d
I0428 15:09:13.619913  5145 net.cpp:434] relu_u0d <- u0d
I0428 15:09:13.619916  5145 net.cpp:395] relu_u0d -> u0d (in-place)
I0428 15:09:13.620100  5145 net.cpp:150] Setting up relu_u0d
I0428 15:09:13.620108  5145 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0428 15:09:13.620112  5145 net.cpp:165] Memory required for data: 1508915008
I0428 15:09:13.620115  5145 layer_factory.hpp:77] Creating layer conv_u0d-score
I0428 15:09:13.620121  5145 net.cpp:100] Creating Layer conv_u0d-score
I0428 15:09:13.620124  5145 net.cpp:434] conv_u0d-score <- u0d
I0428 15:09:13.620129  5145 net.cpp:408] conv_u0d-score -> score
I0428 15:09:13.620429  5145 net.cpp:150] Setting up conv_u0d-score
I0428 15:09:13.620436  5145 net.cpp:157] Top shape: 1 4 244 244 (238144)
I0428 15:09:13.620438  5145 net.cpp:165] Memory required for data: 1509867584
I0428 15:09:13.620445  5145 layer_factory.hpp:77] Creating layer loss
I0428 15:09:13.620450  5145 net.cpp:100] Creating Layer loss
I0428 15:09:13.620465  5145 net.cpp:434] loss <- score
I0428 15:09:13.620468  5145 net.cpp:434] loss <- label
I0428 15:09:13.620472  5145 net.cpp:434] loss <- weights
I0428 15:09:13.620477  5145 net.cpp:408] loss -> loss
I0428 15:09:13.620484  5145 layer_factory.hpp:77] Creating layer loss
I0428 15:09:13.622728  5145 net.cpp:150] Setting up loss
I0428 15:09:13.622743  5145 net.cpp:157] Top shape: (1)
I0428 15:09:13.622745  5145 net.cpp:160]     with loss weight 1
I0428 15:09:13.622755  5145 net.cpp:165] Memory required for data: 1509867588
I0428 15:09:13.622757  5145 net.cpp:226] loss needs backward computation.
I0428 15:09:13.622763  5145 net.cpp:226] conv_u0d-score needs backward computation.
I0428 15:09:13.622766  5145 net.cpp:226] relu_u0d needs backward computation.
I0428 15:09:13.622768  5145 net.cpp:226] sc_u0d needs backward computation.
I0428 15:09:13.622771  5145 net.cpp:226] bn_u0d needs backward computation.
I0428 15:09:13.622773  5145 net.cpp:226] conv_u0c-d needs backward computation.
I0428 15:09:13.622776  5145 net.cpp:226] relu_u0c needs backward computation.
I0428 15:09:13.622778  5145 net.cpp:226] sc_u0c needs backward computation.
I0428 15:09:13.622781  5145 net.cpp:226] bn_u0c needs backward computation.
I0428 15:09:13.622782  5145 net.cpp:226] conv_u0b-c needs backward computation.
I0428 15:09:13.622786  5145 net.cpp:226] concat_d0cc_u0a-b needs backward computation.
I0428 15:09:13.622787  5145 net.cpp:226] crop_d0c-d0cc needs backward computation.
I0428 15:09:13.622792  5145 net.cpp:226] u0a_relu_u0a_0_split needs backward computation.
I0428 15:09:13.622794  5145 net.cpp:226] relu_u0a needs backward computation.
I0428 15:09:13.622797  5145 net.cpp:226] sc_u0a needs backward computation.
I0428 15:09:13.622798  5145 net.cpp:226] bn_u0a needs backward computation.
I0428 15:09:13.622800  5145 net.cpp:226] upconv_u1d_u0a needs backward computation.
I0428 15:09:13.622804  5145 net.cpp:226] relu_u1d needs backward computation.
I0428 15:09:13.622807  5145 net.cpp:226] sc_u1d needs backward computation.
I0428 15:09:13.622808  5145 net.cpp:226] bn_u1d needs backward computation.
I0428 15:09:13.622810  5145 net.cpp:226] conv_u1c-d needs backward computation.
I0428 15:09:13.622813  5145 net.cpp:226] relu_u1c needs backward computation.
I0428 15:09:13.622815  5145 net.cpp:226] sc_u1c needs backward computation.
I0428 15:09:13.622817  5145 net.cpp:226] bn_u1c needs backward computation.
I0428 15:09:13.622819  5145 net.cpp:226] conv_u1b-c needs backward computation.
I0428 15:09:13.622822  5145 net.cpp:226] concat_d1cc_u1a-b needs backward computation.
I0428 15:09:13.622825  5145 net.cpp:226] crop_d1c-d1cc needs backward computation.
I0428 15:09:13.622844  5145 net.cpp:226] u1a_relu_u1a_0_split needs backward computation.
I0428 15:09:13.622848  5145 net.cpp:226] relu_u1a needs backward computation.
I0428 15:09:13.622850  5145 net.cpp:226] sc_u1a needs backward computation.
I0428 15:09:13.622853  5145 net.cpp:226] bn_u1a needs backward computation.
I0428 15:09:13.622854  5145 net.cpp:226] upconv_u2d_u1a needs backward computation.
I0428 15:09:13.622858  5145 net.cpp:226] relu_u2d needs backward computation.
I0428 15:09:13.622860  5145 net.cpp:226] sc_u2d needs backward computation.
I0428 15:09:13.622862  5145 net.cpp:226] bn_u2d needs backward computation.
I0428 15:09:13.622864  5145 net.cpp:226] conv_u2c-d needs backward computation.
I0428 15:09:13.622867  5145 net.cpp:226] relu_u2c needs backward computation.
I0428 15:09:13.622870  5145 net.cpp:226] sc_u2c needs backward computation.
I0428 15:09:13.622872  5145 net.cpp:226] bn_u2c needs backward computation.
I0428 15:09:13.622874  5145 net.cpp:226] conv_u2b-c needs backward computation.
I0428 15:09:13.622877  5145 net.cpp:226] concat_d2cc_u2a-b needs backward computation.
I0428 15:09:13.622881  5145 net.cpp:226] crop_d2c-d2cc needs backward computation.
I0428 15:09:13.622884  5145 net.cpp:226] u2a_relu_u2a_0_split needs backward computation.
I0428 15:09:13.622887  5145 net.cpp:226] relu_u2a needs backward computation.
I0428 15:09:13.622889  5145 net.cpp:226] sc_u2a needs backward computation.
I0428 15:09:13.622903  5145 net.cpp:226] bn_u2a needs backward computation.
I0428 15:09:13.622905  5145 net.cpp:226] upconv_u3d_u2a needs backward computation.
I0428 15:09:13.622908  5145 net.cpp:226] relu_u3d needs backward computation.
I0428 15:09:13.622910  5145 net.cpp:226] sc_u3d needs backward computation.
I0428 15:09:13.622913  5145 net.cpp:226] bn_u3d needs backward computation.
I0428 15:09:13.622916  5145 net.cpp:226] conv_u3c-d needs backward computation.
I0428 15:09:13.622918  5145 net.cpp:226] relu_u3c needs backward computation.
I0428 15:09:13.622921  5145 net.cpp:226] sc_u3c needs backward computation.
I0428 15:09:13.622925  5145 net.cpp:226] bn_u3c needs backward computation.
I0428 15:09:13.622927  5145 net.cpp:226] conv_u3b-c needs backward computation.
I0428 15:09:13.622930  5145 net.cpp:226] concat_d3cc_u3a-b needs backward computation.
I0428 15:09:13.622933  5145 net.cpp:226] crop_d3c-d3cc needs backward computation.
I0428 15:09:13.622937  5145 net.cpp:226] u3a_relu_u3a_0_split needs backward computation.
I0428 15:09:13.622941  5145 net.cpp:226] relu_u3a needs backward computation.
I0428 15:09:13.622942  5145 net.cpp:226] sc_u3a needs backward computation.
I0428 15:09:13.622946  5145 net.cpp:226] bn_u3a needs backward computation.
I0428 15:09:13.622948  5145 net.cpp:226] upconv_d4c_u3a needs backward computation.
I0428 15:09:13.622951  5145 net.cpp:226] relu_d4c needs backward computation.
I0428 15:09:13.622953  5145 net.cpp:226] sc_d4c needs backward computation.
I0428 15:09:13.622956  5145 net.cpp:226] bn_d4c needs backward computation.
I0428 15:09:13.622958  5145 net.cpp:226] conv_d4b-c needs backward computation.
I0428 15:09:13.622961  5145 net.cpp:226] relu_d4b needs backward computation.
I0428 15:09:13.622964  5145 net.cpp:226] sc_d4b needs backward computation.
I0428 15:09:13.622967  5145 net.cpp:226] bn_d4b needs backward computation.
I0428 15:09:13.622969  5145 net.cpp:226] conv_d4a-b needs backward computation.
I0428 15:09:13.622972  5145 net.cpp:226] pool_d3c-4a needs backward computation.
I0428 15:09:13.622975  5145 net.cpp:226] d3c_relu_d3c_0_split needs backward computation.
I0428 15:09:13.622978  5145 net.cpp:226] relu_d3c needs backward computation.
I0428 15:09:13.622982  5145 net.cpp:226] sc_d3c needs backward computation.
I0428 15:09:13.622984  5145 net.cpp:226] bn_d3c needs backward computation.
I0428 15:09:13.622987  5145 net.cpp:226] conv_d3b-c needs backward computation.
I0428 15:09:13.622989  5145 net.cpp:226] relu_d3b needs backward computation.
I0428 15:09:13.622992  5145 net.cpp:226] sc_d3b needs backward computation.
I0428 15:09:13.622994  5145 net.cpp:226] bn_d3b needs backward computation.
I0428 15:09:13.622997  5145 net.cpp:226] conv_d3a-b needs backward computation.
I0428 15:09:13.623000  5145 net.cpp:226] pool_d2c-3a needs backward computation.
I0428 15:09:13.623003  5145 net.cpp:226] d2c_relu_d2c_0_split needs backward computation.
I0428 15:09:13.623006  5145 net.cpp:226] relu_d2c needs backward computation.
I0428 15:09:13.623009  5145 net.cpp:226] sc_d2c needs backward computation.
I0428 15:09:13.623011  5145 net.cpp:226] bn_d2c needs backward computation.
I0428 15:09:13.623014  5145 net.cpp:226] conv_d2b-c needs backward computation.
I0428 15:09:13.623016  5145 net.cpp:226] relu_d2b needs backward computation.
I0428 15:09:13.623019  5145 net.cpp:226] sc_d2b needs backward computation.
I0428 15:09:13.623021  5145 net.cpp:226] bn_d2b needs backward computation.
I0428 15:09:13.623024  5145 net.cpp:226] conv_d2a-b needs backward computation.
I0428 15:09:13.623028  5145 net.cpp:226] pool_d1c-2a needs backward computation.
I0428 15:09:13.623030  5145 net.cpp:226] d1c_relu_d1c_0_split needs backward computation.
I0428 15:09:13.623034  5145 net.cpp:226] relu_d1c needs backward computation.
I0428 15:09:13.623036  5145 net.cpp:226] sc_d1c needs backward computation.
I0428 15:09:13.623039  5145 net.cpp:226] bn_d1c needs backward computation.
I0428 15:09:13.623040  5145 net.cpp:226] conv_d1b-c needs backward computation.
I0428 15:09:13.623044  5145 net.cpp:226] relu_d1b needs backward computation.
I0428 15:09:13.623050  5145 net.cpp:226] sc_d1b needs backward computation.
I0428 15:09:13.623054  5145 net.cpp:226] bn_d1b needs backward computation.
I0428 15:09:13.623055  5145 net.cpp:226] conv_d1a-b needs backward computation.
I0428 15:09:13.623059  5145 net.cpp:226] pool_d0c-1a needs backward computation.
I0428 15:09:13.623061  5145 net.cpp:226] d0c_relu_d0c_0_split needs backward computation.
I0428 15:09:13.623064  5145 net.cpp:226] relu_d0c needs backward computation.
I0428 15:09:13.623067  5145 net.cpp:226] sc_d0c needs backward computation.
I0428 15:09:13.623070  5145 net.cpp:226] bn_d0c needs backward computation.
I0428 15:09:13.623072  5145 net.cpp:226] conv_d0b-c needs backward computation.
I0428 15:09:13.623075  5145 net.cpp:226] relu_d0b needs backward computation.
I0428 15:09:13.623077  5145 net.cpp:226] sc_d0b needs backward computation.
I0428 15:09:13.623080  5145 net.cpp:226] bn_d0b needs backward computation.
I0428 15:09:13.623082  5145 net.cpp:226] conv_d0a-b needs backward computation.
I0428 15:09:13.623085  5145 net.cpp:228] loaddata does not need backward computation.
I0428 15:09:13.623096  5145 net.cpp:270] This network produces output loss
I0428 15:09:13.623167  5145 net.cpp:283] Network initialization done.
I0428 15:09:13.623459  5145 solver.cpp:60] Solver scaffolding done.
I0428 15:09:13.642058  5145 solver.cpp:337] Iteration 0, Testing net (#0)
I0428 15:09:13.663066  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 15:09:13.663079  5145 net.cpp:693] Ignoring source layer visualize
I0428 15:09:13.663081  5145 net.cpp:693] Ignoring source layer fake
I0428 15:18:56.416694  5145 solver.cpp:404]     Test net output #0: loss = 1.56373 (* 1 = 1.56373 loss)
I0428 15:18:56.970158  5145 solver.cpp:228] Iteration 0, loss = 1.53263
I0428 15:18:56.970201  5145 solver.cpp:244]     Train net output #0: loss = 1.53263 (* 1 = 1.53263 loss)
I0428 15:18:56.970208  5145 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0428 15:19:48.201007  5145 solver.cpp:228] Iteration 100, loss = 0.407842
I0428 15:19:48.201148  5145 solver.cpp:244]     Train net output #0: loss = 0.407842 (* 1 = 0.407842 loss)
I0428 15:19:48.201154  5145 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0428 15:20:39.505481  5145 solver.cpp:228] Iteration 200, loss = 0.287997
I0428 15:20:39.505645  5145 solver.cpp:244]     Train net output #0: loss = 0.287997 (* 1 = 0.287997 loss)
I0428 15:20:39.505651  5145 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0428 15:21:31.941092  5145 solver.cpp:228] Iteration 300, loss = 0.448781
I0428 15:21:31.941227  5145 solver.cpp:244]     Train net output #0: loss = 0.448781 (* 1 = 0.448781 loss)
I0428 15:21:31.941233  5145 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0428 15:22:23.260870  5145 solver.cpp:228] Iteration 400, loss = 0.440867
I0428 15:22:23.261019  5145 solver.cpp:244]     Train net output #0: loss = 0.440867 (* 1 = 0.440867 loss)
I0428 15:22:23.261028  5145 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0428 15:23:14.536109  5145 solver.cpp:228] Iteration 500, loss = 0.278844
I0428 15:23:14.536255  5145 solver.cpp:244]     Train net output #0: loss = 0.278844 (* 1 = 0.278844 loss)
I0428 15:23:14.536262  5145 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0428 15:24:07.301642  5145 solver.cpp:228] Iteration 600, loss = 0.329562
I0428 15:24:07.301807  5145 solver.cpp:244]     Train net output #0: loss = 0.329562 (* 1 = 0.329562 loss)
I0428 15:24:07.301815  5145 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0428 15:24:58.516552  5145 solver.cpp:228] Iteration 700, loss = 0.341891
I0428 15:24:58.516696  5145 solver.cpp:244]     Train net output #0: loss = 0.341891 (* 1 = 0.341891 loss)
I0428 15:24:58.516703  5145 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0428 15:25:51.770505  5145 solver.cpp:228] Iteration 800, loss = 0.366462
I0428 15:25:51.770676  5145 solver.cpp:244]     Train net output #0: loss = 0.366462 (* 1 = 0.366462 loss)
I0428 15:25:51.770684  5145 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0428 15:26:42.900625  5145 solver.cpp:228] Iteration 900, loss = 1.01723
I0428 15:26:42.900774  5145 solver.cpp:244]     Train net output #0: loss = 1.01723 (* 1 = 1.01723 loss)
I0428 15:26:42.900780  5145 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0428 15:27:33.851455  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_1000.caffemodel
I0428 15:27:50.310991  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_1000.solverstate
I0428 15:27:50.746460  5145 solver.cpp:337] Iteration 1000, Testing net (#0)
I0428 15:27:50.746644  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 15:27:50.746656  5145 net.cpp:693] Ignoring source layer visualize
I0428 15:27:50.746661  5145 net.cpp:693] Ignoring source layer fake
I0428 15:32:52.257820  5145 solver.cpp:404]     Test net output #0: loss = 0.56931 (* 1 = 0.56931 loss)
I0428 15:32:52.575235  5145 solver.cpp:228] Iteration 1000, loss = 0.741386
I0428 15:32:52.575255  5145 solver.cpp:244]     Train net output #0: loss = 0.741386 (* 1 = 0.741386 loss)
I0428 15:32:52.575276  5145 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0428 15:33:43.871992  5145 solver.cpp:228] Iteration 1100, loss = 0.608982
I0428 15:33:43.872148  5145 solver.cpp:244]     Train net output #0: loss = 0.608982 (* 1 = 0.608982 loss)
I0428 15:33:43.872158  5145 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0428 15:34:36.958526  5145 solver.cpp:228] Iteration 1200, loss = 0.357883
I0428 15:34:36.958676  5145 solver.cpp:244]     Train net output #0: loss = 0.357883 (* 1 = 0.357883 loss)
I0428 15:34:36.958683  5145 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0428 15:35:28.327246  5145 solver.cpp:228] Iteration 1300, loss = 0.355565
I0428 15:35:28.327379  5145 solver.cpp:244]     Train net output #0: loss = 0.355565 (* 1 = 0.355565 loss)
I0428 15:35:28.327385  5145 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0428 15:36:19.571058  5145 solver.cpp:228] Iteration 1400, loss = 0.451783
I0428 15:36:19.571199  5145 solver.cpp:244]     Train net output #0: loss = 0.451783 (* 1 = 0.451783 loss)
I0428 15:36:19.571207  5145 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0428 15:37:12.688907  5145 solver.cpp:228] Iteration 1500, loss = 0.447455
I0428 15:37:12.689057  5145 solver.cpp:244]     Train net output #0: loss = 0.447455 (* 1 = 0.447455 loss)
I0428 15:37:12.689065  5145 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0428 15:38:04.044694  5145 solver.cpp:228] Iteration 1600, loss = 0.443816
I0428 15:38:04.044832  5145 solver.cpp:244]     Train net output #0: loss = 0.443816 (* 1 = 0.443816 loss)
I0428 15:38:04.044839  5145 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0428 15:38:55.342154  5145 solver.cpp:228] Iteration 1700, loss = 0.546544
I0428 15:38:55.342304  5145 solver.cpp:244]     Train net output #0: loss = 0.546544 (* 1 = 0.546544 loss)
I0428 15:38:55.342313  5145 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0428 15:39:46.802760  5145 solver.cpp:228] Iteration 1800, loss = 0.383602
I0428 15:39:46.802939  5145 solver.cpp:244]     Train net output #0: loss = 0.383602 (* 1 = 0.383602 loss)
I0428 15:39:46.802945  5145 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0428 15:40:39.902886  5145 solver.cpp:228] Iteration 1900, loss = 0.506055
I0428 15:40:39.904258  5145 solver.cpp:244]     Train net output #0: loss = 0.506055 (* 1 = 0.506055 loss)
I0428 15:40:39.904278  5145 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0428 15:41:30.909642  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_2000.caffemodel
I0428 15:41:56.294184  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_2000.solverstate
I0428 15:41:56.743826  5145 solver.cpp:337] Iteration 2000, Testing net (#0)
I0428 15:41:56.744000  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 15:41:56.744010  5145 net.cpp:693] Ignoring source layer visualize
I0428 15:41:56.744014  5145 net.cpp:693] Ignoring source layer fake
I0428 15:46:59.071651  5145 solver.cpp:404]     Test net output #0: loss = 0.470198 (* 1 = 0.470198 loss)
I0428 15:46:59.391083  5145 solver.cpp:228] Iteration 2000, loss = 0.287137
I0428 15:46:59.391119  5145 solver.cpp:244]     Train net output #0: loss = 0.287137 (* 1 = 0.287137 loss)
I0428 15:46:59.391125  5145 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0428 15:47:50.750604  5145 solver.cpp:228] Iteration 2100, loss = 0.249659
I0428 15:47:50.750767  5145 solver.cpp:244]     Train net output #0: loss = 0.249659 (* 1 = 0.249659 loss)
I0428 15:47:50.750774  5145 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0428 15:48:43.809291  5145 solver.cpp:228] Iteration 2200, loss = 0.203887
I0428 15:48:43.809424  5145 solver.cpp:244]     Train net output #0: loss = 0.203887 (* 1 = 0.203887 loss)
I0428 15:48:43.809432  5145 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0428 15:49:35.194598  5145 solver.cpp:228] Iteration 2300, loss = 0.141673
I0428 15:49:35.194761  5145 solver.cpp:244]     Train net output #0: loss = 0.141673 (* 1 = 0.141673 loss)
I0428 15:49:35.194768  5145 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0428 15:50:26.470876  5145 solver.cpp:228] Iteration 2400, loss = 0.395496
I0428 15:50:26.471925  5145 solver.cpp:244]     Train net output #0: loss = 0.395496 (* 1 = 0.395496 loss)
I0428 15:50:26.471930  5145 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0428 15:51:19.624032  5145 solver.cpp:228] Iteration 2500, loss = 0.276644
I0428 15:51:19.624202  5145 solver.cpp:244]     Train net output #0: loss = 0.276644 (* 1 = 0.276644 loss)
I0428 15:51:19.624209  5145 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0428 15:52:10.955854  5145 solver.cpp:228] Iteration 2600, loss = 0.311928
I0428 15:52:10.957986  5145 solver.cpp:244]     Train net output #0: loss = 0.311928 (* 1 = 0.311928 loss)
I0428 15:52:10.958009  5145 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0428 15:53:02.253167  5145 solver.cpp:228] Iteration 2700, loss = 0.392048
I0428 15:53:02.253314  5145 solver.cpp:244]     Train net output #0: loss = 0.392048 (* 1 = 0.392048 loss)
I0428 15:53:02.253321  5145 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0428 15:53:53.521157  5145 solver.cpp:228] Iteration 2800, loss = 0.144809
I0428 15:53:53.521307  5145 solver.cpp:244]     Train net output #0: loss = 0.144809 (* 1 = 0.144809 loss)
I0428 15:53:53.521314  5145 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0428 15:54:46.466423  5145 solver.cpp:228] Iteration 2900, loss = 0.285594
I0428 15:54:46.466581  5145 solver.cpp:244]     Train net output #0: loss = 0.285594 (* 1 = 0.285594 loss)
I0428 15:54:46.466588  5145 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0428 15:55:37.464010  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_3000.caffemodel
I0428 15:55:57.064002  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_3000.solverstate
I0428 15:55:57.265949  5145 solver.cpp:337] Iteration 3000, Testing net (#0)
I0428 15:55:57.266075  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 15:55:57.266080  5145 net.cpp:693] Ignoring source layer visualize
I0428 15:55:57.266083  5145 net.cpp:693] Ignoring source layer fake
I0428 16:00:59.832047  5145 solver.cpp:404]     Test net output #0: loss = 0.4491 (* 1 = 0.4491 loss)
I0428 16:01:00.153146  5145 solver.cpp:228] Iteration 3000, loss = 0.363371
I0428 16:01:00.153187  5145 solver.cpp:244]     Train net output #0: loss = 0.363371 (* 1 = 0.363371 loss)
I0428 16:01:00.153194  5145 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0428 16:01:51.592865  5145 solver.cpp:228] Iteration 3100, loss = 0.123117
I0428 16:01:51.593036  5145 solver.cpp:244]     Train net output #0: loss = 0.123117 (* 1 = 0.123117 loss)
I0428 16:01:51.593044  5145 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0428 16:02:58.286007  5145 solver.cpp:228] Iteration 3200, loss = 0.242871
I0428 16:02:58.286152  5145 solver.cpp:244]     Train net output #0: loss = 0.242871 (* 1 = 0.242871 loss)
I0428 16:02:58.286160  5145 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0428 16:03:49.402159  5145 solver.cpp:228] Iteration 3300, loss = 0.346318
I0428 16:03:49.402328  5145 solver.cpp:244]     Train net output #0: loss = 0.346318 (* 1 = 0.346318 loss)
I0428 16:03:49.402336  5145 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0428 16:04:55.540283  5145 solver.cpp:228] Iteration 3400, loss = 0.274674
I0428 16:04:55.540431  5145 solver.cpp:244]     Train net output #0: loss = 0.274674 (* 1 = 0.274674 loss)
I0428 16:04:55.540438  5145 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0428 16:05:46.359736  5145 solver.cpp:228] Iteration 3500, loss = 0.370206
I0428 16:05:46.359880  5145 solver.cpp:244]     Train net output #0: loss = 0.370206 (* 1 = 0.370206 loss)
I0428 16:05:46.359887  5145 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0428 16:06:37.815167  5145 solver.cpp:228] Iteration 3600, loss = 0.395225
I0428 16:06:37.815758  5145 solver.cpp:244]     Train net output #0: loss = 0.395225 (* 1 = 0.395225 loss)
I0428 16:06:37.815764  5145 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0428 16:07:44.158390  5145 solver.cpp:228] Iteration 3700, loss = 0.0651691
I0428 16:07:44.158550  5145 solver.cpp:244]     Train net output #0: loss = 0.0651691 (* 1 = 0.0651691 loss)
I0428 16:07:44.158557  5145 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0428 16:08:35.310174  5145 solver.cpp:228] Iteration 3800, loss = 0.0372255
I0428 16:08:35.310317  5145 solver.cpp:244]     Train net output #0: loss = 0.0372255 (* 1 = 0.0372255 loss)
I0428 16:08:35.310324  5145 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0428 16:09:26.688190  5145 solver.cpp:228] Iteration 3900, loss = 0.0347641
I0428 16:09:26.688359  5145 solver.cpp:244]     Train net output #0: loss = 0.0347641 (* 1 = 0.0347641 loss)
I0428 16:09:26.688365  5145 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0428 16:10:34.527526  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_4000.caffemodel
I0428 16:10:39.265177  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_4000.solverstate
I0428 16:10:39.468153  5145 solver.cpp:337] Iteration 4000, Testing net (#0)
I0428 16:10:39.468258  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 16:10:39.468264  5145 net.cpp:693] Ignoring source layer visualize
I0428 16:10:39.468268  5145 net.cpp:693] Ignoring source layer fake
I0428 16:15:42.066346  5145 solver.cpp:404]     Test net output #0: loss = 0.406081 (* 1 = 0.406081 loss)
I0428 16:15:42.384557  5145 solver.cpp:228] Iteration 4000, loss = 0.568267
I0428 16:15:42.384574  5145 solver.cpp:244]     Train net output #0: loss = 0.568267 (* 1 = 0.568267 loss)
I0428 16:15:42.384598  5145 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0428 16:16:33.818071  5145 solver.cpp:228] Iteration 4100, loss = 0.421679
I0428 16:16:33.818208  5145 solver.cpp:244]     Train net output #0: loss = 0.421679 (* 1 = 0.421679 loss)
I0428 16:16:33.818214  5145 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0428 16:17:25.238975  5145 solver.cpp:228] Iteration 4200, loss = 0.413209
I0428 16:17:25.239122  5145 solver.cpp:244]     Train net output #0: loss = 0.413209 (* 1 = 0.413209 loss)
I0428 16:17:25.239130  5145 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0428 16:18:34.723803  5145 solver.cpp:228] Iteration 4300, loss = 0.499107
I0428 16:18:34.723973  5145 solver.cpp:244]     Train net output #0: loss = 0.499107 (* 1 = 0.499107 loss)
I0428 16:18:34.723981  5145 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0428 16:19:25.579124  5145 solver.cpp:228] Iteration 4400, loss = 0.304982
I0428 16:19:25.579304  5145 solver.cpp:244]     Train net output #0: loss = 0.304982 (* 1 = 0.304982 loss)
I0428 16:19:25.579313  5145 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0428 16:20:17.160027  5145 solver.cpp:228] Iteration 4500, loss = 0.217056
I0428 16:20:17.160179  5145 solver.cpp:244]     Train net output #0: loss = 0.217056 (* 1 = 0.217056 loss)
I0428 16:20:17.160185  5145 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0428 16:21:08.658206  5145 solver.cpp:228] Iteration 4600, loss = 0.301949
I0428 16:21:08.658354  5145 solver.cpp:244]     Train net output #0: loss = 0.301949 (* 1 = 0.301949 loss)
I0428 16:21:08.658361  5145 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0428 16:22:17.691426  5145 solver.cpp:228] Iteration 4700, loss = 0.489599
I0428 16:22:17.691592  5145 solver.cpp:244]     Train net output #0: loss = 0.489599 (* 1 = 0.489599 loss)
I0428 16:22:17.691599  5145 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0428 16:23:09.055420  5145 solver.cpp:228] Iteration 4800, loss = 0.365462
I0428 16:23:09.055575  5145 solver.cpp:244]     Train net output #0: loss = 0.365462 (* 1 = 0.365462 loss)
I0428 16:23:09.055583  5145 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0428 16:24:00.575781  5145 solver.cpp:228] Iteration 4900, loss = 0.360241
I0428 16:24:00.575935  5145 solver.cpp:244]     Train net output #0: loss = 0.360241 (* 1 = 0.360241 loss)
I0428 16:24:00.575942  5145 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0428 16:25:08.540101  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_5000.caffemodel
I0428 16:25:17.526897  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_5000.solverstate
I0428 16:25:17.716785  5145 solver.cpp:337] Iteration 5000, Testing net (#0)
I0428 16:25:17.716874  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 16:25:17.716878  5145 net.cpp:693] Ignoring source layer visualize
I0428 16:25:17.716895  5145 net.cpp:693] Ignoring source layer fake
I0428 16:30:20.672356  5145 solver.cpp:404]     Test net output #0: loss = 0.424952 (* 1 = 0.424952 loss)
I0428 16:30:20.992781  5145 solver.cpp:228] Iteration 5000, loss = 0.369866
I0428 16:30:20.992835  5145 solver.cpp:244]     Train net output #0: loss = 0.369866 (* 1 = 0.369866 loss)
I0428 16:30:20.992841  5145 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0428 16:31:12.440345  5145 solver.cpp:228] Iteration 5100, loss = 0.26038
I0428 16:31:12.440657  5145 solver.cpp:244]     Train net output #0: loss = 0.26038 (* 1 = 0.26038 loss)
I0428 16:31:12.440666  5145 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0428 16:32:03.792805  5145 solver.cpp:228] Iteration 5200, loss = 0.232971
I0428 16:32:03.792960  5145 solver.cpp:244]     Train net output #0: loss = 0.232971 (* 1 = 0.232971 loss)
I0428 16:32:03.792968  5145 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0428 16:33:12.689163  5145 solver.cpp:228] Iteration 5300, loss = 0.224616
I0428 16:33:12.689317  5145 solver.cpp:244]     Train net output #0: loss = 0.224616 (* 1 = 0.224616 loss)
I0428 16:33:12.689324  5145 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0428 16:34:03.397105  5145 solver.cpp:228] Iteration 5400, loss = 0.265295
I0428 16:34:03.397279  5145 solver.cpp:244]     Train net output #0: loss = 0.265295 (* 1 = 0.265295 loss)
I0428 16:34:03.397289  5145 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0428 16:34:54.765260  5145 solver.cpp:228] Iteration 5500, loss = 0.28463
I0428 16:34:54.765411  5145 solver.cpp:244]     Train net output #0: loss = 0.28463 (* 1 = 0.28463 loss)
I0428 16:34:54.765419  5145 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0428 16:35:46.272274  5145 solver.cpp:228] Iteration 5600, loss = 0.229303
I0428 16:35:46.272435  5145 solver.cpp:244]     Train net output #0: loss = 0.229303 (* 1 = 0.229303 loss)
I0428 16:35:46.272442  5145 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0428 16:36:54.358374  5145 solver.cpp:228] Iteration 5700, loss = 0.0975951
I0428 16:36:54.358539  5145 solver.cpp:244]     Train net output #0: loss = 0.0975951 (* 1 = 0.0975951 loss)
I0428 16:36:54.358547  5145 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0428 16:37:45.680071  5145 solver.cpp:228] Iteration 5800, loss = 0.266204
I0428 16:37:45.680218  5145 solver.cpp:244]     Train net output #0: loss = 0.266204 (* 1 = 0.266204 loss)
I0428 16:37:45.680227  5145 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0428 16:38:37.133095  5145 solver.cpp:228] Iteration 5900, loss = 0.252545
I0428 16:38:37.133257  5145 solver.cpp:244]     Train net output #0: loss = 0.252545 (* 1 = 0.252545 loss)
I0428 16:38:37.133266  5145 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0428 16:39:43.607565  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_6000.caffemodel
I0428 16:40:15.781057  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_6000.solverstate
I0428 16:40:15.975600  5145 solver.cpp:337] Iteration 6000, Testing net (#0)
I0428 16:40:15.975706  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 16:40:15.975711  5145 net.cpp:693] Ignoring source layer visualize
I0428 16:40:15.975713  5145 net.cpp:693] Ignoring source layer fake
I0428 16:45:19.157675  5145 solver.cpp:404]     Test net output #0: loss = 0.398309 (* 1 = 0.398309 loss)
I0428 16:45:19.476275  5145 solver.cpp:228] Iteration 6000, loss = 0.20378
I0428 16:45:19.476312  5145 solver.cpp:244]     Train net output #0: loss = 0.20378 (* 1 = 0.20378 loss)
I0428 16:45:19.476318  5145 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0428 16:46:10.937187  5145 solver.cpp:228] Iteration 6100, loss = 0.182149
I0428 16:46:10.937335  5145 solver.cpp:244]     Train net output #0: loss = 0.182149 (* 1 = 0.182149 loss)
I0428 16:46:10.937343  5145 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0428 16:47:02.339584  5145 solver.cpp:228] Iteration 6200, loss = 0.319124
I0428 16:47:02.339745  5145 solver.cpp:244]     Train net output #0: loss = 0.319124 (* 1 = 0.319124 loss)
I0428 16:47:02.339753  5145 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0428 16:47:54.975654  5145 solver.cpp:228] Iteration 6300, loss = 0.283533
I0428 16:47:54.975800  5145 solver.cpp:244]     Train net output #0: loss = 0.283533 (* 1 = 0.283533 loss)
I0428 16:47:54.975807  5145 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0428 16:48:46.258213  5145 solver.cpp:228] Iteration 6400, loss = 0.313725
I0428 16:48:46.258364  5145 solver.cpp:244]     Train net output #0: loss = 0.313725 (* 1 = 0.313725 loss)
I0428 16:48:46.258371  5145 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0428 16:49:39.001220  5145 solver.cpp:228] Iteration 6500, loss = 0.367295
I0428 16:49:39.001364  5145 solver.cpp:244]     Train net output #0: loss = 0.367295 (* 1 = 0.367295 loss)
I0428 16:49:39.001372  5145 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0428 16:50:30.282410  5145 solver.cpp:228] Iteration 6600, loss = 0.308085
I0428 16:50:30.282559  5145 solver.cpp:244]     Train net output #0: loss = 0.308085 (* 1 = 0.308085 loss)
I0428 16:50:30.282567  5145 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0428 16:51:21.628842  5145 solver.cpp:228] Iteration 6700, loss = 0.24373
I0428 16:51:21.628983  5145 solver.cpp:244]     Train net output #0: loss = 0.24373 (* 1 = 0.24373 loss)
I0428 16:51:21.628990  5145 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0428 16:52:14.607637  5145 solver.cpp:228] Iteration 6800, loss = 0.372195
I0428 16:52:14.607787  5145 solver.cpp:244]     Train net output #0: loss = 0.372195 (* 1 = 0.372195 loss)
I0428 16:52:14.607795  5145 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0428 16:53:05.950161  5145 solver.cpp:228] Iteration 6900, loss = 0.223441
I0428 16:53:05.950321  5145 solver.cpp:244]     Train net output #0: loss = 0.223441 (* 1 = 0.223441 loss)
I0428 16:53:05.950328  5145 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0428 16:53:57.030817  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_7000.caffemodel
I0428 16:54:01.610105  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_7000.solverstate
I0428 16:54:01.816047  5145 solver.cpp:337] Iteration 7000, Testing net (#0)
I0428 16:54:01.816179  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 16:54:01.816184  5145 net.cpp:693] Ignoring source layer visualize
I0428 16:54:01.816187  5145 net.cpp:693] Ignoring source layer fake
I0428 16:59:06.026924  5145 solver.cpp:404]     Test net output #0: loss = 0.39512 (* 1 = 0.39512 loss)
I0428 16:59:06.350450  5145 solver.cpp:228] Iteration 7000, loss = 0.232867
I0428 16:59:06.350468  5145 solver.cpp:244]     Train net output #0: loss = 0.232867 (* 1 = 0.232867 loss)
I0428 16:59:06.350492  5145 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0428 16:59:59.594154  5145 solver.cpp:228] Iteration 7100, loss = 0.533241
I0428 16:59:59.594305  5145 solver.cpp:244]     Train net output #0: loss = 0.533241 (* 1 = 0.533241 loss)
I0428 16:59:59.594312  5145 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0428 17:00:50.993274  5145 solver.cpp:228] Iteration 7200, loss = 0.244294
I0428 17:00:50.993427  5145 solver.cpp:244]     Train net output #0: loss = 0.244294 (* 1 = 0.244294 loss)
I0428 17:00:50.993444  5145 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0428 17:01:42.505791  5145 solver.cpp:228] Iteration 7300, loss = 0.235991
I0428 17:01:42.505928  5145 solver.cpp:244]     Train net output #0: loss = 0.235991 (* 1 = 0.235991 loss)
I0428 17:01:42.505936  5145 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0428 17:02:35.760558  5145 solver.cpp:228] Iteration 7400, loss = 0.262
I0428 17:02:35.760741  5145 solver.cpp:244]     Train net output #0: loss = 0.262 (* 1 = 0.262 loss)
I0428 17:02:35.760756  5145 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0428 17:03:27.129770  5145 solver.cpp:228] Iteration 7500, loss = 0.419326
I0428 17:03:27.129930  5145 solver.cpp:244]     Train net output #0: loss = 0.419326 (* 1 = 0.419326 loss)
I0428 17:03:27.129937  5145 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I0428 17:04:18.552314  5145 solver.cpp:228] Iteration 7600, loss = 0.320989
I0428 17:04:18.552461  5145 solver.cpp:244]     Train net output #0: loss = 0.320989 (* 1 = 0.320989 loss)
I0428 17:04:18.552469  5145 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0428 17:05:10.001972  5145 solver.cpp:228] Iteration 7700, loss = 0.362686
I0428 17:05:10.002120  5145 solver.cpp:244]     Train net output #0: loss = 0.362686 (* 1 = 0.362686 loss)
I0428 17:05:10.002127  5145 sgd_solver.cpp:106] Iteration 7700, lr = 0.001
I0428 17:06:03.271767  5145 solver.cpp:228] Iteration 7800, loss = 0.304841
I0428 17:06:03.271905  5145 solver.cpp:244]     Train net output #0: loss = 0.304841 (* 1 = 0.304841 loss)
I0428 17:06:03.271914  5145 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0428 17:06:54.569020  5145 solver.cpp:228] Iteration 7900, loss = 0.224301
I0428 17:06:54.572348  5145 solver.cpp:244]     Train net output #0: loss = 0.224301 (* 1 = 0.224301 loss)
I0428 17:06:54.572357  5145 sgd_solver.cpp:106] Iteration 7900, lr = 0.001
I0428 17:07:45.726609  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_8000.caffemodel
I0428 17:08:23.880504  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_8000.solverstate
I0428 17:08:24.070020  5145 solver.cpp:337] Iteration 8000, Testing net (#0)
I0428 17:08:24.070109  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 17:08:24.070129  5145 net.cpp:693] Ignoring source layer visualize
I0428 17:08:24.070132  5145 net.cpp:693] Ignoring source layer fake
I0428 17:13:26.873836  5145 solver.cpp:404]     Test net output #0: loss = 0.335675 (* 1 = 0.335675 loss)
I0428 17:13:27.197806  5145 solver.cpp:228] Iteration 8000, loss = 0.293128
I0428 17:13:27.197844  5145 solver.cpp:244]     Train net output #0: loss = 0.293128 (* 1 = 0.293128 loss)
I0428 17:13:27.197851  5145 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0428 17:14:20.415596  5145 solver.cpp:228] Iteration 8100, loss = 0.321222
I0428 17:14:20.415742  5145 solver.cpp:244]     Train net output #0: loss = 0.321222 (* 1 = 0.321222 loss)
I0428 17:14:20.415750  5145 sgd_solver.cpp:106] Iteration 8100, lr = 0.001
I0428 17:15:11.865003  5145 solver.cpp:228] Iteration 8200, loss = 0.261032
I0428 17:15:11.865170  5145 solver.cpp:244]     Train net output #0: loss = 0.261032 (* 1 = 0.261032 loss)
I0428 17:15:11.865176  5145 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0428 17:16:03.240326  5145 solver.cpp:228] Iteration 8300, loss = 0.277259
I0428 17:16:03.240489  5145 solver.cpp:244]     Train net output #0: loss = 0.277259 (* 1 = 0.277259 loss)
I0428 17:16:03.240496  5145 sgd_solver.cpp:106] Iteration 8300, lr = 0.001
I0428 17:16:54.718919  5145 solver.cpp:228] Iteration 8400, loss = 0.195614
I0428 17:16:54.719075  5145 solver.cpp:244]     Train net output #0: loss = 0.195614 (* 1 = 0.195614 loss)
I0428 17:16:54.719084  5145 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0428 17:17:47.863870  5145 solver.cpp:228] Iteration 8500, loss = 0.0972623
I0428 17:17:47.865701  5145 solver.cpp:244]     Train net output #0: loss = 0.0972623 (* 1 = 0.0972623 loss)
I0428 17:17:47.865708  5145 sgd_solver.cpp:106] Iteration 8500, lr = 0.001
I0428 17:18:39.289310  5145 solver.cpp:228] Iteration 8600, loss = 0.178559
I0428 17:18:39.289476  5145 solver.cpp:244]     Train net output #0: loss = 0.178559 (* 1 = 0.178559 loss)
I0428 17:18:39.289484  5145 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0428 17:19:30.895694  5145 solver.cpp:228] Iteration 8700, loss = 0.229695
I0428 17:19:30.895809  5145 solver.cpp:244]     Train net output #0: loss = 0.229695 (* 1 = 0.229695 loss)
I0428 17:19:30.895817  5145 sgd_solver.cpp:106] Iteration 8700, lr = 0.001
I0428 17:20:24.226987  5145 solver.cpp:228] Iteration 8800, loss = 0.221019
I0428 17:20:24.227149  5145 solver.cpp:244]     Train net output #0: loss = 0.221019 (* 1 = 0.221019 loss)
I0428 17:20:24.227157  5145 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0428 17:21:15.850102  5145 solver.cpp:228] Iteration 8900, loss = 0.195692
I0428 17:21:15.850281  5145 solver.cpp:244]     Train net output #0: loss = 0.195692 (* 1 = 0.195692 loss)
I0428 17:21:15.850287  5145 sgd_solver.cpp:106] Iteration 8900, lr = 0.001
I0428 17:22:06.974612  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_9000.caffemodel
I0428 17:22:16.207345  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_9000.solverstate
I0428 17:22:16.403861  5145 solver.cpp:337] Iteration 9000, Testing net (#0)
I0428 17:22:16.403949  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 17:22:16.403970  5145 net.cpp:693] Ignoring source layer visualize
I0428 17:22:16.403971  5145 net.cpp:693] Ignoring source layer fake
I0428 17:27:19.597465  5145 solver.cpp:404]     Test net output #0: loss = 0.32847 (* 1 = 0.32847 loss)
I0428 17:27:19.917099  5145 solver.cpp:228] Iteration 9000, loss = 0.191285
I0428 17:27:19.917137  5145 solver.cpp:244]     Train net output #0: loss = 0.191285 (* 1 = 0.191285 loss)
I0428 17:27:19.917143  5145 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0428 17:28:12.983669  5145 solver.cpp:228] Iteration 9100, loss = 0.197808
I0428 17:28:12.983815  5145 solver.cpp:244]     Train net output #0: loss = 0.197808 (* 1 = 0.197808 loss)
I0428 17:28:12.983824  5145 sgd_solver.cpp:106] Iteration 9100, lr = 0.001
I0428 17:29:04.454627  5145 solver.cpp:228] Iteration 9200, loss = 0.208129
I0428 17:29:04.454807  5145 solver.cpp:244]     Train net output #0: loss = 0.208129 (* 1 = 0.208129 loss)
I0428 17:29:04.454813  5145 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0428 17:29:55.831379  5145 solver.cpp:228] Iteration 9300, loss = 0.266671
I0428 17:29:55.831527  5145 solver.cpp:244]     Train net output #0: loss = 0.266671 (* 1 = 0.266671 loss)
I0428 17:29:55.831534  5145 sgd_solver.cpp:106] Iteration 9300, lr = 0.001
I0428 17:30:59.642102  5145 solver.cpp:228] Iteration 9400, loss = 0.376182
I0428 17:30:59.642251  5145 solver.cpp:244]     Train net output #0: loss = 0.376182 (* 1 = 0.376182 loss)
I0428 17:30:59.642259  5145 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0428 17:31:50.594445  5145 solver.cpp:228] Iteration 9500, loss = 0.328833
I0428 17:31:50.594591  5145 solver.cpp:244]     Train net output #0: loss = 0.328833 (* 1 = 0.328833 loss)
I0428 17:31:50.594599  5145 sgd_solver.cpp:106] Iteration 9500, lr = 0.001
I0428 17:32:41.955467  5145 solver.cpp:228] Iteration 9600, loss = 0.327872
I0428 17:32:41.955617  5145 solver.cpp:244]     Train net output #0: loss = 0.327872 (* 1 = 0.327872 loss)
I0428 17:32:41.955626  5145 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0428 17:33:45.914810  5145 solver.cpp:228] Iteration 9700, loss = 0.609979
I0428 17:33:45.914952  5145 solver.cpp:244]     Train net output #0: loss = 0.609979 (* 1 = 0.609979 loss)
I0428 17:33:45.914959  5145 sgd_solver.cpp:106] Iteration 9700, lr = 0.001
I0428 17:34:37.207657  5145 solver.cpp:228] Iteration 9800, loss = 0.180152
I0428 17:34:37.207803  5145 solver.cpp:244]     Train net output #0: loss = 0.180152 (* 1 = 0.180152 loss)
I0428 17:34:37.207810  5145 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0428 17:35:43.653579  5145 solver.cpp:228] Iteration 9900, loss = 0.0523386
I0428 17:35:43.653741  5145 solver.cpp:244]     Train net output #0: loss = 0.0523386 (* 1 = 0.0523386 loss)
I0428 17:35:43.653749  5145 sgd_solver.cpp:106] Iteration 9900, lr = 0.001
I0428 17:36:34.167798  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_10000.caffemodel
I0428 17:36:36.216347  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_10000.solverstate
I0428 17:36:36.403280  5145 solver.cpp:337] Iteration 10000, Testing net (#0)
I0428 17:36:36.403384  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 17:36:36.403389  5145 net.cpp:693] Ignoring source layer visualize
I0428 17:36:36.403391  5145 net.cpp:693] Ignoring source layer fake
I0428 17:41:40.310832  5145 solver.cpp:404]     Test net output #0: loss = 0.349151 (* 1 = 0.349151 loss)
I0428 17:41:40.631923  5145 solver.cpp:228] Iteration 10000, loss = 0.185046
I0428 17:41:40.631963  5145 solver.cpp:244]     Train net output #0: loss = 0.185046 (* 1 = 0.185046 loss)
I0428 17:41:40.631968  5145 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0428 17:42:32.076691  5145 solver.cpp:228] Iteration 10100, loss = 0.307922
I0428 17:42:32.076854  5145 solver.cpp:244]     Train net output #0: loss = 0.307922 (* 1 = 0.307922 loss)
I0428 17:42:32.076861  5145 sgd_solver.cpp:106] Iteration 10100, lr = 0.001
I0428 17:43:36.554898  5145 solver.cpp:228] Iteration 10200, loss = 0.370395
I0428 17:43:36.555048  5145 solver.cpp:244]     Train net output #0: loss = 0.370395 (* 1 = 0.370395 loss)
I0428 17:43:36.555057  5145 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0428 17:44:27.582340  5145 solver.cpp:228] Iteration 10300, loss = 0.106758
I0428 17:44:27.582485  5145 solver.cpp:244]     Train net output #0: loss = 0.106758 (* 1 = 0.106758 loss)
I0428 17:44:27.582492  5145 sgd_solver.cpp:106] Iteration 10300, lr = 0.001
I0428 17:45:19.105934  5145 solver.cpp:228] Iteration 10400, loss = 0.297835
I0428 17:45:19.106077  5145 solver.cpp:244]     Train net output #0: loss = 0.297835 (* 1 = 0.297835 loss)
I0428 17:45:19.106086  5145 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I0428 17:46:10.580126  5145 solver.cpp:228] Iteration 10500, loss = 0.291102
I0428 17:46:10.580293  5145 solver.cpp:244]     Train net output #0: loss = 0.291102 (* 1 = 0.291102 loss)
I0428 17:46:10.580302  5145 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I0428 17:47:04.368243  5145 solver.cpp:228] Iteration 10600, loss = 0.268765
I0428 17:47:04.368399  5145 solver.cpp:244]     Train net output #0: loss = 0.268765 (* 1 = 0.268765 loss)
I0428 17:47:04.368407  5145 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I0428 17:47:55.868022  5145 solver.cpp:228] Iteration 10700, loss = 0.209298
I0428 17:47:55.868163  5145 solver.cpp:244]     Train net output #0: loss = 0.209298 (* 1 = 0.209298 loss)
I0428 17:47:55.868170  5145 sgd_solver.cpp:106] Iteration 10700, lr = 0.001
I0428 17:48:47.331997  5145 solver.cpp:228] Iteration 10800, loss = 0.218894
I0428 17:48:47.332147  5145 solver.cpp:244]     Train net output #0: loss = 0.218894 (* 1 = 0.218894 loss)
I0428 17:48:47.332154  5145 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0428 17:49:40.636962  5145 solver.cpp:228] Iteration 10900, loss = 0.312936
I0428 17:49:40.637135  5145 solver.cpp:244]     Train net output #0: loss = 0.312936 (* 1 = 0.312936 loss)
I0428 17:49:40.637142  5145 sgd_solver.cpp:106] Iteration 10900, lr = 0.001
I0428 17:50:31.817178  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_11000.caffemodel
I0428 17:50:42.898161  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_11000.solverstate
I0428 17:50:43.087842  5145 solver.cpp:337] Iteration 11000, Testing net (#0)
I0428 17:50:43.087929  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 17:50:43.087949  5145 net.cpp:693] Ignoring source layer visualize
I0428 17:50:43.087951  5145 net.cpp:693] Ignoring source layer fake
I0428 17:55:46.628305  5145 solver.cpp:404]     Test net output #0: loss = 0.312985 (* 1 = 0.312985 loss)
I0428 17:55:46.951464  5145 solver.cpp:228] Iteration 11000, loss = 0.419292
I0428 17:55:46.951503  5145 solver.cpp:244]     Train net output #0: loss = 0.419292 (* 1 = 0.419292 loss)
I0428 17:55:46.951508  5145 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0428 17:56:38.512145  5145 solver.cpp:228] Iteration 11100, loss = 0.219407
I0428 17:56:38.512285  5145 solver.cpp:244]     Train net output #0: loss = 0.219407 (* 1 = 0.219407 loss)
I0428 17:56:38.512292  5145 sgd_solver.cpp:106] Iteration 11100, lr = 0.001
I0428 17:57:31.850379  5145 solver.cpp:228] Iteration 11200, loss = 0.340355
I0428 17:57:31.850601  5145 solver.cpp:244]     Train net output #0: loss = 0.340355 (* 1 = 0.340355 loss)
I0428 17:57:31.850610  5145 sgd_solver.cpp:106] Iteration 11200, lr = 0.001
I0428 17:58:23.273274  5145 solver.cpp:228] Iteration 11300, loss = 0.212318
I0428 17:58:23.273442  5145 solver.cpp:244]     Train net output #0: loss = 0.212318 (* 1 = 0.212318 loss)
I0428 17:58:23.273452  5145 sgd_solver.cpp:106] Iteration 11300, lr = 0.001
I0428 17:59:14.714454  5145 solver.cpp:228] Iteration 11400, loss = 0.344204
I0428 17:59:14.714627  5145 solver.cpp:244]     Train net output #0: loss = 0.344204 (* 1 = 0.344204 loss)
I0428 17:59:14.714635  5145 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I0428 18:00:06.223945  5145 solver.cpp:228] Iteration 11500, loss = 0.230563
I0428 18:00:06.224071  5145 solver.cpp:244]     Train net output #0: loss = 0.230563 (* 1 = 0.230563 loss)
I0428 18:00:06.224078  5145 sgd_solver.cpp:106] Iteration 11500, lr = 0.001
I0428 18:00:59.563154  5145 solver.cpp:228] Iteration 11600, loss = 0.17494
I0428 18:00:59.563890  5145 solver.cpp:244]     Train net output #0: loss = 0.17494 (* 1 = 0.17494 loss)
I0428 18:00:59.563899  5145 sgd_solver.cpp:106] Iteration 11600, lr = 0.001
I0428 18:01:50.968767  5145 solver.cpp:228] Iteration 11700, loss = 0.189151
I0428 18:01:50.968955  5145 solver.cpp:244]     Train net output #0: loss = 0.189151 (* 1 = 0.189151 loss)
I0428 18:01:50.968966  5145 sgd_solver.cpp:106] Iteration 11700, lr = 0.001
I0428 18:02:42.468483  5145 solver.cpp:228] Iteration 11800, loss = 0.285827
I0428 18:02:42.468675  5145 solver.cpp:244]     Train net output #0: loss = 0.285827 (* 1 = 0.285827 loss)
I0428 18:02:42.468683  5145 sgd_solver.cpp:106] Iteration 11800, lr = 0.001
I0428 18:03:35.744120  5145 solver.cpp:228] Iteration 11900, loss = 0.232691
I0428 18:03:35.744295  5145 solver.cpp:244]     Train net output #0: loss = 0.232691 (* 1 = 0.232691 loss)
I0428 18:03:35.744304  5145 sgd_solver.cpp:106] Iteration 11900, lr = 0.001
I0428 18:04:26.821529  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_12000.caffemodel
I0428 18:04:42.335408  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_12000.solverstate
I0428 18:04:42.534410  5145 solver.cpp:337] Iteration 12000, Testing net (#0)
I0428 18:04:42.534517  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 18:04:42.534523  5145 net.cpp:693] Ignoring source layer visualize
I0428 18:04:42.534525  5145 net.cpp:693] Ignoring source layer fake
I0428 18:09:46.094296  5145 solver.cpp:404]     Test net output #0: loss = 0.318763 (* 1 = 0.318763 loss)
I0428 18:09:46.413339  5145 solver.cpp:228] Iteration 12000, loss = 0.212929
I0428 18:09:46.413386  5145 solver.cpp:244]     Train net output #0: loss = 0.212929 (* 1 = 0.212929 loss)
I0428 18:09:46.413393  5145 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0428 18:10:37.902981  5145 solver.cpp:228] Iteration 12100, loss = 0.302307
I0428 18:10:37.903142  5145 solver.cpp:244]     Train net output #0: loss = 0.302307 (* 1 = 0.302307 loss)
I0428 18:10:37.903149  5145 sgd_solver.cpp:106] Iteration 12100, lr = 0.001
I0428 18:11:31.096125  5145 solver.cpp:228] Iteration 12200, loss = 0.252902
I0428 18:11:31.096271  5145 solver.cpp:244]     Train net output #0: loss = 0.252902 (* 1 = 0.252902 loss)
I0428 18:11:31.096279  5145 sgd_solver.cpp:106] Iteration 12200, lr = 0.001
I0428 18:12:22.398164  5145 solver.cpp:228] Iteration 12300, loss = 0.316889
I0428 18:12:22.398322  5145 solver.cpp:244]     Train net output #0: loss = 0.316889 (* 1 = 0.316889 loss)
I0428 18:12:22.398329  5145 sgd_solver.cpp:106] Iteration 12300, lr = 0.001
I0428 18:13:13.851824  5145 solver.cpp:228] Iteration 12400, loss = 0.164922
I0428 18:13:13.851972  5145 solver.cpp:244]     Train net output #0: loss = 0.164922 (* 1 = 0.164922 loss)
I0428 18:13:13.851980  5145 sgd_solver.cpp:106] Iteration 12400, lr = 0.001
I0428 18:14:06.554111  5145 solver.cpp:228] Iteration 12500, loss = 0.224616
I0428 18:14:06.554253  5145 solver.cpp:244]     Train net output #0: loss = 0.224616 (* 1 = 0.224616 loss)
I0428 18:14:06.554261  5145 sgd_solver.cpp:106] Iteration 12500, lr = 0.001
I0428 18:14:57.978304  5145 solver.cpp:228] Iteration 12600, loss = 0.258461
I0428 18:14:57.978444  5145 solver.cpp:244]     Train net output #0: loss = 0.258461 (* 1 = 0.258461 loss)
I0428 18:14:57.978451  5145 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I0428 18:15:49.401471  5145 solver.cpp:228] Iteration 12700, loss = 0.218951
I0428 18:15:49.401620  5145 solver.cpp:244]     Train net output #0: loss = 0.218951 (* 1 = 0.218951 loss)
I0428 18:15:49.401628  5145 sgd_solver.cpp:106] Iteration 12700, lr = 0.001
I0428 18:16:42.148788  5145 solver.cpp:228] Iteration 12800, loss = 0.244401
I0428 18:16:42.148918  5145 solver.cpp:244]     Train net output #0: loss = 0.244401 (* 1 = 0.244401 loss)
I0428 18:16:42.148926  5145 sgd_solver.cpp:106] Iteration 12800, lr = 0.001
I0428 18:17:33.658857  5145 solver.cpp:228] Iteration 12900, loss = 0.369267
I0428 18:17:33.659019  5145 solver.cpp:244]     Train net output #0: loss = 0.369267 (* 1 = 0.369267 loss)
I0428 18:17:33.659029  5145 sgd_solver.cpp:106] Iteration 12900, lr = 0.001
I0428 18:18:24.804476  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_13000.caffemodel
I0428 18:18:41.684108  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_13000.solverstate
I0428 18:18:41.886893  5145 solver.cpp:337] Iteration 13000, Testing net (#0)
I0428 18:18:41.886998  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 18:18:41.887006  5145 net.cpp:693] Ignoring source layer visualize
I0428 18:18:41.887007  5145 net.cpp:693] Ignoring source layer fake
I0428 18:23:45.779616  5145 solver.cpp:404]     Test net output #0: loss = 0.333893 (* 1 = 0.333893 loss)
I0428 18:23:46.099076  5145 solver.cpp:228] Iteration 13000, loss = 0.205529
I0428 18:23:46.099112  5145 solver.cpp:244]     Train net output #0: loss = 0.205529 (* 1 = 0.205529 loss)
I0428 18:23:46.099118  5145 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0428 18:24:39.095461  5145 solver.cpp:228] Iteration 13100, loss = 0.300921
I0428 18:24:39.095651  5145 solver.cpp:244]     Train net output #0: loss = 0.300921 (* 1 = 0.300921 loss)
I0428 18:24:39.095662  5145 sgd_solver.cpp:106] Iteration 13100, lr = 0.001
I0428 18:25:30.588212  5145 solver.cpp:228] Iteration 13200, loss = 0.368898
I0428 18:25:30.588686  5145 solver.cpp:244]     Train net output #0: loss = 0.368898 (* 1 = 0.368898 loss)
I0428 18:25:30.588693  5145 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I0428 18:26:23.978286  5145 solver.cpp:228] Iteration 13300, loss = 0.271812
I0428 18:26:23.979272  5145 solver.cpp:244]     Train net output #0: loss = 0.271812 (* 1 = 0.271812 loss)
I0428 18:26:23.979295  5145 sgd_solver.cpp:106] Iteration 13300, lr = 0.001
I0428 18:27:15.322510  5145 solver.cpp:228] Iteration 13400, loss = 0.352843
I0428 18:27:15.322693  5145 solver.cpp:244]     Train net output #0: loss = 0.352843 (* 1 = 0.352843 loss)
I0428 18:27:15.322702  5145 sgd_solver.cpp:106] Iteration 13400, lr = 0.001
I0428 18:28:06.738836  5145 solver.cpp:228] Iteration 13500, loss = 0.256789
I0428 18:28:06.738997  5145 solver.cpp:244]     Train net output #0: loss = 0.256789 (* 1 = 0.256789 loss)
I0428 18:28:06.739006  5145 sgd_solver.cpp:106] Iteration 13500, lr = 0.001
I0428 18:28:58.172461  5145 solver.cpp:228] Iteration 13600, loss = 0.334184
I0428 18:28:58.172624  5145 solver.cpp:244]     Train net output #0: loss = 0.334184 (* 1 = 0.334184 loss)
I0428 18:28:58.172631  5145 sgd_solver.cpp:106] Iteration 13600, lr = 0.001
I0428 18:29:51.590682  5145 solver.cpp:228] Iteration 13700, loss = 0.353275
I0428 18:29:51.590855  5145 solver.cpp:244]     Train net output #0: loss = 0.353275 (* 1 = 0.353275 loss)
I0428 18:29:51.590864  5145 sgd_solver.cpp:106] Iteration 13700, lr = 0.001
I0428 18:30:43.074125  5145 solver.cpp:228] Iteration 13800, loss = 0.316866
I0428 18:30:43.074278  5145 solver.cpp:244]     Train net output #0: loss = 0.316866 (* 1 = 0.316866 loss)
I0428 18:30:43.074285  5145 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I0428 18:31:34.601322  5145 solver.cpp:228] Iteration 13900, loss = 0.316561
I0428 18:31:34.601501  5145 solver.cpp:244]     Train net output #0: loss = 0.316561 (* 1 = 0.316561 loss)
I0428 18:31:34.601510  5145 sgd_solver.cpp:106] Iteration 13900, lr = 0.001
I0428 18:32:27.563478  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_14000.caffemodel
I0428 18:32:38.449697  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_14000.solverstate
I0428 18:32:38.640405  5145 solver.cpp:337] Iteration 14000, Testing net (#0)
I0428 18:32:38.640511  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 18:32:38.640522  5145 net.cpp:693] Ignoring source layer visualize
I0428 18:32:38.640523  5145 net.cpp:693] Ignoring source layer fake
I0428 18:37:42.244701  5145 solver.cpp:404]     Test net output #0: loss = 0.313348 (* 1 = 0.313348 loss)
I0428 18:37:42.567833  5145 solver.cpp:228] Iteration 14000, loss = 0.295515
I0428 18:37:42.567859  5145 solver.cpp:244]     Train net output #0: loss = 0.295515 (* 1 = 0.295515 loss)
I0428 18:37:42.567867  5145 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0428 18:38:34.056694  5145 solver.cpp:228] Iteration 14100, loss = 0.156217
I0428 18:38:34.056860  5145 solver.cpp:244]     Train net output #0: loss = 0.156217 (* 1 = 0.156217 loss)
I0428 18:38:34.056867  5145 sgd_solver.cpp:106] Iteration 14100, lr = 0.001
I0428 18:39:25.491272  5145 solver.cpp:228] Iteration 14200, loss = 0.277903
I0428 18:39:25.491420  5145 solver.cpp:244]     Train net output #0: loss = 0.277903 (* 1 = 0.277903 loss)
I0428 18:39:25.491427  5145 sgd_solver.cpp:106] Iteration 14200, lr = 0.001
I0428 18:40:16.993832  5145 solver.cpp:228] Iteration 14300, loss = 0.384735
I0428 18:40:16.993963  5145 solver.cpp:244]     Train net output #0: loss = 0.384735 (* 1 = 0.384735 loss)
I0428 18:40:16.993968  5145 sgd_solver.cpp:106] Iteration 14300, lr = 0.001
I0428 18:41:10.193464  5145 solver.cpp:228] Iteration 14400, loss = 0.147909
I0428 18:41:10.193636  5145 solver.cpp:244]     Train net output #0: loss = 0.147909 (* 1 = 0.147909 loss)
I0428 18:41:10.193644  5145 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I0428 18:42:01.726011  5145 solver.cpp:228] Iteration 14500, loss = 0.184013
I0428 18:42:01.726166  5145 solver.cpp:244]     Train net output #0: loss = 0.184013 (* 1 = 0.184013 loss)
I0428 18:42:01.726173  5145 sgd_solver.cpp:106] Iteration 14500, lr = 0.001
I0428 18:42:53.125089  5145 solver.cpp:228] Iteration 14600, loss = 0.311068
I0428 18:42:53.125238  5145 solver.cpp:244]     Train net output #0: loss = 0.311068 (* 1 = 0.311068 loss)
I0428 18:42:53.125247  5145 sgd_solver.cpp:106] Iteration 14600, lr = 0.001
I0428 18:43:46.368297  5145 solver.cpp:228] Iteration 14700, loss = 0.17396
I0428 18:43:46.368486  5145 solver.cpp:244]     Train net output #0: loss = 0.17396 (* 1 = 0.17396 loss)
I0428 18:43:46.368495  5145 sgd_solver.cpp:106] Iteration 14700, lr = 0.001
I0428 18:44:37.786052  5145 solver.cpp:228] Iteration 14800, loss = 0.249047
I0428 18:44:37.786229  5145 solver.cpp:244]     Train net output #0: loss = 0.249047 (* 1 = 0.249047 loss)
I0428 18:44:37.786237  5145 sgd_solver.cpp:106] Iteration 14800, lr = 0.001
I0428 18:45:29.332902  5145 solver.cpp:228] Iteration 14900, loss = 0.150069
I0428 18:45:29.333039  5145 solver.cpp:244]     Train net output #0: loss = 0.150069 (* 1 = 0.150069 loss)
I0428 18:45:29.333046  5145 sgd_solver.cpp:106] Iteration 14900, lr = 0.001
I0428 18:46:22.229985  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_15000.caffemodel
I0428 18:46:31.894690  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_15000.solverstate
I0428 18:46:32.081372  5145 solver.cpp:337] Iteration 15000, Testing net (#0)
I0428 18:46:32.081482  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 18:46:32.081486  5145 net.cpp:693] Ignoring source layer visualize
I0428 18:46:32.081488  5145 net.cpp:693] Ignoring source layer fake
I0428 18:51:36.284765  5145 solver.cpp:404]     Test net output #0: loss = 0.329552 (* 1 = 0.329552 loss)
I0428 18:51:36.603580  5145 solver.cpp:228] Iteration 15000, loss = 0.263038
I0428 18:51:36.603623  5145 solver.cpp:244]     Train net output #0: loss = 0.263038 (* 1 = 0.263038 loss)
I0428 18:51:36.603629  5145 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0428 18:52:28.074607  5145 solver.cpp:228] Iteration 15100, loss = 0.0339051
I0428 18:52:28.074767  5145 solver.cpp:244]     Train net output #0: loss = 0.0339051 (* 1 = 0.0339051 loss)
I0428 18:52:28.074775  5145 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0428 18:53:19.472870  5145 solver.cpp:228] Iteration 15200, loss = 0.240341
I0428 18:53:19.473017  5145 solver.cpp:244]     Train net output #0: loss = 0.240341 (* 1 = 0.240341 loss)
I0428 18:53:19.473024  5145 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0428 18:54:10.994055  5145 solver.cpp:228] Iteration 15300, loss = 0.166931
I0428 18:54:10.994230  5145 solver.cpp:244]     Train net output #0: loss = 0.166931 (* 1 = 0.166931 loss)
I0428 18:54:10.994237  5145 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0428 18:55:04.019266  5145 solver.cpp:228] Iteration 15400, loss = 0.303858
I0428 18:55:04.019911  5145 solver.cpp:244]     Train net output #0: loss = 0.303858 (* 1 = 0.303858 loss)
I0428 18:55:04.019917  5145 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0428 18:55:55.497263  5145 solver.cpp:228] Iteration 15500, loss = 0.179135
I0428 18:55:55.497423  5145 solver.cpp:244]     Train net output #0: loss = 0.179135 (* 1 = 0.179135 loss)
I0428 18:55:55.497432  5145 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0428 18:56:46.793071  5145 solver.cpp:228] Iteration 15600, loss = 0.21317
I0428 18:56:46.793231  5145 solver.cpp:244]     Train net output #0: loss = 0.21317 (* 1 = 0.21317 loss)
I0428 18:56:46.793238  5145 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0428 18:57:39.585415  5145 solver.cpp:228] Iteration 15700, loss = 0.340977
I0428 18:57:39.585578  5145 solver.cpp:244]     Train net output #0: loss = 0.340977 (* 1 = 0.340977 loss)
I0428 18:57:39.585588  5145 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0428 18:58:31.083874  5145 solver.cpp:228] Iteration 15800, loss = 0.28909
I0428 18:58:31.084023  5145 solver.cpp:244]     Train net output #0: loss = 0.28909 (* 1 = 0.28909 loss)
I0428 18:58:31.084029  5145 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0428 18:59:23.870038  5145 solver.cpp:228] Iteration 15900, loss = 0.263334
I0428 18:59:23.870189  5145 solver.cpp:244]     Train net output #0: loss = 0.263334 (* 1 = 0.263334 loss)
I0428 18:59:23.870196  5145 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0428 19:00:15.129642  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_16000.caffemodel
I0428 19:00:29.974524  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_16000.solverstate
I0428 19:00:30.159782  5145 solver.cpp:337] Iteration 16000, Testing net (#0)
I0428 19:00:30.159873  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 19:00:30.159893  5145 net.cpp:693] Ignoring source layer visualize
I0428 19:00:30.159895  5145 net.cpp:693] Ignoring source layer fake
I0428 19:05:33.569124  5145 solver.cpp:404]     Test net output #0: loss = 0.301114 (* 1 = 0.301114 loss)
I0428 19:05:33.889770  5145 solver.cpp:228] Iteration 16000, loss = 0.378008
I0428 19:05:33.889823  5145 solver.cpp:244]     Train net output #0: loss = 0.378008 (* 1 = 0.378008 loss)
I0428 19:05:33.889830  5145 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0428 19:06:25.272243  5145 solver.cpp:228] Iteration 16100, loss = 0.380879
I0428 19:06:25.272400  5145 solver.cpp:244]     Train net output #0: loss = 0.380879 (* 1 = 0.380879 loss)
I0428 19:06:25.272408  5145 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0428 19:07:18.321115  5145 solver.cpp:228] Iteration 16200, loss = 0.136192
I0428 19:07:18.321254  5145 solver.cpp:244]     Train net output #0: loss = 0.136192 (* 1 = 0.136192 loss)
I0428 19:07:18.321260  5145 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0428 19:08:09.801021  5145 solver.cpp:228] Iteration 16300, loss = 0.261673
I0428 19:08:09.801187  5145 solver.cpp:244]     Train net output #0: loss = 0.261673 (* 1 = 0.261673 loss)
I0428 19:08:09.801194  5145 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0428 19:09:01.211292  5145 solver.cpp:228] Iteration 16400, loss = 0.1456
I0428 19:09:01.211450  5145 solver.cpp:244]     Train net output #0: loss = 0.1456 (* 1 = 0.1456 loss)
I0428 19:09:01.211458  5145 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0428 19:09:54.456706  5145 solver.cpp:228] Iteration 16500, loss = 0.351257
I0428 19:09:54.456853  5145 solver.cpp:244]     Train net output #0: loss = 0.351257 (* 1 = 0.351257 loss)
I0428 19:09:54.456861  5145 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0428 19:10:45.843010  5145 solver.cpp:228] Iteration 16600, loss = 0.339464
I0428 19:10:45.843180  5145 solver.cpp:244]     Train net output #0: loss = 0.339464 (* 1 = 0.339464 loss)
I0428 19:10:45.843189  5145 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0428 19:11:37.049538  5145 solver.cpp:228] Iteration 16700, loss = 0.350212
I0428 19:11:37.049685  5145 solver.cpp:244]     Train net output #0: loss = 0.350212 (* 1 = 0.350212 loss)
I0428 19:11:37.049692  5145 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0428 19:12:30.248229  5145 solver.cpp:228] Iteration 16800, loss = 0.238369
I0428 19:12:30.248368  5145 solver.cpp:244]     Train net output #0: loss = 0.238369 (* 1 = 0.238369 loss)
I0428 19:12:30.248376  5145 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0428 19:13:21.717134  5145 solver.cpp:228] Iteration 16900, loss = 0.299427
I0428 19:13:21.717303  5145 solver.cpp:244]     Train net output #0: loss = 0.299427 (* 1 = 0.299427 loss)
I0428 19:13:21.717313  5145 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0428 19:14:12.761082  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_17000.caffemodel
I0428 19:14:19.147995  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_17000.solverstate
I0428 19:14:19.345204  5145 solver.cpp:337] Iteration 17000, Testing net (#0)
I0428 19:14:19.345310  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 19:14:19.345319  5145 net.cpp:693] Ignoring source layer visualize
I0428 19:14:19.345321  5145 net.cpp:693] Ignoring source layer fake
I0428 19:19:23.298104  5145 solver.cpp:404]     Test net output #0: loss = 0.293174 (* 1 = 0.293174 loss)
I0428 19:19:23.616551  5145 solver.cpp:228] Iteration 17000, loss = 0.294165
I0428 19:19:23.616590  5145 solver.cpp:244]     Train net output #0: loss = 0.294165 (* 1 = 0.294165 loss)
I0428 19:19:23.616595  5145 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0428 19:20:16.346225  5145 solver.cpp:228] Iteration 17100, loss = 0.393285
I0428 19:20:16.346377  5145 solver.cpp:244]     Train net output #0: loss = 0.393285 (* 1 = 0.393285 loss)
I0428 19:20:16.346385  5145 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0428 19:21:07.178545  5145 solver.cpp:228] Iteration 17200, loss = 0.341259
I0428 19:21:07.178711  5145 solver.cpp:244]     Train net output #0: loss = 0.341259 (* 1 = 0.341259 loss)
I0428 19:21:07.178719  5145 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0428 19:21:58.000380  5145 solver.cpp:228] Iteration 17300, loss = 0.366075
I0428 19:21:58.000526  5145 solver.cpp:244]     Train net output #0: loss = 0.366075 (* 1 = 0.366075 loss)
I0428 19:21:58.000532  5145 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0428 19:22:48.816141  5145 solver.cpp:228] Iteration 17400, loss = 0.263067
I0428 19:22:48.816282  5145 solver.cpp:244]     Train net output #0: loss = 0.263067 (* 1 = 0.263067 loss)
I0428 19:22:48.816288  5145 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0428 19:23:41.567055  5145 solver.cpp:228] Iteration 17500, loss = 0.194781
I0428 19:23:41.567183  5145 solver.cpp:244]     Train net output #0: loss = 0.194781 (* 1 = 0.194781 loss)
I0428 19:23:41.567189  5145 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0428 19:24:32.225517  5145 solver.cpp:228] Iteration 17600, loss = 0.342397
I0428 19:24:32.225930  5145 solver.cpp:244]     Train net output #0: loss = 0.342397 (* 1 = 0.342397 loss)
I0428 19:24:32.225936  5145 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0428 19:25:22.885375  5145 solver.cpp:228] Iteration 17700, loss = 0.23285
I0428 19:25:22.885524  5145 solver.cpp:244]     Train net output #0: loss = 0.23285 (* 1 = 0.23285 loss)
I0428 19:25:22.885532  5145 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0428 19:26:15.360532  5145 solver.cpp:228] Iteration 17800, loss = 0.181389
I0428 19:26:15.360664  5145 solver.cpp:244]     Train net output #0: loss = 0.181389 (* 1 = 0.181389 loss)
I0428 19:26:15.360672  5145 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0428 19:27:06.003242  5145 solver.cpp:228] Iteration 17900, loss = 0.2953
I0428 19:27:06.003396  5145 solver.cpp:244]     Train net output #0: loss = 0.2953 (* 1 = 0.2953 loss)
I0428 19:27:06.003402  5145 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0428 19:27:56.336191  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_18000.caffemodel
I0428 19:27:56.695022  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_18000.solverstate
I0428 19:27:56.878921  5145 solver.cpp:337] Iteration 18000, Testing net (#0)
I0428 19:27:56.878988  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 19:27:56.878991  5145 net.cpp:693] Ignoring source layer visualize
I0428 19:27:56.878993  5145 net.cpp:693] Ignoring source layer fake
I0428 19:32:56.857131  5145 solver.cpp:404]     Test net output #0: loss = 0.283512 (* 1 = 0.283512 loss)
I0428 19:32:57.176322  5145 solver.cpp:228] Iteration 18000, loss = 0.264609
I0428 19:32:57.176342  5145 solver.cpp:244]     Train net output #0: loss = 0.264609 (* 1 = 0.264609 loss)
I0428 19:32:57.176347  5145 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0428 19:33:47.819875  5145 solver.cpp:228] Iteration 18100, loss = 0.227023
I0428 19:33:47.820011  5145 solver.cpp:244]     Train net output #0: loss = 0.227023 (* 1 = 0.227023 loss)
I0428 19:33:47.820017  5145 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0428 19:34:40.418607  5145 solver.cpp:228] Iteration 18200, loss = 0.291032
I0428 19:34:40.418751  5145 solver.cpp:244]     Train net output #0: loss = 0.291032 (* 1 = 0.291032 loss)
I0428 19:34:40.418759  5145 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0428 19:35:31.062245  5145 solver.cpp:228] Iteration 18300, loss = 0.240837
I0428 19:35:31.062399  5145 solver.cpp:244]     Train net output #0: loss = 0.240837 (* 1 = 0.240837 loss)
I0428 19:35:31.062408  5145 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0428 19:36:21.707778  5145 solver.cpp:228] Iteration 18400, loss = 0.256203
I0428 19:36:21.707921  5145 solver.cpp:244]     Train net output #0: loss = 0.256203 (* 1 = 0.256203 loss)
I0428 19:36:21.707928  5145 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0428 19:37:14.049356  5145 solver.cpp:228] Iteration 18500, loss = 0.180068
I0428 19:37:14.049490  5145 solver.cpp:244]     Train net output #0: loss = 0.180068 (* 1 = 0.180068 loss)
I0428 19:37:14.049497  5145 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0428 19:38:04.697355  5145 solver.cpp:228] Iteration 18600, loss = 0.228524
I0428 19:38:04.697486  5145 solver.cpp:244]     Train net output #0: loss = 0.228524 (* 1 = 0.228524 loss)
I0428 19:38:04.697494  5145 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0428 19:38:55.344322  5145 solver.cpp:228] Iteration 18700, loss = 0.243325
I0428 19:38:55.344452  5145 solver.cpp:244]     Train net output #0: loss = 0.243325 (* 1 = 0.243325 loss)
I0428 19:38:55.344460  5145 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0428 19:39:47.249222  5145 solver.cpp:228] Iteration 18800, loss = 0.283225
I0428 19:39:47.249353  5145 solver.cpp:244]     Train net output #0: loss = 0.283225 (* 1 = 0.283225 loss)
I0428 19:39:47.249361  5145 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0428 19:40:37.895767  5145 solver.cpp:228] Iteration 18900, loss = 0.11506
I0428 19:40:37.895907  5145 solver.cpp:244]     Train net output #0: loss = 0.11506 (* 1 = 0.11506 loss)
I0428 19:40:37.895915  5145 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0428 19:41:29.554482  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_19000.caffemodel
I0428 19:41:31.490777  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_19000.solverstate
I0428 19:41:31.677956  5145 solver.cpp:337] Iteration 19000, Testing net (#0)
I0428 19:41:31.678023  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 19:41:31.678026  5145 net.cpp:693] Ignoring source layer visualize
I0428 19:41:31.678028  5145 net.cpp:693] Ignoring source layer fake
I0428 19:46:31.993144  5145 solver.cpp:404]     Test net output #0: loss = 0.286332 (* 1 = 0.286332 loss)
I0428 19:46:32.311123  5145 solver.cpp:228] Iteration 19000, loss = 0.405006
I0428 19:46:32.311141  5145 solver.cpp:244]     Train net output #0: loss = 0.405006 (* 1 = 0.405006 loss)
I0428 19:46:32.311162  5145 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0428 19:47:22.953395  5145 solver.cpp:228] Iteration 19100, loss = 0.311986
I0428 19:47:22.953562  5145 solver.cpp:244]     Train net output #0: loss = 0.311986 (* 1 = 0.311986 loss)
I0428 19:47:22.953570  5145 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0428 19:48:13.597916  5145 solver.cpp:228] Iteration 19200, loss = 0.355059
I0428 19:48:13.598055  5145 solver.cpp:244]     Train net output #0: loss = 0.355059 (* 1 = 0.355059 loss)
I0428 19:48:13.598068  5145 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0428 19:49:05.808326  5145 solver.cpp:228] Iteration 19300, loss = 0.168861
I0428 19:49:05.808460  5145 solver.cpp:244]     Train net output #0: loss = 0.168861 (* 1 = 0.168861 loss)
I0428 19:49:05.808468  5145 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0428 19:49:56.467656  5145 solver.cpp:228] Iteration 19400, loss = 0.225147
I0428 19:49:56.467797  5145 solver.cpp:244]     Train net output #0: loss = 0.225147 (* 1 = 0.225147 loss)
I0428 19:49:56.467803  5145 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0428 19:50:47.121754  5145 solver.cpp:228] Iteration 19500, loss = 0.286312
I0428 19:50:47.121917  5145 solver.cpp:244]     Train net output #0: loss = 0.286312 (* 1 = 0.286312 loss)
I0428 19:50:47.121925  5145 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0428 19:51:39.638175  5145 solver.cpp:228] Iteration 19600, loss = 0.178894
I0428 19:51:39.638365  5145 solver.cpp:244]     Train net output #0: loss = 0.178894 (* 1 = 0.178894 loss)
I0428 19:51:39.638375  5145 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0428 19:52:30.292068  5145 solver.cpp:228] Iteration 19700, loss = 0.369003
I0428 19:52:30.292402  5145 solver.cpp:244]     Train net output #0: loss = 0.369003 (* 1 = 0.369003 loss)
I0428 19:52:30.292409  5145 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0428 19:53:20.954715  5145 solver.cpp:228] Iteration 19800, loss = 0.323054
I0428 19:53:20.954869  5145 solver.cpp:244]     Train net output #0: loss = 0.323054 (* 1 = 0.323054 loss)
I0428 19:53:20.954877  5145 sgd_solver.cpp:106] Iteration 19800, lr = 0.0001
I0428 19:54:13.553359  5145 solver.cpp:228] Iteration 19900, loss = 0.279576
I0428 19:54:13.553562  5145 solver.cpp:244]     Train net output #0: loss = 0.279576 (* 1 = 0.279576 loss)
I0428 19:54:13.553568  5145 sgd_solver.cpp:106] Iteration 19900, lr = 0.0001
I0428 19:55:03.914799  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_20000.caffemodel
I0428 19:55:22.313858  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_20000.solverstate
I0428 19:55:22.518527  5145 solver.cpp:337] Iteration 20000, Testing net (#0)
I0428 19:55:22.518625  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 19:55:22.518630  5145 net.cpp:693] Ignoring source layer visualize
I0428 19:55:22.518633  5145 net.cpp:693] Ignoring source layer fake
I0428 20:00:24.137111  5145 solver.cpp:404]     Test net output #0: loss = 0.297732 (* 1 = 0.297732 loss)
I0428 20:00:24.457588  5145 solver.cpp:228] Iteration 20000, loss = 0.293408
I0428 20:00:24.457609  5145 solver.cpp:244]     Train net output #0: loss = 0.293408 (* 1 = 0.293408 loss)
I0428 20:00:24.457631  5145 sgd_solver.cpp:106] Iteration 20000, lr = 0.0001
I0428 20:01:15.720139  5145 solver.cpp:228] Iteration 20100, loss = 0.214635
I0428 20:01:15.720341  5145 solver.cpp:244]     Train net output #0: loss = 0.214635 (* 1 = 0.214635 loss)
I0428 20:01:15.720350  5145 sgd_solver.cpp:106] Iteration 20100, lr = 0.0001
I0428 20:02:07.054347  5145 solver.cpp:228] Iteration 20200, loss = 0.276004
I0428 20:02:07.055804  5145 solver.cpp:244]     Train net output #0: loss = 0.276004 (* 1 = 0.276004 loss)
I0428 20:02:07.055811  5145 sgd_solver.cpp:106] Iteration 20200, lr = 0.0001
I0428 20:03:00.184866  5145 solver.cpp:228] Iteration 20300, loss = 0.24289
I0428 20:03:00.185032  5145 solver.cpp:244]     Train net output #0: loss = 0.24289 (* 1 = 0.24289 loss)
I0428 20:03:00.185039  5145 sgd_solver.cpp:106] Iteration 20300, lr = 0.0001
I0428 20:03:51.567157  5145 solver.cpp:228] Iteration 20400, loss = 0.375249
I0428 20:03:51.567344  5145 solver.cpp:244]     Train net output #0: loss = 0.375249 (* 1 = 0.375249 loss)
I0428 20:03:51.567354  5145 sgd_solver.cpp:106] Iteration 20400, lr = 0.0001
I0428 20:04:42.976694  5145 solver.cpp:228] Iteration 20500, loss = 0.289687
I0428 20:04:42.976866  5145 solver.cpp:244]     Train net output #0: loss = 0.289687 (* 1 = 0.289687 loss)
I0428 20:04:42.976874  5145 sgd_solver.cpp:106] Iteration 20500, lr = 0.0001
I0428 20:05:36.211508  5145 solver.cpp:228] Iteration 20600, loss = 0.35315
I0428 20:05:36.211654  5145 solver.cpp:244]     Train net output #0: loss = 0.35315 (* 1 = 0.35315 loss)
I0428 20:05:36.211661  5145 sgd_solver.cpp:106] Iteration 20600, lr = 0.0001
I0428 20:06:27.491559  5145 solver.cpp:228] Iteration 20700, loss = 0.233281
I0428 20:06:27.491780  5145 solver.cpp:244]     Train net output #0: loss = 0.233281 (* 1 = 0.233281 loss)
I0428 20:06:27.491796  5145 sgd_solver.cpp:106] Iteration 20700, lr = 0.0001
I0428 20:07:18.935461  5145 solver.cpp:228] Iteration 20800, loss = 0.211661
I0428 20:07:18.935628  5145 solver.cpp:244]     Train net output #0: loss = 0.211661 (* 1 = 0.211661 loss)
I0428 20:07:18.935636  5145 sgd_solver.cpp:106] Iteration 20800, lr = 0.0001
I0428 20:08:10.260542  5145 solver.cpp:228] Iteration 20900, loss = 0.379972
I0428 20:08:10.260699  5145 solver.cpp:244]     Train net output #0: loss = 0.379972 (* 1 = 0.379972 loss)
I0428 20:08:10.260705  5145 sgd_solver.cpp:106] Iteration 20900, lr = 0.0001
I0428 20:09:03.133087  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_21000.caffemodel
I0428 20:09:10.932759  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_21000.solverstate
I0428 20:09:11.182173  5145 solver.cpp:337] Iteration 21000, Testing net (#0)
I0428 20:09:11.182288  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 20:09:11.182296  5145 net.cpp:693] Ignoring source layer visualize
I0428 20:09:11.182314  5145 net.cpp:693] Ignoring source layer fake
I0428 20:14:14.865990  5145 solver.cpp:404]     Test net output #0: loss = 0.286636 (* 1 = 0.286636 loss)
I0428 20:14:15.187299  5145 solver.cpp:228] Iteration 21000, loss = 0.163562
I0428 20:14:15.187336  5145 solver.cpp:244]     Train net output #0: loss = 0.163562 (* 1 = 0.163562 loss)
I0428 20:14:15.187343  5145 sgd_solver.cpp:106] Iteration 21000, lr = 0.0001
I0428 20:15:06.639304  5145 solver.cpp:228] Iteration 21100, loss = 0.282781
I0428 20:15:06.639461  5145 solver.cpp:244]     Train net output #0: loss = 0.282781 (* 1 = 0.282781 loss)
I0428 20:15:06.639468  5145 sgd_solver.cpp:106] Iteration 21100, lr = 0.0001
I0428 20:15:58.063118  5145 solver.cpp:228] Iteration 21200, loss = 0.210158
I0428 20:15:58.063294  5145 solver.cpp:244]     Train net output #0: loss = 0.210158 (* 1 = 0.210158 loss)
I0428 20:15:58.063302  5145 sgd_solver.cpp:106] Iteration 21200, lr = 0.0001
I0428 20:16:51.220073  5145 solver.cpp:228] Iteration 21300, loss = 0.20868
I0428 20:16:51.221302  5145 solver.cpp:244]     Train net output #0: loss = 0.20868 (* 1 = 0.20868 loss)
I0428 20:16:51.221319  5145 sgd_solver.cpp:106] Iteration 21300, lr = 0.0001
I0428 20:17:42.636407  5145 solver.cpp:228] Iteration 21400, loss = 0.295125
I0428 20:17:42.636586  5145 solver.cpp:244]     Train net output #0: loss = 0.295125 (* 1 = 0.295125 loss)
I0428 20:17:42.636593  5145 sgd_solver.cpp:106] Iteration 21400, lr = 0.0001
I0428 20:18:34.024138  5145 solver.cpp:228] Iteration 21500, loss = 0.216852
I0428 20:18:34.024291  5145 solver.cpp:244]     Train net output #0: loss = 0.216852 (* 1 = 0.216852 loss)
I0428 20:18:34.024298  5145 sgd_solver.cpp:106] Iteration 21500, lr = 0.0001
I0428 20:19:26.983579  5145 solver.cpp:228] Iteration 21600, loss = 0.257236
I0428 20:19:26.983737  5145 solver.cpp:244]     Train net output #0: loss = 0.257236 (* 1 = 0.257236 loss)
I0428 20:19:26.983744  5145 sgd_solver.cpp:106] Iteration 21600, lr = 0.0001
I0428 20:20:18.414733  5145 solver.cpp:228] Iteration 21700, loss = 0.184578
I0428 20:20:18.414897  5145 solver.cpp:244]     Train net output #0: loss = 0.184578 (* 1 = 0.184578 loss)
I0428 20:20:18.414903  5145 sgd_solver.cpp:106] Iteration 21700, lr = 0.0001
I0428 20:21:09.794507  5145 solver.cpp:228] Iteration 21800, loss = 0.220308
I0428 20:21:09.794667  5145 solver.cpp:244]     Train net output #0: loss = 0.220308 (* 1 = 0.220308 loss)
I0428 20:21:09.794672  5145 sgd_solver.cpp:106] Iteration 21800, lr = 0.0001
I0428 20:22:02.329241  5145 solver.cpp:228] Iteration 21900, loss = 0.347763
I0428 20:22:02.329387  5145 solver.cpp:244]     Train net output #0: loss = 0.347763 (* 1 = 0.347763 loss)
I0428 20:22:02.329394  5145 sgd_solver.cpp:106] Iteration 21900, lr = 0.0001
I0428 20:22:53.348975  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_22000.caffemodel
I0428 20:23:08.919046  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_22000.solverstate
I0428 20:23:09.104545  5145 solver.cpp:337] Iteration 22000, Testing net (#0)
I0428 20:23:09.104645  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 20:23:09.104650  5145 net.cpp:693] Ignoring source layer visualize
I0428 20:23:09.104652  5145 net.cpp:693] Ignoring source layer fake
I0428 20:28:12.134521  5145 solver.cpp:404]     Test net output #0: loss = 0.285655 (* 1 = 0.285655 loss)
I0428 20:28:12.455232  5145 solver.cpp:228] Iteration 22000, loss = 0.172457
I0428 20:28:12.455250  5145 solver.cpp:244]     Train net output #0: loss = 0.172457 (* 1 = 0.172457 loss)
I0428 20:28:12.455271  5145 sgd_solver.cpp:106] Iteration 22000, lr = 0.0001
I0428 20:29:03.914319  5145 solver.cpp:228] Iteration 22100, loss = 0.312487
I0428 20:29:03.914475  5145 solver.cpp:244]     Train net output #0: loss = 0.312487 (* 1 = 0.312487 loss)
I0428 20:29:03.914481  5145 sgd_solver.cpp:106] Iteration 22100, lr = 0.0001
I0428 20:29:56.498965  5145 solver.cpp:228] Iteration 22200, loss = 0.303559
I0428 20:29:56.499128  5145 solver.cpp:244]     Train net output #0: loss = 0.303559 (* 1 = 0.303559 loss)
I0428 20:29:56.499135  5145 sgd_solver.cpp:106] Iteration 22200, lr = 0.0001
I0428 20:30:47.919919  5145 solver.cpp:228] Iteration 22300, loss = 0.311941
I0428 20:30:47.920073  5145 solver.cpp:244]     Train net output #0: loss = 0.311941 (* 1 = 0.311941 loss)
I0428 20:30:47.920079  5145 sgd_solver.cpp:106] Iteration 22300, lr = 0.0001
I0428 20:31:40.875000  5145 solver.cpp:228] Iteration 22400, loss = 0.15775
I0428 20:31:40.875147  5145 solver.cpp:244]     Train net output #0: loss = 0.15775 (* 1 = 0.15775 loss)
I0428 20:31:40.875154  5145 sgd_solver.cpp:106] Iteration 22400, lr = 0.0001
I0428 20:32:32.355922  5145 solver.cpp:228] Iteration 22500, loss = 0.288122
I0428 20:32:32.356072  5145 solver.cpp:244]     Train net output #0: loss = 0.288122 (* 1 = 0.288122 loss)
I0428 20:32:32.356078  5145 sgd_solver.cpp:106] Iteration 22500, lr = 1e-05
I0428 20:33:23.768169  5145 solver.cpp:228] Iteration 22600, loss = 0.348907
I0428 20:33:23.768311  5145 solver.cpp:244]     Train net output #0: loss = 0.348907 (* 1 = 0.348907 loss)
I0428 20:33:23.768317  5145 sgd_solver.cpp:106] Iteration 22600, lr = 1e-05
I0428 20:34:16.870066  5145 solver.cpp:228] Iteration 22700, loss = 0.205016
I0428 20:34:16.870247  5145 solver.cpp:244]     Train net output #0: loss = 0.205016 (* 1 = 0.205016 loss)
I0428 20:34:16.870255  5145 sgd_solver.cpp:106] Iteration 22700, lr = 1e-05
I0428 20:35:08.234158  5145 solver.cpp:228] Iteration 22800, loss = 0.169341
I0428 20:35:08.234318  5145 solver.cpp:244]     Train net output #0: loss = 0.169341 (* 1 = 0.169341 loss)
I0428 20:35:08.234324  5145 sgd_solver.cpp:106] Iteration 22800, lr = 1e-05
I0428 20:35:59.679834  5145 solver.cpp:228] Iteration 22900, loss = 0.429157
I0428 20:35:59.680001  5145 solver.cpp:244]     Train net output #0: loss = 0.429157 (* 1 = 0.429157 loss)
I0428 20:35:59.680008  5145 sgd_solver.cpp:106] Iteration 22900, lr = 1e-05
I0428 20:36:50.712857  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_23000.caffemodel
I0428 20:36:54.132293  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_23000.solverstate
I0428 20:36:54.324805  5145 solver.cpp:337] Iteration 23000, Testing net (#0)
I0428 20:36:54.324887  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 20:36:54.324892  5145 net.cpp:693] Ignoring source layer visualize
I0428 20:36:54.324893  5145 net.cpp:693] Ignoring source layer fake
I0428 20:41:57.117280  5145 solver.cpp:404]     Test net output #0: loss = 0.297017 (* 1 = 0.297017 loss)
I0428 20:41:57.437121  5145 solver.cpp:228] Iteration 23000, loss = 0.384019
I0428 20:41:57.437139  5145 solver.cpp:244]     Train net output #0: loss = 0.384019 (* 1 = 0.384019 loss)
I0428 20:41:57.437161  5145 sgd_solver.cpp:106] Iteration 23000, lr = 1e-05
I0428 20:42:50.704576  5145 solver.cpp:228] Iteration 23100, loss = 0.426699
I0428 20:42:50.704735  5145 solver.cpp:244]     Train net output #0: loss = 0.426699 (* 1 = 0.426699 loss)
I0428 20:42:50.704741  5145 sgd_solver.cpp:106] Iteration 23100, lr = 1e-05
I0428 20:43:42.032660  5145 solver.cpp:228] Iteration 23200, loss = 0.32633
I0428 20:43:42.032814  5145 solver.cpp:244]     Train net output #0: loss = 0.32633 (* 1 = 0.32633 loss)
I0428 20:43:42.032821  5145 sgd_solver.cpp:106] Iteration 23200, lr = 1e-05
I0428 20:44:33.385179  5145 solver.cpp:228] Iteration 23300, loss = 0.322101
I0428 20:44:33.385341  5145 solver.cpp:244]     Train net output #0: loss = 0.322101 (* 1 = 0.322101 loss)
I0428 20:44:33.385360  5145 sgd_solver.cpp:106] Iteration 23300, lr = 1e-05
I0428 20:45:26.584827  5145 solver.cpp:228] Iteration 23400, loss = 0.251261
I0428 20:45:26.584988  5145 solver.cpp:244]     Train net output #0: loss = 0.251261 (* 1 = 0.251261 loss)
I0428 20:45:26.584995  5145 sgd_solver.cpp:106] Iteration 23400, lr = 1e-05
I0428 20:46:18.014099  5145 solver.cpp:228] Iteration 23500, loss = 0.22211
I0428 20:46:18.014237  5145 solver.cpp:244]     Train net output #0: loss = 0.22211 (* 1 = 0.22211 loss)
I0428 20:46:18.014245  5145 sgd_solver.cpp:106] Iteration 23500, lr = 1e-05
I0428 20:47:09.391417  5145 solver.cpp:228] Iteration 23600, loss = 0.32949
I0428 20:47:09.391566  5145 solver.cpp:244]     Train net output #0: loss = 0.32949 (* 1 = 0.32949 loss)
I0428 20:47:09.391573  5145 sgd_solver.cpp:106] Iteration 23600, lr = 1e-05
I0428 20:48:02.616443  5145 solver.cpp:228] Iteration 23700, loss = 0.245379
I0428 20:48:02.616591  5145 solver.cpp:244]     Train net output #0: loss = 0.245379 (* 1 = 0.245379 loss)
I0428 20:48:02.616598  5145 sgd_solver.cpp:106] Iteration 23700, lr = 1e-05
I0428 20:48:53.999694  5145 solver.cpp:228] Iteration 23800, loss = 0.224483
I0428 20:48:53.999841  5145 solver.cpp:244]     Train net output #0: loss = 0.224483 (* 1 = 0.224483 loss)
I0428 20:48:53.999847  5145 sgd_solver.cpp:106] Iteration 23800, lr = 1e-05
I0428 20:49:45.308280  5145 solver.cpp:228] Iteration 23900, loss = 0.403527
I0428 20:49:45.308447  5145 solver.cpp:244]     Train net output #0: loss = 0.403527 (* 1 = 0.403527 loss)
I0428 20:49:45.308454  5145 sgd_solver.cpp:106] Iteration 23900, lr = 1e-05
I0428 20:50:36.332388  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_24000.caffemodel
I0428 20:50:43.302163  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_24000.solverstate
I0428 20:50:43.491899  5145 solver.cpp:337] Iteration 24000, Testing net (#0)
I0428 20:50:43.491979  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 20:50:43.491983  5145 net.cpp:693] Ignoring source layer visualize
I0428 20:50:43.491986  5145 net.cpp:693] Ignoring source layer fake
I0428 20:55:46.867172  5145 solver.cpp:404]     Test net output #0: loss = 0.291813 (* 1 = 0.291813 loss)
I0428 20:55:47.186933  5145 solver.cpp:228] Iteration 24000, loss = 0.261962
I0428 20:55:47.186952  5145 solver.cpp:244]     Train net output #0: loss = 0.261962 (* 1 = 0.261962 loss)
I0428 20:55:47.186975  5145 sgd_solver.cpp:106] Iteration 24000, lr = 1e-05
I0428 20:56:40.324335  5145 solver.cpp:228] Iteration 24100, loss = 0.157779
I0428 20:56:40.324506  5145 solver.cpp:244]     Train net output #0: loss = 0.157779 (* 1 = 0.157779 loss)
I0428 20:56:40.324513  5145 sgd_solver.cpp:106] Iteration 24100, lr = 1e-05
I0428 20:57:31.858968  5145 solver.cpp:228] Iteration 24200, loss = 0.241263
I0428 20:57:31.860291  5145 solver.cpp:244]     Train net output #0: loss = 0.241263 (* 1 = 0.241263 loss)
I0428 20:57:31.860311  5145 sgd_solver.cpp:106] Iteration 24200, lr = 1e-05
I0428 20:58:23.262622  5145 solver.cpp:228] Iteration 24300, loss = 0.21098
I0428 20:58:23.262783  5145 solver.cpp:244]     Train net output #0: loss = 0.21098 (* 1 = 0.21098 loss)
I0428 20:58:23.262790  5145 sgd_solver.cpp:106] Iteration 24300, lr = 1e-05
I0428 20:59:16.438575  5145 solver.cpp:228] Iteration 24400, loss = 0.19262
I0428 20:59:16.438731  5145 solver.cpp:244]     Train net output #0: loss = 0.19262 (* 1 = 0.19262 loss)
I0428 20:59:16.438740  5145 sgd_solver.cpp:106] Iteration 24400, lr = 1e-05
I0428 21:00:07.816189  5145 solver.cpp:228] Iteration 24500, loss = 0.199334
I0428 21:00:07.816347  5145 solver.cpp:244]     Train net output #0: loss = 0.199334 (* 1 = 0.199334 loss)
I0428 21:00:07.816354  5145 sgd_solver.cpp:106] Iteration 24500, lr = 1e-05
I0428 21:00:59.275321  5145 solver.cpp:228] Iteration 24600, loss = 0.310696
I0428 21:00:59.275482  5145 solver.cpp:244]     Train net output #0: loss = 0.310696 (* 1 = 0.310696 loss)
I0428 21:00:59.275490  5145 sgd_solver.cpp:106] Iteration 24600, lr = 1e-05
I0428 21:01:52.271105  5145 solver.cpp:228] Iteration 24700, loss = 0.183927
I0428 21:01:52.271272  5145 solver.cpp:244]     Train net output #0: loss = 0.183927 (* 1 = 0.183927 loss)
I0428 21:01:52.271280  5145 sgd_solver.cpp:106] Iteration 24700, lr = 1e-05
I0428 21:02:43.622823  5145 solver.cpp:228] Iteration 24800, loss = 0.19112
I0428 21:02:43.622982  5145 solver.cpp:244]     Train net output #0: loss = 0.19112 (* 1 = 0.19112 loss)
I0428 21:02:43.622988  5145 sgd_solver.cpp:106] Iteration 24800, lr = 1e-05
I0428 21:03:35.091948  5145 solver.cpp:228] Iteration 24900, loss = 0.204615
I0428 21:03:35.092084  5145 solver.cpp:244]     Train net output #0: loss = 0.204615 (* 1 = 0.204615 loss)
I0428 21:03:35.092092  5145 sgd_solver.cpp:106] Iteration 24900, lr = 1e-05
I0428 21:04:27.506829  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_25000.caffemodel
I0428 21:04:36.951514  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_25000.solverstate
I0428 21:04:37.143978  5145 solver.cpp:337] Iteration 25000, Testing net (#0)
I0428 21:04:37.144062  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 21:04:37.144067  5145 net.cpp:693] Ignoring source layer visualize
I0428 21:04:37.144084  5145 net.cpp:693] Ignoring source layer fake
I0428 21:09:40.001605  5145 solver.cpp:404]     Test net output #0: loss = 0.288329 (* 1 = 0.288329 loss)
I0428 21:09:40.320446  5145 solver.cpp:228] Iteration 25000, loss = 0.186419
I0428 21:09:40.320466  5145 solver.cpp:244]     Train net output #0: loss = 0.186419 (* 1 = 0.186419 loss)
I0428 21:09:40.320487  5145 sgd_solver.cpp:106] Iteration 25000, lr = 1e-05
I0428 21:10:31.840107  5145 solver.cpp:228] Iteration 25100, loss = 0.273249
I0428 21:10:31.840281  5145 solver.cpp:244]     Train net output #0: loss = 0.273249 (* 1 = 0.273249 loss)
I0428 21:10:31.840289  5145 sgd_solver.cpp:106] Iteration 25100, lr = 1e-05
I0428 21:11:23.330384  5145 solver.cpp:228] Iteration 25200, loss = 0.204828
I0428 21:11:23.330548  5145 solver.cpp:244]     Train net output #0: loss = 0.204828 (* 1 = 0.204828 loss)
I0428 21:11:23.330554  5145 sgd_solver.cpp:106] Iteration 25200, lr = 1e-05
I0428 21:12:25.379390  5145 solver.cpp:228] Iteration 25300, loss = 0.148411
I0428 21:12:25.379552  5145 solver.cpp:244]     Train net output #0: loss = 0.148411 (* 1 = 0.148411 loss)
I0428 21:12:25.379560  5145 sgd_solver.cpp:106] Iteration 25300, lr = 1e-05
I0428 21:13:16.714838  5145 solver.cpp:228] Iteration 25400, loss = 0.288107
I0428 21:13:16.715008  5145 solver.cpp:244]     Train net output #0: loss = 0.288107 (* 1 = 0.288107 loss)
I0428 21:13:16.715014  5145 sgd_solver.cpp:106] Iteration 25400, lr = 1e-05
I0428 21:14:08.189615  5145 solver.cpp:228] Iteration 25500, loss = 0.106391
I0428 21:14:08.189764  5145 solver.cpp:244]     Train net output #0: loss = 0.106391 (* 1 = 0.106391 loss)
I0428 21:14:08.189771  5145 sgd_solver.cpp:106] Iteration 25500, lr = 1e-05
I0428 21:15:13.276994  5145 solver.cpp:228] Iteration 25600, loss = 0.227873
I0428 21:15:13.277176  5145 solver.cpp:244]     Train net output #0: loss = 0.227873 (* 1 = 0.227873 loss)
I0428 21:15:13.277185  5145 sgd_solver.cpp:106] Iteration 25600, lr = 1e-05
I0428 21:16:04.725003  5145 solver.cpp:228] Iteration 25700, loss = 0.336693
I0428 21:16:04.726743  5145 solver.cpp:244]     Train net output #0: loss = 0.336693 (* 1 = 0.336693 loss)
I0428 21:16:04.726752  5145 sgd_solver.cpp:106] Iteration 25700, lr = 1e-05
I0428 21:17:13.087524  5145 solver.cpp:228] Iteration 25800, loss = 0.290228
I0428 21:17:13.087692  5145 solver.cpp:244]     Train net output #0: loss = 0.290228 (* 1 = 0.290228 loss)
I0428 21:17:13.087698  5145 sgd_solver.cpp:106] Iteration 25800, lr = 1e-05
I0428 21:18:03.835937  5145 solver.cpp:228] Iteration 25900, loss = 0.377793
I0428 21:18:03.836092  5145 solver.cpp:244]     Train net output #0: loss = 0.377793 (* 1 = 0.377793 loss)
I0428 21:18:03.836100  5145 sgd_solver.cpp:106] Iteration 25900, lr = 1e-05
I0428 21:18:54.964447  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_26000.caffemodel
I0428 21:19:03.204264  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_26000.solverstate
I0428 21:19:03.433573  5145 solver.cpp:337] Iteration 26000, Testing net (#0)
I0428 21:19:03.433660  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 21:19:03.433663  5145 net.cpp:693] Ignoring source layer visualize
I0428 21:19:03.433666  5145 net.cpp:693] Ignoring source layer fake
I0428 21:24:06.850198  5145 solver.cpp:404]     Test net output #0: loss = 0.287449 (* 1 = 0.287449 loss)
I0428 21:24:07.171090  5145 solver.cpp:228] Iteration 26000, loss = 0.20402
I0428 21:24:07.171108  5145 solver.cpp:244]     Train net output #0: loss = 0.20402 (* 1 = 0.20402 loss)
I0428 21:24:07.171129  5145 sgd_solver.cpp:106] Iteration 26000, lr = 1e-05
I0428 21:24:58.618162  5145 solver.cpp:228] Iteration 26100, loss = 0.372031
I0428 21:24:58.618305  5145 solver.cpp:244]     Train net output #0: loss = 0.372031 (* 1 = 0.372031 loss)
I0428 21:24:58.618312  5145 sgd_solver.cpp:106] Iteration 26100, lr = 1e-05
I0428 21:26:03.999986  5145 solver.cpp:228] Iteration 26200, loss = 0.265897
I0428 21:26:04.000149  5145 solver.cpp:244]     Train net output #0: loss = 0.265897 (* 1 = 0.265897 loss)
I0428 21:26:04.000157  5145 sgd_solver.cpp:106] Iteration 26200, lr = 1e-05
I0428 21:26:55.301822  5145 solver.cpp:228] Iteration 26300, loss = 0.212934
I0428 21:26:55.301995  5145 solver.cpp:244]     Train net output #0: loss = 0.212934 (* 1 = 0.212934 loss)
I0428 21:26:55.302002  5145 sgd_solver.cpp:106] Iteration 26300, lr = 1e-05
I0428 21:27:46.857405  5145 solver.cpp:228] Iteration 26400, loss = 0.243549
I0428 21:27:46.857589  5145 solver.cpp:244]     Train net output #0: loss = 0.243549 (* 1 = 0.243549 loss)
I0428 21:27:46.857595  5145 sgd_solver.cpp:106] Iteration 26400, lr = 1e-05
I0428 21:29:08.621909  5145 solver.cpp:228] Iteration 26500, loss = 0.324177
I0428 21:29:08.622077  5145 solver.cpp:244]     Train net output #0: loss = 0.324177 (* 1 = 0.324177 loss)
I0428 21:29:08.622084  5145 sgd_solver.cpp:106] Iteration 26500, lr = 1e-05
I0428 21:29:58.278849  5145 solver.cpp:228] Iteration 26600, loss = 0.359458
I0428 21:29:58.278997  5145 solver.cpp:244]     Train net output #0: loss = 0.359458 (* 1 = 0.359458 loss)
I0428 21:29:58.279005  5145 sgd_solver.cpp:106] Iteration 26600, lr = 1e-05
I0428 21:30:48.594225  5145 solver.cpp:228] Iteration 26700, loss = 0.346894
I0428 21:30:48.594385  5145 solver.cpp:244]     Train net output #0: loss = 0.346894 (* 1 = 0.346894 loss)
I0428 21:30:48.594393  5145 sgd_solver.cpp:106] Iteration 26700, lr = 1e-05
I0428 21:31:39.112233  5145 solver.cpp:228] Iteration 26800, loss = 0.287591
I0428 21:31:39.112426  5145 solver.cpp:244]     Train net output #0: loss = 0.287591 (* 1 = 0.287591 loss)
I0428 21:31:39.112434  5145 sgd_solver.cpp:106] Iteration 26800, lr = 1e-05
I0428 21:32:31.426883  5145 solver.cpp:228] Iteration 26900, loss = 0.239805
I0428 21:32:31.428158  5145 solver.cpp:244]     Train net output #0: loss = 0.239805 (* 1 = 0.239805 loss)
I0428 21:32:31.428167  5145 sgd_solver.cpp:106] Iteration 26900, lr = 1e-05
I0428 21:33:21.596066  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_27000.caffemodel
I0428 21:33:25.526166  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_27000.solverstate
I0428 21:33:25.730274  5145 solver.cpp:337] Iteration 27000, Testing net (#0)
I0428 21:33:25.730375  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 21:33:25.730379  5145 net.cpp:693] Ignoring source layer visualize
I0428 21:33:25.730382  5145 net.cpp:693] Ignoring source layer fake
I0428 21:38:22.760068  5145 solver.cpp:404]     Test net output #0: loss = 0.287527 (* 1 = 0.287527 loss)
I0428 21:38:23.075004  5145 solver.cpp:228] Iteration 27000, loss = 0.208431
I0428 21:38:23.075045  5145 solver.cpp:244]     Train net output #0: loss = 0.208431 (* 1 = 0.208431 loss)
I0428 21:38:23.075054  5145 sgd_solver.cpp:106] Iteration 27000, lr = 1e-05
I0428 21:39:13.712855  5145 solver.cpp:228] Iteration 27100, loss = 0.2608
I0428 21:39:13.713059  5145 solver.cpp:244]     Train net output #0: loss = 0.2608 (* 1 = 0.2608 loss)
I0428 21:39:13.713068  5145 sgd_solver.cpp:106] Iteration 27100, lr = 1e-05
I0428 21:40:05.927940  5145 solver.cpp:228] Iteration 27200, loss = 0.371684
I0428 21:40:05.930526  5145 solver.cpp:244]     Train net output #0: loss = 0.371684 (* 1 = 0.371684 loss)
I0428 21:40:05.930536  5145 sgd_solver.cpp:106] Iteration 27200, lr = 1e-05
I0428 21:40:56.462308  5145 solver.cpp:228] Iteration 27300, loss = 0.278187
I0428 21:40:56.462466  5145 solver.cpp:244]     Train net output #0: loss = 0.278187 (* 1 = 0.278187 loss)
I0428 21:40:56.462473  5145 sgd_solver.cpp:106] Iteration 27300, lr = 1e-05
I0428 21:41:47.024148  5145 solver.cpp:228] Iteration 27400, loss = 0.171161
I0428 21:41:47.024339  5145 solver.cpp:244]     Train net output #0: loss = 0.171161 (* 1 = 0.171161 loss)
I0428 21:41:47.024349  5145 sgd_solver.cpp:106] Iteration 27400, lr = 1e-05
I0428 21:42:39.404887  5145 solver.cpp:228] Iteration 27500, loss = 0.20957
I0428 21:42:39.405086  5145 solver.cpp:244]     Train net output #0: loss = 0.20957 (* 1 = 0.20957 loss)
I0428 21:42:39.405095  5145 sgd_solver.cpp:106] Iteration 27500, lr = 1e-05
I0428 21:43:29.857264  5145 solver.cpp:228] Iteration 27600, loss = 0.110841
I0428 21:43:29.857431  5145 solver.cpp:244]     Train net output #0: loss = 0.110841 (* 1 = 0.110841 loss)
I0428 21:43:29.857450  5145 sgd_solver.cpp:106] Iteration 27600, lr = 1e-05
I0428 21:44:20.393735  5145 solver.cpp:228] Iteration 27700, loss = 0.246348
I0428 21:44:20.393903  5145 solver.cpp:244]     Train net output #0: loss = 0.246348 (* 1 = 0.246348 loss)
I0428 21:44:20.393911  5145 sgd_solver.cpp:106] Iteration 27700, lr = 1e-05
I0428 21:45:11.007982  5145 solver.cpp:228] Iteration 27800, loss = 0.211257
I0428 21:45:11.008157  5145 solver.cpp:244]     Train net output #0: loss = 0.211257 (* 1 = 0.211257 loss)
I0428 21:45:11.008165  5145 sgd_solver.cpp:106] Iteration 27800, lr = 1e-05
I0428 21:46:03.993553  5145 solver.cpp:228] Iteration 27900, loss = 0.0919155
I0428 21:46:03.993693  5145 solver.cpp:244]     Train net output #0: loss = 0.0919155 (* 1 = 0.0919155 loss)
I0428 21:46:03.993700  5145 sgd_solver.cpp:106] Iteration 27900, lr = 1e-05
I0428 21:46:54.134524  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_28000.caffemodel
I0428 21:47:08.856019  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_28000.solverstate
I0428 21:47:09.050838  5145 solver.cpp:337] Iteration 28000, Testing net (#0)
I0428 21:47:09.050920  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 21:47:09.050925  5145 net.cpp:693] Ignoring source layer visualize
I0428 21:47:09.050942  5145 net.cpp:693] Ignoring source layer fake
I0428 21:52:05.579040  5145 solver.cpp:404]     Test net output #0: loss = 0.276855 (* 1 = 0.276855 loss)
I0428 21:52:05.893213  5145 solver.cpp:228] Iteration 28000, loss = 0.308441
I0428 21:52:05.893250  5145 solver.cpp:244]     Train net output #0: loss = 0.308441 (* 1 = 0.308441 loss)
I0428 21:52:05.893259  5145 sgd_solver.cpp:106] Iteration 28000, lr = 1e-05
I0428 21:52:56.487892  5145 solver.cpp:228] Iteration 28100, loss = 0.241965
I0428 21:52:56.488064  5145 solver.cpp:244]     Train net output #0: loss = 0.241965 (* 1 = 0.241965 loss)
I0428 21:52:56.488070  5145 sgd_solver.cpp:106] Iteration 28100, lr = 1e-05
I0428 21:53:48.313541  5145 solver.cpp:228] Iteration 28200, loss = 0.180795
I0428 21:53:48.313706  5145 solver.cpp:244]     Train net output #0: loss = 0.180795 (* 1 = 0.180795 loss)
I0428 21:53:48.313714  5145 sgd_solver.cpp:106] Iteration 28200, lr = 1e-05
I0428 21:54:38.921203  5145 solver.cpp:228] Iteration 28300, loss = 0.316999
I0428 21:54:38.921386  5145 solver.cpp:244]     Train net output #0: loss = 0.316999 (* 1 = 0.316999 loss)
I0428 21:54:38.921394  5145 sgd_solver.cpp:106] Iteration 28300, lr = 1e-05
I0428 21:55:30.998214  5145 solver.cpp:228] Iteration 28400, loss = 0.21474
I0428 21:55:30.998420  5145 solver.cpp:244]     Train net output #0: loss = 0.21474 (* 1 = 0.21474 loss)
I0428 21:55:30.998430  5145 sgd_solver.cpp:106] Iteration 28400, lr = 1e-05
I0428 21:56:21.549373  5145 solver.cpp:228] Iteration 28500, loss = 0.265422
I0428 21:56:21.549563  5145 solver.cpp:244]     Train net output #0: loss = 0.265422 (* 1 = 0.265422 loss)
I0428 21:56:21.549571  5145 sgd_solver.cpp:106] Iteration 28500, lr = 1e-05
I0428 21:57:12.163776  5145 solver.cpp:228] Iteration 28600, loss = 0.233163
I0428 21:57:12.163929  5145 solver.cpp:244]     Train net output #0: loss = 0.233163 (* 1 = 0.233163 loss)
I0428 21:57:12.163936  5145 sgd_solver.cpp:106] Iteration 28600, lr = 1e-05
I0428 21:58:04.129384  5145 solver.cpp:228] Iteration 28700, loss = 0.275969
I0428 21:58:04.129551  5145 solver.cpp:244]     Train net output #0: loss = 0.275969 (* 1 = 0.275969 loss)
I0428 21:58:04.129559  5145 sgd_solver.cpp:106] Iteration 28700, lr = 1e-05
I0428 21:58:54.661890  5145 solver.cpp:228] Iteration 28800, loss = 0.232971
I0428 21:58:54.662078  5145 solver.cpp:244]     Train net output #0: loss = 0.232971 (* 1 = 0.232971 loss)
I0428 21:58:54.662086  5145 sgd_solver.cpp:106] Iteration 28800, lr = 1e-05
I0428 21:59:45.264467  5145 solver.cpp:228] Iteration 28900, loss = 0.277764
I0428 21:59:45.264627  5145 solver.cpp:244]     Train net output #0: loss = 0.277764 (* 1 = 0.277764 loss)
I0428 21:59:45.264634  5145 sgd_solver.cpp:106] Iteration 28900, lr = 1e-05
I0428 22:00:37.102885  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_29000.caffemodel
I0428 22:00:53.295059  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_29000.solverstate
I0428 22:00:53.497193  5145 solver.cpp:337] Iteration 29000, Testing net (#0)
I0428 22:00:53.497265  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 22:00:53.497269  5145 net.cpp:693] Ignoring source layer visualize
I0428 22:00:53.497272  5145 net.cpp:693] Ignoring source layer fake
I0428 22:05:49.657320  5145 solver.cpp:404]     Test net output #0: loss = 0.287501 (* 1 = 0.287501 loss)
I0428 22:05:49.971923  5145 solver.cpp:228] Iteration 29000, loss = 0.411857
I0428 22:05:49.971959  5145 solver.cpp:244]     Train net output #0: loss = 0.411857 (* 1 = 0.411857 loss)
I0428 22:05:49.971966  5145 sgd_solver.cpp:106] Iteration 29000, lr = 1e-05
I0428 22:06:40.596112  5145 solver.cpp:228] Iteration 29100, loss = 0.312158
I0428 22:06:40.596282  5145 solver.cpp:244]     Train net output #0: loss = 0.312158 (* 1 = 0.312158 loss)
I0428 22:06:40.596290  5145 sgd_solver.cpp:106] Iteration 29100, lr = 1e-05
I0428 22:07:31.169680  5145 solver.cpp:228] Iteration 29200, loss = 0.324766
I0428 22:07:31.169847  5145 solver.cpp:244]     Train net output #0: loss = 0.324766 (* 1 = 0.324766 loss)
I0428 22:07:31.169855  5145 sgd_solver.cpp:106] Iteration 29200, lr = 1e-05
I0428 22:08:23.510485  5145 solver.cpp:228] Iteration 29300, loss = 0.317293
I0428 22:08:23.510660  5145 solver.cpp:244]     Train net output #0: loss = 0.317293 (* 1 = 0.317293 loss)
I0428 22:08:23.510669  5145 sgd_solver.cpp:106] Iteration 29300, lr = 1e-05
I0428 22:09:14.042556  5145 solver.cpp:228] Iteration 29400, loss = 0.288309
I0428 22:09:14.042727  5145 solver.cpp:244]     Train net output #0: loss = 0.288309 (* 1 = 0.288309 loss)
I0428 22:09:14.042734  5145 sgd_solver.cpp:106] Iteration 29400, lr = 1e-05
I0428 22:10:04.654026  5145 solver.cpp:228] Iteration 29500, loss = 0.15709
I0428 22:10:04.654191  5145 solver.cpp:244]     Train net output #0: loss = 0.15709 (* 1 = 0.15709 loss)
I0428 22:10:04.654199  5145 sgd_solver.cpp:106] Iteration 29500, lr = 1e-05
I0428 22:10:57.124594  5145 solver.cpp:228] Iteration 29600, loss = 0.249499
I0428 22:10:57.124759  5145 solver.cpp:244]     Train net output #0: loss = 0.249499 (* 1 = 0.249499 loss)
I0428 22:10:57.124766  5145 sgd_solver.cpp:106] Iteration 29600, lr = 1e-05
I0428 22:11:47.577821  5145 solver.cpp:228] Iteration 29700, loss = 0.252581
I0428 22:11:47.578002  5145 solver.cpp:244]     Train net output #0: loss = 0.252581 (* 1 = 0.252581 loss)
I0428 22:11:47.578009  5145 sgd_solver.cpp:106] Iteration 29700, lr = 1e-05
I0428 22:12:38.136081  5145 solver.cpp:228] Iteration 29800, loss = 0.411997
I0428 22:12:38.136251  5145 solver.cpp:244]     Train net output #0: loss = 0.411997 (* 1 = 0.411997 loss)
I0428 22:12:38.136260  5145 sgd_solver.cpp:106] Iteration 29800, lr = 1e-05
I0428 22:13:28.655385  5145 solver.cpp:228] Iteration 29900, loss = 0.312201
I0428 22:13:28.655544  5145 solver.cpp:244]     Train net output #0: loss = 0.312201 (* 1 = 0.312201 loss)
I0428 22:13:28.655562  5145 sgd_solver.cpp:106] Iteration 29900, lr = 1e-05
I0428 22:14:20.714119  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_30000.caffemodel
I0428 22:14:43.722710  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_30000.solverstate
I0428 22:14:43.921936  5145 solver.cpp:337] Iteration 30000, Testing net (#0)
I0428 22:14:43.922022  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 22:14:43.922025  5145 net.cpp:693] Ignoring source layer visualize
I0428 22:14:43.922027  5145 net.cpp:693] Ignoring source layer fake
I0428 22:19:40.504190  5145 solver.cpp:404]     Test net output #0: loss = 0.293475 (* 1 = 0.293475 loss)
I0428 22:19:40.817342  5145 solver.cpp:228] Iteration 30000, loss = 0.232865
I0428 22:19:40.817361  5145 solver.cpp:244]     Train net output #0: loss = 0.232865 (* 1 = 0.232865 loss)
I0428 22:19:40.817384  5145 sgd_solver.cpp:106] Iteration 30000, lr = 1e-06
I0428 22:20:31.447188  5145 solver.cpp:228] Iteration 30100, loss = 0.353686
I0428 22:20:31.447347  5145 solver.cpp:244]     Train net output #0: loss = 0.353686 (* 1 = 0.353686 loss)
I0428 22:20:31.447355  5145 sgd_solver.cpp:106] Iteration 30100, lr = 1e-06
I0428 22:21:22.034756  5145 solver.cpp:228] Iteration 30200, loss = 0.330428
I0428 22:21:22.034920  5145 solver.cpp:244]     Train net output #0: loss = 0.330428 (* 1 = 0.330428 loss)
I0428 22:21:22.034927  5145 sgd_solver.cpp:106] Iteration 30200, lr = 1e-06
I0428 22:22:14.294391  5145 solver.cpp:228] Iteration 30300, loss = 0.321367
I0428 22:22:14.294549  5145 solver.cpp:244]     Train net output #0: loss = 0.321367 (* 1 = 0.321367 loss)
I0428 22:22:14.294555  5145 sgd_solver.cpp:106] Iteration 30300, lr = 1e-06
I0428 22:23:04.961546  5145 solver.cpp:228] Iteration 30400, loss = 0.271334
I0428 22:23:04.961675  5145 solver.cpp:244]     Train net output #0: loss = 0.271334 (* 1 = 0.271334 loss)
I0428 22:23:04.961683  5145 sgd_solver.cpp:106] Iteration 30400, lr = 1e-06
I0428 22:23:55.495115  5145 solver.cpp:228] Iteration 30500, loss = 0.332508
I0428 22:23:55.495285  5145 solver.cpp:244]     Train net output #0: loss = 0.332508 (* 1 = 0.332508 loss)
I0428 22:23:55.495292  5145 sgd_solver.cpp:106] Iteration 30500, lr = 1e-06
I0428 22:24:46.131847  5145 solver.cpp:228] Iteration 30600, loss = 0.0725425
I0428 22:24:46.131999  5145 solver.cpp:244]     Train net output #0: loss = 0.0725425 (* 1 = 0.0725425 loss)
I0428 22:24:46.132006  5145 sgd_solver.cpp:106] Iteration 30600, lr = 1e-06
I0428 22:25:38.354473  5145 solver.cpp:228] Iteration 30700, loss = 0.200903
I0428 22:25:38.354635  5145 solver.cpp:244]     Train net output #0: loss = 0.200903 (* 1 = 0.200903 loss)
I0428 22:25:38.354640  5145 sgd_solver.cpp:106] Iteration 30700, lr = 1e-06
I0428 22:26:28.837222  5145 solver.cpp:228] Iteration 30800, loss = 0.236952
I0428 22:26:28.837388  5145 solver.cpp:244]     Train net output #0: loss = 0.236952 (* 1 = 0.236952 loss)
I0428 22:26:28.837393  5145 sgd_solver.cpp:106] Iteration 30800, lr = 1e-06
I0428 22:27:19.470732  5145 solver.cpp:228] Iteration 30900, loss = 0.223134
I0428 22:27:19.470898  5145 solver.cpp:244]     Train net output #0: loss = 0.223134 (* 1 = 0.223134 loss)
I0428 22:27:19.470904  5145 sgd_solver.cpp:106] Iteration 30900, lr = 1e-06
I0428 22:28:11.317368  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_31000.caffemodel
I0428 22:28:21.483177  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_31000.solverstate
I0428 22:28:21.672552  5145 solver.cpp:337] Iteration 31000, Testing net (#0)
I0428 22:28:21.672633  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 22:28:21.672636  5145 net.cpp:693] Ignoring source layer visualize
I0428 22:28:21.672638  5145 net.cpp:693] Ignoring source layer fake
I0428 22:33:17.743373  5145 solver.cpp:404]     Test net output #0: loss = 0.288146 (* 1 = 0.288146 loss)
I0428 22:33:18.063262  5145 solver.cpp:228] Iteration 31000, loss = 0.198137
I0428 22:33:18.063279  5145 solver.cpp:244]     Train net output #0: loss = 0.198137 (* 1 = 0.198137 loss)
I0428 22:33:18.063302  5145 sgd_solver.cpp:106] Iteration 31000, lr = 1e-06
I0428 22:34:08.717048  5145 solver.cpp:228] Iteration 31100, loss = 0.441023
I0428 22:34:08.717227  5145 solver.cpp:244]     Train net output #0: loss = 0.441023 (* 1 = 0.441023 loss)
I0428 22:34:08.717234  5145 sgd_solver.cpp:106] Iteration 31100, lr = 1e-06
I0428 22:34:59.412302  5145 solver.cpp:228] Iteration 31200, loss = 0.379679
I0428 22:34:59.412459  5145 solver.cpp:244]     Train net output #0: loss = 0.379679 (* 1 = 0.379679 loss)
I0428 22:34:59.412467  5145 sgd_solver.cpp:106] Iteration 31200, lr = 1e-06
I0428 22:35:51.272284  5145 solver.cpp:228] Iteration 31300, loss = 0.28328
I0428 22:35:51.272436  5145 solver.cpp:244]     Train net output #0: loss = 0.28328 (* 1 = 0.28328 loss)
I0428 22:35:51.272444  5145 sgd_solver.cpp:106] Iteration 31300, lr = 1e-06
I0428 22:36:41.834255  5145 solver.cpp:228] Iteration 31400, loss = 0.141379
I0428 22:36:41.834410  5145 solver.cpp:244]     Train net output #0: loss = 0.141379 (* 1 = 0.141379 loss)
I0428 22:36:41.834424  5145 sgd_solver.cpp:106] Iteration 31400, lr = 1e-06
I0428 22:37:33.635116  5145 solver.cpp:228] Iteration 31500, loss = 0.586287
I0428 22:37:33.635264  5145 solver.cpp:244]     Train net output #0: loss = 0.586287 (* 1 = 0.586287 loss)
I0428 22:37:33.635270  5145 sgd_solver.cpp:106] Iteration 31500, lr = 1e-06
I0428 22:38:24.255053  5145 solver.cpp:228] Iteration 31600, loss = 0.237467
I0428 22:38:24.255206  5145 solver.cpp:244]     Train net output #0: loss = 0.237467 (* 1 = 0.237467 loss)
I0428 22:38:24.255213  5145 sgd_solver.cpp:106] Iteration 31600, lr = 1e-06
I0428 22:39:14.845360  5145 solver.cpp:228] Iteration 31700, loss = 0.210999
I0428 22:39:14.845541  5145 solver.cpp:244]     Train net output #0: loss = 0.210999 (* 1 = 0.210999 loss)
I0428 22:39:14.845551  5145 sgd_solver.cpp:106] Iteration 31700, lr = 1e-06
I0428 22:40:06.861318  5145 solver.cpp:228] Iteration 31800, loss = 0.246162
I0428 22:40:06.861546  5145 solver.cpp:244]     Train net output #0: loss = 0.246162 (* 1 = 0.246162 loss)
I0428 22:40:06.861562  5145 sgd_solver.cpp:106] Iteration 31800, lr = 1e-06
I0428 22:40:57.473338  5145 solver.cpp:228] Iteration 31900, loss = 0.157215
I0428 22:40:57.473583  5145 solver.cpp:244]     Train net output #0: loss = 0.157215 (* 1 = 0.157215 loss)
I0428 22:40:57.473598  5145 sgd_solver.cpp:106] Iteration 31900, lr = 1e-06
I0428 22:41:47.356176  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_32000.caffemodel
I0428 22:42:00.768693  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_32000.solverstate
I0428 22:42:00.972146  5145 solver.cpp:337] Iteration 32000, Testing net (#0)
I0428 22:42:00.972226  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 22:42:00.972230  5145 net.cpp:693] Ignoring source layer visualize
I0428 22:42:00.972234  5145 net.cpp:693] Ignoring source layer fake
I0428 22:46:58.727846  5145 solver.cpp:404]     Test net output #0: loss = 0.285395 (* 1 = 0.285395 loss)
I0428 22:46:59.042282  5145 solver.cpp:228] Iteration 32000, loss = 0.296523
I0428 22:46:59.042300  5145 solver.cpp:244]     Train net output #0: loss = 0.296523 (* 1 = 0.296523 loss)
I0428 22:46:59.042323  5145 sgd_solver.cpp:106] Iteration 32000, lr = 1e-06
I0428 22:47:50.879889  5145 solver.cpp:228] Iteration 32100, loss = 0.329493
I0428 22:47:50.880059  5145 solver.cpp:244]     Train net output #0: loss = 0.329493 (* 1 = 0.329493 loss)
I0428 22:47:50.880065  5145 sgd_solver.cpp:106] Iteration 32100, lr = 1e-06
I0428 22:48:41.056780  5145 solver.cpp:228] Iteration 32200, loss = 0.173454
I0428 22:48:41.056949  5145 solver.cpp:244]     Train net output #0: loss = 0.173454 (* 1 = 0.173454 loss)
I0428 22:48:41.056957  5145 sgd_solver.cpp:106] Iteration 32200, lr = 1e-06
I0428 22:49:31.230058  5145 solver.cpp:228] Iteration 32300, loss = 0.410234
I0428 22:49:31.230221  5145 solver.cpp:244]     Train net output #0: loss = 0.410234 (* 1 = 0.410234 loss)
I0428 22:49:31.230227  5145 sgd_solver.cpp:106] Iteration 32300, lr = 1e-06
I0428 22:50:23.246366  5145 solver.cpp:228] Iteration 32400, loss = 0.237036
I0428 22:50:23.246551  5145 solver.cpp:244]     Train net output #0: loss = 0.237036 (* 1 = 0.237036 loss)
I0428 22:50:23.246558  5145 sgd_solver.cpp:106] Iteration 32400, lr = 1e-06
I0428 22:51:13.426615  5145 solver.cpp:228] Iteration 32500, loss = 0.147199
I0428 22:51:13.426782  5145 solver.cpp:244]     Train net output #0: loss = 0.147199 (* 1 = 0.147199 loss)
I0428 22:51:13.426790  5145 sgd_solver.cpp:106] Iteration 32500, lr = 1e-06
I0428 22:52:03.601833  5145 solver.cpp:228] Iteration 32600, loss = 0.282663
I0428 22:52:03.602816  5145 solver.cpp:244]     Train net output #0: loss = 0.282663 (* 1 = 0.282663 loss)
I0428 22:52:03.602838  5145 sgd_solver.cpp:106] Iteration 32600, lr = 1e-06
I0428 22:52:53.782397  5145 solver.cpp:228] Iteration 32700, loss = 0.330546
I0428 22:52:53.783062  5145 solver.cpp:244]     Train net output #0: loss = 0.330546 (* 1 = 0.330546 loss)
I0428 22:52:53.783084  5145 sgd_solver.cpp:106] Iteration 32700, lr = 1e-06
I0428 22:53:45.792466  5145 solver.cpp:228] Iteration 32800, loss = 0.207716
I0428 22:53:45.792629  5145 solver.cpp:244]     Train net output #0: loss = 0.207716 (* 1 = 0.207716 loss)
I0428 22:53:45.792636  5145 sgd_solver.cpp:106] Iteration 32800, lr = 1e-06
I0428 22:54:35.964916  5145 solver.cpp:228] Iteration 32900, loss = 0.278621
I0428 22:54:35.967844  5145 solver.cpp:244]     Train net output #0: loss = 0.278621 (* 1 = 0.278621 loss)
I0428 22:54:35.967867  5145 sgd_solver.cpp:106] Iteration 32900, lr = 1e-06
I0428 22:55:25.834740  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_33000.caffemodel
I0428 22:55:28.337826  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_33000.solverstate
I0428 22:55:28.529237  5145 solver.cpp:337] Iteration 33000, Testing net (#0)
I0428 22:55:28.529319  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 22:55:28.529322  5145 net.cpp:693] Ignoring source layer visualize
I0428 22:55:28.529325  5145 net.cpp:693] Ignoring source layer fake
I0428 23:00:27.101652  5145 solver.cpp:404]     Test net output #0: loss = 0.282692 (* 1 = 0.282692 loss)
I0428 23:00:27.419366  5145 solver.cpp:228] Iteration 33000, loss = 0.305583
I0428 23:00:27.419384  5145 solver.cpp:244]     Train net output #0: loss = 0.305583 (* 1 = 0.305583 loss)
I0428 23:00:27.419405  5145 sgd_solver.cpp:106] Iteration 33000, lr = 1e-06
I0428 23:01:19.559471  5145 solver.cpp:228] Iteration 33100, loss = 0.378319
I0428 23:01:19.559667  5145 solver.cpp:244]     Train net output #0: loss = 0.378319 (* 1 = 0.378319 loss)
I0428 23:01:19.559674  5145 sgd_solver.cpp:106] Iteration 33100, lr = 1e-06
I0428 23:02:09.688603  5145 solver.cpp:228] Iteration 33200, loss = 0.233515
I0428 23:02:09.688776  5145 solver.cpp:244]     Train net output #0: loss = 0.233515 (* 1 = 0.233515 loss)
I0428 23:02:09.688782  5145 sgd_solver.cpp:106] Iteration 33200, lr = 1e-06
I0428 23:02:59.866304  5145 solver.cpp:228] Iteration 33300, loss = 0.195147
I0428 23:02:59.866457  5145 solver.cpp:244]     Train net output #0: loss = 0.195147 (* 1 = 0.195147 loss)
I0428 23:02:59.866464  5145 sgd_solver.cpp:106] Iteration 33300, lr = 1e-06
I0428 23:03:50.047088  5145 solver.cpp:228] Iteration 33400, loss = 0.211556
I0428 23:03:50.047241  5145 solver.cpp:244]     Train net output #0: loss = 0.211556 (* 1 = 0.211556 loss)
I0428 23:03:50.047248  5145 sgd_solver.cpp:106] Iteration 33400, lr = 1e-06
I0428 23:04:42.227026  5145 solver.cpp:228] Iteration 33500, loss = 0.282439
I0428 23:04:42.227193  5145 solver.cpp:244]     Train net output #0: loss = 0.282439 (* 1 = 0.282439 loss)
I0428 23:04:42.227201  5145 sgd_solver.cpp:106] Iteration 33500, lr = 1e-06
I0428 23:05:32.405643  5145 solver.cpp:228] Iteration 33600, loss = 0.278073
I0428 23:05:32.405802  5145 solver.cpp:244]     Train net output #0: loss = 0.278073 (* 1 = 0.278073 loss)
I0428 23:05:32.405808  5145 sgd_solver.cpp:106] Iteration 33600, lr = 1e-06
I0428 23:06:22.569172  5145 solver.cpp:228] Iteration 33700, loss = 0.206991
I0428 23:06:22.569376  5145 solver.cpp:244]     Train net output #0: loss = 0.206991 (* 1 = 0.206991 loss)
I0428 23:06:22.569382  5145 sgd_solver.cpp:106] Iteration 33700, lr = 1e-06
I0428 23:07:14.589370  5145 solver.cpp:228] Iteration 33800, loss = 0.317208
I0428 23:07:14.589530  5145 solver.cpp:244]     Train net output #0: loss = 0.317208 (* 1 = 0.317208 loss)
I0428 23:07:14.589536  5145 sgd_solver.cpp:106] Iteration 33800, lr = 1e-06
I0428 23:08:04.767066  5145 solver.cpp:228] Iteration 33900, loss = 0.260973
I0428 23:08:04.769116  5145 solver.cpp:244]     Train net output #0: loss = 0.260973 (* 1 = 0.260973 loss)
I0428 23:08:04.769124  5145 sgd_solver.cpp:106] Iteration 33900, lr = 1e-06
I0428 23:08:54.629565  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_34000.caffemodel
I0428 23:09:23.269500  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_34000.solverstate
I0428 23:09:23.470588  5145 solver.cpp:337] Iteration 34000, Testing net (#0)
I0428 23:09:23.470685  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 23:09:23.470691  5145 net.cpp:693] Ignoring source layer visualize
I0428 23:09:23.470695  5145 net.cpp:693] Ignoring source layer fake
I0428 23:14:22.158377  5145 solver.cpp:404]     Test net output #0: loss = 0.289836 (* 1 = 0.289836 loss)
I0428 23:14:22.475520  5145 solver.cpp:228] Iteration 34000, loss = 0.279325
I0428 23:14:22.475543  5145 solver.cpp:244]     Train net output #0: loss = 0.279325 (* 1 = 0.279325 loss)
I0428 23:14:22.475564  5145 sgd_solver.cpp:106] Iteration 34000, lr = 1e-06
I0428 23:15:14.307071  5145 solver.cpp:228] Iteration 34100, loss = 0.288822
I0428 23:15:14.307224  5145 solver.cpp:244]     Train net output #0: loss = 0.288822 (* 1 = 0.288822 loss)
I0428 23:15:14.307232  5145 sgd_solver.cpp:106] Iteration 34100, lr = 1e-06
I0428 23:16:04.498878  5145 solver.cpp:228] Iteration 34200, loss = 0.186908
I0428 23:16:04.499032  5145 solver.cpp:244]     Train net output #0: loss = 0.186908 (* 1 = 0.186908 loss)
I0428 23:16:04.499040  5145 sgd_solver.cpp:106] Iteration 34200, lr = 1e-06
I0428 23:16:54.732899  5145 solver.cpp:228] Iteration 34300, loss = 0.143569
I0428 23:16:54.733057  5145 solver.cpp:244]     Train net output #0: loss = 0.143569 (* 1 = 0.143569 loss)
I0428 23:16:54.733063  5145 sgd_solver.cpp:106] Iteration 34300, lr = 1e-06
I0428 23:17:46.256722  5145 solver.cpp:228] Iteration 34400, loss = 0.196422
I0428 23:17:46.256872  5145 solver.cpp:244]     Train net output #0: loss = 0.196422 (* 1 = 0.196422 loss)
I0428 23:17:46.256880  5145 sgd_solver.cpp:106] Iteration 34400, lr = 1e-06
I0428 23:18:36.437417  5145 solver.cpp:228] Iteration 34500, loss = 0.22592
I0428 23:18:36.437602  5145 solver.cpp:244]     Train net output #0: loss = 0.22592 (* 1 = 0.22592 loss)
I0428 23:18:36.437608  5145 sgd_solver.cpp:106] Iteration 34500, lr = 1e-06
I0428 23:19:26.614238  5145 solver.cpp:228] Iteration 34600, loss = 0.246117
I0428 23:19:26.614400  5145 solver.cpp:244]     Train net output #0: loss = 0.246117 (* 1 = 0.246117 loss)
I0428 23:19:26.614408  5145 sgd_solver.cpp:106] Iteration 34600, lr = 1e-06
I0428 23:20:18.130573  5145 solver.cpp:228] Iteration 34700, loss = 0.291053
I0428 23:20:18.130722  5145 solver.cpp:244]     Train net output #0: loss = 0.291053 (* 1 = 0.291053 loss)
I0428 23:20:18.130728  5145 sgd_solver.cpp:106] Iteration 34700, lr = 1e-06
I0428 23:21:08.309223  5145 solver.cpp:228] Iteration 34800, loss = 0.34255
I0428 23:21:08.309383  5145 solver.cpp:244]     Train net output #0: loss = 0.34255 (* 1 = 0.34255 loss)
I0428 23:21:08.309389  5145 sgd_solver.cpp:106] Iteration 34800, lr = 1e-06
I0428 23:22:00.098989  5145 solver.cpp:228] Iteration 34900, loss = 0.259249
I0428 23:22:00.099169  5145 solver.cpp:244]     Train net output #0: loss = 0.259249 (* 1 = 0.259249 loss)
I0428 23:22:00.099179  5145 sgd_solver.cpp:106] Iteration 34900, lr = 1e-06
I0428 23:22:49.967111  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_35000.caffemodel
I0428 23:23:10.392144  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_35000.solverstate
I0428 23:23:10.584944  5145 solver.cpp:337] Iteration 35000, Testing net (#0)
I0428 23:23:10.585029  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 23:23:10.585033  5145 net.cpp:693] Ignoring source layer visualize
I0428 23:23:10.585036  5145 net.cpp:693] Ignoring source layer fake
I0428 23:28:08.683151  5145 solver.cpp:404]     Test net output #0: loss = 0.289763 (* 1 = 0.289763 loss)
I0428 23:28:08.999544  5145 solver.cpp:228] Iteration 35000, loss = 0.27322
I0428 23:28:08.999583  5145 solver.cpp:244]     Train net output #0: loss = 0.27322 (* 1 = 0.27322 loss)
I0428 23:28:08.999590  5145 sgd_solver.cpp:106] Iteration 35000, lr = 1e-06
I0428 23:28:59.176885  5145 solver.cpp:228] Iteration 35100, loss = 0.307521
I0428 23:28:59.177050  5145 solver.cpp:244]     Train net output #0: loss = 0.307521 (* 1 = 0.307521 loss)
I0428 23:28:59.177057  5145 sgd_solver.cpp:106] Iteration 35100, lr = 1e-06
I0428 23:29:51.265777  5145 solver.cpp:228] Iteration 35200, loss = 0.321372
I0428 23:29:51.265949  5145 solver.cpp:244]     Train net output #0: loss = 0.321372 (* 1 = 0.321372 loss)
I0428 23:29:51.265956  5145 sgd_solver.cpp:106] Iteration 35200, lr = 1e-06
I0428 23:30:41.442610  5145 solver.cpp:228] Iteration 35300, loss = 0.272774
I0428 23:30:41.442775  5145 solver.cpp:244]     Train net output #0: loss = 0.272774 (* 1 = 0.272774 loss)
I0428 23:30:41.442782  5145 sgd_solver.cpp:106] Iteration 35300, lr = 1e-06
I0428 23:31:31.624524  5145 solver.cpp:228] Iteration 35400, loss = 0.25003
I0428 23:31:31.624686  5145 solver.cpp:244]     Train net output #0: loss = 0.25003 (* 1 = 0.25003 loss)
I0428 23:31:31.624692  5145 sgd_solver.cpp:106] Iteration 35400, lr = 1e-06
I0428 23:32:23.746558  5145 solver.cpp:228] Iteration 35500, loss = 0.331636
I0428 23:32:23.746727  5145 solver.cpp:244]     Train net output #0: loss = 0.331636 (* 1 = 0.331636 loss)
I0428 23:32:23.746734  5145 sgd_solver.cpp:106] Iteration 35500, lr = 1e-06
I0428 23:33:13.932822  5145 solver.cpp:228] Iteration 35600, loss = 0.257196
I0428 23:33:13.932976  5145 solver.cpp:244]     Train net output #0: loss = 0.257196 (* 1 = 0.257196 loss)
I0428 23:33:13.932982  5145 sgd_solver.cpp:106] Iteration 35600, lr = 1e-06
I0428 23:34:04.101538  5145 solver.cpp:228] Iteration 35700, loss = 0.215035
I0428 23:34:04.101693  5145 solver.cpp:244]     Train net output #0: loss = 0.215035 (* 1 = 0.215035 loss)
I0428 23:34:04.101701  5145 sgd_solver.cpp:106] Iteration 35700, lr = 1e-06
I0428 23:34:54.284083  5145 solver.cpp:228] Iteration 35800, loss = 0.264292
I0428 23:34:54.284274  5145 solver.cpp:244]     Train net output #0: loss = 0.264292 (* 1 = 0.264292 loss)
I0428 23:34:54.284281  5145 sgd_solver.cpp:106] Iteration 35800, lr = 1e-06
I0428 23:35:46.706064  5145 solver.cpp:228] Iteration 35900, loss = 0.284556
I0428 23:35:46.706254  5145 solver.cpp:244]     Train net output #0: loss = 0.284556 (* 1 = 0.284556 loss)
I0428 23:35:46.706261  5145 sgd_solver.cpp:106] Iteration 35900, lr = 1e-06
I0428 23:36:36.569211  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_36000.caffemodel
I0428 23:36:52.226302  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_36000.solverstate
I0428 23:36:52.419276  5145 solver.cpp:337] Iteration 36000, Testing net (#0)
I0428 23:36:52.419375  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 23:36:52.419380  5145 net.cpp:693] Ignoring source layer visualize
I0428 23:36:52.419384  5145 net.cpp:693] Ignoring source layer fake
I0428 23:41:51.306605  5145 solver.cpp:404]     Test net output #0: loss = 0.287275 (* 1 = 0.287275 loss)
I0428 23:41:51.621004  5145 solver.cpp:228] Iteration 36000, loss = 0.374469
I0428 23:41:51.621042  5145 solver.cpp:244]     Train net output #0: loss = 0.374469 (* 1 = 0.374469 loss)
I0428 23:41:51.621049  5145 sgd_solver.cpp:106] Iteration 36000, lr = 1e-06
I0428 23:42:41.762236  5145 solver.cpp:228] Iteration 36100, loss = 0.256551
I0428 23:42:41.762413  5145 solver.cpp:244]     Train net output #0: loss = 0.256551 (* 1 = 0.256551 loss)
I0428 23:42:41.762421  5145 sgd_solver.cpp:106] Iteration 36100, lr = 1e-06
I0428 23:43:33.859000  5145 solver.cpp:228] Iteration 36200, loss = 0.256151
I0428 23:43:33.859164  5145 solver.cpp:244]     Train net output #0: loss = 0.256151 (* 1 = 0.256151 loss)
I0428 23:43:33.859172  5145 sgd_solver.cpp:106] Iteration 36200, lr = 1e-06
I0428 23:44:23.962362  5145 solver.cpp:228] Iteration 36300, loss = 0.261438
I0428 23:44:23.962523  5145 solver.cpp:244]     Train net output #0: loss = 0.261438 (* 1 = 0.261438 loss)
I0428 23:44:23.962530  5145 sgd_solver.cpp:106] Iteration 36300, lr = 1e-06
I0428 23:45:14.143276  5145 solver.cpp:228] Iteration 36400, loss = 0.208228
I0428 23:45:14.143409  5145 solver.cpp:244]     Train net output #0: loss = 0.208228 (* 1 = 0.208228 loss)
I0428 23:45:14.143431  5145 sgd_solver.cpp:106] Iteration 36400, lr = 1e-06
I0428 23:46:04.317235  5145 solver.cpp:228] Iteration 36500, loss = 0.183616
I0428 23:46:04.317375  5145 solver.cpp:244]     Train net output #0: loss = 0.183616 (* 1 = 0.183616 loss)
I0428 23:46:04.317383  5145 sgd_solver.cpp:106] Iteration 36500, lr = 1e-06
I0428 23:46:56.325047  5145 solver.cpp:228] Iteration 36600, loss = 0.30562
I0428 23:46:56.325203  5145 solver.cpp:244]     Train net output #0: loss = 0.30562 (* 1 = 0.30562 loss)
I0428 23:46:56.325209  5145 sgd_solver.cpp:106] Iteration 36600, lr = 1e-06
I0428 23:47:46.503854  5145 solver.cpp:228] Iteration 36700, loss = 0.395942
I0428 23:47:46.503995  5145 solver.cpp:244]     Train net output #0: loss = 0.395942 (* 1 = 0.395942 loss)
I0428 23:47:46.504003  5145 sgd_solver.cpp:106] Iteration 36700, lr = 1e-06
I0428 23:48:36.684011  5145 solver.cpp:228] Iteration 36800, loss = 0.243282
I0428 23:48:36.684206  5145 solver.cpp:244]     Train net output #0: loss = 0.243282 (* 1 = 0.243282 loss)
I0428 23:48:36.684216  5145 sgd_solver.cpp:106] Iteration 36800, lr = 1e-06
I0428 23:49:28.745311  5145 solver.cpp:228] Iteration 36900, loss = 0.245199
I0428 23:49:28.745486  5145 solver.cpp:244]     Train net output #0: loss = 0.245199 (* 1 = 0.245199 loss)
I0428 23:49:28.745493  5145 sgd_solver.cpp:106] Iteration 36900, lr = 1e-06
I0428 23:50:18.572317  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_37000.caffemodel
I0428 23:50:40.057672  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_37000.solverstate
I0428 23:50:40.256728  5145 solver.cpp:337] Iteration 37000, Testing net (#0)
I0428 23:50:40.256817  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0428 23:50:40.256821  5145 net.cpp:693] Ignoring source layer visualize
I0428 23:50:40.256839  5145 net.cpp:693] Ignoring source layer fake
I0428 23:55:37.492334  5145 solver.cpp:404]     Test net output #0: loss = 0.283504 (* 1 = 0.283504 loss)
I0428 23:55:37.805788  5145 solver.cpp:228] Iteration 37000, loss = 0.272647
I0428 23:55:37.805829  5145 solver.cpp:244]     Train net output #0: loss = 0.272647 (* 1 = 0.272647 loss)
I0428 23:55:37.805835  5145 sgd_solver.cpp:106] Iteration 37000, lr = 1e-06
I0428 23:56:28.385224  5145 solver.cpp:228] Iteration 37100, loss = 0.297996
I0428 23:56:28.385392  5145 solver.cpp:244]     Train net output #0: loss = 0.297996 (* 1 = 0.297996 loss)
I0428 23:56:28.385401  5145 sgd_solver.cpp:106] Iteration 37100, lr = 1e-06
I0428 23:57:20.752954  5145 solver.cpp:228] Iteration 37200, loss = 0.440903
I0428 23:57:20.753140  5145 solver.cpp:244]     Train net output #0: loss = 0.440903 (* 1 = 0.440903 loss)
I0428 23:57:20.753147  5145 sgd_solver.cpp:106] Iteration 37200, lr = 1e-06
I0428 23:58:11.274062  5145 solver.cpp:228] Iteration 37300, loss = 0.175756
I0428 23:58:11.274265  5145 solver.cpp:244]     Train net output #0: loss = 0.175756 (* 1 = 0.175756 loss)
I0428 23:58:11.274276  5145 sgd_solver.cpp:106] Iteration 37300, lr = 1e-06
I0428 23:59:01.882282  5145 solver.cpp:228] Iteration 37400, loss = 0.270313
I0428 23:59:01.882450  5145 solver.cpp:244]     Train net output #0: loss = 0.270313 (* 1 = 0.270313 loss)
I0428 23:59:01.882457  5145 sgd_solver.cpp:106] Iteration 37400, lr = 1e-06
I0428 23:59:53.626330  5145 solver.cpp:228] Iteration 37500, loss = 0.227076
I0428 23:59:53.626490  5145 solver.cpp:244]     Train net output #0: loss = 0.227076 (* 1 = 0.227076 loss)
I0428 23:59:53.626497  5145 sgd_solver.cpp:106] Iteration 37500, lr = 1e-07
I0429 00:00:44.107003  5145 solver.cpp:228] Iteration 37600, loss = 0.277311
I0429 00:00:44.107167  5145 solver.cpp:244]     Train net output #0: loss = 0.277311 (* 1 = 0.277311 loss)
I0429 00:00:44.107172  5145 sgd_solver.cpp:106] Iteration 37600, lr = 1e-07
I0429 00:01:34.704674  5145 solver.cpp:228] Iteration 37700, loss = 0.199087
I0429 00:01:34.705574  5145 solver.cpp:244]     Train net output #0: loss = 0.199087 (* 1 = 0.199087 loss)
I0429 00:01:34.705580  5145 sgd_solver.cpp:106] Iteration 37700, lr = 1e-07
I0429 00:02:26.591032  5145 solver.cpp:228] Iteration 37800, loss = 0.272374
I0429 00:02:26.591193  5145 solver.cpp:244]     Train net output #0: loss = 0.272374 (* 1 = 0.272374 loss)
I0429 00:02:26.591200  5145 sgd_solver.cpp:106] Iteration 37800, lr = 1e-07
I0429 00:03:17.259577  5145 solver.cpp:228] Iteration 37900, loss = 0.20625
I0429 00:03:17.260383  5145 solver.cpp:244]     Train net output #0: loss = 0.20625 (* 1 = 0.20625 loss)
I0429 00:03:17.260391  5145 sgd_solver.cpp:106] Iteration 37900, lr = 1e-07
I0429 00:04:07.400797  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_38000.caffemodel
I0429 00:04:30.413919  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_38000.solverstate
I0429 00:04:30.615600  5145 solver.cpp:337] Iteration 38000, Testing net (#0)
I0429 00:04:30.615685  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 00:04:30.615705  5145 net.cpp:693] Ignoring source layer visualize
I0429 00:04:30.615707  5145 net.cpp:693] Ignoring source layer fake
I0429 00:09:27.039394  5145 solver.cpp:404]     Test net output #0: loss = 0.280899 (* 1 = 0.280899 loss)
I0429 00:09:27.357810  5145 solver.cpp:228] Iteration 38000, loss = 0.353563
I0429 00:09:27.357832  5145 solver.cpp:244]     Train net output #0: loss = 0.353563 (* 1 = 0.353563 loss)
I0429 00:09:27.357853  5145 sgd_solver.cpp:106] Iteration 38000, lr = 1e-07
I0429 00:10:19.409983  5145 solver.cpp:228] Iteration 38100, loss = 0.261415
I0429 00:10:19.410161  5145 solver.cpp:244]     Train net output #0: loss = 0.261415 (* 1 = 0.261415 loss)
I0429 00:10:19.410169  5145 sgd_solver.cpp:106] Iteration 38100, lr = 1e-07
I0429 00:11:10.055776  5145 solver.cpp:228] Iteration 38200, loss = 0.143372
I0429 00:11:10.055945  5145 solver.cpp:244]     Train net output #0: loss = 0.143372 (* 1 = 0.143372 loss)
I0429 00:11:10.055953  5145 sgd_solver.cpp:106] Iteration 38200, lr = 1e-07
I0429 00:12:02.362967  5145 solver.cpp:228] Iteration 38300, loss = 0.270024
I0429 00:12:02.363219  5145 solver.cpp:244]     Train net output #0: loss = 0.270024 (* 1 = 0.270024 loss)
I0429 00:12:02.363234  5145 sgd_solver.cpp:106] Iteration 38300, lr = 1e-07
I0429 00:12:52.876413  5145 solver.cpp:228] Iteration 38400, loss = 0.316565
I0429 00:12:52.876575  5145 solver.cpp:244]     Train net output #0: loss = 0.316565 (* 1 = 0.316565 loss)
I0429 00:12:52.876581  5145 sgd_solver.cpp:106] Iteration 38400, lr = 1e-07
I0429 00:13:43.451009  5145 solver.cpp:228] Iteration 38500, loss = 0.253363
I0429 00:13:43.451213  5145 solver.cpp:244]     Train net output #0: loss = 0.253363 (* 1 = 0.253363 loss)
I0429 00:13:43.451220  5145 sgd_solver.cpp:106] Iteration 38500, lr = 1e-07
I0429 00:14:34.047991  5145 solver.cpp:228] Iteration 38600, loss = 0.165284
I0429 00:14:34.048161  5145 solver.cpp:244]     Train net output #0: loss = 0.165284 (* 1 = 0.165284 loss)
I0429 00:14:34.048167  5145 sgd_solver.cpp:106] Iteration 38600, lr = 1e-07
I0429 00:15:26.397104  5145 solver.cpp:228] Iteration 38700, loss = 0.227114
I0429 00:15:26.397267  5145 solver.cpp:244]     Train net output #0: loss = 0.227114 (* 1 = 0.227114 loss)
I0429 00:15:26.397274  5145 sgd_solver.cpp:106] Iteration 38700, lr = 1e-07
I0429 00:16:17.043357  5145 solver.cpp:228] Iteration 38800, loss = 0.359054
I0429 00:16:17.043921  5145 solver.cpp:244]     Train net output #0: loss = 0.359054 (* 1 = 0.359054 loss)
I0429 00:16:17.043927  5145 sgd_solver.cpp:106] Iteration 38800, lr = 1e-07
I0429 00:17:07.408349  5145 solver.cpp:228] Iteration 38900, loss = 0.283323
I0429 00:17:07.408504  5145 solver.cpp:244]     Train net output #0: loss = 0.283323 (* 1 = 0.283323 loss)
I0429 00:17:07.408509  5145 sgd_solver.cpp:106] Iteration 38900, lr = 1e-07
I0429 00:17:59.303295  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_39000.caffemodel
I0429 00:18:21.201470  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_39000.solverstate
I0429 00:18:21.400768  5145 solver.cpp:337] Iteration 39000, Testing net (#0)
I0429 00:18:21.400867  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 00:18:21.400872  5145 net.cpp:693] Ignoring source layer visualize
I0429 00:18:21.400876  5145 net.cpp:693] Ignoring source layer fake
I0429 00:23:17.142345  5145 solver.cpp:404]     Test net output #0: loss = 0.290031 (* 1 = 0.290031 loss)
I0429 00:23:17.454251  5145 solver.cpp:228] Iteration 39000, loss = 0.301507
I0429 00:23:17.454288  5145 solver.cpp:244]     Train net output #0: loss = 0.301507 (* 1 = 0.301507 loss)
I0429 00:23:17.454293  5145 sgd_solver.cpp:106] Iteration 39000, lr = 1e-07
I0429 00:24:08.066404  5145 solver.cpp:228] Iteration 39100, loss = 0.215434
I0429 00:24:08.066547  5145 solver.cpp:244]     Train net output #0: loss = 0.215434 (* 1 = 0.215434 loss)
I0429 00:24:08.066555  5145 sgd_solver.cpp:106] Iteration 39100, lr = 1e-07
I0429 00:24:58.632607  5145 solver.cpp:228] Iteration 39200, loss = 0.265324
I0429 00:24:58.632760  5145 solver.cpp:244]     Train net output #0: loss = 0.265324 (* 1 = 0.265324 loss)
I0429 00:24:58.632766  5145 sgd_solver.cpp:106] Iteration 39200, lr = 1e-07
I0429 00:25:49.330487  5145 solver.cpp:228] Iteration 39300, loss = 0.267136
I0429 00:25:49.330641  5145 solver.cpp:244]     Train net output #0: loss = 0.267136 (* 1 = 0.267136 loss)
I0429 00:25:49.330647  5145 sgd_solver.cpp:106] Iteration 39300, lr = 1e-07
I0429 00:26:41.813633  5145 solver.cpp:228] Iteration 39400, loss = 0.252081
I0429 00:26:41.813807  5145 solver.cpp:244]     Train net output #0: loss = 0.252081 (* 1 = 0.252081 loss)
I0429 00:26:41.813815  5145 sgd_solver.cpp:106] Iteration 39400, lr = 1e-07
I0429 00:27:32.482774  5145 solver.cpp:228] Iteration 39500, loss = 0.255754
I0429 00:27:32.482934  5145 solver.cpp:244]     Train net output #0: loss = 0.255754 (* 1 = 0.255754 loss)
I0429 00:27:32.482941  5145 sgd_solver.cpp:106] Iteration 39500, lr = 1e-07
I0429 00:28:22.935003  5145 solver.cpp:228] Iteration 39600, loss = 0.285654
I0429 00:28:22.935165  5145 solver.cpp:244]     Train net output #0: loss = 0.285654 (* 1 = 0.285654 loss)
I0429 00:28:22.935173  5145 sgd_solver.cpp:106] Iteration 39600, lr = 1e-07
I0429 00:29:15.233122  5145 solver.cpp:228] Iteration 39700, loss = 0.265849
I0429 00:29:15.234400  5145 solver.cpp:244]     Train net output #0: loss = 0.265849 (* 1 = 0.265849 loss)
I0429 00:29:15.234417  5145 sgd_solver.cpp:106] Iteration 39700, lr = 1e-07
I0429 00:30:05.870234  5145 solver.cpp:228] Iteration 39800, loss = 0.22926
I0429 00:30:05.870429  5145 solver.cpp:244]     Train net output #0: loss = 0.22926 (* 1 = 0.22926 loss)
I0429 00:30:05.870437  5145 sgd_solver.cpp:106] Iteration 39800, lr = 1e-07
I0429 00:30:56.323611  5145 solver.cpp:228] Iteration 39900, loss = 0.23418
I0429 00:30:56.323773  5145 solver.cpp:244]     Train net output #0: loss = 0.23418 (* 1 = 0.23418 loss)
I0429 00:30:56.323781  5145 sgd_solver.cpp:106] Iteration 39900, lr = 1e-07
I0429 00:31:48.243774  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_40000.caffemodel
I0429 00:32:03.832171  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_40000.solverstate
I0429 00:32:04.037277  5145 solver.cpp:337] Iteration 40000, Testing net (#0)
I0429 00:32:04.037364  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 00:32:04.037367  5145 net.cpp:693] Ignoring source layer visualize
I0429 00:32:04.037385  5145 net.cpp:693] Ignoring source layer fake
I0429 00:37:00.332350  5145 solver.cpp:404]     Test net output #0: loss = 0.288203 (* 1 = 0.288203 loss)
I0429 00:37:00.645102  5145 solver.cpp:228] Iteration 40000, loss = 0.235222
I0429 00:37:00.645123  5145 solver.cpp:244]     Train net output #0: loss = 0.235222 (* 1 = 0.235222 loss)
I0429 00:37:00.645145  5145 sgd_solver.cpp:106] Iteration 40000, lr = 1e-07
I0429 00:37:51.156595  5145 solver.cpp:228] Iteration 40100, loss = 0.24863
I0429 00:37:51.156749  5145 solver.cpp:244]     Train net output #0: loss = 0.24863 (* 1 = 0.24863 loss)
I0429 00:37:51.156754  5145 sgd_solver.cpp:106] Iteration 40100, lr = 1e-07
I0429 00:38:41.724722  5145 solver.cpp:228] Iteration 40200, loss = 0.205432
I0429 00:38:41.725464  5145 solver.cpp:244]     Train net output #0: loss = 0.205432 (* 1 = 0.205432 loss)
I0429 00:38:41.725473  5145 sgd_solver.cpp:106] Iteration 40200, lr = 1e-07
I0429 00:39:32.267329  5145 solver.cpp:228] Iteration 40300, loss = 0.171084
I0429 00:39:32.267484  5145 solver.cpp:244]     Train net output #0: loss = 0.171084 (* 1 = 0.171084 loss)
I0429 00:39:32.267490  5145 sgd_solver.cpp:106] Iteration 40300, lr = 1e-07
I0429 00:40:24.458714  5145 solver.cpp:228] Iteration 40400, loss = 0.12395
I0429 00:40:24.458869  5145 solver.cpp:244]     Train net output #0: loss = 0.12395 (* 1 = 0.12395 loss)
I0429 00:40:24.458878  5145 sgd_solver.cpp:106] Iteration 40400, lr = 1e-07
I0429 00:41:14.988157  5145 solver.cpp:228] Iteration 40500, loss = 0.577275
I0429 00:41:14.988315  5145 solver.cpp:244]     Train net output #0: loss = 0.577275 (* 1 = 0.577275 loss)
I0429 00:41:14.988322  5145 sgd_solver.cpp:106] Iteration 40500, lr = 1e-07
I0429 00:42:05.626974  5145 solver.cpp:228] Iteration 40600, loss = 0.232835
I0429 00:42:05.627126  5145 solver.cpp:244]     Train net output #0: loss = 0.232835 (* 1 = 0.232835 loss)
I0429 00:42:05.627133  5145 sgd_solver.cpp:106] Iteration 40600, lr = 1e-07
I0429 00:42:57.325965  5145 solver.cpp:228] Iteration 40700, loss = 0.253514
I0429 00:42:57.326123  5145 solver.cpp:244]     Train net output #0: loss = 0.253514 (* 1 = 0.253514 loss)
I0429 00:42:57.326133  5145 sgd_solver.cpp:106] Iteration 40700, lr = 1e-07
I0429 00:43:47.680249  5145 solver.cpp:228] Iteration 40800, loss = 0.290951
I0429 00:43:47.680429  5145 solver.cpp:244]     Train net output #0: loss = 0.290951 (* 1 = 0.290951 loss)
I0429 00:43:47.680449  5145 sgd_solver.cpp:106] Iteration 40800, lr = 1e-07
I0429 00:44:39.145153  5145 solver.cpp:228] Iteration 40900, loss = 0.408261
I0429 00:44:39.145323  5145 solver.cpp:244]     Train net output #0: loss = 0.408261 (* 1 = 0.408261 loss)
I0429 00:44:39.145329  5145 sgd_solver.cpp:106] Iteration 40900, lr = 1e-07
I0429 00:45:29.173215  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_41000.caffemodel
I0429 00:45:36.065376  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_41000.solverstate
I0429 00:45:36.255928  5145 solver.cpp:337] Iteration 41000, Testing net (#0)
I0429 00:45:36.256028  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 00:45:36.256034  5145 net.cpp:693] Ignoring source layer visualize
I0429 00:45:36.256036  5145 net.cpp:693] Ignoring source layer fake
I0429 00:50:32.210315  5145 solver.cpp:404]     Test net output #0: loss = 0.285951 (* 1 = 0.285951 loss)
I0429 00:50:32.524634  5145 solver.cpp:228] Iteration 41000, loss = 0.435895
I0429 00:50:32.524672  5145 solver.cpp:244]     Train net output #0: loss = 0.435895 (* 1 = 0.435895 loss)
I0429 00:50:32.524678  5145 sgd_solver.cpp:106] Iteration 41000, lr = 1e-07
I0429 00:51:23.068645  5145 solver.cpp:228] Iteration 41100, loss = 0.312054
I0429 00:51:23.070466  5145 solver.cpp:244]     Train net output #0: loss = 0.312054 (* 1 = 0.312054 loss)
I0429 00:51:23.070474  5145 sgd_solver.cpp:106] Iteration 41100, lr = 1e-07
I0429 00:52:15.016010  5145 solver.cpp:228] Iteration 41200, loss = 0.190625
I0429 00:52:15.016182  5145 solver.cpp:244]     Train net output #0: loss = 0.190625 (* 1 = 0.190625 loss)
I0429 00:52:15.016189  5145 sgd_solver.cpp:106] Iteration 41200, lr = 1e-07
I0429 00:53:05.511010  5145 solver.cpp:228] Iteration 41300, loss = 0.344027
I0429 00:53:05.511237  5145 solver.cpp:244]     Train net output #0: loss = 0.344027 (* 1 = 0.344027 loss)
I0429 00:53:05.511255  5145 sgd_solver.cpp:106] Iteration 41300, lr = 1e-07
I0429 00:53:56.051167  5145 solver.cpp:228] Iteration 41400, loss = 0.340269
I0429 00:53:56.051329  5145 solver.cpp:244]     Train net output #0: loss = 0.340269 (* 1 = 0.340269 loss)
I0429 00:53:56.051337  5145 sgd_solver.cpp:106] Iteration 41400, lr = 1e-07
I0429 00:54:48.538436  5145 solver.cpp:228] Iteration 41500, loss = 0.260692
I0429 00:54:48.538601  5145 solver.cpp:244]     Train net output #0: loss = 0.260692 (* 1 = 0.260692 loss)
I0429 00:54:48.538609  5145 sgd_solver.cpp:106] Iteration 41500, lr = 1e-07
I0429 00:55:39.043968  5145 solver.cpp:228] Iteration 41600, loss = 0.354691
I0429 00:55:39.044118  5145 solver.cpp:244]     Train net output #0: loss = 0.354691 (* 1 = 0.354691 loss)
I0429 00:55:39.044127  5145 sgd_solver.cpp:106] Iteration 41600, lr = 1e-07
I0429 00:56:29.753630  5145 solver.cpp:228] Iteration 41700, loss = 0.259414
I0429 00:56:29.753721  5145 solver.cpp:244]     Train net output #0: loss = 0.259414 (* 1 = 0.259414 loss)
I0429 00:56:29.753728  5145 sgd_solver.cpp:106] Iteration 41700, lr = 1e-07
I0429 00:57:22.020330  5145 solver.cpp:228] Iteration 41800, loss = 0.250313
I0429 00:57:22.020530  5145 solver.cpp:244]     Train net output #0: loss = 0.250313 (* 1 = 0.250313 loss)
I0429 00:57:22.020537  5145 sgd_solver.cpp:106] Iteration 41800, lr = 1e-07
I0429 00:58:12.407081  5145 solver.cpp:228] Iteration 41900, loss = 0.210871
I0429 00:58:12.407229  5145 solver.cpp:244]     Train net output #0: loss = 0.210871 (* 1 = 0.210871 loss)
I0429 00:58:12.407238  5145 sgd_solver.cpp:106] Iteration 41900, lr = 1e-07
I0429 00:59:02.551372  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_42000.caffemodel
I0429 00:59:17.898407  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_42000.solverstate
I0429 00:59:18.095576  5145 solver.cpp:337] Iteration 42000, Testing net (#0)
I0429 00:59:18.095664  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 00:59:18.095666  5145 net.cpp:693] Ignoring source layer visualize
I0429 00:59:18.095669  5145 net.cpp:693] Ignoring source layer fake
I0429 01:04:13.992975  5145 solver.cpp:404]     Test net output #0: loss = 0.282095 (* 1 = 0.282095 loss)
I0429 01:04:14.314973  5145 solver.cpp:228] Iteration 42000, loss = 0.260051
I0429 01:04:14.314992  5145 solver.cpp:244]     Train net output #0: loss = 0.260051 (* 1 = 0.260051 loss)
I0429 01:04:14.315014  5145 sgd_solver.cpp:106] Iteration 42000, lr = 1e-07
I0429 01:05:06.784530  5145 solver.cpp:228] Iteration 42100, loss = 0.272034
I0429 01:05:06.784739  5145 solver.cpp:244]     Train net output #0: loss = 0.272034 (* 1 = 0.272034 loss)
I0429 01:05:06.784749  5145 sgd_solver.cpp:106] Iteration 42100, lr = 1e-07
I0429 01:05:57.355818  5145 solver.cpp:228] Iteration 42200, loss = 0.332295
I0429 01:05:57.355978  5145 solver.cpp:244]     Train net output #0: loss = 0.332295 (* 1 = 0.332295 loss)
I0429 01:05:57.355985  5145 sgd_solver.cpp:106] Iteration 42200, lr = 1e-07
I0429 01:06:47.925803  5145 solver.cpp:228] Iteration 42300, loss = 0.232073
I0429 01:06:47.925978  5145 solver.cpp:244]     Train net output #0: loss = 0.232073 (* 1 = 0.232073 loss)
I0429 01:06:47.925986  5145 sgd_solver.cpp:106] Iteration 42300, lr = 1e-07
I0429 01:07:38.523102  5145 solver.cpp:228] Iteration 42400, loss = 0.298691
I0429 01:07:38.523219  5145 solver.cpp:244]     Train net output #0: loss = 0.298691 (* 1 = 0.298691 loss)
I0429 01:07:38.523226  5145 sgd_solver.cpp:106] Iteration 42400, lr = 1e-07
I0429 01:08:30.846607  5145 solver.cpp:228] Iteration 42500, loss = 0.195015
I0429 01:08:30.846761  5145 solver.cpp:244]     Train net output #0: loss = 0.195015 (* 1 = 0.195015 loss)
I0429 01:08:30.846768  5145 sgd_solver.cpp:106] Iteration 42500, lr = 1e-07
I0429 01:09:21.416776  5145 solver.cpp:228] Iteration 42600, loss = 0.314404
I0429 01:09:21.416924  5145 solver.cpp:244]     Train net output #0: loss = 0.314404 (* 1 = 0.314404 loss)
I0429 01:09:21.416931  5145 sgd_solver.cpp:106] Iteration 42600, lr = 1e-07
I0429 01:10:12.175504  5145 solver.cpp:228] Iteration 42700, loss = 0.242382
I0429 01:10:12.175719  5145 solver.cpp:244]     Train net output #0: loss = 0.242382 (* 1 = 0.242382 loss)
I0429 01:10:12.175729  5145 sgd_solver.cpp:106] Iteration 42700, lr = 1e-07
I0429 01:11:04.307556  5145 solver.cpp:228] Iteration 42800, loss = 0.251023
I0429 01:11:04.307721  5145 solver.cpp:244]     Train net output #0: loss = 0.251023 (* 1 = 0.251023 loss)
I0429 01:11:04.307729  5145 sgd_solver.cpp:106] Iteration 42800, lr = 1e-07
I0429 01:11:54.710073  5145 solver.cpp:228] Iteration 42900, loss = 0.228961
I0429 01:11:54.710249  5145 solver.cpp:244]     Train net output #0: loss = 0.228961 (* 1 = 0.228961 loss)
I0429 01:11:54.710258  5145 sgd_solver.cpp:106] Iteration 42900, lr = 1e-07
I0429 01:12:44.867328  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_43000.caffemodel
I0429 01:12:54.974277  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_43000.solverstate
I0429 01:12:55.165347  5145 solver.cpp:337] Iteration 43000, Testing net (#0)
I0429 01:12:55.165431  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 01:12:55.165454  5145 net.cpp:693] Ignoring source layer visualize
I0429 01:12:55.165457  5145 net.cpp:693] Ignoring source layer fake
I0429 01:17:52.370523  5145 solver.cpp:404]     Test net output #0: loss = 0.281342 (* 1 = 0.281342 loss)
I0429 01:17:52.681565  5145 solver.cpp:228] Iteration 43000, loss = 0.260161
I0429 01:17:52.681586  5145 solver.cpp:244]     Train net output #0: loss = 0.260161 (* 1 = 0.260161 loss)
I0429 01:17:52.681607  5145 sgd_solver.cpp:106] Iteration 43000, lr = 1e-07
I0429 01:18:43.233233  5145 solver.cpp:228] Iteration 43100, loss = 0.183685
I0429 01:18:43.233397  5145 solver.cpp:244]     Train net output #0: loss = 0.183685 (* 1 = 0.183685 loss)
I0429 01:18:43.233407  5145 sgd_solver.cpp:106] Iteration 43100, lr = 1e-07
I0429 01:19:35.535075  5145 solver.cpp:228] Iteration 43200, loss = 0.253096
I0429 01:19:35.535248  5145 solver.cpp:244]     Train net output #0: loss = 0.253096 (* 1 = 0.253096 loss)
I0429 01:19:35.535256  5145 sgd_solver.cpp:106] Iteration 43200, lr = 1e-07
I0429 01:20:26.045354  5145 solver.cpp:228] Iteration 43300, loss = 0.0429903
I0429 01:20:26.045527  5145 solver.cpp:244]     Train net output #0: loss = 0.0429903 (* 1 = 0.0429903 loss)
I0429 01:20:26.045536  5145 sgd_solver.cpp:106] Iteration 43300, lr = 1e-07
I0429 01:21:16.603113  5145 solver.cpp:228] Iteration 43400, loss = 0.243623
I0429 01:21:16.603281  5145 solver.cpp:244]     Train net output #0: loss = 0.243623 (* 1 = 0.243623 loss)
I0429 01:21:16.603288  5145 sgd_solver.cpp:106] Iteration 43400, lr = 1e-07
I0429 01:22:08.702644  5145 solver.cpp:228] Iteration 43500, loss = 0.204376
I0429 01:22:08.702802  5145 solver.cpp:244]     Train net output #0: loss = 0.204376 (* 1 = 0.204376 loss)
I0429 01:22:08.702810  5145 sgd_solver.cpp:106] Iteration 43500, lr = 1e-07
I0429 01:22:59.228941  5145 solver.cpp:228] Iteration 43600, loss = 0.251679
I0429 01:22:59.229131  5145 solver.cpp:244]     Train net output #0: loss = 0.251679 (* 1 = 0.251679 loss)
I0429 01:22:59.229141  5145 sgd_solver.cpp:106] Iteration 43600, lr = 1e-07
I0429 01:23:49.827826  5145 solver.cpp:228] Iteration 43700, loss = 0.593489
I0429 01:23:49.830247  5145 solver.cpp:244]     Train net output #0: loss = 0.593489 (* 1 = 0.593489 loss)
I0429 01:23:49.830255  5145 sgd_solver.cpp:106] Iteration 43700, lr = 1e-07
I0429 01:24:41.479398  5145 solver.cpp:228] Iteration 43800, loss = 0.291844
I0429 01:24:41.479571  5145 solver.cpp:244]     Train net output #0: loss = 0.291844 (* 1 = 0.291844 loss)
I0429 01:24:41.479579  5145 sgd_solver.cpp:106] Iteration 43800, lr = 1e-07
I0429 01:25:31.965137  5145 solver.cpp:228] Iteration 43900, loss = 0.182459
I0429 01:25:31.965298  5145 solver.cpp:244]     Train net output #0: loss = 0.182459 (* 1 = 0.182459 loss)
I0429 01:25:31.965306  5145 sgd_solver.cpp:106] Iteration 43900, lr = 1e-07
I0429 01:26:23.476824  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_44000.caffemodel
I0429 01:26:35.679661  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_44000.solverstate
I0429 01:26:35.877869  5145 solver.cpp:337] Iteration 44000, Testing net (#0)
I0429 01:26:35.877954  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 01:26:35.877957  5145 net.cpp:693] Ignoring source layer visualize
I0429 01:26:35.877959  5145 net.cpp:693] Ignoring source layer fake
I0429 01:31:32.546069  5145 solver.cpp:404]     Test net output #0: loss = 0.290827 (* 1 = 0.290827 loss)
I0429 01:31:32.862572  5145 solver.cpp:228] Iteration 44000, loss = 0.232478
I0429 01:31:32.862601  5145 solver.cpp:244]     Train net output #0: loss = 0.232478 (* 1 = 0.232478 loss)
I0429 01:31:32.862613  5145 sgd_solver.cpp:106] Iteration 44000, lr = 1e-07
I0429 01:32:23.406486  5145 solver.cpp:228] Iteration 44100, loss = 0.190222
I0429 01:32:23.406651  5145 solver.cpp:244]     Train net output #0: loss = 0.190222 (* 1 = 0.190222 loss)
I0429 01:32:23.406658  5145 sgd_solver.cpp:106] Iteration 44100, lr = 1e-07
I0429 01:33:13.930307  5145 solver.cpp:228] Iteration 44200, loss = 0.152498
I0429 01:33:13.930461  5145 solver.cpp:244]     Train net output #0: loss = 0.152498 (* 1 = 0.152498 loss)
I0429 01:33:13.930469  5145 sgd_solver.cpp:106] Iteration 44200, lr = 1e-07
I0429 01:34:06.046442  5145 solver.cpp:228] Iteration 44300, loss = 0.296401
I0429 01:34:06.046602  5145 solver.cpp:244]     Train net output #0: loss = 0.296401 (* 1 = 0.296401 loss)
I0429 01:34:06.046608  5145 sgd_solver.cpp:106] Iteration 44300, lr = 1e-07
I0429 01:34:56.588551  5145 solver.cpp:228] Iteration 44400, loss = 0.243877
I0429 01:34:56.589408  5145 solver.cpp:244]     Train net output #0: loss = 0.243877 (* 1 = 0.243877 loss)
I0429 01:34:56.589416  5145 sgd_solver.cpp:106] Iteration 44400, lr = 1e-07
I0429 01:35:47.179451  5145 solver.cpp:228] Iteration 44500, loss = 0.229327
I0429 01:35:47.179641  5145 solver.cpp:244]     Train net output #0: loss = 0.229327 (* 1 = 0.229327 loss)
I0429 01:35:47.179646  5145 sgd_solver.cpp:106] Iteration 44500, lr = 1e-07
I0429 01:36:39.370548  5145 solver.cpp:228] Iteration 44600, loss = 0.368054
I0429 01:36:39.370738  5145 solver.cpp:244]     Train net output #0: loss = 0.368054 (* 1 = 0.368054 loss)
I0429 01:36:39.370745  5145 sgd_solver.cpp:106] Iteration 44600, lr = 1e-07
I0429 01:37:29.853854  5145 solver.cpp:228] Iteration 44700, loss = 0.383585
I0429 01:37:29.854070  5145 solver.cpp:244]     Train net output #0: loss = 0.383585 (* 1 = 0.383585 loss)
I0429 01:37:29.854079  5145 sgd_solver.cpp:106] Iteration 44700, lr = 1e-07
I0429 01:38:20.365000  5145 solver.cpp:228] Iteration 44800, loss = 0.274338
I0429 01:38:20.365159  5145 solver.cpp:244]     Train net output #0: loss = 0.274338 (* 1 = 0.274338 loss)
I0429 01:38:20.365165  5145 sgd_solver.cpp:106] Iteration 44800, lr = 1e-07
I0429 01:39:12.588728  5145 solver.cpp:228] Iteration 44900, loss = 0.276644
I0429 01:39:12.588889  5145 solver.cpp:244]     Train net output #0: loss = 0.276644 (* 1 = 0.276644 loss)
I0429 01:39:12.588896  5145 sgd_solver.cpp:106] Iteration 44900, lr = 1e-07
I0429 01:40:02.692519  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_45000.caffemodel
I0429 01:40:18.910943  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_45000.solverstate
I0429 01:40:19.128374  5145 solver.cpp:337] Iteration 45000, Testing net (#0)
I0429 01:40:19.128443  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 01:40:19.128446  5145 net.cpp:693] Ignoring source layer visualize
I0429 01:40:19.128456  5145 net.cpp:693] Ignoring source layer fake
I0429 01:45:15.029754  5145 solver.cpp:404]     Test net output #0: loss = 0.287333 (* 1 = 0.287333 loss)
I0429 01:45:15.344132  5145 solver.cpp:228] Iteration 45000, loss = 0.344346
I0429 01:45:15.344151  5145 solver.cpp:244]     Train net output #0: loss = 0.344346 (* 1 = 0.344346 loss)
I0429 01:45:15.344172  5145 sgd_solver.cpp:106] Iteration 45000, lr = 1e-08
I0429 01:46:05.909652  5145 solver.cpp:228] Iteration 45100, loss = 0.28955
I0429 01:46:05.909819  5145 solver.cpp:244]     Train net output #0: loss = 0.28955 (* 1 = 0.28955 loss)
I0429 01:46:05.909827  5145 sgd_solver.cpp:106] Iteration 45100, lr = 1e-08
I0429 01:46:56.506616  5145 solver.cpp:228] Iteration 45200, loss = 0.281031
I0429 01:46:56.506788  5145 solver.cpp:244]     Train net output #0: loss = 0.281031 (* 1 = 0.281031 loss)
I0429 01:46:56.506796  5145 sgd_solver.cpp:106] Iteration 45200, lr = 1e-08
I0429 01:47:48.777431  5145 solver.cpp:228] Iteration 45300, loss = 0.265809
I0429 01:47:48.777616  5145 solver.cpp:244]     Train net output #0: loss = 0.265809 (* 1 = 0.265809 loss)
I0429 01:47:48.777623  5145 sgd_solver.cpp:106] Iteration 45300, lr = 1e-08
I0429 01:48:39.358981  5145 solver.cpp:228] Iteration 45400, loss = 0.189092
I0429 01:48:39.359143  5145 solver.cpp:244]     Train net output #0: loss = 0.189092 (* 1 = 0.189092 loss)
I0429 01:48:39.359150  5145 sgd_solver.cpp:106] Iteration 45400, lr = 1e-08
I0429 01:49:29.936758  5145 solver.cpp:228] Iteration 45500, loss = 0.285132
I0429 01:49:29.936921  5145 solver.cpp:244]     Train net output #0: loss = 0.285132 (* 1 = 0.285132 loss)
I0429 01:49:29.936929  5145 sgd_solver.cpp:106] Iteration 45500, lr = 1e-08
I0429 01:50:22.370729  5145 solver.cpp:228] Iteration 45600, loss = 0.20023
I0429 01:50:22.370892  5145 solver.cpp:244]     Train net output #0: loss = 0.20023 (* 1 = 0.20023 loss)
I0429 01:50:22.370898  5145 sgd_solver.cpp:106] Iteration 45600, lr = 1e-08
I0429 01:51:12.996611  5145 solver.cpp:228] Iteration 45700, loss = 0.169897
I0429 01:51:12.996769  5145 solver.cpp:244]     Train net output #0: loss = 0.169897 (* 1 = 0.169897 loss)
I0429 01:51:12.996776  5145 sgd_solver.cpp:106] Iteration 45700, lr = 1e-08
I0429 01:52:03.470037  5145 solver.cpp:228] Iteration 45800, loss = 0.250411
I0429 01:52:03.470209  5145 solver.cpp:244]     Train net output #0: loss = 0.250411 (* 1 = 0.250411 loss)
I0429 01:52:03.470216  5145 sgd_solver.cpp:106] Iteration 45800, lr = 1e-08
I0429 01:52:55.713376  5145 solver.cpp:228] Iteration 45900, loss = 0.222938
I0429 01:52:55.713559  5145 solver.cpp:244]     Train net output #0: loss = 0.222938 (* 1 = 0.222938 loss)
I0429 01:52:55.713567  5145 sgd_solver.cpp:106] Iteration 45900, lr = 1e-08
I0429 01:53:45.757328  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_46000.caffemodel
I0429 01:53:57.004804  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_46000.solverstate
I0429 01:53:57.198225  5145 solver.cpp:337] Iteration 46000, Testing net (#0)
I0429 01:53:57.198325  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 01:53:57.198330  5145 net.cpp:693] Ignoring source layer visualize
I0429 01:53:57.198333  5145 net.cpp:693] Ignoring source layer fake
I0429 01:58:53.370653  5145 solver.cpp:404]     Test net output #0: loss = 0.285881 (* 1 = 0.285881 loss)
I0429 01:58:53.693020  5145 solver.cpp:228] Iteration 46000, loss = 0.167255
I0429 01:58:53.693038  5145 solver.cpp:244]     Train net output #0: loss = 0.167255 (* 1 = 0.167255 loss)
I0429 01:58:53.693060  5145 sgd_solver.cpp:106] Iteration 46000, lr = 1e-08
I0429 01:59:44.193408  5145 solver.cpp:228] Iteration 46100, loss = 0.212768
I0429 01:59:44.193558  5145 solver.cpp:244]     Train net output #0: loss = 0.212768 (* 1 = 0.212768 loss)
I0429 01:59:44.193565  5145 sgd_solver.cpp:106] Iteration 46100, lr = 1e-08
I0429 02:00:34.806509  5145 solver.cpp:228] Iteration 46200, loss = 0.247189
I0429 02:00:34.806666  5145 solver.cpp:244]     Train net output #0: loss = 0.247189 (* 1 = 0.247189 loss)
I0429 02:00:34.806674  5145 sgd_solver.cpp:106] Iteration 46200, lr = 1e-08
I0429 02:01:27.115238  5145 solver.cpp:228] Iteration 46300, loss = 0.22287
I0429 02:01:27.115432  5145 solver.cpp:244]     Train net output #0: loss = 0.22287 (* 1 = 0.22287 loss)
I0429 02:01:27.115439  5145 sgd_solver.cpp:106] Iteration 46300, lr = 1e-08
I0429 02:02:17.769791  5145 solver.cpp:228] Iteration 46400, loss = 0.104531
I0429 02:02:17.769955  5145 solver.cpp:244]     Train net output #0: loss = 0.104531 (* 1 = 0.104531 loss)
I0429 02:02:17.769963  5145 sgd_solver.cpp:106] Iteration 46400, lr = 1e-08
I0429 02:03:08.349601  5145 solver.cpp:228] Iteration 46500, loss = 0.211943
I0429 02:03:08.349745  5145 solver.cpp:244]     Train net output #0: loss = 0.211943 (* 1 = 0.211943 loss)
I0429 02:03:08.349751  5145 sgd_solver.cpp:106] Iteration 46500, lr = 1e-08
I0429 02:04:00.459272  5145 solver.cpp:228] Iteration 46600, loss = 0.490796
I0429 02:04:00.459430  5145 solver.cpp:244]     Train net output #0: loss = 0.490796 (* 1 = 0.490796 loss)
I0429 02:04:00.459450  5145 sgd_solver.cpp:106] Iteration 46600, lr = 1e-08
I0429 02:04:51.044044  5145 solver.cpp:228] Iteration 46700, loss = 0.158578
I0429 02:04:51.044201  5145 solver.cpp:244]     Train net output #0: loss = 0.158578 (* 1 = 0.158578 loss)
I0429 02:04:51.044208  5145 sgd_solver.cpp:106] Iteration 46700, lr = 1e-08
I0429 02:05:41.458214  5145 solver.cpp:228] Iteration 46800, loss = 0.237567
I0429 02:05:41.458387  5145 solver.cpp:244]     Train net output #0: loss = 0.237567 (* 1 = 0.237567 loss)
I0429 02:05:41.458395  5145 sgd_solver.cpp:106] Iteration 46800, lr = 1e-08
I0429 02:06:33.138720  5145 solver.cpp:228] Iteration 46900, loss = 0.230183
I0429 02:06:33.138883  5145 solver.cpp:244]     Train net output #0: loss = 0.230183 (* 1 = 0.230183 loss)
I0429 02:06:33.138890  5145 sgd_solver.cpp:106] Iteration 46900, lr = 1e-08
I0429 02:07:23.276419  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_47000.caffemodel
I0429 02:07:33.318838  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_47000.solverstate
I0429 02:07:33.509374  5145 solver.cpp:337] Iteration 47000, Testing net (#0)
I0429 02:07:33.509479  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 02:07:33.509482  5145 net.cpp:693] Ignoring source layer visualize
I0429 02:07:33.509485  5145 net.cpp:693] Ignoring source layer fake
I0429 02:12:29.172592  5145 solver.cpp:404]     Test net output #0: loss = 0.281532 (* 1 = 0.281532 loss)
I0429 02:12:29.490514  5145 solver.cpp:228] Iteration 47000, loss = 0.225047
I0429 02:12:29.490550  5145 solver.cpp:244]     Train net output #0: loss = 0.225047 (* 1 = 0.225047 loss)
I0429 02:12:29.490556  5145 sgd_solver.cpp:106] Iteration 47000, lr = 1e-08
I0429 02:13:20.025804  5145 solver.cpp:228] Iteration 47100, loss = 0.246483
I0429 02:13:20.025955  5145 solver.cpp:244]     Train net output #0: loss = 0.246483 (* 1 = 0.246483 loss)
I0429 02:13:20.025962  5145 sgd_solver.cpp:106] Iteration 47100, lr = 1e-08
I0429 02:14:11.760501  5145 solver.cpp:228] Iteration 47200, loss = 0.25567
I0429 02:14:11.760668  5145 solver.cpp:244]     Train net output #0: loss = 0.25567 (* 1 = 0.25567 loss)
I0429 02:14:11.760674  5145 sgd_solver.cpp:106] Iteration 47200, lr = 1e-08
I0429 02:15:02.337299  5145 solver.cpp:228] Iteration 47300, loss = 0.214915
I0429 02:15:02.337486  5145 solver.cpp:244]     Train net output #0: loss = 0.214915 (* 1 = 0.214915 loss)
I0429 02:15:02.337494  5145 sgd_solver.cpp:106] Iteration 47300, lr = 1e-08
I0429 02:15:54.424757  5145 solver.cpp:228] Iteration 47400, loss = 0.235915
I0429 02:15:54.424933  5145 solver.cpp:244]     Train net output #0: loss = 0.235915 (* 1 = 0.235915 loss)
I0429 02:15:54.424940  5145 sgd_solver.cpp:106] Iteration 47400, lr = 1e-08
I0429 02:16:45.002183  5145 solver.cpp:228] Iteration 47500, loss = 0.307008
I0429 02:16:45.002360  5145 solver.cpp:244]     Train net output #0: loss = 0.307008 (* 1 = 0.307008 loss)
I0429 02:16:45.002367  5145 sgd_solver.cpp:106] Iteration 47500, lr = 1e-08
I0429 02:17:35.533826  5145 solver.cpp:228] Iteration 47600, loss = 0.229666
I0429 02:17:35.533998  5145 solver.cpp:244]     Train net output #0: loss = 0.229666 (* 1 = 0.229666 loss)
I0429 02:17:35.534004  5145 sgd_solver.cpp:106] Iteration 47600, lr = 1e-08
I0429 02:18:27.984355  5145 solver.cpp:228] Iteration 47700, loss = 0.287992
I0429 02:18:27.984525  5145 solver.cpp:244]     Train net output #0: loss = 0.287992 (* 1 = 0.287992 loss)
I0429 02:18:27.984534  5145 sgd_solver.cpp:106] Iteration 47700, lr = 1e-08
I0429 02:19:18.553692  5145 solver.cpp:228] Iteration 47800, loss = 0.257915
I0429 02:19:18.553855  5145 solver.cpp:244]     Train net output #0: loss = 0.257915 (* 1 = 0.257915 loss)
I0429 02:19:18.553861  5145 sgd_solver.cpp:106] Iteration 47800, lr = 1e-08
I0429 02:20:09.128482  5145 solver.cpp:228] Iteration 47900, loss = 0.385773
I0429 02:20:09.128654  5145 solver.cpp:244]     Train net output #0: loss = 0.385773 (* 1 = 0.385773 loss)
I0429 02:20:09.128659  5145 sgd_solver.cpp:106] Iteration 47900, lr = 1e-08
I0429 02:21:01.151115  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_48000.caffemodel
I0429 02:21:04.590446  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_48000.solverstate
I0429 02:21:04.795930  5145 solver.cpp:337] Iteration 48000, Testing net (#0)
I0429 02:21:04.796013  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 02:21:04.796017  5145 net.cpp:693] Ignoring source layer visualize
I0429 02:21:04.796036  5145 net.cpp:693] Ignoring source layer fake
I0429 02:26:01.524559  5145 solver.cpp:404]     Test net output #0: loss = 0.281734 (* 1 = 0.281734 loss)
I0429 02:26:01.841526  5145 solver.cpp:228] Iteration 48000, loss = 0.305029
I0429 02:26:01.841564  5145 solver.cpp:244]     Train net output #0: loss = 0.305029 (* 1 = 0.305029 loss)
I0429 02:26:01.841572  5145 sgd_solver.cpp:106] Iteration 48000, lr = 1e-08
I0429 02:26:52.537976  5145 solver.cpp:228] Iteration 48100, loss = 0.236035
I0429 02:26:52.538151  5145 solver.cpp:244]     Train net output #0: loss = 0.236035 (* 1 = 0.236035 loss)
I0429 02:26:52.538157  5145 sgd_solver.cpp:106] Iteration 48100, lr = 1e-08
I0429 02:27:43.062508  5145 solver.cpp:228] Iteration 48200, loss = 0.405616
I0429 02:27:43.062700  5145 solver.cpp:244]     Train net output #0: loss = 0.405616 (* 1 = 0.405616 loss)
I0429 02:27:43.062706  5145 sgd_solver.cpp:106] Iteration 48200, lr = 1e-08
I0429 02:28:33.588218  5145 solver.cpp:228] Iteration 48300, loss = 0.285862
I0429 02:28:33.588380  5145 solver.cpp:244]     Train net output #0: loss = 0.285862 (* 1 = 0.285862 loss)
I0429 02:28:33.588387  5145 sgd_solver.cpp:106] Iteration 48300, lr = 1e-08
I0429 02:29:25.985132  5145 solver.cpp:228] Iteration 48400, loss = 0.487469
I0429 02:29:25.985301  5145 solver.cpp:244]     Train net output #0: loss = 0.487469 (* 1 = 0.487469 loss)
I0429 02:29:25.985308  5145 sgd_solver.cpp:106] Iteration 48400, lr = 1e-08
I0429 02:30:16.641355  5145 solver.cpp:228] Iteration 48500, loss = 0.261834
I0429 02:30:16.641530  5145 solver.cpp:244]     Train net output #0: loss = 0.261834 (* 1 = 0.261834 loss)
I0429 02:30:16.641536  5145 sgd_solver.cpp:106] Iteration 48500, lr = 1e-08
I0429 02:31:07.132859  5145 solver.cpp:228] Iteration 48600, loss = 0.288657
I0429 02:31:07.133028  5145 solver.cpp:244]     Train net output #0: loss = 0.288657 (* 1 = 0.288657 loss)
I0429 02:31:07.133035  5145 sgd_solver.cpp:106] Iteration 48600, lr = 1e-08
I0429 02:31:59.658845  5145 solver.cpp:228] Iteration 48700, loss = 0.286905
I0429 02:31:59.659021  5145 solver.cpp:244]     Train net output #0: loss = 0.286905 (* 1 = 0.286905 loss)
I0429 02:31:59.659027  5145 sgd_solver.cpp:106] Iteration 48700, lr = 1e-08
I0429 02:32:50.053617  5145 solver.cpp:228] Iteration 48800, loss = 0.284565
I0429 02:32:50.053803  5145 solver.cpp:244]     Train net output #0: loss = 0.284565 (* 1 = 0.284565 loss)
I0429 02:32:50.053813  5145 sgd_solver.cpp:106] Iteration 48800, lr = 1e-08
I0429 02:33:40.411121  5145 solver.cpp:228] Iteration 48900, loss = 0.275613
I0429 02:33:40.411283  5145 solver.cpp:244]     Train net output #0: loss = 0.275613 (* 1 = 0.275613 loss)
I0429 02:33:40.411289  5145 sgd_solver.cpp:106] Iteration 48900, lr = 1e-08
I0429 02:34:30.565784  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_49000.caffemodel
I0429 02:34:43.976615  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_49000.solverstate
I0429 02:34:44.170769  5145 solver.cpp:337] Iteration 49000, Testing net (#0)
I0429 02:34:44.170850  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 02:34:44.170855  5145 net.cpp:693] Ignoring source layer visualize
I0429 02:34:44.170872  5145 net.cpp:693] Ignoring source layer fake
I0429 02:39:41.098248  5145 solver.cpp:404]     Test net output #0: loss = 0.29063 (* 1 = 0.29063 loss)
I0429 02:39:41.412576  5145 solver.cpp:228] Iteration 49000, loss = 0.229483
I0429 02:39:41.412613  5145 solver.cpp:244]     Train net output #0: loss = 0.229483 (* 1 = 0.229483 loss)
I0429 02:39:41.412619  5145 sgd_solver.cpp:106] Iteration 49000, lr = 1e-08
I0429 02:40:34.005980  5145 solver.cpp:228] Iteration 49100, loss = 0.34989
I0429 02:40:34.016188  5145 solver.cpp:244]     Train net output #0: loss = 0.34989 (* 1 = 0.34989 loss)
I0429 02:40:34.016201  5145 sgd_solver.cpp:106] Iteration 49100, lr = 1e-08
I0429 02:41:24.484822  5145 solver.cpp:228] Iteration 49200, loss = 0.231972
I0429 02:41:24.485000  5145 solver.cpp:244]     Train net output #0: loss = 0.231972 (* 1 = 0.231972 loss)
I0429 02:41:24.485007  5145 sgd_solver.cpp:106] Iteration 49200, lr = 1e-08
I0429 02:42:15.057623  5145 solver.cpp:228] Iteration 49300, loss = 0.265618
I0429 02:42:15.057807  5145 solver.cpp:244]     Train net output #0: loss = 0.265618 (* 1 = 0.265618 loss)
I0429 02:42:15.057813  5145 sgd_solver.cpp:106] Iteration 49300, lr = 1e-08
I0429 02:43:07.744127  5145 solver.cpp:228] Iteration 49400, loss = 0.227035
I0429 02:43:07.744294  5145 solver.cpp:244]     Train net output #0: loss = 0.227035 (* 1 = 0.227035 loss)
I0429 02:43:07.744302  5145 sgd_solver.cpp:106] Iteration 49400, lr = 1e-08
I0429 02:43:58.327975  5145 solver.cpp:228] Iteration 49500, loss = 0.244269
I0429 02:43:58.328162  5145 solver.cpp:244]     Train net output #0: loss = 0.244269 (* 1 = 0.244269 loss)
I0429 02:43:58.328171  5145 sgd_solver.cpp:106] Iteration 49500, lr = 1e-08
I0429 02:44:48.886036  5145 solver.cpp:228] Iteration 49600, loss = 0.303775
I0429 02:44:48.887490  5145 solver.cpp:244]     Train net output #0: loss = 0.303775 (* 1 = 0.303775 loss)
I0429 02:44:48.887513  5145 sgd_solver.cpp:106] Iteration 49600, lr = 1e-08
I0429 02:45:41.036383  5145 solver.cpp:228] Iteration 49700, loss = 0.239265
I0429 02:45:41.037698  5145 solver.cpp:244]     Train net output #0: loss = 0.239265 (* 1 = 0.239265 loss)
I0429 02:45:41.037706  5145 sgd_solver.cpp:106] Iteration 49700, lr = 1e-08
I0429 02:46:31.420243  5145 solver.cpp:228] Iteration 49800, loss = 0.69357
I0429 02:46:31.422624  5145 solver.cpp:244]     Train net output #0: loss = 0.69357 (* 1 = 0.69357 loss)
I0429 02:46:31.422638  5145 sgd_solver.cpp:106] Iteration 49800, lr = 1e-08
I0429 02:47:22.019716  5145 solver.cpp:228] Iteration 49900, loss = 0.23065
I0429 02:47:22.019928  5145 solver.cpp:244]     Train net output #0: loss = 0.23065 (* 1 = 0.23065 loss)
I0429 02:47:22.019937  5145 sgd_solver.cpp:106] Iteration 49900, lr = 1e-08
I0429 02:48:13.440567  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_50000.caffemodel
I0429 02:48:40.834296  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_50000.solverstate
I0429 02:48:41.030927  5145 solver.cpp:337] Iteration 50000, Testing net (#0)
I0429 02:48:41.031028  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 02:48:41.031035  5145 net.cpp:693] Ignoring source layer visualize
I0429 02:48:41.031038  5145 net.cpp:693] Ignoring source layer fake
I0429 02:53:37.382752  5145 solver.cpp:404]     Test net output #0: loss = 0.287564 (* 1 = 0.287564 loss)
I0429 02:53:37.695289  5145 solver.cpp:228] Iteration 50000, loss = 0.200771
I0429 02:53:37.695332  5145 solver.cpp:244]     Train net output #0: loss = 0.200771 (* 1 = 0.200771 loss)
I0429 02:53:37.695338  5145 sgd_solver.cpp:106] Iteration 50000, lr = 1e-08
I0429 02:54:28.290984  5145 solver.cpp:228] Iteration 50100, loss = 0.337167
I0429 02:54:28.291141  5145 solver.cpp:244]     Train net output #0: loss = 0.337167 (* 1 = 0.337167 loss)
I0429 02:54:28.291147  5145 sgd_solver.cpp:106] Iteration 50100, lr = 1e-08
I0429 02:55:18.906133  5145 solver.cpp:228] Iteration 50200, loss = 0.205629
I0429 02:55:18.906307  5145 solver.cpp:244]     Train net output #0: loss = 0.205629 (* 1 = 0.205629 loss)
I0429 02:55:18.906314  5145 sgd_solver.cpp:106] Iteration 50200, lr = 1e-08
I0429 02:56:10.790026  5145 solver.cpp:228] Iteration 50300, loss = 0.273016
I0429 02:56:10.790199  5145 solver.cpp:244]     Train net output #0: loss = 0.273016 (* 1 = 0.273016 loss)
I0429 02:56:10.790205  5145 sgd_solver.cpp:106] Iteration 50300, lr = 1e-08
I0429 02:57:01.274839  5145 solver.cpp:228] Iteration 50400, loss = 0.334642
I0429 02:57:01.274991  5145 solver.cpp:244]     Train net output #0: loss = 0.334642 (* 1 = 0.334642 loss)
I0429 02:57:01.274997  5145 sgd_solver.cpp:106] Iteration 50400, lr = 1e-08
I0429 02:57:53.505317  5145 solver.cpp:228] Iteration 50500, loss = 0.236639
I0429 02:57:53.505486  5145 solver.cpp:244]     Train net output #0: loss = 0.236639 (* 1 = 0.236639 loss)
I0429 02:57:53.505492  5145 sgd_solver.cpp:106] Iteration 50500, lr = 1e-08
I0429 02:58:44.121948  5145 solver.cpp:228] Iteration 50600, loss = 0.288403
I0429 02:58:44.122166  5145 solver.cpp:244]     Train net output #0: loss = 0.288403 (* 1 = 0.288403 loss)
I0429 02:58:44.122182  5145 sgd_solver.cpp:106] Iteration 50600, lr = 1e-08
I0429 02:59:34.671878  5145 solver.cpp:228] Iteration 50700, loss = 0.341383
I0429 02:59:34.672063  5145 solver.cpp:244]     Train net output #0: loss = 0.341383 (* 1 = 0.341383 loss)
I0429 02:59:34.672070  5145 sgd_solver.cpp:106] Iteration 50700, lr = 1e-08
I0429 03:00:26.768601  5145 solver.cpp:228] Iteration 50800, loss = 0.285195
I0429 03:00:26.769968  5145 solver.cpp:244]     Train net output #0: loss = 0.285195 (* 1 = 0.285195 loss)
I0429 03:00:26.769991  5145 sgd_solver.cpp:106] Iteration 50800, lr = 1e-08
I0429 03:01:17.234375  5145 solver.cpp:228] Iteration 50900, loss = 0.307344
I0429 03:01:17.234561  5145 solver.cpp:244]     Train net output #0: loss = 0.307344 (* 1 = 0.307344 loss)
I0429 03:01:17.234570  5145 sgd_solver.cpp:106] Iteration 50900, lr = 1e-08
I0429 03:02:07.375895  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_51000.caffemodel
I0429 03:02:20.983137  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_51000.solverstate
I0429 03:02:21.173329  5145 solver.cpp:337] Iteration 51000, Testing net (#0)
I0429 03:02:21.173413  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 03:02:21.173418  5145 net.cpp:693] Ignoring source layer visualize
I0429 03:02:21.173419  5145 net.cpp:693] Ignoring source layer fake
I0429 03:07:18.114517  5145 solver.cpp:404]     Test net output #0: loss = 0.286028 (* 1 = 0.286028 loss)
I0429 03:07:18.429131  5145 solver.cpp:228] Iteration 51000, loss = 0.123538
I0429 03:07:18.429167  5145 solver.cpp:244]     Train net output #0: loss = 0.123538 (* 1 = 0.123538 loss)
I0429 03:07:18.429173  5145 sgd_solver.cpp:106] Iteration 51000, lr = 1e-08
I0429 03:08:09.107004  5145 solver.cpp:228] Iteration 51100, loss = 0.310022
I0429 03:08:09.107156  5145 solver.cpp:244]     Train net output #0: loss = 0.310022 (* 1 = 0.310022 loss)
I0429 03:08:09.107163  5145 sgd_solver.cpp:106] Iteration 51100, lr = 1e-08
I0429 03:09:01.504791  5145 solver.cpp:228] Iteration 51200, loss = 0.249264
I0429 03:09:01.504940  5145 solver.cpp:244]     Train net output #0: loss = 0.249264 (* 1 = 0.249264 loss)
I0429 03:09:01.504946  5145 sgd_solver.cpp:106] Iteration 51200, lr = 1e-08
I0429 03:09:51.996222  5145 solver.cpp:228] Iteration 51300, loss = 0.361669
I0429 03:09:51.996381  5145 solver.cpp:244]     Train net output #0: loss = 0.361669 (* 1 = 0.361669 loss)
I0429 03:09:51.996389  5145 sgd_solver.cpp:106] Iteration 51300, lr = 1e-08
I0429 03:10:42.541365  5145 solver.cpp:228] Iteration 51400, loss = 0.261325
I0429 03:10:42.541570  5145 solver.cpp:244]     Train net output #0: loss = 0.261325 (* 1 = 0.261325 loss)
I0429 03:10:42.541577  5145 sgd_solver.cpp:106] Iteration 51400, lr = 1e-08
I0429 03:11:34.989995  5145 solver.cpp:228] Iteration 51500, loss = 0.465343
I0429 03:11:34.990165  5145 solver.cpp:244]     Train net output #0: loss = 0.465343 (* 1 = 0.465343 loss)
I0429 03:11:34.990172  5145 sgd_solver.cpp:106] Iteration 51500, lr = 1e-08
I0429 03:12:25.609949  5145 solver.cpp:228] Iteration 51600, loss = 0.294286
I0429 03:12:25.610126  5145 solver.cpp:244]     Train net output #0: loss = 0.294286 (* 1 = 0.294286 loss)
I0429 03:12:25.610132  5145 sgd_solver.cpp:106] Iteration 51600, lr = 1e-08
I0429 03:13:16.009312  5145 solver.cpp:228] Iteration 51700, loss = 0.399206
I0429 03:13:16.009492  5145 solver.cpp:244]     Train net output #0: loss = 0.399206 (* 1 = 0.399206 loss)
I0429 03:13:16.009500  5145 sgd_solver.cpp:106] Iteration 51700, lr = 1e-08
I0429 03:14:06.418535  5145 solver.cpp:228] Iteration 51800, loss = 0.263245
I0429 03:14:06.418705  5145 solver.cpp:244]     Train net output #0: loss = 0.263245 (* 1 = 0.263245 loss)
I0429 03:14:06.418714  5145 sgd_solver.cpp:106] Iteration 51800, lr = 1e-08
I0429 03:14:58.690289  5145 solver.cpp:228] Iteration 51900, loss = 0.240205
I0429 03:14:58.690459  5145 solver.cpp:244]     Train net output #0: loss = 0.240205 (* 1 = 0.240205 loss)
I0429 03:14:58.690467  5145 sgd_solver.cpp:106] Iteration 51900, lr = 1e-08
I0429 03:15:48.774482  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_52000.caffemodel
I0429 03:15:55.371516  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_52000.solverstate
I0429 03:15:55.558751  5145 solver.cpp:337] Iteration 52000, Testing net (#0)
I0429 03:15:55.558835  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 03:15:55.558854  5145 net.cpp:693] Ignoring source layer visualize
I0429 03:15:55.558857  5145 net.cpp:693] Ignoring source layer fake
I0429 03:20:52.027778  5145 solver.cpp:404]     Test net output #0: loss = 0.281148 (* 1 = 0.281148 loss)
I0429 03:20:52.341143  5145 solver.cpp:228] Iteration 52000, loss = 0.227952
I0429 03:20:52.341181  5145 solver.cpp:244]     Train net output #0: loss = 0.227952 (* 1 = 0.227952 loss)
I0429 03:20:52.341187  5145 sgd_solver.cpp:106] Iteration 52000, lr = 1e-08
I0429 03:21:42.852799  5145 solver.cpp:228] Iteration 52100, loss = 0.34861
I0429 03:21:42.852959  5145 solver.cpp:244]     Train net output #0: loss = 0.34861 (* 1 = 0.34861 loss)
I0429 03:21:42.852967  5145 sgd_solver.cpp:106] Iteration 52100, lr = 1e-08
I0429 03:22:35.177366  5145 solver.cpp:228] Iteration 52200, loss = 0.326215
I0429 03:22:35.177516  5145 solver.cpp:244]     Train net output #0: loss = 0.326215 (* 1 = 0.326215 loss)
I0429 03:22:35.177523  5145 sgd_solver.cpp:106] Iteration 52200, lr = 1e-08
I0429 03:23:25.689918  5145 solver.cpp:228] Iteration 52300, loss = 0.160942
I0429 03:23:25.690064  5145 solver.cpp:244]     Train net output #0: loss = 0.160942 (* 1 = 0.160942 loss)
I0429 03:23:25.690070  5145 sgd_solver.cpp:106] Iteration 52300, lr = 1e-08
I0429 03:24:16.181157  5145 solver.cpp:228] Iteration 52400, loss = 0.21456
I0429 03:24:16.181324  5145 solver.cpp:244]     Train net output #0: loss = 0.21456 (* 1 = 0.21456 loss)
I0429 03:24:16.181332  5145 sgd_solver.cpp:106] Iteration 52400, lr = 1e-08
I0429 03:25:08.496807  5145 solver.cpp:228] Iteration 52500, loss = 0.183489
I0429 03:25:08.496963  5145 solver.cpp:244]     Train net output #0: loss = 0.183489 (* 1 = 0.183489 loss)
I0429 03:25:08.496971  5145 sgd_solver.cpp:106] Iteration 52500, lr = 1e-09
I0429 03:25:58.995831  5145 solver.cpp:228] Iteration 52600, loss = 0.0446696
I0429 03:25:58.996065  5145 solver.cpp:244]     Train net output #0: loss = 0.0446696 (* 1 = 0.0446696 loss)
I0429 03:25:58.996074  5145 sgd_solver.cpp:106] Iteration 52600, lr = 1e-09
I0429 03:26:49.548173  5145 solver.cpp:228] Iteration 52700, loss = 0.129874
I0429 03:26:49.548341  5145 solver.cpp:244]     Train net output #0: loss = 0.129874 (* 1 = 0.129874 loss)
I0429 03:26:49.548347  5145 sgd_solver.cpp:106] Iteration 52700, lr = 1e-09
I0429 03:27:40.049563  5145 solver.cpp:228] Iteration 52800, loss = 0.287943
I0429 03:27:40.049728  5145 solver.cpp:244]     Train net output #0: loss = 0.287943 (* 1 = 0.287943 loss)
I0429 03:27:40.049736  5145 sgd_solver.cpp:106] Iteration 52800, lr = 1e-09
I0429 03:28:32.074940  5145 solver.cpp:228] Iteration 52900, loss = 0.0752125
I0429 03:28:32.075094  5145 solver.cpp:244]     Train net output #0: loss = 0.0752125 (* 1 = 0.0752125 loss)
I0429 03:28:32.075101  5145 sgd_solver.cpp:106] Iteration 52900, lr = 1e-09
I0429 03:29:22.292775  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_53000.caffemodel
I0429 03:29:33.815510  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_53000.solverstate
I0429 03:29:34.005074  5145 solver.cpp:337] Iteration 53000, Testing net (#0)
I0429 03:29:34.005174  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 03:29:34.005180  5145 net.cpp:693] Ignoring source layer visualize
I0429 03:29:34.005183  5145 net.cpp:693] Ignoring source layer fake
I0429 03:34:30.612448  5145 solver.cpp:404]     Test net output #0: loss = 0.282326 (* 1 = 0.282326 loss)
I0429 03:34:30.924484  5145 solver.cpp:228] Iteration 53000, loss = 0.116972
I0429 03:34:30.924525  5145 solver.cpp:244]     Train net output #0: loss = 0.116972 (* 1 = 0.116972 loss)
I0429 03:34:30.924532  5145 sgd_solver.cpp:106] Iteration 53000, lr = 1e-09
I0429 03:35:21.459677  5145 solver.cpp:228] Iteration 53100, loss = 0.254015
I0429 03:35:21.460659  5145 solver.cpp:244]     Train net output #0: loss = 0.254015 (* 1 = 0.254015 loss)
I0429 03:35:21.460683  5145 sgd_solver.cpp:106] Iteration 53100, lr = 1e-09
I0429 03:36:13.355216  5145 solver.cpp:228] Iteration 53200, loss = 0.249552
I0429 03:36:13.355379  5145 solver.cpp:244]     Train net output #0: loss = 0.249552 (* 1 = 0.249552 loss)
I0429 03:36:13.355386  5145 sgd_solver.cpp:106] Iteration 53200, lr = 1e-09
I0429 03:37:03.920668  5145 solver.cpp:228] Iteration 53300, loss = 0.289781
I0429 03:37:03.920825  5145 solver.cpp:244]     Train net output #0: loss = 0.289781 (* 1 = 0.289781 loss)
I0429 03:37:03.920831  5145 sgd_solver.cpp:106] Iteration 53300, lr = 1e-09
I0429 03:37:55.723522  5145 solver.cpp:228] Iteration 53400, loss = 0.130182
I0429 03:37:55.723685  5145 solver.cpp:244]     Train net output #0: loss = 0.130182 (* 1 = 0.130182 loss)
I0429 03:37:55.723692  5145 sgd_solver.cpp:106] Iteration 53400, lr = 1e-09
I0429 03:38:46.205240  5145 solver.cpp:228] Iteration 53500, loss = 0.279728
I0429 03:38:46.205385  5145 solver.cpp:244]     Train net output #0: loss = 0.279728 (* 1 = 0.279728 loss)
I0429 03:38:46.205394  5145 sgd_solver.cpp:106] Iteration 53500, lr = 1e-09
I0429 03:39:36.803992  5145 solver.cpp:228] Iteration 53600, loss = 0.34886
I0429 03:39:36.804148  5145 solver.cpp:244]     Train net output #0: loss = 0.34886 (* 1 = 0.34886 loss)
I0429 03:39:36.804155  5145 sgd_solver.cpp:106] Iteration 53600, lr = 1e-09
I0429 03:40:28.808392  5145 solver.cpp:228] Iteration 53700, loss = 0.362677
I0429 03:40:28.808562  5145 solver.cpp:244]     Train net output #0: loss = 0.362677 (* 1 = 0.362677 loss)
I0429 03:40:28.808569  5145 sgd_solver.cpp:106] Iteration 53700, lr = 1e-09
I0429 03:41:19.250756  5145 solver.cpp:228] Iteration 53800, loss = 0.301993
I0429 03:41:19.250916  5145 solver.cpp:244]     Train net output #0: loss = 0.301993 (* 1 = 0.301993 loss)
I0429 03:41:19.250923  5145 sgd_solver.cpp:106] Iteration 53800, lr = 1e-09
I0429 03:42:09.724217  5145 solver.cpp:228] Iteration 53900, loss = 0.0333423
I0429 03:42:09.724411  5145 solver.cpp:244]     Train net output #0: loss = 0.0333423 (* 1 = 0.0333423 loss)
I0429 03:42:09.724419  5145 sgd_solver.cpp:106] Iteration 53900, lr = 1e-09
I0429 03:43:01.649227  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_54000.caffemodel
I0429 03:43:23.788861  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_54000.solverstate
I0429 03:43:23.977811  5145 solver.cpp:337] Iteration 54000, Testing net (#0)
I0429 03:43:23.977896  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 03:43:23.977900  5145 net.cpp:693] Ignoring source layer visualize
I0429 03:43:23.977901  5145 net.cpp:693] Ignoring source layer fake
I0429 03:48:19.980870  5145 solver.cpp:404]     Test net output #0: loss = 0.291371 (* 1 = 0.291371 loss)
I0429 03:48:20.292687  5145 solver.cpp:228] Iteration 54000, loss = 0.252242
I0429 03:48:20.292709  5145 solver.cpp:244]     Train net output #0: loss = 0.252242 (* 1 = 0.252242 loss)
I0429 03:48:20.292732  5145 sgd_solver.cpp:106] Iteration 54000, lr = 1e-09
I0429 03:49:10.907506  5145 solver.cpp:228] Iteration 54100, loss = 0.300715
I0429 03:49:10.907668  5145 solver.cpp:244]     Train net output #0: loss = 0.300715 (* 1 = 0.300715 loss)
I0429 03:49:10.907676  5145 sgd_solver.cpp:106] Iteration 54100, lr = 1e-09
I0429 03:50:01.455837  5145 solver.cpp:228] Iteration 54200, loss = 0.290684
I0429 03:50:01.456014  5145 solver.cpp:244]     Train net output #0: loss = 0.290684 (* 1 = 0.290684 loss)
I0429 03:50:01.456022  5145 sgd_solver.cpp:106] Iteration 54200, lr = 1e-09
I0429 03:50:53.844297  5145 solver.cpp:228] Iteration 54300, loss = 0.332718
I0429 03:50:53.844488  5145 solver.cpp:244]     Train net output #0: loss = 0.332718 (* 1 = 0.332718 loss)
I0429 03:50:53.844496  5145 sgd_solver.cpp:106] Iteration 54300, lr = 1e-09
I0429 03:51:44.388336  5145 solver.cpp:228] Iteration 54400, loss = 0.332252
I0429 03:51:44.388458  5145 solver.cpp:244]     Train net output #0: loss = 0.332252 (* 1 = 0.332252 loss)
I0429 03:51:44.388465  5145 sgd_solver.cpp:106] Iteration 54400, lr = 1e-09
I0429 03:52:35.082270  5145 solver.cpp:228] Iteration 54500, loss = 0.293134
I0429 03:52:35.082427  5145 solver.cpp:244]     Train net output #0: loss = 0.293134 (* 1 = 0.293134 loss)
I0429 03:52:35.082433  5145 sgd_solver.cpp:106] Iteration 54500, lr = 1e-09
I0429 03:53:27.553553  5145 solver.cpp:228] Iteration 54600, loss = 0.329177
I0429 03:53:27.553751  5145 solver.cpp:244]     Train net output #0: loss = 0.329177 (* 1 = 0.329177 loss)
I0429 03:53:27.553758  5145 sgd_solver.cpp:106] Iteration 54600, lr = 1e-09
I0429 03:54:17.911499  5145 solver.cpp:228] Iteration 54700, loss = 0.302619
I0429 03:54:17.911638  5145 solver.cpp:244]     Train net output #0: loss = 0.302619 (* 1 = 0.302619 loss)
I0429 03:54:17.911644  5145 sgd_solver.cpp:106] Iteration 54700, lr = 1e-09
I0429 03:55:08.325785  5145 solver.cpp:228] Iteration 54800, loss = 0.205906
I0429 03:55:08.325948  5145 solver.cpp:244]     Train net output #0: loss = 0.205906 (* 1 = 0.205906 loss)
I0429 03:55:08.325954  5145 sgd_solver.cpp:106] Iteration 54800, lr = 1e-09
I0429 03:55:58.752231  5145 solver.cpp:228] Iteration 54900, loss = 0.311259
I0429 03:55:58.752406  5145 solver.cpp:244]     Train net output #0: loss = 0.311259 (* 1 = 0.311259 loss)
I0429 03:55:58.752413  5145 sgd_solver.cpp:106] Iteration 54900, lr = 1e-09
I0429 03:56:50.745848  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_55000.caffemodel
I0429 03:57:13.930820  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_55000.solverstate
I0429 03:57:14.124689  5145 solver.cpp:337] Iteration 55000, Testing net (#0)
I0429 03:57:14.124788  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 03:57:14.124794  5145 net.cpp:693] Ignoring source layer visualize
I0429 03:57:14.124796  5145 net.cpp:693] Ignoring source layer fake
I0429 04:02:10.501533  5145 solver.cpp:404]     Test net output #0: loss = 0.286633 (* 1 = 0.286633 loss)
I0429 04:02:10.817613  5145 solver.cpp:228] Iteration 55000, loss = 0.311162
I0429 04:02:10.817656  5145 solver.cpp:244]     Train net output #0: loss = 0.311162 (* 1 = 0.311162 loss)
I0429 04:02:10.817663  5145 sgd_solver.cpp:106] Iteration 55000, lr = 1e-09
I0429 04:03:01.466857  5145 solver.cpp:228] Iteration 55100, loss = 0.237061
I0429 04:03:01.467021  5145 solver.cpp:244]     Train net output #0: loss = 0.237061 (* 1 = 0.237061 loss)
I0429 04:03:01.467028  5145 sgd_solver.cpp:106] Iteration 55100, lr = 1e-09
I0429 04:03:52.093268  5145 solver.cpp:228] Iteration 55200, loss = 0.267083
I0429 04:03:52.093428  5145 solver.cpp:244]     Train net output #0: loss = 0.267083 (* 1 = 0.267083 loss)
I0429 04:03:52.093446  5145 sgd_solver.cpp:106] Iteration 55200, lr = 1e-09
I0429 04:04:44.441669  5145 solver.cpp:228] Iteration 55300, loss = 0.191929
I0429 04:04:44.441810  5145 solver.cpp:244]     Train net output #0: loss = 0.191929 (* 1 = 0.191929 loss)
I0429 04:04:44.441818  5145 sgd_solver.cpp:106] Iteration 55300, lr = 1e-09
I0429 04:05:35.059589  5145 solver.cpp:228] Iteration 55400, loss = 0.288026
I0429 04:05:35.060806  5145 solver.cpp:244]     Train net output #0: loss = 0.288026 (* 1 = 0.288026 loss)
I0429 04:05:35.060827  5145 sgd_solver.cpp:106] Iteration 55400, lr = 1e-09
I0429 04:06:25.696347  5145 solver.cpp:228] Iteration 55500, loss = 0.216535
I0429 04:06:25.696521  5145 solver.cpp:244]     Train net output #0: loss = 0.216535 (* 1 = 0.216535 loss)
I0429 04:06:25.696528  5145 sgd_solver.cpp:106] Iteration 55500, lr = 1e-09
I0429 04:07:16.334874  5145 solver.cpp:228] Iteration 55600, loss = 0.204516
I0429 04:07:16.335063  5145 solver.cpp:244]     Train net output #0: loss = 0.204516 (* 1 = 0.204516 loss)
I0429 04:07:16.335070  5145 sgd_solver.cpp:106] Iteration 55600, lr = 1e-09
I0429 04:08:08.578608  5145 solver.cpp:228] Iteration 55700, loss = 0.178174
I0429 04:08:08.578804  5145 solver.cpp:244]     Train net output #0: loss = 0.178174 (* 1 = 0.178174 loss)
I0429 04:08:08.578812  5145 sgd_solver.cpp:106] Iteration 55700, lr = 1e-09
I0429 04:08:59.088685  5145 solver.cpp:228] Iteration 55800, loss = 0.15894
I0429 04:08:59.088840  5145 solver.cpp:244]     Train net output #0: loss = 0.15894 (* 1 = 0.15894 loss)
I0429 04:08:59.088847  5145 sgd_solver.cpp:106] Iteration 55800, lr = 1e-09
I0429 04:09:49.651895  5145 solver.cpp:228] Iteration 55900, loss = 0.202229
I0429 04:09:49.652078  5145 solver.cpp:244]     Train net output #0: loss = 0.202229 (* 1 = 0.202229 loss)
I0429 04:09:49.652086  5145 sgd_solver.cpp:106] Iteration 55900, lr = 1e-09
I0429 04:10:41.518548  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_56000.caffemodel
I0429 04:11:06.833752  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_56000.solverstate
I0429 04:11:07.022907  5145 solver.cpp:337] Iteration 56000, Testing net (#0)
I0429 04:11:07.022991  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 04:11:07.022994  5145 net.cpp:693] Ignoring source layer visualize
I0429 04:11:07.023013  5145 net.cpp:693] Ignoring source layer fake
I0429 04:16:05.341078  5145 solver.cpp:404]     Test net output #0: loss = 0.285816 (* 1 = 0.285816 loss)
I0429 04:16:05.652456  5145 solver.cpp:228] Iteration 56000, loss = 0.154832
I0429 04:16:05.652493  5145 solver.cpp:244]     Train net output #0: loss = 0.154832 (* 1 = 0.154832 loss)
I0429 04:16:05.652500  5145 sgd_solver.cpp:106] Iteration 56000, lr = 1e-09
I0429 04:16:56.327301  5145 solver.cpp:228] Iteration 56100, loss = 0.229376
I0429 04:16:56.327477  5145 solver.cpp:244]     Train net output #0: loss = 0.229376 (* 1 = 0.229376 loss)
I0429 04:16:56.327484  5145 sgd_solver.cpp:106] Iteration 56100, lr = 1e-09
I0429 04:17:46.919219  5145 solver.cpp:228] Iteration 56200, loss = 0.258085
I0429 04:17:46.919384  5145 solver.cpp:244]     Train net output #0: loss = 0.258085 (* 1 = 0.258085 loss)
I0429 04:17:46.919390  5145 sgd_solver.cpp:106] Iteration 56200, lr = 1e-09
I0429 04:18:38.628046  5145 solver.cpp:228] Iteration 56300, loss = 0.188679
I0429 04:18:38.628216  5145 solver.cpp:244]     Train net output #0: loss = 0.188679 (* 1 = 0.188679 loss)
I0429 04:18:38.628223  5145 sgd_solver.cpp:106] Iteration 56300, lr = 1e-09
I0429 04:19:29.357159  5145 solver.cpp:228] Iteration 56400, loss = 0.191136
I0429 04:19:29.357920  5145 solver.cpp:244]     Train net output #0: loss = 0.191136 (* 1 = 0.191136 loss)
I0429 04:19:29.357928  5145 sgd_solver.cpp:106] Iteration 56400, lr = 1e-09
I0429 04:20:21.163027  5145 solver.cpp:228] Iteration 56500, loss = 0.228527
I0429 04:20:21.163202  5145 solver.cpp:244]     Train net output #0: loss = 0.228527 (* 1 = 0.228527 loss)
I0429 04:20:21.163208  5145 sgd_solver.cpp:106] Iteration 56500, lr = 1e-09
I0429 04:21:11.652751  5145 solver.cpp:228] Iteration 56600, loss = 0.229845
I0429 04:21:11.652917  5145 solver.cpp:244]     Train net output #0: loss = 0.229845 (* 1 = 0.229845 loss)
I0429 04:21:11.652925  5145 sgd_solver.cpp:106] Iteration 56600, lr = 1e-09
I0429 04:22:02.204236  5145 solver.cpp:228] Iteration 56700, loss = 0.30931
I0429 04:22:02.204396  5145 solver.cpp:244]     Train net output #0: loss = 0.30931 (* 1 = 0.30931 loss)
I0429 04:22:02.204402  5145 sgd_solver.cpp:106] Iteration 56700, lr = 1e-09
I0429 04:22:54.365885  5145 solver.cpp:228] Iteration 56800, loss = 0.326857
I0429 04:22:54.366063  5145 solver.cpp:244]     Train net output #0: loss = 0.326857 (* 1 = 0.326857 loss)
I0429 04:22:54.366071  5145 sgd_solver.cpp:106] Iteration 56800, lr = 1e-09
I0429 04:23:44.956547  5145 solver.cpp:228] Iteration 56900, loss = 0.364113
I0429 04:23:44.956754  5145 solver.cpp:244]     Train net output #0: loss = 0.364113 (* 1 = 0.364113 loss)
I0429 04:23:44.956763  5145 sgd_solver.cpp:106] Iteration 56900, lr = 1e-09
I0429 04:24:35.175153  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_57000.caffemodel
I0429 04:24:56.375233  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_57000.solverstate
I0429 04:24:56.566617  5145 solver.cpp:337] Iteration 57000, Testing net (#0)
I0429 04:24:56.566718  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 04:24:56.566725  5145 net.cpp:693] Ignoring source layer visualize
I0429 04:24:56.566726  5145 net.cpp:693] Ignoring source layer fake
I0429 04:29:53.007442  5145 solver.cpp:404]     Test net output #0: loss = 0.280825 (* 1 = 0.280825 loss)
I0429 04:29:53.330538  5145 solver.cpp:228] Iteration 57000, loss = 0.367468
I0429 04:29:53.330576  5145 solver.cpp:244]     Train net output #0: loss = 0.367468 (* 1 = 0.367468 loss)
I0429 04:29:53.330582  5145 sgd_solver.cpp:106] Iteration 57000, lr = 1e-09
I0429 04:30:45.726019  5145 solver.cpp:228] Iteration 57100, loss = 0.231947
I0429 04:30:45.726789  5145 solver.cpp:244]     Train net output #0: loss = 0.231947 (* 1 = 0.231947 loss)
I0429 04:30:45.726799  5145 sgd_solver.cpp:106] Iteration 57100, lr = 1e-09
I0429 04:31:36.264281  5145 solver.cpp:228] Iteration 57200, loss = 0.167448
I0429 04:31:36.264443  5145 solver.cpp:244]     Train net output #0: loss = 0.167448 (* 1 = 0.167448 loss)
I0429 04:31:36.264451  5145 sgd_solver.cpp:106] Iteration 57200, lr = 1e-09
I0429 04:32:26.908939  5145 solver.cpp:228] Iteration 57300, loss = 0.330002
I0429 04:32:26.909404  5145 solver.cpp:244]     Train net output #0: loss = 0.330002 (* 1 = 0.330002 loss)
I0429 04:32:26.909410  5145 sgd_solver.cpp:106] Iteration 57300, lr = 1e-09
I0429 04:33:19.418836  5145 solver.cpp:228] Iteration 57400, loss = 0.309515
I0429 04:33:19.420879  5145 solver.cpp:244]     Train net output #0: loss = 0.309515 (* 1 = 0.309515 loss)
I0429 04:33:19.420886  5145 sgd_solver.cpp:106] Iteration 57400, lr = 1e-09
I0429 04:34:09.883669  5145 solver.cpp:228] Iteration 57500, loss = 0.211235
I0429 04:34:09.884914  5145 solver.cpp:244]     Train net output #0: loss = 0.211235 (* 1 = 0.211235 loss)
I0429 04:34:09.884922  5145 sgd_solver.cpp:106] Iteration 57500, lr = 1e-09
I0429 04:35:00.484266  5145 solver.cpp:228] Iteration 57600, loss = 0.227272
I0429 04:35:00.484436  5145 solver.cpp:244]     Train net output #0: loss = 0.227272 (* 1 = 0.227272 loss)
I0429 04:35:00.484447  5145 sgd_solver.cpp:106] Iteration 57600, lr = 1e-09
I0429 04:35:51.033291  5145 solver.cpp:228] Iteration 57700, loss = 0.211907
I0429 04:35:51.033480  5145 solver.cpp:244]     Train net output #0: loss = 0.211907 (* 1 = 0.211907 loss)
I0429 04:35:51.033488  5145 sgd_solver.cpp:106] Iteration 57700, lr = 1e-09
I0429 04:36:43.402623  5145 solver.cpp:228] Iteration 57800, loss = 0.39707
I0429 04:36:43.402793  5145 solver.cpp:244]     Train net output #0: loss = 0.39707 (* 1 = 0.39707 loss)
I0429 04:36:43.402803  5145 sgd_solver.cpp:106] Iteration 57800, lr = 1e-09
I0429 04:37:33.869077  5145 solver.cpp:228] Iteration 57900, loss = 0.37676
I0429 04:37:33.869258  5145 solver.cpp:244]     Train net output #0: loss = 0.37676 (* 1 = 0.37676 loss)
I0429 04:37:33.869266  5145 sgd_solver.cpp:106] Iteration 57900, lr = 1e-09
I0429 04:38:24.044091  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_58000.caffemodel
I0429 04:38:58.787483  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_58000.solverstate
I0429 04:38:59.000473  5145 solver.cpp:337] Iteration 58000, Testing net (#0)
I0429 04:38:59.000545  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 04:38:59.000548  5145 net.cpp:693] Ignoring source layer visualize
I0429 04:38:59.000550  5145 net.cpp:693] Ignoring source layer fake
I0429 04:43:55.513914  5145 solver.cpp:404]     Test net output #0: loss = 0.282986 (* 1 = 0.282986 loss)
I0429 04:43:55.833536  5145 solver.cpp:228] Iteration 58000, loss = 0.413228
I0429 04:43:55.833573  5145 solver.cpp:244]     Train net output #0: loss = 0.413228 (* 1 = 0.413228 loss)
I0429 04:43:55.833580  5145 sgd_solver.cpp:106] Iteration 58000, lr = 1e-09
I0429 04:44:48.278719  5145 solver.cpp:228] Iteration 58100, loss = 0.234206
I0429 04:44:48.278910  5145 solver.cpp:244]     Train net output #0: loss = 0.234206 (* 1 = 0.234206 loss)
I0429 04:44:48.278921  5145 sgd_solver.cpp:106] Iteration 58100, lr = 1e-09
I0429 04:45:38.884439  5145 solver.cpp:228] Iteration 58200, loss = 0.211854
I0429 04:45:38.884608  5145 solver.cpp:244]     Train net output #0: loss = 0.211854 (* 1 = 0.211854 loss)
I0429 04:45:38.884616  5145 sgd_solver.cpp:106] Iteration 58200, lr = 1e-09
I0429 04:46:29.581588  5145 solver.cpp:228] Iteration 58300, loss = 0.258466
I0429 04:46:29.581748  5145 solver.cpp:244]     Train net output #0: loss = 0.258466 (* 1 = 0.258466 loss)
I0429 04:46:29.581754  5145 sgd_solver.cpp:106] Iteration 58300, lr = 1e-09
I0429 04:47:22.068359  5145 solver.cpp:228] Iteration 58400, loss = 0.244749
I0429 04:47:22.068526  5145 solver.cpp:244]     Train net output #0: loss = 0.244749 (* 1 = 0.244749 loss)
I0429 04:47:22.068532  5145 sgd_solver.cpp:106] Iteration 58400, lr = 1e-09
I0429 04:48:12.481307  5145 solver.cpp:228] Iteration 58500, loss = 0.15093
I0429 04:48:12.481451  5145 solver.cpp:244]     Train net output #0: loss = 0.15093 (* 1 = 0.15093 loss)
I0429 04:48:12.481458  5145 sgd_solver.cpp:106] Iteration 58500, lr = 1e-09
I0429 04:49:02.992887  5145 solver.cpp:228] Iteration 58600, loss = 0.282823
I0429 04:49:02.993055  5145 solver.cpp:244]     Train net output #0: loss = 0.282823 (* 1 = 0.282823 loss)
I0429 04:49:02.993062  5145 sgd_solver.cpp:106] Iteration 58600, lr = 1e-09
I0429 04:49:53.574862  5145 solver.cpp:228] Iteration 58700, loss = 0.234131
I0429 04:49:53.575037  5145 solver.cpp:244]     Train net output #0: loss = 0.234131 (* 1 = 0.234131 loss)
I0429 04:49:53.575043  5145 sgd_solver.cpp:106] Iteration 58700, lr = 1e-09
I0429 04:50:45.813189  5145 solver.cpp:228] Iteration 58800, loss = 0.300881
I0429 04:50:45.813369  5145 solver.cpp:244]     Train net output #0: loss = 0.300881 (* 1 = 0.300881 loss)
I0429 04:50:45.813376  5145 sgd_solver.cpp:106] Iteration 58800, lr = 1e-09
I0429 04:51:36.368705  5145 solver.cpp:228] Iteration 58900, loss = 0.238484
I0429 04:51:36.368863  5145 solver.cpp:244]     Train net output #0: loss = 0.238484 (* 1 = 0.238484 loss)
I0429 04:51:36.368870  5145 sgd_solver.cpp:106] Iteration 58900, lr = 1e-09
I0429 04:52:26.640041  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_59000.caffemodel
I0429 04:52:34.779291  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_59000.solverstate
I0429 04:52:34.978286  5145 solver.cpp:337] Iteration 59000, Testing net (#0)
I0429 04:52:34.978369  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 04:52:34.978373  5145 net.cpp:693] Ignoring source layer visualize
I0429 04:52:34.978374  5145 net.cpp:693] Ignoring source layer fake
I0429 04:57:33.411950  5145 solver.cpp:404]     Test net output #0: loss = 0.291354 (* 1 = 0.291354 loss)
I0429 04:57:33.724196  5145 solver.cpp:228] Iteration 59000, loss = 0.240152
I0429 04:57:33.724217  5145 solver.cpp:244]     Train net output #0: loss = 0.240152 (* 1 = 0.240152 loss)
I0429 04:57:33.724239  5145 sgd_solver.cpp:106] Iteration 59000, lr = 1e-09
I0429 04:58:25.880435  5145 solver.cpp:228] Iteration 59100, loss = 0.24648
I0429 04:58:25.880605  5145 solver.cpp:244]     Train net output #0: loss = 0.24648 (* 1 = 0.24648 loss)
I0429 04:58:25.880614  5145 sgd_solver.cpp:106] Iteration 59100, lr = 1e-09
I0429 04:59:16.452406  5145 solver.cpp:228] Iteration 59200, loss = 0.314787
I0429 04:59:16.452571  5145 solver.cpp:244]     Train net output #0: loss = 0.314787 (* 1 = 0.314787 loss)
I0429 04:59:16.452579  5145 sgd_solver.cpp:106] Iteration 59200, lr = 1e-09
I0429 05:00:06.979854  5145 solver.cpp:228] Iteration 59300, loss = 0.20997
I0429 05:00:06.980020  5145 solver.cpp:244]     Train net output #0: loss = 0.20997 (* 1 = 0.20997 loss)
I0429 05:00:06.980031  5145 sgd_solver.cpp:106] Iteration 59300, lr = 1e-09
I0429 05:00:58.770406  5145 solver.cpp:228] Iteration 59400, loss = 0.140329
I0429 05:00:58.770571  5145 solver.cpp:244]     Train net output #0: loss = 0.140329 (* 1 = 0.140329 loss)
I0429 05:00:58.770578  5145 sgd_solver.cpp:106] Iteration 59400, lr = 1e-09
I0429 05:01:49.160068  5145 solver.cpp:228] Iteration 59500, loss = 0.131731
I0429 05:01:49.160231  5145 solver.cpp:244]     Train net output #0: loss = 0.131731 (* 1 = 0.131731 loss)
I0429 05:01:49.160238  5145 sgd_solver.cpp:106] Iteration 59500, lr = 1e-09
I0429 05:02:39.684254  5145 solver.cpp:228] Iteration 59600, loss = 0.23315
I0429 05:02:39.684417  5145 solver.cpp:244]     Train net output #0: loss = 0.23315 (* 1 = 0.23315 loss)
I0429 05:02:39.684425  5145 sgd_solver.cpp:106] Iteration 59600, lr = 1e-09
I0429 05:03:31.476910  5145 solver.cpp:228] Iteration 59700, loss = 0.293554
I0429 05:03:31.477089  5145 solver.cpp:244]     Train net output #0: loss = 0.293554 (* 1 = 0.293554 loss)
I0429 05:03:31.477100  5145 sgd_solver.cpp:106] Iteration 59700, lr = 1e-09
I0429 05:04:22.011739  5145 solver.cpp:228] Iteration 59800, loss = 0.230543
I0429 05:04:22.011903  5145 solver.cpp:244]     Train net output #0: loss = 0.230543 (* 1 = 0.230543 loss)
I0429 05:04:22.011909  5145 sgd_solver.cpp:106] Iteration 59800, lr = 1e-09
I0429 05:05:14.109791  5145 solver.cpp:228] Iteration 59900, loss = 0.408606
I0429 05:05:14.109937  5145 solver.cpp:244]     Train net output #0: loss = 0.408606 (* 1 = 0.408606 loss)
I0429 05:05:14.109944  5145 sgd_solver.cpp:106] Iteration 59900, lr = 1e-09
I0429 05:06:04.343703  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_60000.caffemodel
I0429 05:06:18.775782  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_60000.solverstate
I0429 05:06:18.985885  5145 solver.cpp:337] Iteration 60000, Testing net (#0)
I0429 05:06:18.985954  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 05:06:18.985957  5145 net.cpp:693] Ignoring source layer visualize
I0429 05:06:18.985960  5145 net.cpp:693] Ignoring source layer fake
I0429 05:11:15.330323  5145 solver.cpp:404]     Test net output #0: loss = 0.286509 (* 1 = 0.286509 loss)
I0429 05:11:15.641549  5145 solver.cpp:228] Iteration 60000, loss = 0.306118
I0429 05:11:15.641566  5145 solver.cpp:244]     Train net output #0: loss = 0.306118 (* 1 = 0.306118 loss)
I0429 05:11:15.641589  5145 sgd_solver.cpp:106] Iteration 60000, lr = 1e-10
I0429 05:12:06.259970  5145 solver.cpp:228] Iteration 60100, loss = 0.302473
I0429 05:12:06.260131  5145 solver.cpp:244]     Train net output #0: loss = 0.302473 (* 1 = 0.302473 loss)
I0429 05:12:06.260138  5145 sgd_solver.cpp:106] Iteration 60100, lr = 1e-10
I0429 05:12:58.546918  5145 solver.cpp:228] Iteration 60200, loss = 0.331942
I0429 05:12:58.547088  5145 solver.cpp:244]     Train net output #0: loss = 0.331942 (* 1 = 0.331942 loss)
I0429 05:12:58.547096  5145 sgd_solver.cpp:106] Iteration 60200, lr = 1e-10
I0429 05:13:49.033205  5145 solver.cpp:228] Iteration 60300, loss = 0.312961
I0429 05:13:49.033365  5145 solver.cpp:244]     Train net output #0: loss = 0.312961 (* 1 = 0.312961 loss)
I0429 05:13:49.033372  5145 sgd_solver.cpp:106] Iteration 60300, lr = 1e-10
I0429 05:14:39.559350  5145 solver.cpp:228] Iteration 60400, loss = 0.315047
I0429 05:14:39.559515  5145 solver.cpp:244]     Train net output #0: loss = 0.315047 (* 1 = 0.315047 loss)
I0429 05:14:39.559523  5145 sgd_solver.cpp:106] Iteration 60400, lr = 1e-10
I0429 05:15:31.892873  5145 solver.cpp:228] Iteration 60500, loss = 0.297035
I0429 05:15:31.893030  5145 solver.cpp:244]     Train net output #0: loss = 0.297035 (* 1 = 0.297035 loss)
I0429 05:15:31.893036  5145 sgd_solver.cpp:106] Iteration 60500, lr = 1e-10
I0429 05:16:22.347519  5145 solver.cpp:228] Iteration 60600, loss = 0.276291
I0429 05:16:22.347681  5145 solver.cpp:244]     Train net output #0: loss = 0.276291 (* 1 = 0.276291 loss)
I0429 05:16:22.347689  5145 sgd_solver.cpp:106] Iteration 60600, lr = 1e-10
I0429 05:17:12.956158  5145 solver.cpp:228] Iteration 60700, loss = 0.286616
I0429 05:17:12.956308  5145 solver.cpp:244]     Train net output #0: loss = 0.286616 (* 1 = 0.286616 loss)
I0429 05:17:12.956315  5145 sgd_solver.cpp:106] Iteration 60700, lr = 1e-10
I0429 05:18:03.440788  5145 solver.cpp:228] Iteration 60800, loss = 0.318869
I0429 05:18:03.440933  5145 solver.cpp:244]     Train net output #0: loss = 0.318869 (* 1 = 0.318869 loss)
I0429 05:18:03.440940  5145 sgd_solver.cpp:106] Iteration 60800, lr = 1e-10
I0429 05:18:55.635789  5145 solver.cpp:228] Iteration 60900, loss = 0.296252
I0429 05:18:55.635947  5145 solver.cpp:244]     Train net output #0: loss = 0.296252 (* 1 = 0.296252 loss)
I0429 05:18:55.635954  5145 sgd_solver.cpp:106] Iteration 60900, lr = 1e-10
I0429 05:19:45.961030  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_61000.caffemodel
I0429 05:19:52.270584  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_61000.solverstate
I0429 05:19:52.463416  5145 solver.cpp:337] Iteration 61000, Testing net (#0)
I0429 05:19:52.463515  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 05:19:52.463521  5145 net.cpp:693] Ignoring source layer visualize
I0429 05:19:52.463522  5145 net.cpp:693] Ignoring source layer fake
I0429 05:24:48.864378  5145 solver.cpp:404]     Test net output #0: loss = 0.285654 (* 1 = 0.285654 loss)
I0429 05:24:49.177883  5145 solver.cpp:228] Iteration 61000, loss = 0.289423
I0429 05:24:49.177916  5145 solver.cpp:244]     Train net output #0: loss = 0.289423 (* 1 = 0.289423 loss)
I0429 05:24:49.177929  5145 sgd_solver.cpp:106] Iteration 61000, lr = 1e-10
I0429 05:25:39.815702  5145 solver.cpp:228] Iteration 61100, loss = 0.42268
I0429 05:25:39.815877  5145 solver.cpp:244]     Train net output #0: loss = 0.42268 (* 1 = 0.42268 loss)
I0429 05:25:39.815886  5145 sgd_solver.cpp:106] Iteration 61100, lr = 1e-10
I0429 05:26:32.103070  5145 solver.cpp:228] Iteration 61200, loss = 0.238571
I0429 05:26:32.103233  5145 solver.cpp:244]     Train net output #0: loss = 0.238571 (* 1 = 0.238571 loss)
I0429 05:26:32.103241  5145 sgd_solver.cpp:106] Iteration 61200, lr = 1e-10
I0429 05:27:22.642410  5145 solver.cpp:228] Iteration 61300, loss = 0.375939
I0429 05:27:22.642587  5145 solver.cpp:244]     Train net output #0: loss = 0.375939 (* 1 = 0.375939 loss)
I0429 05:27:22.642594  5145 sgd_solver.cpp:106] Iteration 61300, lr = 1e-10
I0429 05:28:13.196019  5145 solver.cpp:228] Iteration 61400, loss = 0.328038
I0429 05:28:13.196194  5145 solver.cpp:244]     Train net output #0: loss = 0.328038 (* 1 = 0.328038 loss)
I0429 05:28:13.196202  5145 sgd_solver.cpp:106] Iteration 61400, lr = 1e-10
I0429 05:29:03.712709  5145 solver.cpp:228] Iteration 61500, loss = 0.18894
I0429 05:29:03.712896  5145 solver.cpp:244]     Train net output #0: loss = 0.18894 (* 1 = 0.18894 loss)
I0429 05:29:03.712903  5145 sgd_solver.cpp:106] Iteration 61500, lr = 1e-10
I0429 05:29:55.974288  5145 solver.cpp:228] Iteration 61600, loss = 0.275374
I0429 05:29:55.974442  5145 solver.cpp:244]     Train net output #0: loss = 0.275374 (* 1 = 0.275374 loss)
I0429 05:29:55.974449  5145 sgd_solver.cpp:106] Iteration 61600, lr = 1e-10
I0429 05:30:46.528378  5145 solver.cpp:228] Iteration 61700, loss = 0.179985
I0429 05:30:46.528564  5145 solver.cpp:244]     Train net output #0: loss = 0.179985 (* 1 = 0.179985 loss)
I0429 05:30:46.528571  5145 sgd_solver.cpp:106] Iteration 61700, lr = 1e-10
I0429 05:31:37.114150  5145 solver.cpp:228] Iteration 61800, loss = 0.16791
I0429 05:31:37.114325  5145 solver.cpp:244]     Train net output #0: loss = 0.16791 (* 1 = 0.16791 loss)
I0429 05:31:37.114332  5145 sgd_solver.cpp:106] Iteration 61800, lr = 1e-10
I0429 05:32:29.476145  5145 solver.cpp:228] Iteration 61900, loss = 0.122048
I0429 05:32:29.476313  5145 solver.cpp:244]     Train net output #0: loss = 0.122048 (* 1 = 0.122048 loss)
I0429 05:32:29.476320  5145 sgd_solver.cpp:106] Iteration 61900, lr = 1e-10
I0429 05:33:19.696357  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_62000.caffemodel
I0429 05:33:54.146731  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_62000.solverstate
I0429 05:33:54.338737  5145 solver.cpp:337] Iteration 62000, Testing net (#0)
I0429 05:33:54.338837  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 05:33:54.338843  5145 net.cpp:693] Ignoring source layer visualize
I0429 05:33:54.338845  5145 net.cpp:693] Ignoring source layer fake
I0429 05:38:50.936444  5145 solver.cpp:404]     Test net output #0: loss = 0.28033 (* 1 = 0.28033 loss)
I0429 05:38:51.254598  5145 solver.cpp:228] Iteration 62000, loss = 0.348619
I0429 05:38:51.254638  5145 solver.cpp:244]     Train net output #0: loss = 0.348619 (* 1 = 0.348619 loss)
I0429 05:38:51.254644  5145 sgd_solver.cpp:106] Iteration 62000, lr = 1e-10
I0429 05:39:41.949175  5145 solver.cpp:228] Iteration 62100, loss = 0.295081
I0429 05:39:41.949339  5145 solver.cpp:244]     Train net output #0: loss = 0.295081 (* 1 = 0.295081 loss)
I0429 05:39:41.949347  5145 sgd_solver.cpp:106] Iteration 62100, lr = 1e-10
I0429 05:40:34.268357  5145 solver.cpp:228] Iteration 62200, loss = 0.191102
I0429 05:40:34.268518  5145 solver.cpp:244]     Train net output #0: loss = 0.191102 (* 1 = 0.191102 loss)
I0429 05:40:34.268527  5145 sgd_solver.cpp:106] Iteration 62200, lr = 1e-10
I0429 05:41:24.602910  5145 solver.cpp:228] Iteration 62300, loss = 0.279005
I0429 05:41:24.603071  5145 solver.cpp:244]     Train net output #0: loss = 0.279005 (* 1 = 0.279005 loss)
I0429 05:41:24.603078  5145 sgd_solver.cpp:106] Iteration 62300, lr = 1e-10
I0429 05:42:15.134464  5145 solver.cpp:228] Iteration 62400, loss = 0.290702
I0429 05:42:15.134629  5145 solver.cpp:244]     Train net output #0: loss = 0.290702 (* 1 = 0.290702 loss)
I0429 05:42:15.134634  5145 sgd_solver.cpp:106] Iteration 62400, lr = 1e-10
I0429 05:43:06.745241  5145 solver.cpp:228] Iteration 62500, loss = 0.276542
I0429 05:43:06.745405  5145 solver.cpp:244]     Train net output #0: loss = 0.276542 (* 1 = 0.276542 loss)
I0429 05:43:06.745412  5145 sgd_solver.cpp:106] Iteration 62500, lr = 1e-10
I0429 05:43:57.234335  5145 solver.cpp:228] Iteration 62600, loss = 0.209842
I0429 05:43:57.234778  5145 solver.cpp:244]     Train net output #0: loss = 0.209842 (* 1 = 0.209842 loss)
I0429 05:43:57.234803  5145 sgd_solver.cpp:106] Iteration 62600, lr = 1e-10
I0429 05:44:47.727700  5145 solver.cpp:228] Iteration 62700, loss = 0.224998
I0429 05:44:47.727864  5145 solver.cpp:244]     Train net output #0: loss = 0.224998 (* 1 = 0.224998 loss)
I0429 05:44:47.727869  5145 sgd_solver.cpp:106] Iteration 62700, lr = 1e-10
I0429 05:45:39.594795  5145 solver.cpp:228] Iteration 62800, loss = 0.305091
I0429 05:45:39.594928  5145 solver.cpp:244]     Train net output #0: loss = 0.305091 (* 1 = 0.305091 loss)
I0429 05:45:39.594935  5145 sgd_solver.cpp:106] Iteration 62800, lr = 1e-10
I0429 05:46:30.181957  5145 solver.cpp:228] Iteration 62900, loss = 0.291646
I0429 05:46:30.182129  5145 solver.cpp:244]     Train net output #0: loss = 0.291646 (* 1 = 0.291646 loss)
I0429 05:46:30.182135  5145 sgd_solver.cpp:106] Iteration 62900, lr = 1e-10
I0429 05:47:21.984130  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_63000.caffemodel
I0429 05:47:32.330471  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_63000.solverstate
I0429 05:47:32.525058  5145 solver.cpp:337] Iteration 63000, Testing net (#0)
I0429 05:47:32.525157  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 05:47:32.525163  5145 net.cpp:693] Ignoring source layer visualize
I0429 05:47:32.525166  5145 net.cpp:693] Ignoring source layer fake
I0429 05:52:29.110648  5145 solver.cpp:404]     Test net output #0: loss = 0.283445 (* 1 = 0.283445 loss)
I0429 05:52:29.421691  5145 solver.cpp:228] Iteration 63000, loss = 0.382377
I0429 05:52:29.421710  5145 solver.cpp:244]     Train net output #0: loss = 0.382377 (* 1 = 0.382377 loss)
I0429 05:52:29.421732  5145 sgd_solver.cpp:106] Iteration 63000, lr = 1e-10
I0429 05:53:20.149153  5145 solver.cpp:228] Iteration 63100, loss = 0.292947
I0429 05:53:20.149333  5145 solver.cpp:244]     Train net output #0: loss = 0.292947 (* 1 = 0.292947 loss)
I0429 05:53:20.149340  5145 sgd_solver.cpp:106] Iteration 63100, lr = 1e-10
I0429 05:54:10.665839  5145 solver.cpp:228] Iteration 63200, loss = 0.283702
I0429 05:54:10.666013  5145 solver.cpp:244]     Train net output #0: loss = 0.283702 (* 1 = 0.283702 loss)
I0429 05:54:10.666019  5145 sgd_solver.cpp:106] Iteration 63200, lr = 1e-10
I0429 05:55:02.853790  5145 solver.cpp:228] Iteration 63300, loss = 0.363451
I0429 05:55:02.853981  5145 solver.cpp:244]     Train net output #0: loss = 0.363451 (* 1 = 0.363451 loss)
I0429 05:55:02.853988  5145 sgd_solver.cpp:106] Iteration 63300, lr = 1e-10
I0429 05:55:53.267909  5145 solver.cpp:228] Iteration 63400, loss = 0.245774
I0429 05:55:53.268079  5145 solver.cpp:244]     Train net output #0: loss = 0.245774 (* 1 = 0.245774 loss)
I0429 05:55:53.268085  5145 sgd_solver.cpp:106] Iteration 63400, lr = 1e-10
I0429 05:56:43.731767  5145 solver.cpp:228] Iteration 63500, loss = 0.201232
I0429 05:56:43.731933  5145 solver.cpp:244]     Train net output #0: loss = 0.201232 (* 1 = 0.201232 loss)
I0429 05:56:43.731940  5145 sgd_solver.cpp:106] Iteration 63500, lr = 1e-10
I0429 05:57:34.303685  5145 solver.cpp:228] Iteration 63600, loss = 0.207406
I0429 05:57:34.303853  5145 solver.cpp:244]     Train net output #0: loss = 0.207406 (* 1 = 0.207406 loss)
I0429 05:57:34.303860  5145 sgd_solver.cpp:106] Iteration 63600, lr = 1e-10
I0429 05:58:26.483711  5145 solver.cpp:228] Iteration 63700, loss = 0.260655
I0429 05:58:26.483878  5145 solver.cpp:244]     Train net output #0: loss = 0.260655 (* 1 = 0.260655 loss)
I0429 05:58:26.483886  5145 sgd_solver.cpp:106] Iteration 63700, lr = 1e-10
I0429 05:59:17.112082  5145 solver.cpp:228] Iteration 63800, loss = 0.154049
I0429 05:59:17.112246  5145 solver.cpp:244]     Train net output #0: loss = 0.154049 (* 1 = 0.154049 loss)
I0429 05:59:17.112253  5145 sgd_solver.cpp:106] Iteration 63800, lr = 1e-10
I0429 06:00:07.627769  5145 solver.cpp:228] Iteration 63900, loss = 0.286392
I0429 06:00:07.627943  5145 solver.cpp:244]     Train net output #0: loss = 0.286392 (* 1 = 0.286392 loss)
I0429 06:00:07.627950  5145 sgd_solver.cpp:106] Iteration 63900, lr = 1e-10
I0429 06:00:59.761126  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_64000.caffemodel
I0429 06:01:23.602026  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_64000.solverstate
I0429 06:01:23.807366  5145 solver.cpp:337] Iteration 64000, Testing net (#0)
I0429 06:01:23.807452  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 06:01:23.807456  5145 net.cpp:693] Ignoring source layer visualize
I0429 06:01:23.807474  5145 net.cpp:693] Ignoring source layer fake
I0429 06:06:21.049218  5145 solver.cpp:404]     Test net output #0: loss = 0.291307 (* 1 = 0.291307 loss)
I0429 06:06:21.364660  5145 solver.cpp:228] Iteration 64000, loss = 0.208666
I0429 06:06:21.364679  5145 solver.cpp:244]     Train net output #0: loss = 0.208666 (* 1 = 0.208666 loss)
I0429 06:06:21.364701  5145 sgd_solver.cpp:106] Iteration 64000, lr = 1e-10
I0429 06:07:12.050360  5145 solver.cpp:228] Iteration 64100, loss = 0.341388
I0429 06:07:12.050534  5145 solver.cpp:244]     Train net output #0: loss = 0.341388 (* 1 = 0.341388 loss)
I0429 06:07:12.050540  5145 sgd_solver.cpp:106] Iteration 64100, lr = 1e-10
I0429 06:08:02.649286  5145 solver.cpp:228] Iteration 64200, loss = 0.375157
I0429 06:08:02.649514  5145 solver.cpp:244]     Train net output #0: loss = 0.375157 (* 1 = 0.375157 loss)
I0429 06:08:02.649526  5145 sgd_solver.cpp:106] Iteration 64200, lr = 1e-10
I0429 06:08:52.911550  5145 solver.cpp:228] Iteration 64300, loss = 0.408908
I0429 06:08:52.911746  5145 solver.cpp:244]     Train net output #0: loss = 0.408908 (* 1 = 0.408908 loss)
I0429 06:08:52.911753  5145 sgd_solver.cpp:106] Iteration 64300, lr = 1e-10
I0429 06:09:44.945277  5145 solver.cpp:228] Iteration 64400, loss = 0.246091
I0429 06:09:44.945658  5145 solver.cpp:244]     Train net output #0: loss = 0.246091 (* 1 = 0.246091 loss)
I0429 06:09:44.945667  5145 sgd_solver.cpp:106] Iteration 64400, lr = 1e-10
I0429 06:10:35.251438  5145 solver.cpp:228] Iteration 64500, loss = 0.191302
I0429 06:10:35.251606  5145 solver.cpp:244]     Train net output #0: loss = 0.191302 (* 1 = 0.191302 loss)
I0429 06:10:35.251615  5145 sgd_solver.cpp:106] Iteration 64500, lr = 1e-10
I0429 06:11:25.625761  5145 solver.cpp:228] Iteration 64600, loss = 0.136058
I0429 06:11:25.625952  5145 solver.cpp:244]     Train net output #0: loss = 0.136058 (* 1 = 0.136058 loss)
I0429 06:11:25.625959  5145 sgd_solver.cpp:106] Iteration 64600, lr = 1e-10
I0429 06:12:17.755153  5145 solver.cpp:228] Iteration 64700, loss = 0.245347
I0429 06:12:17.755309  5145 solver.cpp:244]     Train net output #0: loss = 0.245347 (* 1 = 0.245347 loss)
I0429 06:12:17.755316  5145 sgd_solver.cpp:106] Iteration 64700, lr = 1e-10
I0429 06:13:08.329882  5145 solver.cpp:228] Iteration 64800, loss = 0.179938
I0429 06:13:08.330059  5145 solver.cpp:244]     Train net output #0: loss = 0.179938 (* 1 = 0.179938 loss)
I0429 06:13:08.330065  5145 sgd_solver.cpp:106] Iteration 64800, lr = 1e-10
I0429 06:13:58.742668  5145 solver.cpp:228] Iteration 64900, loss = 0.2135
I0429 06:13:58.742835  5145 solver.cpp:244]     Train net output #0: loss = 0.2135 (* 1 = 0.2135 loss)
I0429 06:13:58.742842  5145 sgd_solver.cpp:106] Iteration 64900, lr = 1e-10
I0429 06:14:50.778403  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_65000.caffemodel
I0429 06:15:19.259445  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_65000.solverstate
I0429 06:15:19.454123  5145 solver.cpp:337] Iteration 65000, Testing net (#0)
I0429 06:15:19.454205  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 06:15:19.454210  5145 net.cpp:693] Ignoring source layer visualize
I0429 06:15:19.454212  5145 net.cpp:693] Ignoring source layer fake
I0429 06:20:15.807121  5145 solver.cpp:404]     Test net output #0: loss = 0.286599 (* 1 = 0.286599 loss)
I0429 06:20:16.132333  5145 solver.cpp:228] Iteration 65000, loss = 0.0449194
I0429 06:20:16.132370  5145 solver.cpp:244]     Train net output #0: loss = 0.0449194 (* 1 = 0.0449194 loss)
I0429 06:20:16.132377  5145 sgd_solver.cpp:106] Iteration 65000, lr = 1e-10
I0429 06:21:06.740427  5145 solver.cpp:228] Iteration 65100, loss = 0.235386
I0429 06:21:06.740586  5145 solver.cpp:244]     Train net output #0: loss = 0.235386 (* 1 = 0.235386 loss)
I0429 06:21:06.740593  5145 sgd_solver.cpp:106] Iteration 65100, lr = 1e-10
I0429 06:21:57.283166  5145 solver.cpp:228] Iteration 65200, loss = 0.206751
I0429 06:21:57.283351  5145 solver.cpp:244]     Train net output #0: loss = 0.206751 (* 1 = 0.206751 loss)
I0429 06:21:57.283357  5145 sgd_solver.cpp:106] Iteration 65200, lr = 1e-10
I0429 06:22:47.840404  5145 solver.cpp:228] Iteration 65300, loss = 0.183764
I0429 06:22:47.840593  5145 solver.cpp:244]     Train net output #0: loss = 0.183764 (* 1 = 0.183764 loss)
I0429 06:22:47.840600  5145 sgd_solver.cpp:106] Iteration 65300, lr = 1e-10
I0429 06:23:39.795318  5145 solver.cpp:228] Iteration 65400, loss = 0.201488
I0429 06:23:39.795496  5145 solver.cpp:244]     Train net output #0: loss = 0.201488 (* 1 = 0.201488 loss)
I0429 06:23:39.795502  5145 sgd_solver.cpp:106] Iteration 65400, lr = 1e-10
I0429 06:24:30.337343  5145 solver.cpp:228] Iteration 65500, loss = 0.206511
I0429 06:24:30.337546  5145 solver.cpp:244]     Train net output #0: loss = 0.206511 (* 1 = 0.206511 loss)
I0429 06:24:30.337555  5145 sgd_solver.cpp:106] Iteration 65500, lr = 1e-10
I0429 06:25:20.879354  5145 solver.cpp:228] Iteration 65600, loss = 0.234836
I0429 06:25:20.879520  5145 solver.cpp:244]     Train net output #0: loss = 0.234836 (* 1 = 0.234836 loss)
I0429 06:25:20.879526  5145 sgd_solver.cpp:106] Iteration 65600, lr = 1e-10
I0429 06:26:12.525441  5145 solver.cpp:228] Iteration 65700, loss = 0.237753
I0429 06:26:12.525614  5145 solver.cpp:244]     Train net output #0: loss = 0.237753 (* 1 = 0.237753 loss)
I0429 06:26:12.525620  5145 sgd_solver.cpp:106] Iteration 65700, lr = 1e-10
I0429 06:27:03.149461  5145 solver.cpp:228] Iteration 65800, loss = 0.217131
I0429 06:27:03.149639  5145 solver.cpp:244]     Train net output #0: loss = 0.217131 (* 1 = 0.217131 loss)
I0429 06:27:03.149646  5145 sgd_solver.cpp:106] Iteration 65800, lr = 1e-10
I0429 06:27:54.949681  5145 solver.cpp:228] Iteration 65900, loss = 0.338546
I0429 06:27:54.949869  5145 solver.cpp:244]     Train net output #0: loss = 0.338546 (* 1 = 0.338546 loss)
I0429 06:27:54.949877  5145 sgd_solver.cpp:106] Iteration 65900, lr = 1e-10
I0429 06:28:45.140696  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_66000.caffemodel
I0429 06:28:48.499037  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_66000.solverstate
I0429 06:28:48.692003  5145 solver.cpp:337] Iteration 66000, Testing net (#0)
I0429 06:28:48.692102  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 06:28:48.692107  5145 net.cpp:693] Ignoring source layer visualize
I0429 06:28:48.692111  5145 net.cpp:693] Ignoring source layer fake
I0429 06:33:45.538656  5145 solver.cpp:404]     Test net output #0: loss = 0.285803 (* 1 = 0.285803 loss)
I0429 06:33:45.861486  5145 solver.cpp:228] Iteration 66000, loss = 0.281494
I0429 06:33:45.861505  5145 solver.cpp:244]     Train net output #0: loss = 0.281494 (* 1 = 0.281494 loss)
I0429 06:33:45.861526  5145 sgd_solver.cpp:106] Iteration 66000, lr = 1e-10
I0429 06:34:36.442360  5145 solver.cpp:228] Iteration 66100, loss = 0.117163
I0429 06:34:36.442524  5145 solver.cpp:244]     Train net output #0: loss = 0.117163 (* 1 = 0.117163 loss)
I0429 06:34:36.442533  5145 sgd_solver.cpp:106] Iteration 66100, lr = 1e-10
I0429 06:35:28.573173  5145 solver.cpp:228] Iteration 66200, loss = 0.263193
I0429 06:35:28.573328  5145 solver.cpp:244]     Train net output #0: loss = 0.263193 (* 1 = 0.263193 loss)
I0429 06:35:28.573335  5145 sgd_solver.cpp:106] Iteration 66200, lr = 1e-10
I0429 06:36:19.078183  5145 solver.cpp:228] Iteration 66300, loss = 0.19892
I0429 06:36:19.078352  5145 solver.cpp:244]     Train net output #0: loss = 0.19892 (* 1 = 0.19892 loss)
I0429 06:36:19.078361  5145 sgd_solver.cpp:106] Iteration 66300, lr = 1e-10
I0429 06:37:09.548032  5145 solver.cpp:228] Iteration 66400, loss = 0.407049
I0429 06:37:09.548207  5145 solver.cpp:244]     Train net output #0: loss = 0.407049 (* 1 = 0.407049 loss)
I0429 06:37:09.548214  5145 sgd_solver.cpp:106] Iteration 66400, lr = 1e-10
I0429 06:38:01.946786  5145 solver.cpp:228] Iteration 66500, loss = 0.27943
I0429 06:38:01.946966  5145 solver.cpp:244]     Train net output #0: loss = 0.27943 (* 1 = 0.27943 loss)
I0429 06:38:01.946974  5145 sgd_solver.cpp:106] Iteration 66500, lr = 1e-10
I0429 06:38:52.356647  5145 solver.cpp:228] Iteration 66600, loss = 0.331402
I0429 06:38:52.356815  5145 solver.cpp:244]     Train net output #0: loss = 0.331402 (* 1 = 0.331402 loss)
I0429 06:38:52.356822  5145 sgd_solver.cpp:106] Iteration 66600, lr = 1e-10
I0429 06:39:42.913386  5145 solver.cpp:228] Iteration 66700, loss = 0.227769
I0429 06:39:42.913560  5145 solver.cpp:244]     Train net output #0: loss = 0.227769 (* 1 = 0.227769 loss)
I0429 06:39:42.913566  5145 sgd_solver.cpp:106] Iteration 66700, lr = 1e-10
I0429 06:40:35.221679  5145 solver.cpp:228] Iteration 66800, loss = 0.329722
I0429 06:40:35.221797  5145 solver.cpp:244]     Train net output #0: loss = 0.329722 (* 1 = 0.329722 loss)
I0429 06:40:35.221803  5145 sgd_solver.cpp:106] Iteration 66800, lr = 1e-10
I0429 06:41:25.726866  5145 solver.cpp:228] Iteration 66900, loss = 0.199773
I0429 06:41:25.727023  5145 solver.cpp:244]     Train net output #0: loss = 0.199773 (* 1 = 0.199773 loss)
I0429 06:41:25.727030  5145 sgd_solver.cpp:106] Iteration 66900, lr = 1e-10
I0429 06:42:15.873913  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_67000.caffemodel
I0429 06:42:52.838584  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_67000.solverstate
I0429 06:42:53.169859  5145 solver.cpp:337] Iteration 67000, Testing net (#0)
I0429 06:42:53.170017  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 06:42:53.170027  5145 net.cpp:693] Ignoring source layer visualize
I0429 06:42:53.170032  5145 net.cpp:693] Ignoring source layer fake
I0429 06:47:48.704784  5145 solver.cpp:404]     Test net output #0: loss = 0.279895 (* 1 = 0.279895 loss)
I0429 06:47:49.016870  5145 solver.cpp:228] Iteration 67000, loss = 0.295428
I0429 06:47:49.016890  5145 solver.cpp:244]     Train net output #0: loss = 0.295428 (* 1 = 0.295428 loss)
I0429 06:47:49.016911  5145 sgd_solver.cpp:106] Iteration 67000, lr = 1e-10
I0429 06:48:42.001731  5145 solver.cpp:228] Iteration 67100, loss = 0.3392
I0429 06:48:42.001899  5145 solver.cpp:244]     Train net output #0: loss = 0.3392 (* 1 = 0.3392 loss)
I0429 06:48:42.001906  5145 sgd_solver.cpp:106] Iteration 67100, lr = 1e-10
I0429 06:49:32.446064  5145 solver.cpp:228] Iteration 67200, loss = 0.406753
I0429 06:49:32.446228  5145 solver.cpp:244]     Train net output #0: loss = 0.406753 (* 1 = 0.406753 loss)
I0429 06:49:32.446234  5145 sgd_solver.cpp:106] Iteration 67200, lr = 1e-10
I0429 06:50:22.991374  5145 solver.cpp:228] Iteration 67300, loss = 0.234772
I0429 06:50:22.991533  5145 solver.cpp:244]     Train net output #0: loss = 0.234772 (* 1 = 0.234772 loss)
I0429 06:50:22.991540  5145 sgd_solver.cpp:106] Iteration 67300, lr = 1e-10
I0429 06:51:13.528144  5145 solver.cpp:228] Iteration 67400, loss = 0.394828
I0429 06:51:13.528309  5145 solver.cpp:244]     Train net output #0: loss = 0.394828 (* 1 = 0.394828 loss)
I0429 06:51:13.528316  5145 sgd_solver.cpp:106] Iteration 67400, lr = 1e-10
I0429 06:52:05.851730  5145 solver.cpp:228] Iteration 67500, loss = 0.264306
I0429 06:52:05.851899  5145 solver.cpp:244]     Train net output #0: loss = 0.264306 (* 1 = 0.264306 loss)
I0429 06:52:05.851907  5145 sgd_solver.cpp:106] Iteration 67500, lr = 1e-11
I0429 06:52:56.360707  5145 solver.cpp:228] Iteration 67600, loss = 0.207534
I0429 06:52:56.360880  5145 solver.cpp:244]     Train net output #0: loss = 0.207534 (* 1 = 0.207534 loss)
I0429 06:52:56.360888  5145 sgd_solver.cpp:106] Iteration 67600, lr = 1e-11
I0429 06:53:47.052508  5145 solver.cpp:228] Iteration 67700, loss = 0.194967
I0429 06:53:47.052677  5145 solver.cpp:244]     Train net output #0: loss = 0.194967 (* 1 = 0.194967 loss)
I0429 06:53:47.052685  5145 sgd_solver.cpp:106] Iteration 67700, lr = 1e-11
I0429 06:54:39.332803  5145 solver.cpp:228] Iteration 67800, loss = 0.070159
I0429 06:54:39.332994  5145 solver.cpp:244]     Train net output #0: loss = 0.070159 (* 1 = 0.070159 loss)
I0429 06:54:39.333001  5145 sgd_solver.cpp:106] Iteration 67800, lr = 1e-11
I0429 06:55:29.879568  5145 solver.cpp:228] Iteration 67900, loss = 0.200487
I0429 06:55:29.879731  5145 solver.cpp:244]     Train net output #0: loss = 0.200487 (* 1 = 0.200487 loss)
I0429 06:55:29.879739  5145 sgd_solver.cpp:106] Iteration 67900, lr = 1e-11
I0429 06:56:20.151545  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_68000.caffemodel
I0429 06:56:32.464121  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_68000.solverstate
I0429 06:56:32.656766  5145 solver.cpp:337] Iteration 68000, Testing net (#0)
I0429 06:56:32.656848  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 06:56:32.656872  5145 net.cpp:693] Ignoring source layer visualize
I0429 06:56:32.656875  5145 net.cpp:693] Ignoring source layer fake
I0429 07:01:28.838765  5145 solver.cpp:404]     Test net output #0: loss = 0.28466 (* 1 = 0.28466 loss)
I0429 07:01:29.151594  5145 solver.cpp:228] Iteration 68000, loss = 0.230777
I0429 07:01:29.151612  5145 solver.cpp:244]     Train net output #0: loss = 0.230777 (* 1 = 0.230777 loss)
I0429 07:01:29.151635  5145 sgd_solver.cpp:106] Iteration 68000, lr = 1e-11
I0429 07:02:19.688834  5145 solver.cpp:228] Iteration 68100, loss = 0.372665
I0429 07:02:19.688995  5145 solver.cpp:244]     Train net output #0: loss = 0.372665 (* 1 = 0.372665 loss)
I0429 07:02:19.689002  5145 sgd_solver.cpp:106] Iteration 68100, lr = 1e-11
I0429 07:03:11.892802  5145 solver.cpp:228] Iteration 68200, loss = 0.199672
I0429 07:03:11.892976  5145 solver.cpp:244]     Train net output #0: loss = 0.199672 (* 1 = 0.199672 loss)
I0429 07:03:11.892982  5145 sgd_solver.cpp:106] Iteration 68200, lr = 1e-11
I0429 07:04:02.311476  5145 solver.cpp:228] Iteration 68300, loss = 0.204007
I0429 07:04:02.311653  5145 solver.cpp:244]     Train net output #0: loss = 0.204007 (* 1 = 0.204007 loss)
I0429 07:04:02.311661  5145 sgd_solver.cpp:106] Iteration 68300, lr = 1e-11
I0429 07:04:52.758263  5145 solver.cpp:228] Iteration 68400, loss = 0.275011
I0429 07:04:52.758430  5145 solver.cpp:244]     Train net output #0: loss = 0.275011 (* 1 = 0.275011 loss)
I0429 07:04:52.758438  5145 sgd_solver.cpp:106] Iteration 68400, lr = 1e-11
I0429 07:05:44.808255  5145 solver.cpp:228] Iteration 68500, loss = 0.325003
I0429 07:05:44.808444  5145 solver.cpp:244]     Train net output #0: loss = 0.325003 (* 1 = 0.325003 loss)
I0429 07:05:44.808450  5145 sgd_solver.cpp:106] Iteration 68500, lr = 1e-11
I0429 07:06:35.341948  5145 solver.cpp:228] Iteration 68600, loss = 0.243211
I0429 07:06:35.342157  5145 solver.cpp:244]     Train net output #0: loss = 0.243211 (* 1 = 0.243211 loss)
I0429 07:06:35.342166  5145 sgd_solver.cpp:106] Iteration 68600, lr = 1e-11
I0429 07:07:25.866752  5145 solver.cpp:228] Iteration 68700, loss = 0.260664
I0429 07:07:25.866914  5145 solver.cpp:244]     Train net output #0: loss = 0.260664 (* 1 = 0.260664 loss)
I0429 07:07:25.866920  5145 sgd_solver.cpp:106] Iteration 68700, lr = 1e-11
I0429 07:08:17.484424  5145 solver.cpp:228] Iteration 68800, loss = 0.230615
I0429 07:08:17.484570  5145 solver.cpp:244]     Train net output #0: loss = 0.230615 (* 1 = 0.230615 loss)
I0429 07:08:17.484577  5145 sgd_solver.cpp:106] Iteration 68800, lr = 1e-11
I0429 07:09:07.991118  5145 solver.cpp:228] Iteration 68900, loss = 0.188767
I0429 07:09:07.991273  5145 solver.cpp:244]     Train net output #0: loss = 0.188767 (* 1 = 0.188767 loss)
I0429 07:09:07.991281  5145 sgd_solver.cpp:106] Iteration 68900, lr = 1e-11
I0429 07:09:59.451887  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_69000.caffemodel
I0429 07:10:10.275290  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_69000.solverstate
I0429 07:10:10.478919  5145 solver.cpp:337] Iteration 69000, Testing net (#0)
I0429 07:10:10.479012  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 07:10:10.479017  5145 net.cpp:693] Ignoring source layer visualize
I0429 07:10:10.479018  5145 net.cpp:693] Ignoring source layer fake
I0429 07:15:06.544410  5145 solver.cpp:404]     Test net output #0: loss = 0.290983 (* 1 = 0.290983 loss)
I0429 07:15:06.859733  5145 solver.cpp:228] Iteration 69000, loss = 0.295335
I0429 07:15:06.859751  5145 solver.cpp:244]     Train net output #0: loss = 0.295335 (* 1 = 0.295335 loss)
I0429 07:15:06.859773  5145 sgd_solver.cpp:106] Iteration 69000, lr = 1e-11
I0429 07:15:57.354657  5145 solver.cpp:228] Iteration 69100, loss = 0.395149
I0429 07:15:57.354815  5145 solver.cpp:244]     Train net output #0: loss = 0.395149 (* 1 = 0.395149 loss)
I0429 07:15:57.354823  5145 sgd_solver.cpp:106] Iteration 69100, lr = 1e-11
I0429 07:16:47.793969  5145 solver.cpp:228] Iteration 69200, loss = 0.339671
I0429 07:16:47.794140  5145 solver.cpp:244]     Train net output #0: loss = 0.339671 (* 1 = 0.339671 loss)
I0429 07:16:47.794148  5145 sgd_solver.cpp:106] Iteration 69200, lr = 1e-11
I0429 07:17:39.621865  5145 solver.cpp:228] Iteration 69300, loss = 0.279909
I0429 07:17:39.622090  5145 solver.cpp:244]     Train net output #0: loss = 0.279909 (* 1 = 0.279909 loss)
I0429 07:17:39.622107  5145 sgd_solver.cpp:106] Iteration 69300, lr = 1e-11
I0429 07:18:30.112592  5145 solver.cpp:228] Iteration 69400, loss = 0.229857
I0429 07:18:30.112752  5145 solver.cpp:244]     Train net output #0: loss = 0.229857 (* 1 = 0.229857 loss)
I0429 07:18:30.112758  5145 sgd_solver.cpp:106] Iteration 69400, lr = 1e-11
I0429 07:19:20.610571  5145 solver.cpp:228] Iteration 69500, loss = 0.277879
I0429 07:19:20.610733  5145 solver.cpp:244]     Train net output #0: loss = 0.277879 (* 1 = 0.277879 loss)
I0429 07:19:20.610739  5145 sgd_solver.cpp:106] Iteration 69500, lr = 1e-11
I0429 07:20:12.730384  5145 solver.cpp:228] Iteration 69600, loss = 0.35459
I0429 07:20:12.730559  5145 solver.cpp:244]     Train net output #0: loss = 0.35459 (* 1 = 0.35459 loss)
I0429 07:20:12.730566  5145 sgd_solver.cpp:106] Iteration 69600, lr = 1e-11
I0429 07:21:03.320771  5145 solver.cpp:228] Iteration 69700, loss = 0.303512
I0429 07:21:03.320935  5145 solver.cpp:244]     Train net output #0: loss = 0.303512 (* 1 = 0.303512 loss)
I0429 07:21:03.320942  5145 sgd_solver.cpp:106] Iteration 69700, lr = 1e-11
I0429 07:21:53.767711  5145 solver.cpp:228] Iteration 69800, loss = 0.307965
I0429 07:21:53.768317  5145 solver.cpp:244]     Train net output #0: loss = 0.307965 (* 1 = 0.307965 loss)
I0429 07:21:53.768323  5145 sgd_solver.cpp:106] Iteration 69800, lr = 1e-11
I0429 07:22:46.011139  5145 solver.cpp:228] Iteration 69900, loss = 0.263894
I0429 07:22:46.011481  5145 solver.cpp:244]     Train net output #0: loss = 0.263894 (* 1 = 0.263894 loss)
I0429 07:22:46.011488  5145 sgd_solver.cpp:106] Iteration 69900, lr = 1e-11
I0429 07:23:36.155112  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_70000.caffemodel
I0429 07:23:47.054457  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_70000.solverstate
I0429 07:23:47.245501  5145 solver.cpp:337] Iteration 70000, Testing net (#0)
I0429 07:23:47.245601  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 07:23:47.245606  5145 net.cpp:693] Ignoring source layer visualize
I0429 07:23:47.245609  5145 net.cpp:693] Ignoring source layer fake
I0429 07:28:43.211639  5145 solver.cpp:404]     Test net output #0: loss = 0.286461 (* 1 = 0.286461 loss)
I0429 07:28:43.527206  5145 solver.cpp:228] Iteration 70000, loss = 0.246507
I0429 07:28:43.527258  5145 solver.cpp:244]     Train net output #0: loss = 0.246507 (* 1 = 0.246507 loss)
I0429 07:28:43.527266  5145 sgd_solver.cpp:106] Iteration 70000, lr = 1e-11
I0429 07:29:33.976740  5145 solver.cpp:228] Iteration 70100, loss = 0.301909
I0429 07:29:33.976930  5145 solver.cpp:244]     Train net output #0: loss = 0.301909 (* 1 = 0.301909 loss)
I0429 07:29:33.976938  5145 sgd_solver.cpp:106] Iteration 70100, lr = 1e-11
I0429 07:30:24.421799  5145 solver.cpp:228] Iteration 70200, loss = 0.274373
I0429 07:30:24.421973  5145 solver.cpp:244]     Train net output #0: loss = 0.274373 (* 1 = 0.274373 loss)
I0429 07:30:24.421980  5145 sgd_solver.cpp:106] Iteration 70200, lr = 1e-11
I0429 07:31:16.640697  5145 solver.cpp:228] Iteration 70300, loss = 0.368586
I0429 07:31:16.640852  5145 solver.cpp:244]     Train net output #0: loss = 0.368586 (* 1 = 0.368586 loss)
I0429 07:31:16.640859  5145 sgd_solver.cpp:106] Iteration 70300, lr = 1e-11
I0429 07:32:07.203541  5145 solver.cpp:228] Iteration 70400, loss = 0.185729
I0429 07:32:07.203708  5145 solver.cpp:244]     Train net output #0: loss = 0.185729 (* 1 = 0.185729 loss)
I0429 07:32:07.203716  5145 sgd_solver.cpp:106] Iteration 70400, lr = 1e-11
I0429 07:32:57.817701  5145 solver.cpp:228] Iteration 70500, loss = 0.257649
I0429 07:32:57.817849  5145 solver.cpp:244]     Train net output #0: loss = 0.257649 (* 1 = 0.257649 loss)
I0429 07:32:57.817857  5145 sgd_solver.cpp:106] Iteration 70500, lr = 1e-11
I0429 07:33:49.986016  5145 solver.cpp:228] Iteration 70600, loss = 0.298275
I0429 07:33:49.986158  5145 solver.cpp:244]     Train net output #0: loss = 0.298275 (* 1 = 0.298275 loss)
I0429 07:33:49.986166  5145 sgd_solver.cpp:106] Iteration 70600, lr = 1e-11
I0429 07:34:40.478644  5145 solver.cpp:228] Iteration 70700, loss = 0.17158
I0429 07:34:40.479557  5145 solver.cpp:244]     Train net output #0: loss = 0.17158 (* 1 = 0.17158 loss)
I0429 07:34:40.479563  5145 sgd_solver.cpp:106] Iteration 70700, lr = 1e-11
I0429 07:35:31.099442  5145 solver.cpp:228] Iteration 70800, loss = 0.304712
I0429 07:35:31.099588  5145 solver.cpp:244]     Train net output #0: loss = 0.304712 (* 1 = 0.304712 loss)
I0429 07:35:31.099594  5145 sgd_solver.cpp:106] Iteration 70800, lr = 1e-11
I0429 07:36:23.298353  5145 solver.cpp:228] Iteration 70900, loss = 0.210768
I0429 07:36:23.298501  5145 solver.cpp:244]     Train net output #0: loss = 0.210768 (* 1 = 0.210768 loss)
I0429 07:36:23.298508  5145 sgd_solver.cpp:106] Iteration 70900, lr = 1e-11
I0429 07:37:13.459990  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_71000.caffemodel
I0429 07:37:27.358402  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_71000.solverstate
I0429 07:37:27.557788  5145 solver.cpp:337] Iteration 71000, Testing net (#0)
I0429 07:37:27.557868  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 07:37:27.557888  5145 net.cpp:693] Ignoring source layer visualize
I0429 07:37:27.557889  5145 net.cpp:693] Ignoring source layer fake
I0429 07:42:23.460397  5145 solver.cpp:404]     Test net output #0: loss = 0.285211 (* 1 = 0.285211 loss)
I0429 07:42:23.771818  5145 solver.cpp:228] Iteration 71000, loss = 0.254142
I0429 07:42:23.771869  5145 solver.cpp:244]     Train net output #0: loss = 0.254142 (* 1 = 0.254142 loss)
I0429 07:42:23.771877  5145 sgd_solver.cpp:106] Iteration 71000, lr = 1e-11
I0429 07:43:14.272145  5145 solver.cpp:228] Iteration 71100, loss = 0.18701
I0429 07:43:14.272315  5145 solver.cpp:244]     Train net output #0: loss = 0.18701 (* 1 = 0.18701 loss)
I0429 07:43:14.272322  5145 sgd_solver.cpp:106] Iteration 71100, lr = 1e-11
I0429 07:44:04.747951  5145 solver.cpp:228] Iteration 71200, loss = 0.16449
I0429 07:44:04.748106  5145 solver.cpp:244]     Train net output #0: loss = 0.16449 (* 1 = 0.16449 loss)
I0429 07:44:04.748111  5145 sgd_solver.cpp:106] Iteration 71200, lr = 1e-11
I0429 07:44:56.800176  5145 solver.cpp:228] Iteration 71300, loss = 0.137323
I0429 07:44:56.800343  5145 solver.cpp:244]     Train net output #0: loss = 0.137323 (* 1 = 0.137323 loss)
I0429 07:44:56.800351  5145 sgd_solver.cpp:106] Iteration 71300, lr = 1e-11
I0429 07:45:47.295763  5145 solver.cpp:228] Iteration 71400, loss = 0.155423
I0429 07:45:47.295943  5145 solver.cpp:244]     Train net output #0: loss = 0.155423 (* 1 = 0.155423 loss)
I0429 07:45:47.295950  5145 sgd_solver.cpp:106] Iteration 71400, lr = 1e-11
I0429 07:46:37.789405  5145 solver.cpp:228] Iteration 71500, loss = 0.269164
I0429 07:46:37.789572  5145 solver.cpp:244]     Train net output #0: loss = 0.269164 (* 1 = 0.269164 loss)
I0429 07:46:37.789578  5145 sgd_solver.cpp:106] Iteration 71500, lr = 1e-11
I0429 07:47:29.833228  5145 solver.cpp:228] Iteration 71600, loss = 0.240077
I0429 07:47:29.833391  5145 solver.cpp:244]     Train net output #0: loss = 0.240077 (* 1 = 0.240077 loss)
I0429 07:47:29.833397  5145 sgd_solver.cpp:106] Iteration 71600, lr = 1e-11
I0429 07:48:20.429323  5145 solver.cpp:228] Iteration 71700, loss = 0.290447
I0429 07:48:20.429532  5145 solver.cpp:244]     Train net output #0: loss = 0.290447 (* 1 = 0.290447 loss)
I0429 07:48:20.429540  5145 sgd_solver.cpp:106] Iteration 71700, lr = 1e-11
I0429 07:49:10.945230  5145 solver.cpp:228] Iteration 71800, loss = 0.182052
I0429 07:49:10.945372  5145 solver.cpp:244]     Train net output #0: loss = 0.182052 (* 1 = 0.182052 loss)
I0429 07:49:10.945379  5145 sgd_solver.cpp:106] Iteration 71800, lr = 1e-11
I0429 07:50:02.728559  5145 solver.cpp:228] Iteration 71900, loss = 0.260196
I0429 07:50:02.730543  5145 solver.cpp:244]     Train net output #0: loss = 0.260196 (* 1 = 0.260196 loss)
I0429 07:50:02.730551  5145 sgd_solver.cpp:106] Iteration 71900, lr = 1e-11
I0429 07:50:53.016381  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_72000.caffemodel
I0429 07:51:15.483397  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_72000.solverstate
I0429 07:51:15.669386  5145 solver.cpp:337] Iteration 72000, Testing net (#0)
I0429 07:51:15.669499  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 07:51:15.669503  5145 net.cpp:693] Ignoring source layer visualize
I0429 07:51:15.669505  5145 net.cpp:693] Ignoring source layer fake
I0429 07:56:10.821713  5145 solver.cpp:404]     Test net output #0: loss = 0.279689 (* 1 = 0.279689 loss)
I0429 07:56:11.138994  5145 solver.cpp:228] Iteration 72000, loss = 0.205478
I0429 07:56:11.139032  5145 solver.cpp:244]     Train net output #0: loss = 0.205478 (* 1 = 0.205478 loss)
I0429 07:56:11.139040  5145 sgd_solver.cpp:106] Iteration 72000, lr = 1e-11
I0429 07:57:01.603508  5145 solver.cpp:228] Iteration 72100, loss = 0.197636
I0429 07:57:01.603682  5145 solver.cpp:244]     Train net output #0: loss = 0.197636 (* 1 = 0.197636 loss)
I0429 07:57:01.603689  5145 sgd_solver.cpp:106] Iteration 72100, lr = 1e-11
I0429 07:57:53.215716  5145 solver.cpp:228] Iteration 72200, loss = 0.216651
I0429 07:57:53.215891  5145 solver.cpp:244]     Train net output #0: loss = 0.216651 (* 1 = 0.216651 loss)
I0429 07:57:53.215898  5145 sgd_solver.cpp:106] Iteration 72200, lr = 1e-11
I0429 07:58:43.714088  5145 solver.cpp:228] Iteration 72300, loss = 0.356262
I0429 07:58:43.714249  5145 solver.cpp:244]     Train net output #0: loss = 0.356262 (* 1 = 0.356262 loss)
I0429 07:58:43.714256  5145 sgd_solver.cpp:106] Iteration 72300, lr = 1e-11
I0429 07:59:35.629384  5145 solver.cpp:228] Iteration 72400, loss = 0.230439
I0429 07:59:35.629572  5145 solver.cpp:244]     Train net output #0: loss = 0.230439 (* 1 = 0.230439 loss)
I0429 07:59:35.629580  5145 sgd_solver.cpp:106] Iteration 72400, lr = 1e-11
I0429 08:00:26.169893  5145 solver.cpp:228] Iteration 72500, loss = 0.33222
I0429 08:00:26.170189  5145 solver.cpp:244]     Train net output #0: loss = 0.33222 (* 1 = 0.33222 loss)
I0429 08:00:26.170197  5145 sgd_solver.cpp:106] Iteration 72500, lr = 1e-11
I0429 08:01:16.687654  5145 solver.cpp:228] Iteration 72600, loss = 0.205019
I0429 08:01:16.687808  5145 solver.cpp:244]     Train net output #0: loss = 0.205019 (* 1 = 0.205019 loss)
I0429 08:01:16.687814  5145 sgd_solver.cpp:106] Iteration 72600, lr = 1e-11
I0429 08:02:08.856192  5145 solver.cpp:228] Iteration 72700, loss = 0.318164
I0429 08:02:08.856381  5145 solver.cpp:244]     Train net output #0: loss = 0.318164 (* 1 = 0.318164 loss)
I0429 08:02:08.856389  5145 sgd_solver.cpp:106] Iteration 72700, lr = 1e-11
I0429 08:02:59.293201  5145 solver.cpp:228] Iteration 72800, loss = 0.252275
I0429 08:02:59.293361  5145 solver.cpp:244]     Train net output #0: loss = 0.252275 (* 1 = 0.252275 loss)
I0429 08:02:59.293368  5145 sgd_solver.cpp:106] Iteration 72800, lr = 1e-11
I0429 08:03:49.875838  5145 solver.cpp:228] Iteration 72900, loss = 0.440618
I0429 08:03:49.876005  5145 solver.cpp:244]     Train net output #0: loss = 0.440618 (* 1 = 0.440618 loss)
I0429 08:03:49.876013  5145 sgd_solver.cpp:106] Iteration 72900, lr = 1e-11
I0429 08:04:41.809284  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_73000.caffemodel
I0429 08:04:59.828510  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_73000.solverstate
I0429 08:05:00.027288  5145 solver.cpp:337] Iteration 73000, Testing net (#0)
I0429 08:05:00.027369  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 08:05:00.027374  5145 net.cpp:693] Ignoring source layer visualize
I0429 08:05:00.027375  5145 net.cpp:693] Ignoring source layer fake
I0429 08:09:57.152397  5145 solver.cpp:404]     Test net output #0: loss = 0.286449 (* 1 = 0.286449 loss)
I0429 08:09:57.466248  5145 solver.cpp:228] Iteration 73000, loss = 0.400115
I0429 08:09:57.466270  5145 solver.cpp:244]     Train net output #0: loss = 0.400115 (* 1 = 0.400115 loss)
I0429 08:09:57.466292  5145 sgd_solver.cpp:106] Iteration 73000, lr = 1e-11
I0429 08:10:47.896419  5145 solver.cpp:228] Iteration 73100, loss = 0.220848
I0429 08:10:47.897326  5145 solver.cpp:244]     Train net output #0: loss = 0.220848 (* 1 = 0.220848 loss)
I0429 08:10:47.897334  5145 sgd_solver.cpp:106] Iteration 73100, lr = 1e-11
I0429 08:11:38.320669  5145 solver.cpp:228] Iteration 73200, loss = 0.19533
I0429 08:11:38.320837  5145 solver.cpp:244]     Train net output #0: loss = 0.19533 (* 1 = 0.19533 loss)
I0429 08:11:38.320843  5145 sgd_solver.cpp:106] Iteration 73200, lr = 1e-11
I0429 08:12:28.789620  5145 solver.cpp:228] Iteration 73300, loss = 0.285392
I0429 08:12:28.789796  5145 solver.cpp:244]     Train net output #0: loss = 0.285392 (* 1 = 0.285392 loss)
I0429 08:12:28.789804  5145 sgd_solver.cpp:106] Iteration 73300, lr = 1e-11
I0429 08:13:20.986994  5145 solver.cpp:228] Iteration 73400, loss = 0.464947
I0429 08:13:20.987159  5145 solver.cpp:244]     Train net output #0: loss = 0.464947 (* 1 = 0.464947 loss)
I0429 08:13:20.987165  5145 sgd_solver.cpp:106] Iteration 73400, lr = 1e-11
I0429 08:14:11.566884  5145 solver.cpp:228] Iteration 73500, loss = 0.308767
I0429 08:14:11.567047  5145 solver.cpp:244]     Train net output #0: loss = 0.308767 (* 1 = 0.308767 loss)
I0429 08:14:11.567054  5145 sgd_solver.cpp:106] Iteration 73500, lr = 1e-11
I0429 08:15:02.082876  5145 solver.cpp:228] Iteration 73600, loss = 0.428852
I0429 08:15:02.083030  5145 solver.cpp:244]     Train net output #0: loss = 0.428852 (* 1 = 0.428852 loss)
I0429 08:15:02.083036  5145 sgd_solver.cpp:106] Iteration 73600, lr = 1e-11
I0429 08:15:54.297260  5145 solver.cpp:228] Iteration 73700, loss = 0.270375
I0429 08:15:54.297422  5145 solver.cpp:244]     Train net output #0: loss = 0.270375 (* 1 = 0.270375 loss)
I0429 08:15:54.297430  5145 sgd_solver.cpp:106] Iteration 73700, lr = 1e-11
I0429 08:16:44.780510  5145 solver.cpp:228] Iteration 73800, loss = 0.237871
I0429 08:16:44.780683  5145 solver.cpp:244]     Train net output #0: loss = 0.237871 (* 1 = 0.237871 loss)
I0429 08:16:44.780690  5145 sgd_solver.cpp:106] Iteration 73800, lr = 1e-11
I0429 08:17:35.255828  5145 solver.cpp:228] Iteration 73900, loss = 0.228829
I0429 08:17:35.256000  5145 solver.cpp:244]     Train net output #0: loss = 0.228829 (* 1 = 0.228829 loss)
I0429 08:17:35.256007  5145 sgd_solver.cpp:106] Iteration 73900, lr = 1e-11
I0429 08:18:25.440443  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_74000.caffemodel
I0429 08:18:40.387737  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_74000.solverstate
I0429 08:18:40.582052  5145 solver.cpp:337] Iteration 74000, Testing net (#0)
I0429 08:18:40.582134  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 08:18:40.582137  5145 net.cpp:693] Ignoring source layer visualize
I0429 08:18:40.582139  5145 net.cpp:693] Ignoring source layer fake
I0429 08:23:36.722825  5145 solver.cpp:404]     Test net output #0: loss = 0.290254 (* 1 = 0.290254 loss)
I0429 08:23:37.041051  5145 solver.cpp:228] Iteration 74000, loss = 0.214487
I0429 08:23:37.041069  5145 solver.cpp:244]     Train net output #0: loss = 0.214487 (* 1 = 0.214487 loss)
I0429 08:23:37.041092  5145 sgd_solver.cpp:106] Iteration 74000, lr = 1e-11
I0429 08:24:29.177202  5145 solver.cpp:228] Iteration 74100, loss = 0.217711
I0429 08:24:29.177356  5145 solver.cpp:244]     Train net output #0: loss = 0.217711 (* 1 = 0.217711 loss)
I0429 08:24:29.177362  5145 sgd_solver.cpp:106] Iteration 74100, lr = 1e-11
I0429 08:25:19.629863  5145 solver.cpp:228] Iteration 74200, loss = 0.198088
I0429 08:25:19.630060  5145 solver.cpp:244]     Train net output #0: loss = 0.198088 (* 1 = 0.198088 loss)
I0429 08:25:19.630069  5145 sgd_solver.cpp:106] Iteration 74200, lr = 1e-11
I0429 08:26:10.138473  5145 solver.cpp:228] Iteration 74300, loss = 0.251693
I0429 08:26:10.138661  5145 solver.cpp:244]     Train net output #0: loss = 0.251693 (* 1 = 0.251693 loss)
I0429 08:26:10.138669  5145 sgd_solver.cpp:106] Iteration 74300, lr = 1e-11
I0429 08:27:02.272503  5145 solver.cpp:228] Iteration 74400, loss = 0.253959
I0429 08:27:02.272661  5145 solver.cpp:244]     Train net output #0: loss = 0.253959 (* 1 = 0.253959 loss)
I0429 08:27:02.272668  5145 sgd_solver.cpp:106] Iteration 74400, lr = 1e-11
I0429 08:27:52.782819  5145 solver.cpp:228] Iteration 74500, loss = 0.363662
I0429 08:27:52.782968  5145 solver.cpp:244]     Train net output #0: loss = 0.363662 (* 1 = 0.363662 loss)
I0429 08:27:52.782974  5145 sgd_solver.cpp:106] Iteration 74500, lr = 1e-11
I0429 08:28:43.419657  5145 solver.cpp:228] Iteration 74600, loss = 0.230976
I0429 08:28:43.419798  5145 solver.cpp:244]     Train net output #0: loss = 0.230976 (* 1 = 0.230976 loss)
I0429 08:28:43.419806  5145 sgd_solver.cpp:106] Iteration 74600, lr = 1e-11
I0429 08:29:35.547667  5145 solver.cpp:228] Iteration 74700, loss = 0.207675
I0429 08:29:35.547830  5145 solver.cpp:244]     Train net output #0: loss = 0.207675 (* 1 = 0.207675 loss)
I0429 08:29:35.547837  5145 sgd_solver.cpp:106] Iteration 74700, lr = 1e-11
I0429 08:30:25.976945  5145 solver.cpp:228] Iteration 74800, loss = 0.293818
I0429 08:30:25.977113  5145 solver.cpp:244]     Train net output #0: loss = 0.293818 (* 1 = 0.293818 loss)
I0429 08:30:25.977119  5145 sgd_solver.cpp:106] Iteration 74800, lr = 1e-11
I0429 08:31:16.505133  5145 solver.cpp:228] Iteration 74900, loss = 0.344459
I0429 08:31:16.505302  5145 solver.cpp:244]     Train net output #0: loss = 0.344459 (* 1 = 0.344459 loss)
I0429 08:31:16.505308  5145 sgd_solver.cpp:106] Iteration 74900, lr = 1e-11
I0429 08:32:07.901988  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_75000.caffemodel
I0429 08:32:31.612241  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_75000.solverstate
I0429 08:32:31.813287  5145 solver.cpp:337] Iteration 75000, Testing net (#0)
I0429 08:32:31.813370  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 08:32:31.813374  5145 net.cpp:693] Ignoring source layer visualize
I0429 08:32:31.813376  5145 net.cpp:693] Ignoring source layer fake
I0429 08:37:27.520082  5145 solver.cpp:404]     Test net output #0: loss = 0.286111 (* 1 = 0.286111 loss)
I0429 08:37:27.836802  5145 solver.cpp:228] Iteration 75000, loss = 0.183031
I0429 08:37:27.836819  5145 solver.cpp:244]     Train net output #0: loss = 0.183031 (* 1 = 0.183031 loss)
I0429 08:37:27.836841  5145 sgd_solver.cpp:106] Iteration 75000, lr = 1e-12
I0429 08:38:18.280361  5145 solver.cpp:228] Iteration 75100, loss = 0.246604
I0429 08:38:18.280522  5145 solver.cpp:244]     Train net output #0: loss = 0.246604 (* 1 = 0.246604 loss)
I0429 08:38:18.280529  5145 sgd_solver.cpp:106] Iteration 75100, lr = 1e-12
I0429 08:39:08.748615  5145 solver.cpp:228] Iteration 75200, loss = 0.19285
I0429 08:39:08.748780  5145 solver.cpp:244]     Train net output #0: loss = 0.19285 (* 1 = 0.19285 loss)
I0429 08:39:08.748787  5145 sgd_solver.cpp:106] Iteration 75200, lr = 1e-12
I0429 08:40:00.383105  5145 solver.cpp:228] Iteration 75300, loss = 0.358305
I0429 08:40:00.383275  5145 solver.cpp:244]     Train net output #0: loss = 0.358305 (* 1 = 0.358305 loss)
I0429 08:40:00.383281  5145 sgd_solver.cpp:106] Iteration 75300, lr = 1e-12
I0429 08:40:50.850468  5145 solver.cpp:228] Iteration 75400, loss = 0.242527
I0429 08:40:50.850626  5145 solver.cpp:244]     Train net output #0: loss = 0.242527 (* 1 = 0.242527 loss)
I0429 08:40:50.850633  5145 sgd_solver.cpp:106] Iteration 75400, lr = 1e-12
I0429 08:41:42.919267  5145 solver.cpp:228] Iteration 75500, loss = 0.246469
I0429 08:41:42.919423  5145 solver.cpp:244]     Train net output #0: loss = 0.246469 (* 1 = 0.246469 loss)
I0429 08:41:42.919430  5145 sgd_solver.cpp:106] Iteration 75500, lr = 1e-12
I0429 08:42:33.270997  5145 solver.cpp:228] Iteration 75600, loss = 0.224268
I0429 08:42:33.271144  5145 solver.cpp:244]     Train net output #0: loss = 0.224268 (* 1 = 0.224268 loss)
I0429 08:42:33.271152  5145 sgd_solver.cpp:106] Iteration 75600, lr = 1e-12
I0429 08:43:23.846549  5145 solver.cpp:228] Iteration 75700, loss = 0.288501
I0429 08:43:23.846704  5145 solver.cpp:244]     Train net output #0: loss = 0.288501 (* 1 = 0.288501 loss)
I0429 08:43:23.846711  5145 sgd_solver.cpp:106] Iteration 75700, lr = 1e-12
I0429 08:44:15.966650  5145 solver.cpp:228] Iteration 75800, loss = 0.29688
I0429 08:44:15.966817  5145 solver.cpp:244]     Train net output #0: loss = 0.29688 (* 1 = 0.29688 loss)
I0429 08:44:15.966823  5145 sgd_solver.cpp:106] Iteration 75800, lr = 1e-12
I0429 08:45:06.452908  5145 solver.cpp:228] Iteration 75900, loss = 0.250937
I0429 08:45:06.453095  5145 solver.cpp:244]     Train net output #0: loss = 0.250937 (* 1 = 0.250937 loss)
I0429 08:45:06.453102  5145 sgd_solver.cpp:106] Iteration 75900, lr = 1e-12
I0429 08:45:56.725544  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_76000.caffemodel
I0429 08:46:08.334709  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_76000.solverstate
I0429 08:46:08.529795  5145 solver.cpp:337] Iteration 76000, Testing net (#0)
I0429 08:46:08.529893  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 08:46:08.529899  5145 net.cpp:693] Ignoring source layer visualize
I0429 08:46:08.529901  5145 net.cpp:693] Ignoring source layer fake
I0429 08:51:04.259353  5145 solver.cpp:404]     Test net output #0: loss = 0.284379 (* 1 = 0.284379 loss)
I0429 08:51:04.580051  5145 solver.cpp:228] Iteration 76000, loss = 0.360101
I0429 08:51:04.580072  5145 solver.cpp:244]     Train net output #0: loss = 0.360101 (* 1 = 0.360101 loss)
I0429 08:51:04.580096  5145 sgd_solver.cpp:106] Iteration 76000, lr = 1e-12
I0429 08:51:55.137868  5145 solver.cpp:228] Iteration 76100, loss = 0.216965
I0429 08:51:55.138025  5145 solver.cpp:244]     Train net output #0: loss = 0.216965 (* 1 = 0.216965 loss)
I0429 08:51:55.138031  5145 sgd_solver.cpp:106] Iteration 76100, lr = 1e-12
I0429 08:52:47.244719  5145 solver.cpp:228] Iteration 76200, loss = 0.351413
I0429 08:52:47.244889  5145 solver.cpp:244]     Train net output #0: loss = 0.351413 (* 1 = 0.351413 loss)
I0429 08:52:47.244896  5145 sgd_solver.cpp:106] Iteration 76200, lr = 1e-12
I0429 08:53:37.725603  5145 solver.cpp:228] Iteration 76300, loss = 0.299118
I0429 08:53:37.725790  5145 solver.cpp:244]     Train net output #0: loss = 0.299118 (* 1 = 0.299118 loss)
I0429 08:53:37.725797  5145 sgd_solver.cpp:106] Iteration 76300, lr = 1e-12
I0429 08:54:28.174499  5145 solver.cpp:228] Iteration 76400, loss = 0.29941
I0429 08:54:28.174778  5145 solver.cpp:244]     Train net output #0: loss = 0.29941 (* 1 = 0.29941 loss)
I0429 08:54:28.174787  5145 sgd_solver.cpp:106] Iteration 76400, lr = 1e-12
I0429 08:55:20.478799  5145 solver.cpp:228] Iteration 76500, loss = 0.316131
I0429 08:55:20.479106  5145 solver.cpp:244]     Train net output #0: loss = 0.316131 (* 1 = 0.316131 loss)
I0429 08:55:20.479115  5145 sgd_solver.cpp:106] Iteration 76500, lr = 1e-12
I0429 08:56:10.944710  5145 solver.cpp:228] Iteration 76600, loss = 0.219135
I0429 08:56:10.944864  5145 solver.cpp:244]     Train net output #0: loss = 0.219135 (* 1 = 0.219135 loss)
I0429 08:56:10.944869  5145 sgd_solver.cpp:106] Iteration 76600, lr = 1e-12
I0429 08:57:01.442879  5145 solver.cpp:228] Iteration 76700, loss = 0.23721
I0429 08:57:01.443037  5145 solver.cpp:244]     Train net output #0: loss = 0.23721 (* 1 = 0.23721 loss)
I0429 08:57:01.443043  5145 sgd_solver.cpp:106] Iteration 76700, lr = 1e-12
I0429 08:57:51.938803  5145 solver.cpp:228] Iteration 76800, loss = 0.255505
I0429 08:57:51.938968  5145 solver.cpp:244]     Train net output #0: loss = 0.255505 (* 1 = 0.255505 loss)
I0429 08:57:51.938977  5145 sgd_solver.cpp:106] Iteration 76800, lr = 1e-12
I0429 08:58:44.174029  5145 solver.cpp:228] Iteration 76900, loss = 0.176804
I0429 08:58:44.174185  5145 solver.cpp:244]     Train net output #0: loss = 0.176804 (* 1 = 0.176804 loss)
I0429 08:58:44.174191  5145 sgd_solver.cpp:106] Iteration 76900, lr = 1e-12
I0429 08:59:34.342936  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_77000.caffemodel
I0429 08:59:50.350744  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_77000.solverstate
I0429 08:59:50.546815  5145 solver.cpp:337] Iteration 77000, Testing net (#0)
I0429 08:59:50.546914  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 08:59:50.546919  5145 net.cpp:693] Ignoring source layer visualize
I0429 08:59:50.546922  5145 net.cpp:693] Ignoring source layer fake
I0429 09:04:45.973155  5145 solver.cpp:404]     Test net output #0: loss = 0.280081 (* 1 = 0.280081 loss)
I0429 09:04:46.284699  5145 solver.cpp:228] Iteration 77000, loss = 0.239139
I0429 09:04:46.284718  5145 solver.cpp:244]     Train net output #0: loss = 0.239139 (* 1 = 0.239139 loss)
I0429 09:04:46.284741  5145 sgd_solver.cpp:106] Iteration 77000, lr = 1e-12
I0429 09:05:36.855993  5145 solver.cpp:228] Iteration 77100, loss = 0.245628
I0429 09:05:36.856155  5145 solver.cpp:244]     Train net output #0: loss = 0.245628 (* 1 = 0.245628 loss)
I0429 09:05:36.856163  5145 sgd_solver.cpp:106] Iteration 77100, lr = 1e-12
I0429 09:06:29.383023  5145 solver.cpp:228] Iteration 77200, loss = 0.287559
I0429 09:06:29.383203  5145 solver.cpp:244]     Train net output #0: loss = 0.287559 (* 1 = 0.287559 loss)
I0429 09:06:29.383209  5145 sgd_solver.cpp:106] Iteration 77200, lr = 1e-12
I0429 09:07:19.907610  5145 solver.cpp:228] Iteration 77300, loss = 0.243799
I0429 09:07:19.907760  5145 solver.cpp:244]     Train net output #0: loss = 0.243799 (* 1 = 0.243799 loss)
I0429 09:07:19.907766  5145 sgd_solver.cpp:106] Iteration 77300, lr = 1e-12
I0429 09:08:10.486307  5145 solver.cpp:228] Iteration 77400, loss = 0.242809
I0429 09:08:10.486459  5145 solver.cpp:244]     Train net output #0: loss = 0.242809 (* 1 = 0.242809 loss)
I0429 09:08:10.486465  5145 sgd_solver.cpp:106] Iteration 77400, lr = 1e-12
I0429 09:09:02.612618  5145 solver.cpp:228] Iteration 77500, loss = 0.17197
I0429 09:09:02.612813  5145 solver.cpp:244]     Train net output #0: loss = 0.17197 (* 1 = 0.17197 loss)
I0429 09:09:02.612821  5145 sgd_solver.cpp:106] Iteration 77500, lr = 1e-12
I0429 09:09:53.041023  5145 solver.cpp:228] Iteration 77600, loss = 0.224405
I0429 09:09:53.041189  5145 solver.cpp:244]     Train net output #0: loss = 0.224405 (* 1 = 0.224405 loss)
I0429 09:09:53.041196  5145 sgd_solver.cpp:106] Iteration 77600, lr = 1e-12
I0429 09:10:43.497364  5145 solver.cpp:228] Iteration 77700, loss = 0.232077
I0429 09:10:43.497519  5145 solver.cpp:244]     Train net output #0: loss = 0.232077 (* 1 = 0.232077 loss)
I0429 09:10:43.497524  5145 sgd_solver.cpp:106] Iteration 77700, lr = 1e-12
I0429 09:11:34.077529  5145 solver.cpp:228] Iteration 77800, loss = 0.209246
I0429 09:11:34.077782  5145 solver.cpp:244]     Train net output #0: loss = 0.209246 (* 1 = 0.209246 loss)
I0429 09:11:34.077790  5145 sgd_solver.cpp:106] Iteration 77800, lr = 1e-12
I0429 09:12:26.156440  5145 solver.cpp:228] Iteration 77900, loss = 0.25257
I0429 09:12:26.156600  5145 solver.cpp:244]     Train net output #0: loss = 0.25257 (* 1 = 0.25257 loss)
I0429 09:12:26.156607  5145 sgd_solver.cpp:106] Iteration 77900, lr = 1e-12
I0429 09:13:16.328634  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_78000.caffemodel
I0429 09:13:37.969197  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_78000.solverstate
I0429 09:13:38.164994  5145 solver.cpp:337] Iteration 78000, Testing net (#0)
I0429 09:13:38.165076  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 09:13:38.165079  5145 net.cpp:693] Ignoring source layer visualize
I0429 09:13:38.165081  5145 net.cpp:693] Ignoring source layer fake
I0429 09:18:34.030002  5145 solver.cpp:404]     Test net output #0: loss = 0.287456 (* 1 = 0.287456 loss)
I0429 09:18:34.343106  5145 solver.cpp:228] Iteration 78000, loss = 0.410915
I0429 09:18:34.343147  5145 solver.cpp:244]     Train net output #0: loss = 0.410915 (* 1 = 0.410915 loss)
I0429 09:18:34.343153  5145 sgd_solver.cpp:106] Iteration 78000, lr = 1e-12
I0429 09:19:24.793615  5145 solver.cpp:228] Iteration 78100, loss = 0.232976
I0429 09:19:24.793779  5145 solver.cpp:244]     Train net output #0: loss = 0.232976 (* 1 = 0.232976 loss)
I0429 09:19:24.793787  5145 sgd_solver.cpp:106] Iteration 78100, lr = 1e-12
I0429 09:20:16.387943  5145 solver.cpp:228] Iteration 78200, loss = 0.229902
I0429 09:20:16.388113  5145 solver.cpp:244]     Train net output #0: loss = 0.229902 (* 1 = 0.229902 loss)
I0429 09:20:16.388121  5145 sgd_solver.cpp:106] Iteration 78200, lr = 1e-12
I0429 09:21:06.858273  5145 solver.cpp:228] Iteration 78300, loss = 0.176622
I0429 09:21:06.858438  5145 solver.cpp:244]     Train net output #0: loss = 0.176622 (* 1 = 0.176622 loss)
I0429 09:21:06.858444  5145 sgd_solver.cpp:106] Iteration 78300, lr = 1e-12
I0429 09:21:58.528749  5145 solver.cpp:228] Iteration 78400, loss = 0.513854
I0429 09:21:58.528908  5145 solver.cpp:244]     Train net output #0: loss = 0.513854 (* 1 = 0.513854 loss)
I0429 09:21:58.528914  5145 sgd_solver.cpp:106] Iteration 78400, lr = 1e-12
I0429 09:22:49.079557  5145 solver.cpp:228] Iteration 78500, loss = 0.347748
I0429 09:22:49.079710  5145 solver.cpp:244]     Train net output #0: loss = 0.347748 (* 1 = 0.347748 loss)
I0429 09:22:49.079715  5145 sgd_solver.cpp:106] Iteration 78500, lr = 1e-12
I0429 09:23:39.602056  5145 solver.cpp:228] Iteration 78600, loss = 0.315648
I0429 09:23:39.602232  5145 solver.cpp:244]     Train net output #0: loss = 0.315648 (* 1 = 0.315648 loss)
I0429 09:23:39.602239  5145 sgd_solver.cpp:106] Iteration 78600, lr = 1e-12
I0429 09:24:31.654000  5145 solver.cpp:228] Iteration 78700, loss = 0.243076
I0429 09:24:31.654170  5145 solver.cpp:244]     Train net output #0: loss = 0.243076 (* 1 = 0.243076 loss)
I0429 09:24:31.654176  5145 sgd_solver.cpp:106] Iteration 78700, lr = 1e-12
I0429 09:25:22.208570  5145 solver.cpp:228] Iteration 78800, loss = 0.241089
I0429 09:25:22.208747  5145 solver.cpp:244]     Train net output #0: loss = 0.241089 (* 1 = 0.241089 loss)
I0429 09:25:22.208755  5145 sgd_solver.cpp:106] Iteration 78800, lr = 1e-12
I0429 09:26:12.662348  5145 solver.cpp:228] Iteration 78900, loss = 0.27957
I0429 09:26:12.662515  5145 solver.cpp:244]     Train net output #0: loss = 0.27957 (* 1 = 0.27957 loss)
I0429 09:26:12.662523  5145 sgd_solver.cpp:106] Iteration 78900, lr = 1e-12
I0429 09:27:04.556136  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_79000.caffemodel
I0429 09:27:28.379532  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_79000.solverstate
I0429 09:27:28.583318  5145 solver.cpp:337] Iteration 79000, Testing net (#0)
I0429 09:27:28.583415  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 09:27:28.583420  5145 net.cpp:693] Ignoring source layer visualize
I0429 09:27:28.583421  5145 net.cpp:693] Ignoring source layer fake
I0429 09:32:24.135687  5145 solver.cpp:404]     Test net output #0: loss = 0.289801 (* 1 = 0.289801 loss)
I0429 09:32:24.458741  5145 solver.cpp:228] Iteration 79000, loss = 0.322208
I0429 09:32:24.458760  5145 solver.cpp:244]     Train net output #0: loss = 0.322208 (* 1 = 0.322208 loss)
I0429 09:32:24.458781  5145 sgd_solver.cpp:106] Iteration 79000, lr = 1e-12
I0429 09:33:14.808972  5145 solver.cpp:228] Iteration 79100, loss = 0.303103
I0429 09:33:14.809137  5145 solver.cpp:244]     Train net output #0: loss = 0.303103 (* 1 = 0.303103 loss)
I0429 09:33:14.809144  5145 sgd_solver.cpp:106] Iteration 79100, lr = 1e-12
I0429 09:34:05.227061  5145 solver.cpp:228] Iteration 79200, loss = 0.0941458
I0429 09:34:05.227224  5145 solver.cpp:244]     Train net output #0: loss = 0.0941458 (* 1 = 0.0941458 loss)
I0429 09:34:05.227231  5145 sgd_solver.cpp:106] Iteration 79200, lr = 1e-12
I0429 09:34:57.428613  5145 solver.cpp:228] Iteration 79300, loss = 0.244979
I0429 09:34:57.428800  5145 solver.cpp:244]     Train net output #0: loss = 0.244979 (* 1 = 0.244979 loss)
I0429 09:34:57.428808  5145 sgd_solver.cpp:106] Iteration 79300, lr = 1e-12
I0429 09:35:47.952908  5145 solver.cpp:228] Iteration 79400, loss = 0.216896
I0429 09:35:47.953070  5145 solver.cpp:244]     Train net output #0: loss = 0.216896 (* 1 = 0.216896 loss)
I0429 09:35:47.953076  5145 sgd_solver.cpp:106] Iteration 79400, lr = 1e-12
I0429 09:36:38.476264  5145 solver.cpp:228] Iteration 79500, loss = 0.38053
I0429 09:36:38.476418  5145 solver.cpp:244]     Train net output #0: loss = 0.38053 (* 1 = 0.38053 loss)
I0429 09:36:38.476424  5145 sgd_solver.cpp:106] Iteration 79500, lr = 1e-12
I0429 09:37:30.767938  5145 solver.cpp:228] Iteration 79600, loss = 0.303256
I0429 09:37:30.768079  5145 solver.cpp:244]     Train net output #0: loss = 0.303256 (* 1 = 0.303256 loss)
I0429 09:37:30.768085  5145 sgd_solver.cpp:106] Iteration 79600, lr = 1e-12
I0429 09:38:21.282682  5145 solver.cpp:228] Iteration 79700, loss = 0.443849
I0429 09:38:21.282831  5145 solver.cpp:244]     Train net output #0: loss = 0.443849 (* 1 = 0.443849 loss)
I0429 09:38:21.282840  5145 sgd_solver.cpp:106] Iteration 79700, lr = 1e-12
I0429 09:39:11.814322  5145 solver.cpp:228] Iteration 79800, loss = 0.215425
I0429 09:39:11.814478  5145 solver.cpp:244]     Train net output #0: loss = 0.215425 (* 1 = 0.215425 loss)
I0429 09:39:11.814484  5145 sgd_solver.cpp:106] Iteration 79800, lr = 1e-12
I0429 09:40:02.309619  5145 solver.cpp:228] Iteration 79900, loss = 0.280834
I0429 09:40:02.309768  5145 solver.cpp:244]     Train net output #0: loss = 0.280834 (* 1 = 0.280834 loss)
I0429 09:40:02.309774  5145 sgd_solver.cpp:106] Iteration 79900, lr = 1e-12
I0429 09:40:54.195492  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_80000.caffemodel
I0429 09:40:57.751003  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_80000.solverstate
I0429 09:40:57.945318  5145 solver.cpp:337] Iteration 80000, Testing net (#0)
I0429 09:40:57.945400  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 09:40:57.945403  5145 net.cpp:693] Ignoring source layer visualize
I0429 09:40:57.945406  5145 net.cpp:693] Ignoring source layer fake
I0429 09:45:53.955451  5145 solver.cpp:404]     Test net output #0: loss = 0.28592 (* 1 = 0.28592 loss)
I0429 09:45:54.266013  5145 solver.cpp:228] Iteration 80000, loss = 0.269699
I0429 09:45:54.266031  5145 solver.cpp:244]     Train net output #0: loss = 0.269699 (* 1 = 0.269699 loss)
I0429 09:45:54.266054  5145 sgd_solver.cpp:106] Iteration 80000, lr = 1e-12
I0429 09:46:44.686769  5145 solver.cpp:228] Iteration 80100, loss = 0.264914
I0429 09:46:44.686934  5145 solver.cpp:244]     Train net output #0: loss = 0.264914 (* 1 = 0.264914 loss)
I0429 09:46:44.686941  5145 sgd_solver.cpp:106] Iteration 80100, lr = 1e-12
I0429 09:47:35.193737  5145 solver.cpp:228] Iteration 80200, loss = 0.232619
I0429 09:47:35.193955  5145 solver.cpp:244]     Train net output #0: loss = 0.232619 (* 1 = 0.232619 loss)
I0429 09:47:35.193963  5145 sgd_solver.cpp:106] Iteration 80200, lr = 1e-12
I0429 09:48:27.336540  5145 solver.cpp:228] Iteration 80300, loss = 0.169752
I0429 09:48:27.336920  5145 solver.cpp:244]     Train net output #0: loss = 0.169752 (* 1 = 0.169752 loss)
I0429 09:48:27.336928  5145 sgd_solver.cpp:106] Iteration 80300, lr = 1e-12
I0429 09:49:17.927547  5145 solver.cpp:228] Iteration 80400, loss = 0.247904
I0429 09:49:17.927706  5145 solver.cpp:244]     Train net output #0: loss = 0.247904 (* 1 = 0.247904 loss)
I0429 09:49:17.927713  5145 sgd_solver.cpp:106] Iteration 80400, lr = 1e-12
I0429 09:50:08.366083  5145 solver.cpp:228] Iteration 80500, loss = 0.0687763
I0429 09:50:08.366245  5145 solver.cpp:244]     Train net output #0: loss = 0.0687763 (* 1 = 0.0687763 loss)
I0429 09:50:08.366251  5145 sgd_solver.cpp:106] Iteration 80500, lr = 1e-12
I0429 09:51:00.859185  5145 solver.cpp:228] Iteration 80600, loss = 0.289108
I0429 09:51:00.859349  5145 solver.cpp:244]     Train net output #0: loss = 0.289108 (* 1 = 0.289108 loss)
I0429 09:51:00.859356  5145 sgd_solver.cpp:106] Iteration 80600, lr = 1e-12
I0429 09:51:51.222359  5145 solver.cpp:228] Iteration 80700, loss = 0.260827
I0429 09:51:51.222524  5145 solver.cpp:244]     Train net output #0: loss = 0.260827 (* 1 = 0.260827 loss)
I0429 09:51:51.222532  5145 sgd_solver.cpp:106] Iteration 80700, lr = 1e-12
I0429 09:52:41.688325  5145 solver.cpp:228] Iteration 80800, loss = 0.210649
I0429 09:52:41.688460  5145 solver.cpp:244]     Train net output #0: loss = 0.210649 (* 1 = 0.210649 loss)
I0429 09:52:41.688467  5145 sgd_solver.cpp:106] Iteration 80800, lr = 1e-12
I0429 09:53:32.241503  5145 solver.cpp:228] Iteration 80900, loss = 0.272374
I0429 09:53:32.242919  5145 solver.cpp:244]     Train net output #0: loss = 0.272374 (* 1 = 0.272374 loss)
I0429 09:53:32.242925  5145 sgd_solver.cpp:106] Iteration 80900, lr = 1e-12
I0429 09:54:23.881367  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_81000.caffemodel
I0429 09:54:40.467473  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_81000.solverstate
I0429 09:54:40.664793  5145 solver.cpp:337] Iteration 81000, Testing net (#0)
I0429 09:54:40.664892  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 09:54:40.664898  5145 net.cpp:693] Ignoring source layer visualize
I0429 09:54:40.664901  5145 net.cpp:693] Ignoring source layer fake
I0429 09:59:36.757493  5145 solver.cpp:404]     Test net output #0: loss = 0.283675 (* 1 = 0.283675 loss)
I0429 09:59:37.076103  5145 solver.cpp:228] Iteration 81000, loss = 0.300579
I0429 09:59:37.076139  5145 solver.cpp:244]     Train net output #0: loss = 0.300579 (* 1 = 0.300579 loss)
I0429 09:59:37.076148  5145 sgd_solver.cpp:106] Iteration 81000, lr = 1e-12
I0429 10:00:27.471870  5145 solver.cpp:228] Iteration 81100, loss = 0.254444
I0429 10:00:27.472072  5145 solver.cpp:244]     Train net output #0: loss = 0.254444 (* 1 = 0.254444 loss)
I0429 10:00:27.472082  5145 sgd_solver.cpp:106] Iteration 81100, lr = 1e-12
I0429 10:01:18.009827  5145 solver.cpp:228] Iteration 81200, loss = 0.453469
I0429 10:01:18.009999  5145 solver.cpp:244]     Train net output #0: loss = 0.453469 (* 1 = 0.453469 loss)
I0429 10:01:18.010007  5145 sgd_solver.cpp:106] Iteration 81200, lr = 1e-12
I0429 10:02:09.765828  5145 solver.cpp:228] Iteration 81300, loss = 0.146148
I0429 10:02:09.765990  5145 solver.cpp:244]     Train net output #0: loss = 0.146148 (* 1 = 0.146148 loss)
I0429 10:02:09.765997  5145 sgd_solver.cpp:106] Iteration 81300, lr = 1e-12
I0429 10:03:00.129788  5145 solver.cpp:228] Iteration 81400, loss = 0.221011
I0429 10:03:00.129953  5145 solver.cpp:244]     Train net output #0: loss = 0.221011 (* 1 = 0.221011 loss)
I0429 10:03:00.129961  5145 sgd_solver.cpp:106] Iteration 81400, lr = 1e-12
I0429 10:03:51.894884  5145 solver.cpp:228] Iteration 81500, loss = 0.233644
I0429 10:03:51.895064  5145 solver.cpp:244]     Train net output #0: loss = 0.233644 (* 1 = 0.233644 loss)
I0429 10:03:51.895072  5145 sgd_solver.cpp:106] Iteration 81500, lr = 1e-12
I0429 10:04:42.357002  5145 solver.cpp:228] Iteration 81600, loss = 0.406259
I0429 10:04:42.357836  5145 solver.cpp:244]     Train net output #0: loss = 0.406259 (* 1 = 0.406259 loss)
I0429 10:04:42.357843  5145 sgd_solver.cpp:106] Iteration 81600, lr = 1e-12
I0429 10:05:32.927013  5145 solver.cpp:228] Iteration 81700, loss = 0.207074
I0429 10:05:32.927170  5145 solver.cpp:244]     Train net output #0: loss = 0.207074 (* 1 = 0.207074 loss)
I0429 10:05:32.927175  5145 sgd_solver.cpp:106] Iteration 81700, lr = 1e-12
I0429 10:06:25.007783  5145 solver.cpp:228] Iteration 81800, loss = 0.329373
I0429 10:06:25.007968  5145 solver.cpp:244]     Train net output #0: loss = 0.329373 (* 1 = 0.329373 loss)
I0429 10:06:25.007975  5145 sgd_solver.cpp:106] Iteration 81800, lr = 1e-12
I0429 10:07:15.417347  5145 solver.cpp:228] Iteration 81900, loss = 0.0261025
I0429 10:07:15.417544  5145 solver.cpp:244]     Train net output #0: loss = 0.0261025 (* 1 = 0.0261025 loss)
I0429 10:07:15.417554  5145 sgd_solver.cpp:106] Iteration 81900, lr = 1e-12
I0429 10:08:05.746260  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_82000.caffemodel
I0429 10:08:24.294818  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_82000.solverstate
I0429 10:08:24.490301  5145 solver.cpp:337] Iteration 82000, Testing net (#0)
I0429 10:08:24.490399  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 10:08:24.490404  5145 net.cpp:693] Ignoring source layer visualize
I0429 10:08:24.490406  5145 net.cpp:693] Ignoring source layer fake
I0429 10:13:20.154377  5145 solver.cpp:404]     Test net output #0: loss = 0.28042 (* 1 = 0.28042 loss)
I0429 10:13:20.467308  5145 solver.cpp:228] Iteration 82000, loss = 0.186714
I0429 10:13:20.467351  5145 solver.cpp:244]     Train net output #0: loss = 0.186714 (* 1 = 0.186714 loss)
I0429 10:13:20.467375  5145 sgd_solver.cpp:106] Iteration 82000, lr = 1e-12
I0429 10:14:12.608369  5145 solver.cpp:228] Iteration 82100, loss = 0.206394
I0429 10:14:12.608532  5145 solver.cpp:244]     Train net output #0: loss = 0.206394 (* 1 = 0.206394 loss)
I0429 10:14:12.608539  5145 sgd_solver.cpp:106] Iteration 82100, lr = 1e-12
I0429 10:15:03.080649  5145 solver.cpp:228] Iteration 82200, loss = 0.17511
I0429 10:15:03.080847  5145 solver.cpp:244]     Train net output #0: loss = 0.17511 (* 1 = 0.17511 loss)
I0429 10:15:03.080857  5145 sgd_solver.cpp:106] Iteration 82200, lr = 1e-12
I0429 10:15:53.624635  5145 solver.cpp:228] Iteration 82300, loss = 0.292485
I0429 10:15:53.624821  5145 solver.cpp:244]     Train net output #0: loss = 0.292485 (* 1 = 0.292485 loss)
I0429 10:15:53.624828  5145 sgd_solver.cpp:106] Iteration 82300, lr = 1e-12
I0429 10:16:46.000481  5145 solver.cpp:228] Iteration 82400, loss = 0.357694
I0429 10:16:46.000641  5145 solver.cpp:244]     Train net output #0: loss = 0.357694 (* 1 = 0.357694 loss)
I0429 10:16:46.000648  5145 sgd_solver.cpp:106] Iteration 82400, lr = 1e-12
I0429 10:17:36.479293  5145 solver.cpp:228] Iteration 82500, loss = 0.31106
I0429 10:17:36.479454  5145 solver.cpp:244]     Train net output #0: loss = 0.31106 (* 1 = 0.31106 loss)
I0429 10:17:36.479461  5145 sgd_solver.cpp:106] Iteration 82500, lr = 1e-13
I0429 10:18:27.041357  5145 solver.cpp:228] Iteration 82600, loss = 0.269205
I0429 10:18:27.041574  5145 solver.cpp:244]     Train net output #0: loss = 0.269205 (* 1 = 0.269205 loss)
I0429 10:18:27.041582  5145 sgd_solver.cpp:106] Iteration 82600, lr = 1e-13
I0429 10:19:17.618701  5145 solver.cpp:228] Iteration 82700, loss = 0.229797
I0429 10:19:17.618854  5145 solver.cpp:244]     Train net output #0: loss = 0.229797 (* 1 = 0.229797 loss)
I0429 10:19:17.618860  5145 sgd_solver.cpp:106] Iteration 82700, lr = 1e-13
I0429 10:20:10.147258  5145 solver.cpp:228] Iteration 82800, loss = 0.264742
I0429 10:20:10.147989  5145 solver.cpp:244]     Train net output #0: loss = 0.264742 (* 1 = 0.264742 loss)
I0429 10:20:10.147995  5145 sgd_solver.cpp:106] Iteration 82800, lr = 1e-13
I0429 10:21:00.634857  5145 solver.cpp:228] Iteration 82900, loss = 0.223157
I0429 10:21:00.635032  5145 solver.cpp:244]     Train net output #0: loss = 0.223157 (* 1 = 0.223157 loss)
I0429 10:21:00.635040  5145 sgd_solver.cpp:106] Iteration 82900, lr = 1e-13
I0429 10:21:50.815399  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_83000.caffemodel
I0429 10:22:00.855767  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_83000.solverstate
I0429 10:22:01.073421  5145 solver.cpp:337] Iteration 83000, Testing net (#0)
I0429 10:22:01.073509  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 10:22:01.073513  5145 net.cpp:693] Ignoring source layer visualize
I0429 10:22:01.073530  5145 net.cpp:693] Ignoring source layer fake
I0429 10:26:57.416754  5145 solver.cpp:404]     Test net output #0: loss = 0.288449 (* 1 = 0.288449 loss)
I0429 10:26:57.728260  5145 solver.cpp:228] Iteration 83000, loss = 0.232314
I0429 10:26:57.728299  5145 solver.cpp:244]     Train net output #0: loss = 0.232314 (* 1 = 0.232314 loss)
I0429 10:26:57.728307  5145 sgd_solver.cpp:106] Iteration 83000, lr = 1e-13
I0429 10:27:49.863863  5145 solver.cpp:228] Iteration 83100, loss = 0.239664
I0429 10:27:49.864043  5145 solver.cpp:244]     Train net output #0: loss = 0.239664 (* 1 = 0.239664 loss)
I0429 10:27:49.864050  5145 sgd_solver.cpp:106] Iteration 83100, lr = 1e-13
I0429 10:28:40.449976  5145 solver.cpp:228] Iteration 83200, loss = 0.231301
I0429 10:28:40.450168  5145 solver.cpp:244]     Train net output #0: loss = 0.231301 (* 1 = 0.231301 loss)
I0429 10:28:40.450176  5145 sgd_solver.cpp:106] Iteration 83200, lr = 1e-13
I0429 10:29:30.919431  5145 solver.cpp:228] Iteration 83300, loss = 0.34525
I0429 10:29:30.919586  5145 solver.cpp:244]     Train net output #0: loss = 0.34525 (* 1 = 0.34525 loss)
I0429 10:29:30.919595  5145 sgd_solver.cpp:106] Iteration 83300, lr = 1e-13
I0429 10:30:23.249974  5145 solver.cpp:228] Iteration 83400, loss = 0.250853
I0429 10:30:23.250154  5145 solver.cpp:244]     Train net output #0: loss = 0.250853 (* 1 = 0.250853 loss)
I0429 10:30:23.250164  5145 sgd_solver.cpp:106] Iteration 83400, lr = 1e-13
I0429 10:31:13.775174  5145 solver.cpp:228] Iteration 83500, loss = 0.227507
I0429 10:31:13.775341  5145 solver.cpp:244]     Train net output #0: loss = 0.227507 (* 1 = 0.227507 loss)
I0429 10:31:13.775347  5145 sgd_solver.cpp:106] Iteration 83500, lr = 1e-13
I0429 10:32:04.214920  5145 solver.cpp:228] Iteration 83600, loss = 0.177495
I0429 10:32:04.215102  5145 solver.cpp:244]     Train net output #0: loss = 0.177495 (* 1 = 0.177495 loss)
I0429 10:32:04.215111  5145 sgd_solver.cpp:106] Iteration 83600, lr = 1e-13
I0429 10:32:54.742647  5145 solver.cpp:228] Iteration 83700, loss = 0.253184
I0429 10:32:54.742804  5145 solver.cpp:244]     Train net output #0: loss = 0.253184 (* 1 = 0.253184 loss)
I0429 10:32:54.742810  5145 sgd_solver.cpp:106] Iteration 83700, lr = 1e-13
I0429 10:33:46.986407  5145 solver.cpp:228] Iteration 83800, loss = 0.268961
I0429 10:33:46.986578  5145 solver.cpp:244]     Train net output #0: loss = 0.268961 (* 1 = 0.268961 loss)
I0429 10:33:46.986584  5145 sgd_solver.cpp:106] Iteration 83800, lr = 1e-13
I0429 10:34:37.504279  5145 solver.cpp:228] Iteration 83900, loss = 0.232378
I0429 10:34:37.504441  5145 solver.cpp:244]     Train net output #0: loss = 0.232378 (* 1 = 0.232378 loss)
I0429 10:34:37.504448  5145 sgd_solver.cpp:106] Iteration 83900, lr = 1e-13
I0429 10:35:27.703820  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_84000.caffemodel
I0429 10:35:48.385535  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_84000.solverstate
I0429 10:35:48.580014  5145 solver.cpp:337] Iteration 84000, Testing net (#0)
I0429 10:35:48.580098  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 10:35:48.580102  5145 net.cpp:693] Ignoring source layer visualize
I0429 10:35:48.580104  5145 net.cpp:693] Ignoring source layer fake
I0429 10:40:44.798465  5145 solver.cpp:404]     Test net output #0: loss = 0.289082 (* 1 = 0.289082 loss)
I0429 10:40:45.109766  5145 solver.cpp:228] Iteration 84000, loss = 0.0477167
I0429 10:40:45.109822  5145 solver.cpp:244]     Train net output #0: loss = 0.0477167 (* 1 = 0.0477167 loss)
I0429 10:40:45.109830  5145 sgd_solver.cpp:106] Iteration 84000, lr = 1e-13
I0429 10:41:38.186403  5145 solver.cpp:228] Iteration 84100, loss = 0.143137
I0429 10:41:38.186566  5145 solver.cpp:244]     Train net output #0: loss = 0.143137 (* 1 = 0.143137 loss)
I0429 10:41:38.186574  5145 sgd_solver.cpp:106] Iteration 84100, lr = 1e-13
I0429 10:42:28.642272  5145 solver.cpp:228] Iteration 84200, loss = 0.319626
I0429 10:42:28.642447  5145 solver.cpp:244]     Train net output #0: loss = 0.319626 (* 1 = 0.319626 loss)
I0429 10:42:28.642454  5145 sgd_solver.cpp:106] Iteration 84200, lr = 1e-13
I0429 10:43:19.101836  5145 solver.cpp:228] Iteration 84300, loss = 0.169814
I0429 10:43:19.101995  5145 solver.cpp:244]     Train net output #0: loss = 0.169814 (* 1 = 0.169814 loss)
I0429 10:43:19.102002  5145 sgd_solver.cpp:106] Iteration 84300, lr = 1e-13
I0429 10:44:10.817909  5145 solver.cpp:228] Iteration 84400, loss = 0.230382
I0429 10:44:10.818819  5145 solver.cpp:244]     Train net output #0: loss = 0.230382 (* 1 = 0.230382 loss)
I0429 10:44:10.818826  5145 sgd_solver.cpp:106] Iteration 84400, lr = 1e-13
I0429 10:45:01.329689  5145 solver.cpp:228] Iteration 84500, loss = 0.218566
I0429 10:45:01.329839  5145 solver.cpp:244]     Train net output #0: loss = 0.218566 (* 1 = 0.218566 loss)
I0429 10:45:01.329846  5145 sgd_solver.cpp:106] Iteration 84500, lr = 1e-13
I0429 10:45:53.294936  5145 solver.cpp:228] Iteration 84600, loss = 0.300147
I0429 10:45:53.295130  5145 solver.cpp:244]     Train net output #0: loss = 0.300147 (* 1 = 0.300147 loss)
I0429 10:45:53.295137  5145 sgd_solver.cpp:106] Iteration 84600, lr = 1e-13
I0429 10:46:43.685259  5145 solver.cpp:228] Iteration 84700, loss = 0.360521
I0429 10:46:43.685470  5145 solver.cpp:244]     Train net output #0: loss = 0.360521 (* 1 = 0.360521 loss)
I0429 10:46:43.685479  5145 sgd_solver.cpp:106] Iteration 84700, lr = 1e-13
I0429 10:47:34.252754  5145 solver.cpp:228] Iteration 84800, loss = 0.32948
I0429 10:47:34.252918  5145 solver.cpp:244]     Train net output #0: loss = 0.32948 (* 1 = 0.32948 loss)
I0429 10:47:34.252926  5145 sgd_solver.cpp:106] Iteration 84800, lr = 1e-13
I0429 10:48:26.323798  5145 solver.cpp:228] Iteration 84900, loss = 0.298621
I0429 10:48:26.323981  5145 solver.cpp:244]     Train net output #0: loss = 0.298621 (* 1 = 0.298621 loss)
I0429 10:48:26.323988  5145 sgd_solver.cpp:106] Iteration 84900, lr = 1e-13
I0429 10:49:16.529748  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_85000.caffemodel
I0429 10:49:33.939795  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_85000.solverstate
I0429 10:49:34.130686  5145 solver.cpp:337] Iteration 85000, Testing net (#0)
I0429 10:49:34.130769  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 10:49:34.130774  5145 net.cpp:693] Ignoring source layer visualize
I0429 10:49:34.130791  5145 net.cpp:693] Ignoring source layer fake
I0429 10:54:30.915863  5145 solver.cpp:404]     Test net output #0: loss = 0.286178 (* 1 = 0.286178 loss)
I0429 10:54:31.230903  5145 solver.cpp:228] Iteration 85000, loss = 0.200274
I0429 10:54:31.230923  5145 solver.cpp:244]     Train net output #0: loss = 0.200274 (* 1 = 0.200274 loss)
I0429 10:54:31.230947  5145 sgd_solver.cpp:106] Iteration 85000, lr = 1e-13
I0429 10:55:21.772398  5145 solver.cpp:228] Iteration 85100, loss = 0.266007
I0429 10:55:21.772558  5145 solver.cpp:244]     Train net output #0: loss = 0.266007 (* 1 = 0.266007 loss)
I0429 10:55:21.772567  5145 sgd_solver.cpp:106] Iteration 85100, lr = 1e-13
I0429 10:56:14.029541  5145 solver.cpp:228] Iteration 85200, loss = 0.398369
I0429 10:56:14.029706  5145 solver.cpp:244]     Train net output #0: loss = 0.398369 (* 1 = 0.398369 loss)
I0429 10:56:14.029713  5145 sgd_solver.cpp:106] Iteration 85200, lr = 1e-13
I0429 10:57:04.584394  5145 solver.cpp:228] Iteration 85300, loss = 0.251148
I0429 10:57:04.586778  5145 solver.cpp:244]     Train net output #0: loss = 0.251148 (* 1 = 0.251148 loss)
I0429 10:57:04.586786  5145 sgd_solver.cpp:106] Iteration 85300, lr = 1e-13
I0429 10:57:55.114812  5145 solver.cpp:228] Iteration 85400, loss = 0.350503
I0429 10:57:55.114958  5145 solver.cpp:244]     Train net output #0: loss = 0.350503 (* 1 = 0.350503 loss)
I0429 10:57:55.114964  5145 sgd_solver.cpp:106] Iteration 85400, lr = 1e-13
I0429 10:58:47.992552  5145 solver.cpp:228] Iteration 85500, loss = 0.308001
I0429 10:58:47.992719  5145 solver.cpp:244]     Train net output #0: loss = 0.308001 (* 1 = 0.308001 loss)
I0429 10:58:47.992727  5145 sgd_solver.cpp:106] Iteration 85500, lr = 1e-13
I0429 10:59:38.423408  5145 solver.cpp:228] Iteration 85600, loss = 0.339668
I0429 10:59:38.423605  5145 solver.cpp:244]     Train net output #0: loss = 0.339668 (* 1 = 0.339668 loss)
I0429 10:59:38.423619  5145 sgd_solver.cpp:106] Iteration 85600, lr = 1e-13
I0429 11:00:28.986570  5145 solver.cpp:228] Iteration 85700, loss = 0.384153
I0429 11:00:28.986737  5145 solver.cpp:244]     Train net output #0: loss = 0.384153 (* 1 = 0.384153 loss)
I0429 11:00:28.986744  5145 sgd_solver.cpp:106] Iteration 85700, lr = 1e-13
I0429 11:01:19.513960  5145 solver.cpp:228] Iteration 85800, loss = 0.346322
I0429 11:01:19.514155  5145 solver.cpp:244]     Train net output #0: loss = 0.346322 (* 1 = 0.346322 loss)
I0429 11:01:19.514163  5145 sgd_solver.cpp:106] Iteration 85800, lr = 1e-13
I0429 11:02:11.796160  5145 solver.cpp:228] Iteration 85900, loss = 0.367188
I0429 11:02:11.796320  5145 solver.cpp:244]     Train net output #0: loss = 0.367188 (* 1 = 0.367188 loss)
I0429 11:02:11.796327  5145 sgd_solver.cpp:106] Iteration 85900, lr = 1e-13
I0429 11:03:01.962765  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_86000.caffemodel
I0429 11:03:53.920959  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_86000.solverstate
I0429 11:03:54.149037  5145 solver.cpp:337] Iteration 86000, Testing net (#0)
I0429 11:03:54.149139  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 11:03:54.149144  5145 net.cpp:693] Ignoring source layer visualize
I0429 11:03:54.149147  5145 net.cpp:693] Ignoring source layer fake
I0429 11:08:49.530457  5145 solver.cpp:404]     Test net output #0: loss = 0.282767 (* 1 = 0.282767 loss)
I0429 11:08:49.843704  5145 solver.cpp:228] Iteration 86000, loss = 0.473432
I0429 11:08:49.843756  5145 solver.cpp:244]     Train net output #0: loss = 0.473432 (* 1 = 0.473432 loss)
I0429 11:08:49.843763  5145 sgd_solver.cpp:106] Iteration 86000, lr = 1e-13
I0429 11:09:40.300173  5145 solver.cpp:228] Iteration 86100, loss = 0.202399
I0429 11:09:40.300338  5145 solver.cpp:244]     Train net output #0: loss = 0.202399 (* 1 = 0.202399 loss)
I0429 11:09:40.300344  5145 sgd_solver.cpp:106] Iteration 86100, lr = 1e-13
I0429 11:10:32.557612  5145 solver.cpp:228] Iteration 86200, loss = 0.3142
I0429 11:10:32.557759  5145 solver.cpp:244]     Train net output #0: loss = 0.3142 (* 1 = 0.3142 loss)
I0429 11:10:32.557766  5145 sgd_solver.cpp:106] Iteration 86200, lr = 1e-13
I0429 11:11:22.957170  5145 solver.cpp:228] Iteration 86300, loss = 0.231204
I0429 11:11:22.957382  5145 solver.cpp:244]     Train net output #0: loss = 0.231204 (* 1 = 0.231204 loss)
I0429 11:11:22.957391  5145 sgd_solver.cpp:106] Iteration 86300, lr = 1e-13
I0429 11:12:13.547617  5145 solver.cpp:228] Iteration 86400, loss = 0.264271
I0429 11:12:13.547807  5145 solver.cpp:244]     Train net output #0: loss = 0.264271 (* 1 = 0.264271 loss)
I0429 11:12:13.547814  5145 sgd_solver.cpp:106] Iteration 86400, lr = 1e-13
I0429 11:13:04.043467  5145 solver.cpp:228] Iteration 86500, loss = 0.233592
I0429 11:13:04.043651  5145 solver.cpp:244]     Train net output #0: loss = 0.233592 (* 1 = 0.233592 loss)
I0429 11:13:04.043658  5145 sgd_solver.cpp:106] Iteration 86500, lr = 1e-13
I0429 11:13:56.278858  5145 solver.cpp:228] Iteration 86600, loss = 0.217748
I0429 11:13:56.279032  5145 solver.cpp:244]     Train net output #0: loss = 0.217748 (* 1 = 0.217748 loss)
I0429 11:13:56.279040  5145 sgd_solver.cpp:106] Iteration 86600, lr = 1e-13
I0429 11:14:46.745107  5145 solver.cpp:228] Iteration 86700, loss = 0.300268
I0429 11:14:46.745249  5145 solver.cpp:244]     Train net output #0: loss = 0.300268 (* 1 = 0.300268 loss)
I0429 11:14:46.745255  5145 sgd_solver.cpp:106] Iteration 86700, lr = 1e-13
I0429 11:15:37.218116  5145 solver.cpp:228] Iteration 86800, loss = 0.213294
I0429 11:15:37.218266  5145 solver.cpp:244]     Train net output #0: loss = 0.213294 (* 1 = 0.213294 loss)
I0429 11:15:37.218272  5145 sgd_solver.cpp:106] Iteration 86800, lr = 1e-13
I0429 11:16:29.441570  5145 solver.cpp:228] Iteration 86900, loss = 0.201489
I0429 11:16:29.441723  5145 solver.cpp:244]     Train net output #0: loss = 0.201489 (* 1 = 0.201489 loss)
I0429 11:16:29.441730  5145 sgd_solver.cpp:106] Iteration 86900, lr = 1e-13
I0429 11:17:19.583222  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_87000.caffemodel
I0429 11:17:52.064365  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_87000.solverstate
I0429 11:17:52.311138  5145 solver.cpp:337] Iteration 87000, Testing net (#0)
I0429 11:17:52.311223  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 11:17:52.311228  5145 net.cpp:693] Ignoring source layer visualize
I0429 11:17:52.311245  5145 net.cpp:693] Ignoring source layer fake
I0429 11:22:47.848655  5145 solver.cpp:404]     Test net output #0: loss = 0.280851 (* 1 = 0.280851 loss)
I0429 11:22:48.161547  5145 solver.cpp:228] Iteration 87000, loss = 0.472176
I0429 11:22:48.161586  5145 solver.cpp:244]     Train net output #0: loss = 0.472176 (* 1 = 0.472176 loss)
I0429 11:22:48.161592  5145 sgd_solver.cpp:106] Iteration 87000, lr = 1e-13
I0429 11:23:38.715360  5145 solver.cpp:228] Iteration 87100, loss = 0.303973
I0429 11:23:38.715515  5145 solver.cpp:244]     Train net output #0: loss = 0.303973 (* 1 = 0.303973 loss)
I0429 11:23:38.715523  5145 sgd_solver.cpp:106] Iteration 87100, lr = 1e-13
I0429 11:24:31.630007  5145 solver.cpp:228] Iteration 87200, loss = 0.222142
I0429 11:24:31.630216  5145 solver.cpp:244]     Train net output #0: loss = 0.222142 (* 1 = 0.222142 loss)
I0429 11:24:31.630226  5145 sgd_solver.cpp:106] Iteration 87200, lr = 1e-13
I0429 11:25:22.045439  5145 solver.cpp:228] Iteration 87300, loss = 0.118136
I0429 11:25:22.045604  5145 solver.cpp:244]     Train net output #0: loss = 0.118136 (* 1 = 0.118136 loss)
I0429 11:25:22.045613  5145 sgd_solver.cpp:106] Iteration 87300, lr = 1e-13
I0429 11:26:12.455862  5145 solver.cpp:228] Iteration 87400, loss = 0.297113
I0429 11:26:12.456014  5145 solver.cpp:244]     Train net output #0: loss = 0.297113 (* 1 = 0.297113 loss)
I0429 11:26:12.456022  5145 sgd_solver.cpp:106] Iteration 87400, lr = 1e-13
I0429 11:27:04.515395  5145 solver.cpp:228] Iteration 87500, loss = 0.343817
I0429 11:27:04.515642  5145 solver.cpp:244]     Train net output #0: loss = 0.343817 (* 1 = 0.343817 loss)
I0429 11:27:04.515650  5145 sgd_solver.cpp:106] Iteration 87500, lr = 1e-13
I0429 11:27:55.073410  5145 solver.cpp:228] Iteration 87600, loss = 0.210951
I0429 11:27:55.073567  5145 solver.cpp:244]     Train net output #0: loss = 0.210951 (* 1 = 0.210951 loss)
I0429 11:27:55.073575  5145 sgd_solver.cpp:106] Iteration 87600, lr = 1e-13
I0429 11:28:45.562763  5145 solver.cpp:228] Iteration 87700, loss = 0.260633
I0429 11:28:45.562896  5145 solver.cpp:244]     Train net output #0: loss = 0.260633 (* 1 = 0.260633 loss)
I0429 11:28:45.562904  5145 sgd_solver.cpp:106] Iteration 87700, lr = 1e-13
I0429 11:29:37.874336  5145 solver.cpp:228] Iteration 87800, loss = 0.221075
I0429 11:29:37.874475  5145 solver.cpp:244]     Train net output #0: loss = 0.221075 (* 1 = 0.221075 loss)
I0429 11:29:37.874482  5145 sgd_solver.cpp:106] Iteration 87800, lr = 1e-13
I0429 11:30:28.304720  5145 solver.cpp:228] Iteration 87900, loss = 0.284324
I0429 11:30:28.304893  5145 solver.cpp:244]     Train net output #0: loss = 0.284324 (* 1 = 0.284324 loss)
I0429 11:30:28.304901  5145 sgd_solver.cpp:106] Iteration 87900, lr = 1e-13
I0429 11:31:20.842932  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_88000.caffemodel
I0429 11:31:29.925420  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_88000.solverstate
I0429 11:31:30.115900  5145 solver.cpp:337] Iteration 88000, Testing net (#0)
I0429 11:31:30.115986  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 11:31:30.115990  5145 net.cpp:693] Ignoring source layer visualize
I0429 11:31:30.116008  5145 net.cpp:693] Ignoring source layer fake
I0429 11:36:26.258082  5145 solver.cpp:404]     Test net output #0: loss = 0.289955 (* 1 = 0.289955 loss)
I0429 11:36:26.569912  5145 solver.cpp:228] Iteration 88000, loss = 0.24775
I0429 11:36:26.569950  5145 solver.cpp:244]     Train net output #0: loss = 0.24775 (* 1 = 0.24775 loss)
I0429 11:36:26.569962  5145 sgd_solver.cpp:106] Iteration 88000, lr = 1e-13
I0429 11:37:17.070447  5145 solver.cpp:228] Iteration 88100, loss = 0.452697
I0429 11:37:17.070631  5145 solver.cpp:244]     Train net output #0: loss = 0.452697 (* 1 = 0.452697 loss)
I0429 11:37:17.070638  5145 sgd_solver.cpp:106] Iteration 88100, lr = 1e-13
I0429 11:38:07.518860  5145 solver.cpp:228] Iteration 88200, loss = 0.139157
I0429 11:38:07.519073  5145 solver.cpp:244]     Train net output #0: loss = 0.139157 (* 1 = 0.139157 loss)
I0429 11:38:07.519083  5145 sgd_solver.cpp:106] Iteration 88200, lr = 1e-13
I0429 11:39:01.084293  5145 solver.cpp:228] Iteration 88300, loss = 0.313895
I0429 11:39:01.084460  5145 solver.cpp:244]     Train net output #0: loss = 0.313895 (* 1 = 0.313895 loss)
I0429 11:39:01.084467  5145 sgd_solver.cpp:106] Iteration 88300, lr = 1e-13
I0429 11:39:51.541107  5145 solver.cpp:228] Iteration 88400, loss = 0.289655
I0429 11:39:51.541290  5145 solver.cpp:244]     Train net output #0: loss = 0.289655 (* 1 = 0.289655 loss)
I0429 11:39:51.541301  5145 sgd_solver.cpp:106] Iteration 88400, lr = 1e-13
I0429 11:40:42.085469  5145 solver.cpp:228] Iteration 88500, loss = 0.171702
I0429 11:40:42.085647  5145 solver.cpp:244]     Train net output #0: loss = 0.171702 (* 1 = 0.171702 loss)
I0429 11:40:42.085654  5145 sgd_solver.cpp:106] Iteration 88500, lr = 1e-13
I0429 11:41:32.515085  5145 solver.cpp:228] Iteration 88600, loss = 0.369137
I0429 11:41:32.515260  5145 solver.cpp:244]     Train net output #0: loss = 0.369137 (* 1 = 0.369137 loss)
I0429 11:41:32.515267  5145 sgd_solver.cpp:106] Iteration 88600, lr = 1e-13
I0429 11:42:26.373488  5145 solver.cpp:228] Iteration 88700, loss = 0.322791
I0429 11:42:26.373656  5145 solver.cpp:244]     Train net output #0: loss = 0.322791 (* 1 = 0.322791 loss)
I0429 11:42:26.373663  5145 sgd_solver.cpp:106] Iteration 88700, lr = 1e-13
I0429 11:43:16.903223  5145 solver.cpp:228] Iteration 88800, loss = 0.209661
I0429 11:43:16.903384  5145 solver.cpp:244]     Train net output #0: loss = 0.209661 (* 1 = 0.209661 loss)
I0429 11:43:16.903393  5145 sgd_solver.cpp:106] Iteration 88800, lr = 1e-13
I0429 11:44:07.455700  5145 solver.cpp:228] Iteration 88900, loss = 0.271135
I0429 11:44:07.455878  5145 solver.cpp:244]     Train net output #0: loss = 0.271135 (* 1 = 0.271135 loss)
I0429 11:44:07.455886  5145 sgd_solver.cpp:106] Iteration 88900, lr = 1e-13
I0429 11:45:01.062023  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_89000.caffemodel
I0429 11:45:21.922441  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_89000.solverstate
I0429 11:45:22.112967  5145 solver.cpp:337] Iteration 89000, Testing net (#0)
I0429 11:45:22.113051  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 11:45:22.113070  5145 net.cpp:693] Ignoring source layer visualize
I0429 11:45:22.113072  5145 net.cpp:693] Ignoring source layer fake
I0429 11:50:18.152432  5145 solver.cpp:404]     Test net output #0: loss = 0.288137 (* 1 = 0.288137 loss)
I0429 11:50:18.463871  5145 solver.cpp:228] Iteration 89000, loss = 0.260113
I0429 11:50:18.463910  5145 solver.cpp:244]     Train net output #0: loss = 0.260113 (* 1 = 0.260113 loss)
I0429 11:50:18.463917  5145 sgd_solver.cpp:106] Iteration 89000, lr = 1e-13
I0429 11:51:09.138319  5145 solver.cpp:228] Iteration 89100, loss = 0.406233
I0429 11:51:09.138486  5145 solver.cpp:244]     Train net output #0: loss = 0.406233 (* 1 = 0.406233 loss)
I0429 11:51:09.138494  5145 sgd_solver.cpp:106] Iteration 89100, lr = 1e-13
I0429 11:51:59.609375  5145 solver.cpp:228] Iteration 89200, loss = 0.263307
I0429 11:51:59.609567  5145 solver.cpp:244]     Train net output #0: loss = 0.263307 (* 1 = 0.263307 loss)
I0429 11:51:59.609576  5145 sgd_solver.cpp:106] Iteration 89200, lr = 1e-13
I0429 11:52:52.940505  5145 solver.cpp:228] Iteration 89300, loss = 0.270745
I0429 11:52:52.940719  5145 solver.cpp:244]     Train net output #0: loss = 0.270745 (* 1 = 0.270745 loss)
I0429 11:52:52.940737  5145 sgd_solver.cpp:106] Iteration 89300, lr = 1e-13
I0429 11:53:43.237846  5145 solver.cpp:228] Iteration 89400, loss = 0.224995
I0429 11:53:43.238008  5145 solver.cpp:244]     Train net output #0: loss = 0.224995 (* 1 = 0.224995 loss)
I0429 11:53:43.238013  5145 sgd_solver.cpp:106] Iteration 89400, lr = 1e-13
I0429 11:54:33.739578  5145 solver.cpp:228] Iteration 89500, loss = 0.322927
I0429 11:54:33.739781  5145 solver.cpp:244]     Train net output #0: loss = 0.322927 (* 1 = 0.322927 loss)
I0429 11:54:33.739791  5145 sgd_solver.cpp:106] Iteration 89500, lr = 1e-13
I0429 11:55:24.130480  5145 solver.cpp:228] Iteration 89600, loss = 0.244289
I0429 11:55:24.130617  5145 solver.cpp:244]     Train net output #0: loss = 0.244289 (* 1 = 0.244289 loss)
I0429 11:55:24.130625  5145 sgd_solver.cpp:106] Iteration 89600, lr = 1e-13
I0429 11:56:16.862239  5145 solver.cpp:228] Iteration 89700, loss = 0.222984
I0429 11:56:16.862418  5145 solver.cpp:244]     Train net output #0: loss = 0.222984 (* 1 = 0.222984 loss)
I0429 11:56:16.862426  5145 sgd_solver.cpp:106] Iteration 89700, lr = 1e-13
I0429 11:57:07.392499  5145 solver.cpp:228] Iteration 89800, loss = 0.323812
I0429 11:57:07.392654  5145 solver.cpp:244]     Train net output #0: loss = 0.323812 (* 1 = 0.323812 loss)
I0429 11:57:07.392662  5145 sgd_solver.cpp:106] Iteration 89800, lr = 1e-13
I0429 11:57:57.888949  5145 solver.cpp:228] Iteration 89900, loss = 0.160034
I0429 11:57:57.889107  5145 solver.cpp:244]     Train net output #0: loss = 0.160034 (* 1 = 0.160034 loss)
I0429 11:57:57.889114  5145 sgd_solver.cpp:106] Iteration 89900, lr = 1e-13
I0429 11:58:52.029825  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_90000.caffemodel
I0429 11:59:04.598772  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_90000.solverstate
I0429 11:59:04.808395  5145 solver.cpp:337] Iteration 90000, Testing net (#0)
I0429 11:59:04.808482  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 11:59:04.808501  5145 net.cpp:693] Ignoring source layer visualize
I0429 11:59:04.808503  5145 net.cpp:693] Ignoring source layer fake
I0429 12:03:59.607115  5145 solver.cpp:404]     Test net output #0: loss = 0.285947 (* 1 = 0.285947 loss)
I0429 12:03:59.920251  5145 solver.cpp:228] Iteration 90000, loss = 0.195272
I0429 12:03:59.920274  5145 solver.cpp:244]     Train net output #0: loss = 0.195272 (* 1 = 0.195272 loss)
I0429 12:03:59.920295  5145 sgd_solver.cpp:106] Iteration 90000, lr = 1e-14
I0429 12:04:50.356940  5145 solver.cpp:228] Iteration 90100, loss = 0.265225
I0429 12:04:50.357100  5145 solver.cpp:244]     Train net output #0: loss = 0.265225 (* 1 = 0.265225 loss)
I0429 12:04:50.357107  5145 sgd_solver.cpp:106] Iteration 90100, lr = 1e-14
I0429 12:05:40.990728  5145 solver.cpp:228] Iteration 90200, loss = 0.189153
I0429 12:05:40.990895  5145 solver.cpp:244]     Train net output #0: loss = 0.189153 (* 1 = 0.189153 loss)
I0429 12:05:40.990903  5145 sgd_solver.cpp:106] Iteration 90200, lr = 1e-14
I0429 12:06:31.445808  5145 solver.cpp:228] Iteration 90300, loss = 0.245989
I0429 12:06:31.445956  5145 solver.cpp:244]     Train net output #0: loss = 0.245989 (* 1 = 0.245989 loss)
I0429 12:06:31.445962  5145 sgd_solver.cpp:106] Iteration 90300, lr = 1e-14
I0429 12:07:24.253841  5145 solver.cpp:228] Iteration 90400, loss = 0.234902
I0429 12:07:24.254006  5145 solver.cpp:244]     Train net output #0: loss = 0.234902 (* 1 = 0.234902 loss)
I0429 12:07:24.254014  5145 sgd_solver.cpp:106] Iteration 90400, lr = 1e-14
I0429 12:08:14.774571  5145 solver.cpp:228] Iteration 90500, loss = 0.127061
I0429 12:08:14.774732  5145 solver.cpp:244]     Train net output #0: loss = 0.127061 (* 1 = 0.127061 loss)
I0429 12:08:14.774739  5145 sgd_solver.cpp:106] Iteration 90500, lr = 1e-14
I0429 12:09:05.229382  5145 solver.cpp:228] Iteration 90600, loss = 0.631648
I0429 12:09:05.229562  5145 solver.cpp:244]     Train net output #0: loss = 0.631648 (* 1 = 0.631648 loss)
I0429 12:09:05.229569  5145 sgd_solver.cpp:106] Iteration 90600, lr = 1e-14
I0429 12:09:57.733573  5145 solver.cpp:228] Iteration 90700, loss = 0.309834
I0429 12:09:57.733711  5145 solver.cpp:244]     Train net output #0: loss = 0.309834 (* 1 = 0.309834 loss)
I0429 12:09:57.733718  5145 sgd_solver.cpp:106] Iteration 90700, lr = 1e-14
I0429 12:10:48.172312  5145 solver.cpp:228] Iteration 90800, loss = 0.205687
I0429 12:10:48.172475  5145 solver.cpp:244]     Train net output #0: loss = 0.205687 (* 1 = 0.205687 loss)
I0429 12:10:48.172482  5145 sgd_solver.cpp:106] Iteration 90800, lr = 1e-14
I0429 12:11:40.635947  5145 solver.cpp:228] Iteration 90900, loss = 0.215921
I0429 12:11:40.636114  5145 solver.cpp:244]     Train net output #0: loss = 0.215921 (* 1 = 0.215921 loss)
I0429 12:11:40.636121  5145 sgd_solver.cpp:106] Iteration 90900, lr = 1e-14
I0429 12:12:30.796754  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_91000.caffemodel
I0429 12:12:33.838970  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_91000.solverstate
I0429 12:12:34.034066  5145 solver.cpp:337] Iteration 91000, Testing net (#0)
I0429 12:12:34.034150  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 12:12:34.034169  5145 net.cpp:693] Ignoring source layer visualize
I0429 12:12:34.034173  5145 net.cpp:693] Ignoring source layer fake
I0429 12:17:29.909111  5145 solver.cpp:404]     Test net output #0: loss = 0.282059 (* 1 = 0.282059 loss)
I0429 12:17:30.220341  5145 solver.cpp:228] Iteration 91000, loss = 0.276604
I0429 12:17:30.220363  5145 solver.cpp:244]     Train net output #0: loss = 0.276604 (* 1 = 0.276604 loss)
I0429 12:17:30.220384  5145 sgd_solver.cpp:106] Iteration 91000, lr = 1e-14
I0429 12:18:20.649536  5145 solver.cpp:228] Iteration 91100, loss = 0.294063
I0429 12:18:20.649715  5145 solver.cpp:244]     Train net output #0: loss = 0.294063 (* 1 = 0.294063 loss)
I0429 12:18:20.649721  5145 sgd_solver.cpp:106] Iteration 91100, lr = 1e-14
I0429 12:19:13.348393  5145 solver.cpp:228] Iteration 91200, loss = 0.288655
I0429 12:19:13.348558  5145 solver.cpp:244]     Train net output #0: loss = 0.288655 (* 1 = 0.288655 loss)
I0429 12:19:13.348565  5145 sgd_solver.cpp:106] Iteration 91200, lr = 1e-14
I0429 12:20:03.842857  5145 solver.cpp:228] Iteration 91300, loss = 0.299036
I0429 12:20:03.843025  5145 solver.cpp:244]     Train net output #0: loss = 0.299036 (* 1 = 0.299036 loss)
I0429 12:20:03.843034  5145 sgd_solver.cpp:106] Iteration 91300, lr = 1e-14
I0429 12:20:54.246644  5145 solver.cpp:228] Iteration 91400, loss = 0.253591
I0429 12:20:54.246824  5145 solver.cpp:244]     Train net output #0: loss = 0.253591 (* 1 = 0.253591 loss)
I0429 12:20:54.246831  5145 sgd_solver.cpp:106] Iteration 91400, lr = 1e-14
I0429 12:21:49.637984  5145 solver.cpp:228] Iteration 91500, loss = 0.316448
I0429 12:21:49.638155  5145 solver.cpp:244]     Train net output #0: loss = 0.316448 (* 1 = 0.316448 loss)
I0429 12:21:49.638162  5145 sgd_solver.cpp:106] Iteration 91500, lr = 1e-14
I0429 12:22:39.976022  5145 solver.cpp:228] Iteration 91600, loss = 0.248067
I0429 12:22:39.976186  5145 solver.cpp:244]     Train net output #0: loss = 0.248067 (* 1 = 0.248067 loss)
I0429 12:22:39.976192  5145 sgd_solver.cpp:106] Iteration 91600, lr = 1e-14
I0429 12:23:30.404361  5145 solver.cpp:228] Iteration 91700, loss = 0.232758
I0429 12:23:30.404531  5145 solver.cpp:244]     Train net output #0: loss = 0.232758 (* 1 = 0.232758 loss)
I0429 12:23:30.404538  5145 sgd_solver.cpp:106] Iteration 91700, lr = 1e-14
I0429 12:24:26.529042  5145 solver.cpp:228] Iteration 91800, loss = 0.331313
I0429 12:24:26.529219  5145 solver.cpp:244]     Train net output #0: loss = 0.331313 (* 1 = 0.331313 loss)
I0429 12:24:26.529227  5145 sgd_solver.cpp:106] Iteration 91800, lr = 1e-14
I0429 12:25:16.875162  5145 solver.cpp:228] Iteration 91900, loss = 0.306089
I0429 12:25:16.875308  5145 solver.cpp:244]     Train net output #0: loss = 0.306089 (* 1 = 0.306089 loss)
I0429 12:25:16.875314  5145 sgd_solver.cpp:106] Iteration 91900, lr = 1e-14
I0429 12:26:06.952067  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_92000.caffemodel
I0429 12:26:14.997687  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_92000.solverstate
I0429 12:26:15.284709  5145 solver.cpp:337] Iteration 92000, Testing net (#0)
I0429 12:26:15.284809  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 12:26:15.284814  5145 net.cpp:693] Ignoring source layer visualize
I0429 12:26:15.284817  5145 net.cpp:693] Ignoring source layer fake
I0429 12:31:11.426542  5145 solver.cpp:404]     Test net output #0: loss = 0.281297 (* 1 = 0.281297 loss)
I0429 12:31:11.738332  5145 solver.cpp:228] Iteration 92000, loss = 0.392861
I0429 12:31:11.738353  5145 solver.cpp:244]     Train net output #0: loss = 0.392861 (* 1 = 0.392861 loss)
I0429 12:31:11.738378  5145 sgd_solver.cpp:106] Iteration 92000, lr = 1e-14
I0429 12:32:08.951644  5145 solver.cpp:228] Iteration 92100, loss = 0.256353
I0429 12:32:08.951807  5145 solver.cpp:244]     Train net output #0: loss = 0.256353 (* 1 = 0.256353 loss)
I0429 12:32:08.951814  5145 sgd_solver.cpp:106] Iteration 92100, lr = 1e-14
I0429 12:32:59.143438  5145 solver.cpp:228] Iteration 92200, loss = 0.226268
I0429 12:32:59.143604  5145 solver.cpp:244]     Train net output #0: loss = 0.226268 (* 1 = 0.226268 loss)
I0429 12:32:59.143612  5145 sgd_solver.cpp:106] Iteration 92200, lr = 1e-14
I0429 12:33:49.543762  5145 solver.cpp:228] Iteration 92300, loss = 0.22155
I0429 12:33:49.543906  5145 solver.cpp:244]     Train net output #0: loss = 0.22155 (* 1 = 0.22155 loss)
I0429 12:33:49.543913  5145 sgd_solver.cpp:106] Iteration 92300, lr = 1e-14
I0429 12:34:40.114399  5145 solver.cpp:228] Iteration 92400, loss = 0.342617
I0429 12:34:40.114565  5145 solver.cpp:244]     Train net output #0: loss = 0.342617 (* 1 = 0.342617 loss)
I0429 12:34:40.114573  5145 sgd_solver.cpp:106] Iteration 92400, lr = 1e-14
I0429 12:35:37.571081  5145 solver.cpp:228] Iteration 92500, loss = 0.374866
I0429 12:35:37.571244  5145 solver.cpp:244]     Train net output #0: loss = 0.374866 (* 1 = 0.374866 loss)
I0429 12:35:37.571250  5145 sgd_solver.cpp:106] Iteration 92500, lr = 1e-14
I0429 12:36:28.065183  5145 solver.cpp:228] Iteration 92600, loss = 0.32896
I0429 12:36:28.065335  5145 solver.cpp:244]     Train net output #0: loss = 0.32896 (* 1 = 0.32896 loss)
I0429 12:36:28.065341  5145 sgd_solver.cpp:106] Iteration 92600, lr = 1e-14
I0429 12:37:18.559367  5145 solver.cpp:228] Iteration 92700, loss = 0.194262
I0429 12:37:18.559526  5145 solver.cpp:244]     Train net output #0: loss = 0.194262 (* 1 = 0.194262 loss)
I0429 12:37:18.559533  5145 sgd_solver.cpp:106] Iteration 92700, lr = 1e-14
I0429 12:38:16.631270  5145 solver.cpp:228] Iteration 92800, loss = 0.205684
I0429 12:38:16.631428  5145 solver.cpp:244]     Train net output #0: loss = 0.205684 (* 1 = 0.205684 loss)
I0429 12:38:16.631436  5145 sgd_solver.cpp:106] Iteration 92800, lr = 1e-14
I0429 12:39:06.798794  5145 solver.cpp:228] Iteration 92900, loss = 0.235671
I0429 12:39:06.798957  5145 solver.cpp:244]     Train net output #0: loss = 0.235671 (* 1 = 0.235671 loss)
I0429 12:39:06.798964  5145 sgd_solver.cpp:106] Iteration 92900, lr = 1e-14
I0429 12:39:57.082396  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_93000.caffemodel
I0429 12:40:07.120090  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_93000.solverstate
I0429 12:40:07.315352  5145 solver.cpp:337] Iteration 93000, Testing net (#0)
I0429 12:40:07.315438  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 12:40:07.315441  5145 net.cpp:693] Ignoring source layer visualize
I0429 12:40:07.315459  5145 net.cpp:693] Ignoring source layer fake
I0429 12:45:03.473354  5145 solver.cpp:404]     Test net output #0: loss = 0.290855 (* 1 = 0.290855 loss)
I0429 12:45:03.788378  5145 solver.cpp:228] Iteration 93000, loss = 0.156948
I0429 12:45:03.788424  5145 solver.cpp:244]     Train net output #0: loss = 0.156948 (* 1 = 0.156948 loss)
I0429 12:45:03.788432  5145 sgd_solver.cpp:106] Iteration 93000, lr = 1e-14
I0429 12:46:04.831919  5145 solver.cpp:228] Iteration 93100, loss = 0.206728
I0429 12:46:04.832083  5145 solver.cpp:244]     Train net output #0: loss = 0.206728 (* 1 = 0.206728 loss)
I0429 12:46:04.832092  5145 sgd_solver.cpp:106] Iteration 93100, lr = 1e-14
I0429 12:46:54.692275  5145 solver.cpp:228] Iteration 93200, loss = 0.0484401
I0429 12:46:54.692423  5145 solver.cpp:244]     Train net output #0: loss = 0.0484401 (* 1 = 0.0484401 loss)
I0429 12:46:54.692430  5145 sgd_solver.cpp:106] Iteration 93200, lr = 1e-14
I0429 12:47:45.143926  5145 solver.cpp:228] Iteration 93300, loss = 0.195268
I0429 12:47:45.144101  5145 solver.cpp:244]     Train net output #0: loss = 0.195268 (* 1 = 0.195268 loss)
I0429 12:47:45.144109  5145 sgd_solver.cpp:106] Iteration 93300, lr = 1e-14
I0429 12:48:35.715646  5145 solver.cpp:228] Iteration 93400, loss = 0.199136
I0429 12:48:35.715797  5145 solver.cpp:244]     Train net output #0: loss = 0.199136 (* 1 = 0.199136 loss)
I0429 12:48:35.715804  5145 sgd_solver.cpp:106] Iteration 93400, lr = 1e-14
I0429 12:49:37.514984  5145 solver.cpp:228] Iteration 93500, loss = 0.351701
I0429 12:49:37.515223  5145 solver.cpp:244]     Train net output #0: loss = 0.351701 (* 1 = 0.351701 loss)
I0429 12:49:37.515241  5145 sgd_solver.cpp:106] Iteration 93500, lr = 1e-14
I0429 12:50:27.748257  5145 solver.cpp:228] Iteration 93600, loss = 0.181508
I0429 12:50:27.748420  5145 solver.cpp:244]     Train net output #0: loss = 0.181508 (* 1 = 0.181508 loss)
I0429 12:50:27.748426  5145 sgd_solver.cpp:106] Iteration 93600, lr = 1e-14
I0429 12:51:18.227296  5145 solver.cpp:228] Iteration 93700, loss = 0.185016
I0429 12:51:18.227470  5145 solver.cpp:244]     Train net output #0: loss = 0.185016 (* 1 = 0.185016 loss)
I0429 12:51:18.227478  5145 sgd_solver.cpp:106] Iteration 93700, lr = 1e-14
I0429 12:52:16.496312  5145 solver.cpp:228] Iteration 93800, loss = 0.25365
I0429 12:52:16.496479  5145 solver.cpp:244]     Train net output #0: loss = 0.25365 (* 1 = 0.25365 loss)
I0429 12:52:16.496485  5145 sgd_solver.cpp:106] Iteration 93800, lr = 1e-14
I0429 12:53:06.920784  5145 solver.cpp:228] Iteration 93900, loss = 0.22369
I0429 12:53:06.921624  5145 solver.cpp:244]     Train net output #0: loss = 0.22369 (* 1 = 0.22369 loss)
I0429 12:53:06.921643  5145 sgd_solver.cpp:106] Iteration 93900, lr = 1e-14
I0429 12:54:12.258970  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_94000.caffemodel
I0429 12:54:23.880697  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_94000.solverstate
I0429 12:54:24.068212  5145 solver.cpp:337] Iteration 94000, Testing net (#0)
I0429 12:54:24.068292  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 12:54:24.068296  5145 net.cpp:693] Ignoring source layer visualize
I0429 12:54:24.068298  5145 net.cpp:693] Ignoring source layer fake
I0429 12:59:19.639559  5145 solver.cpp:404]     Test net output #0: loss = 0.287333 (* 1 = 0.287333 loss)
I0429 12:59:19.951647  5145 solver.cpp:228] Iteration 94000, loss = 0.275572
I0429 12:59:19.951663  5145 solver.cpp:244]     Train net output #0: loss = 0.275572 (* 1 = 0.275572 loss)
I0429 12:59:19.951685  5145 sgd_solver.cpp:106] Iteration 94000, lr = 1e-14
I0429 13:00:10.561774  5145 solver.cpp:228] Iteration 94100, loss = 0.207389
I0429 13:00:10.562522  5145 solver.cpp:244]     Train net output #0: loss = 0.207389 (* 1 = 0.207389 loss)
I0429 13:00:10.562546  5145 sgd_solver.cpp:106] Iteration 94100, lr = 1e-14
I0429 13:01:01.011135  5145 solver.cpp:228] Iteration 94200, loss = 0.204987
I0429 13:01:01.011288  5145 solver.cpp:244]     Train net output #0: loss = 0.204987 (* 1 = 0.204987 loss)
I0429 13:01:01.011296  5145 sgd_solver.cpp:106] Iteration 94200, lr = 1e-14
I0429 13:02:05.253504  5145 solver.cpp:228] Iteration 94300, loss = 0.251204
I0429 13:02:05.253657  5145 solver.cpp:244]     Train net output #0: loss = 0.251204 (* 1 = 0.251204 loss)
I0429 13:02:05.253664  5145 sgd_solver.cpp:106] Iteration 94300, lr = 1e-14
I0429 13:02:55.515458  5145 solver.cpp:228] Iteration 94400, loss = 0.168243
I0429 13:02:55.515614  5145 solver.cpp:244]     Train net output #0: loss = 0.168243 (* 1 = 0.168243 loss)
I0429 13:02:55.515620  5145 sgd_solver.cpp:106] Iteration 94400, lr = 1e-14
I0429 13:03:46.091078  5145 solver.cpp:228] Iteration 94500, loss = 0.246749
I0429 13:03:46.091230  5145 solver.cpp:244]     Train net output #0: loss = 0.246749 (* 1 = 0.246749 loss)
I0429 13:03:46.091238  5145 sgd_solver.cpp:106] Iteration 94500, lr = 1e-14
I0429 13:04:53.366914  5145 solver.cpp:228] Iteration 94600, loss = 0.388036
I0429 13:04:53.367085  5145 solver.cpp:244]     Train net output #0: loss = 0.388036 (* 1 = 0.388036 loss)
I0429 13:04:53.367094  5145 sgd_solver.cpp:106] Iteration 94600, lr = 1e-14
I0429 13:05:43.641175  5145 solver.cpp:228] Iteration 94700, loss = 0.292627
I0429 13:05:43.641335  5145 solver.cpp:244]     Train net output #0: loss = 0.292627 (* 1 = 0.292627 loss)
I0429 13:05:43.641341  5145 sgd_solver.cpp:106] Iteration 94700, lr = 1e-14
I0429 13:06:34.284778  5145 solver.cpp:228] Iteration 94800, loss = 0.366849
I0429 13:06:34.284946  5145 solver.cpp:244]     Train net output #0: loss = 0.366849 (* 1 = 0.366849 loss)
I0429 13:06:34.284953  5145 sgd_solver.cpp:106] Iteration 94800, lr = 1e-14
I0429 13:07:42.707424  5145 solver.cpp:228] Iteration 94900, loss = 0.324541
I0429 13:07:42.707594  5145 solver.cpp:244]     Train net output #0: loss = 0.324541 (* 1 = 0.324541 loss)
I0429 13:07:42.707602  5145 sgd_solver.cpp:106] Iteration 94900, lr = 1e-14
I0429 13:08:32.366724  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_95000.caffemodel
I0429 13:08:44.063668  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_95000.solverstate
I0429 13:08:44.271381  5145 solver.cpp:337] Iteration 95000, Testing net (#0)
I0429 13:08:44.271467  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 13:08:44.271471  5145 net.cpp:693] Ignoring source layer visualize
I0429 13:08:44.271491  5145 net.cpp:693] Ignoring source layer fake
I0429 13:13:41.063326  5145 solver.cpp:404]     Test net output #0: loss = 0.28588 (* 1 = 0.28588 loss)
I0429 13:13:41.376783  5145 solver.cpp:228] Iteration 95000, loss = 0.220421
I0429 13:13:41.376803  5145 solver.cpp:244]     Train net output #0: loss = 0.220421 (* 1 = 0.220421 loss)
I0429 13:13:41.376827  5145 sgd_solver.cpp:106] Iteration 95000, lr = 1e-14
I0429 13:14:31.931509  5145 solver.cpp:228] Iteration 95100, loss = 0.187271
I0429 13:14:31.931668  5145 solver.cpp:244]     Train net output #0: loss = 0.187271 (* 1 = 0.187271 loss)
I0429 13:14:31.931675  5145 sgd_solver.cpp:106] Iteration 95100, lr = 1e-14
I0429 13:15:22.490382  5145 solver.cpp:228] Iteration 95200, loss = 0.277515
I0429 13:15:22.490531  5145 solver.cpp:244]     Train net output #0: loss = 0.277515 (* 1 = 0.277515 loss)
I0429 13:15:22.490537  5145 sgd_solver.cpp:106] Iteration 95200, lr = 1e-14
I0429 13:16:29.482316  5145 solver.cpp:228] Iteration 95300, loss = 0.391484
I0429 13:16:29.482471  5145 solver.cpp:244]     Train net output #0: loss = 0.391484 (* 1 = 0.391484 loss)
I0429 13:16:29.482480  5145 sgd_solver.cpp:106] Iteration 95300, lr = 1e-14
I0429 13:17:19.984016  5145 solver.cpp:228] Iteration 95400, loss = 0.305354
I0429 13:17:19.984171  5145 solver.cpp:244]     Train net output #0: loss = 0.305354 (* 1 = 0.305354 loss)
I0429 13:17:19.984179  5145 sgd_solver.cpp:106] Iteration 95400, lr = 1e-14
I0429 13:18:10.582013  5145 solver.cpp:228] Iteration 95500, loss = 0.242182
I0429 13:18:10.582443  5145 solver.cpp:244]     Train net output #0: loss = 0.242182 (* 1 = 0.242182 loss)
I0429 13:18:10.582450  5145 sgd_solver.cpp:106] Iteration 95500, lr = 1e-14
I0429 13:19:03.037271  5145 solver.cpp:228] Iteration 95600, loss = 0.269348
I0429 13:19:03.037431  5145 solver.cpp:244]     Train net output #0: loss = 0.269348 (* 1 = 0.269348 loss)
I0429 13:19:03.037451  5145 sgd_solver.cpp:106] Iteration 95600, lr = 1e-14
I0429 13:19:53.597818  5145 solver.cpp:228] Iteration 95700, loss = 0.230085
I0429 13:19:53.597980  5145 solver.cpp:244]     Train net output #0: loss = 0.230085 (* 1 = 0.230085 loss)
I0429 13:19:53.597988  5145 sgd_solver.cpp:106] Iteration 95700, lr = 1e-14
I0429 13:20:44.160989  5145 solver.cpp:228] Iteration 95800, loss = 0.209857
I0429 13:20:44.161159  5145 solver.cpp:244]     Train net output #0: loss = 0.209857 (* 1 = 0.209857 loss)
I0429 13:20:44.161165  5145 sgd_solver.cpp:106] Iteration 95800, lr = 1e-14
I0429 13:21:36.537713  5145 solver.cpp:228] Iteration 95900, loss = 0.184409
I0429 13:21:36.537914  5145 solver.cpp:244]     Train net output #0: loss = 0.184409 (* 1 = 0.184409 loss)
I0429 13:21:36.537922  5145 sgd_solver.cpp:106] Iteration 95900, lr = 1e-14
I0429 13:22:26.632676  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_96000.caffemodel
I0429 13:22:44.667984  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_96000.solverstate
I0429 13:22:44.860234  5145 solver.cpp:337] Iteration 96000, Testing net (#0)
I0429 13:22:44.860321  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 13:22:44.860340  5145 net.cpp:693] Ignoring source layer visualize
I0429 13:22:44.860343  5145 net.cpp:693] Ignoring source layer fake
I0429 13:27:40.967259  5145 solver.cpp:404]     Test net output #0: loss = 0.281531 (* 1 = 0.281531 loss)
I0429 13:27:41.277770  5145 solver.cpp:228] Iteration 96000, loss = 0.236849
I0429 13:27:41.277806  5145 solver.cpp:244]     Train net output #0: loss = 0.236849 (* 1 = 0.236849 loss)
I0429 13:27:41.277813  5145 sgd_solver.cpp:106] Iteration 96000, lr = 1e-14
I0429 13:28:31.875744  5145 solver.cpp:228] Iteration 96100, loss = 0.264978
I0429 13:28:31.875911  5145 solver.cpp:244]     Train net output #0: loss = 0.264978 (* 1 = 0.264978 loss)
I0429 13:28:31.875919  5145 sgd_solver.cpp:106] Iteration 96100, lr = 1e-14
I0429 13:29:22.343943  5145 solver.cpp:228] Iteration 96200, loss = 0.237041
I0429 13:29:22.344110  5145 solver.cpp:244]     Train net output #0: loss = 0.237041 (* 1 = 0.237041 loss)
I0429 13:29:22.344117  5145 sgd_solver.cpp:106] Iteration 96200, lr = 1e-14
I0429 13:30:14.817574  5145 solver.cpp:228] Iteration 96300, loss = 0.0949649
I0429 13:30:14.817739  5145 solver.cpp:244]     Train net output #0: loss = 0.0949649 (* 1 = 0.0949649 loss)
I0429 13:30:14.817747  5145 sgd_solver.cpp:106] Iteration 96300, lr = 1e-14
I0429 13:31:05.298483  5145 solver.cpp:228] Iteration 96400, loss = 0.206956
I0429 13:31:05.298656  5145 solver.cpp:244]     Train net output #0: loss = 0.206956 (* 1 = 0.206956 loss)
I0429 13:31:05.298665  5145 sgd_solver.cpp:106] Iteration 96400, lr = 1e-14
I0429 13:31:55.741490  5145 solver.cpp:228] Iteration 96500, loss = 0.243228
I0429 13:31:55.741674  5145 solver.cpp:244]     Train net output #0: loss = 0.243228 (* 1 = 0.243228 loss)
I0429 13:31:55.741681  5145 sgd_solver.cpp:106] Iteration 96500, lr = 1e-14
I0429 13:32:47.914335  5145 solver.cpp:228] Iteration 96600, loss = 0.239172
I0429 13:32:47.914520  5145 solver.cpp:244]     Train net output #0: loss = 0.239172 (* 1 = 0.239172 loss)
I0429 13:32:47.914527  5145 sgd_solver.cpp:106] Iteration 96600, lr = 1e-14
I0429 13:33:38.467651  5145 solver.cpp:228] Iteration 96700, loss = 0.684103
I0429 13:33:38.467831  5145 solver.cpp:244]     Train net output #0: loss = 0.684103 (* 1 = 0.684103 loss)
I0429 13:33:38.467839  5145 sgd_solver.cpp:106] Iteration 96700, lr = 1e-14
I0429 13:34:28.950994  5145 solver.cpp:228] Iteration 96800, loss = 0.27875
I0429 13:34:28.951156  5145 solver.cpp:244]     Train net output #0: loss = 0.27875 (* 1 = 0.27875 loss)
I0429 13:34:28.951164  5145 sgd_solver.cpp:106] Iteration 96800, lr = 1e-14
I0429 13:35:21.109472  5145 solver.cpp:228] Iteration 96900, loss = 0.38978
I0429 13:35:21.109628  5145 solver.cpp:244]     Train net output #0: loss = 0.38978 (* 1 = 0.38978 loss)
I0429 13:35:21.109635  5145 sgd_solver.cpp:106] Iteration 96900, lr = 1e-14
I0429 13:36:11.185169  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_97000.caffemodel
I0429 13:36:19.734436  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_97000.solverstate
I0429 13:36:19.927376  5145 solver.cpp:337] Iteration 97000, Testing net (#0)
I0429 13:36:19.927462  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 13:36:19.927482  5145 net.cpp:693] Ignoring source layer visualize
I0429 13:36:19.927484  5145 net.cpp:693] Ignoring source layer fake
I0429 13:41:15.833555  5145 solver.cpp:404]     Test net output #0: loss = 0.281732 (* 1 = 0.281732 loss)
I0429 13:41:16.151764  5145 solver.cpp:228] Iteration 97000, loss = 0.242522
I0429 13:41:16.151783  5145 solver.cpp:244]     Train net output #0: loss = 0.242522 (* 1 = 0.242522 loss)
I0429 13:41:16.151805  5145 sgd_solver.cpp:106] Iteration 97000, lr = 1e-14
I0429 13:42:11.248193  5145 solver.cpp:228] Iteration 97100, loss = 0.201048
I0429 13:42:11.248355  5145 solver.cpp:244]     Train net output #0: loss = 0.201048 (* 1 = 0.201048 loss)
I0429 13:42:11.248363  5145 sgd_solver.cpp:106] Iteration 97100, lr = 1e-14
I0429 13:43:01.513816  5145 solver.cpp:228] Iteration 97200, loss = 0.20203
I0429 13:43:01.514005  5145 solver.cpp:244]     Train net output #0: loss = 0.20203 (* 1 = 0.20203 loss)
I0429 13:43:01.514014  5145 sgd_solver.cpp:106] Iteration 97200, lr = 1e-14
I0429 13:43:51.941685  5145 solver.cpp:228] Iteration 97300, loss = 0.235567
I0429 13:43:51.944053  5145 solver.cpp:244]     Train net output #0: loss = 0.235567 (* 1 = 0.235567 loss)
I0429 13:43:51.944072  5145 sgd_solver.cpp:106] Iteration 97300, lr = 1e-14
I0429 13:44:45.032160  5145 solver.cpp:228] Iteration 97400, loss = 0.189191
I0429 13:44:45.032330  5145 solver.cpp:244]     Train net output #0: loss = 0.189191 (* 1 = 0.189191 loss)
I0429 13:44:45.032337  5145 sgd_solver.cpp:106] Iteration 97400, lr = 1e-14
I0429 13:45:35.565547  5145 solver.cpp:228] Iteration 97500, loss = 0.30641
I0429 13:45:35.565701  5145 solver.cpp:244]     Train net output #0: loss = 0.30641 (* 1 = 0.30641 loss)
I0429 13:45:35.565709  5145 sgd_solver.cpp:106] Iteration 97500, lr = 1e-15
I0429 13:46:26.157538  5145 solver.cpp:228] Iteration 97600, loss = 0.310848
I0429 13:46:26.157708  5145 solver.cpp:244]     Train net output #0: loss = 0.310848 (* 1 = 0.310848 loss)
I0429 13:46:26.157716  5145 sgd_solver.cpp:106] Iteration 97600, lr = 1e-15
I0429 13:47:20.149307  5145 solver.cpp:228] Iteration 97700, loss = 0.220315
I0429 13:47:20.149484  5145 solver.cpp:244]     Train net output #0: loss = 0.220315 (* 1 = 0.220315 loss)
I0429 13:47:20.149492  5145 sgd_solver.cpp:106] Iteration 97700, lr = 1e-15
I0429 13:48:10.532867  5145 solver.cpp:228] Iteration 97800, loss = 0.351026
I0429 13:48:10.533038  5145 solver.cpp:244]     Train net output #0: loss = 0.351026 (* 1 = 0.351026 loss)
I0429 13:48:10.533044  5145 sgd_solver.cpp:106] Iteration 97800, lr = 1e-15
I0429 13:49:00.951673  5145 solver.cpp:228] Iteration 97900, loss = 0.418772
I0429 13:49:00.951834  5145 solver.cpp:244]     Train net output #0: loss = 0.418772 (* 1 = 0.418772 loss)
I0429 13:49:00.951841  5145 sgd_solver.cpp:106] Iteration 97900, lr = 1e-15
I0429 13:49:54.933568  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_98000.caffemodel
I0429 13:50:08.956485  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_98000.solverstate
I0429 13:50:09.151520  5145 solver.cpp:337] Iteration 98000, Testing net (#0)
I0429 13:50:09.151603  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 13:50:09.151623  5145 net.cpp:693] Ignoring source layer visualize
I0429 13:50:09.151624  5145 net.cpp:693] Ignoring source layer fake
I0429 13:55:04.692853  5145 solver.cpp:404]     Test net output #0: loss = 0.290629 (* 1 = 0.290629 loss)
I0429 13:55:05.006664  5145 solver.cpp:228] Iteration 98000, loss = 0.238242
I0429 13:55:05.006703  5145 solver.cpp:244]     Train net output #0: loss = 0.238242 (* 1 = 0.238242 loss)
I0429 13:55:05.006711  5145 sgd_solver.cpp:106] Iteration 98000, lr = 1e-15
I0429 13:55:55.503065  5145 solver.cpp:228] Iteration 98100, loss = 0.366668
I0429 13:55:55.503259  5145 solver.cpp:244]     Train net output #0: loss = 0.366668 (* 1 = 0.366668 loss)
I0429 13:55:55.503267  5145 sgd_solver.cpp:106] Iteration 98100, lr = 1e-15
I0429 13:56:45.974824  5145 solver.cpp:228] Iteration 98200, loss = 0.208799
I0429 13:56:45.974994  5145 solver.cpp:244]     Train net output #0: loss = 0.208799 (* 1 = 0.208799 loss)
I0429 13:56:45.975003  5145 sgd_solver.cpp:106] Iteration 98200, lr = 1e-15
I0429 13:57:36.572258  5145 solver.cpp:228] Iteration 98300, loss = 0.257956
I0429 13:57:36.572410  5145 solver.cpp:244]     Train net output #0: loss = 0.257956 (* 1 = 0.257956 loss)
I0429 13:57:36.572417  5145 sgd_solver.cpp:106] Iteration 98300, lr = 1e-15
I0429 13:58:30.033203  5145 solver.cpp:228] Iteration 98400, loss = 0.261312
I0429 13:58:30.033354  5145 solver.cpp:244]     Train net output #0: loss = 0.261312 (* 1 = 0.261312 loss)
I0429 13:58:30.033360  5145 sgd_solver.cpp:106] Iteration 98400, lr = 1e-15
I0429 13:59:20.522308  5145 solver.cpp:228] Iteration 98500, loss = 0.196613
I0429 13:59:20.522482  5145 solver.cpp:244]     Train net output #0: loss = 0.196613 (* 1 = 0.196613 loss)
I0429 13:59:20.522490  5145 sgd_solver.cpp:106] Iteration 98500, lr = 1e-15
I0429 14:00:11.064589  5145 solver.cpp:228] Iteration 98600, loss = 0.362599
I0429 14:00:11.066577  5145 solver.cpp:244]     Train net output #0: loss = 0.362599 (* 1 = 0.362599 loss)
I0429 14:00:11.066586  5145 sgd_solver.cpp:106] Iteration 98600, lr = 1e-15
I0429 14:01:06.574990  5145 solver.cpp:228] Iteration 98700, loss = 0.329213
I0429 14:01:06.575152  5145 solver.cpp:244]     Train net output #0: loss = 0.329213 (* 1 = 0.329213 loss)
I0429 14:01:06.575160  5145 sgd_solver.cpp:106] Iteration 98700, lr = 1e-15
I0429 14:01:56.912251  5145 solver.cpp:228] Iteration 98800, loss = 0.295289
I0429 14:01:56.913624  5145 solver.cpp:244]     Train net output #0: loss = 0.295289 (* 1 = 0.295289 loss)
I0429 14:01:56.913630  5145 sgd_solver.cpp:106] Iteration 98800, lr = 1e-15
I0429 14:02:47.421442  5145 solver.cpp:228] Iteration 98900, loss = 0.298266
I0429 14:02:47.421604  5145 solver.cpp:244]     Train net output #0: loss = 0.298266 (* 1 = 0.298266 loss)
I0429 14:02:47.421612  5145 sgd_solver.cpp:106] Iteration 98900, lr = 1e-15
I0429 14:03:37.585839  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_99000.caffemodel
I0429 14:03:48.243011  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_99000.solverstate
I0429 14:03:48.448474  5145 solver.cpp:337] Iteration 99000, Testing net (#0)
I0429 14:03:48.448555  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 14:03:48.448575  5145 net.cpp:693] Ignoring source layer visualize
I0429 14:03:48.448578  5145 net.cpp:693] Ignoring source layer fake
I0429 14:08:43.952900  5145 solver.cpp:404]     Test net output #0: loss = 0.287564 (* 1 = 0.287564 loss)
I0429 14:08:44.264363  5145 solver.cpp:228] Iteration 99000, loss = 0.296888
I0429 14:08:44.264382  5145 solver.cpp:244]     Train net output #0: loss = 0.296888 (* 1 = 0.296888 loss)
I0429 14:08:44.264405  5145 sgd_solver.cpp:106] Iteration 99000, lr = 1e-15
I0429 14:09:38.688019  5145 solver.cpp:228] Iteration 99100, loss = 0.161981
I0429 14:09:38.688211  5145 solver.cpp:244]     Train net output #0: loss = 0.161981 (* 1 = 0.161981 loss)
I0429 14:09:38.688220  5145 sgd_solver.cpp:106] Iteration 99100, lr = 1e-15
I0429 14:10:29.121565  5145 solver.cpp:228] Iteration 99200, loss = 0.312327
I0429 14:10:29.121726  5145 solver.cpp:244]     Train net output #0: loss = 0.312327 (* 1 = 0.312327 loss)
I0429 14:10:29.121732  5145 sgd_solver.cpp:106] Iteration 99200, lr = 1e-15
I0429 14:11:19.648326  5145 solver.cpp:228] Iteration 99300, loss = 0.261276
I0429 14:11:19.648505  5145 solver.cpp:244]     Train net output #0: loss = 0.261276 (* 1 = 0.261276 loss)
I0429 14:11:19.648512  5145 sgd_solver.cpp:106] Iteration 99300, lr = 1e-15
I0429 14:12:12.445974  5145 solver.cpp:228] Iteration 99400, loss = 0.213817
I0429 14:12:12.446149  5145 solver.cpp:244]     Train net output #0: loss = 0.213817 (* 1 = 0.213817 loss)
I0429 14:12:12.446158  5145 sgd_solver.cpp:106] Iteration 99400, lr = 1e-15
I0429 14:13:03.073969  5145 solver.cpp:228] Iteration 99500, loss = 0.263292
I0429 14:13:03.074139  5145 solver.cpp:244]     Train net output #0: loss = 0.263292 (* 1 = 0.263292 loss)
I0429 14:13:03.074146  5145 sgd_solver.cpp:106] Iteration 99500, lr = 1e-15
I0429 14:13:53.561661  5145 solver.cpp:228] Iteration 99600, loss = 0.207172
I0429 14:13:53.561818  5145 solver.cpp:244]     Train net output #0: loss = 0.207172 (* 1 = 0.207172 loss)
I0429 14:13:53.561825  5145 sgd_solver.cpp:106] Iteration 99600, lr = 1e-15
I0429 14:14:46.137913  5145 solver.cpp:228] Iteration 99700, loss = 0.211367
I0429 14:14:46.138113  5145 solver.cpp:244]     Train net output #0: loss = 0.211367 (* 1 = 0.211367 loss)
I0429 14:14:46.138123  5145 sgd_solver.cpp:106] Iteration 99700, lr = 1e-15
I0429 14:15:36.604192  5145 solver.cpp:228] Iteration 99800, loss = 0.141049
I0429 14:15:36.604375  5145 solver.cpp:244]     Train net output #0: loss = 0.141049 (* 1 = 0.141049 loss)
I0429 14:15:36.604383  5145 sgd_solver.cpp:106] Iteration 99800, lr = 1e-15
I0429 14:16:27.067595  5145 solver.cpp:228] Iteration 99900, loss = 0.58599
I0429 14:16:27.067754  5145 solver.cpp:244]     Train net output #0: loss = 0.58599 (* 1 = 0.58599 loss)
I0429 14:16:27.067760  5145 sgd_solver.cpp:106] Iteration 99900, lr = 1e-15
I0429 14:17:18.362403  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_100000.caffemodel
I0429 14:17:45.003448  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_100000.solverstate
I0429 14:17:45.193511  5145 solver.cpp:337] Iteration 100000, Testing net (#0)
I0429 14:17:45.193595  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 14:17:45.193601  5145 net.cpp:693] Ignoring source layer visualize
I0429 14:17:45.193604  5145 net.cpp:693] Ignoring source layer fake
I0429 14:22:40.612576  5145 solver.cpp:404]     Test net output #0: loss = 0.286028 (* 1 = 0.286028 loss)
I0429 14:22:40.925096  5145 solver.cpp:228] Iteration 100000, loss = 0.279557
I0429 14:22:40.925117  5145 solver.cpp:244]     Train net output #0: loss = 0.279557 (* 1 = 0.279557 loss)
I0429 14:22:40.925138  5145 sgd_solver.cpp:106] Iteration 100000, lr = 1e-15
I0429 14:23:31.520608  5145 solver.cpp:228] Iteration 100100, loss = 0.154849
I0429 14:23:31.520778  5145 solver.cpp:244]     Train net output #0: loss = 0.154849 (* 1 = 0.154849 loss)
I0429 14:23:31.520786  5145 sgd_solver.cpp:106] Iteration 100100, lr = 1e-15
I0429 14:24:22.055640  5145 solver.cpp:228] Iteration 100200, loss = 0.281447
I0429 14:24:22.059132  5145 solver.cpp:244]     Train net output #0: loss = 0.281447 (* 1 = 0.281447 loss)
I0429 14:24:22.059139  5145 sgd_solver.cpp:106] Iteration 100200, lr = 1e-15
I0429 14:25:14.888242  5145 solver.cpp:228] Iteration 100300, loss = 0.243387
I0429 14:25:14.888417  5145 solver.cpp:244]     Train net output #0: loss = 0.243387 (* 1 = 0.243387 loss)
I0429 14:25:14.888423  5145 sgd_solver.cpp:106] Iteration 100300, lr = 1e-15
I0429 14:26:05.420594  5145 solver.cpp:228] Iteration 100400, loss = 0.209224
I0429 14:26:05.420752  5145 solver.cpp:244]     Train net output #0: loss = 0.209224 (* 1 = 0.209224 loss)
I0429 14:26:05.420758  5145 sgd_solver.cpp:106] Iteration 100400, lr = 1e-15
I0429 14:26:57.612742  5145 solver.cpp:228] Iteration 100500, loss = 0.226627
I0429 14:26:57.612887  5145 solver.cpp:244]     Train net output #0: loss = 0.226627 (* 1 = 0.226627 loss)
I0429 14:26:57.612895  5145 sgd_solver.cpp:106] Iteration 100500, lr = 1e-15
I0429 14:27:48.040370  5145 solver.cpp:228] Iteration 100600, loss = 0.27143
I0429 14:27:48.040524  5145 solver.cpp:244]     Train net output #0: loss = 0.27143 (* 1 = 0.27143 loss)
I0429 14:27:48.040531  5145 sgd_solver.cpp:106] Iteration 100600, lr = 1e-15
I0429 14:28:38.552786  5145 solver.cpp:228] Iteration 100700, loss = 0.253437
I0429 14:28:38.552964  5145 solver.cpp:244]     Train net output #0: loss = 0.253437 (* 1 = 0.253437 loss)
I0429 14:28:38.552973  5145 sgd_solver.cpp:106] Iteration 100700, lr = 1e-15
I0429 14:29:30.901386  5145 solver.cpp:228] Iteration 100800, loss = 0.293306
I0429 14:29:30.901772  5145 solver.cpp:244]     Train net output #0: loss = 0.293306 (* 1 = 0.293306 loss)
I0429 14:29:30.901780  5145 sgd_solver.cpp:106] Iteration 100800, lr = 1e-15
I0429 14:30:21.271210  5145 solver.cpp:228] Iteration 100900, loss = 0.0891983
I0429 14:30:21.271383  5145 solver.cpp:244]     Train net output #0: loss = 0.0891983 (* 1 = 0.0891983 loss)
I0429 14:30:21.271389  5145 sgd_solver.cpp:106] Iteration 100900, lr = 1e-15
I0429 14:31:11.398519  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_101000.caffemodel
I0429 14:31:39.101512  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_101000.solverstate
I0429 14:31:39.300860  5145 solver.cpp:337] Iteration 101000, Testing net (#0)
I0429 14:31:39.300963  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 14:31:39.300969  5145 net.cpp:693] Ignoring source layer visualize
I0429 14:31:39.300972  5145 net.cpp:693] Ignoring source layer fake
I0429 14:36:35.414194  5145 solver.cpp:404]     Test net output #0: loss = 0.281148 (* 1 = 0.281148 loss)
I0429 14:36:35.728296  5145 solver.cpp:228] Iteration 101000, loss = 0.316592
I0429 14:36:35.728315  5145 solver.cpp:244]     Train net output #0: loss = 0.316592 (* 1 = 0.316592 loss)
I0429 14:36:35.728338  5145 sgd_solver.cpp:106] Iteration 101000, lr = 1e-15
I0429 14:37:26.308241  5145 solver.cpp:228] Iteration 101100, loss = 0.258339
I0429 14:37:26.308398  5145 solver.cpp:244]     Train net output #0: loss = 0.258339 (* 1 = 0.258339 loss)
I0429 14:37:26.308405  5145 sgd_solver.cpp:106] Iteration 101100, lr = 1e-15
I0429 14:38:18.693918  5145 solver.cpp:228] Iteration 101200, loss = 0.253099
I0429 14:38:18.694097  5145 solver.cpp:244]     Train net output #0: loss = 0.253099 (* 1 = 0.253099 loss)
I0429 14:38:18.694105  5145 sgd_solver.cpp:106] Iteration 101200, lr = 1e-15
I0429 14:39:09.262851  5145 solver.cpp:228] Iteration 101300, loss = 0.191169
I0429 14:39:09.264297  5145 solver.cpp:244]     Train net output #0: loss = 0.191169 (* 1 = 0.191169 loss)
I0429 14:39:09.264304  5145 sgd_solver.cpp:106] Iteration 101300, lr = 1e-15
I0429 14:39:59.794600  5145 solver.cpp:228] Iteration 101400, loss = 0.243589
I0429 14:39:59.794792  5145 solver.cpp:244]     Train net output #0: loss = 0.243589 (* 1 = 0.243589 loss)
I0429 14:39:59.794800  5145 sgd_solver.cpp:106] Iteration 101400, lr = 1e-15
I0429 14:40:52.152797  5145 solver.cpp:228] Iteration 101500, loss = 0.34907
I0429 14:40:52.152966  5145 solver.cpp:244]     Train net output #0: loss = 0.34907 (* 1 = 0.34907 loss)
I0429 14:40:52.152973  5145 sgd_solver.cpp:106] Iteration 101500, lr = 1e-15
I0429 14:41:42.759443  5145 solver.cpp:228] Iteration 101600, loss = 0.365347
I0429 14:41:42.759645  5145 solver.cpp:244]     Train net output #0: loss = 0.365347 (* 1 = 0.365347 loss)
I0429 14:41:42.759654  5145 sgd_solver.cpp:106] Iteration 101600, lr = 1e-15
I0429 14:42:33.252468  5145 solver.cpp:228] Iteration 101700, loss = 0.19334
I0429 14:42:33.252627  5145 solver.cpp:244]     Train net output #0: loss = 0.19334 (* 1 = 0.19334 loss)
I0429 14:42:33.252635  5145 sgd_solver.cpp:106] Iteration 101700, lr = 1e-15
I0429 14:43:25.574638  5145 solver.cpp:228] Iteration 101800, loss = 0.30081
I0429 14:43:25.574813  5145 solver.cpp:244]     Train net output #0: loss = 0.30081 (* 1 = 0.30081 loss)
I0429 14:43:25.574822  5145 sgd_solver.cpp:106] Iteration 101800, lr = 1e-15
I0429 14:44:15.814374  5145 solver.cpp:228] Iteration 101900, loss = 0.179086
I0429 14:44:15.814543  5145 solver.cpp:244]     Train net output #0: loss = 0.179086 (* 1 = 0.179086 loss)
I0429 14:44:15.814550  5145 sgd_solver.cpp:106] Iteration 101900, lr = 1e-15
I0429 14:45:05.911021  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_102000.caffemodel
I0429 14:45:18.399924  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_102000.solverstate
I0429 14:45:18.600889  5145 solver.cpp:337] Iteration 102000, Testing net (#0)
I0429 14:45:18.600973  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 14:45:18.600976  5145 net.cpp:693] Ignoring source layer visualize
I0429 14:45:18.600978  5145 net.cpp:693] Ignoring source layer fake
I0429 14:50:14.675757  5145 solver.cpp:404]     Test net output #0: loss = 0.282326 (* 1 = 0.282326 loss)
I0429 14:50:14.989132  5145 solver.cpp:228] Iteration 102000, loss = 0.298237
I0429 14:50:14.989151  5145 solver.cpp:244]     Train net output #0: loss = 0.298237 (* 1 = 0.298237 loss)
I0429 14:50:14.989173  5145 sgd_solver.cpp:106] Iteration 102000, lr = 1e-15
I0429 14:51:05.564946  5145 solver.cpp:228] Iteration 102100, loss = 0.236522
I0429 14:51:05.565122  5145 solver.cpp:244]     Train net output #0: loss = 0.236522 (* 1 = 0.236522 loss)
I0429 14:51:05.565129  5145 sgd_solver.cpp:106] Iteration 102100, lr = 1e-15
I0429 14:51:57.801172  5145 solver.cpp:228] Iteration 102200, loss = 0.189189
I0429 14:51:57.802075  5145 solver.cpp:244]     Train net output #0: loss = 0.189189 (* 1 = 0.189189 loss)
I0429 14:51:57.802085  5145 sgd_solver.cpp:106] Iteration 102200, lr = 1e-15
I0429 14:52:48.281318  5145 solver.cpp:228] Iteration 102300, loss = 0.184702
I0429 14:52:48.281481  5145 solver.cpp:244]     Train net output #0: loss = 0.184702 (* 1 = 0.184702 loss)
I0429 14:52:48.281487  5145 sgd_solver.cpp:106] Iteration 102300, lr = 1e-15
I0429 14:53:38.748720  5145 solver.cpp:228] Iteration 102400, loss = 0.21873
I0429 14:53:38.748904  5145 solver.cpp:244]     Train net output #0: loss = 0.21873 (* 1 = 0.21873 loss)
I0429 14:53:38.748911  5145 sgd_solver.cpp:106] Iteration 102400, lr = 1e-15
I0429 14:54:31.191453  5145 solver.cpp:228] Iteration 102500, loss = 0.180979
I0429 14:54:31.191617  5145 solver.cpp:244]     Train net output #0: loss = 0.180979 (* 1 = 0.180979 loss)
I0429 14:54:31.191624  5145 sgd_solver.cpp:106] Iteration 102500, lr = 1e-15
I0429 14:55:21.707394  5145 solver.cpp:228] Iteration 102600, loss = 0.195894
I0429 14:55:21.707763  5145 solver.cpp:244]     Train net output #0: loss = 0.195894 (* 1 = 0.195894 loss)
I0429 14:55:21.707780  5145 sgd_solver.cpp:106] Iteration 102600, lr = 1e-15
I0429 14:56:12.152741  5145 solver.cpp:228] Iteration 102700, loss = 0.308723
I0429 14:56:12.152909  5145 solver.cpp:244]     Train net output #0: loss = 0.308723 (* 1 = 0.308723 loss)
I0429 14:56:12.152915  5145 sgd_solver.cpp:106] Iteration 102700, lr = 1e-15
I0429 14:57:04.693755  5145 solver.cpp:228] Iteration 102800, loss = 0.102146
I0429 14:57:04.693922  5145 solver.cpp:244]     Train net output #0: loss = 0.102146 (* 1 = 0.102146 loss)
I0429 14:57:04.693929  5145 sgd_solver.cpp:106] Iteration 102800, lr = 1e-15
I0429 14:57:54.936429  5145 solver.cpp:228] Iteration 102900, loss = 0.252918
I0429 14:57:54.936626  5145 solver.cpp:244]     Train net output #0: loss = 0.252918 (* 1 = 0.252918 loss)
I0429 14:57:54.936632  5145 sgd_solver.cpp:106] Iteration 102900, lr = 1e-15
I0429 14:58:45.030722  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_103000.caffemodel
I0429 14:58:50.896450  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_103000.solverstate
I0429 14:58:51.094137  5145 solver.cpp:337] Iteration 103000, Testing net (#0)
I0429 14:58:51.094223  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 14:58:51.094228  5145 net.cpp:693] Ignoring source layer visualize
I0429 14:58:51.094229  5145 net.cpp:693] Ignoring source layer fake
I0429 15:03:47.504586  5145 solver.cpp:404]     Test net output #0: loss = 0.291371 (* 1 = 0.291371 loss)
I0429 15:03:47.821641  5145 solver.cpp:228] Iteration 103000, loss = 0.229812
I0429 15:03:47.821663  5145 solver.cpp:244]     Train net output #0: loss = 0.229812 (* 1 = 0.229812 loss)
I0429 15:03:47.821686  5145 sgd_solver.cpp:106] Iteration 103000, lr = 1e-15
I0429 15:04:39.978987  5145 solver.cpp:228] Iteration 103100, loss = 0.288896
I0429 15:04:39.979166  5145 solver.cpp:244]     Train net output #0: loss = 0.288896 (* 1 = 0.288896 loss)
I0429 15:04:39.979173  5145 sgd_solver.cpp:106] Iteration 103100, lr = 1e-15
I0429 15:05:30.263985  5145 solver.cpp:228] Iteration 103200, loss = 0.274993
I0429 15:05:30.265425  5145 solver.cpp:244]     Train net output #0: loss = 0.274993 (* 1 = 0.274993 loss)
I0429 15:05:30.265432  5145 sgd_solver.cpp:106] Iteration 103200, lr = 1e-15
I0429 15:06:20.785111  5145 solver.cpp:228] Iteration 103300, loss = 0.251707
I0429 15:06:20.785270  5145 solver.cpp:244]     Train net output #0: loss = 0.251707 (* 1 = 0.251707 loss)
I0429 15:06:20.785279  5145 sgd_solver.cpp:106] Iteration 103300, lr = 1e-15
I0429 15:07:12.516441  5145 solver.cpp:228] Iteration 103400, loss = 0.229868
I0429 15:07:12.516597  5145 solver.cpp:244]     Train net output #0: loss = 0.229868 (* 1 = 0.229868 loss)
I0429 15:07:12.516604  5145 sgd_solver.cpp:106] Iteration 103400, lr = 1e-15
I0429 15:08:03.010516  5145 solver.cpp:228] Iteration 103500, loss = 0.294615
I0429 15:08:03.010676  5145 solver.cpp:244]     Train net output #0: loss = 0.294615 (* 1 = 0.294615 loss)
I0429 15:08:03.010684  5145 sgd_solver.cpp:106] Iteration 103500, lr = 1e-15
I0429 15:08:53.575027  5145 solver.cpp:228] Iteration 103600, loss = 0.396015
I0429 15:08:53.575212  5145 solver.cpp:244]     Train net output #0: loss = 0.396015 (* 1 = 0.396015 loss)
I0429 15:08:53.575220  5145 sgd_solver.cpp:106] Iteration 103600, lr = 1e-15
I0429 15:09:45.460294  5145 solver.cpp:228] Iteration 103700, loss = 0.223662
I0429 15:09:45.460484  5145 solver.cpp:244]     Train net output #0: loss = 0.223662 (* 1 = 0.223662 loss)
I0429 15:09:45.460494  5145 sgd_solver.cpp:106] Iteration 103700, lr = 1e-15
I0429 15:10:35.965706  5145 solver.cpp:228] Iteration 103800, loss = 0.283762
I0429 15:10:35.965879  5145 solver.cpp:244]     Train net output #0: loss = 0.283762 (* 1 = 0.283762 loss)
I0429 15:10:35.965885  5145 sgd_solver.cpp:106] Iteration 103800, lr = 1e-15
I0429 15:11:28.416546  5145 solver.cpp:228] Iteration 103900, loss = 0.124075
I0429 15:11:28.416731  5145 solver.cpp:244]     Train net output #0: loss = 0.124075 (* 1 = 0.124075 loss)
I0429 15:11:28.416738  5145 sgd_solver.cpp:106] Iteration 103900, lr = 1e-15
I0429 15:12:18.426723  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_104000.caffemodel
I0429 15:12:24.539819  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_104000.solverstate
I0429 15:12:24.732116  5145 solver.cpp:337] Iteration 104000, Testing net (#0)
I0429 15:12:24.732198  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 15:12:24.732201  5145 net.cpp:693] Ignoring source layer visualize
I0429 15:12:24.732219  5145 net.cpp:693] Ignoring source layer fake
I0429 15:17:20.959700  5145 solver.cpp:404]     Test net output #0: loss = 0.286633 (* 1 = 0.286633 loss)
I0429 15:17:21.271447  5145 solver.cpp:228] Iteration 104000, loss = 0.332015
I0429 15:17:21.271482  5145 solver.cpp:244]     Train net output #0: loss = 0.332015 (* 1 = 0.332015 loss)
I0429 15:17:21.271491  5145 sgd_solver.cpp:106] Iteration 104000, lr = 1e-15
I0429 15:18:11.847757  5145 solver.cpp:228] Iteration 104100, loss = 0.307435
I0429 15:18:11.847918  5145 solver.cpp:244]     Train net output #0: loss = 0.307435 (* 1 = 0.307435 loss)
I0429 15:18:11.847925  5145 sgd_solver.cpp:106] Iteration 104100, lr = 1e-15
I0429 15:19:02.358507  5145 solver.cpp:228] Iteration 104200, loss = 0.261511
I0429 15:19:02.358672  5145 solver.cpp:244]     Train net output #0: loss = 0.261511 (* 1 = 0.261511 loss)
I0429 15:19:02.358680  5145 sgd_solver.cpp:106] Iteration 104200, lr = 1e-15
I0429 15:19:54.701383  5145 solver.cpp:228] Iteration 104300, loss = 0.25964
I0429 15:19:54.701582  5145 solver.cpp:244]     Train net output #0: loss = 0.25964 (* 1 = 0.25964 loss)
I0429 15:19:54.701589  5145 sgd_solver.cpp:106] Iteration 104300, lr = 1e-15
I0429 15:20:45.364629  5145 solver.cpp:228] Iteration 104400, loss = 0.253883
I0429 15:20:45.364769  5145 solver.cpp:244]     Train net output #0: loss = 0.253883 (* 1 = 0.253883 loss)
I0429 15:20:45.364778  5145 sgd_solver.cpp:106] Iteration 104400, lr = 1e-15
I0429 15:21:35.822696  5145 solver.cpp:228] Iteration 104500, loss = 0.161362
I0429 15:21:35.822861  5145 solver.cpp:244]     Train net output #0: loss = 0.161362 (* 1 = 0.161362 loss)
I0429 15:21:35.822868  5145 sgd_solver.cpp:106] Iteration 104500, lr = 1e-15
I0429 15:22:28.777986  5145 solver.cpp:228] Iteration 104600, loss = 0.347274
I0429 15:22:28.778151  5145 solver.cpp:244]     Train net output #0: loss = 0.347274 (* 1 = 0.347274 loss)
I0429 15:22:28.778157  5145 sgd_solver.cpp:106] Iteration 104600, lr = 1e-15
I0429 15:23:19.209239  5145 solver.cpp:228] Iteration 104700, loss = 0.219663
I0429 15:23:19.209388  5145 solver.cpp:244]     Train net output #0: loss = 0.219663 (* 1 = 0.219663 loss)
I0429 15:23:19.209395  5145 sgd_solver.cpp:106] Iteration 104700, lr = 1e-15
I0429 15:24:09.595964  5145 solver.cpp:228] Iteration 104800, loss = 0.386058
I0429 15:24:09.596138  5145 solver.cpp:244]     Train net output #0: loss = 0.386058 (* 1 = 0.386058 loss)
I0429 15:24:09.596148  5145 sgd_solver.cpp:106] Iteration 104800, lr = 1e-15
I0429 15:25:00.119904  5145 solver.cpp:228] Iteration 104900, loss = 0.329732
I0429 15:25:00.120062  5145 solver.cpp:244]     Train net output #0: loss = 0.329732 (* 1 = 0.329732 loss)
I0429 15:25:00.120080  5145 sgd_solver.cpp:106] Iteration 104900, lr = 1e-15
I0429 15:25:52.030843  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_105000.caffemodel
I0429 15:26:04.142997  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_105000.solverstate
I0429 15:26:04.333923  5145 solver.cpp:337] Iteration 105000, Testing net (#0)
I0429 15:26:04.334005  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 15:26:04.334009  5145 net.cpp:693] Ignoring source layer visualize
I0429 15:26:04.334012  5145 net.cpp:693] Ignoring source layer fake
I0429 15:31:00.309116  5145 solver.cpp:404]     Test net output #0: loss = 0.285816 (* 1 = 0.285816 loss)
I0429 15:31:00.622321  5145 solver.cpp:228] Iteration 105000, loss = 0.350267
I0429 15:31:00.622361  5145 solver.cpp:244]     Train net output #0: loss = 0.350267 (* 1 = 0.350267 loss)
I0429 15:31:00.622380  5145 sgd_solver.cpp:106] Iteration 105000, lr = 1e-16
I0429 15:31:51.079319  5145 solver.cpp:228] Iteration 105100, loss = 0.183054
I0429 15:31:51.079567  5145 solver.cpp:244]     Train net output #0: loss = 0.183054 (* 1 = 0.183054 loss)
I0429 15:31:51.079576  5145 sgd_solver.cpp:106] Iteration 105100, lr = 1e-16
I0429 15:32:41.648249  5145 solver.cpp:228] Iteration 105200, loss = 0.310232
I0429 15:32:41.648444  5145 solver.cpp:244]     Train net output #0: loss = 0.310232 (* 1 = 0.310232 loss)
I0429 15:32:41.648453  5145 sgd_solver.cpp:106] Iteration 105200, lr = 1e-16
I0429 15:33:33.847733  5145 solver.cpp:228] Iteration 105300, loss = 0.330521
I0429 15:33:33.847898  5145 solver.cpp:244]     Train net output #0: loss = 0.330521 (* 1 = 0.330521 loss)
I0429 15:33:33.847905  5145 sgd_solver.cpp:106] Iteration 105300, lr = 1e-16
I0429 15:34:24.334483  5145 solver.cpp:228] Iteration 105400, loss = 0.193705
I0429 15:34:24.334664  5145 solver.cpp:244]     Train net output #0: loss = 0.193705 (* 1 = 0.193705 loss)
I0429 15:34:24.334673  5145 sgd_solver.cpp:106] Iteration 105400, lr = 1e-16
I0429 15:35:14.796459  5145 solver.cpp:228] Iteration 105500, loss = 0.28031
I0429 15:35:14.796653  5145 solver.cpp:244]     Train net output #0: loss = 0.28031 (* 1 = 0.28031 loss)
I0429 15:35:14.796660  5145 sgd_solver.cpp:106] Iteration 105500, lr = 1e-16
I0429 15:36:13.675712  5145 solver.cpp:228] Iteration 105600, loss = 0.175962
I0429 15:36:13.675900  5145 solver.cpp:244]     Train net output #0: loss = 0.175962 (* 1 = 0.175962 loss)
I0429 15:36:13.675909  5145 sgd_solver.cpp:106] Iteration 105600, lr = 1e-16
I0429 15:37:03.557344  5145 solver.cpp:228] Iteration 105700, loss = 0.139462
I0429 15:37:03.557513  5145 solver.cpp:244]     Train net output #0: loss = 0.139462 (* 1 = 0.139462 loss)
I0429 15:37:03.557520  5145 sgd_solver.cpp:106] Iteration 105700, lr = 1e-16
I0429 15:37:53.930516  5145 solver.cpp:228] Iteration 105800, loss = 0.104629
I0429 15:37:53.930687  5145 solver.cpp:244]     Train net output #0: loss = 0.104629 (* 1 = 0.104629 loss)
I0429 15:37:53.930694  5145 sgd_solver.cpp:106] Iteration 105800, lr = 1e-16
I0429 15:38:44.371323  5145 solver.cpp:228] Iteration 105900, loss = 0.243339
I0429 15:38:44.371501  5145 solver.cpp:244]     Train net output #0: loss = 0.243339 (* 1 = 0.243339 loss)
I0429 15:38:44.371510  5145 sgd_solver.cpp:106] Iteration 105900, lr = 1e-16
I0429 15:39:49.502506  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_106000.caffemodel
I0429 15:40:07.487730  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_106000.solverstate
I0429 15:40:07.687870  5145 solver.cpp:337] Iteration 106000, Testing net (#0)
I0429 15:40:07.687952  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 15:40:07.687975  5145 net.cpp:693] Ignoring source layer visualize
I0429 15:40:07.687978  5145 net.cpp:693] Ignoring source layer fake
I0429 15:45:03.367466  5145 solver.cpp:404]     Test net output #0: loss = 0.280825 (* 1 = 0.280825 loss)
I0429 15:45:03.680492  5145 solver.cpp:228] Iteration 106000, loss = 0.786481
I0429 15:45:03.680528  5145 solver.cpp:244]     Train net output #0: loss = 0.786481 (* 1 = 0.786481 loss)
I0429 15:45:03.680534  5145 sgd_solver.cpp:106] Iteration 106000, lr = 1e-16
I0429 15:45:54.093204  5145 solver.cpp:228] Iteration 106100, loss = 0.164791
I0429 15:45:54.093358  5145 solver.cpp:244]     Train net output #0: loss = 0.164791 (* 1 = 0.164791 loss)
I0429 15:45:54.093365  5145 sgd_solver.cpp:106] Iteration 106100, lr = 1e-16
I0429 15:46:44.495760  5145 solver.cpp:228] Iteration 106200, loss = 0.194656
I0429 15:46:44.495895  5145 solver.cpp:244]     Train net output #0: loss = 0.194656 (* 1 = 0.194656 loss)
I0429 15:46:44.495903  5145 sgd_solver.cpp:106] Iteration 106200, lr = 1e-16
I0429 15:47:49.911752  5145 solver.cpp:228] Iteration 106300, loss = 0.207031
I0429 15:47:49.913245  5145 solver.cpp:244]     Train net output #0: loss = 0.207031 (* 1 = 0.207031 loss)
I0429 15:47:49.913254  5145 sgd_solver.cpp:106] Iteration 106300, lr = 1e-16
I0429 15:48:40.110781  5145 solver.cpp:228] Iteration 106400, loss = 0.220138
I0429 15:48:40.110931  5145 solver.cpp:244]     Train net output #0: loss = 0.220138 (* 1 = 0.220138 loss)
I0429 15:48:40.110939  5145 sgd_solver.cpp:106] Iteration 106400, lr = 1e-16
I0429 15:49:45.094509  5145 solver.cpp:228] Iteration 106500, loss = 0.27367
I0429 15:49:45.094689  5145 solver.cpp:244]     Train net output #0: loss = 0.27367 (* 1 = 0.27367 loss)
I0429 15:49:45.094696  5145 sgd_solver.cpp:106] Iteration 106500, lr = 1e-16
I0429 15:50:35.023315  5145 solver.cpp:228] Iteration 106600, loss = 0.20774
I0429 15:50:35.023475  5145 solver.cpp:244]     Train net output #0: loss = 0.20774 (* 1 = 0.20774 loss)
I0429 15:50:35.023483  5145 sgd_solver.cpp:106] Iteration 106600, lr = 1e-16
I0429 15:51:25.449582  5145 solver.cpp:228] Iteration 106700, loss = 0.352591
I0429 15:51:25.449731  5145 solver.cpp:244]     Train net output #0: loss = 0.352591 (* 1 = 0.352591 loss)
I0429 15:51:25.449738  5145 sgd_solver.cpp:106] Iteration 106700, lr = 1e-16
I0429 15:52:29.662854  5145 solver.cpp:228] Iteration 106800, loss = 0.29211
I0429 15:52:29.663053  5145 solver.cpp:244]     Train net output #0: loss = 0.29211 (* 1 = 0.29211 loss)
I0429 15:52:29.663060  5145 sgd_solver.cpp:106] Iteration 106800, lr = 1e-16
I0429 15:53:19.863392  5145 solver.cpp:228] Iteration 106900, loss = 0.237224
I0429 15:53:19.863554  5145 solver.cpp:244]     Train net output #0: loss = 0.237224 (* 1 = 0.237224 loss)
I0429 15:53:19.863560  5145 sgd_solver.cpp:106] Iteration 106900, lr = 1e-16
I0429 15:54:10.149487  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_107000.caffemodel
I0429 15:54:26.450857  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_107000.solverstate
I0429 15:54:26.640712  5145 solver.cpp:337] Iteration 107000, Testing net (#0)
I0429 15:54:26.640812  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 15:54:26.640817  5145 net.cpp:693] Ignoring source layer visualize
I0429 15:54:26.640820  5145 net.cpp:693] Ignoring source layer fake
I0429 15:59:22.871497  5145 solver.cpp:404]     Test net output #0: loss = 0.282986 (* 1 = 0.282986 loss)
I0429 15:59:23.186089  5145 solver.cpp:228] Iteration 107000, loss = 0.225424
I0429 15:59:23.186126  5145 solver.cpp:244]     Train net output #0: loss = 0.225424 (* 1 = 0.225424 loss)
I0429 15:59:23.186132  5145 sgd_solver.cpp:106] Iteration 107000, lr = 1e-16
I0429 16:00:30.423615  5145 solver.cpp:228] Iteration 107100, loss = 0.310376
I0429 16:00:30.423768  5145 solver.cpp:244]     Train net output #0: loss = 0.310376 (* 1 = 0.310376 loss)
I0429 16:00:30.423775  5145 sgd_solver.cpp:106] Iteration 107100, lr = 1e-16
I0429 16:01:20.706724  5145 solver.cpp:228] Iteration 107200, loss = 0.294914
I0429 16:01:20.706876  5145 solver.cpp:244]     Train net output #0: loss = 0.294914 (* 1 = 0.294914 loss)
I0429 16:01:20.706883  5145 sgd_solver.cpp:106] Iteration 107200, lr = 1e-16
I0429 16:02:11.295630  5145 solver.cpp:228] Iteration 107300, loss = 0.303785
I0429 16:02:11.295797  5145 solver.cpp:244]     Train net output #0: loss = 0.303785 (* 1 = 0.303785 loss)
I0429 16:02:11.295804  5145 sgd_solver.cpp:106] Iteration 107300, lr = 1e-16
I0429 16:03:16.640256  5145 solver.cpp:228] Iteration 107400, loss = 0.237116
I0429 16:03:16.640424  5145 solver.cpp:244]     Train net output #0: loss = 0.237116 (* 1 = 0.237116 loss)
I0429 16:03:16.640431  5145 sgd_solver.cpp:106] Iteration 107400, lr = 1e-16
I0429 16:04:06.717542  5145 solver.cpp:228] Iteration 107500, loss = 0.288316
I0429 16:04:06.717674  5145 solver.cpp:244]     Train net output #0: loss = 0.288316 (* 1 = 0.288316 loss)
I0429 16:04:06.717686  5145 sgd_solver.cpp:106] Iteration 107500, lr = 1e-16
I0429 16:04:57.176801  5145 solver.cpp:228] Iteration 107600, loss = 0.277656
I0429 16:04:57.176967  5145 solver.cpp:244]     Train net output #0: loss = 0.277656 (* 1 = 0.277656 loss)
I0429 16:04:57.176975  5145 sgd_solver.cpp:106] Iteration 107600, lr = 1e-16
I0429 16:05:59.795828  5145 solver.cpp:228] Iteration 107700, loss = 0.386186
I0429 16:05:59.796015  5145 solver.cpp:244]     Train net output #0: loss = 0.386186 (* 1 = 0.386186 loss)
I0429 16:05:59.796023  5145 sgd_solver.cpp:106] Iteration 107700, lr = 1e-16
I0429 16:06:49.657043  5145 solver.cpp:228] Iteration 107800, loss = 0.32381
I0429 16:06:49.657225  5145 solver.cpp:244]     Train net output #0: loss = 0.32381 (* 1 = 0.32381 loss)
I0429 16:06:49.657233  5145 sgd_solver.cpp:106] Iteration 107800, lr = 1e-16
I0429 16:07:40.301260  5145 solver.cpp:228] Iteration 107900, loss = 0.325964
I0429 16:07:40.301420  5145 solver.cpp:244]     Train net output #0: loss = 0.325964 (* 1 = 0.325964 loss)
I0429 16:07:40.301427  5145 sgd_solver.cpp:106] Iteration 107900, lr = 1e-16
I0429 16:08:30.470873  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_108000.caffemodel
I0429 16:08:37.161569  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_108000.solverstate
I0429 16:08:37.354151  5145 solver.cpp:337] Iteration 108000, Testing net (#0)
I0429 16:08:37.354234  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 16:08:37.354238  5145 net.cpp:693] Ignoring source layer visualize
I0429 16:08:37.354240  5145 net.cpp:693] Ignoring source layer fake
I0429 16:13:33.249142  5145 solver.cpp:404]     Test net output #0: loss = 0.291354 (* 1 = 0.291354 loss)
I0429 16:13:33.566571  5145 solver.cpp:228] Iteration 108000, loss = 0.251554
I0429 16:13:33.566609  5145 solver.cpp:244]     Train net output #0: loss = 0.251554 (* 1 = 0.251554 loss)
I0429 16:13:33.566618  5145 sgd_solver.cpp:106] Iteration 108000, lr = 1e-16
I0429 16:14:25.944797  5145 solver.cpp:228] Iteration 108100, loss = 0.171663
I0429 16:14:25.944924  5145 solver.cpp:244]     Train net output #0: loss = 0.171663 (* 1 = 0.171663 loss)
I0429 16:14:25.944932  5145 sgd_solver.cpp:106] Iteration 108100, lr = 1e-16
I0429 16:15:16.410928  5145 solver.cpp:228] Iteration 108200, loss = 0.269495
I0429 16:15:16.411075  5145 solver.cpp:244]     Train net output #0: loss = 0.269495 (* 1 = 0.269495 loss)
I0429 16:15:16.411082  5145 sgd_solver.cpp:106] Iteration 108200, lr = 1e-16
I0429 16:16:06.931818  5145 solver.cpp:228] Iteration 108300, loss = 0.233973
I0429 16:16:06.931975  5145 solver.cpp:244]     Train net output #0: loss = 0.233973 (* 1 = 0.233973 loss)
I0429 16:16:06.931982  5145 sgd_solver.cpp:106] Iteration 108300, lr = 1e-16
I0429 16:16:59.193542  5145 solver.cpp:228] Iteration 108400, loss = 0.16601
I0429 16:16:59.197545  5145 solver.cpp:244]     Train net output #0: loss = 0.16601 (* 1 = 0.16601 loss)
I0429 16:16:59.197587  5145 sgd_solver.cpp:106] Iteration 108400, lr = 1e-16
I0429 16:17:49.692075  5145 solver.cpp:228] Iteration 108500, loss = 0.265697
I0429 16:17:49.692237  5145 solver.cpp:244]     Train net output #0: loss = 0.265697 (* 1 = 0.265697 loss)
I0429 16:17:49.692245  5145 sgd_solver.cpp:106] Iteration 108500, lr = 1e-16
I0429 16:18:40.002496  5145 solver.cpp:228] Iteration 108600, loss = 0.267448
I0429 16:18:40.002658  5145 solver.cpp:244]     Train net output #0: loss = 0.267448 (* 1 = 0.267448 loss)
I0429 16:18:40.002665  5145 sgd_solver.cpp:106] Iteration 108600, lr = 1e-16
I0429 16:19:30.409688  5145 solver.cpp:228] Iteration 108700, loss = 0.229993
I0429 16:19:30.409898  5145 solver.cpp:244]     Train net output #0: loss = 0.229993 (* 1 = 0.229993 loss)
I0429 16:19:30.409911  5145 sgd_solver.cpp:106] Iteration 108700, lr = 1e-16
I0429 16:20:22.581913  5145 solver.cpp:228] Iteration 108800, loss = 0.295823
I0429 16:20:22.582087  5145 solver.cpp:244]     Train net output #0: loss = 0.295823 (* 1 = 0.295823 loss)
I0429 16:20:22.582095  5145 sgd_solver.cpp:106] Iteration 108800, lr = 1e-16
I0429 16:21:13.038314  5145 solver.cpp:228] Iteration 108900, loss = 0.2262
I0429 16:21:13.038468  5145 solver.cpp:244]     Train net output #0: loss = 0.2262 (* 1 = 0.2262 loss)
I0429 16:21:13.038475  5145 sgd_solver.cpp:106] Iteration 108900, lr = 1e-16
I0429 16:22:03.213485  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_109000.caffemodel
I0429 16:22:25.652470  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_109000.solverstate
I0429 16:22:25.843282  5145 solver.cpp:337] Iteration 109000, Testing net (#0)
I0429 16:22:25.843381  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 16:22:25.843387  5145 net.cpp:693] Ignoring source layer visualize
I0429 16:22:25.843389  5145 net.cpp:693] Ignoring source layer fake
I0429 16:27:22.010237  5145 solver.cpp:404]     Test net output #0: loss = 0.286509 (* 1 = 0.286509 loss)
I0429 16:27:22.323799  5145 solver.cpp:228] Iteration 109000, loss = 0.246566
I0429 16:27:22.323817  5145 solver.cpp:244]     Train net output #0: loss = 0.246566 (* 1 = 0.246566 loss)
I0429 16:27:22.323838  5145 sgd_solver.cpp:106] Iteration 109000, lr = 1e-16
I0429 16:28:16.008230  5145 solver.cpp:228] Iteration 109100, loss = 0.205633
I0429 16:28:16.008420  5145 solver.cpp:244]     Train net output #0: loss = 0.205633 (* 1 = 0.205633 loss)
I0429 16:28:16.008429  5145 sgd_solver.cpp:106] Iteration 109100, lr = 1e-16
I0429 16:29:06.642158  5145 solver.cpp:228] Iteration 109200, loss = 0.208063
I0429 16:29:06.642316  5145 solver.cpp:244]     Train net output #0: loss = 0.208063 (* 1 = 0.208063 loss)
I0429 16:29:06.642323  5145 sgd_solver.cpp:106] Iteration 109200, lr = 1e-16
I0429 16:29:57.213838  5145 solver.cpp:228] Iteration 109300, loss = 0.304866
I0429 16:29:57.213997  5145 solver.cpp:244]     Train net output #0: loss = 0.304866 (* 1 = 0.304866 loss)
I0429 16:29:57.214004  5145 sgd_solver.cpp:106] Iteration 109300, lr = 1e-16
I0429 16:30:49.863067  5145 solver.cpp:228] Iteration 109400, loss = 0.198221
I0429 16:30:49.863224  5145 solver.cpp:244]     Train net output #0: loss = 0.198221 (* 1 = 0.198221 loss)
I0429 16:30:49.863231  5145 sgd_solver.cpp:106] Iteration 109400, lr = 1e-16
I0429 16:31:40.330201  5145 solver.cpp:228] Iteration 109500, loss = 0.29353
I0429 16:31:40.330365  5145 solver.cpp:244]     Train net output #0: loss = 0.29353 (* 1 = 0.29353 loss)
I0429 16:31:40.330374  5145 sgd_solver.cpp:106] Iteration 109500, lr = 1e-16
I0429 16:32:33.138449  5145 solver.cpp:228] Iteration 109600, loss = 0.354387
I0429 16:32:33.138628  5145 solver.cpp:244]     Train net output #0: loss = 0.354387 (* 1 = 0.354387 loss)
I0429 16:32:33.138635  5145 sgd_solver.cpp:106] Iteration 109600, lr = 1e-16
I0429 16:33:23.508793  5145 solver.cpp:228] Iteration 109700, loss = 0.312277
I0429 16:33:23.508968  5145 solver.cpp:244]     Train net output #0: loss = 0.312277 (* 1 = 0.312277 loss)
I0429 16:33:23.508977  5145 sgd_solver.cpp:106] Iteration 109700, lr = 1e-16
I0429 16:34:13.988906  5145 solver.cpp:228] Iteration 109800, loss = 0.423072
I0429 16:34:13.989076  5145 solver.cpp:244]     Train net output #0: loss = 0.423072 (* 1 = 0.423072 loss)
I0429 16:34:13.989082  5145 sgd_solver.cpp:106] Iteration 109800, lr = 1e-16
I0429 16:35:06.039630  5145 solver.cpp:228] Iteration 109900, loss = 0.16283
I0429 16:35:06.039820  5145 solver.cpp:244]     Train net output #0: loss = 0.16283 (* 1 = 0.16283 loss)
I0429 16:35:06.039829  5145 sgd_solver.cpp:106] Iteration 109900, lr = 1e-16
I0429 16:35:56.269593  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_110000.caffemodel
I0429 16:36:14.287653  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_110000.solverstate
I0429 16:36:14.483585  5145 solver.cpp:337] Iteration 110000, Testing net (#0)
I0429 16:36:14.483669  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 16:36:14.483672  5145 net.cpp:693] Ignoring source layer visualize
I0429 16:36:14.483690  5145 net.cpp:693] Ignoring source layer fake
I0429 16:41:10.484624  5145 solver.cpp:404]     Test net output #0: loss = 0.285654 (* 1 = 0.285654 loss)
I0429 16:41:10.796175  5145 solver.cpp:228] Iteration 110000, loss = 0.0477992
I0429 16:41:10.796213  5145 solver.cpp:244]     Train net output #0: loss = 0.0477992 (* 1 = 0.0477992 loss)
I0429 16:41:10.796219  5145 sgd_solver.cpp:106] Iteration 110000, lr = 1e-16
I0429 16:42:01.297730  5145 solver.cpp:228] Iteration 110100, loss = 0.27097
I0429 16:42:01.297888  5145 solver.cpp:244]     Train net output #0: loss = 0.27097 (* 1 = 0.27097 loss)
I0429 16:42:01.297895  5145 sgd_solver.cpp:106] Iteration 110100, lr = 1e-16
I0429 16:42:54.242084  5145 solver.cpp:228] Iteration 110200, loss = 0.223693
I0429 16:42:54.242240  5145 solver.cpp:244]     Train net output #0: loss = 0.223693 (* 1 = 0.223693 loss)
I0429 16:42:54.242249  5145 sgd_solver.cpp:106] Iteration 110200, lr = 1e-16
I0429 16:43:44.818395  5145 solver.cpp:228] Iteration 110300, loss = 0.328593
I0429 16:43:44.818581  5145 solver.cpp:244]     Train net output #0: loss = 0.328593 (* 1 = 0.328593 loss)
I0429 16:43:44.818589  5145 sgd_solver.cpp:106] Iteration 110300, lr = 1e-16
I0429 16:44:35.317528  5145 solver.cpp:228] Iteration 110400, loss = 0.313669
I0429 16:44:35.317746  5145 solver.cpp:244]     Train net output #0: loss = 0.313669 (* 1 = 0.313669 loss)
I0429 16:44:35.317755  5145 sgd_solver.cpp:106] Iteration 110400, lr = 1e-16
I0429 16:45:28.000874  5145 solver.cpp:228] Iteration 110500, loss = 0.281655
I0429 16:45:28.001080  5145 solver.cpp:244]     Train net output #0: loss = 0.281655 (* 1 = 0.281655 loss)
I0429 16:45:28.001090  5145 sgd_solver.cpp:106] Iteration 110500, lr = 1e-16
I0429 16:46:18.336486  5145 solver.cpp:228] Iteration 110600, loss = 0.219628
I0429 16:46:18.336663  5145 solver.cpp:244]     Train net output #0: loss = 0.219628 (* 1 = 0.219628 loss)
I0429 16:46:18.336670  5145 sgd_solver.cpp:106] Iteration 110600, lr = 1e-16
I0429 16:47:08.771096  5145 solver.cpp:228] Iteration 110700, loss = 0.228675
I0429 16:47:08.771258  5145 solver.cpp:244]     Train net output #0: loss = 0.228675 (* 1 = 0.228675 loss)
I0429 16:47:08.771265  5145 sgd_solver.cpp:106] Iteration 110700, lr = 1e-16
I0429 16:47:59.210510  5145 solver.cpp:228] Iteration 110800, loss = 0.21587
I0429 16:47:59.211987  5145 solver.cpp:244]     Train net output #0: loss = 0.21587 (* 1 = 0.21587 loss)
I0429 16:47:59.212010  5145 sgd_solver.cpp:106] Iteration 110800, lr = 1e-16
I0429 16:48:51.696414  5145 solver.cpp:228] Iteration 110900, loss = 0.29058
I0429 16:48:51.696597  5145 solver.cpp:244]     Train net output #0: loss = 0.29058 (* 1 = 0.29058 loss)
I0429 16:48:51.696606  5145 sgd_solver.cpp:106] Iteration 110900, lr = 1e-16
I0429 16:49:41.845445  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_111000.caffemodel
I0429 16:50:09.539703  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_111000.solverstate
I0429 16:50:09.771566  5145 solver.cpp:337] Iteration 111000, Testing net (#0)
I0429 16:50:09.771648  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 16:50:09.771652  5145 net.cpp:693] Ignoring source layer visualize
I0429 16:50:09.771669  5145 net.cpp:693] Ignoring source layer fake
I0429 16:55:06.604938  5145 solver.cpp:404]     Test net output #0: loss = 0.28033 (* 1 = 0.28033 loss)
I0429 16:55:06.918804  5145 solver.cpp:228] Iteration 111000, loss = 0.370085
I0429 16:55:06.918844  5145 solver.cpp:244]     Train net output #0: loss = 0.370085 (* 1 = 0.370085 loss)
I0429 16:55:06.918850  5145 sgd_solver.cpp:106] Iteration 111000, lr = 1e-16
I0429 16:55:57.520515  5145 solver.cpp:228] Iteration 111100, loss = 0.18868
I0429 16:55:57.520671  5145 solver.cpp:244]     Train net output #0: loss = 0.18868 (* 1 = 0.18868 loss)
I0429 16:55:57.520678  5145 sgd_solver.cpp:106] Iteration 111100, lr = 1e-16
I0429 16:56:50.093964  5145 solver.cpp:228] Iteration 111200, loss = 0.272557
I0429 16:56:50.094182  5145 solver.cpp:244]     Train net output #0: loss = 0.272557 (* 1 = 0.272557 loss)
I0429 16:56:50.094200  5145 sgd_solver.cpp:106] Iteration 111200, lr = 1e-16
I0429 16:57:40.690601  5145 solver.cpp:228] Iteration 111300, loss = 0.253292
I0429 16:57:40.690776  5145 solver.cpp:244]     Train net output #0: loss = 0.253292 (* 1 = 0.253292 loss)
I0429 16:57:40.690784  5145 sgd_solver.cpp:106] Iteration 111300, lr = 1e-16
I0429 16:58:31.137830  5145 solver.cpp:228] Iteration 111400, loss = 0.230761
I0429 16:58:31.138000  5145 solver.cpp:244]     Train net output #0: loss = 0.230761 (* 1 = 0.230761 loss)
I0429 16:58:31.138006  5145 sgd_solver.cpp:106] Iteration 111400, lr = 1e-16
I0429 16:59:21.646733  5145 solver.cpp:228] Iteration 111500, loss = 0.366476
I0429 16:59:21.647092  5145 solver.cpp:244]     Train net output #0: loss = 0.366476 (* 1 = 0.366476 loss)
I0429 16:59:21.647100  5145 sgd_solver.cpp:106] Iteration 111500, lr = 1e-16
I0429 17:00:14.316073  5145 solver.cpp:228] Iteration 111600, loss = 0.179069
I0429 17:00:14.316278  5145 solver.cpp:244]     Train net output #0: loss = 0.179069 (* 1 = 0.179069 loss)
I0429 17:00:14.316287  5145 sgd_solver.cpp:106] Iteration 111600, lr = 1e-16
I0429 17:01:04.436219  5145 solver.cpp:228] Iteration 111700, loss = 0.184478
I0429 17:01:04.436393  5145 solver.cpp:244]     Train net output #0: loss = 0.184478 (* 1 = 0.184478 loss)
I0429 17:01:04.436401  5145 sgd_solver.cpp:106] Iteration 111700, lr = 1e-16
I0429 17:01:54.526449  5145 solver.cpp:228] Iteration 111800, loss = 0.240258
I0429 17:01:54.526623  5145 solver.cpp:244]     Train net output #0: loss = 0.240258 (* 1 = 0.240258 loss)
I0429 17:01:54.526643  5145 sgd_solver.cpp:106] Iteration 111800, lr = 1e-16
I0429 17:02:48.604634  5145 solver.cpp:228] Iteration 111900, loss = 0.301928
I0429 17:02:48.604825  5145 solver.cpp:244]     Train net output #0: loss = 0.301928 (* 1 = 0.301928 loss)
I0429 17:02:48.604832  5145 sgd_solver.cpp:106] Iteration 111900, lr = 1e-16
I0429 17:03:38.351114  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_112000.caffemodel
I0429 17:03:49.673604  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_112000.solverstate
I0429 17:03:49.892006  5145 solver.cpp:337] Iteration 112000, Testing net (#0)
I0429 17:03:49.892118  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 17:03:49.892139  5145 net.cpp:693] Ignoring source layer visualize
I0429 17:03:49.892143  5145 net.cpp:693] Ignoring source layer fake
I0429 17:08:45.150532  5145 solver.cpp:404]     Test net output #0: loss = 0.283445 (* 1 = 0.283445 loss)
I0429 17:08:45.463232  5145 solver.cpp:228] Iteration 112000, loss = 0.266381
I0429 17:08:45.463256  5145 solver.cpp:244]     Train net output #0: loss = 0.266381 (* 1 = 0.266381 loss)
I0429 17:08:45.463276  5145 sgd_solver.cpp:106] Iteration 112000, lr = 1e-16
I0429 17:09:35.525086  5145 solver.cpp:228] Iteration 112100, loss = 0.250871
I0429 17:09:35.525259  5145 solver.cpp:244]     Train net output #0: loss = 0.250871 (* 1 = 0.250871 loss)
I0429 17:09:35.525266  5145 sgd_solver.cpp:106] Iteration 112100, lr = 1e-16
I0429 17:10:27.935740  5145 solver.cpp:228] Iteration 112200, loss = 0.260101
I0429 17:10:27.935912  5145 solver.cpp:244]     Train net output #0: loss = 0.260101 (* 1 = 0.260101 loss)
I0429 17:10:27.935920  5145 sgd_solver.cpp:106] Iteration 112200, lr = 1e-16
I0429 17:11:17.970645  5145 solver.cpp:228] Iteration 112300, loss = 0.0863616
I0429 17:11:17.970811  5145 solver.cpp:244]     Train net output #0: loss = 0.0863616 (* 1 = 0.0863616 loss)
I0429 17:11:17.970818  5145 sgd_solver.cpp:106] Iteration 112300, lr = 1e-16
I0429 17:12:08.064107  5145 solver.cpp:228] Iteration 112400, loss = 0.227582
I0429 17:12:08.064303  5145 solver.cpp:244]     Train net output #0: loss = 0.227582 (* 1 = 0.227582 loss)
I0429 17:12:08.064316  5145 sgd_solver.cpp:106] Iteration 112400, lr = 1e-16
I0429 17:12:59.763378  5145 solver.cpp:228] Iteration 112500, loss = 0.251461
I0429 17:12:59.763545  5145 solver.cpp:244]     Train net output #0: loss = 0.251461 (* 1 = 0.251461 loss)
I0429 17:12:59.763552  5145 sgd_solver.cpp:106] Iteration 112500, lr = 1e-17
I0429 17:13:49.824067  5145 solver.cpp:228] Iteration 112600, loss = 0.194751
I0429 17:13:49.824246  5145 solver.cpp:244]     Train net output #0: loss = 0.194751 (* 1 = 0.194751 loss)
I0429 17:13:49.824254  5145 sgd_solver.cpp:106] Iteration 112600, lr = 1e-17
I0429 17:14:39.909384  5145 solver.cpp:228] Iteration 112700, loss = 0.212891
I0429 17:14:39.909565  5145 solver.cpp:244]     Train net output #0: loss = 0.212891 (* 1 = 0.212891 loss)
I0429 17:14:39.909572  5145 sgd_solver.cpp:106] Iteration 112700, lr = 1e-17
I0429 17:15:31.471483  5145 solver.cpp:228] Iteration 112800, loss = 0.257603
I0429 17:15:31.471675  5145 solver.cpp:244]     Train net output #0: loss = 0.257603 (* 1 = 0.257603 loss)
I0429 17:15:31.471683  5145 sgd_solver.cpp:106] Iteration 112800, lr = 1e-17
I0429 17:16:21.528304  5145 solver.cpp:228] Iteration 112900, loss = 0.296086
I0429 17:16:21.528473  5145 solver.cpp:244]     Train net output #0: loss = 0.296086 (* 1 = 0.296086 loss)
I0429 17:16:21.528481  5145 sgd_solver.cpp:106] Iteration 112900, lr = 1e-17
I0429 17:17:13.327237  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_113000.caffemodel
I0429 17:17:47.050351  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_113000.solverstate
I0429 17:17:47.243242  5145 solver.cpp:337] Iteration 113000, Testing net (#0)
I0429 17:17:47.243343  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 17:17:47.243350  5145 net.cpp:693] Ignoring source layer visualize
I0429 17:17:47.243351  5145 net.cpp:693] Ignoring source layer fake
I0429 17:22:41.940712  5145 solver.cpp:404]     Test net output #0: loss = 0.291307 (* 1 = 0.291307 loss)
I0429 17:22:42.255625  5145 solver.cpp:228] Iteration 113000, loss = 0.192711
I0429 17:22:42.255646  5145 solver.cpp:244]     Train net output #0: loss = 0.192711 (* 1 = 0.192711 loss)
I0429 17:22:42.255668  5145 sgd_solver.cpp:106] Iteration 113000, lr = 1e-17
I0429 17:23:32.351778  5145 solver.cpp:228] Iteration 113100, loss = 0.297297
I0429 17:23:32.351924  5145 solver.cpp:244]     Train net output #0: loss = 0.297297 (* 1 = 0.297297 loss)
I0429 17:23:32.351933  5145 sgd_solver.cpp:106] Iteration 113100, lr = 1e-17
I0429 17:24:22.408612  5145 solver.cpp:228] Iteration 113200, loss = 0.550483
I0429 17:24:22.408758  5145 solver.cpp:244]     Train net output #0: loss = 0.550483 (* 1 = 0.550483 loss)
I0429 17:24:22.408764  5145 sgd_solver.cpp:106] Iteration 113200, lr = 1e-17
I0429 17:25:14.628657  5145 solver.cpp:228] Iteration 113300, loss = 0.233803
I0429 17:25:14.628813  5145 solver.cpp:244]     Train net output #0: loss = 0.233803 (* 1 = 0.233803 loss)
I0429 17:25:14.628820  5145 sgd_solver.cpp:106] Iteration 113300, lr = 1e-17
I0429 17:26:04.686746  5145 solver.cpp:228] Iteration 113400, loss = 0.152791
I0429 17:26:04.686884  5145 solver.cpp:244]     Train net output #0: loss = 0.152791 (* 1 = 0.152791 loss)
I0429 17:26:04.686892  5145 sgd_solver.cpp:106] Iteration 113400, lr = 1e-17
I0429 17:26:54.754520  5145 solver.cpp:228] Iteration 113500, loss = 0.361545
I0429 17:26:54.754715  5145 solver.cpp:244]     Train net output #0: loss = 0.361545 (* 1 = 0.361545 loss)
I0429 17:26:54.754724  5145 sgd_solver.cpp:106] Iteration 113500, lr = 1e-17
I0429 17:27:44.811049  5145 solver.cpp:228] Iteration 113600, loss = 0.382875
I0429 17:27:44.811235  5145 solver.cpp:244]     Train net output #0: loss = 0.382875 (* 1 = 0.382875 loss)
I0429 17:27:44.811242  5145 sgd_solver.cpp:106] Iteration 113600, lr = 1e-17
I0429 17:28:45.751904  5145 solver.cpp:228] Iteration 113700, loss = 0.402561
I0429 17:28:45.752091  5145 solver.cpp:244]     Train net output #0: loss = 0.402561 (* 1 = 0.402561 loss)
I0429 17:28:45.752099  5145 sgd_solver.cpp:106] Iteration 113700, lr = 1e-17
I0429 17:29:35.793409  5145 solver.cpp:228] Iteration 113800, loss = 0.30107
I0429 17:29:35.793570  5145 solver.cpp:244]     Train net output #0: loss = 0.30107 (* 1 = 0.30107 loss)
I0429 17:29:35.793578  5145 sgd_solver.cpp:106] Iteration 113800, lr = 1e-17
I0429 17:30:25.883142  5145 solver.cpp:228] Iteration 113900, loss = 0.300786
I0429 17:30:25.883319  5145 solver.cpp:244]     Train net output #0: loss = 0.300786 (* 1 = 0.300786 loss)
I0429 17:30:25.883327  5145 sgd_solver.cpp:106] Iteration 113900, lr = 1e-17
I0429 17:31:27.126672  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_114000.caffemodel
I0429 17:31:51.835332  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_114000.solverstate
I0429 17:31:52.044955  5145 solver.cpp:337] Iteration 114000, Testing net (#0)
I0429 17:31:52.045054  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 17:31:52.045058  5145 net.cpp:693] Ignoring source layer visualize
I0429 17:31:52.045059  5145 net.cpp:693] Ignoring source layer fake
I0429 17:36:46.255944  5145 solver.cpp:404]     Test net output #0: loss = 0.286599 (* 1 = 0.286599 loss)
I0429 17:36:46.568784  5145 solver.cpp:228] Iteration 114000, loss = 0.246091
I0429 17:36:46.568838  5145 solver.cpp:244]     Train net output #0: loss = 0.246091 (* 1 = 0.246091 loss)
I0429 17:36:46.568845  5145 sgd_solver.cpp:106] Iteration 114000, lr = 1e-17
I0429 17:37:36.614158  5145 solver.cpp:228] Iteration 114100, loss = 0.219331
I0429 17:37:36.614317  5145 solver.cpp:244]     Train net output #0: loss = 0.219331 (* 1 = 0.219331 loss)
I0429 17:37:36.614326  5145 sgd_solver.cpp:106] Iteration 114100, lr = 1e-17
I0429 17:38:26.703904  5145 solver.cpp:228] Iteration 114200, loss = 0.309887
I0429 17:38:26.704066  5145 solver.cpp:244]     Train net output #0: loss = 0.309887 (* 1 = 0.309887 loss)
I0429 17:38:26.704072  5145 sgd_solver.cpp:106] Iteration 114200, lr = 1e-17
I0429 17:39:27.941519  5145 solver.cpp:228] Iteration 114300, loss = 0.232957
I0429 17:39:27.941707  5145 solver.cpp:244]     Train net output #0: loss = 0.232957 (* 1 = 0.232957 loss)
I0429 17:39:27.941715  5145 sgd_solver.cpp:106] Iteration 114300, lr = 1e-17
I0429 17:40:17.924551  5145 solver.cpp:228] Iteration 114400, loss = 0.187544
I0429 17:40:17.924715  5145 solver.cpp:244]     Train net output #0: loss = 0.187544 (* 1 = 0.187544 loss)
I0429 17:40:17.924722  5145 sgd_solver.cpp:106] Iteration 114400, lr = 1e-17
I0429 17:41:07.979477  5145 solver.cpp:228] Iteration 114500, loss = 0.363662
I0429 17:41:07.979640  5145 solver.cpp:244]     Train net output #0: loss = 0.363662 (* 1 = 0.363662 loss)
I0429 17:41:07.979646  5145 sgd_solver.cpp:106] Iteration 114500, lr = 1e-17
I0429 17:41:58.033311  5145 solver.cpp:228] Iteration 114600, loss = 0.244119
I0429 17:41:58.033504  5145 solver.cpp:244]     Train net output #0: loss = 0.244119 (* 1 = 0.244119 loss)
I0429 17:41:58.033514  5145 sgd_solver.cpp:106] Iteration 114600, lr = 1e-17
I0429 17:42:57.495040  5145 solver.cpp:228] Iteration 114700, loss = 0.135992
I0429 17:42:57.495645  5145 solver.cpp:244]     Train net output #0: loss = 0.135992 (* 1 = 0.135992 loss)
I0429 17:42:57.495653  5145 sgd_solver.cpp:106] Iteration 114700, lr = 1e-17
I0429 17:43:47.517918  5145 solver.cpp:228] Iteration 114800, loss = 0.222074
I0429 17:43:47.518085  5145 solver.cpp:244]     Train net output #0: loss = 0.222074 (* 1 = 0.222074 loss)
I0429 17:43:47.518092  5145 sgd_solver.cpp:106] Iteration 114800, lr = 1e-17
I0429 17:44:37.608068  5145 solver.cpp:228] Iteration 114900, loss = 0.168552
I0429 17:44:37.608227  5145 solver.cpp:244]     Train net output #0: loss = 0.168552 (* 1 = 0.168552 loss)
I0429 17:44:37.608233  5145 sgd_solver.cpp:106] Iteration 114900, lr = 1e-17
I0429 17:45:37.064708  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_115000.caffemodel
I0429 17:45:53.343683  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_115000.solverstate
I0429 17:45:53.537962  5145 solver.cpp:337] Iteration 115000, Testing net (#0)
I0429 17:45:53.538060  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 17:45:53.538065  5145 net.cpp:693] Ignoring source layer visualize
I0429 17:45:53.538069  5145 net.cpp:693] Ignoring source layer fake
I0429 17:50:48.399144  5145 solver.cpp:404]     Test net output #0: loss = 0.285803 (* 1 = 0.285803 loss)
I0429 17:50:48.711823  5145 solver.cpp:228] Iteration 115000, loss = 0.170332
I0429 17:50:48.711844  5145 solver.cpp:244]     Train net output #0: loss = 0.170332 (* 1 = 0.170332 loss)
I0429 17:50:48.711865  5145 sgd_solver.cpp:106] Iteration 115000, lr = 1e-17
I0429 17:51:38.764680  5145 solver.cpp:228] Iteration 115100, loss = 0.201073
I0429 17:51:38.764861  5145 solver.cpp:244]     Train net output #0: loss = 0.201073 (* 1 = 0.201073 loss)
I0429 17:51:38.764870  5145 sgd_solver.cpp:106] Iteration 115100, lr = 1e-17
I0429 17:52:28.857653  5145 solver.cpp:228] Iteration 115200, loss = 0.280005
I0429 17:52:28.857812  5145 solver.cpp:244]     Train net output #0: loss = 0.280005 (* 1 = 0.280005 loss)
I0429 17:52:28.857820  5145 sgd_solver.cpp:106] Iteration 115200, lr = 1e-17
I0429 17:53:28.460510  5145 solver.cpp:228] Iteration 115300, loss = 0.212
I0429 17:53:28.460676  5145 solver.cpp:244]     Train net output #0: loss = 0.212 (* 1 = 0.212 loss)
I0429 17:53:28.460685  5145 sgd_solver.cpp:106] Iteration 115300, lr = 1e-17
I0429 17:54:18.417081  5145 solver.cpp:228] Iteration 115400, loss = 0.235631
I0429 17:54:18.417255  5145 solver.cpp:244]     Train net output #0: loss = 0.235631 (* 1 = 0.235631 loss)
I0429 17:54:18.417263  5145 sgd_solver.cpp:106] Iteration 115400, lr = 1e-17
I0429 17:55:08.430784  5145 solver.cpp:228] Iteration 115500, loss = 0.117032
I0429 17:55:08.430946  5145 solver.cpp:244]     Train net output #0: loss = 0.117032 (* 1 = 0.117032 loss)
I0429 17:55:08.430953  5145 sgd_solver.cpp:106] Iteration 115500, lr = 1e-17
I0429 17:56:04.813803  5145 solver.cpp:228] Iteration 115600, loss = 0.174513
I0429 17:56:04.813992  5145 solver.cpp:244]     Train net output #0: loss = 0.174513 (* 1 = 0.174513 loss)
I0429 17:56:04.813999  5145 sgd_solver.cpp:106] Iteration 115600, lr = 1e-17
I0429 17:56:54.828074  5145 solver.cpp:228] Iteration 115700, loss = 0.267428
I0429 17:56:54.828269  5145 solver.cpp:244]     Train net output #0: loss = 0.267428 (* 1 = 0.267428 loss)
I0429 17:56:54.828276  5145 sgd_solver.cpp:106] Iteration 115700, lr = 1e-17
I0429 17:57:44.920902  5145 solver.cpp:228] Iteration 115800, loss = 0.27933
I0429 17:57:44.921059  5145 solver.cpp:244]     Train net output #0: loss = 0.27933 (* 1 = 0.27933 loss)
I0429 17:57:44.921066  5145 sgd_solver.cpp:106] Iteration 115800, lr = 1e-17
I0429 17:58:40.962049  5145 solver.cpp:228] Iteration 115900, loss = 0.255648
I0429 17:58:40.962204  5145 solver.cpp:244]     Train net output #0: loss = 0.255648 (* 1 = 0.255648 loss)
I0429 17:58:40.962213  5145 sgd_solver.cpp:106] Iteration 115900, lr = 1e-17
I0429 17:59:30.706109  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_116000.caffemodel
I0429 17:59:52.336531  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_116000.solverstate
I0429 17:59:52.529626  5145 solver.cpp:337] Iteration 116000, Testing net (#0)
I0429 17:59:52.529727  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 17:59:52.529732  5145 net.cpp:693] Ignoring source layer visualize
I0429 17:59:52.529736  5145 net.cpp:693] Ignoring source layer fake
I0429 18:04:46.954974  5145 solver.cpp:404]     Test net output #0: loss = 0.279895 (* 1 = 0.279895 loss)
I0429 18:04:47.268359  5145 solver.cpp:228] Iteration 116000, loss = 0.257842
I0429 18:04:47.268389  5145 solver.cpp:244]     Train net output #0: loss = 0.257842 (* 1 = 0.257842 loss)
I0429 18:04:47.268398  5145 sgd_solver.cpp:106] Iteration 116000, lr = 1e-17
I0429 18:05:37.331482  5145 solver.cpp:228] Iteration 116100, loss = 0.205238
I0429 18:05:37.331625  5145 solver.cpp:244]     Train net output #0: loss = 0.205238 (* 1 = 0.205238 loss)
I0429 18:05:37.331632  5145 sgd_solver.cpp:106] Iteration 116100, lr = 1e-17
I0429 18:06:33.012327  5145 solver.cpp:228] Iteration 116200, loss = 0.30927
I0429 18:06:33.012496  5145 solver.cpp:244]     Train net output #0: loss = 0.30927 (* 1 = 0.30927 loss)
I0429 18:06:33.012503  5145 sgd_solver.cpp:106] Iteration 116200, lr = 1e-17
I0429 18:07:23.067293  5145 solver.cpp:228] Iteration 116300, loss = 0.322948
I0429 18:07:23.067515  5145 solver.cpp:244]     Train net output #0: loss = 0.322948 (* 1 = 0.322948 loss)
I0429 18:07:23.067529  5145 sgd_solver.cpp:106] Iteration 116300, lr = 1e-17
I0429 18:08:19.368122  5145 solver.cpp:228] Iteration 116400, loss = 0.182579
I0429 18:08:19.368307  5145 solver.cpp:244]     Train net output #0: loss = 0.182579 (* 1 = 0.182579 loss)
I0429 18:08:19.368315  5145 sgd_solver.cpp:106] Iteration 116400, lr = 1e-17
I0429 18:09:09.397269  5145 solver.cpp:228] Iteration 116500, loss = 0.375762
I0429 18:09:09.397495  5145 solver.cpp:244]     Train net output #0: loss = 0.375762 (* 1 = 0.375762 loss)
I0429 18:09:09.397502  5145 sgd_solver.cpp:106] Iteration 116500, lr = 1e-17
I0429 18:09:59.457000  5145 solver.cpp:228] Iteration 116600, loss = 0.326878
I0429 18:09:59.457187  5145 solver.cpp:244]     Train net output #0: loss = 0.326878 (* 1 = 0.326878 loss)
I0429 18:09:59.457195  5145 sgd_solver.cpp:106] Iteration 116600, lr = 1e-17
I0429 18:10:49.547731  5145 solver.cpp:228] Iteration 116700, loss = 0.397436
I0429 18:10:49.547917  5145 solver.cpp:244]     Train net output #0: loss = 0.397436 (* 1 = 0.397436 loss)
I0429 18:10:49.547924  5145 sgd_solver.cpp:106] Iteration 116700, lr = 1e-17
I0429 18:11:46.030095  5145 solver.cpp:228] Iteration 116800, loss = 0.240694
I0429 18:11:46.030284  5145 solver.cpp:244]     Train net output #0: loss = 0.240694 (* 1 = 0.240694 loss)
I0429 18:11:46.030292  5145 sgd_solver.cpp:106] Iteration 116800, lr = 1e-17
I0429 18:12:36.102666  5145 solver.cpp:228] Iteration 116900, loss = 0.381932
I0429 18:12:36.102847  5145 solver.cpp:244]     Train net output #0: loss = 0.381932 (* 1 = 0.381932 loss)
I0429 18:12:36.102854  5145 sgd_solver.cpp:106] Iteration 116900, lr = 1e-17
I0429 18:13:25.881850  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_117000.caffemodel
I0429 18:13:44.029144  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_117000.solverstate
I0429 18:13:44.232182  5145 solver.cpp:337] Iteration 117000, Testing net (#0)
I0429 18:13:44.232282  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 18:13:44.232290  5145 net.cpp:693] Ignoring source layer visualize
I0429 18:13:44.232292  5145 net.cpp:693] Ignoring source layer fake
I0429 18:18:40.079962  5145 solver.cpp:404]     Test net output #0: loss = 0.28466 (* 1 = 0.28466 loss)
I0429 18:18:40.391827  5145 solver.cpp:228] Iteration 117000, loss = 0.296997
I0429 18:18:40.391863  5145 solver.cpp:244]     Train net output #0: loss = 0.296997 (* 1 = 0.296997 loss)
I0429 18:18:40.391873  5145 sgd_solver.cpp:106] Iteration 117000, lr = 1e-17
I0429 18:19:38.342269  5145 solver.cpp:228] Iteration 117100, loss = 0.379024
I0429 18:19:38.342442  5145 solver.cpp:244]     Train net output #0: loss = 0.379024 (* 1 = 0.379024 loss)
I0429 18:19:38.342449  5145 sgd_solver.cpp:106] Iteration 117100, lr = 1e-17
I0429 18:20:28.467886  5145 solver.cpp:228] Iteration 117200, loss = 0.234331
I0429 18:20:28.468044  5145 solver.cpp:244]     Train net output #0: loss = 0.234331 (* 1 = 0.234331 loss)
I0429 18:20:28.468052  5145 sgd_solver.cpp:106] Iteration 117200, lr = 1e-17
I0429 18:21:18.930749  5145 solver.cpp:228] Iteration 117300, loss = 0.21387
I0429 18:21:18.930927  5145 solver.cpp:244]     Train net output #0: loss = 0.21387 (* 1 = 0.21387 loss)
I0429 18:21:18.930934  5145 sgd_solver.cpp:106] Iteration 117300, lr = 1e-17
I0429 18:22:09.428184  5145 solver.cpp:228] Iteration 117400, loss = 0.338295
I0429 18:22:09.428344  5145 solver.cpp:244]     Train net output #0: loss = 0.338295 (* 1 = 0.338295 loss)
I0429 18:22:09.428350  5145 sgd_solver.cpp:106] Iteration 117400, lr = 1e-17
I0429 18:23:07.877007  5145 solver.cpp:228] Iteration 117500, loss = 0.231521
I0429 18:23:07.877190  5145 solver.cpp:244]     Train net output #0: loss = 0.231521 (* 1 = 0.231521 loss)
I0429 18:23:07.877199  5145 sgd_solver.cpp:106] Iteration 117500, lr = 1e-17
I0429 18:23:58.297253  5145 solver.cpp:228] Iteration 117600, loss = 0.259992
I0429 18:23:58.297456  5145 solver.cpp:244]     Train net output #0: loss = 0.259992 (* 1 = 0.259992 loss)
I0429 18:23:58.297464  5145 sgd_solver.cpp:106] Iteration 117600, lr = 1e-17
I0429 18:24:48.673494  5145 solver.cpp:228] Iteration 117700, loss = 0.262887
I0429 18:24:48.673637  5145 solver.cpp:244]     Train net output #0: loss = 0.262887 (* 1 = 0.262887 loss)
I0429 18:24:48.673645  5145 sgd_solver.cpp:106] Iteration 117700, lr = 1e-17
I0429 18:25:47.050071  5145 solver.cpp:228] Iteration 117800, loss = 0.157625
I0429 18:25:47.050248  5145 solver.cpp:244]     Train net output #0: loss = 0.157625 (* 1 = 0.157625 loss)
I0429 18:25:47.050256  5145 sgd_solver.cpp:106] Iteration 117800, lr = 1e-17
I0429 18:26:37.235817  5145 solver.cpp:228] Iteration 117900, loss = 0.221654
I0429 18:26:37.237113  5145 solver.cpp:244]     Train net output #0: loss = 0.221654 (* 1 = 0.221654 loss)
I0429 18:26:37.237136  5145 sgd_solver.cpp:106] Iteration 117900, lr = 1e-17
I0429 18:27:27.463543  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_118000.caffemodel
I0429 18:27:55.486232  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_118000.solverstate
I0429 18:27:55.680500  5145 solver.cpp:337] Iteration 118000, Testing net (#0)
I0429 18:27:55.680582  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 18:27:55.680584  5145 net.cpp:693] Ignoring source layer visualize
I0429 18:27:55.680586  5145 net.cpp:693] Ignoring source layer fake
I0429 18:32:51.112428  5145 solver.cpp:404]     Test net output #0: loss = 0.290983 (* 1 = 0.290983 loss)
I0429 18:32:51.427549  5145 solver.cpp:228] Iteration 118000, loss = 0.352023
I0429 18:32:51.427587  5145 solver.cpp:244]     Train net output #0: loss = 0.352023 (* 1 = 0.352023 loss)
I0429 18:32:51.427593  5145 sgd_solver.cpp:106] Iteration 118000, lr = 1e-17
I0429 18:33:51.972393  5145 solver.cpp:228] Iteration 118100, loss = 0.201792
I0429 18:33:51.972556  5145 solver.cpp:244]     Train net output #0: loss = 0.201792 (* 1 = 0.201792 loss)
I0429 18:33:51.972563  5145 sgd_solver.cpp:106] Iteration 118100, lr = 1e-17
I0429 18:34:41.880960  5145 solver.cpp:228] Iteration 118200, loss = 0.233664
I0429 18:34:41.881134  5145 solver.cpp:244]     Train net output #0: loss = 0.233664 (* 1 = 0.233664 loss)
I0429 18:34:41.881142  5145 sgd_solver.cpp:106] Iteration 118200, lr = 1e-17
I0429 18:35:32.350452  5145 solver.cpp:228] Iteration 118300, loss = 0.228091
I0429 18:35:32.350620  5145 solver.cpp:244]     Train net output #0: loss = 0.228091 (* 1 = 0.228091 loss)
I0429 18:35:32.350627  5145 sgd_solver.cpp:106] Iteration 118300, lr = 1e-17
I0429 18:36:22.728757  5145 solver.cpp:228] Iteration 118400, loss = 0.240933
I0429 18:36:22.728919  5145 solver.cpp:244]     Train net output #0: loss = 0.240933 (* 1 = 0.240933 loss)
I0429 18:36:22.728925  5145 sgd_solver.cpp:106] Iteration 118400, lr = 1e-17
I0429 18:37:28.326306  5145 solver.cpp:228] Iteration 118500, loss = 0.20983
I0429 18:37:28.326472  5145 solver.cpp:244]     Train net output #0: loss = 0.20983 (* 1 = 0.20983 loss)
I0429 18:37:28.326480  5145 sgd_solver.cpp:106] Iteration 118500, lr = 1e-17
I0429 18:38:18.418046  5145 solver.cpp:228] Iteration 118600, loss = 0.301846
I0429 18:38:18.419507  5145 solver.cpp:244]     Train net output #0: loss = 0.301846 (* 1 = 0.301846 loss)
I0429 18:38:18.419515  5145 sgd_solver.cpp:106] Iteration 118600, lr = 1e-17
I0429 18:39:09.007310  5145 solver.cpp:228] Iteration 118700, loss = 0.157456
I0429 18:39:09.007479  5145 solver.cpp:244]     Train net output #0: loss = 0.157456 (* 1 = 0.157456 loss)
I0429 18:39:09.007486  5145 sgd_solver.cpp:106] Iteration 118700, lr = 1e-17
I0429 18:40:14.070554  5145 solver.cpp:228] Iteration 118800, loss = 0.255984
I0429 18:40:14.070721  5145 solver.cpp:244]     Train net output #0: loss = 0.255984 (* 1 = 0.255984 loss)
I0429 18:40:14.070729  5145 sgd_solver.cpp:106] Iteration 118800, lr = 1e-17
I0429 18:41:04.393057  5145 solver.cpp:228] Iteration 118900, loss = 0.191709
I0429 18:41:04.393241  5145 solver.cpp:244]     Train net output #0: loss = 0.191709 (* 1 = 0.191709 loss)
I0429 18:41:04.393249  5145 sgd_solver.cpp:106] Iteration 118900, lr = 1e-17
I0429 18:42:09.231317  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_119000.caffemodel
I0429 18:42:12.821449  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_119000.solverstate
I0429 18:42:13.011605  5145 solver.cpp:337] Iteration 119000, Testing net (#0)
I0429 18:42:13.011703  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 18:42:13.011708  5145 net.cpp:693] Ignoring source layer visualize
I0429 18:42:13.011710  5145 net.cpp:693] Ignoring source layer fake
I0429 18:47:08.562918  5145 solver.cpp:404]     Test net output #0: loss = 0.286461 (* 1 = 0.286461 loss)
I0429 18:47:08.880259  5145 solver.cpp:228] Iteration 119000, loss = 0.135352
I0429 18:47:08.880312  5145 solver.cpp:244]     Train net output #0: loss = 0.135352 (* 1 = 0.135352 loss)
I0429 18:47:08.880319  5145 sgd_solver.cpp:106] Iteration 119000, lr = 1e-17
I0429 18:47:59.284204  5145 solver.cpp:228] Iteration 119100, loss = 0.289643
I0429 18:47:59.284353  5145 solver.cpp:244]     Train net output #0: loss = 0.289643 (* 1 = 0.289643 loss)
I0429 18:47:59.284360  5145 sgd_solver.cpp:106] Iteration 119100, lr = 1e-17
I0429 18:48:49.814688  5145 solver.cpp:228] Iteration 119200, loss = 0.346491
I0429 18:48:49.814851  5145 solver.cpp:244]     Train net output #0: loss = 0.346491 (* 1 = 0.346491 loss)
I0429 18:48:49.814858  5145 sgd_solver.cpp:106] Iteration 119200, lr = 1e-17
I0429 18:49:53.992357  5145 solver.cpp:228] Iteration 119300, loss = 0.319208
I0429 18:49:53.992558  5145 solver.cpp:244]     Train net output #0: loss = 0.319208 (* 1 = 0.319208 loss)
I0429 18:49:53.992565  5145 sgd_solver.cpp:106] Iteration 119300, lr = 1e-17
I0429 18:50:44.060309  5145 solver.cpp:228] Iteration 119400, loss = 0.234201
I0429 18:50:44.060477  5145 solver.cpp:244]     Train net output #0: loss = 0.234201 (* 1 = 0.234201 loss)
I0429 18:50:44.060483  5145 sgd_solver.cpp:106] Iteration 119400, lr = 1e-17
I0429 18:51:34.479678  5145 solver.cpp:228] Iteration 119500, loss = 0.2638
I0429 18:51:34.479833  5145 solver.cpp:244]     Train net output #0: loss = 0.2638 (* 1 = 0.2638 loss)
I0429 18:51:34.479840  5145 sgd_solver.cpp:106] Iteration 119500, lr = 1e-17
I0429 18:52:41.550434  5145 solver.cpp:228] Iteration 119600, loss = 0.461884
I0429 18:52:41.550587  5145 solver.cpp:244]     Train net output #0: loss = 0.461884 (* 1 = 0.461884 loss)
I0429 18:52:41.550595  5145 sgd_solver.cpp:106] Iteration 119600, lr = 1e-17
I0429 18:53:31.804566  5145 solver.cpp:228] Iteration 119700, loss = 0.290933
I0429 18:53:31.804733  5145 solver.cpp:244]     Train net output #0: loss = 0.290933 (* 1 = 0.290933 loss)
I0429 18:53:31.804739  5145 sgd_solver.cpp:106] Iteration 119700, lr = 1e-17
I0429 18:54:22.423745  5145 solver.cpp:228] Iteration 119800, loss = 0.308506
I0429 18:54:22.423892  5145 solver.cpp:244]     Train net output #0: loss = 0.308506 (* 1 = 0.308506 loss)
I0429 18:54:22.423899  5145 sgd_solver.cpp:106] Iteration 119800, lr = 1e-17
I0429 18:55:14.800899  5145 solver.cpp:228] Iteration 119900, loss = 0.315905
I0429 18:55:14.801049  5145 solver.cpp:244]     Train net output #0: loss = 0.315905 (* 1 = 0.315905 loss)
I0429 18:55:14.801057  5145 sgd_solver.cpp:106] Iteration 119900, lr = 1e-17
I0429 18:56:04.991421  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_120000.caffemodel
I0429 18:56:14.387095  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_120000.solverstate
I0429 18:56:14.594230  5145 solver.cpp:337] Iteration 120000, Testing net (#0)
I0429 18:56:14.594316  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 18:56:14.594337  5145 net.cpp:693] Ignoring source layer visualize
I0429 18:56:14.594339  5145 net.cpp:693] Ignoring source layer fake
I0429 19:01:10.855638  5145 solver.cpp:404]     Test net output #0: loss = 0.285211 (* 1 = 0.285211 loss)
I0429 19:01:11.168480  5145 solver.cpp:228] Iteration 120000, loss = 0.271437
I0429 19:01:11.168499  5145 solver.cpp:244]     Train net output #0: loss = 0.271437 (* 1 = 0.271437 loss)
I0429 19:01:11.168521  5145 sgd_solver.cpp:106] Iteration 120000, lr = 1e-18
I0429 19:02:01.575691  5145 solver.cpp:228] Iteration 120100, loss = 0.158482
I0429 19:02:01.575871  5145 solver.cpp:244]     Train net output #0: loss = 0.158482 (* 1 = 0.158482 loss)
I0429 19:02:01.575878  5145 sgd_solver.cpp:106] Iteration 120100, lr = 1e-18
I0429 19:03:05.134290  5145 solver.cpp:228] Iteration 120200, loss = 0.262142
I0429 19:03:05.134543  5145 solver.cpp:244]     Train net output #0: loss = 0.262142 (* 1 = 0.262142 loss)
I0429 19:03:05.134557  5145 sgd_solver.cpp:106] Iteration 120200, lr = 1e-18
I0429 19:03:55.030942  5145 solver.cpp:228] Iteration 120300, loss = 0.243393
I0429 19:03:55.031127  5145 solver.cpp:244]     Train net output #0: loss = 0.243393 (* 1 = 0.243393 loss)
I0429 19:03:55.031137  5145 sgd_solver.cpp:106] Iteration 120300, lr = 1e-18
I0429 19:04:45.445242  5145 solver.cpp:228] Iteration 120400, loss = 0.344661
I0429 19:04:45.446050  5145 solver.cpp:244]     Train net output #0: loss = 0.344661 (* 1 = 0.344661 loss)
I0429 19:04:45.446072  5145 sgd_solver.cpp:106] Iteration 120400, lr = 1e-18
I0429 19:05:35.919198  5145 solver.cpp:228] Iteration 120500, loss = 0.304188
I0429 19:05:35.919360  5145 solver.cpp:244]     Train net output #0: loss = 0.304188 (* 1 = 0.304188 loss)
I0429 19:05:35.919368  5145 sgd_solver.cpp:106] Iteration 120500, lr = 1e-18
I0429 19:06:28.400918  5145 solver.cpp:228] Iteration 120600, loss = 0.231934
I0429 19:06:28.401113  5145 solver.cpp:244]     Train net output #0: loss = 0.231934 (* 1 = 0.231934 loss)
I0429 19:06:28.401121  5145 sgd_solver.cpp:106] Iteration 120600, lr = 1e-18
I0429 19:07:19.016276  5145 solver.cpp:228] Iteration 120700, loss = 0.333565
I0429 19:07:19.016471  5145 solver.cpp:244]     Train net output #0: loss = 0.333565 (* 1 = 0.333565 loss)
I0429 19:07:19.016481  5145 sgd_solver.cpp:106] Iteration 120700, lr = 1e-18
I0429 19:08:09.521975  5145 solver.cpp:228] Iteration 120800, loss = 0.299852
I0429 19:08:09.522133  5145 solver.cpp:244]     Train net output #0: loss = 0.299852 (* 1 = 0.299852 loss)
I0429 19:08:09.522140  5145 sgd_solver.cpp:106] Iteration 120800, lr = 1e-18
I0429 19:09:02.294359  5145 solver.cpp:228] Iteration 120900, loss = 0.290385
I0429 19:09:02.294519  5145 solver.cpp:244]     Train net output #0: loss = 0.290385 (* 1 = 0.290385 loss)
I0429 19:09:02.294526  5145 sgd_solver.cpp:106] Iteration 120900, lr = 1e-18
I0429 19:09:52.498903  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_121000.caffemodel
I0429 19:10:05.760913  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_121000.solverstate
I0429 19:10:05.952399  5145 solver.cpp:337] Iteration 121000, Testing net (#0)
I0429 19:10:05.952481  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 19:10:05.952486  5145 net.cpp:693] Ignoring source layer visualize
I0429 19:10:05.952487  5145 net.cpp:693] Ignoring source layer fake
I0429 19:15:02.294138  5145 solver.cpp:404]     Test net output #0: loss = 0.279689 (* 1 = 0.279689 loss)
I0429 19:15:02.616549  5145 solver.cpp:228] Iteration 121000, loss = 0.247538
I0429 19:15:02.616567  5145 solver.cpp:244]     Train net output #0: loss = 0.247538 (* 1 = 0.247538 loss)
I0429 19:15:02.616590  5145 sgd_solver.cpp:106] Iteration 121000, lr = 1e-18
I0429 19:15:53.145900  5145 solver.cpp:228] Iteration 121100, loss = 0.348787
I0429 19:15:53.146076  5145 solver.cpp:244]     Train net output #0: loss = 0.348787 (* 1 = 0.348787 loss)
I0429 19:15:53.146083  5145 sgd_solver.cpp:106] Iteration 121100, lr = 1e-18
I0429 19:16:43.771626  5145 solver.cpp:228] Iteration 121200, loss = 0.0645262
I0429 19:16:43.771862  5145 solver.cpp:244]     Train net output #0: loss = 0.0645262 (* 1 = 0.0645262 loss)
I0429 19:16:43.771869  5145 sgd_solver.cpp:106] Iteration 121200, lr = 1e-18
I0429 19:17:36.714576  5145 solver.cpp:228] Iteration 121300, loss = 0.176848
I0429 19:17:36.714774  5145 solver.cpp:244]     Train net output #0: loss = 0.176848 (* 1 = 0.176848 loss)
I0429 19:17:36.714783  5145 sgd_solver.cpp:106] Iteration 121300, lr = 1e-18
I0429 19:18:27.153409  5145 solver.cpp:228] Iteration 121400, loss = 0.215727
I0429 19:18:27.169502  5145 solver.cpp:244]     Train net output #0: loss = 0.215727 (* 1 = 0.215727 loss)
I0429 19:18:27.169515  5145 sgd_solver.cpp:106] Iteration 121400, lr = 1e-18
I0429 19:19:17.634647  5145 solver.cpp:228] Iteration 121500, loss = 0.198278
I0429 19:19:17.634830  5145 solver.cpp:244]     Train net output #0: loss = 0.198278 (* 1 = 0.198278 loss)
I0429 19:19:17.634837  5145 sgd_solver.cpp:106] Iteration 121500, lr = 1e-18
I0429 19:20:09.932499  5145 solver.cpp:228] Iteration 121600, loss = 0.192223
I0429 19:20:09.932667  5145 solver.cpp:244]     Train net output #0: loss = 0.192223 (* 1 = 0.192223 loss)
I0429 19:20:09.932674  5145 sgd_solver.cpp:106] Iteration 121600, lr = 1e-18
I0429 19:21:00.449190  5145 solver.cpp:228] Iteration 121700, loss = 0.276213
I0429 19:21:00.449364  5145 solver.cpp:244]     Train net output #0: loss = 0.276213 (* 1 = 0.276213 loss)
I0429 19:21:00.449371  5145 sgd_solver.cpp:106] Iteration 121700, lr = 1e-18
I0429 19:21:50.963098  5145 solver.cpp:228] Iteration 121800, loss = 0.191151
I0429 19:21:50.963318  5145 solver.cpp:244]     Train net output #0: loss = 0.191151 (* 1 = 0.191151 loss)
I0429 19:21:50.963330  5145 sgd_solver.cpp:106] Iteration 121800, lr = 1e-18
I0429 19:22:42.723755  5145 solver.cpp:228] Iteration 121900, loss = 0.210066
I0429 19:22:42.723927  5145 solver.cpp:244]     Train net output #0: loss = 0.210066 (* 1 = 0.210066 loss)
I0429 19:22:42.723933  5145 sgd_solver.cpp:106] Iteration 121900, lr = 1e-18
I0429 19:23:32.891659  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_122000.caffemodel
I0429 19:23:49.554599  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_122000.solverstate
I0429 19:23:49.749167  5145 solver.cpp:337] Iteration 122000, Testing net (#0)
I0429 19:23:49.749253  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 19:23:49.749256  5145 net.cpp:693] Ignoring source layer visualize
I0429 19:23:49.749274  5145 net.cpp:693] Ignoring source layer fake
I0429 19:28:46.148545  5145 solver.cpp:404]     Test net output #0: loss = 0.286449 (* 1 = 0.286449 loss)
I0429 19:28:46.461783  5145 solver.cpp:228] Iteration 122000, loss = 0.23305
I0429 19:28:46.461802  5145 solver.cpp:244]     Train net output #0: loss = 0.23305 (* 1 = 0.23305 loss)
I0429 19:28:46.461824  5145 sgd_solver.cpp:106] Iteration 122000, lr = 1e-18
I0429 19:29:51.824196  5145 solver.cpp:228] Iteration 122100, loss = 0.320459
I0429 19:29:51.824362  5145 solver.cpp:244]     Train net output #0: loss = 0.320459 (* 1 = 0.320459 loss)
I0429 19:29:51.824373  5145 sgd_solver.cpp:106] Iteration 122100, lr = 1e-18
I0429 19:30:41.623805  5145 solver.cpp:228] Iteration 122200, loss = 0.135449
I0429 19:30:41.623971  5145 solver.cpp:244]     Train net output #0: loss = 0.135449 (* 1 = 0.135449 loss)
I0429 19:30:41.623978  5145 sgd_solver.cpp:106] Iteration 122200, lr = 1e-18
I0429 19:31:32.119882  5145 solver.cpp:228] Iteration 122300, loss = 0.296845
I0429 19:31:32.120051  5145 solver.cpp:244]     Train net output #0: loss = 0.296845 (* 1 = 0.296845 loss)
I0429 19:31:32.120059  5145 sgd_solver.cpp:106] Iteration 122300, lr = 1e-18
I0429 19:32:36.071966  5145 solver.cpp:228] Iteration 122400, loss = 0.272757
I0429 19:32:36.072158  5145 solver.cpp:244]     Train net output #0: loss = 0.272757 (* 1 = 0.272757 loss)
I0429 19:32:36.072166  5145 sgd_solver.cpp:106] Iteration 122400, lr = 1e-18
I0429 19:33:26.201601  5145 solver.cpp:228] Iteration 122500, loss = 0.139075
I0429 19:33:26.201797  5145 solver.cpp:244]     Train net output #0: loss = 0.139075 (* 1 = 0.139075 loss)
I0429 19:33:26.201807  5145 sgd_solver.cpp:106] Iteration 122500, lr = 1e-18
I0429 19:34:16.762894  5145 solver.cpp:228] Iteration 122600, loss = 0.266038
I0429 19:34:16.763052  5145 solver.cpp:244]     Train net output #0: loss = 0.266038 (* 1 = 0.266038 loss)
I0429 19:34:16.763061  5145 sgd_solver.cpp:106] Iteration 122600, lr = 1e-18
I0429 19:35:09.071274  5145 solver.cpp:228] Iteration 122700, loss = 0.214929
I0429 19:35:09.071431  5145 solver.cpp:244]     Train net output #0: loss = 0.214929 (* 1 = 0.214929 loss)
I0429 19:35:09.071439  5145 sgd_solver.cpp:106] Iteration 122700, lr = 1e-18
I0429 19:35:59.681502  5145 solver.cpp:228] Iteration 122800, loss = 0.376821
I0429 19:35:59.681695  5145 solver.cpp:244]     Train net output #0: loss = 0.376821 (* 1 = 0.376821 loss)
I0429 19:35:59.681705  5145 sgd_solver.cpp:106] Iteration 122800, lr = 1e-18
I0429 19:36:50.248132  5145 solver.cpp:228] Iteration 122900, loss = 0.25046
I0429 19:36:50.248651  5145 solver.cpp:244]     Train net output #0: loss = 0.25046 (* 1 = 0.25046 loss)
I0429 19:36:50.248658  5145 sgd_solver.cpp:106] Iteration 122900, lr = 1e-18
I0429 19:37:42.516443  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_123000.caffemodel
I0429 19:38:15.134620  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_123000.solverstate
I0429 19:38:15.350271  5145 solver.cpp:337] Iteration 123000, Testing net (#0)
I0429 19:38:15.350373  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 19:38:15.350378  5145 net.cpp:693] Ignoring source layer visualize
I0429 19:38:15.350379  5145 net.cpp:693] Ignoring source layer fake
I0429 19:43:11.630424  5145 solver.cpp:404]     Test net output #0: loss = 0.290254 (* 1 = 0.290254 loss)
I0429 19:43:11.941346  5145 solver.cpp:228] Iteration 123000, loss = 0.296465
I0429 19:43:11.941383  5145 solver.cpp:244]     Train net output #0: loss = 0.296465 (* 1 = 0.296465 loss)
I0429 19:43:11.941390  5145 sgd_solver.cpp:106] Iteration 123000, lr = 1e-18
I0429 19:44:02.582293  5145 solver.cpp:228] Iteration 123100, loss = 0.3482
I0429 19:44:02.582443  5145 solver.cpp:244]     Train net output #0: loss = 0.3482 (* 1 = 0.3482 loss)
I0429 19:44:02.582450  5145 sgd_solver.cpp:106] Iteration 123100, lr = 1e-18
I0429 19:44:52.968118  5145 solver.cpp:228] Iteration 123200, loss = 0.314729
I0429 19:44:52.968297  5145 solver.cpp:244]     Train net output #0: loss = 0.314729 (* 1 = 0.314729 loss)
I0429 19:44:52.968305  5145 sgd_solver.cpp:106] Iteration 123200, lr = 1e-18
I0429 19:45:43.442610  5145 solver.cpp:228] Iteration 123300, loss = 0.312588
I0429 19:45:43.442772  5145 solver.cpp:244]     Train net output #0: loss = 0.312588 (* 1 = 0.312588 loss)
I0429 19:45:43.442780  5145 sgd_solver.cpp:106] Iteration 123300, lr = 1e-18
I0429 19:46:38.112134  5145 solver.cpp:228] Iteration 123400, loss = 0.277698
I0429 19:46:38.112308  5145 solver.cpp:244]     Train net output #0: loss = 0.277698 (* 1 = 0.277698 loss)
I0429 19:46:38.112316  5145 sgd_solver.cpp:106] Iteration 123400, lr = 1e-18
I0429 19:47:28.695766  5145 solver.cpp:228] Iteration 123500, loss = 0.18891
I0429 19:47:28.695930  5145 solver.cpp:244]     Train net output #0: loss = 0.18891 (* 1 = 0.18891 loss)
I0429 19:47:28.695937  5145 sgd_solver.cpp:106] Iteration 123500, lr = 1e-18
I0429 19:48:19.232755  5145 solver.cpp:228] Iteration 123600, loss = 0.357975
I0429 19:48:19.233577  5145 solver.cpp:244]     Train net output #0: loss = 0.357975 (* 1 = 0.357975 loss)
I0429 19:48:19.233593  5145 sgd_solver.cpp:106] Iteration 123600, lr = 1e-18
I0429 19:49:12.147626  5145 solver.cpp:228] Iteration 123700, loss = 0.31124
I0429 19:49:12.147819  5145 solver.cpp:244]     Train net output #0: loss = 0.31124 (* 1 = 0.31124 loss)
I0429 19:49:12.147825  5145 sgd_solver.cpp:106] Iteration 123700, lr = 1e-18
I0429 19:50:02.692399  5145 solver.cpp:228] Iteration 123800, loss = 0.242482
I0429 19:50:02.692564  5145 solver.cpp:244]     Train net output #0: loss = 0.242482 (* 1 = 0.242482 loss)
I0429 19:50:02.692570  5145 sgd_solver.cpp:106] Iteration 123800, lr = 1e-18
I0429 19:50:53.392386  5145 solver.cpp:228] Iteration 123900, loss = 0.2732
I0429 19:50:53.392555  5145 solver.cpp:244]     Train net output #0: loss = 0.2732 (* 1 = 0.2732 loss)
I0429 19:50:53.392562  5145 sgd_solver.cpp:106] Iteration 123900, lr = 1e-18
I0429 19:51:43.595013  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_124000.caffemodel
I0429 19:52:10.276931  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_124000.solverstate
I0429 19:52:10.483935  5145 solver.cpp:337] Iteration 124000, Testing net (#0)
I0429 19:52:10.484020  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 19:52:10.484040  5145 net.cpp:693] Ignoring source layer visualize
I0429 19:52:10.484042  5145 net.cpp:693] Ignoring source layer fake
I0429 19:57:07.759683  5145 solver.cpp:404]     Test net output #0: loss = 0.286111 (* 1 = 0.286111 loss)
I0429 19:57:08.073360  5145 solver.cpp:228] Iteration 124000, loss = 0.242346
I0429 19:57:08.073408  5145 solver.cpp:244]     Train net output #0: loss = 0.242346 (* 1 = 0.242346 loss)
I0429 19:57:08.073416  5145 sgd_solver.cpp:106] Iteration 124000, lr = 1e-18
I0429 19:58:00.802506  5145 solver.cpp:228] Iteration 124100, loss = 0.256902
I0429 19:58:00.802742  5145 solver.cpp:244]     Train net output #0: loss = 0.256902 (* 1 = 0.256902 loss)
I0429 19:58:00.802750  5145 sgd_solver.cpp:106] Iteration 124100, lr = 1e-18
I0429 19:58:51.223314  5145 solver.cpp:228] Iteration 124200, loss = 0.190463
I0429 19:58:51.223474  5145 solver.cpp:244]     Train net output #0: loss = 0.190463 (* 1 = 0.190463 loss)
I0429 19:58:51.223482  5145 sgd_solver.cpp:106] Iteration 124200, lr = 1e-18
I0429 19:59:41.756274  5145 solver.cpp:228] Iteration 124300, loss = 0.283041
I0429 19:59:41.756445  5145 solver.cpp:244]     Train net output #0: loss = 0.283041 (* 1 = 0.283041 loss)
I0429 19:59:41.756453  5145 sgd_solver.cpp:106] Iteration 124300, lr = 1e-18
I0429 20:00:36.053439  5145 solver.cpp:228] Iteration 124400, loss = 0.336648
I0429 20:00:36.053611  5145 solver.cpp:244]     Train net output #0: loss = 0.336648 (* 1 = 0.336648 loss)
I0429 20:00:36.053617  5145 sgd_solver.cpp:106] Iteration 124400, lr = 1e-18
I0429 20:01:26.551040  5145 solver.cpp:228] Iteration 124500, loss = 0.217086
I0429 20:01:26.551199  5145 solver.cpp:244]     Train net output #0: loss = 0.217086 (* 1 = 0.217086 loss)
I0429 20:01:26.551208  5145 sgd_solver.cpp:106] Iteration 124500, lr = 1e-18
I0429 20:02:17.070657  5145 solver.cpp:228] Iteration 124600, loss = 0.271436
I0429 20:02:17.070804  5145 solver.cpp:244]     Train net output #0: loss = 0.271436 (* 1 = 0.271436 loss)
I0429 20:02:17.070811  5145 sgd_solver.cpp:106] Iteration 124600, lr = 1e-18
I0429 20:03:11.109948  5145 solver.cpp:228] Iteration 124700, loss = 0.232964
I0429 20:03:11.110126  5145 solver.cpp:244]     Train net output #0: loss = 0.232964 (* 1 = 0.232964 loss)
I0429 20:03:11.110136  5145 sgd_solver.cpp:106] Iteration 124700, lr = 1e-18
I0429 20:04:01.579924  5145 solver.cpp:228] Iteration 124800, loss = 0.236486
I0429 20:04:01.580083  5145 solver.cpp:244]     Train net output #0: loss = 0.236486 (* 1 = 0.236486 loss)
I0429 20:04:01.580090  5145 sgd_solver.cpp:106] Iteration 124800, lr = 1e-18
I0429 20:04:52.014819  5145 solver.cpp:228] Iteration 124900, loss = 0.255206
I0429 20:04:52.015012  5145 solver.cpp:244]     Train net output #0: loss = 0.255206 (* 1 = 0.255206 loss)
I0429 20:04:52.015029  5145 sgd_solver.cpp:106] Iteration 124900, lr = 1e-18
I0429 20:05:44.335559  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_125000.caffemodel
I0429 20:06:25.290606  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_125000.solverstate
I0429 20:06:25.480190  5145 solver.cpp:337] Iteration 125000, Testing net (#0)
I0429 20:06:25.480273  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 20:06:25.480293  5145 net.cpp:693] Ignoring source layer visualize
I0429 20:06:25.480295  5145 net.cpp:693] Ignoring source layer fake
I0429 20:11:20.986052  5145 solver.cpp:404]     Test net output #0: loss = 0.284379 (* 1 = 0.284379 loss)
I0429 20:11:21.299618  5145 solver.cpp:228] Iteration 125000, loss = 0.295636
I0429 20:11:21.299635  5145 solver.cpp:244]     Train net output #0: loss = 0.295636 (* 1 = 0.295636 loss)
I0429 20:11:21.299659  5145 sgd_solver.cpp:106] Iteration 125000, lr = 1e-18
I0429 20:12:11.778707  5145 solver.cpp:228] Iteration 125100, loss = 0.185111
I0429 20:12:11.778880  5145 solver.cpp:244]     Train net output #0: loss = 0.185111 (* 1 = 0.185111 loss)
I0429 20:12:11.778888  5145 sgd_solver.cpp:106] Iteration 125100, lr = 1e-18
I0429 20:13:02.193259  5145 solver.cpp:228] Iteration 125200, loss = 0.370453
I0429 20:13:02.193451  5145 solver.cpp:244]     Train net output #0: loss = 0.370453 (* 1 = 0.370453 loss)
I0429 20:13:02.193459  5145 sgd_solver.cpp:106] Iteration 125200, lr = 1e-18
I0429 20:13:54.315274  5145 solver.cpp:228] Iteration 125300, loss = 0.241363
I0429 20:13:54.315438  5145 solver.cpp:244]     Train net output #0: loss = 0.241363 (* 1 = 0.241363 loss)
I0429 20:13:54.315445  5145 sgd_solver.cpp:106] Iteration 125300, lr = 1e-18
I0429 20:14:44.799685  5145 solver.cpp:228] Iteration 125400, loss = 0.297636
I0429 20:14:44.799863  5145 solver.cpp:244]     Train net output #0: loss = 0.297636 (* 1 = 0.297636 loss)
I0429 20:14:44.799871  5145 sgd_solver.cpp:106] Iteration 125400, lr = 1e-18
I0429 20:15:36.965617  5145 solver.cpp:228] Iteration 125500, loss = 0.1529
I0429 20:15:36.965780  5145 solver.cpp:244]     Train net output #0: loss = 0.1529 (* 1 = 0.1529 loss)
I0429 20:15:36.965788  5145 sgd_solver.cpp:106] Iteration 125500, lr = 1e-18
I0429 20:16:27.465827  5145 solver.cpp:228] Iteration 125600, loss = 0.237636
I0429 20:16:27.465977  5145 solver.cpp:244]     Train net output #0: loss = 0.237636 (* 1 = 0.237636 loss)
I0429 20:16:27.465987  5145 sgd_solver.cpp:106] Iteration 125600, lr = 1e-18
I0429 20:17:17.994674  5145 solver.cpp:228] Iteration 125700, loss = 0.198165
I0429 20:17:17.994843  5145 solver.cpp:244]     Train net output #0: loss = 0.198165 (* 1 = 0.198165 loss)
I0429 20:17:17.994848  5145 sgd_solver.cpp:106] Iteration 125700, lr = 1e-18
I0429 20:18:10.901496  5145 solver.cpp:228] Iteration 125800, loss = 0.315519
I0429 20:18:10.901677  5145 solver.cpp:244]     Train net output #0: loss = 0.315519 (* 1 = 0.315519 loss)
I0429 20:18:10.901687  5145 sgd_solver.cpp:106] Iteration 125800, lr = 1e-18
I0429 20:19:01.430903  5145 solver.cpp:228] Iteration 125900, loss = 0.230312
I0429 20:19:01.431068  5145 solver.cpp:244]     Train net output #0: loss = 0.230312 (* 1 = 0.230312 loss)
I0429 20:19:01.431077  5145 sgd_solver.cpp:106] Iteration 125900, lr = 1e-18
I0429 20:19:51.599061  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_126000.caffemodel
I0429 20:20:17.026924  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_126000.solverstate
I0429 20:20:17.229964  5145 solver.cpp:337] Iteration 126000, Testing net (#0)
I0429 20:20:17.230051  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 20:20:17.230073  5145 net.cpp:693] Ignoring source layer visualize
I0429 20:20:17.230077  5145 net.cpp:693] Ignoring source layer fake
I0429 20:25:14.974706  5145 solver.cpp:404]     Test net output #0: loss = 0.280081 (* 1 = 0.280081 loss)
I0429 20:25:15.286284  5145 solver.cpp:228] Iteration 126000, loss = 0.224321
I0429 20:25:15.286305  5145 solver.cpp:244]     Train net output #0: loss = 0.224321 (* 1 = 0.224321 loss)
I0429 20:25:15.286326  5145 sgd_solver.cpp:106] Iteration 126000, lr = 1e-18
I0429 20:26:17.031821  5145 solver.cpp:228] Iteration 126100, loss = 0.310701
I0429 20:26:17.031987  5145 solver.cpp:244]     Train net output #0: loss = 0.310701 (* 1 = 0.310701 loss)
I0429 20:26:17.031997  5145 sgd_solver.cpp:106] Iteration 126100, lr = 1e-18
I0429 20:27:06.864143  5145 solver.cpp:228] Iteration 126200, loss = 0.23241
I0429 20:27:06.864318  5145 solver.cpp:244]     Train net output #0: loss = 0.23241 (* 1 = 0.23241 loss)
I0429 20:27:06.864326  5145 sgd_solver.cpp:106] Iteration 126200, lr = 1e-18
I0429 20:27:57.320307  5145 solver.cpp:228] Iteration 126300, loss = 0.209274
I0429 20:27:57.320477  5145 solver.cpp:244]     Train net output #0: loss = 0.209274 (* 1 = 0.209274 loss)
I0429 20:27:57.320484  5145 sgd_solver.cpp:106] Iteration 126300, lr = 1e-18
I0429 20:28:47.871983  5145 solver.cpp:228] Iteration 126400, loss = 0.258863
I0429 20:28:47.872130  5145 solver.cpp:244]     Train net output #0: loss = 0.258863 (* 1 = 0.258863 loss)
I0429 20:28:47.872138  5145 sgd_solver.cpp:106] Iteration 126400, lr = 1e-18
I0429 20:29:49.584183  5145 solver.cpp:228] Iteration 126500, loss = 0.284879
I0429 20:29:49.584375  5145 solver.cpp:244]     Train net output #0: loss = 0.284879 (* 1 = 0.284879 loss)
I0429 20:29:49.584385  5145 sgd_solver.cpp:106] Iteration 126500, lr = 1e-18
I0429 20:30:39.792178  5145 solver.cpp:228] Iteration 126600, loss = 0.376538
I0429 20:30:39.792347  5145 solver.cpp:244]     Train net output #0: loss = 0.376538 (* 1 = 0.376538 loss)
I0429 20:30:39.792354  5145 sgd_solver.cpp:106] Iteration 126600, lr = 1e-18
I0429 20:31:30.219166  5145 solver.cpp:228] Iteration 126700, loss = 0.25563
I0429 20:31:30.219321  5145 solver.cpp:244]     Train net output #0: loss = 0.25563 (* 1 = 0.25563 loss)
I0429 20:31:30.219329  5145 sgd_solver.cpp:106] Iteration 126700, lr = 1e-18
I0429 20:32:30.849689  5145 solver.cpp:228] Iteration 126800, loss = 0.247135
I0429 20:32:30.849855  5145 solver.cpp:244]     Train net output #0: loss = 0.247135 (* 1 = 0.247135 loss)
I0429 20:32:30.849864  5145 sgd_solver.cpp:106] Iteration 126800, lr = 1e-18
I0429 20:33:20.860236  5145 solver.cpp:228] Iteration 126900, loss = 0.250064
I0429 20:33:20.860400  5145 solver.cpp:244]     Train net output #0: loss = 0.250064 (* 1 = 0.250064 loss)
I0429 20:33:20.860407  5145 sgd_solver.cpp:106] Iteration 126900, lr = 1e-18
I0429 20:34:11.071245  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_127000.caffemodel
I0429 20:34:38.543797  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_127000.solverstate
I0429 20:34:38.734148  5145 solver.cpp:337] Iteration 127000, Testing net (#0)
I0429 20:34:38.734233  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 20:34:38.734236  5145 net.cpp:693] Ignoring source layer visualize
I0429 20:34:38.734238  5145 net.cpp:693] Ignoring source layer fake
I0429 20:39:34.238108  5145 solver.cpp:404]     Test net output #0: loss = 0.287456 (* 1 = 0.287456 loss)
I0429 20:39:34.560962  5145 solver.cpp:228] Iteration 127000, loss = 0.206169
I0429 20:39:34.561002  5145 solver.cpp:244]     Train net output #0: loss = 0.206169 (* 1 = 0.206169 loss)
I0429 20:39:34.561008  5145 sgd_solver.cpp:106] Iteration 127000, lr = 1e-18
I0429 20:40:25.011868  5145 solver.cpp:228] Iteration 127100, loss = 0.166746
I0429 20:40:25.012019  5145 solver.cpp:244]     Train net output #0: loss = 0.166746 (* 1 = 0.166746 loss)
I0429 20:40:25.012027  5145 sgd_solver.cpp:106] Iteration 127100, lr = 1e-18
I0429 20:41:24.343411  5145 solver.cpp:228] Iteration 127200, loss = 0.292251
I0429 20:41:24.343600  5145 solver.cpp:244]     Train net output #0: loss = 0.292251 (* 1 = 0.292251 loss)
I0429 20:41:24.343608  5145 sgd_solver.cpp:106] Iteration 127200, lr = 1e-18
I0429 20:42:14.719980  5145 solver.cpp:228] Iteration 127300, loss = 0.368723
I0429 20:42:14.720165  5145 solver.cpp:244]     Train net output #0: loss = 0.368723 (* 1 = 0.368723 loss)
I0429 20:42:14.720173  5145 sgd_solver.cpp:106] Iteration 127300, lr = 1e-18
I0429 20:43:05.150192  5145 solver.cpp:228] Iteration 127400, loss = 0.214855
I0429 20:43:05.150357  5145 solver.cpp:244]     Train net output #0: loss = 0.214855 (* 1 = 0.214855 loss)
I0429 20:43:05.150365  5145 sgd_solver.cpp:106] Iteration 127400, lr = 1e-18
I0429 20:44:03.556236  5145 solver.cpp:228] Iteration 127500, loss = 0.241648
I0429 20:44:03.556426  5145 solver.cpp:244]     Train net output #0: loss = 0.241648 (* 1 = 0.241648 loss)
I0429 20:44:03.556434  5145 sgd_solver.cpp:106] Iteration 127500, lr = 1e-19
I0429 20:44:53.705797  5145 solver.cpp:228] Iteration 127600, loss = 0.245049
I0429 20:44:53.705977  5145 solver.cpp:244]     Train net output #0: loss = 0.245049 (* 1 = 0.245049 loss)
I0429 20:44:53.705986  5145 sgd_solver.cpp:106] Iteration 127600, lr = 1e-19
I0429 20:45:44.181289  5145 solver.cpp:228] Iteration 127700, loss = 0.306921
I0429 20:45:44.181445  5145 solver.cpp:244]     Train net output #0: loss = 0.306921 (* 1 = 0.306921 loss)
I0429 20:45:44.181453  5145 sgd_solver.cpp:106] Iteration 127700, lr = 1e-19
I0429 20:46:46.104931  5145 solver.cpp:228] Iteration 127800, loss = 0.429197
I0429 20:46:46.105114  5145 solver.cpp:244]     Train net output #0: loss = 0.429197 (* 1 = 0.429197 loss)
I0429 20:46:46.105121  5145 sgd_solver.cpp:106] Iteration 127800, lr = 1e-19
I0429 20:47:35.969487  5145 solver.cpp:228] Iteration 127900, loss = 0.19318
I0429 20:47:35.969633  5145 solver.cpp:244]     Train net output #0: loss = 0.19318 (* 1 = 0.19318 loss)
I0429 20:47:35.969640  5145 sgd_solver.cpp:106] Iteration 127900, lr = 1e-19
I0429 20:48:26.131106  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_128000.caffemodel
I0429 20:48:37.272274  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_128000.solverstate
I0429 20:48:37.457247  5145 solver.cpp:337] Iteration 128000, Testing net (#0)
I0429 20:48:37.457345  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 20:48:37.457350  5145 net.cpp:693] Ignoring source layer visualize
I0429 20:48:37.457352  5145 net.cpp:693] Ignoring source layer fake
I0429 20:53:32.718030  5145 solver.cpp:404]     Test net output #0: loss = 0.289801 (* 1 = 0.289801 loss)
I0429 20:53:33.030824  5145 solver.cpp:228] Iteration 128000, loss = 0.244802
I0429 20:53:33.030860  5145 solver.cpp:244]     Train net output #0: loss = 0.244802 (* 1 = 0.244802 loss)
I0429 20:53:33.030867  5145 sgd_solver.cpp:106] Iteration 128000, lr = 1e-19
I0429 20:54:29.969588  5145 solver.cpp:228] Iteration 128100, loss = 0.189062
I0429 20:54:29.969750  5145 solver.cpp:244]     Train net output #0: loss = 0.189062 (* 1 = 0.189062 loss)
I0429 20:54:29.969758  5145 sgd_solver.cpp:106] Iteration 128100, lr = 1e-19
I0429 20:55:20.071712  5145 solver.cpp:228] Iteration 128200, loss = 0.2861
I0429 20:55:20.071876  5145 solver.cpp:244]     Train net output #0: loss = 0.2861 (* 1 = 0.2861 loss)
I0429 20:55:20.071882  5145 sgd_solver.cpp:106] Iteration 128200, lr = 1e-19
I0429 20:56:10.514663  5145 solver.cpp:228] Iteration 128300, loss = 0.36628
I0429 20:56:10.514818  5145 solver.cpp:244]     Train net output #0: loss = 0.36628 (* 1 = 0.36628 loss)
I0429 20:56:10.514825  5145 sgd_solver.cpp:106] Iteration 128300, lr = 1e-19
I0429 20:57:06.756517  5145 solver.cpp:228] Iteration 128400, loss = 0.251859
I0429 20:57:06.756698  5145 solver.cpp:244]     Train net output #0: loss = 0.251859 (* 1 = 0.251859 loss)
I0429 20:57:06.756706  5145 sgd_solver.cpp:106] Iteration 128400, lr = 1e-19
I0429 20:57:57.151125  5145 solver.cpp:228] Iteration 128500, loss = 0.099999
I0429 20:57:57.151304  5145 solver.cpp:244]     Train net output #0: loss = 0.099999 (* 1 = 0.099999 loss)
I0429 20:57:57.151310  5145 sgd_solver.cpp:106] Iteration 128500, lr = 1e-19
I0429 20:58:47.835621  5145 solver.cpp:228] Iteration 128600, loss = 0.251733
I0429 20:58:47.835796  5145 solver.cpp:244]     Train net output #0: loss = 0.251733 (* 1 = 0.251733 loss)
I0429 20:58:47.835803  5145 sgd_solver.cpp:106] Iteration 128600, lr = 1e-19
I0429 20:59:43.396479  5145 solver.cpp:228] Iteration 128700, loss = 0.417625
I0429 20:59:43.396641  5145 solver.cpp:244]     Train net output #0: loss = 0.417625 (* 1 = 0.417625 loss)
I0429 20:59:43.396649  5145 sgd_solver.cpp:106] Iteration 128700, lr = 1e-19
I0429 21:00:33.890738  5145 solver.cpp:228] Iteration 128800, loss = 0.251971
I0429 21:00:33.890919  5145 solver.cpp:244]     Train net output #0: loss = 0.251971 (* 1 = 0.251971 loss)
I0429 21:00:33.890926  5145 sgd_solver.cpp:106] Iteration 128800, lr = 1e-19
I0429 21:01:30.508939  5145 solver.cpp:228] Iteration 128900, loss = 0.159187
I0429 21:01:30.509135  5145 solver.cpp:244]     Train net output #0: loss = 0.159187 (* 1 = 0.159187 loss)
I0429 21:01:30.509143  5145 sgd_solver.cpp:106] Iteration 128900, lr = 1e-19
I0429 21:02:20.337612  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_129000.caffemodel
I0429 21:02:33.598934  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_129000.solverstate
I0429 21:02:33.794147  5145 solver.cpp:337] Iteration 129000, Testing net (#0)
I0429 21:02:33.794231  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 21:02:33.794250  5145 net.cpp:693] Ignoring source layer visualize
I0429 21:02:33.794253  5145 net.cpp:693] Ignoring source layer fake
I0429 21:07:29.994280  5145 solver.cpp:404]     Test net output #0: loss = 0.28592 (* 1 = 0.28592 loss)
I0429 21:07:30.307096  5145 solver.cpp:228] Iteration 129000, loss = 0.33345
I0429 21:07:30.307113  5145 solver.cpp:244]     Train net output #0: loss = 0.33345 (* 1 = 0.33345 loss)
I0429 21:07:30.307137  5145 sgd_solver.cpp:106] Iteration 129000, lr = 1e-19
I0429 21:08:20.784417  5145 solver.cpp:228] Iteration 129100, loss = 0.333111
I0429 21:08:20.784595  5145 solver.cpp:244]     Train net output #0: loss = 0.333111 (* 1 = 0.333111 loss)
I0429 21:08:20.784610  5145 sgd_solver.cpp:106] Iteration 129100, lr = 1e-19
I0429 21:09:11.393697  5145 solver.cpp:228] Iteration 129200, loss = 0.31203
I0429 21:09:11.393862  5145 solver.cpp:244]     Train net output #0: loss = 0.31203 (* 1 = 0.31203 loss)
I0429 21:09:11.393872  5145 sgd_solver.cpp:106] Iteration 129200, lr = 1e-19
I0429 21:10:08.440678  5145 solver.cpp:228] Iteration 129300, loss = 0.295693
I0429 21:10:08.440847  5145 solver.cpp:244]     Train net output #0: loss = 0.295693 (* 1 = 0.295693 loss)
I0429 21:10:08.440855  5145 sgd_solver.cpp:106] Iteration 129300, lr = 1e-19
I0429 21:10:58.851168  5145 solver.cpp:228] Iteration 129400, loss = 0.377148
I0429 21:10:58.851339  5145 solver.cpp:244]     Train net output #0: loss = 0.377148 (* 1 = 0.377148 loss)
I0429 21:10:58.851347  5145 sgd_solver.cpp:106] Iteration 129400, lr = 1e-19
I0429 21:11:49.414872  5145 solver.cpp:228] Iteration 129500, loss = 0.253929
I0429 21:11:49.415047  5145 solver.cpp:244]     Train net output #0: loss = 0.253929 (* 1 = 0.253929 loss)
I0429 21:11:49.415055  5145 sgd_solver.cpp:106] Iteration 129500, lr = 1e-19
I0429 21:12:48.514662  5145 solver.cpp:228] Iteration 129600, loss = 0.33163
I0429 21:12:48.515653  5145 solver.cpp:244]     Train net output #0: loss = 0.33163 (* 1 = 0.33163 loss)
I0429 21:12:48.515661  5145 sgd_solver.cpp:106] Iteration 129600, lr = 1e-19
I0429 21:13:38.683241  5145 solver.cpp:228] Iteration 129700, loss = 0.203116
I0429 21:13:38.683419  5145 solver.cpp:244]     Train net output #0: loss = 0.203116 (* 1 = 0.203116 loss)
I0429 21:13:38.683426  5145 sgd_solver.cpp:106] Iteration 129700, lr = 1e-19
I0429 21:14:29.211064  5145 solver.cpp:228] Iteration 129800, loss = 0.343583
I0429 21:14:29.211227  5145 solver.cpp:244]     Train net output #0: loss = 0.343583 (* 1 = 0.343583 loss)
I0429 21:14:29.211236  5145 sgd_solver.cpp:106] Iteration 129800, lr = 1e-19
I0429 21:15:19.788478  5145 solver.cpp:228] Iteration 129900, loss = 0.277465
I0429 21:15:19.788632  5145 solver.cpp:244]     Train net output #0: loss = 0.277465 (* 1 = 0.277465 loss)
I0429 21:15:19.788640  5145 sgd_solver.cpp:106] Iteration 129900, lr = 1e-19
I0429 21:16:22.177139  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_130000.caffemodel
I0429 21:16:35.459899  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_130000.solverstate
I0429 21:16:35.670478  5145 solver.cpp:337] Iteration 130000, Testing net (#0)
I0429 21:16:35.670547  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 21:16:35.670552  5145 net.cpp:693] Ignoring source layer visualize
I0429 21:16:35.670553  5145 net.cpp:693] Ignoring source layer fake
I0429 21:21:32.241696  5145 solver.cpp:404]     Test net output #0: loss = 0.283675 (* 1 = 0.283675 loss)
I0429 21:21:32.559396  5145 solver.cpp:228] Iteration 130000, loss = 0.225222
I0429 21:21:32.559430  5145 solver.cpp:244]     Train net output #0: loss = 0.225222 (* 1 = 0.225222 loss)
I0429 21:21:32.559438  5145 sgd_solver.cpp:106] Iteration 130000, lr = 1e-19
I0429 21:22:23.055459  5145 solver.cpp:228] Iteration 130100, loss = 0.213325
I0429 21:22:23.055655  5145 solver.cpp:244]     Train net output #0: loss = 0.213325 (* 1 = 0.213325 loss)
I0429 21:22:23.055666  5145 sgd_solver.cpp:106] Iteration 130100, lr = 1e-19
I0429 21:23:13.643471  5145 solver.cpp:228] Iteration 130200, loss = 0.270674
I0429 21:23:13.643630  5145 solver.cpp:244]     Train net output #0: loss = 0.270674 (* 1 = 0.270674 loss)
I0429 21:23:13.643637  5145 sgd_solver.cpp:106] Iteration 130200, lr = 1e-19
I0429 21:24:06.796533  5145 solver.cpp:228] Iteration 130300, loss = 0.235052
I0429 21:24:06.796895  5145 solver.cpp:244]     Train net output #0: loss = 0.235052 (* 1 = 0.235052 loss)
I0429 21:24:06.796903  5145 sgd_solver.cpp:106] Iteration 130300, lr = 1e-19
I0429 21:24:57.283576  5145 solver.cpp:228] Iteration 130400, loss = 0.0948526
I0429 21:24:57.283740  5145 solver.cpp:244]     Train net output #0: loss = 0.0948526 (* 1 = 0.0948526 loss)
I0429 21:24:57.283748  5145 sgd_solver.cpp:106] Iteration 130400, lr = 1e-19
I0429 21:25:47.734256  5145 solver.cpp:228] Iteration 130500, loss = 0.163994
I0429 21:25:47.734418  5145 solver.cpp:244]     Train net output #0: loss = 0.163994 (* 1 = 0.163994 loss)
I0429 21:25:47.734428  5145 sgd_solver.cpp:106] Iteration 130500, lr = 1e-19
I0429 21:26:42.013326  5145 solver.cpp:228] Iteration 130600, loss = 0.210022
I0429 21:26:42.013494  5145 solver.cpp:244]     Train net output #0: loss = 0.210022 (* 1 = 0.210022 loss)
I0429 21:26:42.013500  5145 sgd_solver.cpp:106] Iteration 130600, lr = 1e-19
I0429 21:27:32.220221  5145 solver.cpp:228] Iteration 130700, loss = 0.215031
I0429 21:27:32.220404  5145 solver.cpp:244]     Train net output #0: loss = 0.215031 (* 1 = 0.215031 loss)
I0429 21:27:32.220412  5145 sgd_solver.cpp:106] Iteration 130700, lr = 1e-19
I0429 21:28:22.812430  5145 solver.cpp:228] Iteration 130800, loss = 0.269255
I0429 21:28:22.812578  5145 solver.cpp:244]     Train net output #0: loss = 0.269255 (* 1 = 0.269255 loss)
I0429 21:28:22.812587  5145 sgd_solver.cpp:106] Iteration 130800, lr = 1e-19
I0429 21:29:13.274432  5145 solver.cpp:228] Iteration 130900, loss = 0.278453
I0429 21:29:13.274613  5145 solver.cpp:244]     Train net output #0: loss = 0.278453 (* 1 = 0.278453 loss)
I0429 21:29:13.274631  5145 sgd_solver.cpp:106] Iteration 130900, lr = 1e-19
I0429 21:30:09.552726  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_131000.caffemodel
I0429 21:30:15.091248  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_131000.solverstate
I0429 21:30:15.277673  5145 solver.cpp:337] Iteration 131000, Testing net (#0)
I0429 21:30:15.277757  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 21:30:15.277776  5145 net.cpp:693] Ignoring source layer visualize
I0429 21:30:15.277777  5145 net.cpp:693] Ignoring source layer fake
I0429 21:35:11.234009  5145 solver.cpp:404]     Test net output #0: loss = 0.28042 (* 1 = 0.28042 loss)
I0429 21:35:11.553244  5145 solver.cpp:228] Iteration 131000, loss = 0.293834
I0429 21:35:11.553283  5145 solver.cpp:244]     Train net output #0: loss = 0.293834 (* 1 = 0.293834 loss)
I0429 21:35:11.553290  5145 sgd_solver.cpp:106] Iteration 131000, lr = 1e-19
I0429 21:36:01.865140  5145 solver.cpp:228] Iteration 131100, loss = 0.364897
I0429 21:36:01.865305  5145 solver.cpp:244]     Train net output #0: loss = 0.364897 (* 1 = 0.364897 loss)
I0429 21:36:01.865312  5145 sgd_solver.cpp:106] Iteration 131100, lr = 1e-19
I0429 21:36:52.260267  5145 solver.cpp:228] Iteration 131200, loss = 0.2241
I0429 21:36:52.260414  5145 solver.cpp:244]     Train net output #0: loss = 0.2241 (* 1 = 0.2241 loss)
I0429 21:36:52.260421  5145 sgd_solver.cpp:106] Iteration 131200, lr = 1e-19
I0429 21:37:56.673152  5145 solver.cpp:228] Iteration 131300, loss = 0.352441
I0429 21:37:56.673315  5145 solver.cpp:244]     Train net output #0: loss = 0.352441 (* 1 = 0.352441 loss)
I0429 21:37:56.673322  5145 sgd_solver.cpp:106] Iteration 131300, lr = 1e-19
I0429 21:38:46.952885  5145 solver.cpp:228] Iteration 131400, loss = 0.252121
I0429 21:38:46.953045  5145 solver.cpp:244]     Train net output #0: loss = 0.252121 (* 1 = 0.252121 loss)
I0429 21:38:46.953052  5145 sgd_solver.cpp:106] Iteration 131400, lr = 1e-19
I0429 21:39:40.423750  5145 solver.cpp:228] Iteration 131500, loss = 0.309774
I0429 21:39:40.423910  5145 solver.cpp:244]     Train net output #0: loss = 0.309774 (* 1 = 0.309774 loss)
I0429 21:39:40.423918  5145 sgd_solver.cpp:106] Iteration 131500, lr = 1e-19
I0429 21:40:30.930721  5145 solver.cpp:228] Iteration 131600, loss = 0.324822
I0429 21:40:30.930876  5145 solver.cpp:244]     Train net output #0: loss = 0.324822 (* 1 = 0.324822 loss)
I0429 21:40:30.930884  5145 sgd_solver.cpp:106] Iteration 131600, lr = 1e-19
I0429 21:41:21.614166  5145 solver.cpp:228] Iteration 131700, loss = 0.229916
I0429 21:41:21.614329  5145 solver.cpp:244]     Train net output #0: loss = 0.229916 (* 1 = 0.229916 loss)
I0429 21:41:21.614336  5145 sgd_solver.cpp:106] Iteration 131700, lr = 1e-19
I0429 21:42:25.735189  5145 solver.cpp:228] Iteration 131800, loss = 0.261161
I0429 21:42:25.735359  5145 solver.cpp:244]     Train net output #0: loss = 0.261161 (* 1 = 0.261161 loss)
I0429 21:42:25.735368  5145 sgd_solver.cpp:106] Iteration 131800, lr = 1e-19
I0429 21:43:15.838114  5145 solver.cpp:228] Iteration 131900, loss = 0.373164
I0429 21:43:15.838294  5145 solver.cpp:244]     Train net output #0: loss = 0.373164 (* 1 = 0.373164 loss)
I0429 21:43:15.838301  5145 sgd_solver.cpp:106] Iteration 131900, lr = 1e-19
I0429 21:44:06.025867  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_132000.caffemodel
I0429 21:44:36.212158  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_132000.solverstate
I0429 21:44:36.419337  5145 solver.cpp:337] Iteration 132000, Testing net (#0)
I0429 21:44:36.419422  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 21:44:36.419426  5145 net.cpp:693] Ignoring source layer visualize
I0429 21:44:36.419443  5145 net.cpp:693] Ignoring source layer fake
I0429 21:49:32.275413  5145 solver.cpp:404]     Test net output #0: loss = 0.288449 (* 1 = 0.288449 loss)
I0429 21:49:32.590275  5145 solver.cpp:228] Iteration 132000, loss = 0.436793
I0429 21:49:32.590293  5145 solver.cpp:244]     Train net output #0: loss = 0.436793 (* 1 = 0.436793 loss)
I0429 21:49:32.590315  5145 sgd_solver.cpp:106] Iteration 132000, lr = 1e-19
I0429 21:50:39.802155  5145 solver.cpp:228] Iteration 132100, loss = 0.246289
I0429 21:50:39.802336  5145 solver.cpp:244]     Train net output #0: loss = 0.246289 (* 1 = 0.246289 loss)
I0429 21:50:39.802343  5145 sgd_solver.cpp:106] Iteration 132100, lr = 1e-19
I0429 21:51:30.176926  5145 solver.cpp:228] Iteration 132200, loss = 0.330579
I0429 21:51:30.177098  5145 solver.cpp:244]     Train net output #0: loss = 0.330579 (* 1 = 0.330579 loss)
I0429 21:51:30.177105  5145 sgd_solver.cpp:106] Iteration 132200, lr = 1e-19
I0429 21:52:20.755836  5145 solver.cpp:228] Iteration 132300, loss = 0.262978
I0429 21:52:20.756013  5145 solver.cpp:244]     Train net output #0: loss = 0.262978 (* 1 = 0.262978 loss)
I0429 21:52:20.756021  5145 sgd_solver.cpp:106] Iteration 132300, lr = 1e-19
I0429 21:53:28.199416  5145 solver.cpp:228] Iteration 132400, loss = 0.233401
I0429 21:53:28.199573  5145 solver.cpp:244]     Train net output #0: loss = 0.233401 (* 1 = 0.233401 loss)
I0429 21:53:28.199579  5145 sgd_solver.cpp:106] Iteration 132400, lr = 1e-19
I0429 21:54:18.307417  5145 solver.cpp:228] Iteration 132500, loss = 0.205167
I0429 21:54:18.307576  5145 solver.cpp:244]     Train net output #0: loss = 0.205167 (* 1 = 0.205167 loss)
I0429 21:54:18.307585  5145 sgd_solver.cpp:106] Iteration 132500, lr = 1e-19
I0429 21:55:08.954430  5145 solver.cpp:228] Iteration 132600, loss = 0.246131
I0429 21:55:08.954577  5145 solver.cpp:244]     Train net output #0: loss = 0.246131 (* 1 = 0.246131 loss)
I0429 21:55:08.954584  5145 sgd_solver.cpp:106] Iteration 132600, lr = 1e-19
I0429 21:56:16.460052  5145 solver.cpp:228] Iteration 132700, loss = 0.249998
I0429 21:56:16.460213  5145 solver.cpp:244]     Train net output #0: loss = 0.249998 (* 1 = 0.249998 loss)
I0429 21:56:16.460222  5145 sgd_solver.cpp:106] Iteration 132700, lr = 1e-19
I0429 21:57:06.206658  5145 solver.cpp:228] Iteration 132800, loss = 0.323458
I0429 21:57:06.206818  5145 solver.cpp:244]     Train net output #0: loss = 0.323458 (* 1 = 0.323458 loss)
I0429 21:57:06.206825  5145 sgd_solver.cpp:106] Iteration 132800, lr = 1e-19
I0429 21:57:56.698483  5145 solver.cpp:228] Iteration 132900, loss = 0.216171
I0429 21:57:56.698639  5145 solver.cpp:244]     Train net output #0: loss = 0.216171 (* 1 = 0.216171 loss)
I0429 21:57:56.698647  5145 sgd_solver.cpp:106] Iteration 132900, lr = 1e-19
I0429 21:58:46.876726  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_133000.caffemodel
I0429 21:59:00.757668  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_133000.solverstate
I0429 21:59:00.949415  5145 solver.cpp:337] Iteration 133000, Testing net (#0)
I0429 21:59:00.949535  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 21:59:00.949543  5145 net.cpp:693] Ignoring source layer visualize
I0429 21:59:00.949546  5145 net.cpp:693] Ignoring source layer fake
I0429 22:03:57.657814  5145 solver.cpp:404]     Test net output #0: loss = 0.289082 (* 1 = 0.289082 loss)
I0429 22:03:57.973412  5145 solver.cpp:228] Iteration 133000, loss = 0.270589
I0429 22:03:57.973453  5145 solver.cpp:244]     Train net output #0: loss = 0.270589 (* 1 = 0.270589 loss)
I0429 22:03:57.973461  5145 sgd_solver.cpp:106] Iteration 133000, lr = 1e-19
I0429 22:05:05.341379  5145 solver.cpp:228] Iteration 133100, loss = 0.176255
I0429 22:05:05.341616  5145 solver.cpp:244]     Train net output #0: loss = 0.176255 (* 1 = 0.176255 loss)
I0429 22:05:05.341639  5145 sgd_solver.cpp:106] Iteration 133100, lr = 1e-19
I0429 22:05:55.460708  5145 solver.cpp:228] Iteration 133200, loss = 0.298282
I0429 22:05:55.460880  5145 solver.cpp:244]     Train net output #0: loss = 0.298282 (* 1 = 0.298282 loss)
I0429 22:05:55.460887  5145 sgd_solver.cpp:106] Iteration 133200, lr = 1e-19
I0429 22:06:46.116339  5145 solver.cpp:228] Iteration 133300, loss = 0.237759
I0429 22:06:46.116521  5145 solver.cpp:244]     Train net output #0: loss = 0.237759 (* 1 = 0.237759 loss)
I0429 22:06:46.116528  5145 sgd_solver.cpp:106] Iteration 133300, lr = 1e-19
I0429 22:07:41.371157  5145 solver.cpp:228] Iteration 133400, loss = 0.233739
I0429 22:07:41.371335  5145 solver.cpp:244]     Train net output #0: loss = 0.233739 (* 1 = 0.233739 loss)
I0429 22:07:41.371345  5145 sgd_solver.cpp:106] Iteration 133400, lr = 1e-19
I0429 22:08:31.751801  5145 solver.cpp:228] Iteration 133500, loss = 0.203924
I0429 22:08:31.751950  5145 solver.cpp:244]     Train net output #0: loss = 0.203924 (* 1 = 0.203924 loss)
I0429 22:08:31.751958  5145 sgd_solver.cpp:106] Iteration 133500, lr = 1e-19
I0429 22:09:22.340317  5145 solver.cpp:228] Iteration 133600, loss = 0.245892
I0429 22:09:22.340466  5145 solver.cpp:244]     Train net output #0: loss = 0.245892 (* 1 = 0.245892 loss)
I0429 22:09:22.340471  5145 sgd_solver.cpp:106] Iteration 133600, lr = 1e-19
I0429 22:10:12.864554  5145 solver.cpp:228] Iteration 133700, loss = 0.182493
I0429 22:10:12.864718  5145 solver.cpp:244]     Train net output #0: loss = 0.182493 (* 1 = 0.182493 loss)
I0429 22:10:12.864725  5145 sgd_solver.cpp:106] Iteration 133700, lr = 1e-19
I0429 22:11:05.473057  5145 solver.cpp:228] Iteration 133800, loss = 0.238469
I0429 22:11:05.473218  5145 solver.cpp:244]     Train net output #0: loss = 0.238469 (* 1 = 0.238469 loss)
I0429 22:11:05.473227  5145 sgd_solver.cpp:106] Iteration 133800, lr = 1e-19
I0429 22:11:56.001945  5145 solver.cpp:228] Iteration 133900, loss = 0.0428373
I0429 22:11:56.002080  5145 solver.cpp:244]     Train net output #0: loss = 0.0428373 (* 1 = 0.0428373 loss)
I0429 22:11:56.002087  5145 sgd_solver.cpp:106] Iteration 133900, lr = 1e-19
I0429 22:12:46.256181  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_134000.caffemodel
I0429 22:12:56.182533  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_134000.solverstate
I0429 22:12:56.384356  5145 solver.cpp:337] Iteration 134000, Testing net (#0)
I0429 22:12:56.384438  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 22:12:56.384441  5145 net.cpp:693] Ignoring source layer visualize
I0429 22:12:56.384459  5145 net.cpp:693] Ignoring source layer fake
I0429 22:17:52.470716  5145 solver.cpp:404]     Test net output #0: loss = 0.286178 (* 1 = 0.286178 loss)
I0429 22:17:52.782882  5145 solver.cpp:228] Iteration 134000, loss = 0.232795
I0429 22:17:52.782903  5145 solver.cpp:244]     Train net output #0: loss = 0.232795 (* 1 = 0.232795 loss)
I0429 22:17:52.782925  5145 sgd_solver.cpp:106] Iteration 134000, lr = 1e-19
I0429 22:18:45.008749  5145 solver.cpp:228] Iteration 134100, loss = 0.167358
I0429 22:18:45.008920  5145 solver.cpp:244]     Train net output #0: loss = 0.167358 (* 1 = 0.167358 loss)
I0429 22:18:45.008929  5145 sgd_solver.cpp:106] Iteration 134100, lr = 1e-19
I0429 22:19:35.494896  5145 solver.cpp:228] Iteration 134200, loss = 0.204948
I0429 22:19:35.495056  5145 solver.cpp:244]     Train net output #0: loss = 0.204948 (* 1 = 0.204948 loss)
I0429 22:19:35.495064  5145 sgd_solver.cpp:106] Iteration 134200, lr = 1e-19
I0429 22:20:25.920426  5145 solver.cpp:228] Iteration 134300, loss = 0.164371
I0429 22:20:25.920577  5145 solver.cpp:244]     Train net output #0: loss = 0.164371 (* 1 = 0.164371 loss)
I0429 22:20:25.920583  5145 sgd_solver.cpp:106] Iteration 134300, lr = 1e-19
I0429 22:21:18.028746  5145 solver.cpp:228] Iteration 134400, loss = 0.274827
I0429 22:21:18.028913  5145 solver.cpp:244]     Train net output #0: loss = 0.274827 (* 1 = 0.274827 loss)
I0429 22:21:18.028920  5145 sgd_solver.cpp:106] Iteration 134400, lr = 1e-19
I0429 22:22:08.526768  5145 solver.cpp:228] Iteration 134500, loss = 0.152781
I0429 22:22:08.526926  5145 solver.cpp:244]     Train net output #0: loss = 0.152781 (* 1 = 0.152781 loss)
I0429 22:22:08.526933  5145 sgd_solver.cpp:106] Iteration 134500, lr = 1e-19
I0429 22:23:00.357512  5145 solver.cpp:228] Iteration 134600, loss = 0.352976
I0429 22:23:00.357702  5145 solver.cpp:244]     Train net output #0: loss = 0.352976 (* 1 = 0.352976 loss)
I0429 22:23:00.357709  5145 sgd_solver.cpp:106] Iteration 134600, lr = 1e-19
I0429 22:23:50.953797  5145 solver.cpp:228] Iteration 134700, loss = 0.208221
I0429 22:23:50.953941  5145 solver.cpp:244]     Train net output #0: loss = 0.208221 (* 1 = 0.208221 loss)
I0429 22:23:50.953953  5145 sgd_solver.cpp:106] Iteration 134700, lr = 1e-19
I0429 22:24:41.411334  5145 solver.cpp:228] Iteration 134800, loss = 0.299162
I0429 22:24:41.411479  5145 solver.cpp:244]     Train net output #0: loss = 0.299162 (* 1 = 0.299162 loss)
I0429 22:24:41.411486  5145 sgd_solver.cpp:106] Iteration 134800, lr = 1e-19
I0429 22:25:33.363788  5145 solver.cpp:228] Iteration 134900, loss = 0.371881
I0429 22:25:33.363960  5145 solver.cpp:244]     Train net output #0: loss = 0.371881 (* 1 = 0.371881 loss)
I0429 22:25:33.363966  5145 sgd_solver.cpp:106] Iteration 134900, lr = 1e-19
I0429 22:26:23.542943  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_135000.caffemodel
I0429 22:26:34.346451  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_135000.solverstate
I0429 22:26:34.546152  5145 solver.cpp:337] Iteration 135000, Testing net (#0)
I0429 22:26:34.546253  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 22:26:34.546259  5145 net.cpp:693] Ignoring source layer visualize
I0429 22:26:34.546262  5145 net.cpp:693] Ignoring source layer fake
I0429 22:31:30.635252  5145 solver.cpp:404]     Test net output #0: loss = 0.282767 (* 1 = 0.282767 loss)
I0429 22:31:30.949585  5145 solver.cpp:228] Iteration 135000, loss = 0.153729
I0429 22:31:30.949622  5145 solver.cpp:244]     Train net output #0: loss = 0.153729 (* 1 = 0.153729 loss)
I0429 22:31:30.949630  5145 sgd_solver.cpp:106] Iteration 135000, lr = 1e-20
I0429 22:32:21.456908  5145 solver.cpp:228] Iteration 135100, loss = 0.260703
I0429 22:32:21.457083  5145 solver.cpp:244]     Train net output #0: loss = 0.260703 (* 1 = 0.260703 loss)
I0429 22:32:21.457090  5145 sgd_solver.cpp:106] Iteration 135100, lr = 1e-20
I0429 22:33:13.727991  5145 solver.cpp:228] Iteration 135200, loss = 0.218435
I0429 22:33:13.728153  5145 solver.cpp:244]     Train net output #0: loss = 0.218435 (* 1 = 0.218435 loss)
I0429 22:33:13.728162  5145 sgd_solver.cpp:106] Iteration 135200, lr = 1e-20
I0429 22:34:04.235556  5145 solver.cpp:228] Iteration 135300, loss = 0.397367
I0429 22:34:04.235713  5145 solver.cpp:244]     Train net output #0: loss = 0.397367 (* 1 = 0.397367 loss)
I0429 22:34:04.235718  5145 sgd_solver.cpp:106] Iteration 135300, lr = 1e-20
I0429 22:34:54.816316  5145 solver.cpp:228] Iteration 135400, loss = 0.335158
I0429 22:34:54.816468  5145 solver.cpp:244]     Train net output #0: loss = 0.335158 (* 1 = 0.335158 loss)
I0429 22:34:54.816474  5145 sgd_solver.cpp:106] Iteration 135400, lr = 1e-20
I0429 22:35:47.209331  5145 solver.cpp:228] Iteration 135500, loss = 0.318442
I0429 22:35:47.209506  5145 solver.cpp:244]     Train net output #0: loss = 0.318442 (* 1 = 0.318442 loss)
I0429 22:35:47.209516  5145 sgd_solver.cpp:106] Iteration 135500, lr = 1e-20
I0429 22:36:37.667958  5145 solver.cpp:228] Iteration 135600, loss = 0.274161
I0429 22:36:37.668112  5145 solver.cpp:244]     Train net output #0: loss = 0.274161 (* 1 = 0.274161 loss)
I0429 22:36:37.668119  5145 sgd_solver.cpp:106] Iteration 135600, lr = 1e-20
I0429 22:37:28.249927  5145 solver.cpp:228] Iteration 135700, loss = 0.180629
I0429 22:37:28.250084  5145 solver.cpp:244]     Train net output #0: loss = 0.180629 (* 1 = 0.180629 loss)
I0429 22:37:28.250092  5145 sgd_solver.cpp:106] Iteration 135700, lr = 1e-20
I0429 22:38:18.782948  5145 solver.cpp:228] Iteration 135800, loss = 0.298275
I0429 22:38:18.783092  5145 solver.cpp:244]     Train net output #0: loss = 0.298275 (* 1 = 0.298275 loss)
I0429 22:38:18.783099  5145 sgd_solver.cpp:106] Iteration 135800, lr = 1e-20
I0429 22:39:11.365346  5145 solver.cpp:228] Iteration 135900, loss = 0.31955
I0429 22:39:11.365530  5145 solver.cpp:244]     Train net output #0: loss = 0.31955 (* 1 = 0.31955 loss)
I0429 22:39:11.365537  5145 sgd_solver.cpp:106] Iteration 135900, lr = 1e-20
I0429 22:40:01.522573  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_136000.caffemodel
I0429 22:40:09.608880  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_136000.solverstate
I0429 22:40:09.817057  5145 solver.cpp:337] Iteration 136000, Testing net (#0)
I0429 22:40:09.817123  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 22:40:09.817127  5145 net.cpp:693] Ignoring source layer visualize
I0429 22:40:09.817129  5145 net.cpp:693] Ignoring source layer fake
I0429 22:45:05.371924  5145 solver.cpp:404]     Test net output #0: loss = 0.280851 (* 1 = 0.280851 loss)
I0429 22:45:05.687521  5145 solver.cpp:228] Iteration 136000, loss = 0.412755
I0429 22:45:05.687542  5145 solver.cpp:244]     Train net output #0: loss = 0.412755 (* 1 = 0.412755 loss)
I0429 22:45:05.687564  5145 sgd_solver.cpp:106] Iteration 136000, lr = 1e-20
I0429 22:45:56.196085  5145 solver.cpp:228] Iteration 136100, loss = 0.314508
I0429 22:45:56.196229  5145 solver.cpp:244]     Train net output #0: loss = 0.314508 (* 1 = 0.314508 loss)
I0429 22:45:56.196236  5145 sgd_solver.cpp:106] Iteration 136100, lr = 1e-20
I0429 22:46:48.631064  5145 solver.cpp:228] Iteration 136200, loss = 0.354828
I0429 22:46:48.631224  5145 solver.cpp:244]     Train net output #0: loss = 0.354828 (* 1 = 0.354828 loss)
I0429 22:46:48.631232  5145 sgd_solver.cpp:106] Iteration 136200, lr = 1e-20
I0429 22:47:39.061743  5145 solver.cpp:228] Iteration 136300, loss = 0.183525
I0429 22:47:39.061903  5145 solver.cpp:244]     Train net output #0: loss = 0.183525 (* 1 = 0.183525 loss)
I0429 22:47:39.061910  5145 sgd_solver.cpp:106] Iteration 136300, lr = 1e-20
I0429 22:48:29.611696  5145 solver.cpp:228] Iteration 136400, loss = 0.308268
I0429 22:48:29.611852  5145 solver.cpp:244]     Train net output #0: loss = 0.308268 (* 1 = 0.308268 loss)
I0429 22:48:29.611860  5145 sgd_solver.cpp:106] Iteration 136400, lr = 1e-20
I0429 22:49:20.048288  5145 solver.cpp:228] Iteration 136500, loss = 0.237566
I0429 22:49:20.048441  5145 solver.cpp:244]     Train net output #0: loss = 0.237566 (* 1 = 0.237566 loss)
I0429 22:49:20.048447  5145 sgd_solver.cpp:106] Iteration 136500, lr = 1e-20
I0429 22:50:12.087826  5145 solver.cpp:228] Iteration 136600, loss = 0.266157
I0429 22:50:12.089107  5145 solver.cpp:244]     Train net output #0: loss = 0.266157 (* 1 = 0.266157 loss)
I0429 22:50:12.089131  5145 sgd_solver.cpp:106] Iteration 136600, lr = 1e-20
I0429 22:51:02.525164  5145 solver.cpp:228] Iteration 136700, loss = 0.244526
I0429 22:51:02.525315  5145 solver.cpp:244]     Train net output #0: loss = 0.244526 (* 1 = 0.244526 loss)
I0429 22:51:02.525322  5145 sgd_solver.cpp:106] Iteration 136700, lr = 1e-20
I0429 22:51:53.050683  5145 solver.cpp:228] Iteration 136800, loss = 0.22447
I0429 22:51:53.050822  5145 solver.cpp:244]     Train net output #0: loss = 0.22447 (* 1 = 0.22447 loss)
I0429 22:51:53.050828  5145 sgd_solver.cpp:106] Iteration 136800, lr = 1e-20
I0429 22:52:45.344180  5145 solver.cpp:228] Iteration 136900, loss = 0.289902
I0429 22:52:45.344341  5145 solver.cpp:244]     Train net output #0: loss = 0.289902 (* 1 = 0.289902 loss)
I0429 22:52:45.344349  5145 sgd_solver.cpp:106] Iteration 136900, lr = 1e-20
I0429 22:53:35.416218  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_137000.caffemodel
I0429 22:53:53.768695  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_137000.solverstate
I0429 22:53:53.967298  5145 solver.cpp:337] Iteration 137000, Testing net (#0)
I0429 22:53:53.967381  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 22:53:53.967401  5145 net.cpp:693] Ignoring source layer visualize
I0429 22:53:53.967403  5145 net.cpp:693] Ignoring source layer fake
I0429 22:58:49.141212  5145 solver.cpp:404]     Test net output #0: loss = 0.289955 (* 1 = 0.289955 loss)
I0429 22:58:49.453285  5145 solver.cpp:228] Iteration 137000, loss = 0.244653
I0429 22:58:49.453305  5145 solver.cpp:244]     Train net output #0: loss = 0.244653 (* 1 = 0.244653 loss)
I0429 22:58:49.453326  5145 sgd_solver.cpp:106] Iteration 137000, lr = 1e-20
I0429 22:59:40.126929  5145 solver.cpp:228] Iteration 137100, loss = 0.198133
I0429 22:59:40.127127  5145 solver.cpp:244]     Train net output #0: loss = 0.198133 (* 1 = 0.198133 loss)
I0429 22:59:40.127135  5145 sgd_solver.cpp:106] Iteration 137100, lr = 1e-20
I0429 23:00:32.505156  5145 solver.cpp:228] Iteration 137200, loss = 0.263507
I0429 23:00:32.505311  5145 solver.cpp:244]     Train net output #0: loss = 0.263507 (* 1 = 0.263507 loss)
I0429 23:00:32.505318  5145 sgd_solver.cpp:106] Iteration 137200, lr = 1e-20
I0429 23:01:23.018926  5145 solver.cpp:228] Iteration 137300, loss = 0.263431
I0429 23:01:23.019104  5145 solver.cpp:244]     Train net output #0: loss = 0.263431 (* 1 = 0.263431 loss)
I0429 23:01:23.019112  5145 sgd_solver.cpp:106] Iteration 137300, lr = 1e-20
I0429 23:02:13.513917  5145 solver.cpp:228] Iteration 137400, loss = 0.22045
I0429 23:02:13.514089  5145 solver.cpp:244]     Train net output #0: loss = 0.22045 (* 1 = 0.22045 loss)
I0429 23:02:13.514096  5145 sgd_solver.cpp:106] Iteration 137400, lr = 1e-20
I0429 23:03:05.529198  5145 solver.cpp:228] Iteration 137500, loss = 0.133549
I0429 23:03:05.529353  5145 solver.cpp:244]     Train net output #0: loss = 0.133549 (* 1 = 0.133549 loss)
I0429 23:03:05.529361  5145 sgd_solver.cpp:106] Iteration 137500, lr = 1e-20
I0429 23:03:56.019240  5145 solver.cpp:228] Iteration 137600, loss = 0.27381
I0429 23:03:56.019395  5145 solver.cpp:244]     Train net output #0: loss = 0.27381 (* 1 = 0.27381 loss)
I0429 23:03:56.019402  5145 sgd_solver.cpp:106] Iteration 137600, lr = 1e-20
I0429 23:04:46.601754  5145 solver.cpp:228] Iteration 137700, loss = 0.175391
I0429 23:04:46.601922  5145 solver.cpp:244]     Train net output #0: loss = 0.175391 (* 1 = 0.175391 loss)
I0429 23:04:46.601928  5145 sgd_solver.cpp:106] Iteration 137700, lr = 1e-20
I0429 23:05:38.515979  5145 solver.cpp:228] Iteration 137800, loss = 0.315014
I0429 23:05:38.516142  5145 solver.cpp:244]     Train net output #0: loss = 0.315014 (* 1 = 0.315014 loss)
I0429 23:05:38.516149  5145 sgd_solver.cpp:106] Iteration 137800, lr = 1e-20
I0429 23:06:28.993432  5145 solver.cpp:228] Iteration 137900, loss = 0.386586
I0429 23:06:28.993715  5145 solver.cpp:244]     Train net output #0: loss = 0.386586 (* 1 = 0.386586 loss)
I0429 23:06:28.993729  5145 sgd_solver.cpp:106] Iteration 137900, lr = 1e-20
I0429 23:07:20.548879  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_138000.caffemodel
I0429 23:07:36.570822  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_138000.solverstate
I0429 23:07:36.758806  5145 solver.cpp:337] Iteration 138000, Testing net (#0)
I0429 23:07:36.758889  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 23:07:36.758908  5145 net.cpp:693] Ignoring source layer visualize
I0429 23:07:36.758910  5145 net.cpp:693] Ignoring source layer fake
I0429 23:12:32.825336  5145 solver.cpp:404]     Test net output #0: loss = 0.288137 (* 1 = 0.288137 loss)
I0429 23:12:33.139163  5145 solver.cpp:228] Iteration 138000, loss = 0.315647
I0429 23:12:33.139189  5145 solver.cpp:244]     Train net output #0: loss = 0.315647 (* 1 = 0.315647 loss)
I0429 23:12:33.139196  5145 sgd_solver.cpp:106] Iteration 138000, lr = 1e-20
I0429 23:13:23.659119  5145 solver.cpp:228] Iteration 138100, loss = 0.217901
I0429 23:13:23.659286  5145 solver.cpp:244]     Train net output #0: loss = 0.217901 (* 1 = 0.217901 loss)
I0429 23:13:23.659292  5145 sgd_solver.cpp:106] Iteration 138100, lr = 1e-20
I0429 23:14:14.138896  5145 solver.cpp:228] Iteration 138200, loss = 0.258767
I0429 23:14:14.139044  5145 solver.cpp:244]     Train net output #0: loss = 0.258767 (* 1 = 0.258767 loss)
I0429 23:14:14.139050  5145 sgd_solver.cpp:106] Iteration 138200, lr = 1e-20
I0429 23:15:06.193132  5145 solver.cpp:228] Iteration 138300, loss = 0.255213
I0429 23:15:06.193274  5145 solver.cpp:244]     Train net output #0: loss = 0.255213 (* 1 = 0.255213 loss)
I0429 23:15:06.193280  5145 sgd_solver.cpp:106] Iteration 138300, lr = 1e-20
I0429 23:15:56.685278  5145 solver.cpp:228] Iteration 138400, loss = 0.235622
I0429 23:15:56.685431  5145 solver.cpp:244]     Train net output #0: loss = 0.235622 (* 1 = 0.235622 loss)
I0429 23:15:56.685446  5145 sgd_solver.cpp:106] Iteration 138400, lr = 1e-20
I0429 23:16:47.229333  5145 solver.cpp:228] Iteration 138500, loss = 0.358043
I0429 23:16:47.229498  5145 solver.cpp:244]     Train net output #0: loss = 0.358043 (* 1 = 0.358043 loss)
I0429 23:16:47.229504  5145 sgd_solver.cpp:106] Iteration 138500, lr = 1e-20
I0429 23:17:39.804378  5145 solver.cpp:228] Iteration 138600, loss = 0.320337
I0429 23:17:39.804546  5145 solver.cpp:244]     Train net output #0: loss = 0.320337 (* 1 = 0.320337 loss)
I0429 23:17:39.804553  5145 sgd_solver.cpp:106] Iteration 138600, lr = 1e-20
I0429 23:18:30.176857  5145 solver.cpp:228] Iteration 138700, loss = 0.230285
I0429 23:18:30.177000  5145 solver.cpp:244]     Train net output #0: loss = 0.230285 (* 1 = 0.230285 loss)
I0429 23:18:30.177006  5145 sgd_solver.cpp:106] Iteration 138700, lr = 1e-20
I0429 23:19:20.639108  5145 solver.cpp:228] Iteration 138800, loss = 0.35739
I0429 23:19:20.639261  5145 solver.cpp:244]     Train net output #0: loss = 0.35739 (* 1 = 0.35739 loss)
I0429 23:19:20.639268  5145 sgd_solver.cpp:106] Iteration 138800, lr = 1e-20
I0429 23:20:11.179456  5145 solver.cpp:228] Iteration 138900, loss = 0.273065
I0429 23:20:11.179622  5145 solver.cpp:244]     Train net output #0: loss = 0.273065 (* 1 = 0.273065 loss)
I0429 23:20:11.179628  5145 sgd_solver.cpp:106] Iteration 138900, lr = 1e-20
I0429 23:21:03.100057  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_139000.caffemodel
I0429 23:21:43.579526  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_139000.solverstate
I0429 23:21:43.769301  5145 solver.cpp:337] Iteration 139000, Testing net (#0)
I0429 23:21:43.769384  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 23:21:43.769388  5145 net.cpp:693] Ignoring source layer visualize
I0429 23:21:43.769405  5145 net.cpp:693] Ignoring source layer fake
I0429 23:26:38.202952  5145 solver.cpp:404]     Test net output #0: loss = 0.285947 (* 1 = 0.285947 loss)
I0429 23:26:38.515367  5145 solver.cpp:228] Iteration 139000, loss = 0.446704
I0429 23:26:38.515385  5145 solver.cpp:244]     Train net output #0: loss = 0.446704 (* 1 = 0.446704 loss)
I0429 23:26:38.515408  5145 sgd_solver.cpp:106] Iteration 139000, lr = 1e-20
I0429 23:27:29.065634  5145 solver.cpp:228] Iteration 139100, loss = 0.235127
I0429 23:27:29.065783  5145 solver.cpp:244]     Train net output #0: loss = 0.235127 (* 1 = 0.235127 loss)
I0429 23:27:29.065790  5145 sgd_solver.cpp:106] Iteration 139100, lr = 1e-20
I0429 23:28:19.648911  5145 solver.cpp:228] Iteration 139200, loss = 0.288808
I0429 23:28:19.649081  5145 solver.cpp:244]     Train net output #0: loss = 0.288808 (* 1 = 0.288808 loss)
I0429 23:28:19.649088  5145 sgd_solver.cpp:106] Iteration 139200, lr = 1e-20
I0429 23:29:11.969137  5145 solver.cpp:228] Iteration 139300, loss = 0.263991
I0429 23:29:11.969305  5145 solver.cpp:244]     Train net output #0: loss = 0.263991 (* 1 = 0.263991 loss)
I0429 23:29:11.969311  5145 sgd_solver.cpp:106] Iteration 139300, lr = 1e-20
I0429 23:30:02.425369  5145 solver.cpp:228] Iteration 139400, loss = 0.24634
I0429 23:30:02.425554  5145 solver.cpp:244]     Train net output #0: loss = 0.24634 (* 1 = 0.24634 loss)
I0429 23:30:02.425561  5145 sgd_solver.cpp:106] Iteration 139400, lr = 1e-20
I0429 23:30:52.853644  5145 solver.cpp:228] Iteration 139500, loss = 0.263865
I0429 23:30:52.853798  5145 solver.cpp:244]     Train net output #0: loss = 0.263865 (* 1 = 0.263865 loss)
I0429 23:30:52.853806  5145 sgd_solver.cpp:106] Iteration 139500, lr = 1e-20
I0429 23:31:43.460068  5145 solver.cpp:228] Iteration 139600, loss = 0.224916
I0429 23:31:43.460220  5145 solver.cpp:244]     Train net output #0: loss = 0.224916 (* 1 = 0.224916 loss)
I0429 23:31:43.460227  5145 sgd_solver.cpp:106] Iteration 139600, lr = 1e-20
I0429 23:32:35.685470  5145 solver.cpp:228] Iteration 139700, loss = 0.332387
I0429 23:32:35.685627  5145 solver.cpp:244]     Train net output #0: loss = 0.332387 (* 1 = 0.332387 loss)
I0429 23:32:35.685634  5145 sgd_solver.cpp:106] Iteration 139700, lr = 1e-20
I0429 23:33:26.216431  5145 solver.cpp:228] Iteration 139800, loss = 0.211548
I0429 23:33:26.216604  5145 solver.cpp:244]     Train net output #0: loss = 0.211548 (* 1 = 0.211548 loss)
I0429 23:33:26.216610  5145 sgd_solver.cpp:106] Iteration 139800, lr = 1e-20
I0429 23:34:16.797900  5145 solver.cpp:228] Iteration 139900, loss = 0.258188
I0429 23:34:16.798089  5145 solver.cpp:244]     Train net output #0: loss = 0.258188 (* 1 = 0.258188 loss)
I0429 23:34:16.798096  5145 sgd_solver.cpp:106] Iteration 139900, lr = 1e-20
I0429 23:35:08.603816  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_140000.caffemodel
I0429 23:35:18.631129  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_140000.solverstate
I0429 23:35:18.838601  5145 solver.cpp:337] Iteration 140000, Testing net (#0)
I0429 23:35:18.838755  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 23:35:18.838762  5145 net.cpp:693] Ignoring source layer visualize
I0429 23:35:18.838766  5145 net.cpp:693] Ignoring source layer fake
I0429 23:40:14.406637  5145 solver.cpp:404]     Test net output #0: loss = 0.282059 (* 1 = 0.282059 loss)
I0429 23:40:14.718173  5145 solver.cpp:228] Iteration 140000, loss = 0.218172
I0429 23:40:14.718190  5145 solver.cpp:244]     Train net output #0: loss = 0.218172 (* 1 = 0.218172 loss)
I0429 23:40:14.718214  5145 sgd_solver.cpp:106] Iteration 140000, lr = 1e-20
I0429 23:41:05.333159  5145 solver.cpp:228] Iteration 140100, loss = 0.211312
I0429 23:41:05.333308  5145 solver.cpp:244]     Train net output #0: loss = 0.211312 (* 1 = 0.211312 loss)
I0429 23:41:05.333314  5145 sgd_solver.cpp:106] Iteration 140100, lr = 1e-20
I0429 23:41:55.809729  5145 solver.cpp:228] Iteration 140200, loss = 0.307372
I0429 23:41:55.809928  5145 solver.cpp:244]     Train net output #0: loss = 0.307372 (* 1 = 0.307372 loss)
I0429 23:41:55.809937  5145 sgd_solver.cpp:106] Iteration 140200, lr = 1e-20
I0429 23:42:47.916157  5145 solver.cpp:228] Iteration 140300, loss = 0.128137
I0429 23:42:47.916304  5145 solver.cpp:244]     Train net output #0: loss = 0.128137 (* 1 = 0.128137 loss)
I0429 23:42:47.916311  5145 sgd_solver.cpp:106] Iteration 140300, lr = 1e-20
I0429 23:43:38.522255  5145 solver.cpp:228] Iteration 140400, loss = 0.643763
I0429 23:43:38.522410  5145 solver.cpp:244]     Train net output #0: loss = 0.643763 (* 1 = 0.643763 loss)
I0429 23:43:38.522416  5145 sgd_solver.cpp:106] Iteration 140400, lr = 1e-20
I0429 23:44:28.966023  5145 solver.cpp:228] Iteration 140500, loss = 0.213497
I0429 23:44:28.966176  5145 solver.cpp:244]     Train net output #0: loss = 0.213497 (* 1 = 0.213497 loss)
I0429 23:44:28.966182  5145 sgd_solver.cpp:106] Iteration 140500, lr = 1e-20
I0429 23:45:20.655138  5145 solver.cpp:228] Iteration 140600, loss = 0.231969
I0429 23:45:20.655287  5145 solver.cpp:244]     Train net output #0: loss = 0.231969 (* 1 = 0.231969 loss)
I0429 23:45:20.655294  5145 sgd_solver.cpp:106] Iteration 140600, lr = 1e-20
I0429 23:46:11.167539  5145 solver.cpp:228] Iteration 140700, loss = 0.25157
I0429 23:46:11.167739  5145 solver.cpp:244]     Train net output #0: loss = 0.25157 (* 1 = 0.25157 loss)
I0429 23:46:11.167747  5145 sgd_solver.cpp:106] Iteration 140700, lr = 1e-20
I0429 23:47:01.690147  5145 solver.cpp:228] Iteration 140800, loss = 0.22378
I0429 23:47:01.690301  5145 solver.cpp:244]     Train net output #0: loss = 0.22378 (* 1 = 0.22378 loss)
I0429 23:47:01.690307  5145 sgd_solver.cpp:106] Iteration 140800, lr = 1e-20
I0429 23:47:53.403738  5145 solver.cpp:228] Iteration 140900, loss = 0.295582
I0429 23:47:53.403897  5145 solver.cpp:244]     Train net output #0: loss = 0.295582 (* 1 = 0.295582 loss)
I0429 23:47:53.403903  5145 sgd_solver.cpp:106] Iteration 140900, lr = 1e-20
I0429 23:48:43.630522  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_141000.caffemodel
I0429 23:49:03.762820  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_141000.solverstate
I0429 23:49:03.967340  5145 solver.cpp:337] Iteration 141000, Testing net (#0)
I0429 23:49:03.967438  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0429 23:49:03.967442  5145 net.cpp:693] Ignoring source layer visualize
I0429 23:49:03.967444  5145 net.cpp:693] Ignoring source layer fake
I0429 23:53:59.628991  5145 solver.cpp:404]     Test net output #0: loss = 0.281297 (* 1 = 0.281297 loss)
I0429 23:53:59.941231  5145 solver.cpp:228] Iteration 141000, loss = 0.208929
I0429 23:53:59.941252  5145 solver.cpp:244]     Train net output #0: loss = 0.208929 (* 1 = 0.208929 loss)
I0429 23:53:59.941274  5145 sgd_solver.cpp:106] Iteration 141000, lr = 1e-20
I0429 23:54:50.423398  5145 solver.cpp:228] Iteration 141100, loss = 0.369896
I0429 23:54:50.423563  5145 solver.cpp:244]     Train net output #0: loss = 0.369896 (* 1 = 0.369896 loss)
I0429 23:54:50.423568  5145 sgd_solver.cpp:106] Iteration 141100, lr = 1e-20
I0429 23:55:42.289505  5145 solver.cpp:228] Iteration 141200, loss = 0.237793
I0429 23:55:42.289662  5145 solver.cpp:244]     Train net output #0: loss = 0.237793 (* 1 = 0.237793 loss)
I0429 23:55:42.289669  5145 sgd_solver.cpp:106] Iteration 141200, lr = 1e-20
I0429 23:56:32.798861  5145 solver.cpp:228] Iteration 141300, loss = 0.297436
I0429 23:56:32.799048  5145 solver.cpp:244]     Train net output #0: loss = 0.297436 (* 1 = 0.297436 loss)
I0429 23:56:32.799055  5145 sgd_solver.cpp:106] Iteration 141300, lr = 1e-20
I0429 23:57:25.054157  5145 solver.cpp:228] Iteration 141400, loss = 0.293803
I0429 23:57:25.054314  5145 solver.cpp:244]     Train net output #0: loss = 0.293803 (* 1 = 0.293803 loss)
I0429 23:57:25.054322  5145 sgd_solver.cpp:106] Iteration 141400, lr = 1e-20
I0429 23:58:15.504030  5145 solver.cpp:228] Iteration 141500, loss = 0.264816
I0429 23:58:15.504165  5145 solver.cpp:244]     Train net output #0: loss = 0.264816 (* 1 = 0.264816 loss)
I0429 23:58:15.504173  5145 sgd_solver.cpp:106] Iteration 141500, lr = 1e-20
I0429 23:59:05.902508  5145 solver.cpp:228] Iteration 141600, loss = 0.263959
I0429 23:59:05.902664  5145 solver.cpp:244]     Train net output #0: loss = 0.263959 (* 1 = 0.263959 loss)
I0429 23:59:05.902670  5145 sgd_solver.cpp:106] Iteration 141600, lr = 1e-20
I0429 23:59:56.442215  5145 solver.cpp:228] Iteration 141700, loss = 0.307447
I0429 23:59:56.442373  5145 solver.cpp:244]     Train net output #0: loss = 0.307447 (* 1 = 0.307447 loss)
I0429 23:59:56.442379  5145 sgd_solver.cpp:106] Iteration 141700, lr = 1e-20
I0430 00:00:48.658819  5145 solver.cpp:228] Iteration 141800, loss = 0.230574
I0430 00:00:48.658970  5145 solver.cpp:244]     Train net output #0: loss = 0.230574 (* 1 = 0.230574 loss)
I0430 00:00:48.658977  5145 sgd_solver.cpp:106] Iteration 141800, lr = 1e-20
I0430 00:01:39.205538  5145 solver.cpp:228] Iteration 141900, loss = 0.180954
I0430 00:01:39.205729  5145 solver.cpp:244]     Train net output #0: loss = 0.180954 (* 1 = 0.180954 loss)
I0430 00:01:39.205736  5145 sgd_solver.cpp:106] Iteration 141900, lr = 1e-20
I0430 00:02:29.511950  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_142000.caffemodel
I0430 00:02:52.143805  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_142000.solverstate
I0430 00:02:52.335052  5145 solver.cpp:337] Iteration 142000, Testing net (#0)
I0430 00:02:52.335136  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 00:02:52.335139  5145 net.cpp:693] Ignoring source layer visualize
I0430 00:02:52.335142  5145 net.cpp:693] Ignoring source layer fake
I0430 00:07:47.837443  5145 solver.cpp:404]     Test net output #0: loss = 0.290855 (* 1 = 0.290855 loss)
I0430 00:07:48.150400  5145 solver.cpp:228] Iteration 142000, loss = 0.279497
I0430 00:07:48.150418  5145 solver.cpp:244]     Train net output #0: loss = 0.279497 (* 1 = 0.279497 loss)
I0430 00:07:48.150439  5145 sgd_solver.cpp:106] Iteration 142000, lr = 1e-20
I0430 00:08:40.331046  5145 solver.cpp:228] Iteration 142100, loss = 0.316403
I0430 00:08:40.331212  5145 solver.cpp:244]     Train net output #0: loss = 0.316403 (* 1 = 0.316403 loss)
I0430 00:08:40.331218  5145 sgd_solver.cpp:106] Iteration 142100, lr = 1e-20
I0430 00:09:30.861791  5145 solver.cpp:228] Iteration 142200, loss = 0.28453
I0430 00:09:30.861956  5145 solver.cpp:244]     Train net output #0: loss = 0.28453 (* 1 = 0.28453 loss)
I0430 00:09:30.861963  5145 sgd_solver.cpp:106] Iteration 142200, lr = 1e-20
I0430 00:10:21.379582  5145 solver.cpp:228] Iteration 142300, loss = 0.345987
I0430 00:10:21.380123  5145 solver.cpp:244]     Train net output #0: loss = 0.345987 (* 1 = 0.345987 loss)
I0430 00:10:21.380147  5145 sgd_solver.cpp:106] Iteration 142300, lr = 1e-20
I0430 00:11:11.839082  5145 solver.cpp:228] Iteration 142400, loss = 0.26874
I0430 00:11:11.839236  5145 solver.cpp:244]     Train net output #0: loss = 0.26874 (* 1 = 0.26874 loss)
I0430 00:11:11.839243  5145 sgd_solver.cpp:106] Iteration 142400, lr = 1e-20
I0430 00:12:04.065232  5145 solver.cpp:228] Iteration 142500, loss = 0.24362
I0430 00:12:04.065389  5145 solver.cpp:244]     Train net output #0: loss = 0.24362 (* 1 = 0.24362 loss)
I0430 00:12:04.065397  5145 sgd_solver.cpp:106] Iteration 142500, lr = 1e-21
I0430 00:12:54.600714  5145 solver.cpp:228] Iteration 142600, loss = 0.235701
I0430 00:12:54.600873  5145 solver.cpp:244]     Train net output #0: loss = 0.235701 (* 1 = 0.235701 loss)
I0430 00:12:54.600879  5145 sgd_solver.cpp:106] Iteration 142600, lr = 1e-21
I0430 00:13:45.231835  5145 solver.cpp:228] Iteration 142700, loss = 0.369168
I0430 00:13:45.231992  5145 solver.cpp:244]     Train net output #0: loss = 0.369168 (* 1 = 0.369168 loss)
I0430 00:13:45.231999  5145 sgd_solver.cpp:106] Iteration 142700, lr = 1e-21
I0430 00:14:37.443162  5145 solver.cpp:228] Iteration 142800, loss = 0.321487
I0430 00:14:37.443313  5145 solver.cpp:244]     Train net output #0: loss = 0.321487 (* 1 = 0.321487 loss)
I0430 00:14:37.443320  5145 sgd_solver.cpp:106] Iteration 142800, lr = 1e-21
I0430 00:15:27.975658  5145 solver.cpp:228] Iteration 142900, loss = 0.145125
I0430 00:15:27.975801  5145 solver.cpp:244]     Train net output #0: loss = 0.145125 (* 1 = 0.145125 loss)
I0430 00:15:27.975807  5145 sgd_solver.cpp:106] Iteration 142900, lr = 1e-21
I0430 00:16:18.174494  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_143000.caffemodel
I0430 00:16:22.330704  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_143000.solverstate
I0430 00:16:22.514969  5145 solver.cpp:337] Iteration 143000, Testing net (#0)
I0430 00:16:22.515080  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 00:16:22.515105  5145 net.cpp:693] Ignoring source layer visualize
I0430 00:16:22.515106  5145 net.cpp:693] Ignoring source layer fake
I0430 00:21:18.154522  5145 solver.cpp:404]     Test net output #0: loss = 0.287333 (* 1 = 0.287333 loss)
I0430 00:21:18.465701  5145 solver.cpp:228] Iteration 143000, loss = 0.216083
I0430 00:21:18.465739  5145 solver.cpp:244]     Train net output #0: loss = 0.216083 (* 1 = 0.216083 loss)
I0430 00:21:18.465744  5145 sgd_solver.cpp:106] Iteration 143000, lr = 1e-21
I0430 00:22:10.642724  5145 solver.cpp:228] Iteration 143100, loss = 0.0781525
I0430 00:22:10.642894  5145 solver.cpp:244]     Train net output #0: loss = 0.0781525 (* 1 = 0.0781525 loss)
I0430 00:22:10.642902  5145 sgd_solver.cpp:106] Iteration 143100, lr = 1e-21
I0430 00:23:01.094635  5145 solver.cpp:228] Iteration 143200, loss = 0.227335
I0430 00:23:01.094792  5145 solver.cpp:244]     Train net output #0: loss = 0.227335 (* 1 = 0.227335 loss)
I0430 00:23:01.094799  5145 sgd_solver.cpp:106] Iteration 143200, lr = 1e-21
I0430 00:23:51.710520  5145 solver.cpp:228] Iteration 143300, loss = 0.254833
I0430 00:23:51.710721  5145 solver.cpp:244]     Train net output #0: loss = 0.254833 (* 1 = 0.254833 loss)
I0430 00:23:51.710728  5145 sgd_solver.cpp:106] Iteration 143300, lr = 1e-21
I0430 00:24:42.102876  5145 solver.cpp:228] Iteration 143400, loss = 0.364937
I0430 00:24:42.103039  5145 solver.cpp:244]     Train net output #0: loss = 0.364937 (* 1 = 0.364937 loss)
I0430 00:24:42.103044  5145 sgd_solver.cpp:106] Iteration 143400, lr = 1e-21
I0430 00:25:34.221572  5145 solver.cpp:228] Iteration 143500, loss = 0.233287
I0430 00:25:34.221712  5145 solver.cpp:244]     Train net output #0: loss = 0.233287 (* 1 = 0.233287 loss)
I0430 00:25:34.221720  5145 sgd_solver.cpp:106] Iteration 143500, lr = 1e-21
I0430 00:26:24.825462  5145 solver.cpp:228] Iteration 143600, loss = 0.523809
I0430 00:26:24.825713  5145 solver.cpp:244]     Train net output #0: loss = 0.523809 (* 1 = 0.523809 loss)
I0430 00:26:24.825722  5145 sgd_solver.cpp:106] Iteration 143600, lr = 1e-21
I0430 00:27:15.271226  5145 solver.cpp:228] Iteration 143700, loss = 0.246467
I0430 00:27:15.271421  5145 solver.cpp:244]     Train net output #0: loss = 0.246467 (* 1 = 0.246467 loss)
I0430 00:27:15.271428  5145 sgd_solver.cpp:106] Iteration 143700, lr = 1e-21
I0430 00:28:06.982965  5145 solver.cpp:228] Iteration 143800, loss = 0.219574
I0430 00:28:06.983652  5145 solver.cpp:244]     Train net output #0: loss = 0.219574 (* 1 = 0.219574 loss)
I0430 00:28:06.983659  5145 sgd_solver.cpp:106] Iteration 143800, lr = 1e-21
I0430 00:28:57.435577  5145 solver.cpp:228] Iteration 143900, loss = 0.228512
I0430 00:28:57.435735  5145 solver.cpp:244]     Train net output #0: loss = 0.228512 (* 1 = 0.228512 loss)
I0430 00:28:57.435744  5145 sgd_solver.cpp:106] Iteration 143900, lr = 1e-21
I0430 00:29:49.311381  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_144000.caffemodel
I0430 00:29:59.280428  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_144000.solverstate
I0430 00:29:59.557569  5145 solver.cpp:337] Iteration 144000, Testing net (#0)
I0430 00:29:59.557683  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 00:29:59.557690  5145 net.cpp:693] Ignoring source layer visualize
I0430 00:29:59.557694  5145 net.cpp:693] Ignoring source layer fake
I0430 00:34:54.550132  5145 solver.cpp:404]     Test net output #0: loss = 0.28588 (* 1 = 0.28588 loss)
I0430 00:34:54.860780  5145 solver.cpp:228] Iteration 144000, loss = 0.360642
I0430 00:34:54.860800  5145 solver.cpp:244]     Train net output #0: loss = 0.360642 (* 1 = 0.360642 loss)
I0430 00:34:54.860821  5145 sgd_solver.cpp:106] Iteration 144000, lr = 1e-21
I0430 00:35:45.434252  5145 solver.cpp:228] Iteration 144100, loss = 0.271553
I0430 00:35:45.434408  5145 solver.cpp:244]     Train net output #0: loss = 0.271553 (* 1 = 0.271553 loss)
I0430 00:35:45.434415  5145 sgd_solver.cpp:106] Iteration 144100, lr = 1e-21
I0430 00:36:35.929930  5145 solver.cpp:228] Iteration 144200, loss = 0.360213
I0430 00:36:35.930130  5145 solver.cpp:244]     Train net output #0: loss = 0.360213 (* 1 = 0.360213 loss)
I0430 00:36:35.930140  5145 sgd_solver.cpp:106] Iteration 144200, lr = 1e-21
I0430 00:37:27.756580  5145 solver.cpp:228] Iteration 144300, loss = 0.460021
I0430 00:37:27.756779  5145 solver.cpp:244]     Train net output #0: loss = 0.460021 (* 1 = 0.460021 loss)
I0430 00:37:27.756795  5145 sgd_solver.cpp:106] Iteration 144300, lr = 1e-21
I0430 00:38:18.362511  5145 solver.cpp:228] Iteration 144400, loss = 0.277651
I0430 00:38:18.362680  5145 solver.cpp:244]     Train net output #0: loss = 0.277651 (* 1 = 0.277651 loss)
I0430 00:38:18.362687  5145 sgd_solver.cpp:106] Iteration 144400, lr = 1e-21
I0430 00:39:08.833549  5145 solver.cpp:228] Iteration 144500, loss = 0.211569
I0430 00:39:08.833717  5145 solver.cpp:244]     Train net output #0: loss = 0.211569 (* 1 = 0.211569 loss)
I0430 00:39:08.833724  5145 sgd_solver.cpp:106] Iteration 144500, lr = 1e-21
I0430 00:40:01.006901  5145 solver.cpp:228] Iteration 144600, loss = 0.245067
I0430 00:40:01.007055  5145 solver.cpp:244]     Train net output #0: loss = 0.245067 (* 1 = 0.245067 loss)
I0430 00:40:01.007062  5145 sgd_solver.cpp:106] Iteration 144600, lr = 1e-21
I0430 00:40:51.442021  5145 solver.cpp:228] Iteration 144700, loss = 0.295173
I0430 00:40:51.442180  5145 solver.cpp:244]     Train net output #0: loss = 0.295173 (* 1 = 0.295173 loss)
I0430 00:40:51.442186  5145 sgd_solver.cpp:106] Iteration 144700, lr = 1e-21
I0430 00:41:42.022830  5145 solver.cpp:228] Iteration 144800, loss = 0.253014
I0430 00:41:42.022974  5145 solver.cpp:244]     Train net output #0: loss = 0.253014 (* 1 = 0.253014 loss)
I0430 00:41:42.022980  5145 sgd_solver.cpp:106] Iteration 144800, lr = 1e-21
I0430 00:42:34.267945  5145 solver.cpp:228] Iteration 144900, loss = 0.296154
I0430 00:42:34.268103  5145 solver.cpp:244]     Train net output #0: loss = 0.296154 (* 1 = 0.296154 loss)
I0430 00:42:34.268110  5145 sgd_solver.cpp:106] Iteration 144900, lr = 1e-21
I0430 00:43:24.524011  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_145000.caffemodel
I0430 00:43:46.760040  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_145000.solverstate
I0430 00:43:46.993178  5145 solver.cpp:337] Iteration 145000, Testing net (#0)
I0430 00:43:46.993293  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 00:43:46.993300  5145 net.cpp:693] Ignoring source layer visualize
I0430 00:43:46.993304  5145 net.cpp:693] Ignoring source layer fake
I0430 00:48:41.669687  5145 solver.cpp:404]     Test net output #0: loss = 0.281531 (* 1 = 0.281531 loss)
I0430 00:48:41.984426  5145 solver.cpp:228] Iteration 145000, loss = 0.331007
I0430 00:48:41.984465  5145 solver.cpp:244]     Train net output #0: loss = 0.331007 (* 1 = 0.331007 loss)
I0430 00:48:41.984472  5145 sgd_solver.cpp:106] Iteration 145000, lr = 1e-21
I0430 00:49:32.612319  5145 solver.cpp:228] Iteration 145100, loss = 0.285065
I0430 00:49:32.612483  5145 solver.cpp:244]     Train net output #0: loss = 0.285065 (* 1 = 0.285065 loss)
I0430 00:49:32.612490  5145 sgd_solver.cpp:106] Iteration 145100, lr = 1e-21
I0430 00:50:24.827050  5145 solver.cpp:228] Iteration 145200, loss = 0.315769
I0430 00:50:24.827208  5145 solver.cpp:244]     Train net output #0: loss = 0.315769 (* 1 = 0.315769 loss)
I0430 00:50:24.827215  5145 sgd_solver.cpp:106] Iteration 145200, lr = 1e-21
I0430 00:51:15.271340  5145 solver.cpp:228] Iteration 145300, loss = 0.274038
I0430 00:51:15.271505  5145 solver.cpp:244]     Train net output #0: loss = 0.274038 (* 1 = 0.274038 loss)
I0430 00:51:15.271512  5145 sgd_solver.cpp:106] Iteration 145300, lr = 1e-21
I0430 00:52:05.832193  5145 solver.cpp:228] Iteration 145400, loss = 0.191498
I0430 00:52:05.834069  5145 solver.cpp:244]     Train net output #0: loss = 0.191498 (* 1 = 0.191498 loss)
I0430 00:52:05.834075  5145 sgd_solver.cpp:106] Iteration 145400, lr = 1e-21
I0430 00:52:56.372211  5145 solver.cpp:228] Iteration 145500, loss = 0.286896
I0430 00:52:56.372398  5145 solver.cpp:244]     Train net output #0: loss = 0.286896 (* 1 = 0.286896 loss)
I0430 00:52:56.372406  5145 sgd_solver.cpp:106] Iteration 145500, lr = 1e-21
I0430 00:53:48.627528  5145 solver.cpp:228] Iteration 145600, loss = 0.281366
I0430 00:53:48.627701  5145 solver.cpp:244]     Train net output #0: loss = 0.281366 (* 1 = 0.281366 loss)
I0430 00:53:48.627707  5145 sgd_solver.cpp:106] Iteration 145600, lr = 1e-21
I0430 00:54:39.184743  5145 solver.cpp:228] Iteration 145700, loss = 0.227286
I0430 00:54:39.184957  5145 solver.cpp:244]     Train net output #0: loss = 0.227286 (* 1 = 0.227286 loss)
I0430 00:54:39.184979  5145 sgd_solver.cpp:106] Iteration 145700, lr = 1e-21
I0430 00:55:29.663352  5145 solver.cpp:228] Iteration 145800, loss = 0.283532
I0430 00:55:29.663516  5145 solver.cpp:244]     Train net output #0: loss = 0.283532 (* 1 = 0.283532 loss)
I0430 00:55:29.663522  5145 sgd_solver.cpp:106] Iteration 145800, lr = 1e-21
I0430 00:56:21.851191  5145 solver.cpp:228] Iteration 145900, loss = 0.194176
I0430 00:56:21.851351  5145 solver.cpp:244]     Train net output #0: loss = 0.194176 (* 1 = 0.194176 loss)
I0430 00:56:21.851357  5145 sgd_solver.cpp:106] Iteration 145900, lr = 1e-21
I0430 00:57:12.160940  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_146000.caffemodel
I0430 00:57:26.583290  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_146000.solverstate
I0430 00:57:26.773960  5145 solver.cpp:337] Iteration 146000, Testing net (#0)
I0430 00:57:26.774041  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 00:57:26.774044  5145 net.cpp:693] Ignoring source layer visualize
I0430 00:57:26.774047  5145 net.cpp:693] Ignoring source layer fake
I0430 01:02:21.884449  5145 solver.cpp:404]     Test net output #0: loss = 0.281732 (* 1 = 0.281732 loss)
I0430 01:02:22.197650  5145 solver.cpp:228] Iteration 146000, loss = 0.267839
I0430 01:02:22.197667  5145 solver.cpp:244]     Train net output #0: loss = 0.267839 (* 1 = 0.267839 loss)
I0430 01:02:22.197690  5145 sgd_solver.cpp:106] Iteration 146000, lr = 1e-21
I0430 01:03:12.763504  5145 solver.cpp:228] Iteration 146100, loss = 0.200159
I0430 01:03:12.763662  5145 solver.cpp:244]     Train net output #0: loss = 0.200159 (* 1 = 0.200159 loss)
I0430 01:03:12.763669  5145 sgd_solver.cpp:106] Iteration 146100, lr = 1e-21
I0430 01:04:03.300407  5145 solver.cpp:228] Iteration 146200, loss = 0.196562
I0430 01:04:03.300560  5145 solver.cpp:244]     Train net output #0: loss = 0.196562 (* 1 = 0.196562 loss)
I0430 01:04:03.300566  5145 sgd_solver.cpp:106] Iteration 146200, lr = 1e-21
I0430 01:04:55.476032  5145 solver.cpp:228] Iteration 146300, loss = 0.178339
I0430 01:04:55.476192  5145 solver.cpp:244]     Train net output #0: loss = 0.178339 (* 1 = 0.178339 loss)
I0430 01:04:55.476198  5145 sgd_solver.cpp:106] Iteration 146300, lr = 1e-21
I0430 01:05:45.953409  5145 solver.cpp:228] Iteration 146400, loss = 0.147605
I0430 01:05:45.953586  5145 solver.cpp:244]     Train net output #0: loss = 0.147605 (* 1 = 0.147605 loss)
I0430 01:05:45.953593  5145 sgd_solver.cpp:106] Iteration 146400, lr = 1e-21
I0430 01:06:36.500329  5145 solver.cpp:228] Iteration 146500, loss = 0.178511
I0430 01:06:36.500488  5145 solver.cpp:244]     Train net output #0: loss = 0.178511 (* 1 = 0.178511 loss)
I0430 01:06:36.500494  5145 sgd_solver.cpp:106] Iteration 146500, lr = 1e-21
I0430 01:07:28.617909  5145 solver.cpp:228] Iteration 146600, loss = 0.278331
I0430 01:07:28.618059  5145 solver.cpp:244]     Train net output #0: loss = 0.278331 (* 1 = 0.278331 loss)
I0430 01:07:28.618067  5145 sgd_solver.cpp:106] Iteration 146600, lr = 1e-21
I0430 01:08:19.062484  5145 solver.cpp:228] Iteration 146700, loss = 0.115223
I0430 01:08:19.062659  5145 solver.cpp:244]     Train net output #0: loss = 0.115223 (* 1 = 0.115223 loss)
I0430 01:08:19.062665  5145 sgd_solver.cpp:106] Iteration 146700, lr = 1e-21
I0430 01:09:09.567082  5145 solver.cpp:228] Iteration 146800, loss = 0.569491
I0430 01:09:09.567250  5145 solver.cpp:244]     Train net output #0: loss = 0.569491 (* 1 = 0.569491 loss)
I0430 01:09:09.567260  5145 sgd_solver.cpp:106] Iteration 146800, lr = 1e-21
I0430 01:10:01.230023  5145 solver.cpp:228] Iteration 146900, loss = 0.261539
I0430 01:10:01.230175  5145 solver.cpp:244]     Train net output #0: loss = 0.261539 (* 1 = 0.261539 loss)
I0430 01:10:01.230181  5145 sgd_solver.cpp:106] Iteration 146900, lr = 1e-21
I0430 01:10:51.458890  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_147000.caffemodel
I0430 01:11:02.314118  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_147000.solverstate
I0430 01:11:02.503425  5145 solver.cpp:337] Iteration 147000, Testing net (#0)
I0430 01:11:02.503511  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 01:11:02.503515  5145 net.cpp:693] Ignoring source layer visualize
I0430 01:11:02.503517  5145 net.cpp:693] Ignoring source layer fake
I0430 01:15:58.102535  5145 solver.cpp:404]     Test net output #0: loss = 0.290629 (* 1 = 0.290629 loss)
I0430 01:15:58.421020  5145 solver.cpp:228] Iteration 147000, loss = 0.270395
I0430 01:15:58.421038  5145 solver.cpp:244]     Train net output #0: loss = 0.270395 (* 1 = 0.270395 loss)
I0430 01:15:58.421059  5145 sgd_solver.cpp:106] Iteration 147000, lr = 1e-21
I0430 01:16:50.186317  5145 solver.cpp:228] Iteration 147100, loss = 0.623905
I0430 01:16:50.186491  5145 solver.cpp:244]     Train net output #0: loss = 0.623905 (* 1 = 0.623905 loss)
I0430 01:16:50.186499  5145 sgd_solver.cpp:106] Iteration 147100, lr = 1e-21
I0430 01:17:40.634166  5145 solver.cpp:228] Iteration 147200, loss = 0.485926
I0430 01:17:40.634327  5145 solver.cpp:244]     Train net output #0: loss = 0.485926 (* 1 = 0.485926 loss)
I0430 01:17:40.634335  5145 sgd_solver.cpp:106] Iteration 147200, lr = 1e-21
I0430 01:18:31.126935  5145 solver.cpp:228] Iteration 147300, loss = 0.348051
I0430 01:18:31.127110  5145 solver.cpp:244]     Train net output #0: loss = 0.348051 (* 1 = 0.348051 loss)
I0430 01:18:31.127115  5145 sgd_solver.cpp:106] Iteration 147300, lr = 1e-21
I0430 01:19:23.130488  5145 solver.cpp:228] Iteration 147400, loss = 0.23905
I0430 01:19:23.130651  5145 solver.cpp:244]     Train net output #0: loss = 0.23905 (* 1 = 0.23905 loss)
I0430 01:19:23.130657  5145 sgd_solver.cpp:106] Iteration 147400, lr = 1e-21
I0430 01:20:13.656694  5145 solver.cpp:228] Iteration 147500, loss = 0.360324
I0430 01:20:13.656863  5145 solver.cpp:244]     Train net output #0: loss = 0.360324 (* 1 = 0.360324 loss)
I0430 01:20:13.656872  5145 sgd_solver.cpp:106] Iteration 147500, lr = 1e-21
I0430 01:21:04.195698  5145 solver.cpp:228] Iteration 147600, loss = 0.344407
I0430 01:21:04.198611  5145 solver.cpp:244]     Train net output #0: loss = 0.344407 (* 1 = 0.344407 loss)
I0430 01:21:04.198632  5145 sgd_solver.cpp:106] Iteration 147600, lr = 1e-21
I0430 01:21:56.311558  5145 solver.cpp:228] Iteration 147700, loss = 0.38495
I0430 01:21:56.311714  5145 solver.cpp:244]     Train net output #0: loss = 0.38495 (* 1 = 0.38495 loss)
I0430 01:21:56.311720  5145 sgd_solver.cpp:106] Iteration 147700, lr = 1e-21
I0430 01:22:46.862985  5145 solver.cpp:228] Iteration 147800, loss = 0.136801
I0430 01:22:46.863129  5145 solver.cpp:244]     Train net output #0: loss = 0.136801 (* 1 = 0.136801 loss)
I0430 01:22:46.863135  5145 sgd_solver.cpp:106] Iteration 147800, lr = 1e-21
I0430 01:23:37.471822  5145 solver.cpp:228] Iteration 147900, loss = 0.315169
I0430 01:23:37.471989  5145 solver.cpp:244]     Train net output #0: loss = 0.315169 (* 1 = 0.315169 loss)
I0430 01:23:37.471997  5145 sgd_solver.cpp:106] Iteration 147900, lr = 1e-21
I0430 01:24:29.677040  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_148000.caffemodel
I0430 01:24:39.109393  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_148000.solverstate
I0430 01:24:39.298719  5145 solver.cpp:337] Iteration 148000, Testing net (#0)
I0430 01:24:39.298810  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 01:24:39.298813  5145 net.cpp:693] Ignoring source layer visualize
I0430 01:24:39.298815  5145 net.cpp:693] Ignoring source layer fake
I0430 01:29:34.776846  5145 solver.cpp:404]     Test net output #0: loss = 0.287564 (* 1 = 0.287564 loss)
I0430 01:29:35.090106  5145 solver.cpp:228] Iteration 148000, loss = 0.289959
I0430 01:29:35.090126  5145 solver.cpp:244]     Train net output #0: loss = 0.289959 (* 1 = 0.289959 loss)
I0430 01:29:35.090148  5145 sgd_solver.cpp:106] Iteration 148000, lr = 1e-21
I0430 01:30:25.552297  5145 solver.cpp:228] Iteration 148100, loss = 0.228101
I0430 01:30:25.552458  5145 solver.cpp:244]     Train net output #0: loss = 0.228101 (* 1 = 0.228101 loss)
I0430 01:30:25.552464  5145 sgd_solver.cpp:106] Iteration 148100, lr = 1e-21
I0430 01:31:16.106398  5145 solver.cpp:228] Iteration 148200, loss = 0.404853
I0430 01:31:16.107230  5145 solver.cpp:244]     Train net output #0: loss = 0.404853 (* 1 = 0.404853 loss)
I0430 01:31:16.107254  5145 sgd_solver.cpp:106] Iteration 148200, lr = 1e-21
I0430 01:32:06.700392  5145 solver.cpp:228] Iteration 148300, loss = 0.269146
I0430 01:32:06.700551  5145 solver.cpp:244]     Train net output #0: loss = 0.269146 (* 1 = 0.269146 loss)
I0430 01:32:06.700557  5145 sgd_solver.cpp:106] Iteration 148300, lr = 1e-21
I0430 01:32:58.929415  5145 solver.cpp:228] Iteration 148400, loss = 0.201935
I0430 01:32:58.929558  5145 solver.cpp:244]     Train net output #0: loss = 0.201935 (* 1 = 0.201935 loss)
I0430 01:32:58.929565  5145 sgd_solver.cpp:106] Iteration 148400, lr = 1e-21
I0430 01:33:49.416175  5145 solver.cpp:228] Iteration 148500, loss = 0.201695
I0430 01:33:49.416332  5145 solver.cpp:244]     Train net output #0: loss = 0.201695 (* 1 = 0.201695 loss)
I0430 01:33:49.416339  5145 sgd_solver.cpp:106] Iteration 148500, lr = 1e-21
I0430 01:34:40.064319  5145 solver.cpp:228] Iteration 148600, loss = 0.367109
I0430 01:34:40.064468  5145 solver.cpp:244]     Train net output #0: loss = 0.367109 (* 1 = 0.367109 loss)
I0430 01:34:40.064476  5145 sgd_solver.cpp:106] Iteration 148600, lr = 1e-21
I0430 01:35:32.335317  5145 solver.cpp:228] Iteration 148700, loss = 0.216348
I0430 01:35:32.335458  5145 solver.cpp:244]     Train net output #0: loss = 0.216348 (* 1 = 0.216348 loss)
I0430 01:35:32.335464  5145 sgd_solver.cpp:106] Iteration 148700, lr = 1e-21
I0430 01:36:22.816951  5145 solver.cpp:228] Iteration 148800, loss = 0.250455
I0430 01:36:22.817106  5145 solver.cpp:244]     Train net output #0: loss = 0.250455 (* 1 = 0.250455 loss)
I0430 01:36:22.817112  5145 sgd_solver.cpp:106] Iteration 148800, lr = 1e-21
I0430 01:37:13.349503  5145 solver.cpp:228] Iteration 148900, loss = 0.352218
I0430 01:37:13.349673  5145 solver.cpp:244]     Train net output #0: loss = 0.352218 (* 1 = 0.352218 loss)
I0430 01:37:13.349689  5145 sgd_solver.cpp:106] Iteration 148900, lr = 1e-21
I0430 01:38:03.474344  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_149000.caffemodel
I0430 01:38:14.301880  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_149000.solverstate
I0430 01:38:14.494894  5145 solver.cpp:337] Iteration 149000, Testing net (#0)
I0430 01:38:14.494961  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 01:38:14.494963  5145 net.cpp:693] Ignoring source layer visualize
I0430 01:38:14.494966  5145 net.cpp:693] Ignoring source layer fake
I0430 01:43:09.745137  5145 solver.cpp:404]     Test net output #0: loss = 0.286028 (* 1 = 0.286028 loss)
I0430 01:43:10.059422  5145 solver.cpp:228] Iteration 149000, loss = 0.29444
I0430 01:43:10.059456  5145 solver.cpp:244]     Train net output #0: loss = 0.29444 (* 1 = 0.29444 loss)
I0430 01:43:10.059478  5145 sgd_solver.cpp:106] Iteration 149000, lr = 1e-21
I0430 01:44:02.199039  5145 solver.cpp:228] Iteration 149100, loss = 0.348533
I0430 01:44:02.199201  5145 solver.cpp:244]     Train net output #0: loss = 0.348533 (* 1 = 0.348533 loss)
I0430 01:44:02.199208  5145 sgd_solver.cpp:106] Iteration 149100, lr = 1e-21
I0430 01:44:52.725261  5145 solver.cpp:228] Iteration 149200, loss = 0.167167
I0430 01:44:52.725415  5145 solver.cpp:244]     Train net output #0: loss = 0.167167 (* 1 = 0.167167 loss)
I0430 01:44:52.725422  5145 sgd_solver.cpp:106] Iteration 149200, lr = 1e-21
I0430 01:45:43.239305  5145 solver.cpp:228] Iteration 149300, loss = 0.243333
I0430 01:45:43.239461  5145 solver.cpp:244]     Train net output #0: loss = 0.243333 (* 1 = 0.243333 loss)
I0430 01:45:43.239470  5145 sgd_solver.cpp:106] Iteration 149300, lr = 1e-21
I0430 01:46:35.375423  5145 solver.cpp:228] Iteration 149400, loss = 0.296757
I0430 01:46:35.375591  5145 solver.cpp:244]     Train net output #0: loss = 0.296757 (* 1 = 0.296757 loss)
I0430 01:46:35.375597  5145 sgd_solver.cpp:106] Iteration 149400, lr = 1e-21
I0430 01:47:25.857926  5145 solver.cpp:228] Iteration 149500, loss = 0.421966
I0430 01:47:25.858065  5145 solver.cpp:244]     Train net output #0: loss = 0.421966 (* 1 = 0.421966 loss)
I0430 01:47:25.858072  5145 sgd_solver.cpp:106] Iteration 149500, lr = 1e-21
I0430 01:48:16.344854  5145 solver.cpp:228] Iteration 149600, loss = 0.271427
I0430 01:48:16.345021  5145 solver.cpp:244]     Train net output #0: loss = 0.271427 (* 1 = 0.271427 loss)
I0430 01:48:16.345027  5145 sgd_solver.cpp:106] Iteration 149600, lr = 1e-21
I0430 01:49:08.337924  5145 solver.cpp:228] Iteration 149700, loss = 0.18023
I0430 01:49:08.338105  5145 solver.cpp:244]     Train net output #0: loss = 0.18023 (* 1 = 0.18023 loss)
I0430 01:49:08.338112  5145 sgd_solver.cpp:106] Iteration 149700, lr = 1e-21
I0430 01:49:58.836874  5145 solver.cpp:228] Iteration 149800, loss = 0.242705
I0430 01:49:58.837015  5145 solver.cpp:244]     Train net output #0: loss = 0.242705 (* 1 = 0.242705 loss)
I0430 01:49:58.837023  5145 sgd_solver.cpp:106] Iteration 149800, lr = 1e-21
I0430 01:50:49.391284  5145 solver.cpp:228] Iteration 149900, loss = 0.242837
I0430 01:50:49.391451  5145 solver.cpp:244]     Train net output #0: loss = 0.242837 (* 1 = 0.242837 loss)
I0430 01:50:49.391458  5145 sgd_solver.cpp:106] Iteration 149900, lr = 1e-21
I0430 01:51:41.313954  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_150000.caffemodel
I0430 01:52:10.238862  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_150000.solverstate
I0430 01:52:10.427595  5145 solver.cpp:337] Iteration 150000, Testing net (#0)
I0430 01:52:10.427693  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 01:52:10.427698  5145 net.cpp:693] Ignoring source layer visualize
I0430 01:52:10.427701  5145 net.cpp:693] Ignoring source layer fake
I0430 01:57:05.348873  5145 solver.cpp:404]     Test net output #0: loss = 0.281148 (* 1 = 0.281148 loss)
I0430 01:57:05.665665  5145 solver.cpp:228] Iteration 150000, loss = 0.228451
I0430 01:57:05.665701  5145 solver.cpp:244]     Train net output #0: loss = 0.228451 (* 1 = 0.228451 loss)
I0430 01:57:05.665709  5145 sgd_solver.cpp:106] Iteration 150000, lr = 1e-22
I0430 01:57:56.234100  5145 solver.cpp:228] Iteration 150100, loss = 0.176557
I0430 01:57:56.234261  5145 solver.cpp:244]     Train net output #0: loss = 0.176557 (* 1 = 0.176557 loss)
I0430 01:57:56.234267  5145 sgd_solver.cpp:106] Iteration 150100, lr = 1e-22
I0430 01:58:46.817442  5145 solver.cpp:228] Iteration 150200, loss = 0.199076
I0430 01:58:46.817610  5145 solver.cpp:244]     Train net output #0: loss = 0.199076 (* 1 = 0.199076 loss)
I0430 01:58:46.817616  5145 sgd_solver.cpp:106] Iteration 150200, lr = 1e-22
I0430 01:59:38.519436  5145 solver.cpp:228] Iteration 150300, loss = 0.391809
I0430 01:59:38.519629  5145 solver.cpp:244]     Train net output #0: loss = 0.391809 (* 1 = 0.391809 loss)
I0430 01:59:38.519635  5145 sgd_solver.cpp:106] Iteration 150300, lr = 1e-22
I0430 02:00:29.055968  5145 solver.cpp:228] Iteration 150400, loss = 0.208179
I0430 02:00:29.056128  5145 solver.cpp:244]     Train net output #0: loss = 0.208179 (* 1 = 0.208179 loss)
I0430 02:00:29.056134  5145 sgd_solver.cpp:106] Iteration 150400, lr = 1e-22
I0430 02:01:21.027495  5145 solver.cpp:228] Iteration 150500, loss = 0.232992
I0430 02:01:21.027644  5145 solver.cpp:244]     Train net output #0: loss = 0.232992 (* 1 = 0.232992 loss)
I0430 02:01:21.027652  5145 sgd_solver.cpp:106] Iteration 150500, lr = 1e-22
I0430 02:02:11.618227  5145 solver.cpp:228] Iteration 150600, loss = 0.26379
I0430 02:02:11.618386  5145 solver.cpp:244]     Train net output #0: loss = 0.26379 (* 1 = 0.26379 loss)
I0430 02:02:11.618392  5145 sgd_solver.cpp:106] Iteration 150600, lr = 1e-22
I0430 02:03:02.226459  5145 solver.cpp:228] Iteration 150700, loss = 0.231914
I0430 02:03:02.226614  5145 solver.cpp:244]     Train net output #0: loss = 0.231914 (* 1 = 0.231914 loss)
I0430 02:03:02.226621  5145 sgd_solver.cpp:106] Iteration 150700, lr = 1e-22
I0430 02:03:54.428102  5145 solver.cpp:228] Iteration 150800, loss = 0.314749
I0430 02:03:54.428264  5145 solver.cpp:244]     Train net output #0: loss = 0.314749 (* 1 = 0.314749 loss)
I0430 02:03:54.428272  5145 sgd_solver.cpp:106] Iteration 150800, lr = 1e-22
I0430 02:04:44.910639  5145 solver.cpp:228] Iteration 150900, loss = 0.289164
I0430 02:04:44.910794  5145 solver.cpp:244]     Train net output #0: loss = 0.289164 (* 1 = 0.289164 loss)
I0430 02:04:44.910799  5145 sgd_solver.cpp:106] Iteration 150900, lr = 1e-22
I0430 02:05:35.180418  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_151000.caffemodel
I0430 02:05:47.216055  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_151000.solverstate
I0430 02:05:47.423920  5145 solver.cpp:337] Iteration 151000, Testing net (#0)
I0430 02:05:47.424019  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 02:05:47.424026  5145 net.cpp:693] Ignoring source layer visualize
I0430 02:05:47.424027  5145 net.cpp:693] Ignoring source layer fake
I0430 02:10:43.345141  5145 solver.cpp:404]     Test net output #0: loss = 0.282326 (* 1 = 0.282326 loss)
I0430 02:10:43.657361  5145 solver.cpp:228] Iteration 151000, loss = 0.299684
I0430 02:10:43.657387  5145 solver.cpp:244]     Train net output #0: loss = 0.299684 (* 1 = 0.299684 loss)
I0430 02:10:43.657393  5145 sgd_solver.cpp:106] Iteration 151000, lr = 1e-22
I0430 02:11:35.940009  5145 solver.cpp:228] Iteration 151100, loss = 0.281643
I0430 02:11:35.940187  5145 solver.cpp:244]     Train net output #0: loss = 0.281643 (* 1 = 0.281643 loss)
I0430 02:11:35.940194  5145 sgd_solver.cpp:106] Iteration 151100, lr = 1e-22
I0430 02:12:26.335531  5145 solver.cpp:228] Iteration 151200, loss = 0.266842
I0430 02:12:26.335676  5145 solver.cpp:244]     Train net output #0: loss = 0.266842 (* 1 = 0.266842 loss)
I0430 02:12:26.335695  5145 sgd_solver.cpp:106] Iteration 151200, lr = 1e-22
I0430 02:13:16.820401  5145 solver.cpp:228] Iteration 151300, loss = 0.275291
I0430 02:13:16.820570  5145 solver.cpp:244]     Train net output #0: loss = 0.275291 (* 1 = 0.275291 loss)
I0430 02:13:16.820577  5145 sgd_solver.cpp:106] Iteration 151300, lr = 1e-22
I0430 02:14:07.422027  5145 solver.cpp:228] Iteration 151400, loss = 0.310889
I0430 02:14:07.422174  5145 solver.cpp:244]     Train net output #0: loss = 0.310889 (* 1 = 0.310889 loss)
I0430 02:14:07.422181  5145 sgd_solver.cpp:106] Iteration 151400, lr = 1e-22
I0430 02:14:59.605459  5145 solver.cpp:228] Iteration 151500, loss = 0.262817
I0430 02:14:59.605643  5145 solver.cpp:244]     Train net output #0: loss = 0.262817 (* 1 = 0.262817 loss)
I0430 02:14:59.605651  5145 sgd_solver.cpp:106] Iteration 151500, lr = 1e-22
I0430 02:15:50.107923  5145 solver.cpp:228] Iteration 151600, loss = 0.268167
I0430 02:15:50.108520  5145 solver.cpp:244]     Train net output #0: loss = 0.268167 (* 1 = 0.268167 loss)
I0430 02:15:50.108526  5145 sgd_solver.cpp:106] Iteration 151600, lr = 1e-22
I0430 02:16:40.591142  5145 solver.cpp:228] Iteration 151700, loss = 0.374472
I0430 02:16:40.591290  5145 solver.cpp:244]     Train net output #0: loss = 0.374472 (* 1 = 0.374472 loss)
I0430 02:16:40.591297  5145 sgd_solver.cpp:106] Iteration 151700, lr = 1e-22
I0430 02:17:32.789280  5145 solver.cpp:228] Iteration 151800, loss = 0.236761
I0430 02:17:32.789433  5145 solver.cpp:244]     Train net output #0: loss = 0.236761 (* 1 = 0.236761 loss)
I0430 02:17:32.789448  5145 sgd_solver.cpp:106] Iteration 151800, lr = 1e-22
I0430 02:18:23.217897  5145 solver.cpp:228] Iteration 151900, loss = 0.331487
I0430 02:18:23.218061  5145 solver.cpp:244]     Train net output #0: loss = 0.331487 (* 1 = 0.331487 loss)
I0430 02:18:23.218070  5145 sgd_solver.cpp:106] Iteration 151900, lr = 1e-22
I0430 02:19:13.307549  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_152000.caffemodel
I0430 02:19:23.008890  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_152000.solverstate
I0430 02:19:23.201004  5145 solver.cpp:337] Iteration 152000, Testing net (#0)
I0430 02:19:23.201102  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 02:19:23.201107  5145 net.cpp:693] Ignoring source layer visualize
I0430 02:19:23.201109  5145 net.cpp:693] Ignoring source layer fake
I0430 02:24:19.008744  5145 solver.cpp:404]     Test net output #0: loss = 0.291371 (* 1 = 0.291371 loss)
I0430 02:24:19.326896  5145 solver.cpp:228] Iteration 152000, loss = 0.300119
I0430 02:24:19.326932  5145 solver.cpp:244]     Train net output #0: loss = 0.300119 (* 1 = 0.300119 loss)
I0430 02:24:19.326938  5145 sgd_solver.cpp:106] Iteration 152000, lr = 1e-22
I0430 02:25:09.856710  5145 solver.cpp:228] Iteration 152100, loss = 0.173905
I0430 02:25:09.856880  5145 solver.cpp:244]     Train net output #0: loss = 0.173905 (* 1 = 0.173905 loss)
I0430 02:25:09.856887  5145 sgd_solver.cpp:106] Iteration 152100, lr = 1e-22
I0430 02:26:02.075716  5145 solver.cpp:228] Iteration 152200, loss = 0.245839
I0430 02:26:02.076464  5145 solver.cpp:244]     Train net output #0: loss = 0.245839 (* 1 = 0.245839 loss)
I0430 02:26:02.076472  5145 sgd_solver.cpp:106] Iteration 152200, lr = 1e-22
I0430 02:26:52.632025  5145 solver.cpp:228] Iteration 152300, loss = 0.173856
I0430 02:26:52.632174  5145 solver.cpp:244]     Train net output #0: loss = 0.173856 (* 1 = 0.173856 loss)
I0430 02:26:52.632180  5145 sgd_solver.cpp:106] Iteration 152300, lr = 1e-22
I0430 02:27:43.150574  5145 solver.cpp:228] Iteration 152400, loss = 0.158228
I0430 02:27:43.150738  5145 solver.cpp:244]     Train net output #0: loss = 0.158228 (* 1 = 0.158228 loss)
I0430 02:27:43.150743  5145 sgd_solver.cpp:106] Iteration 152400, lr = 1e-22
I0430 02:28:35.373821  5145 solver.cpp:228] Iteration 152500, loss = 0.131799
I0430 02:28:35.373989  5145 solver.cpp:244]     Train net output #0: loss = 0.131799 (* 1 = 0.131799 loss)
I0430 02:28:35.373996  5145 sgd_solver.cpp:106] Iteration 152500, lr = 1e-22
I0430 02:29:25.977136  5145 solver.cpp:228] Iteration 152600, loss = 0.334717
I0430 02:29:25.977290  5145 solver.cpp:244]     Train net output #0: loss = 0.334717 (* 1 = 0.334717 loss)
I0430 02:29:25.977298  5145 sgd_solver.cpp:106] Iteration 152600, lr = 1e-22
I0430 02:30:16.499044  5145 solver.cpp:228] Iteration 152700, loss = 0.267643
I0430 02:30:16.499207  5145 solver.cpp:244]     Train net output #0: loss = 0.267643 (* 1 = 0.267643 loss)
I0430 02:30:16.499213  5145 sgd_solver.cpp:106] Iteration 152700, lr = 1e-22
I0430 02:31:08.516831  5145 solver.cpp:228] Iteration 152800, loss = 0.221541
I0430 02:31:08.517007  5145 solver.cpp:244]     Train net output #0: loss = 0.221541 (* 1 = 0.221541 loss)
I0430 02:31:08.517014  5145 sgd_solver.cpp:106] Iteration 152800, lr = 1e-22
I0430 02:31:58.957890  5145 solver.cpp:228] Iteration 152900, loss = 0.323506
I0430 02:31:58.958057  5145 solver.cpp:244]     Train net output #0: loss = 0.323506 (* 1 = 0.323506 loss)
I0430 02:31:58.958063  5145 sgd_solver.cpp:106] Iteration 152900, lr = 1e-22
I0430 02:32:49.037420  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_153000.caffemodel
I0430 02:32:54.229539  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_153000.solverstate
I0430 02:32:54.422682  5145 solver.cpp:337] Iteration 153000, Testing net (#0)
I0430 02:32:54.422765  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 02:32:54.422791  5145 net.cpp:693] Ignoring source layer visualize
I0430 02:32:54.422792  5145 net.cpp:693] Ignoring source layer fake
I0430 02:37:49.980499  5145 solver.cpp:404]     Test net output #0: loss = 0.286633 (* 1 = 0.286633 loss)
I0430 02:37:50.293392  5145 solver.cpp:228] Iteration 153000, loss = 0.154706
I0430 02:37:50.293409  5145 solver.cpp:244]     Train net output #0: loss = 0.154706 (* 1 = 0.154706 loss)
I0430 02:37:50.293431  5145 sgd_solver.cpp:106] Iteration 153000, lr = 1e-22
I0430 02:38:42.019390  5145 solver.cpp:228] Iteration 153100, loss = 0.207848
I0430 02:38:42.019556  5145 solver.cpp:244]     Train net output #0: loss = 0.207848 (* 1 = 0.207848 loss)
I0430 02:38:42.019562  5145 sgd_solver.cpp:106] Iteration 153100, lr = 1e-22
I0430 02:39:32.427018  5145 solver.cpp:228] Iteration 153200, loss = 0.195608
I0430 02:39:32.427186  5145 solver.cpp:244]     Train net output #0: loss = 0.195608 (* 1 = 0.195608 loss)
I0430 02:39:32.427192  5145 sgd_solver.cpp:106] Iteration 153200, lr = 1e-22
I0430 02:40:22.988560  5145 solver.cpp:228] Iteration 153300, loss = 0.261442
I0430 02:40:22.988723  5145 solver.cpp:244]     Train net output #0: loss = 0.261442 (* 1 = 0.261442 loss)
I0430 02:40:22.988729  5145 sgd_solver.cpp:106] Iteration 153300, lr = 1e-22
I0430 02:41:14.726773  5145 solver.cpp:228] Iteration 153400, loss = 0.246002
I0430 02:41:14.726936  5145 solver.cpp:244]     Train net output #0: loss = 0.246002 (* 1 = 0.246002 loss)
I0430 02:41:14.726943  5145 sgd_solver.cpp:106] Iteration 153400, lr = 1e-22
I0430 02:42:05.204382  5145 solver.cpp:228] Iteration 153500, loss = 0.321777
I0430 02:42:05.204545  5145 solver.cpp:244]     Train net output #0: loss = 0.321777 (* 1 = 0.321777 loss)
I0430 02:42:05.204551  5145 sgd_solver.cpp:106] Iteration 153500, lr = 1e-22
I0430 02:42:57.180863  5145 solver.cpp:228] Iteration 153600, loss = 0.242004
I0430 02:42:57.181030  5145 solver.cpp:244]     Train net output #0: loss = 0.242004 (* 1 = 0.242004 loss)
I0430 02:42:57.181035  5145 sgd_solver.cpp:106] Iteration 153600, lr = 1e-22
I0430 02:43:47.631616  5145 solver.cpp:228] Iteration 153700, loss = 0.0547162
I0430 02:43:47.631765  5145 solver.cpp:244]     Train net output #0: loss = 0.0547162 (* 1 = 0.0547162 loss)
I0430 02:43:47.631773  5145 sgd_solver.cpp:106] Iteration 153700, lr = 1e-22
I0430 02:44:38.136348  5145 solver.cpp:228] Iteration 153800, loss = 0.0291983
I0430 02:44:38.136507  5145 solver.cpp:244]     Train net output #0: loss = 0.0291983 (* 1 = 0.0291983 loss)
I0430 02:44:38.136512  5145 sgd_solver.cpp:106] Iteration 153800, lr = 1e-22
I0430 02:45:30.291752  5145 solver.cpp:228] Iteration 153900, loss = 0.315092
I0430 02:45:30.291918  5145 solver.cpp:244]     Train net output #0: loss = 0.315092 (* 1 = 0.315092 loss)
I0430 02:45:30.291924  5145 sgd_solver.cpp:106] Iteration 153900, lr = 1e-22
I0430 02:46:20.439499  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_154000.caffemodel
I0430 02:46:37.689230  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_154000.solverstate
I0430 02:46:37.890254  5145 solver.cpp:337] Iteration 154000, Testing net (#0)
I0430 02:46:37.890336  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 02:46:37.890338  5145 net.cpp:693] Ignoring source layer visualize
I0430 02:46:37.890357  5145 net.cpp:693] Ignoring source layer fake
I0430 02:51:33.594071  5145 solver.cpp:404]     Test net output #0: loss = 0.285816 (* 1 = 0.285816 loss)
I0430 02:51:33.906366  5145 solver.cpp:228] Iteration 154000, loss = 0.321884
I0430 02:51:33.906417  5145 solver.cpp:244]     Train net output #0: loss = 0.321884 (* 1 = 0.321884 loss)
I0430 02:51:33.906425  5145 sgd_solver.cpp:106] Iteration 154000, lr = 1e-22
I0430 02:52:24.434967  5145 solver.cpp:228] Iteration 154100, loss = 0.369483
I0430 02:52:24.435112  5145 solver.cpp:244]     Train net output #0: loss = 0.369483 (* 1 = 0.369483 loss)
I0430 02:52:24.435118  5145 sgd_solver.cpp:106] Iteration 154100, lr = 1e-22
I0430 02:53:15.103240  5145 solver.cpp:228] Iteration 154200, loss = 0.245476
I0430 02:53:15.103394  5145 solver.cpp:244]     Train net output #0: loss = 0.245476 (* 1 = 0.245476 loss)
I0430 02:53:15.103400  5145 sgd_solver.cpp:106] Iteration 154200, lr = 1e-22
I0430 02:54:07.259595  5145 solver.cpp:228] Iteration 154300, loss = 0.261174
I0430 02:54:07.259794  5145 solver.cpp:244]     Train net output #0: loss = 0.261174 (* 1 = 0.261174 loss)
I0430 02:54:07.259800  5145 sgd_solver.cpp:106] Iteration 154300, lr = 1e-22
I0430 02:54:57.782213  5145 solver.cpp:228] Iteration 154400, loss = 0.403432
I0430 02:54:57.782367  5145 solver.cpp:244]     Train net output #0: loss = 0.403432 (* 1 = 0.403432 loss)
I0430 02:54:57.782376  5145 sgd_solver.cpp:106] Iteration 154400, lr = 1e-22
I0430 02:55:48.436826  5145 solver.cpp:228] Iteration 154500, loss = 0.297757
I0430 02:55:48.436985  5145 solver.cpp:244]     Train net output #0: loss = 0.297757 (* 1 = 0.297757 loss)
I0430 02:55:48.436991  5145 sgd_solver.cpp:106] Iteration 154500, lr = 1e-22
I0430 02:56:40.669867  5145 solver.cpp:228] Iteration 154600, loss = 0.262065
I0430 02:56:40.670053  5145 solver.cpp:244]     Train net output #0: loss = 0.262065 (* 1 = 0.262065 loss)
I0430 02:56:40.670059  5145 sgd_solver.cpp:106] Iteration 154600, lr = 1e-22
I0430 02:57:31.233734  5145 solver.cpp:228] Iteration 154700, loss = 0.247758
I0430 02:57:31.233894  5145 solver.cpp:244]     Train net output #0: loss = 0.247758 (* 1 = 0.247758 loss)
I0430 02:57:31.233901  5145 sgd_solver.cpp:106] Iteration 154700, lr = 1e-22
I0430 02:58:21.888833  5145 solver.cpp:228] Iteration 154800, loss = 0.219138
I0430 02:58:21.889003  5145 solver.cpp:244]     Train net output #0: loss = 0.219138 (* 1 = 0.219138 loss)
I0430 02:58:21.889010  5145 sgd_solver.cpp:106] Iteration 154800, lr = 1e-22
I0430 02:59:12.424980  5145 solver.cpp:228] Iteration 154900, loss = 0.357561
I0430 02:59:12.425155  5145 solver.cpp:244]     Train net output #0: loss = 0.357561 (* 1 = 0.357561 loss)
I0430 02:59:12.425163  5145 sgd_solver.cpp:106] Iteration 154900, lr = 1e-22
I0430 03:00:04.055285  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_155000.caffemodel
I0430 03:00:19.947897  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_155000.solverstate
I0430 03:00:20.150735  5145 solver.cpp:337] Iteration 155000, Testing net (#0)
I0430 03:00:20.150833  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 03:00:20.150840  5145 net.cpp:693] Ignoring source layer visualize
I0430 03:00:20.150841  5145 net.cpp:693] Ignoring source layer fake
I0430 03:05:15.728075  5145 solver.cpp:404]     Test net output #0: loss = 0.280825 (* 1 = 0.280825 loss)
I0430 03:05:16.039582  5145 solver.cpp:228] Iteration 155000, loss = 0.196639
I0430 03:05:16.039607  5145 solver.cpp:244]     Train net output #0: loss = 0.196639 (* 1 = 0.196639 loss)
I0430 03:05:16.039628  5145 sgd_solver.cpp:106] Iteration 155000, lr = 1e-22
I0430 03:06:06.610987  5145 solver.cpp:228] Iteration 155100, loss = 0.265756
I0430 03:06:06.611160  5145 solver.cpp:244]     Train net output #0: loss = 0.265756 (* 1 = 0.265756 loss)
I0430 03:06:06.611168  5145 sgd_solver.cpp:106] Iteration 155100, lr = 1e-22
I0430 03:06:57.129613  5145 solver.cpp:228] Iteration 155200, loss = 0.3474
I0430 03:06:57.133941  5145 solver.cpp:244]     Train net output #0: loss = 0.3474 (* 1 = 0.3474 loss)
I0430 03:06:57.133947  5145 sgd_solver.cpp:106] Iteration 155200, lr = 1e-22
I0430 03:07:49.320287  5145 solver.cpp:228] Iteration 155300, loss = 0.20297
I0430 03:07:49.320461  5145 solver.cpp:244]     Train net output #0: loss = 0.20297 (* 1 = 0.20297 loss)
I0430 03:07:49.320468  5145 sgd_solver.cpp:106] Iteration 155300, lr = 1e-22
I0430 03:08:39.846643  5145 solver.cpp:228] Iteration 155400, loss = 0.25539
I0430 03:08:39.846799  5145 solver.cpp:244]     Train net output #0: loss = 0.25539 (* 1 = 0.25539 loss)
I0430 03:08:39.846807  5145 sgd_solver.cpp:106] Iteration 155400, lr = 1e-22
I0430 03:09:30.372017  5145 solver.cpp:228] Iteration 155500, loss = 0.18227
I0430 03:09:30.372184  5145 solver.cpp:244]     Train net output #0: loss = 0.18227 (* 1 = 0.18227 loss)
I0430 03:09:30.372191  5145 sgd_solver.cpp:106] Iteration 155500, lr = 1e-22
I0430 03:10:22.538930  5145 solver.cpp:228] Iteration 155600, loss = 0.180613
I0430 03:10:22.539085  5145 solver.cpp:244]     Train net output #0: loss = 0.180613 (* 1 = 0.180613 loss)
I0430 03:10:22.539093  5145 sgd_solver.cpp:106] Iteration 155600, lr = 1e-22
I0430 03:11:13.022816  5145 solver.cpp:228] Iteration 155700, loss = 0.346276
I0430 03:11:13.024217  5145 solver.cpp:244]     Train net output #0: loss = 0.346276 (* 1 = 0.346276 loss)
I0430 03:11:13.024240  5145 sgd_solver.cpp:106] Iteration 155700, lr = 1e-22
I0430 03:12:03.565826  5145 solver.cpp:228] Iteration 155800, loss = 0.203513
I0430 03:12:03.565997  5145 solver.cpp:244]     Train net output #0: loss = 0.203513 (* 1 = 0.203513 loss)
I0430 03:12:03.566004  5145 sgd_solver.cpp:106] Iteration 155800, lr = 1e-22
I0430 03:12:54.038987  5145 solver.cpp:228] Iteration 155900, loss = 0.421638
I0430 03:12:54.039142  5145 solver.cpp:244]     Train net output #0: loss = 0.421638 (* 1 = 0.421638 loss)
I0430 03:12:54.039149  5145 sgd_solver.cpp:106] Iteration 155900, lr = 1e-22
I0430 03:13:45.750347  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_156000.caffemodel
I0430 03:13:57.259516  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_156000.solverstate
I0430 03:13:57.447335  5145 solver.cpp:337] Iteration 156000, Testing net (#0)
I0430 03:13:57.447433  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 03:13:57.447438  5145 net.cpp:693] Ignoring source layer visualize
I0430 03:13:57.447440  5145 net.cpp:693] Ignoring source layer fake
I0430 03:18:52.747272  5145 solver.cpp:404]     Test net output #0: loss = 0.282986 (* 1 = 0.282986 loss)
I0430 03:18:53.064551  5145 solver.cpp:228] Iteration 156000, loss = 0.224792
I0430 03:18:53.064570  5145 solver.cpp:244]     Train net output #0: loss = 0.224792 (* 1 = 0.224792 loss)
I0430 03:18:53.064592  5145 sgd_solver.cpp:106] Iteration 156000, lr = 1e-22
I0430 03:19:43.598204  5145 solver.cpp:228] Iteration 156100, loss = 0.533771
I0430 03:19:43.598352  5145 solver.cpp:244]     Train net output #0: loss = 0.533771 (* 1 = 0.533771 loss)
I0430 03:19:43.598359  5145 sgd_solver.cpp:106] Iteration 156100, lr = 1e-22
I0430 03:20:34.145109  5145 solver.cpp:228] Iteration 156200, loss = 0.260221
I0430 03:20:34.145258  5145 solver.cpp:244]     Train net output #0: loss = 0.260221 (* 1 = 0.260221 loss)
I0430 03:20:34.145265  5145 sgd_solver.cpp:106] Iteration 156200, lr = 1e-22
I0430 03:21:25.761009  5145 solver.cpp:228] Iteration 156300, loss = 0.208298
I0430 03:21:25.761178  5145 solver.cpp:244]     Train net output #0: loss = 0.208298 (* 1 = 0.208298 loss)
I0430 03:21:25.761183  5145 sgd_solver.cpp:106] Iteration 156300, lr = 1e-22
I0430 03:22:16.282423  5145 solver.cpp:228] Iteration 156400, loss = 0.279776
I0430 03:22:16.283879  5145 solver.cpp:244]     Train net output #0: loss = 0.279776 (* 1 = 0.279776 loss)
I0430 03:22:16.283886  5145 sgd_solver.cpp:106] Iteration 156400, lr = 1e-22
I0430 03:23:07.992903  5145 solver.cpp:228] Iteration 156500, loss = 0.223155
I0430 03:23:07.993046  5145 solver.cpp:244]     Train net output #0: loss = 0.223155 (* 1 = 0.223155 loss)
I0430 03:23:07.993052  5145 sgd_solver.cpp:106] Iteration 156500, lr = 1e-22
I0430 03:23:58.562150  5145 solver.cpp:228] Iteration 156600, loss = 0.255669
I0430 03:23:58.562310  5145 solver.cpp:244]     Train net output #0: loss = 0.255669 (* 1 = 0.255669 loss)
I0430 03:23:58.562317  5145 sgd_solver.cpp:106] Iteration 156600, lr = 1e-22
I0430 03:24:49.091889  5145 solver.cpp:228] Iteration 156700, loss = 0.301343
I0430 03:24:49.092028  5145 solver.cpp:244]     Train net output #0: loss = 0.301343 (* 1 = 0.301343 loss)
I0430 03:24:49.092034  5145 sgd_solver.cpp:106] Iteration 156700, lr = 1e-22
I0430 03:25:41.177831  5145 solver.cpp:228] Iteration 156800, loss = 0.20396
I0430 03:25:41.178014  5145 solver.cpp:244]     Train net output #0: loss = 0.20396 (* 1 = 0.20396 loss)
I0430 03:25:41.178021  5145 sgd_solver.cpp:106] Iteration 156800, lr = 1e-22
I0430 03:26:31.668190  5145 solver.cpp:228] Iteration 156900, loss = 0.134958
I0430 03:26:31.668354  5145 solver.cpp:244]     Train net output #0: loss = 0.134958 (* 1 = 0.134958 loss)
I0430 03:26:31.668360  5145 sgd_solver.cpp:106] Iteration 156900, lr = 1e-22
I0430 03:27:21.776026  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_157000.caffemodel
I0430 03:27:36.437721  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_157000.solverstate
I0430 03:27:36.642288  5145 solver.cpp:337] Iteration 157000, Testing net (#0)
I0430 03:27:36.642388  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 03:27:36.642393  5145 net.cpp:693] Ignoring source layer visualize
I0430 03:27:36.642395  5145 net.cpp:693] Ignoring source layer fake
I0430 03:32:31.783442  5145 solver.cpp:404]     Test net output #0: loss = 0.291354 (* 1 = 0.291354 loss)
I0430 03:32:32.108865  5145 solver.cpp:228] Iteration 157000, loss = 0.224776
I0430 03:32:32.108887  5145 solver.cpp:244]     Train net output #0: loss = 0.224776 (* 1 = 0.224776 loss)
I0430 03:32:32.108908  5145 sgd_solver.cpp:106] Iteration 157000, lr = 1e-22
I0430 03:33:24.401237  5145 solver.cpp:228] Iteration 157100, loss = 0.241461
I0430 03:33:24.401397  5145 solver.cpp:244]     Train net output #0: loss = 0.241461 (* 1 = 0.241461 loss)
I0430 03:33:24.401404  5145 sgd_solver.cpp:106] Iteration 157100, lr = 1e-22
I0430 03:34:14.852212  5145 solver.cpp:228] Iteration 157200, loss = 0.29104
I0430 03:34:14.852380  5145 solver.cpp:244]     Train net output #0: loss = 0.29104 (* 1 = 0.29104 loss)
I0430 03:34:14.852385  5145 sgd_solver.cpp:106] Iteration 157200, lr = 1e-22
I0430 03:35:05.371302  5145 solver.cpp:228] Iteration 157300, loss = 0.23994
I0430 03:35:05.371482  5145 solver.cpp:244]     Train net output #0: loss = 0.23994 (* 1 = 0.23994 loss)
I0430 03:35:05.371490  5145 sgd_solver.cpp:106] Iteration 157300, lr = 1e-22
I0430 03:35:57.860431  5145 solver.cpp:228] Iteration 157400, loss = 0.294459
I0430 03:35:57.861130  5145 solver.cpp:244]     Train net output #0: loss = 0.294459 (* 1 = 0.294459 loss)
I0430 03:35:57.861138  5145 sgd_solver.cpp:106] Iteration 157400, lr = 1e-22
I0430 03:36:48.368851  5145 solver.cpp:228] Iteration 157500, loss = 0.189173
I0430 03:36:48.369606  5145 solver.cpp:244]     Train net output #0: loss = 0.189173 (* 1 = 0.189173 loss)
I0430 03:36:48.369612  5145 sgd_solver.cpp:106] Iteration 157500, lr = 1e-23
I0430 03:37:38.851805  5145 solver.cpp:228] Iteration 157600, loss = 0.294553
I0430 03:37:38.852919  5145 solver.cpp:244]     Train net output #0: loss = 0.294553 (* 1 = 0.294553 loss)
I0430 03:37:38.852926  5145 sgd_solver.cpp:106] Iteration 157600, lr = 1e-23
I0430 03:38:31.383474  5145 solver.cpp:228] Iteration 157700, loss = 0.32401
I0430 03:38:31.383651  5145 solver.cpp:244]     Train net output #0: loss = 0.32401 (* 1 = 0.32401 loss)
I0430 03:38:31.383661  5145 sgd_solver.cpp:106] Iteration 157700, lr = 1e-23
I0430 03:39:21.895911  5145 solver.cpp:228] Iteration 157800, loss = 0.382071
I0430 03:39:21.896070  5145 solver.cpp:244]     Train net output #0: loss = 0.382071 (* 1 = 0.382071 loss)
I0430 03:39:21.896076  5145 sgd_solver.cpp:106] Iteration 157800, lr = 1e-23
I0430 03:40:12.448925  5145 solver.cpp:228] Iteration 157900, loss = 0.233278
I0430 03:40:12.449090  5145 solver.cpp:244]     Train net output #0: loss = 0.233278 (* 1 = 0.233278 loss)
I0430 03:40:12.449095  5145 sgd_solver.cpp:106] Iteration 157900, lr = 1e-23
I0430 03:41:02.723881  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_158000.caffemodel
I0430 03:41:22.418555  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_158000.solverstate
I0430 03:41:22.612774  5145 solver.cpp:337] Iteration 158000, Testing net (#0)
I0430 03:41:22.612874  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 03:41:22.612879  5145 net.cpp:693] Ignoring source layer visualize
I0430 03:41:22.612882  5145 net.cpp:693] Ignoring source layer fake
I0430 03:46:18.045161  5145 solver.cpp:404]     Test net output #0: loss = 0.286509 (* 1 = 0.286509 loss)
I0430 03:46:18.357633  5145 solver.cpp:228] Iteration 158000, loss = 0.379712
I0430 03:46:18.357655  5145 solver.cpp:244]     Train net output #0: loss = 0.379712 (* 1 = 0.379712 loss)
I0430 03:46:18.357677  5145 sgd_solver.cpp:106] Iteration 158000, lr = 1e-23
I0430 03:47:10.622268  5145 solver.cpp:228] Iteration 158100, loss = 0.252163
I0430 03:47:10.623414  5145 solver.cpp:244]     Train net output #0: loss = 0.252163 (* 1 = 0.252163 loss)
I0430 03:47:10.623435  5145 sgd_solver.cpp:106] Iteration 158100, lr = 1e-23
I0430 03:48:01.181306  5145 solver.cpp:228] Iteration 158200, loss = 0.203457
I0430 03:48:01.181485  5145 solver.cpp:244]     Train net output #0: loss = 0.203457 (* 1 = 0.203457 loss)
I0430 03:48:01.181493  5145 sgd_solver.cpp:106] Iteration 158200, lr = 1e-23
I0430 03:48:51.676841  5145 solver.cpp:228] Iteration 158300, loss = 0.17231
I0430 03:48:51.677008  5145 solver.cpp:244]     Train net output #0: loss = 0.17231 (* 1 = 0.17231 loss)
I0430 03:48:51.677016  5145 sgd_solver.cpp:106] Iteration 158300, lr = 1e-23
I0430 03:49:44.060251  5145 solver.cpp:228] Iteration 158400, loss = 0.0657379
I0430 03:49:44.060398  5145 solver.cpp:244]     Train net output #0: loss = 0.0657379 (* 1 = 0.0657379 loss)
I0430 03:49:44.060406  5145 sgd_solver.cpp:106] Iteration 158400, lr = 1e-23
I0430 03:50:34.588982  5145 solver.cpp:228] Iteration 158500, loss = 0.179784
I0430 03:50:34.589148  5145 solver.cpp:244]     Train net output #0: loss = 0.179784 (* 1 = 0.179784 loss)
I0430 03:50:34.589155  5145 sgd_solver.cpp:106] Iteration 158500, lr = 1e-23
I0430 03:51:25.241446  5145 solver.cpp:228] Iteration 158600, loss = 0.21904
I0430 03:51:25.241607  5145 solver.cpp:244]     Train net output #0: loss = 0.21904 (* 1 = 0.21904 loss)
I0430 03:51:25.241613  5145 sgd_solver.cpp:106] Iteration 158600, lr = 1e-23
I0430 03:52:15.724294  5145 solver.cpp:228] Iteration 158700, loss = 0.325708
I0430 03:52:15.724455  5145 solver.cpp:244]     Train net output #0: loss = 0.325708 (* 1 = 0.325708 loss)
I0430 03:52:15.724462  5145 sgd_solver.cpp:106] Iteration 158700, lr = 1e-23
I0430 03:53:07.927418  5145 solver.cpp:228] Iteration 158800, loss = 0.175802
I0430 03:53:07.927580  5145 solver.cpp:244]     Train net output #0: loss = 0.175802 (* 1 = 0.175802 loss)
I0430 03:53:07.927587  5145 sgd_solver.cpp:106] Iteration 158800, lr = 1e-23
I0430 03:53:58.348197  5145 solver.cpp:228] Iteration 158900, loss = 0.198845
I0430 03:53:58.348364  5145 solver.cpp:244]     Train net output #0: loss = 0.198845 (* 1 = 0.198845 loss)
I0430 03:53:58.348371  5145 sgd_solver.cpp:106] Iteration 158900, lr = 1e-23
I0430 03:54:48.616597  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_159000.caffemodel
I0430 03:54:57.094288  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_159000.solverstate
I0430 03:54:57.283463  5145 solver.cpp:337] Iteration 159000, Testing net (#0)
I0430 03:54:57.283560  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 03:54:57.283566  5145 net.cpp:693] Ignoring source layer visualize
I0430 03:54:57.283568  5145 net.cpp:693] Ignoring source layer fake
I0430 03:59:53.761292  5145 solver.cpp:404]     Test net output #0: loss = 0.285654 (* 1 = 0.285654 loss)
I0430 03:59:54.073823  5145 solver.cpp:228] Iteration 159000, loss = 0.259407
I0430 03:59:54.073842  5145 solver.cpp:244]     Train net output #0: loss = 0.259407 (* 1 = 0.259407 loss)
I0430 03:59:54.073863  5145 sgd_solver.cpp:106] Iteration 159000, lr = 1e-23
I0430 04:00:46.163158  5145 solver.cpp:228] Iteration 159100, loss = 0.299419
I0430 04:00:46.163319  5145 solver.cpp:244]     Train net output #0: loss = 0.299419 (* 1 = 0.299419 loss)
I0430 04:00:46.163326  5145 sgd_solver.cpp:106] Iteration 159100, lr = 1e-23
I0430 04:01:36.667089  5145 solver.cpp:228] Iteration 159200, loss = 0.202918
I0430 04:01:36.667246  5145 solver.cpp:244]     Train net output #0: loss = 0.202918 (* 1 = 0.202918 loss)
I0430 04:01:36.667253  5145 sgd_solver.cpp:106] Iteration 159200, lr = 1e-23
I0430 04:02:27.125026  5145 solver.cpp:228] Iteration 159300, loss = 0.237189
I0430 04:02:27.125192  5145 solver.cpp:244]     Train net output #0: loss = 0.237189 (* 1 = 0.237189 loss)
I0430 04:02:27.125198  5145 sgd_solver.cpp:106] Iteration 159300, lr = 1e-23
I0430 04:03:18.836055  5145 solver.cpp:228] Iteration 159400, loss = 0.147759
I0430 04:03:18.836236  5145 solver.cpp:244]     Train net output #0: loss = 0.147759 (* 1 = 0.147759 loss)
I0430 04:03:18.836242  5145 sgd_solver.cpp:106] Iteration 159400, lr = 1e-23
I0430 04:04:09.350208  5145 solver.cpp:228] Iteration 159500, loss = 0.272578
I0430 04:04:09.350354  5145 solver.cpp:244]     Train net output #0: loss = 0.272578 (* 1 = 0.272578 loss)
I0430 04:04:09.350361  5145 sgd_solver.cpp:106] Iteration 159500, lr = 1e-23
I0430 04:05:01.100469  5145 solver.cpp:228] Iteration 159600, loss = 0.270781
I0430 04:05:01.100627  5145 solver.cpp:244]     Train net output #0: loss = 0.270781 (* 1 = 0.270781 loss)
I0430 04:05:01.100633  5145 sgd_solver.cpp:106] Iteration 159600, lr = 1e-23
I0430 04:05:51.617874  5145 solver.cpp:228] Iteration 159700, loss = 0.29784
I0430 04:05:51.618089  5145 solver.cpp:244]     Train net output #0: loss = 0.29784 (* 1 = 0.29784 loss)
I0430 04:05:51.618098  5145 sgd_solver.cpp:106] Iteration 159700, lr = 1e-23
I0430 04:06:42.117269  5145 solver.cpp:228] Iteration 159800, loss = 0.257366
I0430 04:06:42.117429  5145 solver.cpp:244]     Train net output #0: loss = 0.257366 (* 1 = 0.257366 loss)
I0430 04:06:42.117445  5145 sgd_solver.cpp:106] Iteration 159800, lr = 1e-23
I0430 04:07:33.958514  5145 solver.cpp:228] Iteration 159900, loss = 0.0329019
I0430 04:07:33.958683  5145 solver.cpp:244]     Train net output #0: loss = 0.0329019 (* 1 = 0.0329019 loss)
I0430 04:07:33.958689  5145 sgd_solver.cpp:106] Iteration 159900, lr = 1e-23
I0430 04:08:24.177109  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_160000.caffemodel
I0430 04:08:37.250702  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_160000.solverstate
I0430 04:08:37.450943  5145 solver.cpp:337] Iteration 160000, Testing net (#0)
I0430 04:08:37.451045  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 04:08:37.451050  5145 net.cpp:693] Ignoring source layer visualize
I0430 04:08:37.451051  5145 net.cpp:693] Ignoring source layer fake
I0430 04:13:33.510288  5145 solver.cpp:404]     Test net output #0: loss = 0.28033 (* 1 = 0.28033 loss)
I0430 04:13:33.823410  5145 solver.cpp:228] Iteration 160000, loss = 0.184153
I0430 04:13:33.823446  5145 solver.cpp:244]     Train net output #0: loss = 0.184153 (* 1 = 0.184153 loss)
I0430 04:13:33.823452  5145 sgd_solver.cpp:106] Iteration 160000, lr = 1e-23
I0430 04:14:24.393070  5145 solver.cpp:228] Iteration 160100, loss = 0.310307
I0430 04:14:24.393424  5145 solver.cpp:244]     Train net output #0: loss = 0.310307 (* 1 = 0.310307 loss)
I0430 04:14:24.393431  5145 sgd_solver.cpp:106] Iteration 160100, lr = 1e-23
I0430 04:15:16.510200  5145 solver.cpp:228] Iteration 160200, loss = 0.426273
I0430 04:15:16.511052  5145 solver.cpp:244]     Train net output #0: loss = 0.426273 (* 1 = 0.426273 loss)
I0430 04:15:16.511061  5145 sgd_solver.cpp:106] Iteration 160200, lr = 1e-23
I0430 04:16:07.148248  5145 solver.cpp:228] Iteration 160300, loss = 0.363992
I0430 04:16:07.148407  5145 solver.cpp:244]     Train net output #0: loss = 0.363992 (* 1 = 0.363992 loss)
I0430 04:16:07.148414  5145 sgd_solver.cpp:106] Iteration 160300, lr = 1e-23
I0430 04:16:57.584038  5145 solver.cpp:228] Iteration 160400, loss = 0.350532
I0430 04:16:57.584197  5145 solver.cpp:244]     Train net output #0: loss = 0.350532 (* 1 = 0.350532 loss)
I0430 04:16:57.584203  5145 sgd_solver.cpp:106] Iteration 160400, lr = 1e-23
I0430 04:17:49.915782  5145 solver.cpp:228] Iteration 160500, loss = 0.312308
I0430 04:17:49.915952  5145 solver.cpp:244]     Train net output #0: loss = 0.312308 (* 1 = 0.312308 loss)
I0430 04:17:49.915958  5145 sgd_solver.cpp:106] Iteration 160500, lr = 1e-23
I0430 04:18:40.444069  5145 solver.cpp:228] Iteration 160600, loss = 0.353071
I0430 04:18:40.444231  5145 solver.cpp:244]     Train net output #0: loss = 0.353071 (* 1 = 0.353071 loss)
I0430 04:18:40.444239  5145 sgd_solver.cpp:106] Iteration 160600, lr = 1e-23
I0430 04:19:30.967511  5145 solver.cpp:228] Iteration 160700, loss = 0.372883
I0430 04:19:30.967671  5145 solver.cpp:244]     Train net output #0: loss = 0.372883 (* 1 = 0.372883 loss)
I0430 04:19:30.967679  5145 sgd_solver.cpp:106] Iteration 160700, lr = 1e-23
I0430 04:20:21.497431  5145 solver.cpp:228] Iteration 160800, loss = 0.306656
I0430 04:20:21.497583  5145 solver.cpp:244]     Train net output #0: loss = 0.306656 (* 1 = 0.306656 loss)
I0430 04:20:21.497591  5145 sgd_solver.cpp:106] Iteration 160800, lr = 1e-23
I0430 04:21:13.654317  5145 solver.cpp:228] Iteration 160900, loss = 0.289284
I0430 04:21:13.654487  5145 solver.cpp:244]     Train net output #0: loss = 0.289284 (* 1 = 0.289284 loss)
I0430 04:21:13.654495  5145 sgd_solver.cpp:106] Iteration 160900, lr = 1e-23
I0430 04:22:03.853976  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_161000.caffemodel
I0430 04:22:15.430321  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_161000.solverstate
I0430 04:22:15.634299  5145 solver.cpp:337] Iteration 161000, Testing net (#0)
I0430 04:22:15.634383  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 04:22:15.634387  5145 net.cpp:693] Ignoring source layer visualize
I0430 04:22:15.634389  5145 net.cpp:693] Ignoring source layer fake
I0430 04:27:11.725913  5145 solver.cpp:404]     Test net output #0: loss = 0.283445 (* 1 = 0.283445 loss)
I0430 04:27:12.039961  5145 solver.cpp:228] Iteration 161000, loss = 0.291205
I0430 04:27:12.039980  5145 solver.cpp:244]     Train net output #0: loss = 0.291205 (* 1 = 0.291205 loss)
I0430 04:27:12.040002  5145 sgd_solver.cpp:106] Iteration 161000, lr = 1e-23
I0430 04:28:02.645154  5145 solver.cpp:228] Iteration 161100, loss = 0.376811
I0430 04:28:02.645334  5145 solver.cpp:244]     Train net output #0: loss = 0.376811 (* 1 = 0.376811 loss)
I0430 04:28:02.645340  5145 sgd_solver.cpp:106] Iteration 161100, lr = 1e-23
I0430 04:28:54.733460  5145 solver.cpp:228] Iteration 161200, loss = 0.226398
I0430 04:28:54.733621  5145 solver.cpp:244]     Train net output #0: loss = 0.226398 (* 1 = 0.226398 loss)
I0430 04:28:54.733628  5145 sgd_solver.cpp:106] Iteration 161200, lr = 1e-23
I0430 04:29:45.232271  5145 solver.cpp:228] Iteration 161300, loss = 0.211759
I0430 04:29:45.232434  5145 solver.cpp:244]     Train net output #0: loss = 0.211759 (* 1 = 0.211759 loss)
I0430 04:29:45.232441  5145 sgd_solver.cpp:106] Iteration 161300, lr = 1e-23
I0430 04:30:35.694324  5145 solver.cpp:228] Iteration 161400, loss = 0.271549
I0430 04:30:35.694475  5145 solver.cpp:244]     Train net output #0: loss = 0.271549 (* 1 = 0.271549 loss)
I0430 04:30:35.694483  5145 sgd_solver.cpp:106] Iteration 161400, lr = 1e-23
I0430 04:31:28.124152  5145 solver.cpp:228] Iteration 161500, loss = 0.312526
I0430 04:31:28.125223  5145 solver.cpp:244]     Train net output #0: loss = 0.312526 (* 1 = 0.312526 loss)
I0430 04:31:28.125231  5145 sgd_solver.cpp:106] Iteration 161500, lr = 1e-23
I0430 04:32:18.472015  5145 solver.cpp:228] Iteration 161600, loss = 0.175564
I0430 04:32:18.472157  5145 solver.cpp:244]     Train net output #0: loss = 0.175564 (* 1 = 0.175564 loss)
I0430 04:32:18.472163  5145 sgd_solver.cpp:106] Iteration 161600, lr = 1e-23
I0430 04:33:09.117123  5145 solver.cpp:228] Iteration 161700, loss = 0.255556
I0430 04:33:09.117318  5145 solver.cpp:244]     Train net output #0: loss = 0.255556 (* 1 = 0.255556 loss)
I0430 04:33:09.117327  5145 sgd_solver.cpp:106] Iteration 161700, lr = 1e-23
I0430 04:33:59.474382  5145 solver.cpp:228] Iteration 161800, loss = 0.137154
I0430 04:33:59.474555  5145 solver.cpp:244]     Train net output #0: loss = 0.137154 (* 1 = 0.137154 loss)
I0430 04:33:59.474561  5145 sgd_solver.cpp:106] Iteration 161800, lr = 1e-23
I0430 04:34:51.560837  5145 solver.cpp:228] Iteration 161900, loss = 0.163928
I0430 04:34:51.561003  5145 solver.cpp:244]     Train net output #0: loss = 0.163928 (* 1 = 0.163928 loss)
I0430 04:34:51.561010  5145 sgd_solver.cpp:106] Iteration 161900, lr = 1e-23
I0430 04:35:41.714936  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_162000.caffemodel
I0430 04:35:46.414335  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_162000.solverstate
I0430 04:35:46.601021  5145 solver.cpp:337] Iteration 162000, Testing net (#0)
I0430 04:35:46.601117  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 04:35:46.601122  5145 net.cpp:693] Ignoring source layer visualize
I0430 04:35:46.601125  5145 net.cpp:693] Ignoring source layer fake
I0430 04:40:42.550356  5145 solver.cpp:404]     Test net output #0: loss = 0.291307 (* 1 = 0.291307 loss)
I0430 04:40:42.862025  5145 solver.cpp:228] Iteration 162000, loss = 0.209835
I0430 04:40:42.862062  5145 solver.cpp:244]     Train net output #0: loss = 0.209835 (* 1 = 0.209835 loss)
I0430 04:40:42.862069  5145 sgd_solver.cpp:106] Iteration 162000, lr = 1e-23
I0430 04:41:33.313524  5145 solver.cpp:228] Iteration 162100, loss = 0.0547989
I0430 04:41:33.313681  5145 solver.cpp:244]     Train net output #0: loss = 0.0547989 (* 1 = 0.0547989 loss)
I0430 04:41:33.313688  5145 sgd_solver.cpp:106] Iteration 162100, lr = 1e-23
I0430 04:42:25.341877  5145 solver.cpp:228] Iteration 162200, loss = 0.526043
I0430 04:42:25.342131  5145 solver.cpp:244]     Train net output #0: loss = 0.526043 (* 1 = 0.526043 loss)
I0430 04:42:25.342137  5145 sgd_solver.cpp:106] Iteration 162200, lr = 1e-23
I0430 04:43:15.790736  5145 solver.cpp:228] Iteration 162300, loss = 0.273737
I0430 04:43:15.790897  5145 solver.cpp:244]     Train net output #0: loss = 0.273737 (* 1 = 0.273737 loss)
I0430 04:43:15.790904  5145 sgd_solver.cpp:106] Iteration 162300, lr = 1e-23
I0430 04:44:06.345226  5145 solver.cpp:228] Iteration 162400, loss = 0.202834
I0430 04:44:06.345396  5145 solver.cpp:244]     Train net output #0: loss = 0.202834 (* 1 = 0.202834 loss)
I0430 04:44:06.345403  5145 sgd_solver.cpp:106] Iteration 162400, lr = 1e-23
I0430 04:44:58.044466  5145 solver.cpp:228] Iteration 162500, loss = 0.17883
I0430 04:44:58.044603  5145 solver.cpp:244]     Train net output #0: loss = 0.17883 (* 1 = 0.17883 loss)
I0430 04:44:58.044610  5145 sgd_solver.cpp:106] Iteration 162500, lr = 1e-23
I0430 04:45:48.564107  5145 solver.cpp:228] Iteration 162600, loss = 0.372623
I0430 04:45:48.564267  5145 solver.cpp:244]     Train net output #0: loss = 0.372623 (* 1 = 0.372623 loss)
I0430 04:45:48.564273  5145 sgd_solver.cpp:106] Iteration 162600, lr = 1e-23
I0430 04:46:39.047652  5145 solver.cpp:228] Iteration 162700, loss = 0.239143
I0430 04:46:39.047806  5145 solver.cpp:244]     Train net output #0: loss = 0.239143 (* 1 = 0.239143 loss)
I0430 04:46:39.047813  5145 sgd_solver.cpp:106] Iteration 162700, lr = 1e-23
I0430 04:47:30.738684  5145 solver.cpp:228] Iteration 162800, loss = 0.206704
I0430 04:47:30.738848  5145 solver.cpp:244]     Train net output #0: loss = 0.206704 (* 1 = 0.206704 loss)
I0430 04:47:30.738855  5145 sgd_solver.cpp:106] Iteration 162800, lr = 1e-23
I0430 04:48:21.171593  5145 solver.cpp:228] Iteration 162900, loss = 0.233586
I0430 04:48:21.171752  5145 solver.cpp:244]     Train net output #0: loss = 0.233586 (* 1 = 0.233586 loss)
I0430 04:48:21.171759  5145 sgd_solver.cpp:106] Iteration 162900, lr = 1e-23
I0430 04:49:12.800694  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_163000.caffemodel
I0430 04:49:22.279492  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_163000.solverstate
I0430 04:49:22.465136  5145 solver.cpp:337] Iteration 163000, Testing net (#0)
I0430 04:49:22.465216  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 04:49:22.465220  5145 net.cpp:693] Ignoring source layer visualize
I0430 04:49:22.465237  5145 net.cpp:693] Ignoring source layer fake
I0430 04:54:17.711302  5145 solver.cpp:404]     Test net output #0: loss = 0.286599 (* 1 = 0.286599 loss)
I0430 04:54:18.025095  5145 solver.cpp:228] Iteration 163000, loss = 0.143763
I0430 04:54:18.025115  5145 solver.cpp:244]     Train net output #0: loss = 0.143763 (* 1 = 0.143763 loss)
I0430 04:54:18.025135  5145 sgd_solver.cpp:106] Iteration 163000, lr = 1e-23
I0430 04:55:08.647006  5145 solver.cpp:228] Iteration 163100, loss = 0.24207
I0430 04:55:08.647169  5145 solver.cpp:244]     Train net output #0: loss = 0.24207 (* 1 = 0.24207 loss)
I0430 04:55:08.647177  5145 sgd_solver.cpp:106] Iteration 163100, lr = 1e-23
I0430 04:55:59.115612  5145 solver.cpp:228] Iteration 163200, loss = 0.197848
I0430 04:55:59.115767  5145 solver.cpp:244]     Train net output #0: loss = 0.197848 (* 1 = 0.197848 loss)
I0430 04:55:59.115773  5145 sgd_solver.cpp:106] Iteration 163200, lr = 1e-23
I0430 04:56:51.286880  5145 solver.cpp:228] Iteration 163300, loss = 0.288421
I0430 04:56:51.287047  5145 solver.cpp:244]     Train net output #0: loss = 0.288421 (* 1 = 0.288421 loss)
I0430 04:56:51.287053  5145 sgd_solver.cpp:106] Iteration 163300, lr = 1e-23
I0430 04:57:41.893584  5145 solver.cpp:228] Iteration 163400, loss = 0.236279
I0430 04:57:41.893744  5145 solver.cpp:244]     Train net output #0: loss = 0.236279 (* 1 = 0.236279 loss)
I0430 04:57:41.893751  5145 sgd_solver.cpp:106] Iteration 163400, lr = 1e-23
I0430 04:58:32.407625  5145 solver.cpp:228] Iteration 163500, loss = 0.378109
I0430 04:58:32.407838  5145 solver.cpp:244]     Train net output #0: loss = 0.378109 (* 1 = 0.378109 loss)
I0430 04:58:32.407848  5145 sgd_solver.cpp:106] Iteration 163500, lr = 1e-23
I0430 04:59:25.050051  5145 solver.cpp:228] Iteration 163600, loss = 0.382013
I0430 04:59:25.050207  5145 solver.cpp:244]     Train net output #0: loss = 0.382013 (* 1 = 0.382013 loss)
I0430 04:59:25.050215  5145 sgd_solver.cpp:106] Iteration 163600, lr = 1e-23
I0430 05:00:15.493065  5145 solver.cpp:228] Iteration 163700, loss = 0.207735
I0430 05:00:15.493252  5145 solver.cpp:244]     Train net output #0: loss = 0.207735 (* 1 = 0.207735 loss)
I0430 05:00:15.493258  5145 sgd_solver.cpp:106] Iteration 163700, lr = 1e-23
I0430 05:01:05.913828  5145 solver.cpp:228] Iteration 163800, loss = 0.174926
I0430 05:01:05.914099  5145 solver.cpp:244]     Train net output #0: loss = 0.174926 (* 1 = 0.174926 loss)
I0430 05:01:05.914106  5145 sgd_solver.cpp:106] Iteration 163800, lr = 1e-23
I0430 05:01:56.396526  5145 solver.cpp:228] Iteration 163900, loss = 0.274033
I0430 05:01:56.396688  5145 solver.cpp:244]     Train net output #0: loss = 0.274033 (* 1 = 0.274033 loss)
I0430 05:01:56.396695  5145 sgd_solver.cpp:106] Iteration 163900, lr = 1e-23
I0430 05:02:48.290768  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_164000.caffemodel
I0430 05:03:03.922550  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_164000.solverstate
I0430 05:03:04.117972  5145 solver.cpp:337] Iteration 164000, Testing net (#0)
I0430 05:03:04.118072  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 05:03:04.118077  5145 net.cpp:693] Ignoring source layer visualize
I0430 05:03:04.118078  5145 net.cpp:693] Ignoring source layer fake
I0430 05:07:59.630657  5145 solver.cpp:404]     Test net output #0: loss = 0.285803 (* 1 = 0.285803 loss)
I0430 05:07:59.942257  5145 solver.cpp:228] Iteration 164000, loss = 0.442209
I0430 05:07:59.942276  5145 solver.cpp:244]     Train net output #0: loss = 0.442209 (* 1 = 0.442209 loss)
I0430 05:07:59.942299  5145 sgd_solver.cpp:106] Iteration 164000, lr = 1e-23
I0430 05:08:50.530511  5145 solver.cpp:228] Iteration 164100, loss = 0.305127
I0430 05:08:50.530678  5145 solver.cpp:244]     Train net output #0: loss = 0.305127 (* 1 = 0.305127 loss)
I0430 05:08:50.530684  5145 sgd_solver.cpp:106] Iteration 164100, lr = 1e-23
I0430 05:09:41.089542  5145 solver.cpp:228] Iteration 164200, loss = 0.36904
I0430 05:09:41.089715  5145 solver.cpp:244]     Train net output #0: loss = 0.36904 (* 1 = 0.36904 loss)
I0430 05:09:41.089723  5145 sgd_solver.cpp:106] Iteration 164200, lr = 1e-23
I0430 05:10:33.383322  5145 solver.cpp:228] Iteration 164300, loss = 0.26505
I0430 05:10:33.383489  5145 solver.cpp:244]     Train net output #0: loss = 0.26505 (* 1 = 0.26505 loss)
I0430 05:10:33.383496  5145 sgd_solver.cpp:106] Iteration 164300, lr = 1e-23
I0430 05:11:23.899366  5145 solver.cpp:228] Iteration 164400, loss = 0.230131
I0430 05:11:23.899513  5145 solver.cpp:244]     Train net output #0: loss = 0.230131 (* 1 = 0.230131 loss)
I0430 05:11:23.899520  5145 sgd_solver.cpp:106] Iteration 164400, lr = 1e-23
I0430 05:12:14.472590  5145 solver.cpp:228] Iteration 164500, loss = 0.228604
I0430 05:12:14.472748  5145 solver.cpp:244]     Train net output #0: loss = 0.228604 (* 1 = 0.228604 loss)
I0430 05:12:14.472754  5145 sgd_solver.cpp:106] Iteration 164500, lr = 1e-23
I0430 05:13:05.033979  5145 solver.cpp:228] Iteration 164600, loss = 0.192226
I0430 05:13:05.034204  5145 solver.cpp:244]     Train net output #0: loss = 0.192226 (* 1 = 0.192226 loss)
I0430 05:13:05.034219  5145 sgd_solver.cpp:106] Iteration 164600, lr = 1e-23
I0430 05:13:57.335635  5145 solver.cpp:228] Iteration 164700, loss = 0.215571
I0430 05:13:57.335824  5145 solver.cpp:244]     Train net output #0: loss = 0.215571 (* 1 = 0.215571 loss)
I0430 05:13:57.335831  5145 sgd_solver.cpp:106] Iteration 164700, lr = 1e-23
I0430 05:14:47.751266  5145 solver.cpp:228] Iteration 164800, loss = 0.183151
I0430 05:14:47.751435  5145 solver.cpp:244]     Train net output #0: loss = 0.183151 (* 1 = 0.183151 loss)
I0430 05:14:47.751441  5145 sgd_solver.cpp:106] Iteration 164800, lr = 1e-23
I0430 05:15:38.204861  5145 solver.cpp:228] Iteration 164900, loss = 0.235867
I0430 05:15:38.205040  5145 solver.cpp:244]     Train net output #0: loss = 0.235867 (* 1 = 0.235867 loss)
I0430 05:15:38.205046  5145 sgd_solver.cpp:106] Iteration 164900, lr = 1e-23
I0430 05:16:30.150657  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_165000.caffemodel
I0430 05:16:32.338938  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_165000.solverstate
I0430 05:16:32.523829  5145 solver.cpp:337] Iteration 165000, Testing net (#0)
I0430 05:16:32.523911  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 05:16:32.523916  5145 net.cpp:693] Ignoring source layer visualize
I0430 05:16:32.523917  5145 net.cpp:693] Ignoring source layer fake
I0430 05:21:28.725870  5145 solver.cpp:404]     Test net output #0: loss = 0.279895 (* 1 = 0.279895 loss)
I0430 05:21:29.038581  5145 solver.cpp:228] Iteration 165000, loss = 0.217717
I0430 05:21:29.038620  5145 solver.cpp:244]     Train net output #0: loss = 0.217717 (* 1 = 0.217717 loss)
I0430 05:21:29.038626  5145 sgd_solver.cpp:106] Iteration 165000, lr = 1e-24
I0430 05:22:19.557201  5145 solver.cpp:228] Iteration 165100, loss = 0.329091
I0430 05:22:19.557341  5145 solver.cpp:244]     Train net output #0: loss = 0.329091 (* 1 = 0.329091 loss)
I0430 05:22:19.557348  5145 sgd_solver.cpp:106] Iteration 165100, lr = 1e-24
I0430 05:23:10.076154  5145 solver.cpp:228] Iteration 165200, loss = 0.221903
I0430 05:23:10.076305  5145 solver.cpp:244]     Train net output #0: loss = 0.221903 (* 1 = 0.221903 loss)
I0430 05:23:10.076313  5145 sgd_solver.cpp:106] Iteration 165200, lr = 1e-24
I0430 05:24:02.157240  5145 solver.cpp:228] Iteration 165300, loss = 0.111269
I0430 05:24:02.157408  5145 solver.cpp:244]     Train net output #0: loss = 0.111269 (* 1 = 0.111269 loss)
I0430 05:24:02.157415  5145 sgd_solver.cpp:106] Iteration 165300, lr = 1e-24
I0430 05:24:52.540169  5145 solver.cpp:228] Iteration 165400, loss = 0.103809
I0430 05:24:52.540323  5145 solver.cpp:244]     Train net output #0: loss = 0.103809 (* 1 = 0.103809 loss)
I0430 05:24:52.540329  5145 sgd_solver.cpp:106] Iteration 165400, lr = 1e-24
I0430 05:25:43.088205  5145 solver.cpp:228] Iteration 165500, loss = 0.278617
I0430 05:25:43.088371  5145 solver.cpp:244]     Train net output #0: loss = 0.278617 (* 1 = 0.278617 loss)
I0430 05:25:43.088377  5145 sgd_solver.cpp:106] Iteration 165500, lr = 1e-24
I0430 05:26:34.901984  5145 solver.cpp:228] Iteration 165600, loss = 0.301067
I0430 05:26:34.902199  5145 solver.cpp:244]     Train net output #0: loss = 0.301067 (* 1 = 0.301067 loss)
I0430 05:26:34.902207  5145 sgd_solver.cpp:106] Iteration 165600, lr = 1e-24
I0430 05:27:25.446241  5145 solver.cpp:228] Iteration 165700, loss = 0.271381
I0430 05:27:25.446404  5145 solver.cpp:244]     Train net output #0: loss = 0.271381 (* 1 = 0.271381 loss)
I0430 05:27:25.446413  5145 sgd_solver.cpp:106] Iteration 165700, lr = 1e-24
I0430 05:28:15.697815  5145 solver.cpp:228] Iteration 165800, loss = 0.213666
I0430 05:28:15.697979  5145 solver.cpp:244]     Train net output #0: loss = 0.213666 (* 1 = 0.213666 loss)
I0430 05:28:15.697988  5145 sgd_solver.cpp:106] Iteration 165800, lr = 1e-24
I0430 05:29:07.323339  5145 solver.cpp:228] Iteration 165900, loss = 0.192285
I0430 05:29:07.323508  5145 solver.cpp:244]     Train net output #0: loss = 0.192285 (* 1 = 0.192285 loss)
I0430 05:29:07.323515  5145 sgd_solver.cpp:106] Iteration 165900, lr = 1e-24
I0430 05:29:57.458600  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_166000.caffemodel
I0430 05:30:14.062134  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_166000.solverstate
I0430 05:30:14.253689  5145 solver.cpp:337] Iteration 166000, Testing net (#0)
I0430 05:30:14.253844  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 05:30:14.253849  5145 net.cpp:693] Ignoring source layer visualize
I0430 05:30:14.253852  5145 net.cpp:693] Ignoring source layer fake
I0430 05:35:10.124291  5145 solver.cpp:404]     Test net output #0: loss = 0.28466 (* 1 = 0.28466 loss)
I0430 05:35:10.436178  5145 solver.cpp:228] Iteration 166000, loss = 0.203447
I0430 05:35:10.436197  5145 solver.cpp:244]     Train net output #0: loss = 0.203447 (* 1 = 0.203447 loss)
I0430 05:35:10.436219  5145 sgd_solver.cpp:106] Iteration 166000, lr = 1e-24
I0430 05:36:02.523772  5145 solver.cpp:228] Iteration 166100, loss = 0.401149
I0430 05:36:02.523926  5145 solver.cpp:244]     Train net output #0: loss = 0.401149 (* 1 = 0.401149 loss)
I0430 05:36:02.523932  5145 sgd_solver.cpp:106] Iteration 166100, lr = 1e-24
I0430 05:36:52.917512  5145 solver.cpp:228] Iteration 166200, loss = 0.133819
I0430 05:36:52.917670  5145 solver.cpp:244]     Train net output #0: loss = 0.133819 (* 1 = 0.133819 loss)
I0430 05:36:52.917677  5145 sgd_solver.cpp:106] Iteration 166200, lr = 1e-24
I0430 05:37:43.551460  5145 solver.cpp:228] Iteration 166300, loss = 0.284103
I0430 05:37:43.551611  5145 solver.cpp:244]     Train net output #0: loss = 0.284103 (* 1 = 0.284103 loss)
I0430 05:37:43.551618  5145 sgd_solver.cpp:106] Iteration 166300, lr = 1e-24
I0430 05:38:35.915423  5145 solver.cpp:228] Iteration 166400, loss = 0.358411
I0430 05:38:35.915570  5145 solver.cpp:244]     Train net output #0: loss = 0.358411 (* 1 = 0.358411 loss)
I0430 05:38:35.915576  5145 sgd_solver.cpp:106] Iteration 166400, lr = 1e-24
I0430 05:39:26.430956  5145 solver.cpp:228] Iteration 166500, loss = 0.334868
I0430 05:39:26.431107  5145 solver.cpp:244]     Train net output #0: loss = 0.334868 (* 1 = 0.334868 loss)
I0430 05:39:26.431114  5145 sgd_solver.cpp:106] Iteration 166500, lr = 1e-24
I0430 05:40:17.028106  5145 solver.cpp:228] Iteration 166600, loss = 0.212713
I0430 05:40:17.028311  5145 solver.cpp:244]     Train net output #0: loss = 0.212713 (* 1 = 0.212713 loss)
I0430 05:40:17.028329  5145 sgd_solver.cpp:106] Iteration 166600, lr = 1e-24
I0430 05:41:07.492754  5145 solver.cpp:228] Iteration 166700, loss = 0.360727
I0430 05:41:07.492936  5145 solver.cpp:244]     Train net output #0: loss = 0.360727 (* 1 = 0.360727 loss)
I0430 05:41:07.492944  5145 sgd_solver.cpp:106] Iteration 166700, lr = 1e-24
I0430 05:41:59.478951  5145 solver.cpp:228] Iteration 166800, loss = 0.297085
I0430 05:41:59.479120  5145 solver.cpp:244]     Train net output #0: loss = 0.297085 (* 1 = 0.297085 loss)
I0430 05:41:59.479127  5145 sgd_solver.cpp:106] Iteration 166800, lr = 1e-24
I0430 05:42:49.755450  5145 solver.cpp:228] Iteration 166900, loss = 0.283074
I0430 05:42:49.755607  5145 solver.cpp:244]     Train net output #0: loss = 0.283074 (* 1 = 0.283074 loss)
I0430 05:42:49.755614  5145 sgd_solver.cpp:106] Iteration 166900, lr = 1e-24
I0430 05:43:39.854298  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_167000.caffemodel
I0430 05:44:02.049720  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_167000.solverstate
I0430 05:44:02.251644  5145 solver.cpp:337] Iteration 167000, Testing net (#0)
I0430 05:44:02.251744  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 05:44:02.251766  5145 net.cpp:693] Ignoring source layer visualize
I0430 05:44:02.251768  5145 net.cpp:693] Ignoring source layer fake
I0430 05:48:58.871994  5145 solver.cpp:404]     Test net output #0: loss = 0.290983 (* 1 = 0.290983 loss)
I0430 05:48:59.183818  5145 solver.cpp:228] Iteration 167000, loss = 0.271681
I0430 05:48:59.183858  5145 solver.cpp:244]     Train net output #0: loss = 0.271681 (* 1 = 0.271681 loss)
I0430 05:48:59.183866  5145 sgd_solver.cpp:106] Iteration 167000, lr = 1e-24
I0430 05:49:51.604393  5145 solver.cpp:228] Iteration 167100, loss = 0.335454
I0430 05:49:51.604552  5145 solver.cpp:244]     Train net output #0: loss = 0.335454 (* 1 = 0.335454 loss)
I0430 05:49:51.604562  5145 sgd_solver.cpp:106] Iteration 167100, lr = 1e-24
I0430 05:50:42.082450  5145 solver.cpp:228] Iteration 167200, loss = 0.470318
I0430 05:50:42.082631  5145 solver.cpp:244]     Train net output #0: loss = 0.470318 (* 1 = 0.470318 loss)
I0430 05:50:42.082638  5145 sgd_solver.cpp:106] Iteration 167200, lr = 1e-24
I0430 05:51:32.655184  5145 solver.cpp:228] Iteration 167300, loss = 0.424322
I0430 05:51:32.655349  5145 solver.cpp:244]     Train net output #0: loss = 0.424322 (* 1 = 0.424322 loss)
I0430 05:51:32.655364  5145 sgd_solver.cpp:106] Iteration 167300, lr = 1e-24
I0430 05:52:23.300150  5145 solver.cpp:228] Iteration 167400, loss = 0.340431
I0430 05:52:23.300302  5145 solver.cpp:244]     Train net output #0: loss = 0.340431 (* 1 = 0.340431 loss)
I0430 05:52:23.300309  5145 sgd_solver.cpp:106] Iteration 167400, lr = 1e-24
I0430 05:53:15.549741  5145 solver.cpp:228] Iteration 167500, loss = 0.177693
I0430 05:53:15.549885  5145 solver.cpp:244]     Train net output #0: loss = 0.177693 (* 1 = 0.177693 loss)
I0430 05:53:15.549893  5145 sgd_solver.cpp:106] Iteration 167500, lr = 1e-24
I0430 05:54:06.163578  5145 solver.cpp:228] Iteration 167600, loss = 0.315273
I0430 05:54:06.163739  5145 solver.cpp:244]     Train net output #0: loss = 0.315273 (* 1 = 0.315273 loss)
I0430 05:54:06.163746  5145 sgd_solver.cpp:106] Iteration 167600, lr = 1e-24
I0430 05:54:56.774446  5145 solver.cpp:228] Iteration 167700, loss = 0.233337
I0430 05:54:56.774667  5145 solver.cpp:244]     Train net output #0: loss = 0.233337 (* 1 = 0.233337 loss)
I0430 05:54:56.774683  5145 sgd_solver.cpp:106] Iteration 167700, lr = 1e-24
I0430 05:55:48.794826  5145 solver.cpp:228] Iteration 167800, loss = 0.202087
I0430 05:55:48.794970  5145 solver.cpp:244]     Train net output #0: loss = 0.202087 (* 1 = 0.202087 loss)
I0430 05:55:48.794975  5145 sgd_solver.cpp:106] Iteration 167800, lr = 1e-24
I0430 05:56:39.180483  5145 solver.cpp:228] Iteration 167900, loss = 0.292091
I0430 05:56:39.180649  5145 solver.cpp:244]     Train net output #0: loss = 0.292091 (* 1 = 0.292091 loss)
I0430 05:56:39.180655  5145 sgd_solver.cpp:106] Iteration 167900, lr = 1e-24
I0430 05:57:29.163061  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_168000.caffemodel
I0430 05:57:39.078721  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_168000.solverstate
I0430 05:57:39.263568  5145 solver.cpp:337] Iteration 168000, Testing net (#0)
I0430 05:57:39.263667  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 05:57:39.263672  5145 net.cpp:693] Ignoring source layer visualize
I0430 05:57:39.263674  5145 net.cpp:693] Ignoring source layer fake
I0430 06:02:35.142838  5145 solver.cpp:404]     Test net output #0: loss = 0.286461 (* 1 = 0.286461 loss)
I0430 06:02:35.456151  5145 solver.cpp:228] Iteration 168000, loss = 0.164855
I0430 06:02:35.456190  5145 solver.cpp:244]     Train net output #0: loss = 0.164855 (* 1 = 0.164855 loss)
I0430 06:02:35.456197  5145 sgd_solver.cpp:106] Iteration 168000, lr = 1e-24
I0430 06:03:27.667847  5145 solver.cpp:228] Iteration 168100, loss = 0.215306
I0430 06:03:27.668009  5145 solver.cpp:244]     Train net output #0: loss = 0.215306 (* 1 = 0.215306 loss)
I0430 06:03:27.668016  5145 sgd_solver.cpp:106] Iteration 168100, lr = 1e-24
I0430 06:04:18.126852  5145 solver.cpp:228] Iteration 168200, loss = 0.177883
I0430 06:04:18.126996  5145 solver.cpp:244]     Train net output #0: loss = 0.177883 (* 1 = 0.177883 loss)
I0430 06:04:18.127002  5145 sgd_solver.cpp:106] Iteration 168200, lr = 1e-24
I0430 06:05:08.736124  5145 solver.cpp:228] Iteration 168300, loss = 0.211217
I0430 06:05:08.736276  5145 solver.cpp:244]     Train net output #0: loss = 0.211217 (* 1 = 0.211217 loss)
I0430 06:05:08.736284  5145 sgd_solver.cpp:106] Iteration 168300, lr = 1e-24
I0430 06:05:59.296316  5145 solver.cpp:228] Iteration 168400, loss = 0.265985
I0430 06:05:59.296478  5145 solver.cpp:244]     Train net output #0: loss = 0.265985 (* 1 = 0.265985 loss)
I0430 06:05:59.296484  5145 sgd_solver.cpp:106] Iteration 168400, lr = 1e-24
I0430 06:06:51.372663  5145 solver.cpp:228] Iteration 168500, loss = 0.270917
I0430 06:06:51.372839  5145 solver.cpp:244]     Train net output #0: loss = 0.270917 (* 1 = 0.270917 loss)
I0430 06:06:51.372846  5145 sgd_solver.cpp:106] Iteration 168500, lr = 1e-24
I0430 06:07:41.999500  5145 solver.cpp:228] Iteration 168600, loss = 0.276349
I0430 06:07:41.999652  5145 solver.cpp:244]     Train net output #0: loss = 0.276349 (* 1 = 0.276349 loss)
I0430 06:07:41.999660  5145 sgd_solver.cpp:106] Iteration 168600, lr = 1e-24
I0430 06:08:32.478058  5145 solver.cpp:228] Iteration 168700, loss = 0.160741
I0430 06:08:32.478202  5145 solver.cpp:244]     Train net output #0: loss = 0.160741 (* 1 = 0.160741 loss)
I0430 06:08:32.478209  5145 sgd_solver.cpp:106] Iteration 168700, lr = 1e-24
I0430 06:09:24.042275  5145 solver.cpp:228] Iteration 168800, loss = 0.198149
I0430 06:09:24.042439  5145 solver.cpp:244]     Train net output #0: loss = 0.198149 (* 1 = 0.198149 loss)
I0430 06:09:24.042446  5145 sgd_solver.cpp:106] Iteration 168800, lr = 1e-24
I0430 06:10:14.527389  5145 solver.cpp:228] Iteration 168900, loss = 0.260486
I0430 06:10:14.527550  5145 solver.cpp:244]     Train net output #0: loss = 0.260486 (* 1 = 0.260486 loss)
I0430 06:10:14.527557  5145 sgd_solver.cpp:106] Iteration 168900, lr = 1e-24
I0430 06:11:05.933454  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_169000.caffemodel
I0430 06:11:15.405076  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_169000.solverstate
I0430 06:11:15.643715  5145 solver.cpp:337] Iteration 169000, Testing net (#0)
I0430 06:11:15.643812  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 06:11:15.643818  5145 net.cpp:693] Ignoring source layer visualize
I0430 06:11:15.643821  5145 net.cpp:693] Ignoring source layer fake
I0430 06:16:12.444983  5145 solver.cpp:404]     Test net output #0: loss = 0.285211 (* 1 = 0.285211 loss)
I0430 06:16:12.758242  5145 solver.cpp:228] Iteration 169000, loss = 0.363374
I0430 06:16:12.758265  5145 solver.cpp:244]     Train net output #0: loss = 0.363374 (* 1 = 0.363374 loss)
I0430 06:16:12.758287  5145 sgd_solver.cpp:106] Iteration 169000, lr = 1e-24
I0430 06:17:03.307071  5145 solver.cpp:228] Iteration 169100, loss = 0.231496
I0430 06:17:03.307281  5145 solver.cpp:244]     Train net output #0: loss = 0.231496 (* 1 = 0.231496 loss)
I0430 06:17:03.307289  5145 sgd_solver.cpp:106] Iteration 169100, lr = 1e-24
I0430 06:17:53.718613  5145 solver.cpp:228] Iteration 169200, loss = 0.287082
I0430 06:17:53.718777  5145 solver.cpp:244]     Train net output #0: loss = 0.287082 (* 1 = 0.287082 loss)
I0430 06:17:53.718785  5145 sgd_solver.cpp:106] Iteration 169200, lr = 1e-24
I0430 06:18:45.632819  5145 solver.cpp:228] Iteration 169300, loss = 0.170951
I0430 06:18:45.632978  5145 solver.cpp:244]     Train net output #0: loss = 0.170951 (* 1 = 0.170951 loss)
I0430 06:18:45.632985  5145 sgd_solver.cpp:106] Iteration 169300, lr = 1e-24
I0430 06:19:36.093511  5145 solver.cpp:228] Iteration 169400, loss = 0.193436
I0430 06:19:36.093657  5145 solver.cpp:244]     Train net output #0: loss = 0.193436 (* 1 = 0.193436 loss)
I0430 06:19:36.093663  5145 sgd_solver.cpp:106] Iteration 169400, lr = 1e-24
I0430 06:20:26.747833  5145 solver.cpp:228] Iteration 169500, loss = 0.128165
I0430 06:20:26.747990  5145 solver.cpp:244]     Train net output #0: loss = 0.128165 (* 1 = 0.128165 loss)
I0430 06:20:26.747997  5145 sgd_solver.cpp:106] Iteration 169500, lr = 1e-24
I0430 06:21:18.982483  5145 solver.cpp:228] Iteration 169600, loss = 0.300479
I0430 06:21:18.982640  5145 solver.cpp:244]     Train net output #0: loss = 0.300479 (* 1 = 0.300479 loss)
I0430 06:21:18.982645  5145 sgd_solver.cpp:106] Iteration 169600, lr = 1e-24
I0430 06:22:09.572811  5145 solver.cpp:228] Iteration 169700, loss = 0.295101
I0430 06:22:09.573016  5145 solver.cpp:244]     Train net output #0: loss = 0.295101 (* 1 = 0.295101 loss)
I0430 06:22:09.573024  5145 sgd_solver.cpp:106] Iteration 169700, lr = 1e-24
I0430 06:23:00.015559  5145 solver.cpp:228] Iteration 169800, loss = 0.0883123
I0430 06:23:00.015729  5145 solver.cpp:244]     Train net output #0: loss = 0.0883123 (* 1 = 0.0883123 loss)
I0430 06:23:00.015738  5145 sgd_solver.cpp:106] Iteration 169800, lr = 1e-24
I0430 06:23:52.205080  5145 solver.cpp:228] Iteration 169900, loss = 0.227623
I0430 06:23:52.205257  5145 solver.cpp:244]     Train net output #0: loss = 0.227623 (* 1 = 0.227623 loss)
I0430 06:23:52.205265  5145 sgd_solver.cpp:106] Iteration 169900, lr = 1e-24
I0430 06:24:42.307606  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_170000.caffemodel
I0430 06:25:18.768833  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_170000.solverstate
I0430 06:25:18.972537  5145 solver.cpp:337] Iteration 170000, Testing net (#0)
I0430 06:25:18.972637  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 06:25:18.972643  5145 net.cpp:693] Ignoring source layer visualize
I0430 06:25:18.972646  5145 net.cpp:693] Ignoring source layer fake
I0430 06:30:12.750577  5145 solver.cpp:404]     Test net output #0: loss = 0.279689 (* 1 = 0.279689 loss)
I0430 06:30:13.064968  5145 solver.cpp:228] Iteration 170000, loss = 0.211491
I0430 06:30:13.064990  5145 solver.cpp:244]     Train net output #0: loss = 0.211491 (* 1 = 0.211491 loss)
I0430 06:30:13.065011  5145 sgd_solver.cpp:106] Iteration 170000, lr = 1e-24
I0430 06:31:03.141492  5145 solver.cpp:228] Iteration 170100, loss = 0.357244
I0430 06:31:03.141664  5145 solver.cpp:244]     Train net output #0: loss = 0.357244 (* 1 = 0.357244 loss)
I0430 06:31:03.141670  5145 sgd_solver.cpp:106] Iteration 170100, lr = 1e-24
I0430 06:31:55.133448  5145 solver.cpp:228] Iteration 170200, loss = 0.311546
I0430 06:31:55.133594  5145 solver.cpp:244]     Train net output #0: loss = 0.311546 (* 1 = 0.311546 loss)
I0430 06:31:55.133600  5145 sgd_solver.cpp:106] Iteration 170200, lr = 1e-24
I0430 06:32:45.223769  5145 solver.cpp:228] Iteration 170300, loss = 0.423293
I0430 06:32:45.223937  5145 solver.cpp:244]     Train net output #0: loss = 0.423293 (* 1 = 0.423293 loss)
I0430 06:32:45.223944  5145 sgd_solver.cpp:106] Iteration 170300, lr = 1e-24
I0430 06:33:35.318048  5145 solver.cpp:228] Iteration 170400, loss = 0.210907
I0430 06:33:35.318208  5145 solver.cpp:244]     Train net output #0: loss = 0.210907 (* 1 = 0.210907 loss)
I0430 06:33:35.318217  5145 sgd_solver.cpp:106] Iteration 170400, lr = 1e-24
I0430 06:34:25.407116  5145 solver.cpp:228] Iteration 170500, loss = 0.260593
I0430 06:34:25.407284  5145 solver.cpp:244]     Train net output #0: loss = 0.260593 (* 1 = 0.260593 loss)
I0430 06:34:25.407291  5145 sgd_solver.cpp:106] Iteration 170500, lr = 1e-24
I0430 06:35:17.359738  5145 solver.cpp:228] Iteration 170600, loss = 0.248621
I0430 06:35:17.359907  5145 solver.cpp:244]     Train net output #0: loss = 0.248621 (* 1 = 0.248621 loss)
I0430 06:35:17.359915  5145 sgd_solver.cpp:106] Iteration 170600, lr = 1e-24
I0430 06:36:07.452620  5145 solver.cpp:228] Iteration 170700, loss = 0.26347
I0430 06:36:07.452805  5145 solver.cpp:244]     Train net output #0: loss = 0.26347 (* 1 = 0.26347 loss)
I0430 06:36:07.452812  5145 sgd_solver.cpp:106] Iteration 170700, lr = 1e-24
I0430 06:36:57.545810  5145 solver.cpp:228] Iteration 170800, loss = 0.230554
I0430 06:36:57.545984  5145 solver.cpp:244]     Train net output #0: loss = 0.230554 (* 1 = 0.230554 loss)
I0430 06:36:57.545991  5145 sgd_solver.cpp:106] Iteration 170800, lr = 1e-24
I0430 06:37:49.440419  5145 solver.cpp:228] Iteration 170900, loss = 0.18182
I0430 06:37:49.440588  5145 solver.cpp:244]     Train net output #0: loss = 0.18182 (* 1 = 0.18182 loss)
I0430 06:37:49.440595  5145 sgd_solver.cpp:106] Iteration 170900, lr = 1e-24
I0430 06:38:39.201637  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_171000.caffemodel
I0430 06:38:58.659153  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_171000.solverstate
I0430 06:38:58.849997  5145 solver.cpp:337] Iteration 171000, Testing net (#0)
I0430 06:38:58.850080  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 06:38:58.850085  5145 net.cpp:693] Ignoring source layer visualize
I0430 06:38:58.850086  5145 net.cpp:693] Ignoring source layer fake
I0430 06:43:54.276087  5145 solver.cpp:404]     Test net output #0: loss = 0.286449 (* 1 = 0.286449 loss)
I0430 06:43:54.589926  5145 solver.cpp:228] Iteration 171000, loss = 0.219814
I0430 06:43:54.589949  5145 solver.cpp:244]     Train net output #0: loss = 0.219814 (* 1 = 0.219814 loss)
I0430 06:43:54.589970  5145 sgd_solver.cpp:106] Iteration 171000, lr = 1e-24
I0430 06:44:44.646463  5145 solver.cpp:228] Iteration 171100, loss = 0.0683517
I0430 06:44:44.646625  5145 solver.cpp:244]     Train net output #0: loss = 0.0683517 (* 1 = 0.0683517 loss)
I0430 06:44:44.646633  5145 sgd_solver.cpp:106] Iteration 171100, lr = 1e-24
I0430 06:45:36.562814  5145 solver.cpp:228] Iteration 171200, loss = 0.253601
I0430 06:45:36.562985  5145 solver.cpp:244]     Train net output #0: loss = 0.253601 (* 1 = 0.253601 loss)
I0430 06:45:36.562994  5145 sgd_solver.cpp:106] Iteration 171200, lr = 1e-24
I0430 06:46:26.649935  5145 solver.cpp:228] Iteration 171300, loss = 0.25296
I0430 06:46:26.650096  5145 solver.cpp:244]     Train net output #0: loss = 0.25296 (* 1 = 0.25296 loss)
I0430 06:46:26.650104  5145 sgd_solver.cpp:106] Iteration 171300, lr = 1e-24
I0430 06:47:16.738648  5145 solver.cpp:228] Iteration 171400, loss = 0.196385
I0430 06:47:16.738807  5145 solver.cpp:244]     Train net output #0: loss = 0.196385 (* 1 = 0.196385 loss)
I0430 06:47:16.738826  5145 sgd_solver.cpp:106] Iteration 171400, lr = 1e-24
I0430 06:48:06.833827  5145 solver.cpp:228] Iteration 171500, loss = 0.230747
I0430 06:48:06.833978  5145 solver.cpp:244]     Train net output #0: loss = 0.230747 (* 1 = 0.230747 loss)
I0430 06:48:06.833986  5145 sgd_solver.cpp:106] Iteration 171500, lr = 1e-24
I0430 06:48:58.768590  5145 solver.cpp:228] Iteration 171600, loss = 0.191514
I0430 06:48:58.768787  5145 solver.cpp:244]     Train net output #0: loss = 0.191514 (* 1 = 0.191514 loss)
I0430 06:48:58.768796  5145 sgd_solver.cpp:106] Iteration 171600, lr = 1e-24
I0430 06:49:48.861115  5145 solver.cpp:228] Iteration 171700, loss = 0.180396
I0430 06:49:48.861275  5145 solver.cpp:244]     Train net output #0: loss = 0.180396 (* 1 = 0.180396 loss)
I0430 06:49:48.861281  5145 sgd_solver.cpp:106] Iteration 171700, lr = 1e-24
I0430 06:50:38.954411  5145 solver.cpp:228] Iteration 171800, loss = 0.217728
I0430 06:50:38.954586  5145 solver.cpp:244]     Train net output #0: loss = 0.217728 (* 1 = 0.217728 loss)
I0430 06:50:38.954596  5145 sgd_solver.cpp:106] Iteration 171800, lr = 1e-24
I0430 06:51:30.483110  5145 solver.cpp:228] Iteration 171900, loss = 0.378068
I0430 06:51:30.483280  5145 solver.cpp:244]     Train net output #0: loss = 0.378068 (* 1 = 0.378068 loss)
I0430 06:51:30.483289  5145 sgd_solver.cpp:106] Iteration 171900, lr = 1e-24
I0430 06:52:20.266222  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_172000.caffemodel
I0430 06:52:53.191009  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_172000.solverstate
I0430 06:52:53.394388  5145 solver.cpp:337] Iteration 172000, Testing net (#0)
I0430 06:52:53.394472  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 06:52:53.394475  5145 net.cpp:693] Ignoring source layer visualize
I0430 06:52:53.394477  5145 net.cpp:693] Ignoring source layer fake
I0430 06:57:48.789533  5145 solver.cpp:404]     Test net output #0: loss = 0.290254 (* 1 = 0.290254 loss)
I0430 06:57:49.102736  5145 solver.cpp:228] Iteration 172000, loss = 0.229422
I0430 06:57:49.102754  5145 solver.cpp:244]     Train net output #0: loss = 0.229422 (* 1 = 0.229422 loss)
I0430 06:57:49.102777  5145 sgd_solver.cpp:106] Iteration 172000, lr = 1e-24
I0430 06:58:40.529942  5145 solver.cpp:228] Iteration 172100, loss = 0.280666
I0430 06:58:40.530097  5145 solver.cpp:244]     Train net output #0: loss = 0.280666 (* 1 = 0.280666 loss)
I0430 06:58:40.530105  5145 sgd_solver.cpp:106] Iteration 172100, lr = 1e-24
I0430 06:59:30.604051  5145 solver.cpp:228] Iteration 172200, loss = 0.216497
I0430 06:59:30.604213  5145 solver.cpp:244]     Train net output #0: loss = 0.216497 (* 1 = 0.216497 loss)
I0430 06:59:30.604221  5145 sgd_solver.cpp:106] Iteration 172200, lr = 1e-24
I0430 07:00:20.696336  5145 solver.cpp:228] Iteration 172300, loss = 0.284988
I0430 07:00:20.696492  5145 solver.cpp:244]     Train net output #0: loss = 0.284988 (* 1 = 0.284988 loss)
I0430 07:00:20.696499  5145 sgd_solver.cpp:106] Iteration 172300, lr = 1e-24
I0430 07:01:12.507853  5145 solver.cpp:228] Iteration 172400, loss = 0.146319
I0430 07:01:12.508018  5145 solver.cpp:244]     Train net output #0: loss = 0.146319 (* 1 = 0.146319 loss)
I0430 07:01:12.508024  5145 sgd_solver.cpp:106] Iteration 172400, lr = 1e-24
I0430 07:02:02.582187  5145 solver.cpp:228] Iteration 172500, loss = 0.279724
I0430 07:02:02.582315  5145 solver.cpp:244]     Train net output #0: loss = 0.279724 (* 1 = 0.279724 loss)
I0430 07:02:02.582321  5145 sgd_solver.cpp:106] Iteration 172500, lr = 1e-25
I0430 07:02:52.661927  5145 solver.cpp:228] Iteration 172600, loss = 0.390762
I0430 07:02:52.662094  5145 solver.cpp:244]     Train net output #0: loss = 0.390762 (* 1 = 0.390762 loss)
I0430 07:02:52.662102  5145 sgd_solver.cpp:106] Iteration 172600, lr = 1e-25
I0430 07:03:44.566874  5145 solver.cpp:228] Iteration 172700, loss = 0.36267
I0430 07:03:44.567051  5145 solver.cpp:244]     Train net output #0: loss = 0.36267 (* 1 = 0.36267 loss)
I0430 07:03:44.567059  5145 sgd_solver.cpp:106] Iteration 172700, lr = 1e-25
I0430 07:04:34.640250  5145 solver.cpp:228] Iteration 172800, loss = 0.125201
I0430 07:04:34.640417  5145 solver.cpp:244]     Train net output #0: loss = 0.125201 (* 1 = 0.125201 loss)
I0430 07:04:34.640430  5145 sgd_solver.cpp:106] Iteration 172800, lr = 1e-25
I0430 07:05:24.732276  5145 solver.cpp:228] Iteration 172900, loss = 0.328644
I0430 07:05:24.732440  5145 solver.cpp:244]     Train net output #0: loss = 0.328644 (* 1 = 0.328644 loss)
I0430 07:05:24.732447  5145 sgd_solver.cpp:106] Iteration 172900, lr = 1e-25
I0430 07:06:16.572269  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_173000.caffemodel
I0430 07:06:23.681038  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_173000.solverstate
I0430 07:06:23.951041  5145 solver.cpp:337] Iteration 173000, Testing net (#0)
I0430 07:06:23.951124  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 07:06:23.951128  5145 net.cpp:693] Ignoring source layer visualize
I0430 07:06:23.951129  5145 net.cpp:693] Ignoring source layer fake
I0430 07:11:20.008370  5145 solver.cpp:404]     Test net output #0: loss = 0.286111 (* 1 = 0.286111 loss)
I0430 07:11:20.320861  5145 solver.cpp:228] Iteration 173000, loss = 0.297197
I0430 07:11:20.320878  5145 solver.cpp:244]     Train net output #0: loss = 0.297197 (* 1 = 0.297197 loss)
I0430 07:11:20.320899  5145 sgd_solver.cpp:106] Iteration 173000, lr = 1e-25
I0430 07:12:10.401376  5145 solver.cpp:228] Iteration 173100, loss = 0.248895
I0430 07:12:10.401546  5145 solver.cpp:244]     Train net output #0: loss = 0.248895 (* 1 = 0.248895 loss)
I0430 07:12:10.401552  5145 sgd_solver.cpp:106] Iteration 173100, lr = 1e-25
I0430 07:13:00.495918  5145 solver.cpp:228] Iteration 173200, loss = 0.138783
I0430 07:13:00.496094  5145 solver.cpp:244]     Train net output #0: loss = 0.138783 (* 1 = 0.138783 loss)
I0430 07:13:00.496101  5145 sgd_solver.cpp:106] Iteration 173200, lr = 1e-25
I0430 07:13:50.590010  5145 solver.cpp:228] Iteration 173300, loss = 0.29212
I0430 07:13:50.590162  5145 solver.cpp:244]     Train net output #0: loss = 0.29212 (* 1 = 0.29212 loss)
I0430 07:13:50.590170  5145 sgd_solver.cpp:106] Iteration 173300, lr = 1e-25
I0430 07:14:42.487725  5145 solver.cpp:228] Iteration 173400, loss = 0.406034
I0430 07:14:42.487869  5145 solver.cpp:244]     Train net output #0: loss = 0.406034 (* 1 = 0.406034 loss)
I0430 07:14:42.487875  5145 sgd_solver.cpp:106] Iteration 173400, lr = 1e-25
I0430 07:15:32.576685  5145 solver.cpp:228] Iteration 173500, loss = 0.367373
I0430 07:15:32.576825  5145 solver.cpp:244]     Train net output #0: loss = 0.367373 (* 1 = 0.367373 loss)
I0430 07:15:32.576833  5145 sgd_solver.cpp:106] Iteration 173500, lr = 1e-25
I0430 07:16:22.673466  5145 solver.cpp:228] Iteration 173600, loss = 0.290055
I0430 07:16:22.673627  5145 solver.cpp:244]     Train net output #0: loss = 0.290055 (* 1 = 0.290055 loss)
I0430 07:16:22.673635  5145 sgd_solver.cpp:106] Iteration 173600, lr = 1e-25
I0430 07:17:14.967913  5145 solver.cpp:228] Iteration 173700, loss = 0.214176
I0430 07:17:14.968073  5145 solver.cpp:244]     Train net output #0: loss = 0.214176 (* 1 = 0.214176 loss)
I0430 07:17:14.968080  5145 sgd_solver.cpp:106] Iteration 173700, lr = 1e-25
I0430 07:18:05.060144  5145 solver.cpp:228] Iteration 173800, loss = 0.245332
I0430 07:18:05.060290  5145 solver.cpp:244]     Train net output #0: loss = 0.245332 (* 1 = 0.245332 loss)
I0430 07:18:05.060297  5145 sgd_solver.cpp:106] Iteration 173800, lr = 1e-25
I0430 07:18:55.133417  5145 solver.cpp:228] Iteration 173900, loss = 0.309325
I0430 07:18:55.133571  5145 solver.cpp:244]     Train net output #0: loss = 0.309325 (* 1 = 0.309325 loss)
I0430 07:18:55.133577  5145 sgd_solver.cpp:106] Iteration 173900, lr = 1e-25
I0430 07:19:46.672466  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_174000.caffemodel
I0430 07:20:14.445245  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_174000.solverstate
I0430 07:20:14.638788  5145 solver.cpp:337] Iteration 174000, Testing net (#0)
I0430 07:20:14.638875  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 07:20:14.638893  5145 net.cpp:693] Ignoring source layer visualize
I0430 07:20:14.638895  5145 net.cpp:693] Ignoring source layer fake
I0430 07:25:08.788192  5145 solver.cpp:404]     Test net output #0: loss = 0.284379 (* 1 = 0.284379 loss)
I0430 07:25:09.100237  5145 solver.cpp:228] Iteration 174000, loss = 0.286867
I0430 07:25:09.100260  5145 solver.cpp:244]     Train net output #0: loss = 0.286867 (* 1 = 0.286867 loss)
I0430 07:25:09.100282  5145 sgd_solver.cpp:106] Iteration 174000, lr = 1e-25
I0430 07:25:59.187000  5145 solver.cpp:228] Iteration 174100, loss = 0.187758
I0430 07:25:59.187131  5145 solver.cpp:244]     Train net output #0: loss = 0.187758 (* 1 = 0.187758 loss)
I0430 07:25:59.187139  5145 sgd_solver.cpp:106] Iteration 174100, lr = 1e-25
I0430 07:26:49.279712  5145 solver.cpp:228] Iteration 174200, loss = 0.328222
I0430 07:26:49.279858  5145 solver.cpp:244]     Train net output #0: loss = 0.328222 (* 1 = 0.328222 loss)
I0430 07:26:49.279865  5145 sgd_solver.cpp:106] Iteration 174200, lr = 1e-25
I0430 07:27:39.351346  5145 solver.cpp:228] Iteration 174300, loss = 0.189761
I0430 07:27:39.351501  5145 solver.cpp:244]     Train net output #0: loss = 0.189761 (* 1 = 0.189761 loss)
I0430 07:27:39.351508  5145 sgd_solver.cpp:106] Iteration 174300, lr = 1e-25
I0430 07:28:31.205734  5145 solver.cpp:228] Iteration 174400, loss = 0.248246
I0430 07:28:31.205911  5145 solver.cpp:244]     Train net output #0: loss = 0.248246 (* 1 = 0.248246 loss)
I0430 07:28:31.205919  5145 sgd_solver.cpp:106] Iteration 174400, lr = 1e-25
I0430 07:29:21.298761  5145 solver.cpp:228] Iteration 174500, loss = 0.326372
I0430 07:29:21.298938  5145 solver.cpp:244]     Train net output #0: loss = 0.326372 (* 1 = 0.326372 loss)
I0430 07:29:21.298944  5145 sgd_solver.cpp:106] Iteration 174500, lr = 1e-25
I0430 07:30:11.369185  5145 solver.cpp:228] Iteration 174600, loss = 0.0704523
I0430 07:30:11.369423  5145 solver.cpp:244]     Train net output #0: loss = 0.0704523 (* 1 = 0.0704523 loss)
I0430 07:30:11.369451  5145 sgd_solver.cpp:106] Iteration 174600, lr = 1e-25
I0430 07:31:03.039891  5145 solver.cpp:228] Iteration 174700, loss = 0.108551
I0430 07:31:03.040047  5145 solver.cpp:244]     Train net output #0: loss = 0.108551 (* 1 = 0.108551 loss)
I0430 07:31:03.040053  5145 sgd_solver.cpp:106] Iteration 174700, lr = 1e-25
I0430 07:31:53.130331  5145 solver.cpp:228] Iteration 174800, loss = 0.254656
I0430 07:31:53.130501  5145 solver.cpp:244]     Train net output #0: loss = 0.254656 (* 1 = 0.254656 loss)
I0430 07:31:53.130507  5145 sgd_solver.cpp:106] Iteration 174800, lr = 1e-25
I0430 07:32:43.204540  5145 solver.cpp:228] Iteration 174900, loss = 0.189423
I0430 07:32:43.204699  5145 solver.cpp:244]     Train net output #0: loss = 0.189423 (* 1 = 0.189423 loss)
I0430 07:32:43.204705  5145 sgd_solver.cpp:106] Iteration 174900, lr = 1e-25
I0430 07:33:34.225004  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_175000.caffemodel
I0430 07:34:15.555944  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_175000.solverstate
I0430 07:34:15.757403  5145 solver.cpp:337] Iteration 175000, Testing net (#0)
I0430 07:34:15.757508  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 07:34:15.757515  5145 net.cpp:693] Ignoring source layer visualize
I0430 07:34:15.757517  5145 net.cpp:693] Ignoring source layer fake
I0430 07:39:09.714390  5145 solver.cpp:404]     Test net output #0: loss = 0.280081 (* 1 = 0.280081 loss)
I0430 07:39:10.025950  5145 solver.cpp:228] Iteration 175000, loss = 0.252124
I0430 07:39:10.025969  5145 solver.cpp:244]     Train net output #0: loss = 0.252124 (* 1 = 0.252124 loss)
I0430 07:39:10.025990  5145 sgd_solver.cpp:106] Iteration 175000, lr = 1e-25
I0430 07:40:00.111063  5145 solver.cpp:228] Iteration 175100, loss = 0.224547
I0430 07:40:00.111214  5145 solver.cpp:244]     Train net output #0: loss = 0.224547 (* 1 = 0.224547 loss)
I0430 07:40:00.111222  5145 sgd_solver.cpp:106] Iteration 175100, lr = 1e-25
I0430 07:40:50.415326  5145 solver.cpp:228] Iteration 175200, loss = 0.25292
I0430 07:40:50.415490  5145 solver.cpp:244]     Train net output #0: loss = 0.25292 (* 1 = 0.25292 loss)
I0430 07:40:50.415496  5145 sgd_solver.cpp:106] Iteration 175200, lr = 1e-25
I0430 07:41:42.026464  5145 solver.cpp:228] Iteration 175300, loss = 0.201795
I0430 07:41:42.027235  5145 solver.cpp:244]     Train net output #0: loss = 0.201795 (* 1 = 0.201795 loss)
I0430 07:41:42.027240  5145 sgd_solver.cpp:106] Iteration 175300, lr = 1e-25
I0430 07:42:32.519706  5145 solver.cpp:228] Iteration 175400, loss = 0.355017
I0430 07:42:32.519894  5145 solver.cpp:244]     Train net output #0: loss = 0.355017 (* 1 = 0.355017 loss)
I0430 07:42:32.519901  5145 sgd_solver.cpp:106] Iteration 175400, lr = 1e-25
I0430 07:43:24.504367  5145 solver.cpp:228] Iteration 175500, loss = 0.284198
I0430 07:43:24.504540  5145 solver.cpp:244]     Train net output #0: loss = 0.284198 (* 1 = 0.284198 loss)
I0430 07:43:24.504549  5145 sgd_solver.cpp:106] Iteration 175500, lr = 1e-25
I0430 07:44:15.131470  5145 solver.cpp:228] Iteration 175600, loss = 0.211445
I0430 07:44:15.131629  5145 solver.cpp:244]     Train net output #0: loss = 0.211445 (* 1 = 0.211445 loss)
I0430 07:44:15.131635  5145 sgd_solver.cpp:106] Iteration 175600, lr = 1e-25
I0430 07:45:05.479800  5145 solver.cpp:228] Iteration 175700, loss = 0.270651
I0430 07:45:05.482017  5145 solver.cpp:244]     Train net output #0: loss = 0.270651 (* 1 = 0.270651 loss)
I0430 07:45:05.482038  5145 sgd_solver.cpp:106] Iteration 175700, lr = 1e-25
I0430 07:45:57.543233  5145 solver.cpp:228] Iteration 175800, loss = 0.347068
I0430 07:45:57.543407  5145 solver.cpp:244]     Train net output #0: loss = 0.347068 (* 1 = 0.347068 loss)
I0430 07:45:57.543413  5145 sgd_solver.cpp:106] Iteration 175800, lr = 1e-25
I0430 07:46:48.059857  5145 solver.cpp:228] Iteration 175900, loss = 0.236653
I0430 07:46:48.061089  5145 solver.cpp:244]     Train net output #0: loss = 0.236653 (* 1 = 0.236653 loss)
I0430 07:46:48.061097  5145 sgd_solver.cpp:106] Iteration 175900, lr = 1e-25
I0430 07:47:38.272203  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_176000.caffemodel
I0430 07:47:55.102671  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_176000.solverstate
I0430 07:47:55.304015  5145 solver.cpp:337] Iteration 176000, Testing net (#0)
I0430 07:47:55.304100  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 07:47:55.304103  5145 net.cpp:693] Ignoring source layer visualize
I0430 07:47:55.304105  5145 net.cpp:693] Ignoring source layer fake
I0430 07:52:51.241845  5145 solver.cpp:404]     Test net output #0: loss = 0.287456 (* 1 = 0.287456 loss)
I0430 07:52:51.555315  5145 solver.cpp:228] Iteration 176000, loss = 0.351874
I0430 07:52:51.555331  5145 solver.cpp:244]     Train net output #0: loss = 0.351874 (* 1 = 0.351874 loss)
I0430 07:52:51.555353  5145 sgd_solver.cpp:106] Iteration 176000, lr = 1e-25
I0430 07:53:43.858419  5145 solver.cpp:228] Iteration 176100, loss = 0.269424
I0430 07:53:43.859083  5145 solver.cpp:244]     Train net output #0: loss = 0.269424 (* 1 = 0.269424 loss)
I0430 07:53:43.859091  5145 sgd_solver.cpp:106] Iteration 176100, lr = 1e-25
I0430 07:54:34.350664  5145 solver.cpp:228] Iteration 176200, loss = 0.331884
I0430 07:54:34.350854  5145 solver.cpp:244]     Train net output #0: loss = 0.331884 (* 1 = 0.331884 loss)
I0430 07:54:34.350862  5145 sgd_solver.cpp:106] Iteration 176200, lr = 1e-25
I0430 07:55:24.857959  5145 solver.cpp:228] Iteration 176300, loss = 0.38209
I0430 07:55:24.858117  5145 solver.cpp:244]     Train net output #0: loss = 0.38209 (* 1 = 0.38209 loss)
I0430 07:55:24.858124  5145 sgd_solver.cpp:106] Iteration 176300, lr = 1e-25
I0430 07:56:15.369734  5145 solver.cpp:228] Iteration 176400, loss = 0.321421
I0430 07:56:15.369900  5145 solver.cpp:244]     Train net output #0: loss = 0.321421 (* 1 = 0.321421 loss)
I0430 07:56:15.369906  5145 sgd_solver.cpp:106] Iteration 176400, lr = 1e-25
I0430 07:57:07.624802  5145 solver.cpp:228] Iteration 176500, loss = 0.378378
I0430 07:57:07.624981  5145 solver.cpp:244]     Train net output #0: loss = 0.378378 (* 1 = 0.378378 loss)
I0430 07:57:07.624989  5145 sgd_solver.cpp:106] Iteration 176500, lr = 1e-25
I0430 07:57:58.152798  5145 solver.cpp:228] Iteration 176600, loss = 0.408692
I0430 07:57:58.152964  5145 solver.cpp:244]     Train net output #0: loss = 0.408692 (* 1 = 0.408692 loss)
I0430 07:57:58.152971  5145 sgd_solver.cpp:106] Iteration 176600, lr = 1e-25
I0430 07:58:48.696959  5145 solver.cpp:228] Iteration 176700, loss = 0.196446
I0430 07:58:48.697134  5145 solver.cpp:244]     Train net output #0: loss = 0.196446 (* 1 = 0.196446 loss)
I0430 07:58:48.697139  5145 sgd_solver.cpp:106] Iteration 176700, lr = 1e-25
I0430 07:59:40.806659  5145 solver.cpp:228] Iteration 176800, loss = 0.291204
I0430 07:59:40.808209  5145 solver.cpp:244]     Train net output #0: loss = 0.291204 (* 1 = 0.291204 loss)
I0430 07:59:40.808230  5145 sgd_solver.cpp:106] Iteration 176800, lr = 1e-25
I0430 08:00:31.293766  5145 solver.cpp:228] Iteration 176900, loss = 0.224511
I0430 08:00:31.293913  5145 solver.cpp:244]     Train net output #0: loss = 0.224511 (* 1 = 0.224511 loss)
I0430 08:00:31.293920  5145 sgd_solver.cpp:106] Iteration 176900, lr = 1e-25
I0430 08:01:21.530159  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_177000.caffemodel
I0430 08:01:26.188285  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_177000.solverstate
I0430 08:01:26.377472  5145 solver.cpp:337] Iteration 177000, Testing net (#0)
I0430 08:01:26.377571  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 08:01:26.377576  5145 net.cpp:693] Ignoring source layer visualize
I0430 08:01:26.377579  5145 net.cpp:693] Ignoring source layer fake
I0430 08:06:21.941507  5145 solver.cpp:404]     Test net output #0: loss = 0.289801 (* 1 = 0.289801 loss)
I0430 08:06:22.252694  5145 solver.cpp:228] Iteration 177000, loss = 0.283352
I0430 08:06:22.252712  5145 solver.cpp:244]     Train net output #0: loss = 0.283352 (* 1 = 0.283352 loss)
I0430 08:06:22.252733  5145 sgd_solver.cpp:106] Iteration 177000, lr = 1e-25
I0430 08:07:12.734199  5145 solver.cpp:228] Iteration 177100, loss = 0.230216
I0430 08:07:12.734360  5145 solver.cpp:244]     Train net output #0: loss = 0.230216 (* 1 = 0.230216 loss)
I0430 08:07:12.734367  5145 sgd_solver.cpp:106] Iteration 177100, lr = 1e-25
I0430 08:08:04.907721  5145 solver.cpp:228] Iteration 177200, loss = 0.183312
I0430 08:08:04.907876  5145 solver.cpp:244]     Train net output #0: loss = 0.183312 (* 1 = 0.183312 loss)
I0430 08:08:04.907882  5145 sgd_solver.cpp:106] Iteration 177200, lr = 1e-25
I0430 08:08:55.381314  5145 solver.cpp:228] Iteration 177300, loss = 0.268237
I0430 08:08:55.381482  5145 solver.cpp:244]     Train net output #0: loss = 0.268237 (* 1 = 0.268237 loss)
I0430 08:08:55.381489  5145 sgd_solver.cpp:106] Iteration 177300, lr = 1e-25
I0430 08:09:45.896932  5145 solver.cpp:228] Iteration 177400, loss = 0.212054
I0430 08:09:45.897089  5145 solver.cpp:244]     Train net output #0: loss = 0.212054 (* 1 = 0.212054 loss)
I0430 08:09:45.897095  5145 sgd_solver.cpp:106] Iteration 177400, lr = 1e-25
I0430 08:10:38.070353  5145 solver.cpp:228] Iteration 177500, loss = 0.202923
I0430 08:10:38.070511  5145 solver.cpp:244]     Train net output #0: loss = 0.202923 (* 1 = 0.202923 loss)
I0430 08:10:38.070518  5145 sgd_solver.cpp:106] Iteration 177500, lr = 1e-25
I0430 08:11:28.670763  5145 solver.cpp:228] Iteration 177600, loss = 0.402317
I0430 08:11:28.671130  5145 solver.cpp:244]     Train net output #0: loss = 0.402317 (* 1 = 0.402317 loss)
I0430 08:11:28.671139  5145 sgd_solver.cpp:106] Iteration 177600, lr = 1e-25
I0430 08:12:19.094645  5145 solver.cpp:228] Iteration 177700, loss = 0.304004
I0430 08:12:19.094811  5145 solver.cpp:244]     Train net output #0: loss = 0.304004 (* 1 = 0.304004 loss)
I0430 08:12:19.094818  5145 sgd_solver.cpp:106] Iteration 177700, lr = 1e-25
I0430 08:13:11.152534  5145 solver.cpp:228] Iteration 177800, loss = 0.242044
I0430 08:13:11.152721  5145 solver.cpp:244]     Train net output #0: loss = 0.242044 (* 1 = 0.242044 loss)
I0430 08:13:11.152729  5145 sgd_solver.cpp:106] Iteration 177800, lr = 1e-25
I0430 08:14:01.546751  5145 solver.cpp:228] Iteration 177900, loss = 0.20545
I0430 08:14:01.546911  5145 solver.cpp:244]     Train net output #0: loss = 0.20545 (* 1 = 0.20545 loss)
I0430 08:14:01.546917  5145 sgd_solver.cpp:106] Iteration 177900, lr = 1e-25
I0430 08:14:51.769461  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_178000.caffemodel
I0430 08:14:53.183984  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_178000.solverstate
I0430 08:14:53.382295  5145 solver.cpp:337] Iteration 178000, Testing net (#0)
I0430 08:14:53.382361  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 08:14:53.382364  5145 net.cpp:693] Ignoring source layer visualize
I0430 08:14:53.382366  5145 net.cpp:693] Ignoring source layer fake
I0430 08:19:49.600955  5145 solver.cpp:404]     Test net output #0: loss = 0.28592 (* 1 = 0.28592 loss)
I0430 08:19:49.911924  5145 solver.cpp:228] Iteration 178000, loss = 0.332298
I0430 08:19:49.911942  5145 solver.cpp:244]     Train net output #0: loss = 0.332298 (* 1 = 0.332298 loss)
I0430 08:19:49.911965  5145 sgd_solver.cpp:106] Iteration 178000, lr = 1e-25
I0430 08:20:41.678144  5145 solver.cpp:228] Iteration 178100, loss = 0.273035
I0430 08:20:41.678323  5145 solver.cpp:244]     Train net output #0: loss = 0.273035 (* 1 = 0.273035 loss)
I0430 08:20:41.678329  5145 sgd_solver.cpp:106] Iteration 178100, lr = 1e-25
I0430 08:21:32.120265  5145 solver.cpp:228] Iteration 178200, loss = 0.222602
I0430 08:21:32.120424  5145 solver.cpp:244]     Train net output #0: loss = 0.222602 (* 1 = 0.222602 loss)
I0430 08:21:32.120431  5145 sgd_solver.cpp:106] Iteration 178200, lr = 1e-25
I0430 08:22:22.600497  5145 solver.cpp:228] Iteration 178300, loss = 0.14014
I0430 08:22:22.600658  5145 solver.cpp:244]     Train net output #0: loss = 0.14014 (* 1 = 0.14014 loss)
I0430 08:22:22.600666  5145 sgd_solver.cpp:106] Iteration 178300, lr = 1e-25
I0430 08:23:14.393898  5145 solver.cpp:228] Iteration 178400, loss = 0.384052
I0430 08:23:14.394065  5145 solver.cpp:244]     Train net output #0: loss = 0.384052 (* 1 = 0.384052 loss)
I0430 08:23:14.394071  5145 sgd_solver.cpp:106] Iteration 178400, lr = 1e-25
I0430 08:24:05.001250  5145 solver.cpp:228] Iteration 178500, loss = 0.43439
I0430 08:24:05.001426  5145 solver.cpp:244]     Train net output #0: loss = 0.43439 (* 1 = 0.43439 loss)
I0430 08:24:05.001444  5145 sgd_solver.cpp:106] Iteration 178500, lr = 1e-25
I0430 08:24:57.115862  5145 solver.cpp:228] Iteration 178600, loss = 0.144954
I0430 08:24:57.116040  5145 solver.cpp:244]     Train net output #0: loss = 0.144954 (* 1 = 0.144954 loss)
I0430 08:24:57.116047  5145 sgd_solver.cpp:106] Iteration 178600, lr = 1e-25
I0430 08:25:47.568336  5145 solver.cpp:228] Iteration 178700, loss = 0.273383
I0430 08:25:47.568493  5145 solver.cpp:244]     Train net output #0: loss = 0.273383 (* 1 = 0.273383 loss)
I0430 08:25:47.568501  5145 sgd_solver.cpp:106] Iteration 178700, lr = 1e-25
I0430 08:26:38.020917  5145 solver.cpp:228] Iteration 178800, loss = 0.240061
I0430 08:26:38.021072  5145 solver.cpp:244]     Train net output #0: loss = 0.240061 (* 1 = 0.240061 loss)
I0430 08:26:38.021078  5145 sgd_solver.cpp:106] Iteration 178800, lr = 1e-25
I0430 08:27:30.166262  5145 solver.cpp:228] Iteration 178900, loss = 0.324368
I0430 08:27:30.166417  5145 solver.cpp:244]     Train net output #0: loss = 0.324368 (* 1 = 0.324368 loss)
I0430 08:27:30.166424  5145 sgd_solver.cpp:106] Iteration 178900, lr = 1e-25
I0430 08:28:20.353091  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_179000.caffemodel
I0430 08:28:56.892751  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_179000.solverstate
I0430 08:28:57.081727  5145 solver.cpp:337] Iteration 179000, Testing net (#0)
I0430 08:28:57.081825  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 08:28:57.081827  5145 net.cpp:693] Ignoring source layer visualize
I0430 08:28:57.081845  5145 net.cpp:693] Ignoring source layer fake
I0430 08:33:52.256726  5145 solver.cpp:404]     Test net output #0: loss = 0.283675 (* 1 = 0.283675 loss)
I0430 08:33:52.571439  5145 solver.cpp:228] Iteration 179000, loss = 0.323941
I0430 08:33:52.571456  5145 solver.cpp:244]     Train net output #0: loss = 0.323941 (* 1 = 0.323941 loss)
I0430 08:33:52.571478  5145 sgd_solver.cpp:106] Iteration 179000, lr = 1e-25
I0430 08:34:43.133680  5145 solver.cpp:228] Iteration 179100, loss = 0.216368
I0430 08:34:43.133826  5145 solver.cpp:244]     Train net output #0: loss = 0.216368 (* 1 = 0.216368 loss)
I0430 08:34:43.133832  5145 sgd_solver.cpp:106] Iteration 179100, lr = 1e-25
I0430 08:35:33.746054  5145 solver.cpp:228] Iteration 179200, loss = 0.339171
I0430 08:35:33.748317  5145 solver.cpp:244]     Train net output #0: loss = 0.339171 (* 1 = 0.339171 loss)
I0430 08:35:33.748323  5145 sgd_solver.cpp:106] Iteration 179200, lr = 1e-25
I0430 08:36:25.950386  5145 solver.cpp:228] Iteration 179300, loss = 0.30045
I0430 08:36:25.950579  5145 solver.cpp:244]     Train net output #0: loss = 0.30045 (* 1 = 0.30045 loss)
I0430 08:36:25.950587  5145 sgd_solver.cpp:106] Iteration 179300, lr = 1e-25
I0430 08:37:16.510586  5145 solver.cpp:228] Iteration 179400, loss = 0.273047
I0430 08:37:16.510751  5145 solver.cpp:244]     Train net output #0: loss = 0.273047 (* 1 = 0.273047 loss)
I0430 08:37:16.510757  5145 sgd_solver.cpp:106] Iteration 179400, lr = 1e-25
I0430 08:38:07.113418  5145 solver.cpp:228] Iteration 179500, loss = 0.316588
I0430 08:38:07.113581  5145 solver.cpp:244]     Train net output #0: loss = 0.316588 (* 1 = 0.316588 loss)
I0430 08:38:07.113589  5145 sgd_solver.cpp:106] Iteration 179500, lr = 1e-25
I0430 08:38:59.111734  5145 solver.cpp:228] Iteration 179600, loss = 0.243371
I0430 08:38:59.111901  5145 solver.cpp:244]     Train net output #0: loss = 0.243371 (* 1 = 0.243371 loss)
I0430 08:38:59.111908  5145 sgd_solver.cpp:106] Iteration 179600, lr = 1e-25
I0430 08:39:49.481911  5145 solver.cpp:228] Iteration 179700, loss = 0.388339
I0430 08:39:49.482064  5145 solver.cpp:244]     Train net output #0: loss = 0.388339 (* 1 = 0.388339 loss)
I0430 08:39:49.482070  5145 sgd_solver.cpp:106] Iteration 179700, lr = 1e-25
I0430 08:40:39.852136  5145 solver.cpp:228] Iteration 179800, loss = 0.204789
I0430 08:40:39.852299  5145 solver.cpp:244]     Train net output #0: loss = 0.204789 (* 1 = 0.204789 loss)
I0430 08:40:39.852306  5145 sgd_solver.cpp:106] Iteration 179800, lr = 1e-25
I0430 08:41:30.218168  5145 solver.cpp:228] Iteration 179900, loss = 0.498183
I0430 08:41:30.218328  5145 solver.cpp:244]     Train net output #0: loss = 0.498183 (* 1 = 0.498183 loss)
I0430 08:41:30.218335  5145 sgd_solver.cpp:106] Iteration 179900, lr = 1e-25
I0430 08:42:22.027863  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_180000.caffemodel
I0430 08:42:36.890791  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_180000.solverstate
I0430 08:42:37.076887  5145 solver.cpp:337] Iteration 180000, Testing net (#0)
I0430 08:42:37.076983  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 08:42:37.076989  5145 net.cpp:693] Ignoring source layer visualize
I0430 08:42:37.076992  5145 net.cpp:693] Ignoring source layer fake
I0430 08:47:32.818444  5145 solver.cpp:404]     Test net output #0: loss = 0.28042 (* 1 = 0.28042 loss)
I0430 08:47:33.131963  5145 solver.cpp:228] Iteration 180000, loss = 0.23436
I0430 08:47:33.131984  5145 solver.cpp:244]     Train net output #0: loss = 0.23436 (* 1 = 0.23436 loss)
I0430 08:47:33.132006  5145 sgd_solver.cpp:106] Iteration 180000, lr = 1e-26
I0430 08:48:23.697302  5145 solver.cpp:228] Iteration 180100, loss = 0.327971
I0430 08:48:23.697484  5145 solver.cpp:244]     Train net output #0: loss = 0.327971 (* 1 = 0.327971 loss)
I0430 08:48:23.697491  5145 sgd_solver.cpp:106] Iteration 180100, lr = 1e-26
I0430 08:49:14.240584  5145 solver.cpp:228] Iteration 180200, loss = 0.227662
I0430 08:49:14.240756  5145 solver.cpp:244]     Train net output #0: loss = 0.227662 (* 1 = 0.227662 loss)
I0430 08:49:14.240763  5145 sgd_solver.cpp:106] Iteration 180200, lr = 1e-26
I0430 08:50:06.324518  5145 solver.cpp:228] Iteration 180300, loss = 0.0897663
I0430 08:50:06.324672  5145 solver.cpp:244]     Train net output #0: loss = 0.0897663 (* 1 = 0.0897663 loss)
I0430 08:50:06.324679  5145 sgd_solver.cpp:106] Iteration 180300, lr = 1e-26
I0430 08:50:56.844199  5145 solver.cpp:228] Iteration 180400, loss = 0.235691
I0430 08:50:56.844353  5145 solver.cpp:244]     Train net output #0: loss = 0.235691 (* 1 = 0.235691 loss)
I0430 08:50:56.844360  5145 sgd_solver.cpp:106] Iteration 180400, lr = 1e-26
I0430 08:51:47.337164  5145 solver.cpp:228] Iteration 180500, loss = 0.269362
I0430 08:51:47.337321  5145 solver.cpp:244]     Train net output #0: loss = 0.269362 (* 1 = 0.269362 loss)
I0430 08:51:47.337327  5145 sgd_solver.cpp:106] Iteration 180500, lr = 1e-26
I0430 08:52:39.443557  5145 solver.cpp:228] Iteration 180600, loss = 0.273277
I0430 08:52:39.443717  5145 solver.cpp:244]     Train net output #0: loss = 0.273277 (* 1 = 0.273277 loss)
I0430 08:52:39.443724  5145 sgd_solver.cpp:106] Iteration 180600, lr = 1e-26
I0430 08:53:29.792742  5145 solver.cpp:228] Iteration 180700, loss = 0.243682
I0430 08:53:29.792904  5145 solver.cpp:244]     Train net output #0: loss = 0.243682 (* 1 = 0.243682 loss)
I0430 08:53:29.792910  5145 sgd_solver.cpp:106] Iteration 180700, lr = 1e-26
I0430 08:54:20.295810  5145 solver.cpp:228] Iteration 180800, loss = 0.255468
I0430 08:54:20.295969  5145 solver.cpp:244]     Train net output #0: loss = 0.255468 (* 1 = 0.255468 loss)
I0430 08:54:20.295975  5145 sgd_solver.cpp:106] Iteration 180800, lr = 1e-26
I0430 08:55:10.673233  5145 solver.cpp:228] Iteration 180900, loss = 0.231671
I0430 08:55:10.673384  5145 solver.cpp:244]     Train net output #0: loss = 0.231671 (* 1 = 0.231671 loss)
I0430 08:55:10.673391  5145 sgd_solver.cpp:106] Iteration 180900, lr = 1e-26
I0430 08:56:02.407379  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_181000.caffemodel
I0430 08:56:05.037165  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_181000.solverstate
I0430 08:56:05.222123  5145 solver.cpp:337] Iteration 181000, Testing net (#0)
I0430 08:56:05.222204  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 08:56:05.222208  5145 net.cpp:693] Ignoring source layer visualize
I0430 08:56:05.222209  5145 net.cpp:693] Ignoring source layer fake
I0430 09:01:01.329893  5145 solver.cpp:404]     Test net output #0: loss = 0.288449 (* 1 = 0.288449 loss)
I0430 09:01:01.643556  5145 solver.cpp:228] Iteration 181000, loss = 0.241009
I0430 09:01:01.643575  5145 solver.cpp:244]     Train net output #0: loss = 0.241009 (* 1 = 0.241009 loss)
I0430 09:01:01.643581  5145 sgd_solver.cpp:106] Iteration 181000, lr = 1e-26
I0430 09:01:52.237624  5145 solver.cpp:228] Iteration 181100, loss = 0.250005
I0430 09:01:52.237782  5145 solver.cpp:244]     Train net output #0: loss = 0.250005 (* 1 = 0.250005 loss)
I0430 09:01:52.237789  5145 sgd_solver.cpp:106] Iteration 181100, lr = 1e-26
I0430 09:02:42.773602  5145 solver.cpp:228] Iteration 181200, loss = 0.263196
I0430 09:02:42.773756  5145 solver.cpp:244]     Train net output #0: loss = 0.263196 (* 1 = 0.263196 loss)
I0430 09:02:42.773764  5145 sgd_solver.cpp:106] Iteration 181200, lr = 1e-26
I0430 09:03:34.504243  5145 solver.cpp:228] Iteration 181300, loss = 0.223493
I0430 09:03:34.504398  5145 solver.cpp:244]     Train net output #0: loss = 0.223493 (* 1 = 0.223493 loss)
I0430 09:03:34.504405  5145 sgd_solver.cpp:106] Iteration 181300, lr = 1e-26
I0430 09:04:24.996295  5145 solver.cpp:228] Iteration 181400, loss = 0.26669
I0430 09:04:24.996460  5145 solver.cpp:244]     Train net output #0: loss = 0.26669 (* 1 = 0.26669 loss)
I0430 09:04:24.996466  5145 sgd_solver.cpp:106] Iteration 181400, lr = 1e-26
I0430 09:05:16.802875  5145 solver.cpp:228] Iteration 181500, loss = 0.257611
I0430 09:05:16.803073  5145 solver.cpp:244]     Train net output #0: loss = 0.257611 (* 1 = 0.257611 loss)
I0430 09:05:16.803081  5145 sgd_solver.cpp:106] Iteration 181500, lr = 1e-26
I0430 09:06:07.227274  5145 solver.cpp:228] Iteration 181600, loss = 0.275634
I0430 09:06:07.227437  5145 solver.cpp:244]     Train net output #0: loss = 0.275634 (* 1 = 0.275634 loss)
I0430 09:06:07.227443  5145 sgd_solver.cpp:106] Iteration 181600, lr = 1e-26
I0430 09:06:57.518260  5145 solver.cpp:228] Iteration 181700, loss = 0.160839
I0430 09:06:57.518424  5145 solver.cpp:244]     Train net output #0: loss = 0.160839 (* 1 = 0.160839 loss)
I0430 09:06:57.518429  5145 sgd_solver.cpp:106] Iteration 181700, lr = 1e-26
I0430 09:07:49.351929  5145 solver.cpp:228] Iteration 181800, loss = 0.231149
I0430 09:07:49.352093  5145 solver.cpp:244]     Train net output #0: loss = 0.231149 (* 1 = 0.231149 loss)
I0430 09:07:49.352100  5145 sgd_solver.cpp:106] Iteration 181800, lr = 1e-26
I0430 09:08:39.807150  5145 solver.cpp:228] Iteration 181900, loss = 0.356148
I0430 09:08:39.807399  5145 solver.cpp:244]     Train net output #0: loss = 0.356148 (* 1 = 0.356148 loss)
I0430 09:08:39.807406  5145 sgd_solver.cpp:106] Iteration 181900, lr = 1e-26
I0430 09:09:30.002341  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_182000.caffemodel
I0430 09:09:42.619094  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_182000.solverstate
I0430 09:09:42.815167  5145 solver.cpp:337] Iteration 182000, Testing net (#0)
I0430 09:09:42.815254  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 09:09:42.815279  5145 net.cpp:693] Ignoring source layer visualize
I0430 09:09:42.815280  5145 net.cpp:693] Ignoring source layer fake
I0430 09:14:39.889062  5145 solver.cpp:404]     Test net output #0: loss = 0.289082 (* 1 = 0.289082 loss)
I0430 09:14:40.206035  5145 solver.cpp:228] Iteration 182000, loss = 0.336421
I0430 09:14:40.206071  5145 solver.cpp:244]     Train net output #0: loss = 0.336421 (* 1 = 0.336421 loss)
I0430 09:14:40.206079  5145 sgd_solver.cpp:106] Iteration 182000, lr = 1e-26
I0430 09:15:32.318756  5145 solver.cpp:228] Iteration 182100, loss = 0.293872
I0430 09:15:32.318931  5145 solver.cpp:244]     Train net output #0: loss = 0.293872 (* 1 = 0.293872 loss)
I0430 09:15:32.318938  5145 sgd_solver.cpp:106] Iteration 182100, lr = 1e-26
I0430 09:16:22.896819  5145 solver.cpp:228] Iteration 182200, loss = 0.250755
I0430 09:16:22.896976  5145 solver.cpp:244]     Train net output #0: loss = 0.250755 (* 1 = 0.250755 loss)
I0430 09:16:22.896982  5145 sgd_solver.cpp:106] Iteration 182200, lr = 1e-26
I0430 09:17:13.445957  5145 solver.cpp:228] Iteration 182300, loss = 0.237959
I0430 09:17:13.446121  5145 solver.cpp:244]     Train net output #0: loss = 0.237959 (* 1 = 0.237959 loss)
I0430 09:17:13.446128  5145 sgd_solver.cpp:106] Iteration 182300, lr = 1e-26
I0430 09:18:05.896574  5145 solver.cpp:228] Iteration 182400, loss = 0.315896
I0430 09:18:05.896787  5145 solver.cpp:244]     Train net output #0: loss = 0.315896 (* 1 = 0.315896 loss)
I0430 09:18:05.896796  5145 sgd_solver.cpp:106] Iteration 182400, lr = 1e-26
I0430 09:18:56.487272  5145 solver.cpp:228] Iteration 182500, loss = 0.293357
I0430 09:18:56.487483  5145 solver.cpp:244]     Train net output #0: loss = 0.293357 (* 1 = 0.293357 loss)
I0430 09:18:56.487498  5145 sgd_solver.cpp:106] Iteration 182500, lr = 1e-26
I0430 09:19:46.768971  5145 solver.cpp:228] Iteration 182600, loss = 0.312688
I0430 09:19:46.769116  5145 solver.cpp:244]     Train net output #0: loss = 0.312688 (* 1 = 0.312688 loss)
I0430 09:19:46.769122  5145 sgd_solver.cpp:106] Iteration 182600, lr = 1e-26
I0430 09:20:38.814044  5145 solver.cpp:228] Iteration 182700, loss = 0.246669
I0430 09:20:38.814223  5145 solver.cpp:244]     Train net output #0: loss = 0.246669 (* 1 = 0.246669 loss)
I0430 09:20:38.814229  5145 sgd_solver.cpp:106] Iteration 182700, lr = 1e-26
I0430 09:21:29.033336  5145 solver.cpp:228] Iteration 182800, loss = 0.210298
I0430 09:21:29.033499  5145 solver.cpp:244]     Train net output #0: loss = 0.210298 (* 1 = 0.210298 loss)
I0430 09:21:29.033506  5145 sgd_solver.cpp:106] Iteration 182800, lr = 1e-26
I0430 09:22:19.335081  5145 solver.cpp:228] Iteration 182900, loss = 0.215331
I0430 09:22:19.335235  5145 solver.cpp:244]     Train net output #0: loss = 0.215331 (* 1 = 0.215331 loss)
I0430 09:22:19.335242  5145 sgd_solver.cpp:106] Iteration 182900, lr = 1e-26
I0430 09:23:09.400460  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_183000.caffemodel
I0430 09:23:22.365332  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_183000.solverstate
I0430 09:23:22.565950  5145 solver.cpp:337] Iteration 183000, Testing net (#0)
I0430 09:23:22.566048  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 09:23:22.566053  5145 net.cpp:693] Ignoring source layer visualize
I0430 09:23:22.566056  5145 net.cpp:693] Ignoring source layer fake
I0430 09:28:18.481824  5145 solver.cpp:404]     Test net output #0: loss = 0.286178 (* 1 = 0.286178 loss)
I0430 09:28:18.797724  5145 solver.cpp:228] Iteration 183000, loss = 0.329921
I0430 09:28:18.797741  5145 solver.cpp:244]     Train net output #0: loss = 0.329921 (* 1 = 0.329921 loss)
I0430 09:28:18.797763  5145 sgd_solver.cpp:106] Iteration 183000, lr = 1e-26
I0430 09:29:11.090595  5145 solver.cpp:228] Iteration 183100, loss = 0.333631
I0430 09:29:11.090780  5145 solver.cpp:244]     Train net output #0: loss = 0.333631 (* 1 = 0.333631 loss)
I0430 09:29:11.090786  5145 sgd_solver.cpp:106] Iteration 183100, lr = 1e-26
I0430 09:30:01.606585  5145 solver.cpp:228] Iteration 183200, loss = 0.303772
I0430 09:30:01.606748  5145 solver.cpp:244]     Train net output #0: loss = 0.303772 (* 1 = 0.303772 loss)
I0430 09:30:01.606755  5145 sgd_solver.cpp:106] Iteration 183200, lr = 1e-26
I0430 09:30:52.174022  5145 solver.cpp:228] Iteration 183300, loss = 0.177935
I0430 09:30:52.175783  5145 solver.cpp:244]     Train net output #0: loss = 0.177935 (* 1 = 0.177935 loss)
I0430 09:30:52.175806  5145 sgd_solver.cpp:106] Iteration 183300, lr = 1e-26
I0430 09:31:44.373154  5145 solver.cpp:228] Iteration 183400, loss = 0.197137
I0430 09:31:44.373322  5145 solver.cpp:244]     Train net output #0: loss = 0.197137 (* 1 = 0.197137 loss)
I0430 09:31:44.373329  5145 sgd_solver.cpp:106] Iteration 183400, lr = 1e-26
I0430 09:32:34.893090  5145 solver.cpp:228] Iteration 183500, loss = 0.216184
I0430 09:32:34.893252  5145 solver.cpp:244]     Train net output #0: loss = 0.216184 (* 1 = 0.216184 loss)
I0430 09:32:34.893259  5145 sgd_solver.cpp:106] Iteration 183500, lr = 1e-26
I0430 09:33:25.490286  5145 solver.cpp:228] Iteration 183600, loss = 0.143737
I0430 09:33:25.490531  5145 solver.cpp:244]     Train net output #0: loss = 0.143737 (* 1 = 0.143737 loss)
I0430 09:33:25.490548  5145 sgd_solver.cpp:106] Iteration 183600, lr = 1e-26
I0430 09:34:17.560130  5145 solver.cpp:228] Iteration 183700, loss = 0.189388
I0430 09:34:17.560312  5145 solver.cpp:244]     Train net output #0: loss = 0.189388 (* 1 = 0.189388 loss)
I0430 09:34:17.560319  5145 sgd_solver.cpp:106] Iteration 183700, lr = 1e-26
I0430 09:35:07.887809  5145 solver.cpp:228] Iteration 183800, loss = 0.0503635
I0430 09:35:07.887980  5145 solver.cpp:244]     Train net output #0: loss = 0.0503635 (* 1 = 0.0503635 loss)
I0430 09:35:07.887989  5145 sgd_solver.cpp:106] Iteration 183800, lr = 1e-26
I0430 09:35:58.317884  5145 solver.cpp:228] Iteration 183900, loss = 0.179386
I0430 09:35:58.318055  5145 solver.cpp:244]     Train net output #0: loss = 0.179386 (* 1 = 0.179386 loss)
I0430 09:35:58.318063  5145 sgd_solver.cpp:106] Iteration 183900, lr = 1e-26
I0430 09:36:48.503046  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_184000.caffemodel
I0430 09:36:53.305702  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_184000.solverstate
I0430 09:36:53.498844  5145 solver.cpp:337] Iteration 184000, Testing net (#0)
I0430 09:36:53.498927  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 09:36:53.498931  5145 net.cpp:693] Ignoring source layer visualize
I0430 09:36:53.498949  5145 net.cpp:693] Ignoring source layer fake
I0430 09:41:49.296380  5145 solver.cpp:404]     Test net output #0: loss = 0.282767 (* 1 = 0.282767 loss)
I0430 09:41:49.614722  5145 solver.cpp:228] Iteration 184000, loss = 0.19674
I0430 09:41:49.614743  5145 solver.cpp:244]     Train net output #0: loss = 0.19674 (* 1 = 0.19674 loss)
I0430 09:41:49.614765  5145 sgd_solver.cpp:106] Iteration 184000, lr = 1e-26
I0430 09:42:41.708494  5145 solver.cpp:228] Iteration 184100, loss = 0.163421
I0430 09:42:41.708678  5145 solver.cpp:244]     Train net output #0: loss = 0.163421 (* 1 = 0.163421 loss)
I0430 09:42:41.708685  5145 sgd_solver.cpp:106] Iteration 184100, lr = 1e-26
I0430 09:43:32.161751  5145 solver.cpp:228] Iteration 184200, loss = 0.296578
I0430 09:43:32.161902  5145 solver.cpp:244]     Train net output #0: loss = 0.296578 (* 1 = 0.296578 loss)
I0430 09:43:32.161908  5145 sgd_solver.cpp:106] Iteration 184200, lr = 1e-26
I0430 09:44:22.729754  5145 solver.cpp:228] Iteration 184300, loss = 0.435534
I0430 09:44:22.729919  5145 solver.cpp:244]     Train net output #0: loss = 0.435534 (* 1 = 0.435534 loss)
I0430 09:44:22.729925  5145 sgd_solver.cpp:106] Iteration 184300, lr = 1e-26
I0430 09:45:14.394809  5145 solver.cpp:228] Iteration 184400, loss = 0.1852
I0430 09:45:14.394969  5145 solver.cpp:244]     Train net output #0: loss = 0.1852 (* 1 = 0.1852 loss)
I0430 09:45:14.394975  5145 sgd_solver.cpp:106] Iteration 184400, lr = 1e-26
I0430 09:46:04.900101  5145 solver.cpp:228] Iteration 184500, loss = 0.240893
I0430 09:46:04.900264  5145 solver.cpp:244]     Train net output #0: loss = 0.240893 (* 1 = 0.240893 loss)
I0430 09:46:04.900270  5145 sgd_solver.cpp:106] Iteration 184500, lr = 1e-26
I0430 09:46:57.180449  5145 solver.cpp:228] Iteration 184600, loss = 0.199556
I0430 09:46:57.180619  5145 solver.cpp:244]     Train net output #0: loss = 0.199556 (* 1 = 0.199556 loss)
I0430 09:46:57.180625  5145 sgd_solver.cpp:106] Iteration 184600, lr = 1e-26
I0430 09:47:47.592125  5145 solver.cpp:228] Iteration 184700, loss = 0.242594
I0430 09:47:47.592288  5145 solver.cpp:244]     Train net output #0: loss = 0.242594 (* 1 = 0.242594 loss)
I0430 09:47:47.592296  5145 sgd_solver.cpp:106] Iteration 184700, lr = 1e-26
I0430 09:48:38.015089  5145 solver.cpp:228] Iteration 184800, loss = 0.223306
I0430 09:48:38.015249  5145 solver.cpp:244]     Train net output #0: loss = 0.223306 (* 1 = 0.223306 loss)
I0430 09:48:38.015256  5145 sgd_solver.cpp:106] Iteration 184800, lr = 1e-26
I0430 09:49:29.926949  5145 solver.cpp:228] Iteration 184900, loss = 0.291528
I0430 09:49:29.927129  5145 solver.cpp:244]     Train net output #0: loss = 0.291528 (* 1 = 0.291528 loss)
I0430 09:49:29.927137  5145 sgd_solver.cpp:106] Iteration 184900, lr = 1e-26
I0430 09:50:20.149098  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_185000.caffemodel
I0430 09:50:30.823876  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_185000.solverstate
I0430 09:50:31.023710  5145 solver.cpp:337] Iteration 185000, Testing net (#0)
I0430 09:50:31.023810  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 09:50:31.023815  5145 net.cpp:693] Ignoring source layer visualize
I0430 09:50:31.023818  5145 net.cpp:693] Ignoring source layer fake
I0430 09:55:26.615530  5145 solver.cpp:404]     Test net output #0: loss = 0.280851 (* 1 = 0.280851 loss)
I0430 09:55:26.928791  5145 solver.cpp:228] Iteration 185000, loss = 0.273693
I0430 09:55:26.928828  5145 solver.cpp:244]     Train net output #0: loss = 0.273693 (* 1 = 0.273693 loss)
I0430 09:55:26.928833  5145 sgd_solver.cpp:106] Iteration 185000, lr = 1e-26
I0430 09:56:17.500213  5145 solver.cpp:228] Iteration 185100, loss = 0.313122
I0430 09:56:17.500380  5145 solver.cpp:244]     Train net output #0: loss = 0.313122 (* 1 = 0.313122 loss)
I0430 09:56:17.500386  5145 sgd_solver.cpp:106] Iteration 185100, lr = 1e-26
I0430 09:57:10.844087  5145 solver.cpp:228] Iteration 185200, loss = 0.392069
I0430 09:57:10.844241  5145 solver.cpp:244]     Train net output #0: loss = 0.392069 (* 1 = 0.392069 loss)
I0430 09:57:10.844249  5145 sgd_solver.cpp:106] Iteration 185200, lr = 1e-26
I0430 09:58:01.485014  5145 solver.cpp:228] Iteration 185300, loss = 0.134995
I0430 09:58:01.485175  5145 solver.cpp:244]     Train net output #0: loss = 0.134995 (* 1 = 0.134995 loss)
I0430 09:58:01.485182  5145 sgd_solver.cpp:106] Iteration 185300, lr = 1e-26
I0430 09:58:51.930613  5145 solver.cpp:228] Iteration 185400, loss = 0.396808
I0430 09:58:51.930799  5145 solver.cpp:244]     Train net output #0: loss = 0.396808 (* 1 = 0.396808 loss)
I0430 09:58:51.930806  5145 sgd_solver.cpp:106] Iteration 185400, lr = 1e-26
I0430 09:59:44.162541  5145 solver.cpp:228] Iteration 185500, loss = 0.286558
I0430 09:59:44.162706  5145 solver.cpp:244]     Train net output #0: loss = 0.286558 (* 1 = 0.286558 loss)
I0430 09:59:44.162714  5145 sgd_solver.cpp:106] Iteration 185500, lr = 1e-26
I0430 10:00:34.741418  5145 solver.cpp:228] Iteration 185600, loss = 0.405573
I0430 10:00:34.741621  5145 solver.cpp:244]     Train net output #0: loss = 0.405573 (* 1 = 0.405573 loss)
I0430 10:00:34.741639  5145 sgd_solver.cpp:106] Iteration 185600, lr = 1e-26
I0430 10:01:25.212626  5145 solver.cpp:228] Iteration 185700, loss = 0.339065
I0430 10:01:25.212798  5145 solver.cpp:244]     Train net output #0: loss = 0.339065 (* 1 = 0.339065 loss)
I0430 10:01:25.212817  5145 sgd_solver.cpp:106] Iteration 185700, lr = 1e-26
I0430 10:02:15.503654  5145 solver.cpp:228] Iteration 185800, loss = 0.350263
I0430 10:02:15.503801  5145 solver.cpp:244]     Train net output #0: loss = 0.350263 (* 1 = 0.350263 loss)
I0430 10:02:15.503808  5145 sgd_solver.cpp:106] Iteration 185800, lr = 1e-26
I0430 10:03:07.638062  5145 solver.cpp:228] Iteration 185900, loss = 0.403938
I0430 10:03:07.638218  5145 solver.cpp:244]     Train net output #0: loss = 0.403938 (* 1 = 0.403938 loss)
I0430 10:03:07.638226  5145 sgd_solver.cpp:106] Iteration 185900, lr = 1e-26
I0430 10:03:57.778079  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_186000.caffemodel
I0430 10:04:17.890849  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_186000.solverstate
I0430 10:04:18.079454  5145 solver.cpp:337] Iteration 186000, Testing net (#0)
I0430 10:04:18.079537  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 10:04:18.079541  5145 net.cpp:693] Ignoring source layer visualize
I0430 10:04:18.079543  5145 net.cpp:693] Ignoring source layer fake
I0430 10:09:14.673125  5145 solver.cpp:404]     Test net output #0: loss = 0.289955 (* 1 = 0.289955 loss)
I0430 10:09:14.987905  5145 solver.cpp:228] Iteration 186000, loss = 0.261675
I0430 10:09:14.987926  5145 solver.cpp:244]     Train net output #0: loss = 0.261675 (* 1 = 0.261675 loss)
I0430 10:09:14.987948  5145 sgd_solver.cpp:106] Iteration 186000, lr = 1e-26
I0430 10:10:05.081993  5145 solver.cpp:228] Iteration 186100, loss = 0.164986
I0430 10:10:05.082164  5145 solver.cpp:244]     Train net output #0: loss = 0.164986 (* 1 = 0.164986 loss)
I0430 10:10:05.082170  5145 sgd_solver.cpp:106] Iteration 186100, lr = 1e-26
I0430 10:10:57.054143  5145 solver.cpp:228] Iteration 186200, loss = 0.199823
I0430 10:10:57.054308  5145 solver.cpp:244]     Train net output #0: loss = 0.199823 (* 1 = 0.199823 loss)
I0430 10:10:57.054316  5145 sgd_solver.cpp:106] Iteration 186200, lr = 1e-26
I0430 10:11:47.144527  5145 solver.cpp:228] Iteration 186300, loss = 0.2657
I0430 10:11:47.144704  5145 solver.cpp:244]     Train net output #0: loss = 0.2657 (* 1 = 0.2657 loss)
I0430 10:11:47.144711  5145 sgd_solver.cpp:106] Iteration 186300, lr = 1e-26
I0430 10:12:37.240977  5145 solver.cpp:228] Iteration 186400, loss = 0.350567
I0430 10:12:37.241134  5145 solver.cpp:244]     Train net output #0: loss = 0.350567 (* 1 = 0.350567 loss)
I0430 10:12:37.241142  5145 sgd_solver.cpp:106] Iteration 186400, lr = 1e-26
I0430 10:13:29.180536  5145 solver.cpp:228] Iteration 186500, loss = 0.345962
I0430 10:13:29.180709  5145 solver.cpp:244]     Train net output #0: loss = 0.345962 (* 1 = 0.345962 loss)
I0430 10:13:29.180716  5145 sgd_solver.cpp:106] Iteration 186500, lr = 1e-26
I0430 10:14:19.269193  5145 solver.cpp:228] Iteration 186600, loss = 0.242259
I0430 10:14:19.269371  5145 solver.cpp:244]     Train net output #0: loss = 0.242259 (* 1 = 0.242259 loss)
I0430 10:14:19.269376  5145 sgd_solver.cpp:106] Iteration 186600, lr = 1e-26
I0430 10:15:09.362867  5145 solver.cpp:228] Iteration 186700, loss = 0.16394
I0430 10:15:09.363049  5145 solver.cpp:244]     Train net output #0: loss = 0.16394 (* 1 = 0.16394 loss)
I0430 10:15:09.363055  5145 sgd_solver.cpp:106] Iteration 186700, lr = 1e-26
I0430 10:15:59.458279  5145 solver.cpp:228] Iteration 186800, loss = 0.281255
I0430 10:15:59.458444  5145 solver.cpp:244]     Train net output #0: loss = 0.281255 (* 1 = 0.281255 loss)
I0430 10:15:59.458451  5145 sgd_solver.cpp:106] Iteration 186800, lr = 1e-26
I0430 10:16:51.394493  5145 solver.cpp:228] Iteration 186900, loss = 0.0923364
I0430 10:16:51.394666  5145 solver.cpp:244]     Train net output #0: loss = 0.0923364 (* 1 = 0.0923364 loss)
I0430 10:16:51.394673  5145 sgd_solver.cpp:106] Iteration 186900, lr = 1e-26
I0430 10:17:41.174638  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_187000.caffemodel
I0430 10:17:47.174346  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_187000.solverstate
I0430 10:17:47.359640  5145 solver.cpp:337] Iteration 187000, Testing net (#0)
I0430 10:17:47.359740  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 10:17:47.359745  5145 net.cpp:693] Ignoring source layer visualize
I0430 10:17:47.359747  5145 net.cpp:693] Ignoring source layer fake
I0430 10:22:42.368019  5145 solver.cpp:404]     Test net output #0: loss = 0.288137 (* 1 = 0.288137 loss)
I0430 10:22:42.679489  5145 solver.cpp:228] Iteration 187000, loss = 0.201265
I0430 10:22:42.679529  5145 solver.cpp:244]     Train net output #0: loss = 0.201265 (* 1 = 0.201265 loss)
I0430 10:22:42.679536  5145 sgd_solver.cpp:106] Iteration 187000, lr = 1e-26
I0430 10:23:32.650167  5145 solver.cpp:228] Iteration 187100, loss = 0.231931
I0430 10:23:32.650326  5145 solver.cpp:244]     Train net output #0: loss = 0.231931 (* 1 = 0.231931 loss)
I0430 10:23:32.650333  5145 sgd_solver.cpp:106] Iteration 187100, lr = 1e-26
I0430 10:24:24.382669  5145 solver.cpp:228] Iteration 187200, loss = 0.223383
I0430 10:24:24.382843  5145 solver.cpp:244]     Train net output #0: loss = 0.223383 (* 1 = 0.223383 loss)
I0430 10:24:24.382851  5145 sgd_solver.cpp:106] Iteration 187200, lr = 1e-26
I0430 10:25:14.397729  5145 solver.cpp:228] Iteration 187300, loss = 0.227544
I0430 10:25:14.397948  5145 solver.cpp:244]     Train net output #0: loss = 0.227544 (* 1 = 0.227544 loss)
I0430 10:25:14.397964  5145 sgd_solver.cpp:106] Iteration 187300, lr = 1e-26
I0430 10:26:04.410154  5145 solver.cpp:228] Iteration 187400, loss = 0.302442
I0430 10:26:04.410356  5145 solver.cpp:244]     Train net output #0: loss = 0.302442 (* 1 = 0.302442 loss)
I0430 10:26:04.410367  5145 sgd_solver.cpp:106] Iteration 187400, lr = 1e-26
I0430 10:26:55.667927  5145 solver.cpp:228] Iteration 187500, loss = 0.186677
I0430 10:26:55.668092  5145 solver.cpp:244]     Train net output #0: loss = 0.186677 (* 1 = 0.186677 loss)
I0430 10:26:55.668097  5145 sgd_solver.cpp:106] Iteration 187500, lr = 1e-27
I0430 10:27:45.700048  5145 solver.cpp:228] Iteration 187600, loss = 0.204966
I0430 10:27:45.700219  5145 solver.cpp:244]     Train net output #0: loss = 0.204966 (* 1 = 0.204966 loss)
I0430 10:27:45.700229  5145 sgd_solver.cpp:106] Iteration 187600, lr = 1e-27
I0430 10:28:37.000564  5145 solver.cpp:228] Iteration 187700, loss = 0.284361
I0430 10:28:37.000735  5145 solver.cpp:244]     Train net output #0: loss = 0.284361 (* 1 = 0.284361 loss)
I0430 10:28:37.000741  5145 sgd_solver.cpp:106] Iteration 187700, lr = 1e-27
I0430 10:29:26.986410  5145 solver.cpp:228] Iteration 187800, loss = 0.221304
I0430 10:29:26.986573  5145 solver.cpp:244]     Train net output #0: loss = 0.221304 (* 1 = 0.221304 loss)
I0430 10:29:26.986582  5145 sgd_solver.cpp:106] Iteration 187800, lr = 1e-27
I0430 10:30:17.020293  5145 solver.cpp:228] Iteration 187900, loss = 0.39644
I0430 10:30:17.020480  5145 solver.cpp:244]     Train net output #0: loss = 0.39644 (* 1 = 0.39644 loss)
I0430 10:30:17.020486  5145 sgd_solver.cpp:106] Iteration 187900, lr = 1e-27
I0430 10:31:08.225494  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_188000.caffemodel
I0430 10:31:19.149091  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_188000.solverstate
I0430 10:31:19.337628  5145 solver.cpp:337] Iteration 188000, Testing net (#0)
I0430 10:31:19.337714  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 10:31:19.337720  5145 net.cpp:693] Ignoring source layer visualize
I0430 10:31:19.337723  5145 net.cpp:693] Ignoring source layer fake
I0430 10:36:13.757709  5145 solver.cpp:404]     Test net output #0: loss = 0.285947 (* 1 = 0.285947 loss)
I0430 10:36:14.072410  5145 solver.cpp:228] Iteration 188000, loss = 0.25333
I0430 10:36:14.072428  5145 solver.cpp:244]     Train net output #0: loss = 0.25333 (* 1 = 0.25333 loss)
I0430 10:36:14.072449  5145 sgd_solver.cpp:106] Iteration 188000, lr = 1e-27
I0430 10:37:04.147517  5145 solver.cpp:228] Iteration 188100, loss = 0.249221
I0430 10:37:04.148767  5145 solver.cpp:244]     Train net output #0: loss = 0.249221 (* 1 = 0.249221 loss)
I0430 10:37:04.148774  5145 sgd_solver.cpp:106] Iteration 188100, lr = 1e-27
I0430 10:37:54.242440  5145 solver.cpp:228] Iteration 188200, loss = 0.244168
I0430 10:37:54.242595  5145 solver.cpp:244]     Train net output #0: loss = 0.244168 (* 1 = 0.244168 loss)
I0430 10:37:54.242602  5145 sgd_solver.cpp:106] Iteration 188200, lr = 1e-27
I0430 10:38:46.082056  5145 solver.cpp:228] Iteration 188300, loss = 0.204788
I0430 10:38:46.082233  5145 solver.cpp:244]     Train net output #0: loss = 0.204788 (* 1 = 0.204788 loss)
I0430 10:38:46.082240  5145 sgd_solver.cpp:106] Iteration 188300, lr = 1e-27
I0430 10:39:36.170981  5145 solver.cpp:228] Iteration 188400, loss = 0.33102
I0430 10:39:36.171144  5145 solver.cpp:244]     Train net output #0: loss = 0.33102 (* 1 = 0.33102 loss)
I0430 10:39:36.171151  5145 sgd_solver.cpp:106] Iteration 188400, lr = 1e-27
I0430 10:40:26.267088  5145 solver.cpp:228] Iteration 188500, loss = 0.468511
I0430 10:40:26.267243  5145 solver.cpp:244]     Train net output #0: loss = 0.468511 (* 1 = 0.468511 loss)
I0430 10:40:26.267251  5145 sgd_solver.cpp:106] Iteration 188500, lr = 1e-27
I0430 10:41:18.883440  5145 solver.cpp:228] Iteration 188600, loss = 0.234192
I0430 10:41:18.883605  5145 solver.cpp:244]     Train net output #0: loss = 0.234192 (* 1 = 0.234192 loss)
I0430 10:41:18.883611  5145 sgd_solver.cpp:106] Iteration 188600, lr = 1e-27
I0430 10:42:08.975276  5145 solver.cpp:228] Iteration 188700, loss = 0.326503
I0430 10:42:08.975435  5145 solver.cpp:244]     Train net output #0: loss = 0.326503 (* 1 = 0.326503 loss)
I0430 10:42:08.975440  5145 sgd_solver.cpp:106] Iteration 188700, lr = 1e-27
I0430 10:42:59.071094  5145 solver.cpp:228] Iteration 188800, loss = 0.193639
I0430 10:42:59.071252  5145 solver.cpp:244]     Train net output #0: loss = 0.193639 (* 1 = 0.193639 loss)
I0430 10:42:59.071259  5145 sgd_solver.cpp:106] Iteration 188800, lr = 1e-27
I0430 10:43:49.162423  5145 solver.cpp:228] Iteration 188900, loss = 0.243612
I0430 10:43:49.162600  5145 solver.cpp:244]     Train net output #0: loss = 0.243612 (* 1 = 0.243612 loss)
I0430 10:43:49.162608  5145 sgd_solver.cpp:106] Iteration 188900, lr = 1e-27
I0430 10:44:41.130753  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_189000.caffemodel
I0430 10:44:48.131695  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_189000.solverstate
I0430 10:44:48.346307  5145 solver.cpp:337] Iteration 189000, Testing net (#0)
I0430 10:44:48.346405  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 10:44:48.346410  5145 net.cpp:693] Ignoring source layer visualize
I0430 10:44:48.346412  5145 net.cpp:693] Ignoring source layer fake
I0430 10:49:43.112877  5145 solver.cpp:404]     Test net output #0: loss = 0.282059 (* 1 = 0.282059 loss)
I0430 10:49:43.427258  5145 solver.cpp:228] Iteration 189000, loss = 0.249941
I0430 10:49:43.427297  5145 solver.cpp:244]     Train net output #0: loss = 0.249941 (* 1 = 0.249941 loss)
I0430 10:49:43.427304  5145 sgd_solver.cpp:106] Iteration 189000, lr = 1e-27
I0430 10:50:33.522027  5145 solver.cpp:228] Iteration 189100, loss = 0.220496
I0430 10:50:33.522192  5145 solver.cpp:244]     Train net output #0: loss = 0.220496 (* 1 = 0.220496 loss)
I0430 10:50:33.522198  5145 sgd_solver.cpp:106] Iteration 189100, lr = 1e-27
I0430 10:51:23.617708  5145 solver.cpp:228] Iteration 189200, loss = 0.357064
I0430 10:51:23.617854  5145 solver.cpp:244]     Train net output #0: loss = 0.357064 (* 1 = 0.357064 loss)
I0430 10:51:23.617861  5145 sgd_solver.cpp:106] Iteration 189200, lr = 1e-27
I0430 10:52:15.511703  5145 solver.cpp:228] Iteration 189300, loss = 0.330566
I0430 10:52:15.513404  5145 solver.cpp:244]     Train net output #0: loss = 0.330566 (* 1 = 0.330566 loss)
I0430 10:52:15.513427  5145 sgd_solver.cpp:106] Iteration 189300, lr = 1e-27
I0430 10:53:05.607225  5145 solver.cpp:228] Iteration 189400, loss = 0.268394
I0430 10:53:05.607380  5145 solver.cpp:244]     Train net output #0: loss = 0.268394 (* 1 = 0.268394 loss)
I0430 10:53:05.607388  5145 sgd_solver.cpp:106] Iteration 189400, lr = 1e-27
I0430 10:53:55.697275  5145 solver.cpp:228] Iteration 189500, loss = 0.274431
I0430 10:53:55.697444  5145 solver.cpp:244]     Train net output #0: loss = 0.274431 (* 1 = 0.274431 loss)
I0430 10:53:55.697451  5145 sgd_solver.cpp:106] Iteration 189500, lr = 1e-27
I0430 10:54:45.791901  5145 solver.cpp:228] Iteration 189600, loss = 0.253779
I0430 10:54:45.792114  5145 solver.cpp:244]     Train net output #0: loss = 0.253779 (* 1 = 0.253779 loss)
I0430 10:54:45.792130  5145 sgd_solver.cpp:106] Iteration 189600, lr = 1e-27
I0430 10:55:38.646316  5145 solver.cpp:228] Iteration 189700, loss = 0.142915
I0430 10:55:38.646466  5145 solver.cpp:244]     Train net output #0: loss = 0.142915 (* 1 = 0.142915 loss)
I0430 10:55:38.646473  5145 sgd_solver.cpp:106] Iteration 189700, lr = 1e-27
I0430 10:56:28.736058  5145 solver.cpp:228] Iteration 189800, loss = 0.292112
I0430 10:56:28.736210  5145 solver.cpp:244]     Train net output #0: loss = 0.292112 (* 1 = 0.292112 loss)
I0430 10:56:28.736217  5145 sgd_solver.cpp:106] Iteration 189800, lr = 1e-27
I0430 10:57:18.829627  5145 solver.cpp:228] Iteration 189900, loss = 0.244801
I0430 10:57:18.829780  5145 solver.cpp:244]     Train net output #0: loss = 0.244801 (* 1 = 0.244801 loss)
I0430 10:57:18.829787  5145 sgd_solver.cpp:106] Iteration 189900, lr = 1e-27
I0430 10:58:10.432044  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_190000.caffemodel
I0430 10:58:15.439633  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_190000.solverstate
I0430 10:58:15.633604  5145 solver.cpp:337] Iteration 190000, Testing net (#0)
I0430 10:58:15.633685  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 10:58:15.633688  5145 net.cpp:693] Ignoring source layer visualize
I0430 10:58:15.633690  5145 net.cpp:693] Ignoring source layer fake
I0430 11:03:10.007988  5145 solver.cpp:404]     Test net output #0: loss = 0.281297 (* 1 = 0.281297 loss)
I0430 11:03:10.323101  5145 solver.cpp:228] Iteration 190000, loss = 0.205033
I0430 11:03:10.323119  5145 solver.cpp:244]     Train net output #0: loss = 0.205033 (* 1 = 0.205033 loss)
I0430 11:03:10.323141  5145 sgd_solver.cpp:106] Iteration 190000, lr = 1e-27
I0430 11:04:00.305661  5145 solver.cpp:228] Iteration 190100, loss = 0.255448
I0430 11:04:00.305820  5145 solver.cpp:244]     Train net output #0: loss = 0.255448 (* 1 = 0.255448 loss)
I0430 11:04:00.305827  5145 sgd_solver.cpp:106] Iteration 190100, lr = 1e-27
I0430 11:04:50.297204  5145 solver.cpp:228] Iteration 190200, loss = 0.201952
I0430 11:04:50.298061  5145 solver.cpp:244]     Train net output #0: loss = 0.201952 (* 1 = 0.201952 loss)
I0430 11:04:50.298069  5145 sgd_solver.cpp:106] Iteration 190200, lr = 1e-27
I0430 11:05:41.952502  5145 solver.cpp:228] Iteration 190300, loss = 0.221499
I0430 11:05:41.952667  5145 solver.cpp:244]     Train net output #0: loss = 0.221499 (* 1 = 0.221499 loss)
I0430 11:05:41.952675  5145 sgd_solver.cpp:106] Iteration 190300, lr = 1e-27
I0430 11:06:31.933784  5145 solver.cpp:228] Iteration 190400, loss = 0.101846
I0430 11:06:31.933931  5145 solver.cpp:244]     Train net output #0: loss = 0.101846 (* 1 = 0.101846 loss)
I0430 11:06:31.933938  5145 sgd_solver.cpp:106] Iteration 190400, lr = 1e-27
I0430 11:07:21.925086  5145 solver.cpp:228] Iteration 190500, loss = 0.554795
I0430 11:07:21.925226  5145 solver.cpp:244]     Train net output #0: loss = 0.554795 (* 1 = 0.554795 loss)
I0430 11:07:21.925232  5145 sgd_solver.cpp:106] Iteration 190500, lr = 1e-27
I0430 11:08:13.225703  5145 solver.cpp:228] Iteration 190600, loss = 0.241103
I0430 11:08:13.225877  5145 solver.cpp:244]     Train net output #0: loss = 0.241103 (* 1 = 0.241103 loss)
I0430 11:08:13.225883  5145 sgd_solver.cpp:106] Iteration 190600, lr = 1e-27
I0430 11:09:03.258129  5145 solver.cpp:228] Iteration 190700, loss = 0.264577
I0430 11:09:03.258270  5145 solver.cpp:244]     Train net output #0: loss = 0.264577 (* 1 = 0.264577 loss)
I0430 11:09:03.258277  5145 sgd_solver.cpp:106] Iteration 190700, lr = 1e-27
I0430 11:09:53.247999  5145 solver.cpp:228] Iteration 190800, loss = 0.209172
I0430 11:09:53.248152  5145 solver.cpp:244]     Train net output #0: loss = 0.209172 (* 1 = 0.209172 loss)
I0430 11:09:53.248158  5145 sgd_solver.cpp:106] Iteration 190800, lr = 1e-27
I0430 11:10:44.564887  5145 solver.cpp:228] Iteration 190900, loss = 0.332869
I0430 11:10:44.565035  5145 solver.cpp:244]     Train net output #0: loss = 0.332869 (* 1 = 0.332869 loss)
I0430 11:10:44.565042  5145 sgd_solver.cpp:106] Iteration 190900, lr = 1e-27
I0430 11:11:34.309185  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_191000.caffemodel
I0430 11:11:43.459687  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_191000.solverstate
I0430 11:11:43.650607  5145 solver.cpp:337] Iteration 191000, Testing net (#0)
I0430 11:11:43.650688  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 11:11:43.650691  5145 net.cpp:693] Ignoring source layer visualize
I0430 11:11:43.650694  5145 net.cpp:693] Ignoring source layer fake
I0430 11:16:38.542629  5145 solver.cpp:404]     Test net output #0: loss = 0.290855 (* 1 = 0.290855 loss)
I0430 11:16:38.855670  5145 solver.cpp:228] Iteration 191000, loss = 0.134776
I0430 11:16:38.855687  5145 solver.cpp:244]     Train net output #0: loss = 0.134776 (* 1 = 0.134776 loss)
I0430 11:16:38.855710  5145 sgd_solver.cpp:106] Iteration 191000, lr = 1e-27
I0430 11:17:30.453404  5145 solver.cpp:228] Iteration 191100, loss = 0.355038
I0430 11:17:30.453532  5145 solver.cpp:244]     Train net output #0: loss = 0.355038 (* 1 = 0.355038 loss)
I0430 11:17:30.453538  5145 sgd_solver.cpp:106] Iteration 191100, lr = 1e-27
I0430 11:18:20.542912  5145 solver.cpp:228] Iteration 191200, loss = 0.191203
I0430 11:18:20.543043  5145 solver.cpp:244]     Train net output #0: loss = 0.191203 (* 1 = 0.191203 loss)
I0430 11:18:20.543050  5145 sgd_solver.cpp:106] Iteration 191200, lr = 1e-27
I0430 11:19:10.637567  5145 solver.cpp:228] Iteration 191300, loss = 0.341998
I0430 11:19:10.637718  5145 solver.cpp:244]     Train net output #0: loss = 0.341998 (* 1 = 0.341998 loss)
I0430 11:19:10.637725  5145 sgd_solver.cpp:106] Iteration 191300, lr = 1e-27
I0430 11:20:02.468927  5145 solver.cpp:228] Iteration 191400, loss = 0.251596
I0430 11:20:02.469068  5145 solver.cpp:244]     Train net output #0: loss = 0.251596 (* 1 = 0.251596 loss)
I0430 11:20:02.469074  5145 sgd_solver.cpp:106] Iteration 191400, lr = 1e-27
I0430 11:20:52.685958  5145 solver.cpp:228] Iteration 191500, loss = 0.335473
I0430 11:20:52.686139  5145 solver.cpp:244]     Train net output #0: loss = 0.335473 (* 1 = 0.335473 loss)
I0430 11:20:52.686156  5145 sgd_solver.cpp:106] Iteration 191500, lr = 1e-27
I0430 11:21:43.097126  5145 solver.cpp:228] Iteration 191600, loss = 0.26243
I0430 11:21:43.097329  5145 solver.cpp:244]     Train net output #0: loss = 0.26243 (* 1 = 0.26243 loss)
I0430 11:21:43.097339  5145 sgd_solver.cpp:106] Iteration 191600, lr = 1e-27
I0430 11:22:33.528578  5145 solver.cpp:228] Iteration 191700, loss = 0.31224
I0430 11:22:33.528734  5145 solver.cpp:244]     Train net output #0: loss = 0.31224 (* 1 = 0.31224 loss)
I0430 11:22:33.528740  5145 sgd_solver.cpp:106] Iteration 191700, lr = 1e-27
I0430 11:23:25.609452  5145 solver.cpp:228] Iteration 191800, loss = 0.352235
I0430 11:23:25.609617  5145 solver.cpp:244]     Train net output #0: loss = 0.352235 (* 1 = 0.352235 loss)
I0430 11:23:25.609624  5145 sgd_solver.cpp:106] Iteration 191800, lr = 1e-27
I0430 11:24:15.991577  5145 solver.cpp:228] Iteration 191900, loss = 0.284469
I0430 11:24:15.991740  5145 solver.cpp:244]     Train net output #0: loss = 0.284469 (* 1 = 0.284469 loss)
I0430 11:24:15.991747  5145 sgd_solver.cpp:106] Iteration 191900, lr = 1e-27
I0430 11:25:06.111412  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_192000.caffemodel
I0430 11:25:31.511061  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_192000.solverstate
I0430 11:25:31.711257  5145 solver.cpp:337] Iteration 192000, Testing net (#0)
I0430 11:25:31.711355  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 11:25:31.711361  5145 net.cpp:693] Ignoring source layer visualize
I0430 11:25:31.711364  5145 net.cpp:693] Ignoring source layer fake
I0430 11:30:27.014686  5145 solver.cpp:404]     Test net output #0: loss = 0.287333 (* 1 = 0.287333 loss)
I0430 11:30:27.329062  5145 solver.cpp:228] Iteration 192000, loss = 0.301531
I0430 11:30:27.329082  5145 solver.cpp:244]     Train net output #0: loss = 0.301531 (* 1 = 0.301531 loss)
I0430 11:30:27.329103  5145 sgd_solver.cpp:106] Iteration 192000, lr = 1e-27
I0430 11:31:19.609122  5145 solver.cpp:228] Iteration 192100, loss = 0.28232
I0430 11:31:19.609287  5145 solver.cpp:244]     Train net output #0: loss = 0.28232 (* 1 = 0.28232 loss)
I0430 11:31:19.609294  5145 sgd_solver.cpp:106] Iteration 192100, lr = 1e-27
I0430 11:32:10.106225  5145 solver.cpp:228] Iteration 192200, loss = 0.203627
I0430 11:32:10.106377  5145 solver.cpp:244]     Train net output #0: loss = 0.203627 (* 1 = 0.203627 loss)
I0430 11:32:10.106384  5145 sgd_solver.cpp:106] Iteration 192200, lr = 1e-27
I0430 11:33:00.662675  5145 solver.cpp:228] Iteration 192300, loss = 0.227516
I0430 11:33:00.663669  5145 solver.cpp:244]     Train net output #0: loss = 0.227516 (* 1 = 0.227516 loss)
I0430 11:33:00.663692  5145 sgd_solver.cpp:106] Iteration 192300, lr = 1e-27
I0430 11:33:51.116655  5145 solver.cpp:228] Iteration 192400, loss = 0.205171
I0430 11:33:51.116817  5145 solver.cpp:244]     Train net output #0: loss = 0.205171 (* 1 = 0.205171 loss)
I0430 11:33:51.116824  5145 sgd_solver.cpp:106] Iteration 192400, lr = 1e-27
I0430 11:34:43.347795  5145 solver.cpp:228] Iteration 192500, loss = 0.201593
I0430 11:34:43.347954  5145 solver.cpp:244]     Train net output #0: loss = 0.201593 (* 1 = 0.201593 loss)
I0430 11:34:43.347961  5145 sgd_solver.cpp:106] Iteration 192500, lr = 1e-27
I0430 11:35:33.912192  5145 solver.cpp:228] Iteration 192600, loss = 0.278616
I0430 11:35:33.912364  5145 solver.cpp:244]     Train net output #0: loss = 0.278616 (* 1 = 0.278616 loss)
I0430 11:35:33.912371  5145 sgd_solver.cpp:106] Iteration 192600, lr = 1e-27
I0430 11:36:24.554553  5145 solver.cpp:228] Iteration 192700, loss = 0.257245
I0430 11:36:24.554738  5145 solver.cpp:244]     Train net output #0: loss = 0.257245 (* 1 = 0.257245 loss)
I0430 11:36:24.554744  5145 sgd_solver.cpp:106] Iteration 192700, lr = 1e-27
I0430 11:37:16.467758  5145 solver.cpp:228] Iteration 192800, loss = 0.202763
I0430 11:37:16.467959  5145 solver.cpp:244]     Train net output #0: loss = 0.202763 (* 1 = 0.202763 loss)
I0430 11:37:16.467967  5145 sgd_solver.cpp:106] Iteration 192800, lr = 1e-27
I0430 11:38:06.933789  5145 solver.cpp:228] Iteration 192900, loss = 0.379963
I0430 11:38:06.933967  5145 solver.cpp:244]     Train net output #0: loss = 0.379963 (* 1 = 0.379963 loss)
I0430 11:38:06.933974  5145 sgd_solver.cpp:106] Iteration 192900, lr = 1e-27
I0430 11:38:56.953279  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_193000.caffemodel
I0430 11:39:01.558845  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_193000.solverstate
I0430 11:39:01.742435  5145 solver.cpp:337] Iteration 193000, Testing net (#0)
I0430 11:39:01.742518  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 11:39:01.742522  5145 net.cpp:693] Ignoring source layer visualize
I0430 11:39:01.742523  5145 net.cpp:693] Ignoring source layer fake
I0430 11:43:57.433142  5145 solver.cpp:404]     Test net output #0: loss = 0.28588 (* 1 = 0.28588 loss)
I0430 11:43:57.744138  5145 solver.cpp:228] Iteration 193000, loss = 0.260451
I0430 11:43:57.744155  5145 solver.cpp:244]     Train net output #0: loss = 0.260451 (* 1 = 0.260451 loss)
I0430 11:43:57.744161  5145 sgd_solver.cpp:106] Iteration 193000, lr = 1e-27
I0430 11:44:49.887413  5145 solver.cpp:228] Iteration 193100, loss = 0.257152
I0430 11:44:49.887573  5145 solver.cpp:244]     Train net output #0: loss = 0.257152 (* 1 = 0.257152 loss)
I0430 11:44:49.887580  5145 sgd_solver.cpp:106] Iteration 193100, lr = 1e-27
I0430 11:45:40.554082  5145 solver.cpp:228] Iteration 193200, loss = 0.291969
I0430 11:45:40.554239  5145 solver.cpp:244]     Train net output #0: loss = 0.291969 (* 1 = 0.291969 loss)
I0430 11:45:40.554246  5145 sgd_solver.cpp:106] Iteration 193200, lr = 1e-27
I0430 11:46:31.009383  5145 solver.cpp:228] Iteration 193300, loss = 0.327097
I0430 11:46:31.009532  5145 solver.cpp:244]     Train net output #0: loss = 0.327097 (* 1 = 0.327097 loss)
I0430 11:46:31.009538  5145 sgd_solver.cpp:106] Iteration 193300, lr = 1e-27
I0430 11:47:21.541596  5145 solver.cpp:228] Iteration 193400, loss = 0.220916
I0430 11:47:21.541759  5145 solver.cpp:244]     Train net output #0: loss = 0.220916 (* 1 = 0.220916 loss)
I0430 11:47:21.541766  5145 sgd_solver.cpp:106] Iteration 193400, lr = 1e-27
I0430 11:48:13.567003  5145 solver.cpp:228] Iteration 193500, loss = 0.197497
I0430 11:48:13.567150  5145 solver.cpp:244]     Train net output #0: loss = 0.197497 (* 1 = 0.197497 loss)
I0430 11:48:13.567157  5145 sgd_solver.cpp:106] Iteration 193500, lr = 1e-27
I0430 11:49:04.155910  5145 solver.cpp:228] Iteration 193600, loss = 0.163022
I0430 11:49:04.156070  5145 solver.cpp:244]     Train net output #0: loss = 0.163022 (* 1 = 0.163022 loss)
I0430 11:49:04.156077  5145 sgd_solver.cpp:106] Iteration 193600, lr = 1e-27
I0430 11:49:54.734282  5145 solver.cpp:228] Iteration 193700, loss = 0.317338
I0430 11:49:54.734660  5145 solver.cpp:244]     Train net output #0: loss = 0.317338 (* 1 = 0.317338 loss)
I0430 11:49:54.734668  5145 sgd_solver.cpp:106] Iteration 193700, lr = 1e-27
I0430 11:50:46.325727  5145 solver.cpp:228] Iteration 193800, loss = 0.195523
I0430 11:50:46.325893  5145 solver.cpp:244]     Train net output #0: loss = 0.195523 (* 1 = 0.195523 loss)
I0430 11:50:46.325901  5145 sgd_solver.cpp:106] Iteration 193800, lr = 1e-27
I0430 11:51:36.807873  5145 solver.cpp:228] Iteration 193900, loss = 0.208057
I0430 11:51:36.808032  5145 solver.cpp:244]     Train net output #0: loss = 0.208057 (* 1 = 0.208057 loss)
I0430 11:51:36.808039  5145 sgd_solver.cpp:106] Iteration 193900, lr = 1e-27
I0430 11:52:28.041854  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_194000.caffemodel
I0430 11:52:31.210463  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_194000.solverstate
I0430 11:52:31.410007  5145 solver.cpp:337] Iteration 194000, Testing net (#0)
I0430 11:52:31.410106  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 11:52:31.410110  5145 net.cpp:693] Ignoring source layer visualize
I0430 11:52:31.410114  5145 net.cpp:693] Ignoring source layer fake
I0430 11:57:26.711416  5145 solver.cpp:404]     Test net output #0: loss = 0.281531 (* 1 = 0.281531 loss)
I0430 11:57:27.024138  5145 solver.cpp:228] Iteration 194000, loss = 0.267136
I0430 11:57:27.024178  5145 solver.cpp:244]     Train net output #0: loss = 0.267136 (* 1 = 0.267136 loss)
I0430 11:57:27.024183  5145 sgd_solver.cpp:106] Iteration 194000, lr = 1e-27
I0430 11:58:17.628275  5145 solver.cpp:228] Iteration 194100, loss = 0.345434
I0430 11:58:17.628826  5145 solver.cpp:244]     Train net output #0: loss = 0.345434 (* 1 = 0.345434 loss)
I0430 11:58:17.628834  5145 sgd_solver.cpp:106] Iteration 194100, lr = 1e-27
I0430 11:59:08.160981  5145 solver.cpp:228] Iteration 194200, loss = 0.289427
I0430 11:59:08.161141  5145 solver.cpp:244]     Train net output #0: loss = 0.289427 (* 1 = 0.289427 loss)
I0430 11:59:08.161159  5145 sgd_solver.cpp:106] Iteration 194200, lr = 1e-27
I0430 12:00:00.534478  5145 solver.cpp:228] Iteration 194300, loss = 0.272102
I0430 12:00:00.534633  5145 solver.cpp:244]     Train net output #0: loss = 0.272102 (* 1 = 0.272102 loss)
I0430 12:00:00.534641  5145 sgd_solver.cpp:106] Iteration 194300, lr = 1e-27
I0430 12:00:51.113881  5145 solver.cpp:228] Iteration 194400, loss = 0.275734
I0430 12:00:51.114043  5145 solver.cpp:244]     Train net output #0: loss = 0.275734 (* 1 = 0.275734 loss)
I0430 12:00:51.114049  5145 sgd_solver.cpp:106] Iteration 194400, lr = 1e-27
I0430 12:01:43.355532  5145 solver.cpp:228] Iteration 194500, loss = 0.139065
I0430 12:01:43.355702  5145 solver.cpp:244]     Train net output #0: loss = 0.139065 (* 1 = 0.139065 loss)
I0430 12:01:43.355710  5145 sgd_solver.cpp:106] Iteration 194500, lr = 1e-27
I0430 12:02:33.792018  5145 solver.cpp:228] Iteration 194600, loss = 0.337322
I0430 12:02:33.792181  5145 solver.cpp:244]     Train net output #0: loss = 0.337322 (* 1 = 0.337322 loss)
I0430 12:02:33.792187  5145 sgd_solver.cpp:106] Iteration 194600, lr = 1e-27
I0430 12:03:24.427479  5145 solver.cpp:228] Iteration 194700, loss = 0.304405
I0430 12:03:24.427939  5145 solver.cpp:244]     Train net output #0: loss = 0.304405 (* 1 = 0.304405 loss)
I0430 12:03:24.427958  5145 sgd_solver.cpp:106] Iteration 194700, lr = 1e-27
I0430 12:04:14.848508  5145 solver.cpp:228] Iteration 194800, loss = 0.231239
I0430 12:04:14.848677  5145 solver.cpp:244]     Train net output #0: loss = 0.231239 (* 1 = 0.231239 loss)
I0430 12:04:14.848685  5145 sgd_solver.cpp:106] Iteration 194800, lr = 1e-27
I0430 12:05:07.281932  5145 solver.cpp:228] Iteration 194900, loss = 0.273521
I0430 12:05:07.282099  5145 solver.cpp:244]     Train net output #0: loss = 0.273521 (* 1 = 0.273521 loss)
I0430 12:05:07.282105  5145 sgd_solver.cpp:106] Iteration 194900, lr = 1e-27
I0430 12:05:57.414288  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_195000.caffemodel
I0430 12:06:09.235880  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_195000.solverstate
I0430 12:06:09.438377  5145 solver.cpp:337] Iteration 195000, Testing net (#0)
I0430 12:06:09.438473  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 12:06:09.438479  5145 net.cpp:693] Ignoring source layer visualize
I0430 12:06:09.438482  5145 net.cpp:693] Ignoring source layer fake
I0430 12:11:05.489347  5145 solver.cpp:404]     Test net output #0: loss = 0.281732 (* 1 = 0.281732 loss)
I0430 12:11:05.801441  5145 solver.cpp:228] Iteration 195000, loss = 0.235127
I0430 12:11:05.801466  5145 solver.cpp:244]     Train net output #0: loss = 0.235127 (* 1 = 0.235127 loss)
I0430 12:11:05.801476  5145 sgd_solver.cpp:106] Iteration 195000, lr = 1e-28
I0430 12:11:56.312822  5145 solver.cpp:228] Iteration 195100, loss = 0.163575
I0430 12:11:56.314924  5145 solver.cpp:244]     Train net output #0: loss = 0.163575 (* 1 = 0.163575 loss)
I0430 12:11:56.314950  5145 sgd_solver.cpp:106] Iteration 195100, lr = 1e-28
I0430 12:12:48.637318  5145 solver.cpp:228] Iteration 195200, loss = 0.316696
I0430 12:12:48.637490  5145 solver.cpp:244]     Train net output #0: loss = 0.316696 (* 1 = 0.316696 loss)
I0430 12:12:48.637501  5145 sgd_solver.cpp:106] Iteration 195200, lr = 1e-28
I0430 12:13:39.164317  5145 solver.cpp:228] Iteration 195300, loss = 0.208986
I0430 12:13:39.164484  5145 solver.cpp:244]     Train net output #0: loss = 0.208986 (* 1 = 0.208986 loss)
I0430 12:13:39.164494  5145 sgd_solver.cpp:106] Iteration 195300, lr = 1e-28
I0430 12:14:29.733062  5145 solver.cpp:228] Iteration 195400, loss = 0.343316
I0430 12:14:29.733175  5145 solver.cpp:244]     Train net output #0: loss = 0.343316 (* 1 = 0.343316 loss)
I0430 12:14:29.733184  5145 sgd_solver.cpp:106] Iteration 195400, lr = 1e-28
I0430 12:15:20.330960  5145 solver.cpp:228] Iteration 195500, loss = 0.312379
I0430 12:15:20.331132  5145 solver.cpp:244]     Train net output #0: loss = 0.312379 (* 1 = 0.312379 loss)
I0430 12:15:20.331141  5145 sgd_solver.cpp:106] Iteration 195500, lr = 1e-28
I0430 12:16:12.551548  5145 solver.cpp:228] Iteration 195600, loss = 0.331749
I0430 12:16:12.551699  5145 solver.cpp:244]     Train net output #0: loss = 0.331749 (* 1 = 0.331749 loss)
I0430 12:16:12.551719  5145 sgd_solver.cpp:106] Iteration 195600, lr = 1e-28
I0430 12:17:03.140539  5145 solver.cpp:228] Iteration 195700, loss = 0.178511
I0430 12:17:03.140740  5145 solver.cpp:244]     Train net output #0: loss = 0.178511 (* 1 = 0.178511 loss)
I0430 12:17:03.140758  5145 sgd_solver.cpp:106] Iteration 195700, lr = 1e-28
I0430 12:17:53.650876  5145 solver.cpp:228] Iteration 195800, loss = 0.282797
I0430 12:17:53.651021  5145 solver.cpp:244]     Train net output #0: loss = 0.282797 (* 1 = 0.282797 loss)
I0430 12:17:53.651031  5145 sgd_solver.cpp:106] Iteration 195800, lr = 1e-28
I0430 12:18:45.746103  5145 solver.cpp:228] Iteration 195900, loss = 0.310678
I0430 12:18:45.746266  5145 solver.cpp:244]     Train net output #0: loss = 0.310678 (* 1 = 0.310678 loss)
I0430 12:18:45.746275  5145 sgd_solver.cpp:106] Iteration 195900, lr = 1e-28
I0430 12:19:35.822669  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_196000.caffemodel
I0430 12:19:49.958703  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_196000.solverstate
I0430 12:19:50.161916  5145 solver.cpp:337] Iteration 196000, Testing net (#0)
I0430 12:19:50.162004  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 12:19:50.162026  5145 net.cpp:693] Ignoring source layer visualize
I0430 12:19:50.162029  5145 net.cpp:693] Ignoring source layer fake
I0430 12:24:46.007585  5145 solver.cpp:404]     Test net output #0: loss = 0.290629 (* 1 = 0.290629 loss)
I0430 12:24:46.320834  5145 solver.cpp:228] Iteration 196000, loss = 0.177801
I0430 12:24:46.320858  5145 solver.cpp:244]     Train net output #0: loss = 0.177801 (* 1 = 0.177801 loss)
I0430 12:24:46.320864  5145 sgd_solver.cpp:106] Iteration 196000, lr = 1e-28
I0430 12:25:36.851450  5145 solver.cpp:228] Iteration 196100, loss = 0.283023
I0430 12:25:36.851559  5145 solver.cpp:244]     Train net output #0: loss = 0.283023 (* 1 = 0.283023 loss)
I0430 12:25:36.851568  5145 sgd_solver.cpp:106] Iteration 196100, lr = 1e-28
I0430 12:26:29.397667  5145 solver.cpp:228] Iteration 196200, loss = 0.178218
I0430 12:26:29.397833  5145 solver.cpp:244]     Train net output #0: loss = 0.178218 (* 1 = 0.178218 loss)
I0430 12:26:29.397843  5145 sgd_solver.cpp:106] Iteration 196200, lr = 1e-28
I0430 12:27:19.809190  5145 solver.cpp:228] Iteration 196300, loss = 0.135488
I0430 12:27:19.809372  5145 solver.cpp:244]     Train net output #0: loss = 0.135488 (* 1 = 0.135488 loss)
I0430 12:27:19.809382  5145 sgd_solver.cpp:106] Iteration 196300, lr = 1e-28
I0430 12:28:10.420866  5145 solver.cpp:228] Iteration 196400, loss = 0.116198
I0430 12:28:10.421052  5145 solver.cpp:244]     Train net output #0: loss = 0.116198 (* 1 = 0.116198 loss)
I0430 12:28:10.421061  5145 sgd_solver.cpp:106] Iteration 196400, lr = 1e-28
I0430 12:29:00.882907  5145 solver.cpp:228] Iteration 196500, loss = 0.230788
I0430 12:29:00.883066  5145 solver.cpp:244]     Train net output #0: loss = 0.230788 (* 1 = 0.230788 loss)
I0430 12:29:00.883076  5145 sgd_solver.cpp:106] Iteration 196500, lr = 1e-28
I0430 12:29:53.080731  5145 solver.cpp:228] Iteration 196600, loss = 0.550231
I0430 12:29:53.080902  5145 solver.cpp:244]     Train net output #0: loss = 0.550231 (* 1 = 0.550231 loss)
I0430 12:29:53.080911  5145 sgd_solver.cpp:106] Iteration 196600, lr = 1e-28
I0430 12:30:43.595764  5145 solver.cpp:228] Iteration 196700, loss = 0.250731
I0430 12:30:43.595973  5145 solver.cpp:244]     Train net output #0: loss = 0.250731 (* 1 = 0.250731 loss)
I0430 12:30:43.595991  5145 sgd_solver.cpp:106] Iteration 196700, lr = 1e-28
I0430 12:31:34.176439  5145 solver.cpp:228] Iteration 196800, loss = 0.246615
I0430 12:31:34.177976  5145 solver.cpp:244]     Train net output #0: loss = 0.246615 (* 1 = 0.246615 loss)
I0430 12:31:34.177999  5145 sgd_solver.cpp:106] Iteration 196800, lr = 1e-28
I0430 12:32:25.857293  5145 solver.cpp:228] Iteration 196900, loss = 0.191985
I0430 12:32:25.857492  5145 solver.cpp:244]     Train net output #0: loss = 0.191985 (* 1 = 0.191985 loss)
I0430 12:32:25.857502  5145 sgd_solver.cpp:106] Iteration 196900, lr = 1e-28
I0430 12:33:15.991312  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_197000.caffemodel
I0430 12:33:33.726578  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_197000.solverstate
I0430 12:33:33.916554  5145 solver.cpp:337] Iteration 197000, Testing net (#0)
I0430 12:33:33.916662  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 12:33:33.916668  5145 net.cpp:693] Ignoring source layer visualize
I0430 12:33:33.916671  5145 net.cpp:693] Ignoring source layer fake
I0430 12:38:30.403514  5145 solver.cpp:404]     Test net output #0: loss = 0.287564 (* 1 = 0.287564 loss)
I0430 12:38:30.717854  5145 solver.cpp:228] Iteration 197000, loss = 0.187997
I0430 12:38:30.717875  5145 solver.cpp:244]     Train net output #0: loss = 0.187997 (* 1 = 0.187997 loss)
I0430 12:38:30.717883  5145 sgd_solver.cpp:106] Iteration 197000, lr = 1e-28
I0430 12:39:22.556923  5145 solver.cpp:228] Iteration 197100, loss = 0.347511
I0430 12:39:22.557103  5145 solver.cpp:244]     Train net output #0: loss = 0.347511 (* 1 = 0.347511 loss)
I0430 12:39:22.557112  5145 sgd_solver.cpp:106] Iteration 197100, lr = 1e-28
I0430 12:40:13.117172  5145 solver.cpp:228] Iteration 197200, loss = 0.250535
I0430 12:40:13.117333  5145 solver.cpp:244]     Train net output #0: loss = 0.250535 (* 1 = 0.250535 loss)
I0430 12:40:13.117344  5145 sgd_solver.cpp:106] Iteration 197200, lr = 1e-28
I0430 12:41:03.525230  5145 solver.cpp:228] Iteration 197300, loss = 0.115325
I0430 12:41:03.525390  5145 solver.cpp:244]     Train net output #0: loss = 0.115325 (* 1 = 0.115325 loss)
I0430 12:41:03.525400  5145 sgd_solver.cpp:106] Iteration 197300, lr = 1e-28
I0430 12:41:55.544476  5145 solver.cpp:228] Iteration 197400, loss = 0.236852
I0430 12:41:55.544637  5145 solver.cpp:244]     Train net output #0: loss = 0.236852 (* 1 = 0.236852 loss)
I0430 12:41:55.544648  5145 sgd_solver.cpp:106] Iteration 197400, lr = 1e-28
I0430 12:42:46.015234  5145 solver.cpp:228] Iteration 197500, loss = 0.303016
I0430 12:42:46.015413  5145 solver.cpp:244]     Train net output #0: loss = 0.303016 (* 1 = 0.303016 loss)
I0430 12:42:46.015422  5145 sgd_solver.cpp:106] Iteration 197500, lr = 1e-28
I0430 12:43:36.692200  5145 solver.cpp:228] Iteration 197600, loss = 0.226589
I0430 12:43:36.692356  5145 solver.cpp:244]     Train net output #0: loss = 0.226589 (* 1 = 0.226589 loss)
I0430 12:43:36.692368  5145 sgd_solver.cpp:106] Iteration 197600, lr = 1e-28
I0430 12:44:28.984510  5145 solver.cpp:228] Iteration 197700, loss = 0.134546
I0430 12:44:28.984714  5145 solver.cpp:244]     Train net output #0: loss = 0.134546 (* 1 = 0.134546 loss)
I0430 12:44:28.984730  5145 sgd_solver.cpp:106] Iteration 197700, lr = 1e-28
I0430 12:45:19.516681  5145 solver.cpp:228] Iteration 197800, loss = 0.168006
I0430 12:45:19.516849  5145 solver.cpp:244]     Train net output #0: loss = 0.168006 (* 1 = 0.168006 loss)
I0430 12:45:19.516858  5145 sgd_solver.cpp:106] Iteration 197800, lr = 1e-28
I0430 12:46:09.800329  5145 solver.cpp:228] Iteration 197900, loss = 0.328836
I0430 12:46:09.800505  5145 solver.cpp:244]     Train net output #0: loss = 0.328836 (* 1 = 0.328836 loss)
I0430 12:46:09.800515  5145 sgd_solver.cpp:106] Iteration 197900, lr = 1e-28
I0430 12:47:01.519421  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_198000.caffemodel
I0430 12:47:17.587406  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_198000.solverstate
I0430 12:47:17.777336  5145 solver.cpp:337] Iteration 198000, Testing net (#0)
I0430 12:47:17.777417  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 12:47:17.777420  5145 net.cpp:693] Ignoring source layer visualize
I0430 12:47:17.777422  5145 net.cpp:693] Ignoring source layer fake
I0430 12:52:14.211242  5145 solver.cpp:404]     Test net output #0: loss = 0.286028 (* 1 = 0.286028 loss)
I0430 12:52:14.524812  5145 solver.cpp:228] Iteration 198000, loss = 0.273889
I0430 12:52:14.524852  5145 solver.cpp:244]     Train net output #0: loss = 0.273889 (* 1 = 0.273889 loss)
I0430 12:52:14.524858  5145 sgd_solver.cpp:106] Iteration 198000, lr = 1e-28
I0430 12:53:05.037963  5145 solver.cpp:228] Iteration 198100, loss = 0.391195
I0430 12:53:05.038130  5145 solver.cpp:244]     Train net output #0: loss = 0.391195 (* 1 = 0.391195 loss)
I0430 12:53:05.038141  5145 sgd_solver.cpp:106] Iteration 198100, lr = 1e-28
I0430 12:53:55.587972  5145 solver.cpp:228] Iteration 198200, loss = 0.190594
I0430 12:53:55.588145  5145 solver.cpp:244]     Train net output #0: loss = 0.190594 (* 1 = 0.190594 loss)
I0430 12:53:55.588153  5145 sgd_solver.cpp:106] Iteration 198200, lr = 1e-28
I0430 12:54:46.202980  5145 solver.cpp:228] Iteration 198300, loss = 0.283667
I0430 12:54:46.203143  5145 solver.cpp:244]     Train net output #0: loss = 0.283667 (* 1 = 0.283667 loss)
I0430 12:54:46.203155  5145 sgd_solver.cpp:106] Iteration 198300, lr = 1e-28
I0430 12:55:38.414659  5145 solver.cpp:228] Iteration 198400, loss = 0.33397
I0430 12:55:38.415169  5145 solver.cpp:244]     Train net output #0: loss = 0.33397 (* 1 = 0.33397 loss)
I0430 12:55:38.415177  5145 sgd_solver.cpp:106] Iteration 198400, lr = 1e-28
I0430 12:56:28.983348  5145 solver.cpp:228] Iteration 198500, loss = 0.410859
I0430 12:56:28.984681  5145 solver.cpp:244]     Train net output #0: loss = 0.410859 (* 1 = 0.410859 loss)
I0430 12:56:28.984694  5145 sgd_solver.cpp:106] Iteration 198500, lr = 1e-28
I0430 12:57:19.583748  5145 solver.cpp:228] Iteration 198600, loss = 0.283449
I0430 12:57:19.583947  5145 solver.cpp:244]     Train net output #0: loss = 0.283449 (* 1 = 0.283449 loss)
I0430 12:57:19.583959  5145 sgd_solver.cpp:106] Iteration 198600, lr = 1e-28
I0430 12:58:11.793306  5145 solver.cpp:228] Iteration 198700, loss = 0.240646
I0430 12:58:11.793540  5145 solver.cpp:244]     Train net output #0: loss = 0.240646 (* 1 = 0.240646 loss)
I0430 12:58:11.793552  5145 sgd_solver.cpp:106] Iteration 198700, lr = 1e-28
I0430 12:59:02.296644  5145 solver.cpp:228] Iteration 198800, loss = 0.280417
I0430 12:59:02.296829  5145 solver.cpp:244]     Train net output #0: loss = 0.280417 (* 1 = 0.280417 loss)
I0430 12:59:02.296836  5145 sgd_solver.cpp:106] Iteration 198800, lr = 1e-28
I0430 12:59:52.759275  5145 solver.cpp:228] Iteration 198900, loss = 0.209472
I0430 12:59:52.759438  5145 solver.cpp:244]     Train net output #0: loss = 0.209472 (* 1 = 0.209472 loss)
I0430 12:59:52.759444  5145 sgd_solver.cpp:106] Iteration 198900, lr = 1e-28
I0430 13:00:44.661332  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_199000.caffemodel
I0430 13:00:54.510833  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_199000.solverstate
I0430 13:00:54.704661  5145 solver.cpp:337] Iteration 199000, Testing net (#0)
I0430 13:00:54.704761  5145 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0430 13:00:54.704766  5145 net.cpp:693] Ignoring source layer visualize
I0430 13:00:54.704767  5145 net.cpp:693] Ignoring source layer fake
I0430 13:05:50.608902  5145 solver.cpp:404]     Test net output #0: loss = 0.281148 (* 1 = 0.281148 loss)
I0430 13:05:50.922503  5145 solver.cpp:228] Iteration 199000, loss = 0.291523
I0430 13:05:50.922540  5145 solver.cpp:244]     Train net output #0: loss = 0.291523 (* 1 = 0.291523 loss)
I0430 13:05:50.922547  5145 sgd_solver.cpp:106] Iteration 199000, lr = 1e-28
I0430 13:06:41.398847  5145 solver.cpp:228] Iteration 199100, loss = 0.176224
I0430 13:06:41.399014  5145 solver.cpp:244]     Train net output #0: loss = 0.176224 (* 1 = 0.176224 loss)
I0430 13:06:41.399020  5145 sgd_solver.cpp:106] Iteration 199100, lr = 1e-28
I0430 13:07:31.951809  5145 solver.cpp:228] Iteration 199200, loss = 0.23563
I0430 13:07:31.951982  5145 solver.cpp:244]     Train net output #0: loss = 0.23563 (* 1 = 0.23563 loss)
I0430 13:07:31.951988  5145 sgd_solver.cpp:106] Iteration 199200, lr = 1e-28
I0430 13:08:22.548264  5145 solver.cpp:228] Iteration 199300, loss = 0.0915129
I0430 13:08:22.548424  5145 solver.cpp:244]     Train net output #0: loss = 0.0915129 (* 1 = 0.0915129 loss)
I0430 13:08:22.548432  5145 sgd_solver.cpp:106] Iteration 199300, lr = 1e-28
I0430 13:09:14.944655  5145 solver.cpp:228] Iteration 199400, loss = 0.278889
I0430 13:09:14.944815  5145 solver.cpp:244]     Train net output #0: loss = 0.278889 (* 1 = 0.278889 loss)
I0430 13:09:14.944823  5145 sgd_solver.cpp:106] Iteration 199400, lr = 1e-28
I0430 13:10:05.569969  5145 solver.cpp:228] Iteration 199500, loss = 0.262898
I0430 13:10:05.570935  5145 solver.cpp:244]     Train net output #0: loss = 0.262898 (* 1 = 0.262898 loss)
I0430 13:10:05.570960  5145 sgd_solver.cpp:106] Iteration 199500, lr = 1e-28
I0430 13:10:56.098256  5145 solver.cpp:228] Iteration 199600, loss = 0.210482
I0430 13:10:56.098423  5145 solver.cpp:244]     Train net output #0: loss = 0.210482 (* 1 = 0.210482 loss)
I0430 13:10:56.098433  5145 sgd_solver.cpp:106] Iteration 199600, lr = 1e-28
I0430 13:11:48.197863  5145 solver.cpp:228] Iteration 199700, loss = 0.118434
I0430 13:11:48.198056  5145 solver.cpp:244]     Train net output #0: loss = 0.118434 (* 1 = 0.118434 loss)
I0430 13:11:48.198068  5145 sgd_solver.cpp:106] Iteration 199700, lr = 1e-28
I0430 13:12:38.684852  5145 solver.cpp:228] Iteration 199800, loss = 0.714342
I0430 13:12:38.685010  5145 solver.cpp:244]     Train net output #0: loss = 0.714342 (* 1 = 0.714342 loss)
I0430 13:12:38.685016  5145 sgd_solver.cpp:106] Iteration 199800, lr = 1e-28
I0430 13:13:29.115386  5145 solver.cpp:228] Iteration 199900, loss = 0.254206
I0430 13:13:29.115540  5145 solver.cpp:244]     Train net output #0: loss = 0.254206 (* 1 = 0.254206 loss)
I0430 13:13:29.115545  5145 sgd_solver.cpp:106] Iteration 199900, lr = 1e-28
I0430 13:14:20.531774  5145 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_200000.caffemodel
I0430 13:14:24.746366  5145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_batchnorm_4/unet_weighted_batchnorm_4_iter_200000.solverstate
