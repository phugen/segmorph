I0422 22:48:56.586175 30295 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3456
test_interval: 1000
base_lr: 0.0001
display: 100
max_iter: 300000
lr_policy: "step"
gamma: 0.3
momentum: 0.99
stepsize: 20000
snapshot: 5000
snapshot_prefix: "./snapshots/unet_f1_4/unet_f1_4"
solver_mode: GPU
net: "./unet_f1_4/unet_f1_4.prototxt"
regularization_type: "L2"
test_initialization: true
iter_size: 1
I0422 22:48:56.594096 30295 solver.cpp:91] Creating training net from net file: ./unet_f1_4/unet_f1_4.prototxt
I0422 22:48:56.595330 30295 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer loaddata
I0422 22:48:56.596065 30295 net.cpp:58] Initializing net from parameters: 
name: "unet_f1_4"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "caffeHDF5_4.txt"
    batch_size: 5
  }
}
layer {
  name: "conv_d0a-b"
  type: "Convolution"
  bottom: "data"
  top: "d0b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0b"
  type: "ReLU"
  bottom: "d0b"
  top: "d0b"
}
layer {
  name: "conv_d0b-c"
  type: "Convolution"
  bottom: "d0b"
  top: "d0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0c"
  type: "ReLU"
  bottom: "d0c"
  top: "d0c"
}
layer {
  name: "pool_d0c-1a"
  type: "Pooling"
  bottom: "d0c"
  top: "d1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d1a-b"
  type: "Convolution"
  bottom: "d1a"
  top: "d1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1b"
  type: "ReLU"
  bottom: "d1b"
  top: "d1b"
}
layer {
  name: "conv_d1b-c"
  type: "Convolution"
  bottom: "d1b"
  top: "d1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1c"
  type: "ReLU"
  bottom: "d1c"
  top: "d1c"
}
layer {
  name: "pool_d1c-2a"
  type: "Pooling"
  bottom: "d1c"
  top: "d2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d2a-b"
  type: "Convolution"
  bottom: "d2a"
  top: "d2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2b"
  type: "ReLU"
  bottom: "d2b"
  top: "d2b"
}
layer {
  name: "conv_d2b-c"
  type: "Convolution"
  bottom: "d2b"
  top: "d2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2c"
  type: "ReLU"
  bottom: "d2c"
  top: "d2c"
}
layer {
  name: "pool_d2c-3a"
  type: "Pooling"
  bottom: "d2c"
  top: "d3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d3a-b"
  type: "Convolution"
  bottom: "d3a"
  top: "d3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3b"
  type: "ReLU"
  bottom: "d3b"
  top: "d3b"
}
layer {
  name: "conv_d3b-c"
  type: "Convolution"
  bottom: "d3b"
  top: "d3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3c"
  type: "ReLU"
  bottom: "d3c"
  top: "d3c"
}
layer {
  name: "dropout_d3c"
  type: "Dropout"
  bottom: "d3c"
  top: "d3c"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool_d3c-4a"
  type: "Pooling"
  bottom: "d3c"
  top: "d4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d4a-b"
  type: "Convolution"
  bottom: "d4a"
  top: "d4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4b"
  type: "ReLU"
  bottom: "d4b"
  top: "d4b"
}
layer {
  name: "conv_d4b-c"
  type: "Convolution"
  bottom: "d4b"
  top: "d4c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4c"
  type: "ReLU"
  bottom: "d4c"
  top: "d4c"
}
layer {
  name: "dropout_d4c"
  type: "Dropout"
  bottom: "d4c"
  top: "d4c"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upconv_d4c_u3a"
  type: "Deconvolution"
  bottom: "d4c"
  top: "u3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u3a"
  type: "ReLU"
  bottom: "u3a"
  top: "u3a"
}
layer {
  name: "crop_d3c-d3cc"
  type: "Crop"
  bottom: "d3c"
  bottom: "u3a"
  top: "d3cc"
  crop_param {
    axis: 2
    offset: 4
  }
}
layer {
  name: "concat_d3cc_u3a-b"
  type: "Concat"
  bottom: "u3a"
  bottom: "d3cc"
  top: "u3b"
}
layer {
  name: "conv_u3b-c"
  type: "Convolution"
  bottom: "u3b"
  top: "u3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3c"
  type: "ReLU"
  bottom: "u3c"
  top: "u3c"
}
layer {
  name: "conv_u3c-d"
  type: "Convolution"
  bottom: "u3c"
  top: "u3d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3d"
  type: "ReLU"
  bottom: "u3d"
  top: "u3d"
}
layer {
  name: "upconv_u3d_u2a"
  type: "Deconvolution"
  bottom: "u3d"
  top: "u2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u2a"
  type: "ReLU"
  bottom: "u2a"
  top: "u2a"
}
layer {
  name: "crop_d2c-d2cc"
  type: "Crop"
  bottom: "d2c"
  bottom: "u2a"
  top: "d2cc"
  crop_param {
    axis: 2
    offset: 16
  }
}
layer {
  name: "concat_d2cc_u2a-b"
  type: "Concat"
  bottom: "u2a"
  bottom: "d2cc"
  top: "u2b"
}
layer {
  name: "conv_u2b-c"
  type: "Convolution"
  bottom: "u2b"
  top: "u2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2c"
  type: "ReLU"
  bottom: "u2c"
  top: "u2c"
}
layer {
  name: "conv_u2c-d"
  type: "Convolution"
  bottom: "u2c"
  top: "u2d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2d"
  type: "ReLU"
  bottom: "u2d"
  top: "u2d"
}
layer {
  name: "upconv_u2d_u1a"
  type: "Deconvolution"
  bottom: "u2d"
  top: "u1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u1a"
  type: "ReLU"
  bottom: "u1a"
  top: "u1a"
}
layer {
  name: "crop_d1c-d1cc"
  type: "Crop"
  bottom: "d1c"
  bottom: "u1a"
  top: "d1cc"
  crop_param {
    axis: 2
    offset: 40
  }
}
layer {
  name: "concat_d1cc_u1a-b"
  type: "Concat"
  bottom: "u1a"
  bottom: "d1cc"
  top: "u1b"
}
layer {
  name: "conv_u1b-c"
  type: "Convolution"
  bottom: "u1b"
  top: "u1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1c"
  type: "ReLU"
  bottom: "u1c"
  top: "u1c"
}
layer {
  name: "conv_u1c-d"
  type: "Convolution"
  bottom: "u1c"
  top: "u1d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1d"
  type: "ReLU"
  bottom: "u1d"
  top: "u1d"
}
layer {
  name: "upconv_u1d_u0a"
  type: "Deconvolution"
  bottom: "u1d"
  top: "u0a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u0a"
  type: "ReLU"
  bottom: "u0a"
  top: "u0a"
}
layer {
  name: "crop_d0c-d0cc"
  type: "Crop"
  bottom: "d0c"
  bottom: "u0a"
  top: "d0cc"
  crop_param {
    axis: 2
    offset: 88
  }
}
layer {
  name: "concat_d0cc_u0a-b"
  type: "Concat"
  bottom: "u0a"
  bottom: "d0cc"
  top: "u0b"
}
layer {
  name: "conv_u0b-c"
  type: "Convolution"
  bottom: "u0b"
  top: "u0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0c"
  type: "ReLU"
  bottom: "u0c"
  top: "u0c"
}
layer {
  name: "conv_u0c-d"
  type: "Convolution"
  bottom: "u0c"
  top: "u0d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0d"
  type: "ReLU"
  bottom: "u0d"
  top: "u0d"
}
layer {
  name: "conv_u0d-score"
  type: "Convolution"
  bottom: "u0d"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "score"
  top: "softmax_out"
}
layer {
  name: "reshapelab"
  type: "Reshape"
  bottom: "label"
  top: "label_flat"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "reshaperes"
  type: "Reshape"
  bottom: "softmax_out"
  top: "softmax_out_flat"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "loss"
  type: "Python"
  bottom: "softmax_out_flat"
  bottom: "label_flat"
  top: "loss"
  loss_weight: 1
  python_param {
    module: "multiclass_f1_loss"
    layer: "F1Loss"
  }
}
layer {
  name: "visualize"
  type: "Softmax"
  bottom: "score"
  top: "visualize_out"
  include {
    phase: TRAIN
  }
}
layer {
  name: "fake"
  type: "Silence"
  bottom: "visualize_out"
  include {
    phase: TRAIN
  }
}
I0422 22:48:56.596693 30295 layer_factory.hpp:77] Creating layer loaddata
I0422 22:48:56.596714 30295 net.cpp:100] Creating Layer loaddata
I0422 22:48:56.596735 30295 net.cpp:408] loaddata -> data
I0422 22:48:56.596760 30295 net.cpp:408] loaddata -> label
I0422 22:48:56.596771 30295 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: caffeHDF5_4.txt
I0422 22:48:56.599552 30295 hdf5_data_layer.cpp:93] Number of HDF5 files: 20
I0422 22:48:56.601254 30295 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0422 22:48:57.672313 30295 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0422 22:48:57.781744 30295 net.cpp:150] Setting up loaddata
I0422 22:48:57.781785 30295 net.cpp:157] Top shape: 5 3 428 428 (2747760)
I0422 22:48:57.781790 30295 net.cpp:157] Top shape: 5 244 244 (297680)
I0422 22:48:57.781791 30295 net.cpp:165] Memory required for data: 12181760
I0422 22:48:57.781796 30295 layer_factory.hpp:77] Creating layer conv_d0a-b
I0422 22:48:57.781812 30295 net.cpp:100] Creating Layer conv_d0a-b
I0422 22:48:57.781816 30295 net.cpp:434] conv_d0a-b <- data
I0422 22:48:57.781821 30295 net.cpp:408] conv_d0a-b -> d0b
I0422 22:48:57.784173 30295 net.cpp:150] Setting up conv_d0a-b
I0422 22:48:57.784188 30295 net.cpp:157] Top shape: 5 64 426 426 (58072320)
I0422 22:48:57.784205 30295 net.cpp:165] Memory required for data: 244471040
I0422 22:48:57.784214 30295 layer_factory.hpp:77] Creating layer relu_d0b
I0422 22:48:57.784220 30295 net.cpp:100] Creating Layer relu_d0b
I0422 22:48:57.784224 30295 net.cpp:434] relu_d0b <- d0b
I0422 22:48:57.784227 30295 net.cpp:395] relu_d0b -> d0b (in-place)
I0422 22:48:57.981281 30295 net.cpp:150] Setting up relu_d0b
I0422 22:48:57.981322 30295 net.cpp:157] Top shape: 5 64 426 426 (58072320)
I0422 22:48:57.981324 30295 net.cpp:165] Memory required for data: 476760320
I0422 22:48:57.981329 30295 layer_factory.hpp:77] Creating layer conv_d0b-c
I0422 22:48:57.981343 30295 net.cpp:100] Creating Layer conv_d0b-c
I0422 22:48:57.981346 30295 net.cpp:434] conv_d0b-c <- d0b
I0422 22:48:57.981353 30295 net.cpp:408] conv_d0b-c -> d0c
I0422 22:48:57.982837 30295 net.cpp:150] Setting up conv_d0b-c
I0422 22:48:57.982851 30295 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0422 22:48:57.982868 30295 net.cpp:165] Memory required for data: 706873600
I0422 22:48:57.982878 30295 layer_factory.hpp:77] Creating layer relu_d0c
I0422 22:48:57.982885 30295 net.cpp:100] Creating Layer relu_d0c
I0422 22:48:57.982887 30295 net.cpp:434] relu_d0c <- d0c
I0422 22:48:57.982892 30295 net.cpp:395] relu_d0c -> d0c (in-place)
I0422 22:48:57.983683 30295 net.cpp:150] Setting up relu_d0c
I0422 22:48:57.983695 30295 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0422 22:48:57.983697 30295 net.cpp:165] Memory required for data: 936986880
I0422 22:48:57.983716 30295 layer_factory.hpp:77] Creating layer d0c_relu_d0c_0_split
I0422 22:48:57.983721 30295 net.cpp:100] Creating Layer d0c_relu_d0c_0_split
I0422 22:48:57.983723 30295 net.cpp:434] d0c_relu_d0c_0_split <- d0c
I0422 22:48:57.983727 30295 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_0
I0422 22:48:57.983736 30295 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_1
I0422 22:48:57.983784 30295 net.cpp:150] Setting up d0c_relu_d0c_0_split
I0422 22:48:57.983788 30295 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0422 22:48:57.983791 30295 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0422 22:48:57.983808 30295 net.cpp:165] Memory required for data: 1397213440
I0422 22:48:57.983811 30295 layer_factory.hpp:77] Creating layer pool_d0c-1a
I0422 22:48:57.983816 30295 net.cpp:100] Creating Layer pool_d0c-1a
I0422 22:48:57.983819 30295 net.cpp:434] pool_d0c-1a <- d0c_relu_d0c_0_split_0
I0422 22:48:57.983822 30295 net.cpp:408] pool_d0c-1a -> d1a
I0422 22:48:57.983850 30295 net.cpp:150] Setting up pool_d0c-1a
I0422 22:48:57.983856 30295 net.cpp:157] Top shape: 5 64 212 212 (14382080)
I0422 22:48:57.983860 30295 net.cpp:165] Memory required for data: 1454741760
I0422 22:48:57.983861 30295 layer_factory.hpp:77] Creating layer conv_d1a-b
I0422 22:48:57.983870 30295 net.cpp:100] Creating Layer conv_d1a-b
I0422 22:48:57.983871 30295 net.cpp:434] conv_d1a-b <- d1a
I0422 22:48:57.983875 30295 net.cpp:408] conv_d1a-b -> d1b
I0422 22:48:57.984484 30295 net.cpp:150] Setting up conv_d1a-b
I0422 22:48:57.984493 30295 net.cpp:157] Top shape: 5 128 210 210 (28224000)
I0422 22:48:57.984494 30295 net.cpp:165] Memory required for data: 1567637760
I0422 22:48:57.984516 30295 layer_factory.hpp:77] Creating layer relu_d1b
I0422 22:48:57.984522 30295 net.cpp:100] Creating Layer relu_d1b
I0422 22:48:57.984525 30295 net.cpp:434] relu_d1b <- d1b
I0422 22:48:57.984529 30295 net.cpp:395] relu_d1b -> d1b (in-place)
I0422 22:48:57.984685 30295 net.cpp:150] Setting up relu_d1b
I0422 22:48:57.984694 30295 net.cpp:157] Top shape: 5 128 210 210 (28224000)
I0422 22:48:57.984696 30295 net.cpp:165] Memory required for data: 1680533760
I0422 22:48:57.984699 30295 layer_factory.hpp:77] Creating layer conv_d1b-c
I0422 22:48:57.984704 30295 net.cpp:100] Creating Layer conv_d1b-c
I0422 22:48:57.984706 30295 net.cpp:434] conv_d1b-c <- d1b
I0422 22:48:57.984711 30295 net.cpp:408] conv_d1b-c -> d1c
I0422 22:48:57.987377 30295 net.cpp:150] Setting up conv_d1b-c
I0422 22:48:57.987392 30295 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0422 22:48:57.987411 30295 net.cpp:165] Memory required for data: 1791289600
I0422 22:48:57.987416 30295 layer_factory.hpp:77] Creating layer relu_d1c
I0422 22:48:57.987421 30295 net.cpp:100] Creating Layer relu_d1c
I0422 22:48:57.987424 30295 net.cpp:434] relu_d1c <- d1c
I0422 22:48:57.987428 30295 net.cpp:395] relu_d1c -> d1c (in-place)
I0422 22:48:57.987601 30295 net.cpp:150] Setting up relu_d1c
I0422 22:48:57.987612 30295 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0422 22:48:57.987614 30295 net.cpp:165] Memory required for data: 1902045440
I0422 22:48:57.987617 30295 layer_factory.hpp:77] Creating layer d1c_relu_d1c_0_split
I0422 22:48:57.987622 30295 net.cpp:100] Creating Layer d1c_relu_d1c_0_split
I0422 22:48:57.987624 30295 net.cpp:434] d1c_relu_d1c_0_split <- d1c
I0422 22:48:57.987628 30295 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_0
I0422 22:48:57.987635 30295 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_1
I0422 22:48:57.987673 30295 net.cpp:150] Setting up d1c_relu_d1c_0_split
I0422 22:48:57.987680 30295 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0422 22:48:57.987684 30295 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0422 22:48:57.987686 30295 net.cpp:165] Memory required for data: 2123557120
I0422 22:48:57.987689 30295 layer_factory.hpp:77] Creating layer pool_d1c-2a
I0422 22:48:57.987694 30295 net.cpp:100] Creating Layer pool_d1c-2a
I0422 22:48:57.987696 30295 net.cpp:434] pool_d1c-2a <- d1c_relu_d1c_0_split_0
I0422 22:48:57.987700 30295 net.cpp:408] pool_d1c-2a -> d2a
I0422 22:48:57.987732 30295 net.cpp:150] Setting up pool_d1c-2a
I0422 22:48:57.987738 30295 net.cpp:157] Top shape: 5 128 104 104 (6922240)
I0422 22:48:57.987741 30295 net.cpp:165] Memory required for data: 2151246080
I0422 22:48:57.987743 30295 layer_factory.hpp:77] Creating layer conv_d2a-b
I0422 22:48:57.987751 30295 net.cpp:100] Creating Layer conv_d2a-b
I0422 22:48:57.987754 30295 net.cpp:434] conv_d2a-b <- d2a
I0422 22:48:57.987758 30295 net.cpp:408] conv_d2a-b -> d2b
I0422 22:48:57.990201 30295 net.cpp:150] Setting up conv_d2a-b
I0422 22:48:57.990214 30295 net.cpp:157] Top shape: 5 256 102 102 (13317120)
I0422 22:48:57.990216 30295 net.cpp:165] Memory required for data: 2204514560
I0422 22:48:57.990242 30295 layer_factory.hpp:77] Creating layer relu_d2b
I0422 22:48:57.990245 30295 net.cpp:100] Creating Layer relu_d2b
I0422 22:48:57.990248 30295 net.cpp:434] relu_d2b <- d2b
I0422 22:48:57.990253 30295 net.cpp:395] relu_d2b -> d2b (in-place)
I0422 22:48:57.990417 30295 net.cpp:150] Setting up relu_d2b
I0422 22:48:57.990427 30295 net.cpp:157] Top shape: 5 256 102 102 (13317120)
I0422 22:48:57.990429 30295 net.cpp:165] Memory required for data: 2257783040
I0422 22:48:57.990432 30295 layer_factory.hpp:77] Creating layer conv_d2b-c
I0422 22:48:57.990439 30295 net.cpp:100] Creating Layer conv_d2b-c
I0422 22:48:57.990442 30295 net.cpp:434] conv_d2b-c <- d2b
I0422 22:48:57.990447 30295 net.cpp:408] conv_d2b-c -> d2c
I0422 22:48:57.994381 30295 net.cpp:150] Setting up conv_d2b-c
I0422 22:48:57.994393 30295 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0422 22:48:57.994411 30295 net.cpp:165] Memory required for data: 2308983040
I0422 22:48:57.994417 30295 layer_factory.hpp:77] Creating layer relu_d2c
I0422 22:48:57.994426 30295 net.cpp:100] Creating Layer relu_d2c
I0422 22:48:57.994431 30295 net.cpp:434] relu_d2c <- d2c
I0422 22:48:57.994434 30295 net.cpp:395] relu_d2c -> d2c (in-place)
I0422 22:48:57.995133 30295 net.cpp:150] Setting up relu_d2c
I0422 22:48:57.995146 30295 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0422 22:48:57.995148 30295 net.cpp:165] Memory required for data: 2360183040
I0422 22:48:57.995167 30295 layer_factory.hpp:77] Creating layer d2c_relu_d2c_0_split
I0422 22:48:57.995173 30295 net.cpp:100] Creating Layer d2c_relu_d2c_0_split
I0422 22:48:57.995175 30295 net.cpp:434] d2c_relu_d2c_0_split <- d2c
I0422 22:48:57.995182 30295 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_0
I0422 22:48:57.995189 30295 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_1
I0422 22:48:57.995231 30295 net.cpp:150] Setting up d2c_relu_d2c_0_split
I0422 22:48:57.995236 30295 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0422 22:48:57.995239 30295 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0422 22:48:57.995241 30295 net.cpp:165] Memory required for data: 2462583040
I0422 22:48:57.995245 30295 layer_factory.hpp:77] Creating layer pool_d2c-3a
I0422 22:48:57.995251 30295 net.cpp:100] Creating Layer pool_d2c-3a
I0422 22:48:57.995254 30295 net.cpp:434] pool_d2c-3a <- d2c_relu_d2c_0_split_0
I0422 22:48:57.995259 30295 net.cpp:408] pool_d2c-3a -> d3a
I0422 22:48:57.995296 30295 net.cpp:150] Setting up pool_d2c-3a
I0422 22:48:57.995304 30295 net.cpp:157] Top shape: 5 256 50 50 (3200000)
I0422 22:48:57.995306 30295 net.cpp:165] Memory required for data: 2475383040
I0422 22:48:57.995308 30295 layer_factory.hpp:77] Creating layer conv_d3a-b
I0422 22:48:57.995316 30295 net.cpp:100] Creating Layer conv_d3a-b
I0422 22:48:57.995318 30295 net.cpp:434] conv_d3a-b <- d3a
I0422 22:48:57.995327 30295 net.cpp:408] conv_d3a-b -> d3b
I0422 22:48:58.003480 30295 net.cpp:150] Setting up conv_d3a-b
I0422 22:48:58.003494 30295 net.cpp:157] Top shape: 5 512 48 48 (5898240)
I0422 22:48:58.003512 30295 net.cpp:165] Memory required for data: 2498976000
I0422 22:48:58.003517 30295 layer_factory.hpp:77] Creating layer relu_d3b
I0422 22:48:58.003522 30295 net.cpp:100] Creating Layer relu_d3b
I0422 22:48:58.003525 30295 net.cpp:434] relu_d3b <- d3b
I0422 22:48:58.003531 30295 net.cpp:395] relu_d3b -> d3b (in-place)
I0422 22:48:58.003728 30295 net.cpp:150] Setting up relu_d3b
I0422 22:48:58.003738 30295 net.cpp:157] Top shape: 5 512 48 48 (5898240)
I0422 22:48:58.003741 30295 net.cpp:165] Memory required for data: 2522568960
I0422 22:48:58.003743 30295 layer_factory.hpp:77] Creating layer conv_d3b-c
I0422 22:48:58.003751 30295 net.cpp:100] Creating Layer conv_d3b-c
I0422 22:48:58.003754 30295 net.cpp:434] conv_d3b-c <- d3b
I0422 22:48:58.003760 30295 net.cpp:408] conv_d3b-c -> d3c
I0422 22:48:58.018442 30295 net.cpp:150] Setting up conv_d3b-c
I0422 22:48:58.018455 30295 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0422 22:48:58.018456 30295 net.cpp:165] Memory required for data: 2544236800
I0422 22:48:58.018478 30295 layer_factory.hpp:77] Creating layer relu_d3c
I0422 22:48:58.018484 30295 net.cpp:100] Creating Layer relu_d3c
I0422 22:48:58.018487 30295 net.cpp:434] relu_d3c <- d3c
I0422 22:48:58.018491 30295 net.cpp:395] relu_d3c -> d3c (in-place)
I0422 22:48:58.018671 30295 net.cpp:150] Setting up relu_d3c
I0422 22:48:58.018681 30295 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0422 22:48:58.018682 30295 net.cpp:165] Memory required for data: 2565904640
I0422 22:48:58.018685 30295 layer_factory.hpp:77] Creating layer dropout_d3c
I0422 22:48:58.018693 30295 net.cpp:100] Creating Layer dropout_d3c
I0422 22:48:58.018695 30295 net.cpp:434] dropout_d3c <- d3c
I0422 22:48:58.018700 30295 net.cpp:395] dropout_d3c -> d3c (in-place)
I0422 22:48:58.018740 30295 net.cpp:150] Setting up dropout_d3c
I0422 22:48:58.018765 30295 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0422 22:48:58.018767 30295 net.cpp:165] Memory required for data: 2587572480
I0422 22:48:58.018769 30295 layer_factory.hpp:77] Creating layer d3c_dropout_d3c_0_split
I0422 22:48:58.018776 30295 net.cpp:100] Creating Layer d3c_dropout_d3c_0_split
I0422 22:48:58.018779 30295 net.cpp:434] d3c_dropout_d3c_0_split <- d3c
I0422 22:48:58.018784 30295 net.cpp:408] d3c_dropout_d3c_0_split -> d3c_dropout_d3c_0_split_0
I0422 22:48:58.018790 30295 net.cpp:408] d3c_dropout_d3c_0_split -> d3c_dropout_d3c_0_split_1
I0422 22:48:58.018826 30295 net.cpp:150] Setting up d3c_dropout_d3c_0_split
I0422 22:48:58.018832 30295 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0422 22:48:58.018836 30295 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0422 22:48:58.018838 30295 net.cpp:165] Memory required for data: 2630908160
I0422 22:48:58.018841 30295 layer_factory.hpp:77] Creating layer pool_d3c-4a
I0422 22:48:58.018848 30295 net.cpp:100] Creating Layer pool_d3c-4a
I0422 22:48:58.018851 30295 net.cpp:434] pool_d3c-4a <- d3c_dropout_d3c_0_split_0
I0422 22:48:58.018854 30295 net.cpp:408] pool_d3c-4a -> d4a
I0422 22:48:58.018889 30295 net.cpp:150] Setting up pool_d3c-4a
I0422 22:48:58.018896 30295 net.cpp:157] Top shape: 5 512 23 23 (1354240)
I0422 22:48:58.018899 30295 net.cpp:165] Memory required for data: 2636325120
I0422 22:48:58.018901 30295 layer_factory.hpp:77] Creating layer conv_d4a-b
I0422 22:48:58.018908 30295 net.cpp:100] Creating Layer conv_d4a-b
I0422 22:48:58.018913 30295 net.cpp:434] conv_d4a-b <- d4a
I0422 22:48:58.018916 30295 net.cpp:408] conv_d4a-b -> d4b
I0422 22:48:58.047088 30295 net.cpp:150] Setting up conv_d4a-b
I0422 22:48:58.047102 30295 net.cpp:157] Top shape: 5 1024 21 21 (2257920)
I0422 22:48:58.047122 30295 net.cpp:165] Memory required for data: 2645356800
I0422 22:48:58.047132 30295 layer_factory.hpp:77] Creating layer relu_d4b
I0422 22:48:58.047137 30295 net.cpp:100] Creating Layer relu_d4b
I0422 22:48:58.047140 30295 net.cpp:434] relu_d4b <- d4b
I0422 22:48:58.047145 30295 net.cpp:395] relu_d4b -> d4b (in-place)
I0422 22:48:58.047955 30295 net.cpp:150] Setting up relu_d4b
I0422 22:48:58.047966 30295 net.cpp:157] Top shape: 5 1024 21 21 (2257920)
I0422 22:48:58.047967 30295 net.cpp:165] Memory required for data: 2654388480
I0422 22:48:58.047986 30295 layer_factory.hpp:77] Creating layer conv_d4b-c
I0422 22:48:58.047996 30295 net.cpp:100] Creating Layer conv_d4b-c
I0422 22:48:58.047997 30295 net.cpp:434] conv_d4b-c <- d4b
I0422 22:48:58.048007 30295 net.cpp:408] conv_d4b-c -> d4c
I0422 22:48:58.103507 30295 net.cpp:150] Setting up conv_d4b-c
I0422 22:48:58.103543 30295 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0422 22:48:58.103545 30295 net.cpp:165] Memory required for data: 2661781760
I0422 22:48:58.103554 30295 layer_factory.hpp:77] Creating layer relu_d4c
I0422 22:48:58.103561 30295 net.cpp:100] Creating Layer relu_d4c
I0422 22:48:58.103564 30295 net.cpp:434] relu_d4c <- d4c
I0422 22:48:58.103569 30295 net.cpp:395] relu_d4c -> d4c (in-place)
I0422 22:48:58.103828 30295 net.cpp:150] Setting up relu_d4c
I0422 22:48:58.103839 30295 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0422 22:48:58.103842 30295 net.cpp:165] Memory required for data: 2669175040
I0422 22:48:58.103843 30295 layer_factory.hpp:77] Creating layer dropout_d4c
I0422 22:48:58.103850 30295 net.cpp:100] Creating Layer dropout_d4c
I0422 22:48:58.103854 30295 net.cpp:434] dropout_d4c <- d4c
I0422 22:48:58.103860 30295 net.cpp:395] dropout_d4c -> d4c (in-place)
I0422 22:48:58.103890 30295 net.cpp:150] Setting up dropout_d4c
I0422 22:48:58.103898 30295 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0422 22:48:58.103900 30295 net.cpp:165] Memory required for data: 2676568320
I0422 22:48:58.103902 30295 layer_factory.hpp:77] Creating layer upconv_d4c_u3a
I0422 22:48:58.103909 30295 net.cpp:100] Creating Layer upconv_d4c_u3a
I0422 22:48:58.103912 30295 net.cpp:434] upconv_d4c_u3a <- d4c
I0422 22:48:58.103952 30295 net.cpp:408] upconv_d4c_u3a -> u3a
I0422 22:48:58.117014 30295 net.cpp:150] Setting up upconv_d4c_u3a
I0422 22:48:58.117027 30295 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0422 22:48:58.117045 30295 net.cpp:165] Memory required for data: 2691354880
I0422 22:48:58.117051 30295 layer_factory.hpp:77] Creating layer relu_u3a
I0422 22:48:58.117063 30295 net.cpp:100] Creating Layer relu_u3a
I0422 22:48:58.117065 30295 net.cpp:434] relu_u3a <- u3a
I0422 22:48:58.117069 30295 net.cpp:395] relu_u3a -> u3a (in-place)
I0422 22:48:58.117264 30295 net.cpp:150] Setting up relu_u3a
I0422 22:48:58.117274 30295 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0422 22:48:58.117275 30295 net.cpp:165] Memory required for data: 2706141440
I0422 22:48:58.117278 30295 layer_factory.hpp:77] Creating layer u3a_relu_u3a_0_split
I0422 22:48:58.117283 30295 net.cpp:100] Creating Layer u3a_relu_u3a_0_split
I0422 22:48:58.117286 30295 net.cpp:434] u3a_relu_u3a_0_split <- u3a
I0422 22:48:58.117291 30295 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_0
I0422 22:48:58.117296 30295 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_1
I0422 22:48:58.117337 30295 net.cpp:150] Setting up u3a_relu_u3a_0_split
I0422 22:48:58.117344 30295 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0422 22:48:58.117347 30295 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0422 22:48:58.117349 30295 net.cpp:165] Memory required for data: 2735714560
I0422 22:48:58.117352 30295 layer_factory.hpp:77] Creating layer crop_d3c-d3cc
I0422 22:48:58.117358 30295 net.cpp:100] Creating Layer crop_d3c-d3cc
I0422 22:48:58.117362 30295 net.cpp:434] crop_d3c-d3cc <- d3c_dropout_d3c_0_split_1
I0422 22:48:58.117364 30295 net.cpp:434] crop_d3c-d3cc <- u3a_relu_u3a_0_split_0
I0422 22:48:58.117370 30295 net.cpp:408] crop_d3c-d3cc -> d3cc
I0422 22:48:58.117389 30295 net.cpp:150] Setting up crop_d3c-d3cc
I0422 22:48:58.117393 30295 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0422 22:48:58.117395 30295 net.cpp:165] Memory required for data: 2750501120
I0422 22:48:58.117399 30295 layer_factory.hpp:77] Creating layer concat_d3cc_u3a-b
I0422 22:48:58.117404 30295 net.cpp:100] Creating Layer concat_d3cc_u3a-b
I0422 22:48:58.117406 30295 net.cpp:434] concat_d3cc_u3a-b <- u3a_relu_u3a_0_split_1
I0422 22:48:58.117409 30295 net.cpp:434] concat_d3cc_u3a-b <- d3cc
I0422 22:48:58.117413 30295 net.cpp:408] concat_d3cc_u3a-b -> u3b
I0422 22:48:58.117432 30295 net.cpp:150] Setting up concat_d3cc_u3a-b
I0422 22:48:58.117441 30295 net.cpp:157] Top shape: 5 1024 38 38 (7393280)
I0422 22:48:58.117444 30295 net.cpp:165] Memory required for data: 2780074240
I0422 22:48:58.117462 30295 layer_factory.hpp:77] Creating layer conv_u3b-c
I0422 22:48:58.117470 30295 net.cpp:100] Creating Layer conv_u3b-c
I0422 22:48:58.117472 30295 net.cpp:434] conv_u3b-c <- u3b
I0422 22:48:58.117477 30295 net.cpp:408] conv_u3b-c -> u3c
I0422 22:48:58.146292 30295 net.cpp:150] Setting up conv_u3b-c
I0422 22:48:58.146309 30295 net.cpp:157] Top shape: 5 512 36 36 (3317760)
I0422 22:48:58.146327 30295 net.cpp:165] Memory required for data: 2793345280
I0422 22:48:58.146333 30295 layer_factory.hpp:77] Creating layer relu_u3c
I0422 22:48:58.146339 30295 net.cpp:100] Creating Layer relu_u3c
I0422 22:48:58.146342 30295 net.cpp:434] relu_u3c <- u3c
I0422 22:48:58.146349 30295 net.cpp:395] relu_u3c -> u3c (in-place)
I0422 22:48:58.146550 30295 net.cpp:150] Setting up relu_u3c
I0422 22:48:58.146560 30295 net.cpp:157] Top shape: 5 512 36 36 (3317760)
I0422 22:48:58.146562 30295 net.cpp:165] Memory required for data: 2806616320
I0422 22:48:58.146565 30295 layer_factory.hpp:77] Creating layer conv_u3c-d
I0422 22:48:58.146574 30295 net.cpp:100] Creating Layer conv_u3c-d
I0422 22:48:58.146577 30295 net.cpp:434] conv_u3c-d <- u3c
I0422 22:48:58.146584 30295 net.cpp:408] conv_u3c-d -> u3d
I0422 22:48:58.160837 30295 net.cpp:150] Setting up conv_u3c-d
I0422 22:48:58.160851 30295 net.cpp:157] Top shape: 5 512 34 34 (2959360)
I0422 22:48:58.160852 30295 net.cpp:165] Memory required for data: 2818453760
I0422 22:48:58.160873 30295 layer_factory.hpp:77] Creating layer relu_u3d
I0422 22:48:58.160893 30295 net.cpp:100] Creating Layer relu_u3d
I0422 22:48:58.160897 30295 net.cpp:434] relu_u3d <- u3d
I0422 22:48:58.160902 30295 net.cpp:395] relu_u3d -> u3d (in-place)
I0422 22:48:58.161674 30295 net.cpp:150] Setting up relu_u3d
I0422 22:48:58.161687 30295 net.cpp:157] Top shape: 5 512 34 34 (2959360)
I0422 22:48:58.161706 30295 net.cpp:165] Memory required for data: 2830291200
I0422 22:48:58.161710 30295 layer_factory.hpp:77] Creating layer upconv_u3d_u2a
I0422 22:48:58.161720 30295 net.cpp:100] Creating Layer upconv_u3d_u2a
I0422 22:48:58.161723 30295 net.cpp:434] upconv_u3d_u2a <- u3d
I0422 22:48:58.161730 30295 net.cpp:408] upconv_u3d_u2a -> u2a
I0422 22:48:58.165431 30295 net.cpp:150] Setting up upconv_u3d_u2a
I0422 22:48:58.165463 30295 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0422 22:48:58.165467 30295 net.cpp:165] Memory required for data: 2853966080
I0422 22:48:58.165488 30295 layer_factory.hpp:77] Creating layer relu_u2a
I0422 22:48:58.165493 30295 net.cpp:100] Creating Layer relu_u2a
I0422 22:48:58.165495 30295 net.cpp:434] relu_u2a <- u2a
I0422 22:48:58.165501 30295 net.cpp:395] relu_u2a -> u2a (in-place)
I0422 22:48:58.165678 30295 net.cpp:150] Setting up relu_u2a
I0422 22:48:58.165688 30295 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0422 22:48:58.165690 30295 net.cpp:165] Memory required for data: 2877640960
I0422 22:48:58.165693 30295 layer_factory.hpp:77] Creating layer u2a_relu_u2a_0_split
I0422 22:48:58.165699 30295 net.cpp:100] Creating Layer u2a_relu_u2a_0_split
I0422 22:48:58.165702 30295 net.cpp:434] u2a_relu_u2a_0_split <- u2a
I0422 22:48:58.165707 30295 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_0
I0422 22:48:58.165720 30295 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_1
I0422 22:48:58.165760 30295 net.cpp:150] Setting up u2a_relu_u2a_0_split
I0422 22:48:58.165783 30295 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0422 22:48:58.165789 30295 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0422 22:48:58.165807 30295 net.cpp:165] Memory required for data: 2924990720
I0422 22:48:58.165810 30295 layer_factory.hpp:77] Creating layer crop_d2c-d2cc
I0422 22:48:58.165817 30295 net.cpp:100] Creating Layer crop_d2c-d2cc
I0422 22:48:58.165818 30295 net.cpp:434] crop_d2c-d2cc <- d2c_relu_d2c_0_split_1
I0422 22:48:58.165822 30295 net.cpp:434] crop_d2c-d2cc <- u2a_relu_u2a_0_split_0
I0422 22:48:58.165827 30295 net.cpp:408] crop_d2c-d2cc -> d2cc
I0422 22:48:58.165848 30295 net.cpp:150] Setting up crop_d2c-d2cc
I0422 22:48:58.165854 30295 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0422 22:48:58.165856 30295 net.cpp:165] Memory required for data: 2948665600
I0422 22:48:58.165858 30295 layer_factory.hpp:77] Creating layer concat_d2cc_u2a-b
I0422 22:48:58.165864 30295 net.cpp:100] Creating Layer concat_d2cc_u2a-b
I0422 22:48:58.165866 30295 net.cpp:434] concat_d2cc_u2a-b <- u2a_relu_u2a_0_split_1
I0422 22:48:58.165869 30295 net.cpp:434] concat_d2cc_u2a-b <- d2cc
I0422 22:48:58.165873 30295 net.cpp:408] concat_d2cc_u2a-b -> u2b
I0422 22:48:58.165892 30295 net.cpp:150] Setting up concat_d2cc_u2a-b
I0422 22:48:58.165896 30295 net.cpp:157] Top shape: 5 512 68 68 (11837440)
I0422 22:48:58.165899 30295 net.cpp:165] Memory required for data: 2996015360
I0422 22:48:58.165901 30295 layer_factory.hpp:77] Creating layer conv_u2b-c
I0422 22:48:58.165910 30295 net.cpp:100] Creating Layer conv_u2b-c
I0422 22:48:58.165911 30295 net.cpp:434] conv_u2b-c <- u2b
I0422 22:48:58.165916 30295 net.cpp:408] conv_u2b-c -> u2c
I0422 22:48:58.173204 30295 net.cpp:150] Setting up conv_u2b-c
I0422 22:48:58.173218 30295 net.cpp:157] Top shape: 5 256 66 66 (5575680)
I0422 22:48:58.173219 30295 net.cpp:165] Memory required for data: 3018318080
I0422 22:48:58.173240 30295 layer_factory.hpp:77] Creating layer relu_u2c
I0422 22:48:58.173245 30295 net.cpp:100] Creating Layer relu_u2c
I0422 22:48:58.173249 30295 net.cpp:434] relu_u2c <- u2c
I0422 22:48:58.173254 30295 net.cpp:395] relu_u2c -> u2c (in-place)
I0422 22:48:58.173422 30295 net.cpp:150] Setting up relu_u2c
I0422 22:48:58.173465 30295 net.cpp:157] Top shape: 5 256 66 66 (5575680)
I0422 22:48:58.173467 30295 net.cpp:165] Memory required for data: 3040620800
I0422 22:48:58.173470 30295 layer_factory.hpp:77] Creating layer conv_u2c-d
I0422 22:48:58.173478 30295 net.cpp:100] Creating Layer conv_u2c-d
I0422 22:48:58.173481 30295 net.cpp:434] conv_u2c-d <- u2c
I0422 22:48:58.173487 30295 net.cpp:408] conv_u2c-d -> u2d
I0422 22:48:58.177368 30295 net.cpp:150] Setting up conv_u2c-d
I0422 22:48:58.177381 30295 net.cpp:157] Top shape: 5 256 64 64 (5242880)
I0422 22:48:58.177382 30295 net.cpp:165] Memory required for data: 3061592320
I0422 22:48:58.177403 30295 layer_factory.hpp:77] Creating layer relu_u2d
I0422 22:48:58.177409 30295 net.cpp:100] Creating Layer relu_u2d
I0422 22:48:58.177412 30295 net.cpp:434] relu_u2d <- u2d
I0422 22:48:58.177417 30295 net.cpp:395] relu_u2d -> u2d (in-place)
I0422 22:48:58.177618 30295 net.cpp:150] Setting up relu_u2d
I0422 22:48:58.177628 30295 net.cpp:157] Top shape: 5 256 64 64 (5242880)
I0422 22:48:58.177631 30295 net.cpp:165] Memory required for data: 3082563840
I0422 22:48:58.177634 30295 layer_factory.hpp:77] Creating layer upconv_u2d_u1a
I0422 22:48:58.177641 30295 net.cpp:100] Creating Layer upconv_u2d_u1a
I0422 22:48:58.177644 30295 net.cpp:434] upconv_u2d_u1a <- u2d
I0422 22:48:58.177649 30295 net.cpp:408] upconv_u2d_u1a -> u1a
I0422 22:48:58.179316 30295 net.cpp:150] Setting up upconv_u2d_u1a
I0422 22:48:58.179329 30295 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0422 22:48:58.179332 30295 net.cpp:165] Memory required for data: 3124506880
I0422 22:48:58.179358 30295 layer_factory.hpp:77] Creating layer relu_u1a
I0422 22:48:58.179363 30295 net.cpp:100] Creating Layer relu_u1a
I0422 22:48:58.179368 30295 net.cpp:434] relu_u1a <- u1a
I0422 22:48:58.179370 30295 net.cpp:395] relu_u1a -> u1a (in-place)
I0422 22:48:58.180094 30295 net.cpp:150] Setting up relu_u1a
I0422 22:48:58.180105 30295 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0422 22:48:58.180124 30295 net.cpp:165] Memory required for data: 3166449920
I0422 22:48:58.180126 30295 layer_factory.hpp:77] Creating layer u1a_relu_u1a_0_split
I0422 22:48:58.180132 30295 net.cpp:100] Creating Layer u1a_relu_u1a_0_split
I0422 22:48:58.180135 30295 net.cpp:434] u1a_relu_u1a_0_split <- u1a
I0422 22:48:58.180140 30295 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_0
I0422 22:48:58.180146 30295 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_1
I0422 22:48:58.180186 30295 net.cpp:150] Setting up u1a_relu_u1a_0_split
I0422 22:48:58.180191 30295 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0422 22:48:58.180194 30295 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0422 22:48:58.180197 30295 net.cpp:165] Memory required for data: 3250336000
I0422 22:48:58.180198 30295 layer_factory.hpp:77] Creating layer crop_d1c-d1cc
I0422 22:48:58.180202 30295 net.cpp:100] Creating Layer crop_d1c-d1cc
I0422 22:48:58.180205 30295 net.cpp:434] crop_d1c-d1cc <- d1c_relu_d1c_0_split_1
I0422 22:48:58.180208 30295 net.cpp:434] crop_d1c-d1cc <- u1a_relu_u1a_0_split_0
I0422 22:48:58.180212 30295 net.cpp:408] crop_d1c-d1cc -> d1cc
I0422 22:48:58.180233 30295 net.cpp:150] Setting up crop_d1c-d1cc
I0422 22:48:58.180238 30295 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0422 22:48:58.180239 30295 net.cpp:165] Memory required for data: 3292279040
I0422 22:48:58.180241 30295 layer_factory.hpp:77] Creating layer concat_d1cc_u1a-b
I0422 22:48:58.180246 30295 net.cpp:100] Creating Layer concat_d1cc_u1a-b
I0422 22:48:58.180248 30295 net.cpp:434] concat_d1cc_u1a-b <- u1a_relu_u1a_0_split_1
I0422 22:48:58.180251 30295 net.cpp:434] concat_d1cc_u1a-b <- d1cc
I0422 22:48:58.180254 30295 net.cpp:408] concat_d1cc_u1a-b -> u1b
I0422 22:48:58.180280 30295 net.cpp:150] Setting up concat_d1cc_u1a-b
I0422 22:48:58.180284 30295 net.cpp:157] Top shape: 5 256 128 128 (20971520)
I0422 22:48:58.180286 30295 net.cpp:165] Memory required for data: 3376165120
I0422 22:48:58.180289 30295 layer_factory.hpp:77] Creating layer conv_u1b-c
I0422 22:48:58.180308 30295 net.cpp:100] Creating Layer conv_u1b-c
I0422 22:48:58.180312 30295 net.cpp:434] conv_u1b-c <- u1b
I0422 22:48:58.180316 30295 net.cpp:408] conv_u1b-c -> u1c
I0422 22:48:58.181988 30295 net.cpp:150] Setting up conv_u1b-c
I0422 22:48:58.181996 30295 net.cpp:157] Top shape: 5 128 126 126 (10160640)
I0422 22:48:58.181998 30295 net.cpp:165] Memory required for data: 3416807680
I0422 22:48:58.182019 30295 layer_factory.hpp:77] Creating layer relu_u1c
I0422 22:48:58.182024 30295 net.cpp:100] Creating Layer relu_u1c
I0422 22:48:58.182025 30295 net.cpp:434] relu_u1c <- u1c
I0422 22:48:58.182031 30295 net.cpp:395] relu_u1c -> u1c (in-place)
I0422 22:48:58.182207 30295 net.cpp:150] Setting up relu_u1c
I0422 22:48:58.182215 30295 net.cpp:157] Top shape: 5 128 126 126 (10160640)
I0422 22:48:58.182219 30295 net.cpp:165] Memory required for data: 3457450240
I0422 22:48:58.182221 30295 layer_factory.hpp:77] Creating layer conv_u1c-d
I0422 22:48:58.182229 30295 net.cpp:100] Creating Layer conv_u1c-d
I0422 22:48:58.182230 30295 net.cpp:434] conv_u1c-d <- u1c
I0422 22:48:58.182235 30295 net.cpp:408] conv_u1c-d -> u1d
I0422 22:48:58.184029 30295 net.cpp:150] Setting up conv_u1c-d
I0422 22:48:58.184053 30295 net.cpp:157] Top shape: 5 128 124 124 (9840640)
I0422 22:48:58.184056 30295 net.cpp:165] Memory required for data: 3496812800
I0422 22:48:58.184059 30295 layer_factory.hpp:77] Creating layer relu_u1d
I0422 22:48:58.184082 30295 net.cpp:100] Creating Layer relu_u1d
I0422 22:48:58.184084 30295 net.cpp:434] relu_u1d <- u1d
I0422 22:48:58.184088 30295 net.cpp:395] relu_u1d -> u1d (in-place)
I0422 22:48:58.184269 30295 net.cpp:150] Setting up relu_u1d
I0422 22:48:58.184278 30295 net.cpp:157] Top shape: 5 128 124 124 (9840640)
I0422 22:48:58.184280 30295 net.cpp:165] Memory required for data: 3536175360
I0422 22:48:58.184283 30295 layer_factory.hpp:77] Creating layer upconv_u1d_u0a
I0422 22:48:58.184290 30295 net.cpp:100] Creating Layer upconv_u1d_u0a
I0422 22:48:58.184293 30295 net.cpp:434] upconv_u1d_u0a <- u1d
I0422 22:48:58.184298 30295 net.cpp:408] upconv_u1d_u0a -> u0a
I0422 22:48:58.184898 30295 net.cpp:150] Setting up upconv_u1d_u0a
I0422 22:48:58.184906 30295 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0422 22:48:58.184908 30295 net.cpp:165] Memory required for data: 3693625600
I0422 22:48:58.184928 30295 layer_factory.hpp:77] Creating layer relu_u0a
I0422 22:48:58.184934 30295 net.cpp:100] Creating Layer relu_u0a
I0422 22:48:58.184937 30295 net.cpp:434] relu_u0a <- u0a
I0422 22:48:58.184940 30295 net.cpp:395] relu_u0a -> u0a (in-place)
I0422 22:48:58.185106 30295 net.cpp:150] Setting up relu_u0a
I0422 22:48:58.185115 30295 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0422 22:48:58.185117 30295 net.cpp:165] Memory required for data: 3851075840
I0422 22:48:58.185120 30295 layer_factory.hpp:77] Creating layer u0a_relu_u0a_0_split
I0422 22:48:58.185125 30295 net.cpp:100] Creating Layer u0a_relu_u0a_0_split
I0422 22:48:58.185128 30295 net.cpp:434] u0a_relu_u0a_0_split <- u0a
I0422 22:48:58.185132 30295 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_0
I0422 22:48:58.185138 30295 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_1
I0422 22:48:58.185176 30295 net.cpp:150] Setting up u0a_relu_u0a_0_split
I0422 22:48:58.185183 30295 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0422 22:48:58.185186 30295 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0422 22:48:58.185189 30295 net.cpp:165] Memory required for data: 4165976320
I0422 22:48:58.185190 30295 layer_factory.hpp:77] Creating layer crop_d0c-d0cc
I0422 22:48:58.185197 30295 net.cpp:100] Creating Layer crop_d0c-d0cc
I0422 22:48:58.185199 30295 net.cpp:434] crop_d0c-d0cc <- d0c_relu_d0c_0_split_1
I0422 22:48:58.185204 30295 net.cpp:434] crop_d0c-d0cc <- u0a_relu_u0a_0_split_0
I0422 22:48:58.185207 30295 net.cpp:408] crop_d0c-d0cc -> d0cc
I0422 22:48:58.185228 30295 net.cpp:150] Setting up crop_d0c-d0cc
I0422 22:48:58.185232 30295 net.cpp:157] Top shape: 5 64 248 248 (19681280)
I0422 22:48:58.185235 30295 net.cpp:165] Memory required for data: 4244701440
I0422 22:48:58.185250 30295 layer_factory.hpp:77] Creating layer concat_d0cc_u0a-b
I0422 22:48:58.185266 30295 net.cpp:100] Creating Layer concat_d0cc_u0a-b
I0422 22:48:58.185269 30295 net.cpp:434] concat_d0cc_u0a-b <- u0a_relu_u0a_0_split_1
I0422 22:48:58.185289 30295 net.cpp:434] concat_d0cc_u0a-b <- d0cc
I0422 22:48:58.185295 30295 net.cpp:408] concat_d0cc_u0a-b -> u0b
I0422 22:48:58.185322 30295 net.cpp:150] Setting up concat_d0cc_u0a-b
I0422 22:48:58.185328 30295 net.cpp:157] Top shape: 5 192 248 248 (59043840)
I0422 22:48:58.185331 30295 net.cpp:165] Memory required for data: 4480876800
I0422 22:48:58.185333 30295 layer_factory.hpp:77] Creating layer conv_u0b-c
I0422 22:48:58.185341 30295 net.cpp:100] Creating Layer conv_u0b-c
I0422 22:48:58.185343 30295 net.cpp:434] conv_u0b-c <- u0b
I0422 22:48:58.185348 30295 net.cpp:408] conv_u0b-c -> u0c
I0422 22:48:58.186231 30295 net.cpp:150] Setting up conv_u0b-c
I0422 22:48:58.186239 30295 net.cpp:157] Top shape: 5 64 246 246 (19365120)
I0422 22:48:58.186241 30295 net.cpp:165] Memory required for data: 4558337280
I0422 22:48:58.186264 30295 layer_factory.hpp:77] Creating layer relu_u0c
I0422 22:48:58.186276 30295 net.cpp:100] Creating Layer relu_u0c
I0422 22:48:58.186280 30295 net.cpp:434] relu_u0c <- u0c
I0422 22:48:58.186282 30295 net.cpp:395] relu_u0c -> u0c (in-place)
I0422 22:48:58.187042 30295 net.cpp:150] Setting up relu_u0c
I0422 22:48:58.187054 30295 net.cpp:157] Top shape: 5 64 246 246 (19365120)
I0422 22:48:58.187057 30295 net.cpp:165] Memory required for data: 4635797760
I0422 22:48:58.187077 30295 layer_factory.hpp:77] Creating layer conv_u0c-d
I0422 22:48:58.187084 30295 net.cpp:100] Creating Layer conv_u0c-d
I0422 22:48:58.187088 30295 net.cpp:434] conv_u0c-d <- u0c
I0422 22:48:58.187108 30295 net.cpp:408] conv_u0c-d -> u0d
I0422 22:48:58.187569 30295 net.cpp:150] Setting up conv_u0c-d
I0422 22:48:58.187577 30295 net.cpp:157] Top shape: 5 64 244 244 (19051520)
I0422 22:48:58.187579 30295 net.cpp:165] Memory required for data: 4712003840
I0422 22:48:58.187599 30295 layer_factory.hpp:77] Creating layer relu_u0d
I0422 22:48:58.187603 30295 net.cpp:100] Creating Layer relu_u0d
I0422 22:48:58.187607 30295 net.cpp:434] relu_u0d <- u0d
I0422 22:48:58.187611 30295 net.cpp:395] relu_u0d -> u0d (in-place)
I0422 22:48:58.187767 30295 net.cpp:150] Setting up relu_u0d
I0422 22:48:58.187775 30295 net.cpp:157] Top shape: 5 64 244 244 (19051520)
I0422 22:48:58.187777 30295 net.cpp:165] Memory required for data: 4788209920
I0422 22:48:58.187780 30295 layer_factory.hpp:77] Creating layer conv_u0d-score
I0422 22:48:58.187788 30295 net.cpp:100] Creating Layer conv_u0d-score
I0422 22:48:58.187789 30295 net.cpp:434] conv_u0d-score <- u0d
I0422 22:48:58.187795 30295 net.cpp:408] conv_u0d-score -> score
I0422 22:48:58.188041 30295 net.cpp:150] Setting up conv_u0d-score
I0422 22:48:58.188048 30295 net.cpp:157] Top shape: 5 4 244 244 (1190720)
I0422 22:48:58.188050 30295 net.cpp:165] Memory required for data: 4792972800
I0422 22:48:58.188055 30295 layer_factory.hpp:77] Creating layer score_conv_u0d-score_0_split
I0422 22:48:58.188060 30295 net.cpp:100] Creating Layer score_conv_u0d-score_0_split
I0422 22:48:58.188062 30295 net.cpp:434] score_conv_u0d-score_0_split <- score
I0422 22:48:58.188067 30295 net.cpp:408] score_conv_u0d-score_0_split -> score_conv_u0d-score_0_split_0
I0422 22:48:58.188072 30295 net.cpp:408] score_conv_u0d-score_0_split -> score_conv_u0d-score_0_split_1
I0422 22:48:58.188109 30295 net.cpp:150] Setting up score_conv_u0d-score_0_split
I0422 22:48:58.188115 30295 net.cpp:157] Top shape: 5 4 244 244 (1190720)
I0422 22:48:58.188118 30295 net.cpp:157] Top shape: 5 4 244 244 (1190720)
I0422 22:48:58.188122 30295 net.cpp:165] Memory required for data: 4802498560
I0422 22:48:58.188123 30295 layer_factory.hpp:77] Creating layer softmax
I0422 22:48:58.188127 30295 net.cpp:100] Creating Layer softmax
I0422 22:48:58.188129 30295 net.cpp:434] softmax <- score_conv_u0d-score_0_split_0
I0422 22:48:58.188133 30295 net.cpp:408] softmax -> softmax_out
I0422 22:48:58.188354 30295 net.cpp:150] Setting up softmax
I0422 22:48:58.188365 30295 net.cpp:157] Top shape: 5 4 244 244 (1190720)
I0422 22:48:58.188367 30295 net.cpp:165] Memory required for data: 4807261440
I0422 22:48:58.188370 30295 layer_factory.hpp:77] Creating layer reshapelab
I0422 22:48:58.188377 30295 net.cpp:100] Creating Layer reshapelab
I0422 22:48:58.188380 30295 net.cpp:434] reshapelab <- label
I0422 22:48:58.188383 30295 net.cpp:408] reshapelab -> label_flat
I0422 22:48:58.188408 30295 net.cpp:150] Setting up reshapelab
I0422 22:48:58.188415 30295 net.cpp:157] Top shape: 5 59536 (297680)
I0422 22:48:58.188417 30295 net.cpp:165] Memory required for data: 4808452160
I0422 22:48:58.188419 30295 layer_factory.hpp:77] Creating layer reshaperes
I0422 22:48:58.188424 30295 net.cpp:100] Creating Layer reshaperes
I0422 22:48:58.188427 30295 net.cpp:434] reshaperes <- softmax_out
I0422 22:48:58.188431 30295 net.cpp:408] reshaperes -> softmax_out_flat
I0422 22:48:58.188452 30295 net.cpp:150] Setting up reshaperes
I0422 22:48:58.188457 30295 net.cpp:157] Top shape: 5 4 59536 (1190720)
I0422 22:48:58.188458 30295 net.cpp:165] Memory required for data: 4813215040
I0422 22:48:58.188460 30295 layer_factory.hpp:77] Creating layer loss
I0422 22:48:58.188627 30295 net.cpp:100] Creating Layer loss
I0422 22:48:58.188637 30295 net.cpp:434] loss <- softmax_out_flat
I0422 22:48:58.188640 30295 net.cpp:434] loss <- label_flat
I0422 22:48:58.188644 30295 net.cpp:408] loss -> loss
I0422 22:48:58.196929 30295 net.cpp:150] Setting up loss
I0422 22:48:58.196943 30295 net.cpp:157] Top shape: 4 (4)
I0422 22:48:58.196944 30295 net.cpp:160]     with loss weight 1
I0422 22:48:58.196975 30295 net.cpp:165] Memory required for data: 4813215056
I0422 22:48:58.196980 30295 layer_factory.hpp:77] Creating layer visualize
I0422 22:48:58.196987 30295 net.cpp:100] Creating Layer visualize
I0422 22:48:58.196990 30295 net.cpp:434] visualize <- score_conv_u0d-score_0_split_1
I0422 22:48:58.196995 30295 net.cpp:408] visualize -> visualize_out
I0422 22:48:58.197824 30295 net.cpp:150] Setting up visualize
I0422 22:48:58.197839 30295 net.cpp:157] Top shape: 5 4 244 244 (1190720)
I0422 22:48:58.197840 30295 net.cpp:165] Memory required for data: 4817977936
I0422 22:48:58.197859 30295 layer_factory.hpp:77] Creating layer fake
I0422 22:48:58.197863 30295 net.cpp:100] Creating Layer fake
I0422 22:48:58.197867 30295 net.cpp:434] fake <- visualize_out
I0422 22:48:58.197871 30295 net.cpp:150] Setting up fake
I0422 22:48:58.197875 30295 net.cpp:165] Memory required for data: 4817977936
I0422 22:48:58.197876 30295 net.cpp:228] fake does not need backward computation.
I0422 22:48:58.197880 30295 net.cpp:228] visualize does not need backward computation.
I0422 22:48:58.197882 30295 net.cpp:226] loss needs backward computation.
I0422 22:48:58.197885 30295 net.cpp:226] reshaperes needs backward computation.
I0422 22:48:58.197887 30295 net.cpp:228] reshapelab does not need backward computation.
I0422 22:48:58.197890 30295 net.cpp:226] softmax needs backward computation.
I0422 22:48:58.197892 30295 net.cpp:226] score_conv_u0d-score_0_split needs backward computation.
I0422 22:48:58.197895 30295 net.cpp:226] conv_u0d-score needs backward computation.
I0422 22:48:58.197896 30295 net.cpp:226] relu_u0d needs backward computation.
I0422 22:48:58.197899 30295 net.cpp:226] conv_u0c-d needs backward computation.
I0422 22:48:58.197901 30295 net.cpp:226] relu_u0c needs backward computation.
I0422 22:48:58.197903 30295 net.cpp:226] conv_u0b-c needs backward computation.
I0422 22:48:58.197906 30295 net.cpp:226] concat_d0cc_u0a-b needs backward computation.
I0422 22:48:58.197908 30295 net.cpp:226] crop_d0c-d0cc needs backward computation.
I0422 22:48:58.197911 30295 net.cpp:226] u0a_relu_u0a_0_split needs backward computation.
I0422 22:48:58.197912 30295 net.cpp:226] relu_u0a needs backward computation.
I0422 22:48:58.197914 30295 net.cpp:226] upconv_u1d_u0a needs backward computation.
I0422 22:48:58.197917 30295 net.cpp:226] relu_u1d needs backward computation.
I0422 22:48:58.197931 30295 net.cpp:226] conv_u1c-d needs backward computation.
I0422 22:48:58.197933 30295 net.cpp:226] relu_u1c needs backward computation.
I0422 22:48:58.197935 30295 net.cpp:226] conv_u1b-c needs backward computation.
I0422 22:48:58.197938 30295 net.cpp:226] concat_d1cc_u1a-b needs backward computation.
I0422 22:48:58.197940 30295 net.cpp:226] crop_d1c-d1cc needs backward computation.
I0422 22:48:58.197943 30295 net.cpp:226] u1a_relu_u1a_0_split needs backward computation.
I0422 22:48:58.197945 30295 net.cpp:226] relu_u1a needs backward computation.
I0422 22:48:58.197948 30295 net.cpp:226] upconv_u2d_u1a needs backward computation.
I0422 22:48:58.197950 30295 net.cpp:226] relu_u2d needs backward computation.
I0422 22:48:58.197952 30295 net.cpp:226] conv_u2c-d needs backward computation.
I0422 22:48:58.197954 30295 net.cpp:226] relu_u2c needs backward computation.
I0422 22:48:58.197957 30295 net.cpp:226] conv_u2b-c needs backward computation.
I0422 22:48:58.197958 30295 net.cpp:226] concat_d2cc_u2a-b needs backward computation.
I0422 22:48:58.197962 30295 net.cpp:226] crop_d2c-d2cc needs backward computation.
I0422 22:48:58.197964 30295 net.cpp:226] u2a_relu_u2a_0_split needs backward computation.
I0422 22:48:58.197966 30295 net.cpp:226] relu_u2a needs backward computation.
I0422 22:48:58.197968 30295 net.cpp:226] upconv_u3d_u2a needs backward computation.
I0422 22:48:58.197970 30295 net.cpp:226] relu_u3d needs backward computation.
I0422 22:48:58.197973 30295 net.cpp:226] conv_u3c-d needs backward computation.
I0422 22:48:58.197975 30295 net.cpp:226] relu_u3c needs backward computation.
I0422 22:48:58.197978 30295 net.cpp:226] conv_u3b-c needs backward computation.
I0422 22:48:58.197979 30295 net.cpp:226] concat_d3cc_u3a-b needs backward computation.
I0422 22:48:58.197981 30295 net.cpp:226] crop_d3c-d3cc needs backward computation.
I0422 22:48:58.197984 30295 net.cpp:226] u3a_relu_u3a_0_split needs backward computation.
I0422 22:48:58.197986 30295 net.cpp:226] relu_u3a needs backward computation.
I0422 22:48:58.197988 30295 net.cpp:226] upconv_d4c_u3a needs backward computation.
I0422 22:48:58.197990 30295 net.cpp:226] dropout_d4c needs backward computation.
I0422 22:48:58.197993 30295 net.cpp:226] relu_d4c needs backward computation.
I0422 22:48:58.197995 30295 net.cpp:226] conv_d4b-c needs backward computation.
I0422 22:48:58.197999 30295 net.cpp:226] relu_d4b needs backward computation.
I0422 22:48:58.198000 30295 net.cpp:226] conv_d4a-b needs backward computation.
I0422 22:48:58.198002 30295 net.cpp:226] pool_d3c-4a needs backward computation.
I0422 22:48:58.198005 30295 net.cpp:226] d3c_dropout_d3c_0_split needs backward computation.
I0422 22:48:58.198007 30295 net.cpp:226] dropout_d3c needs backward computation.
I0422 22:48:58.198009 30295 net.cpp:226] relu_d3c needs backward computation.
I0422 22:48:58.198011 30295 net.cpp:226] conv_d3b-c needs backward computation.
I0422 22:48:58.198014 30295 net.cpp:226] relu_d3b needs backward computation.
I0422 22:48:58.198016 30295 net.cpp:226] conv_d3a-b needs backward computation.
I0422 22:48:58.198017 30295 net.cpp:226] pool_d2c-3a needs backward computation.
I0422 22:48:58.198020 30295 net.cpp:226] d2c_relu_d2c_0_split needs backward computation.
I0422 22:48:58.198022 30295 net.cpp:226] relu_d2c needs backward computation.
I0422 22:48:58.198024 30295 net.cpp:226] conv_d2b-c needs backward computation.
I0422 22:48:58.198027 30295 net.cpp:226] relu_d2b needs backward computation.
I0422 22:48:58.198029 30295 net.cpp:226] conv_d2a-b needs backward computation.
I0422 22:48:58.198031 30295 net.cpp:226] pool_d1c-2a needs backward computation.
I0422 22:48:58.198035 30295 net.cpp:226] d1c_relu_d1c_0_split needs backward computation.
I0422 22:48:58.198036 30295 net.cpp:226] relu_d1c needs backward computation.
I0422 22:48:58.198040 30295 net.cpp:226] conv_d1b-c needs backward computation.
I0422 22:48:58.198041 30295 net.cpp:226] relu_d1b needs backward computation.
I0422 22:48:58.198043 30295 net.cpp:226] conv_d1a-b needs backward computation.
I0422 22:48:58.198045 30295 net.cpp:226] pool_d0c-1a needs backward computation.
I0422 22:48:58.198053 30295 net.cpp:226] d0c_relu_d0c_0_split needs backward computation.
I0422 22:48:58.198056 30295 net.cpp:226] relu_d0c needs backward computation.
I0422 22:48:58.198058 30295 net.cpp:226] conv_d0b-c needs backward computation.
I0422 22:48:58.198060 30295 net.cpp:226] relu_d0b needs backward computation.
I0422 22:48:58.198063 30295 net.cpp:226] conv_d0a-b needs backward computation.
I0422 22:48:58.198065 30295 net.cpp:228] loaddata does not need backward computation.
I0422 22:48:58.198072 30295 net.cpp:270] This network produces output loss
I0422 22:48:58.198110 30295 net.cpp:283] Network initialization done.
I0422 22:48:58.198602 30295 solver.cpp:181] Creating test net (#0) specified by net file: ./unet_f1_4/unet_f1_4.prototxt
I0422 22:48:58.198658 30295 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer loaddata
I0422 22:48:58.198673 30295 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer dropout_d3c
I0422 22:48:58.198675 30295 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer dropout_d4c
I0422 22:48:58.198690 30295 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer visualize
I0422 22:48:58.198693 30295 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer fake
I0422 22:48:58.198940 30295 net.cpp:58] Initializing net from parameters: 
name: "unet_f1_4"
force_backward: true
state {
  phase: TEST
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "caffeHDF5_validation_4.txt"
    batch_size: 1
  }
}
layer {
  name: "conv_d0a-b"
  type: "Convolution"
  bottom: "data"
  top: "d0b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0b"
  type: "ReLU"
  bottom: "d0b"
  top: "d0b"
}
layer {
  name: "conv_d0b-c"
  type: "Convolution"
  bottom: "d0b"
  top: "d0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0c"
  type: "ReLU"
  bottom: "d0c"
  top: "d0c"
}
layer {
  name: "pool_d0c-1a"
  type: "Pooling"
  bottom: "d0c"
  top: "d1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d1a-b"
  type: "Convolution"
  bottom: "d1a"
  top: "d1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1b"
  type: "ReLU"
  bottom: "d1b"
  top: "d1b"
}
layer {
  name: "conv_d1b-c"
  type: "Convolution"
  bottom: "d1b"
  top: "d1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1c"
  type: "ReLU"
  bottom: "d1c"
  top: "d1c"
}
layer {
  name: "pool_d1c-2a"
  type: "Pooling"
  bottom: "d1c"
  top: "d2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d2a-b"
  type: "Convolution"
  bottom: "d2a"
  top: "d2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2b"
  type: "ReLU"
  bottom: "d2b"
  top: "d2b"
}
layer {
  name: "conv_d2b-c"
  type: "Convolution"
  bottom: "d2b"
  top: "d2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2c"
  type: "ReLU"
  bottom: "d2c"
  top: "d2c"
}
layer {
  name: "pool_d2c-3a"
  type: "Pooling"
  bottom: "d2c"
  top: "d3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d3a-b"
  type: "Convolution"
  bottom: "d3a"
  top: "d3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3b"
  type: "ReLU"
  bottom: "d3b"
  top: "d3b"
}
layer {
  name: "conv_d3b-c"
  type: "Convolution"
  bottom: "d3b"
  top: "d3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3c"
  type: "ReLU"
  bottom: "d3c"
  top: "d3c"
}
layer {
  name: "pool_d3c-4a"
  type: "Pooling"
  bottom: "d3c"
  top: "d4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d4a-b"
  type: "Convolution"
  bottom: "d4a"
  top: "d4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4b"
  type: "ReLU"
  bottom: "d4b"
  top: "d4b"
}
layer {
  name: "conv_d4b-c"
  type: "Convolution"
  bottom: "d4b"
  top: "d4c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4c"
  type: "ReLU"
  bottom: "d4c"
  top: "d4c"
}
layer {
  name: "upconv_d4c_u3a"
  type: "Deconvolution"
  bottom: "d4c"
  top: "u3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u3a"
  type: "ReLU"
  bottom: "u3a"
  top: "u3a"
}
layer {
  name: "crop_d3c-d3cc"
  type: "Crop"
  bottom: "d3c"
  bottom: "u3a"
  top: "d3cc"
  crop_param {
    axis: 2
    offset: 4
  }
}
layer {
  name: "concat_d3cc_u3a-b"
  type: "Concat"
  bottom: "u3a"
  bottom: "d3cc"
  top: "u3b"
}
layer {
  name: "conv_u3b-c"
  type: "Convolution"
  bottom: "u3b"
  top: "u3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3c"
  type: "ReLU"
  bottom: "u3c"
  top: "u3c"
}
layer {
  name: "conv_u3c-d"
  type: "Convolution"
  bottom: "u3c"
  top: "u3d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3d"
  type: "ReLU"
  bottom: "u3d"
  top: "u3d"
}
layer {
  name: "upconv_u3d_u2a"
  type: "Deconvolution"
  bottom: "u3d"
  top: "u2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u2a"
  type: "ReLU"
  bottom: "u2a"
  top: "u2a"
}
layer {
  name: "crop_d2c-d2cc"
  type: "Crop"
  bottom: "d2c"
  bottom: "u2a"
  top: "d2cc"
  crop_param {
    axis: 2
    offset: 16
  }
}
layer {
  name: "concat_d2cc_u2a-b"
  type: "Concat"
  bottom: "u2a"
  bottom: "d2cc"
  top: "u2b"
}
layer {
  name: "conv_u2b-c"
  type: "Convolution"
  bottom: "u2b"
  top: "u2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2c"
  type: "ReLU"
  bottom: "u2c"
  top: "u2c"
}
layer {
  name: "conv_u2c-d"
  type: "Convolution"
  bottom: "u2c"
  top: "u2d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2d"
  type: "ReLU"
  bottom: "u2d"
  top: "u2d"
}
layer {
  name: "upconv_u2d_u1a"
  type: "Deconvolution"
  bottom: "u2d"
  top: "u1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u1a"
  type: "ReLU"
  bottom: "u1a"
  top: "u1a"
}
layer {
  name: "crop_d1c-d1cc"
  type: "Crop"
  bottom: "d1c"
  bottom: "u1a"
  top: "d1cc"
  crop_param {
    axis: 2
    offset: 40
  }
}
layer {
  name: "concat_d1cc_u1a-b"
  type: "Concat"
  bottom: "u1a"
  bottom: "d1cc"
  top: "u1b"
}
layer {
  name: "conv_u1b-c"
  type: "Convolution"
  bottom: "u1b"
  top: "u1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1c"
  type: "ReLU"
  bottom: "u1c"
  top: "u1c"
}
layer {
  name: "conv_u1c-d"
  type: "Convolution"
  bottom: "u1c"
  top: "u1d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1d"
  type: "ReLU"
  bottom: "u1d"
  top: "u1d"
}
layer {
  name: "upconv_u1d_u0a"
  type: "Deconvolution"
  bottom: "u1d"
  top: "u0a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u0a"
  type: "ReLU"
  bottom: "u0a"
  top: "u0a"
}
layer {
  name: "crop_d0c-d0cc"
  type: "Crop"
  bottom: "d0c"
  bottom: "u0a"
  top: "d0cc"
  crop_param {
    axis: 2
    offset: 88
  }
}
layer {
  name: "concat_d0cc_u0a-b"
  type: "Concat"
  bottom: "u0a"
  bottom: "d0cc"
  top: "u0b"
}
layer {
  name: "conv_u0b-c"
  type: "Convolution"
  bottom: "u0b"
  top: "u0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0c"
  type: "ReLU"
  bottom: "u0c"
  top: "u0c"
}
layer {
  name: "conv_u0c-d"
  type: "Convolution"
  bottom: "u0c"
  top: "u0d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0d"
  type: "ReLU"
  bottom: "u0d"
  top: "u0d"
}
layer {
  name: "conv_u0d-score"
  type: "Convolution"
  bottom: "u0d"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "score"
  top: "softmax_out"
}
layer {
  name: "reshapelab"
  type: "Reshape"
  bottom: "label"
  top: "label_flat"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "reshaperes"
  type: "Reshape"
  bottom: "softmax_out"
  top: "softmax_out_flat"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "loss"
  type: "Python"
  bottom: "softmax_out_flat"
  bottom: "label_flat"
  top: "loss"
  loss_weight: 1
  python_param {
    module: "multiclass_f1_loss"
    layer: "F1Loss"
  }
}
I0422 22:48:58.199154 30295 layer_factory.hpp:77] Creating layer loaddata
I0422 22:48:58.199162 30295 net.cpp:100] Creating Layer loaddata
I0422 22:48:58.199165 30295 net.cpp:408] loaddata -> data
I0422 22:48:58.199172 30295 net.cpp:408] loaddata -> label
I0422 22:48:58.199177 30295 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: caffeHDF5_validation_4.txt
I0422 22:48:58.202594 30295 hdf5_data_layer.cpp:93] Number of HDF5 files: 10
I0422 22:48:58.461236 30295 net.cpp:150] Setting up loaddata
I0422 22:48:58.461272 30295 net.cpp:157] Top shape: 1 3 428 428 (549552)
I0422 22:48:58.461275 30295 net.cpp:157] Top shape: 1 244 244 (59536)
I0422 22:48:58.461278 30295 net.cpp:165] Memory required for data: 2436352
I0422 22:48:58.461283 30295 layer_factory.hpp:77] Creating layer conv_d0a-b
I0422 22:48:58.461298 30295 net.cpp:100] Creating Layer conv_d0a-b
I0422 22:48:58.461302 30295 net.cpp:434] conv_d0a-b <- data
I0422 22:48:58.461308 30295 net.cpp:408] conv_d0a-b -> d0b
I0422 22:48:58.461840 30295 net.cpp:150] Setting up conv_d0a-b
I0422 22:48:58.461849 30295 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0422 22:48:58.461851 30295 net.cpp:165] Memory required for data: 48894208
I0422 22:48:58.461876 30295 layer_factory.hpp:77] Creating layer relu_d0b
I0422 22:48:58.461895 30295 net.cpp:100] Creating Layer relu_d0b
I0422 22:48:58.461899 30295 net.cpp:434] relu_d0b <- d0b
I0422 22:48:58.461901 30295 net.cpp:395] relu_d0b -> d0b (in-place)
I0422 22:48:58.462147 30295 net.cpp:150] Setting up relu_d0b
I0422 22:48:58.462157 30295 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0422 22:48:58.462159 30295 net.cpp:165] Memory required for data: 95352064
I0422 22:48:58.462162 30295 layer_factory.hpp:77] Creating layer conv_d0b-c
I0422 22:48:58.462168 30295 net.cpp:100] Creating Layer conv_d0b-c
I0422 22:48:58.462170 30295 net.cpp:434] conv_d0b-c <- d0b
I0422 22:48:58.462174 30295 net.cpp:408] conv_d0b-c -> d0c
I0422 22:48:58.462759 30295 net.cpp:150] Setting up conv_d0b-c
I0422 22:48:58.462767 30295 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0422 22:48:58.462769 30295 net.cpp:165] Memory required for data: 141374720
I0422 22:48:58.462791 30295 layer_factory.hpp:77] Creating layer relu_d0c
I0422 22:48:58.462795 30295 net.cpp:100] Creating Layer relu_d0c
I0422 22:48:58.462798 30295 net.cpp:434] relu_d0c <- d0c
I0422 22:48:58.462801 30295 net.cpp:395] relu_d0c -> d0c (in-place)
I0422 22:48:58.462985 30295 net.cpp:150] Setting up relu_d0c
I0422 22:48:58.462992 30295 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0422 22:48:58.462994 30295 net.cpp:165] Memory required for data: 187397376
I0422 22:48:58.462997 30295 layer_factory.hpp:77] Creating layer d0c_relu_d0c_0_split
I0422 22:48:58.463001 30295 net.cpp:100] Creating Layer d0c_relu_d0c_0_split
I0422 22:48:58.463004 30295 net.cpp:434] d0c_relu_d0c_0_split <- d0c
I0422 22:48:58.463008 30295 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_0
I0422 22:48:58.463014 30295 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_1
I0422 22:48:58.463052 30295 net.cpp:150] Setting up d0c_relu_d0c_0_split
I0422 22:48:58.463058 30295 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0422 22:48:58.463063 30295 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0422 22:48:58.463064 30295 net.cpp:165] Memory required for data: 279442688
I0422 22:48:58.463066 30295 layer_factory.hpp:77] Creating layer pool_d0c-1a
I0422 22:48:58.463071 30295 net.cpp:100] Creating Layer pool_d0c-1a
I0422 22:48:58.463089 30295 net.cpp:434] pool_d0c-1a <- d0c_relu_d0c_0_split_0
I0422 22:48:58.463095 30295 net.cpp:408] pool_d0c-1a -> d1a
I0422 22:48:58.463131 30295 net.cpp:150] Setting up pool_d0c-1a
I0422 22:48:58.463138 30295 net.cpp:157] Top shape: 1 64 212 212 (2876416)
I0422 22:48:58.463141 30295 net.cpp:165] Memory required for data: 290948352
I0422 22:48:58.463143 30295 layer_factory.hpp:77] Creating layer conv_d1a-b
I0422 22:48:58.463150 30295 net.cpp:100] Creating Layer conv_d1a-b
I0422 22:48:58.463151 30295 net.cpp:434] conv_d1a-b <- d1a
I0422 22:48:58.463156 30295 net.cpp:408] conv_d1a-b -> d1b
I0422 22:48:58.464645 30295 net.cpp:150] Setting up conv_d1a-b
I0422 22:48:58.464658 30295 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0422 22:48:58.464659 30295 net.cpp:165] Memory required for data: 313527552
I0422 22:48:58.464684 30295 layer_factory.hpp:77] Creating layer relu_d1b
I0422 22:48:58.464690 30295 net.cpp:100] Creating Layer relu_d1b
I0422 22:48:58.464694 30295 net.cpp:434] relu_d1b <- d1b
I0422 22:48:58.464699 30295 net.cpp:395] relu_d1b -> d1b (in-place)
I0422 22:48:58.464870 30295 net.cpp:150] Setting up relu_d1b
I0422 22:48:58.464879 30295 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0422 22:48:58.464880 30295 net.cpp:165] Memory required for data: 336106752
I0422 22:48:58.464884 30295 layer_factory.hpp:77] Creating layer conv_d1b-c
I0422 22:48:58.464890 30295 net.cpp:100] Creating Layer conv_d1b-c
I0422 22:48:58.464892 30295 net.cpp:434] conv_d1b-c <- d1b
I0422 22:48:58.464896 30295 net.cpp:408] conv_d1b-c -> d1c
I0422 22:48:58.466768 30295 net.cpp:150] Setting up conv_d1b-c
I0422 22:48:58.466781 30295 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0422 22:48:58.466784 30295 net.cpp:165] Memory required for data: 358257920
I0422 22:48:58.466804 30295 layer_factory.hpp:77] Creating layer relu_d1c
I0422 22:48:58.466809 30295 net.cpp:100] Creating Layer relu_d1c
I0422 22:48:58.466812 30295 net.cpp:434] relu_d1c <- d1c
I0422 22:48:58.466816 30295 net.cpp:395] relu_d1c -> d1c (in-place)
I0422 22:48:58.467563 30295 net.cpp:150] Setting up relu_d1c
I0422 22:48:58.467576 30295 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0422 22:48:58.467577 30295 net.cpp:165] Memory required for data: 380409088
I0422 22:48:58.467597 30295 layer_factory.hpp:77] Creating layer d1c_relu_d1c_0_split
I0422 22:48:58.467602 30295 net.cpp:100] Creating Layer d1c_relu_d1c_0_split
I0422 22:48:58.467604 30295 net.cpp:434] d1c_relu_d1c_0_split <- d1c
I0422 22:48:58.467609 30295 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_0
I0422 22:48:58.467617 30295 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_1
I0422 22:48:58.467655 30295 net.cpp:150] Setting up d1c_relu_d1c_0_split
I0422 22:48:58.467659 30295 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0422 22:48:58.467664 30295 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0422 22:48:58.467664 30295 net.cpp:165] Memory required for data: 424711424
I0422 22:48:58.467667 30295 layer_factory.hpp:77] Creating layer pool_d1c-2a
I0422 22:48:58.467671 30295 net.cpp:100] Creating Layer pool_d1c-2a
I0422 22:48:58.467674 30295 net.cpp:434] pool_d1c-2a <- d1c_relu_d1c_0_split_0
I0422 22:48:58.467677 30295 net.cpp:408] pool_d1c-2a -> d2a
I0422 22:48:58.467710 30295 net.cpp:150] Setting up pool_d1c-2a
I0422 22:48:58.467713 30295 net.cpp:157] Top shape: 1 128 104 104 (1384448)
I0422 22:48:58.467715 30295 net.cpp:165] Memory required for data: 430249216
I0422 22:48:58.467717 30295 layer_factory.hpp:77] Creating layer conv_d2a-b
I0422 22:48:58.467723 30295 net.cpp:100] Creating Layer conv_d2a-b
I0422 22:48:58.467726 30295 net.cpp:434] conv_d2a-b <- d2a
I0422 22:48:58.467730 30295 net.cpp:408] conv_d2a-b -> d2b
I0422 22:48:58.469362 30295 net.cpp:150] Setting up conv_d2a-b
I0422 22:48:58.469370 30295 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0422 22:48:58.469372 30295 net.cpp:165] Memory required for data: 440902912
I0422 22:48:58.469396 30295 layer_factory.hpp:77] Creating layer relu_d2b
I0422 22:48:58.469400 30295 net.cpp:100] Creating Layer relu_d2b
I0422 22:48:58.469403 30295 net.cpp:434] relu_d2b <- d2b
I0422 22:48:58.469419 30295 net.cpp:395] relu_d2b -> d2b (in-place)
I0422 22:48:58.469615 30295 net.cpp:150] Setting up relu_d2b
I0422 22:48:58.469625 30295 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0422 22:48:58.469627 30295 net.cpp:165] Memory required for data: 451556608
I0422 22:48:58.469630 30295 layer_factory.hpp:77] Creating layer conv_d2b-c
I0422 22:48:58.469637 30295 net.cpp:100] Creating Layer conv_d2b-c
I0422 22:48:58.469640 30295 net.cpp:434] conv_d2b-c <- d2b
I0422 22:48:58.469645 30295 net.cpp:408] conv_d2b-c -> d2c
I0422 22:48:58.473628 30295 net.cpp:150] Setting up conv_d2b-c
I0422 22:48:58.473642 30295 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0422 22:48:58.473660 30295 net.cpp:165] Memory required for data: 461796608
I0422 22:48:58.473666 30295 layer_factory.hpp:77] Creating layer relu_d2c
I0422 22:48:58.473673 30295 net.cpp:100] Creating Layer relu_d2c
I0422 22:48:58.473676 30295 net.cpp:434] relu_d2c <- d2c
I0422 22:48:58.473680 30295 net.cpp:395] relu_d2c -> d2c (in-place)
I0422 22:48:58.473878 30295 net.cpp:150] Setting up relu_d2c
I0422 22:48:58.473887 30295 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0422 22:48:58.473889 30295 net.cpp:165] Memory required for data: 472036608
I0422 22:48:58.473891 30295 layer_factory.hpp:77] Creating layer d2c_relu_d2c_0_split
I0422 22:48:58.473896 30295 net.cpp:100] Creating Layer d2c_relu_d2c_0_split
I0422 22:48:58.473898 30295 net.cpp:434] d2c_relu_d2c_0_split <- d2c
I0422 22:48:58.473903 30295 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_0
I0422 22:48:58.473908 30295 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_1
I0422 22:48:58.473947 30295 net.cpp:150] Setting up d2c_relu_d2c_0_split
I0422 22:48:58.473953 30295 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0422 22:48:58.473956 30295 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0422 22:48:58.473958 30295 net.cpp:165] Memory required for data: 492516608
I0422 22:48:58.473960 30295 layer_factory.hpp:77] Creating layer pool_d2c-3a
I0422 22:48:58.473964 30295 net.cpp:100] Creating Layer pool_d2c-3a
I0422 22:48:58.473968 30295 net.cpp:434] pool_d2c-3a <- d2c_relu_d2c_0_split_0
I0422 22:48:58.473970 30295 net.cpp:408] pool_d2c-3a -> d3a
I0422 22:48:58.474004 30295 net.cpp:150] Setting up pool_d2c-3a
I0422 22:48:58.474010 30295 net.cpp:157] Top shape: 1 256 50 50 (640000)
I0422 22:48:58.474014 30295 net.cpp:165] Memory required for data: 495076608
I0422 22:48:58.474015 30295 layer_factory.hpp:77] Creating layer conv_d3a-b
I0422 22:48:58.474021 30295 net.cpp:100] Creating Layer conv_d3a-b
I0422 22:48:58.474023 30295 net.cpp:434] conv_d3a-b <- d3a
I0422 22:48:58.474028 30295 net.cpp:408] conv_d3a-b -> d3b
I0422 22:48:58.481364 30295 net.cpp:150] Setting up conv_d3a-b
I0422 22:48:58.481375 30295 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0422 22:48:58.481379 30295 net.cpp:165] Memory required for data: 499795200
I0422 22:48:58.481398 30295 layer_factory.hpp:77] Creating layer relu_d3b
I0422 22:48:58.481403 30295 net.cpp:100] Creating Layer relu_d3b
I0422 22:48:58.481406 30295 net.cpp:434] relu_d3b <- d3b
I0422 22:48:58.481410 30295 net.cpp:395] relu_d3b -> d3b (in-place)
I0422 22:48:58.481623 30295 net.cpp:150] Setting up relu_d3b
I0422 22:48:58.481633 30295 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0422 22:48:58.481636 30295 net.cpp:165] Memory required for data: 504513792
I0422 22:48:58.481638 30295 layer_factory.hpp:77] Creating layer conv_d3b-c
I0422 22:48:58.481647 30295 net.cpp:100] Creating Layer conv_d3b-c
I0422 22:48:58.481648 30295 net.cpp:434] conv_d3b-c <- d3b
I0422 22:48:58.481653 30295 net.cpp:408] conv_d3b-c -> d3c
I0422 22:48:58.495705 30295 net.cpp:150] Setting up conv_d3b-c
I0422 22:48:58.495719 30295 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0422 22:48:58.495721 30295 net.cpp:165] Memory required for data: 508847360
I0422 22:48:58.495743 30295 layer_factory.hpp:77] Creating layer relu_d3c
I0422 22:48:58.495746 30295 net.cpp:100] Creating Layer relu_d3c
I0422 22:48:58.495750 30295 net.cpp:434] relu_d3c <- d3c
I0422 22:48:58.495765 30295 net.cpp:395] relu_d3c -> d3c (in-place)
I0422 22:48:58.496541 30295 net.cpp:150] Setting up relu_d3c
I0422 22:48:58.496552 30295 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0422 22:48:58.496570 30295 net.cpp:165] Memory required for data: 513180928
I0422 22:48:58.496572 30295 layer_factory.hpp:77] Creating layer d3c_relu_d3c_0_split
I0422 22:48:58.496577 30295 net.cpp:100] Creating Layer d3c_relu_d3c_0_split
I0422 22:48:58.496580 30295 net.cpp:434] d3c_relu_d3c_0_split <- d3c
I0422 22:48:58.496585 30295 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_0
I0422 22:48:58.496592 30295 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_1
I0422 22:48:58.496646 30295 net.cpp:150] Setting up d3c_relu_d3c_0_split
I0422 22:48:58.496651 30295 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0422 22:48:58.496654 30295 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0422 22:48:58.496656 30295 net.cpp:165] Memory required for data: 521848064
I0422 22:48:58.496659 30295 layer_factory.hpp:77] Creating layer pool_d3c-4a
I0422 22:48:58.496664 30295 net.cpp:100] Creating Layer pool_d3c-4a
I0422 22:48:58.496666 30295 net.cpp:434] pool_d3c-4a <- d3c_relu_d3c_0_split_0
I0422 22:48:58.496670 30295 net.cpp:408] pool_d3c-4a -> d4a
I0422 22:48:58.496701 30295 net.cpp:150] Setting up pool_d3c-4a
I0422 22:48:58.496707 30295 net.cpp:157] Top shape: 1 512 23 23 (270848)
I0422 22:48:58.496711 30295 net.cpp:165] Memory required for data: 522931456
I0422 22:48:58.496712 30295 layer_factory.hpp:77] Creating layer conv_d4a-b
I0422 22:48:58.496719 30295 net.cpp:100] Creating Layer conv_d4a-b
I0422 22:48:58.496721 30295 net.cpp:434] conv_d4a-b <- d4a
I0422 22:48:58.496726 30295 net.cpp:408] conv_d4a-b -> d4b
I0422 22:48:58.524914 30295 net.cpp:150] Setting up conv_d4a-b
I0422 22:48:58.524927 30295 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0422 22:48:58.524946 30295 net.cpp:165] Memory required for data: 524737792
I0422 22:48:58.524956 30295 layer_factory.hpp:77] Creating layer relu_d4b
I0422 22:48:58.524961 30295 net.cpp:100] Creating Layer relu_d4b
I0422 22:48:58.524965 30295 net.cpp:434] relu_d4b <- d4b
I0422 22:48:58.524968 30295 net.cpp:395] relu_d4b -> d4b (in-place)
I0422 22:48:58.525158 30295 net.cpp:150] Setting up relu_d4b
I0422 22:48:58.525167 30295 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0422 22:48:58.525169 30295 net.cpp:165] Memory required for data: 526544128
I0422 22:48:58.525171 30295 layer_factory.hpp:77] Creating layer conv_d4b-c
I0422 22:48:58.525180 30295 net.cpp:100] Creating Layer conv_d4b-c
I0422 22:48:58.525182 30295 net.cpp:434] conv_d4b-c <- d4b
I0422 22:48:58.525188 30295 net.cpp:408] conv_d4b-c -> d4c
I0422 22:48:58.582268 30295 net.cpp:150] Setting up conv_d4b-c
I0422 22:48:58.582307 30295 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0422 22:48:58.582310 30295 net.cpp:165] Memory required for data: 528022784
I0422 22:48:58.582317 30295 layer_factory.hpp:77] Creating layer relu_d4c
I0422 22:48:58.582324 30295 net.cpp:100] Creating Layer relu_d4c
I0422 22:48:58.582329 30295 net.cpp:434] relu_d4c <- d4c
I0422 22:48:58.582334 30295 net.cpp:395] relu_d4c -> d4c (in-place)
I0422 22:48:58.582571 30295 net.cpp:150] Setting up relu_d4c
I0422 22:48:58.582579 30295 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0422 22:48:58.582582 30295 net.cpp:165] Memory required for data: 529501440
I0422 22:48:58.582586 30295 layer_factory.hpp:77] Creating layer upconv_d4c_u3a
I0422 22:48:58.582593 30295 net.cpp:100] Creating Layer upconv_d4c_u3a
I0422 22:48:58.582595 30295 net.cpp:434] upconv_d4c_u3a <- d4c
I0422 22:48:58.582602 30295 net.cpp:408] upconv_d4c_u3a -> u3a
I0422 22:48:58.595625 30295 net.cpp:150] Setting up upconv_d4c_u3a
I0422 22:48:58.595638 30295 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0422 22:48:58.595640 30295 net.cpp:165] Memory required for data: 532458752
I0422 22:48:58.595645 30295 layer_factory.hpp:77] Creating layer relu_u3a
I0422 22:48:58.595650 30295 net.cpp:100] Creating Layer relu_u3a
I0422 22:48:58.595654 30295 net.cpp:434] relu_u3a <- u3a
I0422 22:48:58.595674 30295 net.cpp:395] relu_u3a -> u3a (in-place)
I0422 22:48:58.595865 30295 net.cpp:150] Setting up relu_u3a
I0422 22:48:58.595875 30295 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0422 22:48:58.595877 30295 net.cpp:165] Memory required for data: 535416064
I0422 22:48:58.595880 30295 layer_factory.hpp:77] Creating layer u3a_relu_u3a_0_split
I0422 22:48:58.595885 30295 net.cpp:100] Creating Layer u3a_relu_u3a_0_split
I0422 22:48:58.595887 30295 net.cpp:434] u3a_relu_u3a_0_split <- u3a
I0422 22:48:58.595891 30295 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_0
I0422 22:48:58.595896 30295 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_1
I0422 22:48:58.595937 30295 net.cpp:150] Setting up u3a_relu_u3a_0_split
I0422 22:48:58.595942 30295 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0422 22:48:58.595945 30295 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0422 22:48:58.595947 30295 net.cpp:165] Memory required for data: 541330688
I0422 22:48:58.595950 30295 layer_factory.hpp:77] Creating layer crop_d3c-d3cc
I0422 22:48:58.595960 30295 net.cpp:100] Creating Layer crop_d3c-d3cc
I0422 22:48:58.595963 30295 net.cpp:434] crop_d3c-d3cc <- d3c_relu_d3c_0_split_1
I0422 22:48:58.595965 30295 net.cpp:434] crop_d3c-d3cc <- u3a_relu_u3a_0_split_0
I0422 22:48:58.595970 30295 net.cpp:408] crop_d3c-d3cc -> d3cc
I0422 22:48:58.595991 30295 net.cpp:150] Setting up crop_d3c-d3cc
I0422 22:48:58.595995 30295 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0422 22:48:58.595998 30295 net.cpp:165] Memory required for data: 544288000
I0422 22:48:58.596000 30295 layer_factory.hpp:77] Creating layer concat_d3cc_u3a-b
I0422 22:48:58.596005 30295 net.cpp:100] Creating Layer concat_d3cc_u3a-b
I0422 22:48:58.596007 30295 net.cpp:434] concat_d3cc_u3a-b <- u3a_relu_u3a_0_split_1
I0422 22:48:58.596010 30295 net.cpp:434] concat_d3cc_u3a-b <- d3cc
I0422 22:48:58.596015 30295 net.cpp:408] concat_d3cc_u3a-b -> u3b
I0422 22:48:58.596035 30295 net.cpp:150] Setting up concat_d3cc_u3a-b
I0422 22:48:58.596040 30295 net.cpp:157] Top shape: 1 1024 38 38 (1478656)
I0422 22:48:58.596041 30295 net.cpp:165] Memory required for data: 550202624
I0422 22:48:58.596043 30295 layer_factory.hpp:77] Creating layer conv_u3b-c
I0422 22:48:58.596050 30295 net.cpp:100] Creating Layer conv_u3b-c
I0422 22:48:58.596052 30295 net.cpp:434] conv_u3b-c <- u3b
I0422 22:48:58.596057 30295 net.cpp:408] conv_u3b-c -> u3c
I0422 22:48:58.624203 30295 net.cpp:150] Setting up conv_u3b-c
I0422 22:48:58.624218 30295 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0422 22:48:58.624238 30295 net.cpp:165] Memory required for data: 552856832
I0422 22:48:58.624243 30295 layer_factory.hpp:77] Creating layer relu_u3c
I0422 22:48:58.624248 30295 net.cpp:100] Creating Layer relu_u3c
I0422 22:48:58.624251 30295 net.cpp:434] relu_u3c <- u3c
I0422 22:48:58.624258 30295 net.cpp:395] relu_u3c -> u3c (in-place)
I0422 22:48:58.625113 30295 net.cpp:150] Setting up relu_u3c
I0422 22:48:58.625125 30295 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0422 22:48:58.625144 30295 net.cpp:165] Memory required for data: 555511040
I0422 22:48:58.625145 30295 layer_factory.hpp:77] Creating layer conv_u3c-d
I0422 22:48:58.625154 30295 net.cpp:100] Creating Layer conv_u3c-d
I0422 22:48:58.625157 30295 net.cpp:434] conv_u3c-d <- u3c
I0422 22:48:58.625164 30295 net.cpp:408] conv_u3c-d -> u3d
I0422 22:48:58.640442 30295 net.cpp:150] Setting up conv_u3c-d
I0422 22:48:58.640455 30295 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0422 22:48:58.640473 30295 net.cpp:165] Memory required for data: 557878528
I0422 22:48:58.640480 30295 layer_factory.hpp:77] Creating layer relu_u3d
I0422 22:48:58.640483 30295 net.cpp:100] Creating Layer relu_u3d
I0422 22:48:58.640486 30295 net.cpp:434] relu_u3d <- u3d
I0422 22:48:58.640492 30295 net.cpp:395] relu_u3d -> u3d (in-place)
I0422 22:48:58.640683 30295 net.cpp:150] Setting up relu_u3d
I0422 22:48:58.640692 30295 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0422 22:48:58.640694 30295 net.cpp:165] Memory required for data: 560246016
I0422 22:48:58.640697 30295 layer_factory.hpp:77] Creating layer upconv_u3d_u2a
I0422 22:48:58.640722 30295 net.cpp:100] Creating Layer upconv_u3d_u2a
I0422 22:48:58.640724 30295 net.cpp:434] upconv_u3d_u2a <- u3d
I0422 22:48:58.640732 30295 net.cpp:408] upconv_u3d_u2a -> u2a
I0422 22:48:58.644465 30295 net.cpp:150] Setting up upconv_u3d_u2a
I0422 22:48:58.644477 30295 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0422 22:48:58.644479 30295 net.cpp:165] Memory required for data: 564980992
I0422 22:48:58.644501 30295 layer_factory.hpp:77] Creating layer relu_u2a
I0422 22:48:58.644507 30295 net.cpp:100] Creating Layer relu_u2a
I0422 22:48:58.644510 30295 net.cpp:434] relu_u2a <- u2a
I0422 22:48:58.644513 30295 net.cpp:395] relu_u2a -> u2a (in-place)
I0422 22:48:58.644686 30295 net.cpp:150] Setting up relu_u2a
I0422 22:48:58.644695 30295 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0422 22:48:58.644697 30295 net.cpp:165] Memory required for data: 569715968
I0422 22:48:58.644701 30295 layer_factory.hpp:77] Creating layer u2a_relu_u2a_0_split
I0422 22:48:58.644706 30295 net.cpp:100] Creating Layer u2a_relu_u2a_0_split
I0422 22:48:58.644709 30295 net.cpp:434] u2a_relu_u2a_0_split <- u2a
I0422 22:48:58.644714 30295 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_0
I0422 22:48:58.644728 30295 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_1
I0422 22:48:58.644773 30295 net.cpp:150] Setting up u2a_relu_u2a_0_split
I0422 22:48:58.644780 30295 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0422 22:48:58.644783 30295 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0422 22:48:58.644785 30295 net.cpp:165] Memory required for data: 579185920
I0422 22:48:58.644788 30295 layer_factory.hpp:77] Creating layer crop_d2c-d2cc
I0422 22:48:58.644794 30295 net.cpp:100] Creating Layer crop_d2c-d2cc
I0422 22:48:58.644798 30295 net.cpp:434] crop_d2c-d2cc <- d2c_relu_d2c_0_split_1
I0422 22:48:58.644801 30295 net.cpp:434] crop_d2c-d2cc <- u2a_relu_u2a_0_split_0
I0422 22:48:58.644807 30295 net.cpp:408] crop_d2c-d2cc -> d2cc
I0422 22:48:58.644834 30295 net.cpp:150] Setting up crop_d2c-d2cc
I0422 22:48:58.644840 30295 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0422 22:48:58.644843 30295 net.cpp:165] Memory required for data: 583920896
I0422 22:48:58.644845 30295 layer_factory.hpp:77] Creating layer concat_d2cc_u2a-b
I0422 22:48:58.644851 30295 net.cpp:100] Creating Layer concat_d2cc_u2a-b
I0422 22:48:58.644855 30295 net.cpp:434] concat_d2cc_u2a-b <- u2a_relu_u2a_0_split_1
I0422 22:48:58.644857 30295 net.cpp:434] concat_d2cc_u2a-b <- d2cc
I0422 22:48:58.644862 30295 net.cpp:408] concat_d2cc_u2a-b -> u2b
I0422 22:48:58.644887 30295 net.cpp:150] Setting up concat_d2cc_u2a-b
I0422 22:48:58.644894 30295 net.cpp:157] Top shape: 1 512 68 68 (2367488)
I0422 22:48:58.644896 30295 net.cpp:165] Memory required for data: 593390848
I0422 22:48:58.644898 30295 layer_factory.hpp:77] Creating layer conv_u2b-c
I0422 22:48:58.644907 30295 net.cpp:100] Creating Layer conv_u2b-c
I0422 22:48:58.644909 30295 net.cpp:434] conv_u2b-c <- u2b
I0422 22:48:58.644914 30295 net.cpp:408] conv_u2b-c -> u2c
I0422 22:48:58.652603 30295 net.cpp:150] Setting up conv_u2b-c
I0422 22:48:58.652616 30295 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0422 22:48:58.652618 30295 net.cpp:165] Memory required for data: 597851392
I0422 22:48:58.652639 30295 layer_factory.hpp:77] Creating layer relu_u2c
I0422 22:48:58.652644 30295 net.cpp:100] Creating Layer relu_u2c
I0422 22:48:58.652647 30295 net.cpp:434] relu_u2c <- u2c
I0422 22:48:58.652652 30295 net.cpp:395] relu_u2c -> u2c (in-place)
I0422 22:48:58.653466 30295 net.cpp:150] Setting up relu_u2c
I0422 22:48:58.653478 30295 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0422 22:48:58.653497 30295 net.cpp:165] Memory required for data: 602311936
I0422 22:48:58.653501 30295 layer_factory.hpp:77] Creating layer conv_u2c-d
I0422 22:48:58.653508 30295 net.cpp:100] Creating Layer conv_u2c-d
I0422 22:48:58.653512 30295 net.cpp:434] conv_u2c-d <- u2c
I0422 22:48:58.653517 30295 net.cpp:408] conv_u2c-d -> u2d
I0422 22:48:58.657631 30295 net.cpp:150] Setting up conv_u2c-d
I0422 22:48:58.657655 30295 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0422 22:48:58.657673 30295 net.cpp:165] Memory required for data: 606506240
I0422 22:48:58.657680 30295 layer_factory.hpp:77] Creating layer relu_u2d
I0422 22:48:58.657685 30295 net.cpp:100] Creating Layer relu_u2d
I0422 22:48:58.657688 30295 net.cpp:434] relu_u2d <- u2d
I0422 22:48:58.657694 30295 net.cpp:395] relu_u2d -> u2d (in-place)
I0422 22:48:58.657902 30295 net.cpp:150] Setting up relu_u2d
I0422 22:48:58.657910 30295 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0422 22:48:58.657912 30295 net.cpp:165] Memory required for data: 610700544
I0422 22:48:58.657914 30295 layer_factory.hpp:77] Creating layer upconv_u2d_u1a
I0422 22:48:58.657922 30295 net.cpp:100] Creating Layer upconv_u2d_u1a
I0422 22:48:58.657925 30295 net.cpp:434] upconv_u2d_u1a <- u2d
I0422 22:48:58.657932 30295 net.cpp:408] upconv_u2d_u1a -> u1a
I0422 22:48:58.659657 30295 net.cpp:150] Setting up upconv_u2d_u1a
I0422 22:48:58.659670 30295 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0422 22:48:58.659672 30295 net.cpp:165] Memory required for data: 619089152
I0422 22:48:58.659698 30295 layer_factory.hpp:77] Creating layer relu_u1a
I0422 22:48:58.659703 30295 net.cpp:100] Creating Layer relu_u1a
I0422 22:48:58.659706 30295 net.cpp:434] relu_u1a <- u1a
I0422 22:48:58.659711 30295 net.cpp:395] relu_u1a -> u1a (in-place)
I0422 22:48:58.659884 30295 net.cpp:150] Setting up relu_u1a
I0422 22:48:58.659893 30295 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0422 22:48:58.659895 30295 net.cpp:165] Memory required for data: 627477760
I0422 22:48:58.659898 30295 layer_factory.hpp:77] Creating layer u1a_relu_u1a_0_split
I0422 22:48:58.659904 30295 net.cpp:100] Creating Layer u1a_relu_u1a_0_split
I0422 22:48:58.659906 30295 net.cpp:434] u1a_relu_u1a_0_split <- u1a
I0422 22:48:58.659911 30295 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_0
I0422 22:48:58.659919 30295 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_1
I0422 22:48:58.659961 30295 net.cpp:150] Setting up u1a_relu_u1a_0_split
I0422 22:48:58.659968 30295 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0422 22:48:58.659971 30295 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0422 22:48:58.659973 30295 net.cpp:165] Memory required for data: 644254976
I0422 22:48:58.659976 30295 layer_factory.hpp:77] Creating layer crop_d1c-d1cc
I0422 22:48:58.659981 30295 net.cpp:100] Creating Layer crop_d1c-d1cc
I0422 22:48:58.659986 30295 net.cpp:434] crop_d1c-d1cc <- d1c_relu_d1c_0_split_1
I0422 22:48:58.659989 30295 net.cpp:434] crop_d1c-d1cc <- u1a_relu_u1a_0_split_0
I0422 22:48:58.659994 30295 net.cpp:408] crop_d1c-d1cc -> d1cc
I0422 22:48:58.660019 30295 net.cpp:150] Setting up crop_d1c-d1cc
I0422 22:48:58.660027 30295 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0422 22:48:58.660028 30295 net.cpp:165] Memory required for data: 652643584
I0422 22:48:58.660030 30295 layer_factory.hpp:77] Creating layer concat_d1cc_u1a-b
I0422 22:48:58.660034 30295 net.cpp:100] Creating Layer concat_d1cc_u1a-b
I0422 22:48:58.660038 30295 net.cpp:434] concat_d1cc_u1a-b <- u1a_relu_u1a_0_split_1
I0422 22:48:58.660042 30295 net.cpp:434] concat_d1cc_u1a-b <- d1cc
I0422 22:48:58.660046 30295 net.cpp:408] concat_d1cc_u1a-b -> u1b
I0422 22:48:58.660070 30295 net.cpp:150] Setting up concat_d1cc_u1a-b
I0422 22:48:58.660079 30295 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0422 22:48:58.660080 30295 net.cpp:165] Memory required for data: 669420800
I0422 22:48:58.660082 30295 layer_factory.hpp:77] Creating layer conv_u1b-c
I0422 22:48:58.660090 30295 net.cpp:100] Creating Layer conv_u1b-c
I0422 22:48:58.660094 30295 net.cpp:434] conv_u1b-c <- u1b
I0422 22:48:58.660099 30295 net.cpp:408] conv_u1b-c -> u1c
I0422 22:48:58.661859 30295 net.cpp:150] Setting up conv_u1b-c
I0422 22:48:58.661866 30295 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0422 22:48:58.661870 30295 net.cpp:165] Memory required for data: 677549312
I0422 22:48:58.661890 30295 layer_factory.hpp:77] Creating layer relu_u1c
I0422 22:48:58.661895 30295 net.cpp:100] Creating Layer relu_u1c
I0422 22:48:58.661907 30295 net.cpp:434] relu_u1c <- u1c
I0422 22:48:58.661913 30295 net.cpp:395] relu_u1c -> u1c (in-place)
I0422 22:48:58.662081 30295 net.cpp:150] Setting up relu_u1c
I0422 22:48:58.662089 30295 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0422 22:48:58.662091 30295 net.cpp:165] Memory required for data: 685677824
I0422 22:48:58.662094 30295 layer_factory.hpp:77] Creating layer conv_u1c-d
I0422 22:48:58.662102 30295 net.cpp:100] Creating Layer conv_u1c-d
I0422 22:48:58.662106 30295 net.cpp:434] conv_u1c-d <- u1c
I0422 22:48:58.662111 30295 net.cpp:408] conv_u1c-d -> u1d
I0422 22:48:58.663964 30295 net.cpp:150] Setting up conv_u1c-d
I0422 22:48:58.663976 30295 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0422 22:48:58.663980 30295 net.cpp:165] Memory required for data: 693550336
I0422 22:48:58.664000 30295 layer_factory.hpp:77] Creating layer relu_u1d
I0422 22:48:58.664006 30295 net.cpp:100] Creating Layer relu_u1d
I0422 22:48:58.664010 30295 net.cpp:434] relu_u1d <- u1d
I0422 22:48:58.664013 30295 net.cpp:395] relu_u1d -> u1d (in-place)
I0422 22:48:58.664816 30295 net.cpp:150] Setting up relu_u1d
I0422 22:48:58.664829 30295 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0422 22:48:58.664846 30295 net.cpp:165] Memory required for data: 701422848
I0422 22:48:58.664849 30295 layer_factory.hpp:77] Creating layer upconv_u1d_u0a
I0422 22:48:58.664856 30295 net.cpp:100] Creating Layer upconv_u1d_u0a
I0422 22:48:58.664860 30295 net.cpp:434] upconv_u1d_u0a <- u1d
I0422 22:48:58.664868 30295 net.cpp:408] upconv_u1d_u0a -> u0a
I0422 22:48:58.665547 30295 net.cpp:150] Setting up upconv_u1d_u0a
I0422 22:48:58.665556 30295 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0422 22:48:58.665575 30295 net.cpp:165] Memory required for data: 732912896
I0422 22:48:58.665581 30295 layer_factory.hpp:77] Creating layer relu_u0a
I0422 22:48:58.665585 30295 net.cpp:100] Creating Layer relu_u0a
I0422 22:48:58.665594 30295 net.cpp:434] relu_u0a <- u0a
I0422 22:48:58.665598 30295 net.cpp:395] relu_u0a -> u0a (in-place)
I0422 22:48:58.665794 30295 net.cpp:150] Setting up relu_u0a
I0422 22:48:58.665803 30295 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0422 22:48:58.665805 30295 net.cpp:165] Memory required for data: 764402944
I0422 22:48:58.665808 30295 layer_factory.hpp:77] Creating layer u0a_relu_u0a_0_split
I0422 22:48:58.665812 30295 net.cpp:100] Creating Layer u0a_relu_u0a_0_split
I0422 22:48:58.665815 30295 net.cpp:434] u0a_relu_u0a_0_split <- u0a
I0422 22:48:58.665820 30295 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_0
I0422 22:48:58.665827 30295 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_1
I0422 22:48:58.665871 30295 net.cpp:150] Setting up u0a_relu_u0a_0_split
I0422 22:48:58.665877 30295 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0422 22:48:58.665881 30295 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0422 22:48:58.665884 30295 net.cpp:165] Memory required for data: 827383040
I0422 22:48:58.665885 30295 layer_factory.hpp:77] Creating layer crop_d0c-d0cc
I0422 22:48:58.665891 30295 net.cpp:100] Creating Layer crop_d0c-d0cc
I0422 22:48:58.665894 30295 net.cpp:434] crop_d0c-d0cc <- d0c_relu_d0c_0_split_1
I0422 22:48:58.665899 30295 net.cpp:434] crop_d0c-d0cc <- u0a_relu_u0a_0_split_0
I0422 22:48:58.665904 30295 net.cpp:408] crop_d0c-d0cc -> d0cc
I0422 22:48:58.665930 30295 net.cpp:150] Setting up crop_d0c-d0cc
I0422 22:48:58.665938 30295 net.cpp:157] Top shape: 1 64 248 248 (3936256)
I0422 22:48:58.665941 30295 net.cpp:165] Memory required for data: 843128064
I0422 22:48:58.665943 30295 layer_factory.hpp:77] Creating layer concat_d0cc_u0a-b
I0422 22:48:58.665946 30295 net.cpp:100] Creating Layer concat_d0cc_u0a-b
I0422 22:48:58.665949 30295 net.cpp:434] concat_d0cc_u0a-b <- u0a_relu_u0a_0_split_1
I0422 22:48:58.665953 30295 net.cpp:434] concat_d0cc_u0a-b <- d0cc
I0422 22:48:58.665957 30295 net.cpp:408] concat_d0cc_u0a-b -> u0b
I0422 22:48:58.665980 30295 net.cpp:150] Setting up concat_d0cc_u0a-b
I0422 22:48:58.665984 30295 net.cpp:157] Top shape: 1 192 248 248 (11808768)
I0422 22:48:58.665999 30295 net.cpp:165] Memory required for data: 890363136
I0422 22:48:58.666002 30295 layer_factory.hpp:77] Creating layer conv_u0b-c
I0422 22:48:58.666012 30295 net.cpp:100] Creating Layer conv_u0b-c
I0422 22:48:58.666014 30295 net.cpp:434] conv_u0b-c <- u0b
I0422 22:48:58.666020 30295 net.cpp:408] conv_u0b-c -> u0c
I0422 22:48:58.666893 30295 net.cpp:150] Setting up conv_u0b-c
I0422 22:48:58.666901 30295 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0422 22:48:58.666903 30295 net.cpp:165] Memory required for data: 905855232
I0422 22:48:58.666924 30295 layer_factory.hpp:77] Creating layer relu_u0c
I0422 22:48:58.666929 30295 net.cpp:100] Creating Layer relu_u0c
I0422 22:48:58.666931 30295 net.cpp:434] relu_u0c <- u0c
I0422 22:48:58.666935 30295 net.cpp:395] relu_u0c -> u0c (in-place)
I0422 22:48:58.667105 30295 net.cpp:150] Setting up relu_u0c
I0422 22:48:58.667114 30295 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0422 22:48:58.667116 30295 net.cpp:165] Memory required for data: 921347328
I0422 22:48:58.667119 30295 layer_factory.hpp:77] Creating layer conv_u0c-d
I0422 22:48:58.667127 30295 net.cpp:100] Creating Layer conv_u0c-d
I0422 22:48:58.667130 30295 net.cpp:434] conv_u0c-d <- u0c
I0422 22:48:58.667135 30295 net.cpp:408] conv_u0c-d -> u0d
I0422 22:48:58.667628 30295 net.cpp:150] Setting up conv_u0c-d
I0422 22:48:58.667634 30295 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0422 22:48:58.667636 30295 net.cpp:165] Memory required for data: 936588544
I0422 22:48:58.667657 30295 layer_factory.hpp:77] Creating layer relu_u0d
I0422 22:48:58.667668 30295 net.cpp:100] Creating Layer relu_u0d
I0422 22:48:58.667671 30295 net.cpp:434] relu_u0d <- u0d
I0422 22:48:58.667675 30295 net.cpp:395] relu_u0d -> u0d (in-place)
I0422 22:48:58.667840 30295 net.cpp:150] Setting up relu_u0d
I0422 22:48:58.667847 30295 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0422 22:48:58.667850 30295 net.cpp:165] Memory required for data: 951829760
I0422 22:48:58.667853 30295 layer_factory.hpp:77] Creating layer conv_u0d-score
I0422 22:48:58.667860 30295 net.cpp:100] Creating Layer conv_u0d-score
I0422 22:48:58.667862 30295 net.cpp:434] conv_u0d-score <- u0d
I0422 22:48:58.667870 30295 net.cpp:408] conv_u0d-score -> score
I0422 22:48:58.668143 30295 net.cpp:150] Setting up conv_u0d-score
I0422 22:48:58.668149 30295 net.cpp:157] Top shape: 1 4 244 244 (238144)
I0422 22:48:58.668151 30295 net.cpp:165] Memory required for data: 952782336
I0422 22:48:58.668157 30295 layer_factory.hpp:77] Creating layer softmax
I0422 22:48:58.668162 30295 net.cpp:100] Creating Layer softmax
I0422 22:48:58.668164 30295 net.cpp:434] softmax <- score
I0422 22:48:58.668169 30295 net.cpp:408] softmax -> softmax_out
I0422 22:48:58.669018 30295 net.cpp:150] Setting up softmax
I0422 22:48:58.669029 30295 net.cpp:157] Top shape: 1 4 244 244 (238144)
I0422 22:48:58.669031 30295 net.cpp:165] Memory required for data: 953734912
I0422 22:48:58.669050 30295 layer_factory.hpp:77] Creating layer reshapelab
I0422 22:48:58.669057 30295 net.cpp:100] Creating Layer reshapelab
I0422 22:48:58.669060 30295 net.cpp:434] reshapelab <- label
I0422 22:48:58.669065 30295 net.cpp:408] reshapelab -> label_flat
I0422 22:48:58.669093 30295 net.cpp:150] Setting up reshapelab
I0422 22:48:58.669100 30295 net.cpp:157] Top shape: 1 59536 (59536)
I0422 22:48:58.669102 30295 net.cpp:165] Memory required for data: 953973056
I0422 22:48:58.669104 30295 layer_factory.hpp:77] Creating layer reshaperes
I0422 22:48:58.669109 30295 net.cpp:100] Creating Layer reshaperes
I0422 22:48:58.669113 30295 net.cpp:434] reshaperes <- softmax_out
I0422 22:48:58.669118 30295 net.cpp:408] reshaperes -> softmax_out_flat
I0422 22:48:58.669144 30295 net.cpp:150] Setting up reshaperes
I0422 22:48:58.669148 30295 net.cpp:157] Top shape: 1 4 59536 (238144)
I0422 22:48:58.669152 30295 net.cpp:165] Memory required for data: 954925632
I0422 22:48:58.669154 30295 layer_factory.hpp:77] Creating layer loss
I0422 22:48:58.669193 30295 net.cpp:100] Creating Layer loss
I0422 22:48:58.669196 30295 net.cpp:434] loss <- softmax_out_flat
I0422 22:48:58.669215 30295 net.cpp:434] loss <- label_flat
I0422 22:48:58.669220 30295 net.cpp:408] loss -> loss
I0422 22:48:58.670349 30295 net.cpp:150] Setting up loss
I0422 22:48:58.670361 30295 net.cpp:157] Top shape: 4 (4)
I0422 22:48:58.670363 30295 net.cpp:160]     with loss weight 1
I0422 22:48:58.670388 30295 net.cpp:165] Memory required for data: 954925648
I0422 22:48:58.670392 30295 net.cpp:226] loss needs backward computation.
I0422 22:48:58.670395 30295 net.cpp:226] reshaperes needs backward computation.
I0422 22:48:58.670398 30295 net.cpp:228] reshapelab does not need backward computation.
I0422 22:48:58.670402 30295 net.cpp:226] softmax needs backward computation.
I0422 22:48:58.670403 30295 net.cpp:226] conv_u0d-score needs backward computation.
I0422 22:48:58.670405 30295 net.cpp:226] relu_u0d needs backward computation.
I0422 22:48:58.670408 30295 net.cpp:226] conv_u0c-d needs backward computation.
I0422 22:48:58.670410 30295 net.cpp:226] relu_u0c needs backward computation.
I0422 22:48:58.670413 30295 net.cpp:226] conv_u0b-c needs backward computation.
I0422 22:48:58.670414 30295 net.cpp:226] concat_d0cc_u0a-b needs backward computation.
I0422 22:48:58.670419 30295 net.cpp:226] crop_d0c-d0cc needs backward computation.
I0422 22:48:58.670423 30295 net.cpp:226] u0a_relu_u0a_0_split needs backward computation.
I0422 22:48:58.670424 30295 net.cpp:226] relu_u0a needs backward computation.
I0422 22:48:58.670428 30295 net.cpp:226] upconv_u1d_u0a needs backward computation.
I0422 22:48:58.670431 30295 net.cpp:226] relu_u1d needs backward computation.
I0422 22:48:58.670433 30295 net.cpp:226] conv_u1c-d needs backward computation.
I0422 22:48:58.670436 30295 net.cpp:226] relu_u1c needs backward computation.
I0422 22:48:58.670439 30295 net.cpp:226] conv_u1b-c needs backward computation.
I0422 22:48:58.670442 30295 net.cpp:226] concat_d1cc_u1a-b needs backward computation.
I0422 22:48:58.670445 30295 net.cpp:226] crop_d1c-d1cc needs backward computation.
I0422 22:48:58.670449 30295 net.cpp:226] u1a_relu_u1a_0_split needs backward computation.
I0422 22:48:58.670451 30295 net.cpp:226] relu_u1a needs backward computation.
I0422 22:48:58.670454 30295 net.cpp:226] upconv_u2d_u1a needs backward computation.
I0422 22:48:58.670457 30295 net.cpp:226] relu_u2d needs backward computation.
I0422 22:48:58.670459 30295 net.cpp:226] conv_u2c-d needs backward computation.
I0422 22:48:58.670462 30295 net.cpp:226] relu_u2c needs backward computation.
I0422 22:48:58.670465 30295 net.cpp:226] conv_u2b-c needs backward computation.
I0422 22:48:58.670469 30295 net.cpp:226] concat_d2cc_u2a-b needs backward computation.
I0422 22:48:58.670471 30295 net.cpp:226] crop_d2c-d2cc needs backward computation.
I0422 22:48:58.670475 30295 net.cpp:226] u2a_relu_u2a_0_split needs backward computation.
I0422 22:48:58.670478 30295 net.cpp:226] relu_u2a needs backward computation.
I0422 22:48:58.670481 30295 net.cpp:226] upconv_u3d_u2a needs backward computation.
I0422 22:48:58.670483 30295 net.cpp:226] relu_u3d needs backward computation.
I0422 22:48:58.670485 30295 net.cpp:226] conv_u3c-d needs backward computation.
I0422 22:48:58.670490 30295 net.cpp:226] relu_u3c needs backward computation.
I0422 22:48:58.670492 30295 net.cpp:226] conv_u3b-c needs backward computation.
I0422 22:48:58.670495 30295 net.cpp:226] concat_d3cc_u3a-b needs backward computation.
I0422 22:48:58.670498 30295 net.cpp:226] crop_d3c-d3cc needs backward computation.
I0422 22:48:58.670502 30295 net.cpp:226] u3a_relu_u3a_0_split needs backward computation.
I0422 22:48:58.670505 30295 net.cpp:226] relu_u3a needs backward computation.
I0422 22:48:58.670507 30295 net.cpp:226] upconv_d4c_u3a needs backward computation.
I0422 22:48:58.670511 30295 net.cpp:226] relu_d4c needs backward computation.
I0422 22:48:58.670514 30295 net.cpp:226] conv_d4b-c needs backward computation.
I0422 22:48:58.670517 30295 net.cpp:226] relu_d4b needs backward computation.
I0422 22:48:58.670521 30295 net.cpp:226] conv_d4a-b needs backward computation.
I0422 22:48:58.670536 30295 net.cpp:226] pool_d3c-4a needs backward computation.
I0422 22:48:58.670541 30295 net.cpp:226] d3c_relu_d3c_0_split needs backward computation.
I0422 22:48:58.670542 30295 net.cpp:226] relu_d3c needs backward computation.
I0422 22:48:58.670545 30295 net.cpp:226] conv_d3b-c needs backward computation.
I0422 22:48:58.670547 30295 net.cpp:226] relu_d3b needs backward computation.
I0422 22:48:58.670552 30295 net.cpp:226] conv_d3a-b needs backward computation.
I0422 22:48:58.670553 30295 net.cpp:226] pool_d2c-3a needs backward computation.
I0422 22:48:58.670557 30295 net.cpp:226] d2c_relu_d2c_0_split needs backward computation.
I0422 22:48:58.670559 30295 net.cpp:226] relu_d2c needs backward computation.
I0422 22:48:58.670563 30295 net.cpp:226] conv_d2b-c needs backward computation.
I0422 22:48:58.670567 30295 net.cpp:226] relu_d2b needs backward computation.
I0422 22:48:58.670568 30295 net.cpp:226] conv_d2a-b needs backward computation.
I0422 22:48:58.670572 30295 net.cpp:226] pool_d1c-2a needs backward computation.
I0422 22:48:58.670575 30295 net.cpp:226] d1c_relu_d1c_0_split needs backward computation.
I0422 22:48:58.670578 30295 net.cpp:226] relu_d1c needs backward computation.
I0422 22:48:58.670580 30295 net.cpp:226] conv_d1b-c needs backward computation.
I0422 22:48:58.670583 30295 net.cpp:226] relu_d1b needs backward computation.
I0422 22:48:58.670586 30295 net.cpp:226] conv_d1a-b needs backward computation.
I0422 22:48:58.670589 30295 net.cpp:226] pool_d0c-1a needs backward computation.
I0422 22:48:58.670593 30295 net.cpp:226] d0c_relu_d0c_0_split needs backward computation.
I0422 22:48:58.670595 30295 net.cpp:226] relu_d0c needs backward computation.
I0422 22:48:58.670598 30295 net.cpp:226] conv_d0b-c needs backward computation.
I0422 22:48:58.670601 30295 net.cpp:226] relu_d0b needs backward computation.
I0422 22:48:58.670603 30295 net.cpp:226] conv_d0a-b needs backward computation.
I0422 22:48:58.670608 30295 net.cpp:228] loaddata does not need backward computation.
I0422 22:48:58.670615 30295 net.cpp:270] This network produces output loss
I0422 22:48:58.670665 30295 net.cpp:283] Network initialization done.
I0422 22:48:58.670850 30295 solver.cpp:60] Solver scaffolding done.
I0422 22:48:58.682351 30295 solver.cpp:337] Iteration 0, Testing net (#0)
I0422 22:48:58.685403 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0422 22:48:58.685412 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 22:48:58.693703 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0422 22:48:58.700505 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 22:48:58.700517 30295 net.cpp:693] Ignoring source layer visualize
I0422 22:48:58.700520 30295 net.cpp:693] Ignoring source layer fake
I0422 22:52:36.207041 30295 solver.cpp:404]     Test net output #0: loss = 0.708474 (* 1 = 0.708474 loss)
I0422 22:52:36.207113 30295 solver.cpp:404]     Test net output #1: loss = 0.0520358 (* 1 = 0.0520358 loss)
I0422 22:52:36.207119 30295 solver.cpp:404]     Test net output #2: loss = 5.22526e-05 (* 1 = 5.22526e-05 loss)
I0422 22:52:36.207123 30295 solver.cpp:404]     Test net output #3: loss = 0.0567426 (* 1 = 0.0567426 loss)
I0422 22:52:36.912295 30295 solver.cpp:228] Iteration 0, loss = 0.771052
I0422 22:52:36.912339 30295 solver.cpp:244]     Train net output #0: loss = 0.660808 (* 1 = 0.660808 loss)
I0422 22:52:36.912345 30295 solver.cpp:244]     Train net output #1: loss = 0.030148 (* 1 = 0.030148 loss)
I0422 22:52:36.912349 30295 solver.cpp:244]     Train net output #2: loss = 0 (* 1 = 0 loss)
I0422 22:52:36.912354 30295 solver.cpp:244]     Train net output #3: loss = 0.0800967 (* 1 = 0.0800967 loss)
I0422 22:52:36.912359 30295 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0422 22:54:18.010783 30295 solver.cpp:228] Iteration 100, loss = 1.5948
I0422 22:54:18.010944 30295 solver.cpp:244]     Train net output #0: loss = 0.929691 (* 1 = 0.929691 loss)
I0422 22:54:18.010951 30295 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0422 22:54:18.010957 30295 solver.cpp:244]     Train net output #2: loss = 0.665107 (* 1 = 0.665107 loss)
I0422 22:54:18.010962 30295 solver.cpp:244]     Train net output #3: loss = 0 (* 1 = 0 loss)
I0422 22:54:18.010965 30295 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0422 22:55:57.823217 30295 solver.cpp:228] Iteration 200, loss = 1.63601
I0422 22:55:57.823377 30295 solver.cpp:244]     Train net output #0: loss = 0.941408 (* 1 = 0.941408 loss)
I0422 22:55:57.823385 30295 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0422 22:55:57.823390 30295 solver.cpp:244]     Train net output #2: loss = 0.694602 (* 1 = 0.694602 loss)
I0422 22:55:57.823395 30295 solver.cpp:244]     Train net output #3: loss = 0 (* 1 = 0 loss)
I0422 22:55:57.823400 30295 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0422 22:57:38.789505 30295 solver.cpp:228] Iteration 300, loss = 1.89797
I0422 22:57:38.790861 30295 solver.cpp:244]     Train net output #0: loss = 0.955417 (* 1 = 0.955417 loss)
I0422 22:57:38.790868 30295 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0422 22:57:38.790871 30295 solver.cpp:244]     Train net output #2: loss = 0.694334 (* 1 = 0.694334 loss)
I0422 22:57:38.790876 30295 solver.cpp:244]     Train net output #3: loss = 0.248221 (* 1 = 0.248221 loss)
I0422 22:57:38.790880 30295 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0422 22:59:20.440255 30295 solver.cpp:228] Iteration 400, loss = 1.93141
I0422 22:59:20.441934 30295 solver.cpp:244]     Train net output #0: loss = 0.917047 (* 1 = 0.917047 loss)
I0422 22:59:20.441943 30295 solver.cpp:244]     Train net output #1: loss = 0.024782 (* 1 = 0.024782 loss)
I0422 22:59:20.441947 30295 solver.cpp:244]     Train net output #2: loss = 0.766686 (* 1 = 0.766686 loss)
I0422 22:59:20.441951 30295 solver.cpp:244]     Train net output #3: loss = 0.222899 (* 1 = 0.222899 loss)
I0422 22:59:20.441956 30295 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0422 23:01:02.423336 30295 solver.cpp:228] Iteration 500, loss = 2.18258
I0422 23:01:02.423493 30295 solver.cpp:244]     Train net output #0: loss = 0.939722 (* 1 = 0.939722 loss)
I0422 23:01:02.423501 30295 solver.cpp:244]     Train net output #1: loss = 0.209692 (* 1 = 0.209692 loss)
I0422 23:01:02.423506 30295 solver.cpp:244]     Train net output #2: loss = 0.811428 (* 1 = 0.811428 loss)
I0422 23:01:02.423511 30295 solver.cpp:244]     Train net output #3: loss = 0.221739 (* 1 = 0.221739 loss)
I0422 23:01:02.423516 30295 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0422 23:02:43.772815 30295 solver.cpp:228] Iteration 600, loss = 2.66828
I0422 23:02:43.772941 30295 solver.cpp:244]     Train net output #0: loss = 0.954467 (* 1 = 0.954467 loss)
I0422 23:02:43.772949 30295 solver.cpp:244]     Train net output #1: loss = 0.506017 (* 1 = 0.506017 loss)
I0422 23:02:43.772953 30295 solver.cpp:244]     Train net output #2: loss = 0.852281 (* 1 = 0.852281 loss)
I0422 23:02:43.772958 30295 solver.cpp:244]     Train net output #3: loss = 0.355516 (* 1 = 0.355516 loss)
I0422 23:02:43.772964 30295 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0422 23:04:23.515427 30295 solver.cpp:228] Iteration 700, loss = 2.81001
I0422 23:04:23.515578 30295 solver.cpp:244]     Train net output #0: loss = 0.95382 (* 1 = 0.95382 loss)
I0422 23:04:23.515586 30295 solver.cpp:244]     Train net output #1: loss = 0.547868 (* 1 = 0.547868 loss)
I0422 23:04:23.515590 30295 solver.cpp:244]     Train net output #2: loss = 0.832008 (* 1 = 0.832008 loss)
I0422 23:04:23.515596 30295 solver.cpp:244]     Train net output #3: loss = 0.476318 (* 1 = 0.476318 loss)
I0422 23:04:23.515600 30295 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0422 23:06:05.024765 30295 solver.cpp:228] Iteration 800, loss = 2.48534
I0422 23:06:05.024955 30295 solver.cpp:244]     Train net output #0: loss = 0.961709 (* 1 = 0.961709 loss)
I0422 23:06:05.024962 30295 solver.cpp:244]     Train net output #1: loss = 0.28524 (* 1 = 0.28524 loss)
I0422 23:06:05.024967 30295 solver.cpp:244]     Train net output #2: loss = 0.848194 (* 1 = 0.848194 loss)
I0422 23:06:05.024972 30295 solver.cpp:244]     Train net output #3: loss = 0.390198 (* 1 = 0.390198 loss)
I0422 23:06:05.024977 30295 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0422 23:07:46.265391 30295 solver.cpp:228] Iteration 900, loss = 2.34755
I0422 23:07:46.265564 30295 solver.cpp:244]     Train net output #0: loss = 0.972135 (* 1 = 0.972135 loss)
I0422 23:07:46.265573 30295 solver.cpp:244]     Train net output #1: loss = 0.354213 (* 1 = 0.354213 loss)
I0422 23:07:46.265578 30295 solver.cpp:244]     Train net output #2: loss = 0.648428 (* 1 = 0.648428 loss)
I0422 23:07:46.265583 30295 solver.cpp:244]     Train net output #3: loss = 0.372771 (* 1 = 0.372771 loss)
I0422 23:07:46.265586 30295 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0422 23:09:26.762117 30295 solver.cpp:337] Iteration 1000, Testing net (#0)
I0422 23:09:26.762281 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0422 23:09:26.762286 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 23:09:26.762290 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0422 23:09:26.762313 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 23:09:26.762316 30295 net.cpp:693] Ignoring source layer visualize
I0422 23:09:26.762320 30295 net.cpp:693] Ignoring source layer fake
I0422 23:13:04.478559 30295 solver.cpp:404]     Test net output #0: loss = 0.941168 (* 1 = 0.941168 loss)
I0422 23:13:04.478703 30295 solver.cpp:404]     Test net output #1: loss = 0.352341 (* 1 = 0.352341 loss)
I0422 23:13:04.478710 30295 solver.cpp:404]     Test net output #2: loss = 0.675537 (* 1 = 0.675537 loss)
I0422 23:13:04.478716 30295 solver.cpp:404]     Test net output #3: loss = 0.370859 (* 1 = 0.370859 loss)
I0422 23:13:05.139751 30295 solver.cpp:228] Iteration 1000, loss = 2.52157
I0422 23:13:05.139794 30295 solver.cpp:244]     Train net output #0: loss = 0.958531 (* 1 = 0.958531 loss)
I0422 23:13:05.139799 30295 solver.cpp:244]     Train net output #1: loss = 0.408742 (* 1 = 0.408742 loss)
I0422 23:13:05.139804 30295 solver.cpp:244]     Train net output #2: loss = 0.706546 (* 1 = 0.706546 loss)
I0422 23:13:05.139808 30295 solver.cpp:244]     Train net output #3: loss = 0.447748 (* 1 = 0.447748 loss)
I0422 23:13:05.139814 30295 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0422 23:14:45.063541 30295 solver.cpp:228] Iteration 1100, loss = 2.45923
I0422 23:14:45.063693 30295 solver.cpp:244]     Train net output #0: loss = 0.968123 (* 1 = 0.968123 loss)
I0422 23:14:45.063699 30295 solver.cpp:244]     Train net output #1: loss = 0.348175 (* 1 = 0.348175 loss)
I0422 23:14:45.063704 30295 solver.cpp:244]     Train net output #2: loss = 0.717534 (* 1 = 0.717534 loss)
I0422 23:14:45.063709 30295 solver.cpp:244]     Train net output #3: loss = 0.425401 (* 1 = 0.425401 loss)
I0422 23:14:45.063714 30295 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0422 23:16:26.122112 30295 solver.cpp:228] Iteration 1200, loss = 2.51013
I0422 23:16:26.122261 30295 solver.cpp:244]     Train net output #0: loss = 0.961185 (* 1 = 0.961185 loss)
I0422 23:16:26.122268 30295 solver.cpp:244]     Train net output #1: loss = 0.196638 (* 1 = 0.196638 loss)
I0422 23:16:26.122274 30295 solver.cpp:244]     Train net output #2: loss = 0.892318 (* 1 = 0.892318 loss)
I0422 23:16:26.122278 30295 solver.cpp:244]     Train net output #3: loss = 0.45999 (* 1 = 0.45999 loss)
I0422 23:16:26.122283 30295 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0422 23:18:07.036396 30295 solver.cpp:228] Iteration 1300, loss = 2.02056
I0422 23:18:07.036543 30295 solver.cpp:244]     Train net output #0: loss = 0.959672 (* 1 = 0.959672 loss)
I0422 23:18:07.036550 30295 solver.cpp:244]     Train net output #1: loss = 0.13227 (* 1 = 0.13227 loss)
I0422 23:18:07.036556 30295 solver.cpp:244]     Train net output #2: loss = 0.704624 (* 1 = 0.704624 loss)
I0422 23:18:07.036559 30295 solver.cpp:244]     Train net output #3: loss = 0.223997 (* 1 = 0.223997 loss)
I0422 23:18:07.036564 30295 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0422 23:19:47.911988 30295 solver.cpp:228] Iteration 1400, loss = 2.49144
I0422 23:19:47.912184 30295 solver.cpp:244]     Train net output #0: loss = 0.9662 (* 1 = 0.9662 loss)
I0422 23:19:47.912191 30295 solver.cpp:244]     Train net output #1: loss = 0.368916 (* 1 = 0.368916 loss)
I0422 23:19:47.912196 30295 solver.cpp:244]     Train net output #2: loss = 0.65391 (* 1 = 0.65391 loss)
I0422 23:19:47.912201 30295 solver.cpp:244]     Train net output #3: loss = 0.502416 (* 1 = 0.502416 loss)
I0422 23:19:47.912206 30295 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0422 23:21:29.036788 30295 solver.cpp:228] Iteration 1500, loss = 2.28016
I0422 23:21:29.036924 30295 solver.cpp:244]     Train net output #0: loss = 0.951507 (* 1 = 0.951507 loss)
I0422 23:21:29.036932 30295 solver.cpp:244]     Train net output #1: loss = 0.411093 (* 1 = 0.411093 loss)
I0422 23:21:29.036937 30295 solver.cpp:244]     Train net output #2: loss = 0.631833 (* 1 = 0.631833 loss)
I0422 23:21:29.036942 30295 solver.cpp:244]     Train net output #3: loss = 0.285724 (* 1 = 0.285724 loss)
I0422 23:21:29.036947 30295 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0422 23:23:10.518720 30295 solver.cpp:228] Iteration 1600, loss = 2.46804
I0422 23:23:10.518898 30295 solver.cpp:244]     Train net output #0: loss = 0.7318 (* 1 = 0.7318 loss)
I0422 23:23:10.518905 30295 solver.cpp:244]     Train net output #1: loss = 0.360682 (* 1 = 0.360682 loss)
I0422 23:23:10.518911 30295 solver.cpp:244]     Train net output #2: loss = 0.821218 (* 1 = 0.821218 loss)
I0422 23:23:10.518915 30295 solver.cpp:244]     Train net output #3: loss = 0.554343 (* 1 = 0.554343 loss)
I0422 23:23:10.518920 30295 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0422 23:24:50.429252 30295 solver.cpp:228] Iteration 1700, loss = 2.61147
I0422 23:24:50.429424 30295 solver.cpp:244]     Train net output #0: loss = 0.79796 (* 1 = 0.79796 loss)
I0422 23:24:50.429433 30295 solver.cpp:244]     Train net output #1: loss = 0.495898 (* 1 = 0.495898 loss)
I0422 23:24:50.429450 30295 solver.cpp:244]     Train net output #2: loss = 0.825161 (* 1 = 0.825161 loss)
I0422 23:24:50.429456 30295 solver.cpp:244]     Train net output #3: loss = 0.492447 (* 1 = 0.492447 loss)
I0422 23:24:50.429464 30295 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0422 23:26:31.873747 30295 solver.cpp:228] Iteration 1800, loss = 2.64393
I0422 23:26:31.873906 30295 solver.cpp:244]     Train net output #0: loss = 0.960337 (* 1 = 0.960337 loss)
I0422 23:26:31.873914 30295 solver.cpp:244]     Train net output #1: loss = 0.485448 (* 1 = 0.485448 loss)
I0422 23:26:31.873919 30295 solver.cpp:244]     Train net output #2: loss = 0.74245 (* 1 = 0.74245 loss)
I0422 23:26:31.873924 30295 solver.cpp:244]     Train net output #3: loss = 0.455691 (* 1 = 0.455691 loss)
I0422 23:26:31.873929 30295 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0422 23:28:13.318606 30295 solver.cpp:228] Iteration 1900, loss = 2.61178
I0422 23:28:13.318765 30295 solver.cpp:244]     Train net output #0: loss = 0.896083 (* 1 = 0.896083 loss)
I0422 23:28:13.318773 30295 solver.cpp:244]     Train net output #1: loss = 0.31814 (* 1 = 0.31814 loss)
I0422 23:28:13.318778 30295 solver.cpp:244]     Train net output #2: loss = 0.885622 (* 1 = 0.885622 loss)
I0422 23:28:13.318781 30295 solver.cpp:244]     Train net output #3: loss = 0.511935 (* 1 = 0.511935 loss)
I0422 23:28:13.318788 30295 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0422 23:29:53.984980 30295 solver.cpp:337] Iteration 2000, Testing net (#0)
I0422 23:29:53.985139 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0422 23:29:53.985143 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 23:29:53.985148 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0422 23:29:53.985164 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 23:29:53.985168 30295 net.cpp:693] Ignoring source layer visualize
I0422 23:29:53.985170 30295 net.cpp:693] Ignoring source layer fake
I0422 23:33:31.892726 30295 solver.cpp:404]     Test net output #0: loss = 0.935127 (* 1 = 0.935127 loss)
I0422 23:33:31.892890 30295 solver.cpp:404]     Test net output #1: loss = 0.377928 (* 1 = 0.377928 loss)
I0422 23:33:31.892897 30295 solver.cpp:404]     Test net output #2: loss = 0.741169 (* 1 = 0.741169 loss)
I0422 23:33:31.892902 30295 solver.cpp:404]     Test net output #3: loss = 0.42846 (* 1 = 0.42846 loss)
I0422 23:33:32.555748 30295 solver.cpp:228] Iteration 2000, loss = 2.65012
I0422 23:33:32.555790 30295 solver.cpp:244]     Train net output #0: loss = 0.958818 (* 1 = 0.958818 loss)
I0422 23:33:32.555795 30295 solver.cpp:244]     Train net output #1: loss = 0.439429 (* 1 = 0.439429 loss)
I0422 23:33:32.555799 30295 solver.cpp:244]     Train net output #2: loss = 0.801902 (* 1 = 0.801902 loss)
I0422 23:33:32.555804 30295 solver.cpp:244]     Train net output #3: loss = 0.44997 (* 1 = 0.44997 loss)
I0422 23:33:32.555809 30295 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0422 23:35:12.517896 30295 solver.cpp:228] Iteration 2100, loss = 2.51535
I0422 23:35:12.518054 30295 solver.cpp:244]     Train net output #0: loss = 0.967252 (* 1 = 0.967252 loss)
I0422 23:35:12.518062 30295 solver.cpp:244]     Train net output #1: loss = 0.345897 (* 1 = 0.345897 loss)
I0422 23:35:12.518066 30295 solver.cpp:244]     Train net output #2: loss = 0.809478 (* 1 = 0.809478 loss)
I0422 23:35:12.518071 30295 solver.cpp:244]     Train net output #3: loss = 0.392721 (* 1 = 0.392721 loss)
I0422 23:35:12.518076 30295 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0422 23:36:53.787952 30295 solver.cpp:228] Iteration 2200, loss = 2.73569
I0422 23:36:53.788136 30295 solver.cpp:244]     Train net output #0: loss = 0.961753 (* 1 = 0.961753 loss)
I0422 23:36:53.788142 30295 solver.cpp:244]     Train net output #1: loss = 0.497027 (* 1 = 0.497027 loss)
I0422 23:36:53.788147 30295 solver.cpp:244]     Train net output #2: loss = 0.82945 (* 1 = 0.82945 loss)
I0422 23:36:53.788153 30295 solver.cpp:244]     Train net output #3: loss = 0.447463 (* 1 = 0.447463 loss)
I0422 23:36:53.788159 30295 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0422 23:38:35.429808 30295 solver.cpp:228] Iteration 2300, loss = 2.22973
I0422 23:38:35.429971 30295 solver.cpp:244]     Train net output #0: loss = 0.961243 (* 1 = 0.961243 loss)
I0422 23:38:35.429980 30295 solver.cpp:244]     Train net output #1: loss = 0.26149 (* 1 = 0.26149 loss)
I0422 23:38:35.429986 30295 solver.cpp:244]     Train net output #2: loss = 0.672467 (* 1 = 0.672467 loss)
I0422 23:38:35.429989 30295 solver.cpp:244]     Train net output #3: loss = 0.334531 (* 1 = 0.334531 loss)
I0422 23:38:35.429994 30295 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0422 23:40:16.616631 30295 solver.cpp:228] Iteration 2400, loss = 2.19665
I0422 23:40:16.616780 30295 solver.cpp:244]     Train net output #0: loss = 0.976524 (* 1 = 0.976524 loss)
I0422 23:40:16.616788 30295 solver.cpp:244]     Train net output #1: loss = 0.188164 (* 1 = 0.188164 loss)
I0422 23:40:16.616793 30295 solver.cpp:244]     Train net output #2: loss = 0.664709 (* 1 = 0.664709 loss)
I0422 23:40:16.616798 30295 solver.cpp:244]     Train net output #3: loss = 0.367254 (* 1 = 0.367254 loss)
I0422 23:40:16.616803 30295 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0422 23:41:57.488358 30295 solver.cpp:228] Iteration 2500, loss = 2.06582
I0422 23:41:57.488525 30295 solver.cpp:244]     Train net output #0: loss = 0.9239 (* 1 = 0.9239 loss)
I0422 23:41:57.488533 30295 solver.cpp:244]     Train net output #1: loss = 0.1594 (* 1 = 0.1594 loss)
I0422 23:41:57.488538 30295 solver.cpp:244]     Train net output #2: loss = 0.650877 (* 1 = 0.650877 loss)
I0422 23:41:57.488543 30295 solver.cpp:244]     Train net output #3: loss = 0.331645 (* 1 = 0.331645 loss)
I0422 23:41:57.488546 30295 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0422 23:43:38.183053 30295 solver.cpp:228] Iteration 2600, loss = 2.12186
I0422 23:43:38.183243 30295 solver.cpp:244]     Train net output #0: loss = 0.959257 (* 1 = 0.959257 loss)
I0422 23:43:38.183251 30295 solver.cpp:244]     Train net output #1: loss = 0.191823 (* 1 = 0.191823 loss)
I0422 23:43:38.183256 30295 solver.cpp:244]     Train net output #2: loss = 0.660161 (* 1 = 0.660161 loss)
I0422 23:43:38.183261 30295 solver.cpp:244]     Train net output #3: loss = 0.310615 (* 1 = 0.310615 loss)
I0422 23:43:38.183266 30295 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0422 23:45:17.886313 30295 solver.cpp:228] Iteration 2700, loss = 2.36333
I0422 23:45:17.887629 30295 solver.cpp:244]     Train net output #0: loss = 0.963606 (* 1 = 0.963606 loss)
I0422 23:45:17.887637 30295 solver.cpp:244]     Train net output #1: loss = 0.288839 (* 1 = 0.288839 loss)
I0422 23:45:17.887641 30295 solver.cpp:244]     Train net output #2: loss = 0.629092 (* 1 = 0.629092 loss)
I0422 23:45:17.887645 30295 solver.cpp:244]     Train net output #3: loss = 0.48179 (* 1 = 0.48179 loss)
I0422 23:45:17.887650 30295 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0422 23:46:59.109519 30295 solver.cpp:228] Iteration 2800, loss = 2.67469
I0422 23:46:59.109643 30295 solver.cpp:244]     Train net output #0: loss = 0.936733 (* 1 = 0.936733 loss)
I0422 23:46:59.109650 30295 solver.cpp:244]     Train net output #1: loss = 0.543128 (* 1 = 0.543128 loss)
I0422 23:46:59.109655 30295 solver.cpp:244]     Train net output #2: loss = 0.742824 (* 1 = 0.742824 loss)
I0422 23:46:59.109660 30295 solver.cpp:244]     Train net output #3: loss = 0.452007 (* 1 = 0.452007 loss)
I0422 23:46:59.109664 30295 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0422 23:48:40.413121 30295 solver.cpp:228] Iteration 2900, loss = 2.4786
I0422 23:48:40.413275 30295 solver.cpp:244]     Train net output #0: loss = 0.676087 (* 1 = 0.676087 loss)
I0422 23:48:40.413282 30295 solver.cpp:244]     Train net output #1: loss = 0.516434 (* 1 = 0.516434 loss)
I0422 23:48:40.413287 30295 solver.cpp:244]     Train net output #2: loss = 0.862629 (* 1 = 0.862629 loss)
I0422 23:48:40.413291 30295 solver.cpp:244]     Train net output #3: loss = 0.42345 (* 1 = 0.42345 loss)
I0422 23:48:40.413300 30295 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0422 23:50:20.827461 30295 solver.cpp:337] Iteration 3000, Testing net (#0)
I0422 23:50:20.827607 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0422 23:50:20.827611 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 23:50:20.827615 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0422 23:50:20.827632 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 23:50:20.827636 30295 net.cpp:693] Ignoring source layer visualize
I0422 23:50:20.827637 30295 net.cpp:693] Ignoring source layer fake
I0422 23:53:59.523450 30295 solver.cpp:404]     Test net output #0: loss = 0.939627 (* 1 = 0.939627 loss)
I0422 23:53:59.523594 30295 solver.cpp:404]     Test net output #1: loss = 0.33738 (* 1 = 0.33738 loss)
I0422 23:53:59.523602 30295 solver.cpp:404]     Test net output #2: loss = 0.761781 (* 1 = 0.761781 loss)
I0422 23:53:59.523605 30295 solver.cpp:404]     Test net output #3: loss = 0.483187 (* 1 = 0.483187 loss)
I0422 23:54:00.179610 30295 solver.cpp:228] Iteration 3000, loss = 2.91775
I0422 23:54:00.179654 30295 solver.cpp:244]     Train net output #0: loss = 0.969144 (* 1 = 0.969144 loss)
I0422 23:54:00.179659 30295 solver.cpp:244]     Train net output #1: loss = 0.509944 (* 1 = 0.509944 loss)
I0422 23:54:00.179663 30295 solver.cpp:244]     Train net output #2: loss = 0.864255 (* 1 = 0.864255 loss)
I0422 23:54:00.179667 30295 solver.cpp:244]     Train net output #3: loss = 0.574412 (* 1 = 0.574412 loss)
I0422 23:54:00.179672 30295 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0422 23:55:41.903242 30295 solver.cpp:228] Iteration 3100, loss = 2.95852
I0422 23:55:41.903419 30295 solver.cpp:244]     Train net output #0: loss = 0.966619 (* 1 = 0.966619 loss)
I0422 23:55:41.903427 30295 solver.cpp:244]     Train net output #1: loss = 0.610789 (* 1 = 0.610789 loss)
I0422 23:55:41.903434 30295 solver.cpp:244]     Train net output #2: loss = 0.828584 (* 1 = 0.828584 loss)
I0422 23:55:41.903437 30295 solver.cpp:244]     Train net output #3: loss = 0.552525 (* 1 = 0.552525 loss)
I0422 23:55:41.903441 30295 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0422 23:57:21.677887 30295 solver.cpp:228] Iteration 3200, loss = 2.73737
I0422 23:57:21.678072 30295 solver.cpp:244]     Train net output #0: loss = 0.938268 (* 1 = 0.938268 loss)
I0422 23:57:21.678081 30295 solver.cpp:244]     Train net output #1: loss = 0.456578 (* 1 = 0.456578 loss)
I0422 23:57:21.678084 30295 solver.cpp:244]     Train net output #2: loss = 0.780915 (* 1 = 0.780915 loss)
I0422 23:57:21.678088 30295 solver.cpp:244]     Train net output #3: loss = 0.56161 (* 1 = 0.56161 loss)
I0422 23:57:21.678094 30295 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0422 23:59:02.991885 30295 solver.cpp:228] Iteration 3300, loss = 2.83969
I0422 23:59:02.992038 30295 solver.cpp:244]     Train net output #0: loss = 0.959041 (* 1 = 0.959041 loss)
I0422 23:59:02.992045 30295 solver.cpp:244]     Train net output #1: loss = 0.53326 (* 1 = 0.53326 loss)
I0422 23:59:02.992051 30295 solver.cpp:244]     Train net output #2: loss = 0.870806 (* 1 = 0.870806 loss)
I0422 23:59:02.992055 30295 solver.cpp:244]     Train net output #3: loss = 0.476587 (* 1 = 0.476587 loss)
I0422 23:59:02.992061 30295 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0423 00:00:44.359325 30295 solver.cpp:228] Iteration 3400, loss = 2.61084
I0423 00:00:44.359496 30295 solver.cpp:244]     Train net output #0: loss = 0.975429 (* 1 = 0.975429 loss)
I0423 00:00:44.359504 30295 solver.cpp:244]     Train net output #1: loss = 0.410775 (* 1 = 0.410775 loss)
I0423 00:00:44.359508 30295 solver.cpp:244]     Train net output #2: loss = 0.719326 (* 1 = 0.719326 loss)
I0423 00:00:44.359513 30295 solver.cpp:244]     Train net output #3: loss = 0.50531 (* 1 = 0.50531 loss)
I0423 00:00:44.359519 30295 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0423 00:02:25.622122 30295 solver.cpp:228] Iteration 3500, loss = 3.01725
I0423 00:02:25.623332 30295 solver.cpp:244]     Train net output #0: loss = 0.96083 (* 1 = 0.96083 loss)
I0423 00:02:25.623342 30295 solver.cpp:244]     Train net output #1: loss = 0.469209 (* 1 = 0.469209 loss)
I0423 00:02:25.623347 30295 solver.cpp:244]     Train net output #2: loss = 0.940949 (* 1 = 0.940949 loss)
I0423 00:02:25.623352 30295 solver.cpp:244]     Train net output #3: loss = 0.646263 (* 1 = 0.646263 loss)
I0423 00:02:25.623356 30295 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0423 00:04:05.125835 30295 solver.cpp:228] Iteration 3600, loss = 2.89484
I0423 00:04:05.125989 30295 solver.cpp:244]     Train net output #0: loss = 0.978249 (* 1 = 0.978249 loss)
I0423 00:04:05.125998 30295 solver.cpp:244]     Train net output #1: loss = 0.48268 (* 1 = 0.48268 loss)
I0423 00:04:05.126003 30295 solver.cpp:244]     Train net output #2: loss = 0.841394 (* 1 = 0.841394 loss)
I0423 00:04:05.126006 30295 solver.cpp:244]     Train net output #3: loss = 0.592521 (* 1 = 0.592521 loss)
I0423 00:04:05.126013 30295 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0423 00:05:46.068819 30295 solver.cpp:228] Iteration 3700, loss = 2.3023
I0423 00:05:46.068972 30295 solver.cpp:244]     Train net output #0: loss = 0.971193 (* 1 = 0.971193 loss)
I0423 00:05:46.068980 30295 solver.cpp:244]     Train net output #1: loss = 0.187595 (* 1 = 0.187595 loss)
I0423 00:05:46.068986 30295 solver.cpp:244]     Train net output #2: loss = 0.733843 (* 1 = 0.733843 loss)
I0423 00:05:46.068990 30295 solver.cpp:244]     Train net output #3: loss = 0.409672 (* 1 = 0.409672 loss)
I0423 00:05:46.068995 30295 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0423 00:07:26.676259 30295 solver.cpp:228] Iteration 3800, loss = 2.22566
I0423 00:07:26.676409 30295 solver.cpp:244]     Train net output #0: loss = 0.949214 (* 1 = 0.949214 loss)
I0423 00:07:26.676417 30295 solver.cpp:244]     Train net output #1: loss = 0.117625 (* 1 = 0.117625 loss)
I0423 00:07:26.676421 30295 solver.cpp:244]     Train net output #2: loss = 0.814146 (* 1 = 0.814146 loss)
I0423 00:07:26.676426 30295 solver.cpp:244]     Train net output #3: loss = 0.344672 (* 1 = 0.344672 loss)
I0423 00:07:26.676431 30295 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0423 00:09:07.443043 30295 solver.cpp:228] Iteration 3900, loss = 2.81408
I0423 00:09:07.443243 30295 solver.cpp:244]     Train net output #0: loss = 0.97005 (* 1 = 0.97005 loss)
I0423 00:09:07.443251 30295 solver.cpp:244]     Train net output #1: loss = 0.397465 (* 1 = 0.397465 loss)
I0423 00:09:07.443256 30295 solver.cpp:244]     Train net output #2: loss = 0.908528 (* 1 = 0.908528 loss)
I0423 00:09:07.443260 30295 solver.cpp:244]     Train net output #3: loss = 0.538035 (* 1 = 0.538035 loss)
I0423 00:09:07.443265 30295 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0423 00:10:47.490623 30295 solver.cpp:337] Iteration 4000, Testing net (#0)
I0423 00:10:47.490772 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 00:10:47.490777 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 00:10:47.490780 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 00:10:47.490795 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 00:10:47.490799 30295 net.cpp:693] Ignoring source layer visualize
I0423 00:10:47.490802 30295 net.cpp:693] Ignoring source layer fake
I0423 00:14:26.616896 30295 solver.cpp:404]     Test net output #0: loss = 0.872984 (* 1 = 0.872984 loss)
I0423 00:14:26.617043 30295 solver.cpp:404]     Test net output #1: loss = 0.313227 (* 1 = 0.313227 loss)
I0423 00:14:26.617050 30295 solver.cpp:404]     Test net output #2: loss = 0.784314 (* 1 = 0.784314 loss)
I0423 00:14:26.617054 30295 solver.cpp:404]     Test net output #3: loss = 0.459868 (* 1 = 0.459868 loss)
I0423 00:14:27.279279 30295 solver.cpp:228] Iteration 4000, loss = 2.4093
I0423 00:14:27.279327 30295 solver.cpp:244]     Train net output #0: loss = 0.952816 (* 1 = 0.952816 loss)
I0423 00:14:27.279333 30295 solver.cpp:244]     Train net output #1: loss = 0.401676 (* 1 = 0.401676 loss)
I0423 00:14:27.279338 30295 solver.cpp:244]     Train net output #2: loss = 0.707474 (* 1 = 0.707474 loss)
I0423 00:14:27.279342 30295 solver.cpp:244]     Train net output #3: loss = 0.347329 (* 1 = 0.347329 loss)
I0423 00:14:27.279346 30295 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0423 00:16:08.802448 30295 solver.cpp:228] Iteration 4100, loss = 2.25707
I0423 00:16:08.802590 30295 solver.cpp:244]     Train net output #0: loss = 0.551755 (* 1 = 0.551755 loss)
I0423 00:16:08.802597 30295 solver.cpp:244]     Train net output #1: loss = 0.358841 (* 1 = 0.358841 loss)
I0423 00:16:08.802603 30295 solver.cpp:244]     Train net output #2: loss = 0.780032 (* 1 = 0.780032 loss)
I0423 00:16:08.802608 30295 solver.cpp:244]     Train net output #3: loss = 0.566443 (* 1 = 0.566443 loss)
I0423 00:16:08.802611 30295 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0423 00:17:48.485625 30295 solver.cpp:228] Iteration 4200, loss = 2.57681
I0423 00:17:48.485771 30295 solver.cpp:244]     Train net output #0: loss = 0.710586 (* 1 = 0.710586 loss)
I0423 00:17:48.485780 30295 solver.cpp:244]     Train net output #1: loss = 0.476597 (* 1 = 0.476597 loss)
I0423 00:17:48.485785 30295 solver.cpp:244]     Train net output #2: loss = 0.856003 (* 1 = 0.856003 loss)
I0423 00:17:48.485788 30295 solver.cpp:244]     Train net output #3: loss = 0.533619 (* 1 = 0.533619 loss)
I0423 00:17:48.485793 30295 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0423 00:19:29.686117 30295 solver.cpp:228] Iteration 4300, loss = 2.78733
I0423 00:19:29.686290 30295 solver.cpp:244]     Train net output #0: loss = 0.924275 (* 1 = 0.924275 loss)
I0423 00:19:29.686297 30295 solver.cpp:244]     Train net output #1: loss = 0.470921 (* 1 = 0.470921 loss)
I0423 00:19:29.686302 30295 solver.cpp:244]     Train net output #2: loss = 0.863378 (* 1 = 0.863378 loss)
I0423 00:19:29.686307 30295 solver.cpp:244]     Train net output #3: loss = 0.528758 (* 1 = 0.528758 loss)
I0423 00:19:29.686311 30295 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0423 00:21:11.349755 30295 solver.cpp:228] Iteration 4400, loss = 2.71786
I0423 00:21:11.349943 30295 solver.cpp:244]     Train net output #0: loss = 0.914454 (* 1 = 0.914454 loss)
I0423 00:21:11.349952 30295 solver.cpp:244]     Train net output #1: loss = 0.468627 (* 1 = 0.468627 loss)
I0423 00:21:11.349957 30295 solver.cpp:244]     Train net output #2: loss = 0.854509 (* 1 = 0.854509 loss)
I0423 00:21:11.349961 30295 solver.cpp:244]     Train net output #3: loss = 0.480271 (* 1 = 0.480271 loss)
I0423 00:21:11.349967 30295 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0423 00:22:52.705389 30295 solver.cpp:228] Iteration 4500, loss = 2.73819
I0423 00:22:52.705490 30295 solver.cpp:244]     Train net output #0: loss = 0.977992 (* 1 = 0.977992 loss)
I0423 00:22:52.705497 30295 solver.cpp:244]     Train net output #1: loss = 0.546194 (* 1 = 0.546194 loss)
I0423 00:22:52.705502 30295 solver.cpp:244]     Train net output #2: loss = 0.781475 (* 1 = 0.781475 loss)
I0423 00:22:52.705508 30295 solver.cpp:244]     Train net output #3: loss = 0.432535 (* 1 = 0.432535 loss)
I0423 00:22:52.705513 30295 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0423 00:24:32.409051 30295 solver.cpp:228] Iteration 4600, loss = 2.71739
I0423 00:24:32.409226 30295 solver.cpp:244]     Train net output #0: loss = 0.963398 (* 1 = 0.963398 loss)
I0423 00:24:32.409235 30295 solver.cpp:244]     Train net output #1: loss = 0.41397 (* 1 = 0.41397 loss)
I0423 00:24:32.409240 30295 solver.cpp:244]     Train net output #2: loss = 0.877347 (* 1 = 0.877347 loss)
I0423 00:24:32.409245 30295 solver.cpp:244]     Train net output #3: loss = 0.462677 (* 1 = 0.462677 loss)
I0423 00:24:32.409250 30295 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0423 00:26:13.714823 30295 solver.cpp:228] Iteration 4700, loss = 2.89754
I0423 00:26:13.714970 30295 solver.cpp:244]     Train net output #0: loss = 0.967929 (* 1 = 0.967929 loss)
I0423 00:26:13.714977 30295 solver.cpp:244]     Train net output #1: loss = 0.453513 (* 1 = 0.453513 loss)
I0423 00:26:13.714982 30295 solver.cpp:244]     Train net output #2: loss = 0.874621 (* 1 = 0.874621 loss)
I0423 00:26:13.714987 30295 solver.cpp:244]     Train net output #3: loss = 0.601474 (* 1 = 0.601474 loss)
I0423 00:26:13.714993 30295 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0423 00:27:54.691308 30295 solver.cpp:228] Iteration 4800, loss = 1.92356
I0423 00:27:54.691485 30295 solver.cpp:244]     Train net output #0: loss = 0.986932 (* 1 = 0.986932 loss)
I0423 00:27:54.691493 30295 solver.cpp:244]     Train net output #1: loss = 0.150967 (* 1 = 0.150967 loss)
I0423 00:27:54.691498 30295 solver.cpp:244]     Train net output #2: loss = 0.519396 (* 1 = 0.519396 loss)
I0423 00:27:54.691504 30295 solver.cpp:244]     Train net output #3: loss = 0.26627 (* 1 = 0.26627 loss)
I0423 00:27:54.691509 30295 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0423 00:29:35.889536 30295 solver.cpp:228] Iteration 4900, loss = 2.42882
I0423 00:29:35.890672 30295 solver.cpp:244]     Train net output #0: loss = 0.970427 (* 1 = 0.970427 loss)
I0423 00:29:35.890681 30295 solver.cpp:244]     Train net output #1: loss = 0.300884 (* 1 = 0.300884 loss)
I0423 00:29:35.890684 30295 solver.cpp:244]     Train net output #2: loss = 0.709155 (* 1 = 0.709155 loss)
I0423 00:29:35.890689 30295 solver.cpp:244]     Train net output #3: loss = 0.448357 (* 1 = 0.448357 loss)
I0423 00:29:35.890693 30295 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0423 00:31:15.957500 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_5000.caffemodel
I0423 00:31:26.090790 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_5000.solverstate
I0423 00:31:26.286548 30295 solver.cpp:337] Iteration 5000, Testing net (#0)
I0423 00:31:26.286590 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 00:31:26.286592 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 00:31:26.286597 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 00:31:26.286612 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 00:31:26.286614 30295 net.cpp:693] Ignoring source layer visualize
I0423 00:31:26.286617 30295 net.cpp:693] Ignoring source layer fake
I0423 00:35:03.390614 30295 solver.cpp:404]     Test net output #0: loss = 0.947838 (* 1 = 0.947838 loss)
I0423 00:35:03.392627 30295 solver.cpp:404]     Test net output #1: loss = 0.322712 (* 1 = 0.322712 loss)
I0423 00:35:03.392634 30295 solver.cpp:404]     Test net output #2: loss = 0.776677 (* 1 = 0.776677 loss)
I0423 00:35:03.392638 30295 solver.cpp:404]     Test net output #3: loss = 0.479314 (* 1 = 0.479314 loss)
I0423 00:35:04.082095 30295 solver.cpp:228] Iteration 5000, loss = 2.20576
I0423 00:35:04.082139 30295 solver.cpp:244]     Train net output #0: loss = 0.972516 (* 1 = 0.972516 loss)
I0423 00:35:04.082144 30295 solver.cpp:244]     Train net output #1: loss = 0.201763 (* 1 = 0.201763 loss)
I0423 00:35:04.082147 30295 solver.cpp:244]     Train net output #2: loss = 0.707708 (* 1 = 0.707708 loss)
I0423 00:35:04.082151 30295 solver.cpp:244]     Train net output #3: loss = 0.323769 (* 1 = 0.323769 loss)
I0423 00:35:04.082155 30295 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0423 00:36:45.235990 30295 solver.cpp:228] Iteration 5100, loss = 2.58298
I0423 00:36:45.236141 30295 solver.cpp:244]     Train net output #0: loss = 0.918652 (* 1 = 0.918652 loss)
I0423 00:36:45.236148 30295 solver.cpp:244]     Train net output #1: loss = 0.236241 (* 1 = 0.236241 loss)
I0423 00:36:45.236155 30295 solver.cpp:244]     Train net output #2: loss = 0.935351 (* 1 = 0.935351 loss)
I0423 00:36:45.236158 30295 solver.cpp:244]     Train net output #3: loss = 0.492732 (* 1 = 0.492732 loss)
I0423 00:36:45.236163 30295 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0423 00:38:24.904409 30295 solver.cpp:228] Iteration 5200, loss = 2.80011
I0423 00:38:24.904541 30295 solver.cpp:244]     Train net output #0: loss = 0.962706 (* 1 = 0.962706 loss)
I0423 00:38:24.904548 30295 solver.cpp:244]     Train net output #1: loss = 0.394896 (* 1 = 0.394896 loss)
I0423 00:38:24.904553 30295 solver.cpp:244]     Train net output #2: loss = 0.947432 (* 1 = 0.947432 loss)
I0423 00:38:24.904557 30295 solver.cpp:244]     Train net output #3: loss = 0.495077 (* 1 = 0.495077 loss)
I0423 00:38:24.904562 30295 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0423 00:40:06.154603 30295 solver.cpp:228] Iteration 5300, loss = 2.35165
I0423 00:40:06.154772 30295 solver.cpp:244]     Train net output #0: loss = 0.924615 (* 1 = 0.924615 loss)
I0423 00:40:06.154779 30295 solver.cpp:244]     Train net output #1: loss = 0.483753 (* 1 = 0.483753 loss)
I0423 00:40:06.154784 30295 solver.cpp:244]     Train net output #2: loss = 0.566673 (* 1 = 0.566673 loss)
I0423 00:40:06.154789 30295 solver.cpp:244]     Train net output #3: loss = 0.37661 (* 1 = 0.37661 loss)
I0423 00:40:06.154794 30295 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0423 00:41:47.531414 30295 solver.cpp:228] Iteration 5400, loss = 1.91284
I0423 00:41:47.531576 30295 solver.cpp:244]     Train net output #0: loss = 0.898235 (* 1 = 0.898235 loss)
I0423 00:41:47.531584 30295 solver.cpp:244]     Train net output #1: loss = 0.263177 (* 1 = 0.263177 loss)
I0423 00:41:47.531589 30295 solver.cpp:244]     Train net output #2: loss = 0.526296 (* 1 = 0.526296 loss)
I0423 00:41:47.531594 30295 solver.cpp:244]     Train net output #3: loss = 0.225131 (* 1 = 0.225131 loss)
I0423 00:41:47.531599 30295 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0423 00:43:29.396281 30295 solver.cpp:228] Iteration 5500, loss = 2.74076
I0423 00:43:29.396420 30295 solver.cpp:244]     Train net output #0: loss = 0.927281 (* 1 = 0.927281 loss)
I0423 00:43:29.396428 30295 solver.cpp:244]     Train net output #1: loss = 0.37677 (* 1 = 0.37677 loss)
I0423 00:43:29.396433 30295 solver.cpp:244]     Train net output #2: loss = 0.899853 (* 1 = 0.899853 loss)
I0423 00:43:29.396438 30295 solver.cpp:244]     Train net output #3: loss = 0.536861 (* 1 = 0.536861 loss)
I0423 00:43:29.396443 30295 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0423 00:45:10.643844 30295 solver.cpp:228] Iteration 5600, loss = 2.8212
I0423 00:45:10.644022 30295 solver.cpp:244]     Train net output #0: loss = 0.936999 (* 1 = 0.936999 loss)
I0423 00:45:10.644031 30295 solver.cpp:244]     Train net output #1: loss = 0.37038 (* 1 = 0.37038 loss)
I0423 00:45:10.644034 30295 solver.cpp:244]     Train net output #2: loss = 0.925081 (* 1 = 0.925081 loss)
I0423 00:45:10.644039 30295 solver.cpp:244]     Train net output #3: loss = 0.588745 (* 1 = 0.588745 loss)
I0423 00:45:10.644043 30295 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0423 00:46:50.192713 30295 solver.cpp:228] Iteration 5700, loss = 2.7719
I0423 00:46:50.192862 30295 solver.cpp:244]     Train net output #0: loss = 0.910147 (* 1 = 0.910147 loss)
I0423 00:46:50.192870 30295 solver.cpp:244]     Train net output #1: loss = 0.495479 (* 1 = 0.495479 loss)
I0423 00:46:50.192875 30295 solver.cpp:244]     Train net output #2: loss = 0.833298 (* 1 = 0.833298 loss)
I0423 00:46:50.192879 30295 solver.cpp:244]     Train net output #3: loss = 0.532977 (* 1 = 0.532977 loss)
I0423 00:46:50.192884 30295 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0423 00:48:31.437325 30295 solver.cpp:228] Iteration 5800, loss = 2.72826
I0423 00:48:31.437487 30295 solver.cpp:244]     Train net output #0: loss = 0.971691 (* 1 = 0.971691 loss)
I0423 00:48:31.437494 30295 solver.cpp:244]     Train net output #1: loss = 0.505023 (* 1 = 0.505023 loss)
I0423 00:48:31.437500 30295 solver.cpp:244]     Train net output #2: loss = 0.701427 (* 1 = 0.701427 loss)
I0423 00:48:31.437505 30295 solver.cpp:244]     Train net output #3: loss = 0.550118 (* 1 = 0.550118 loss)
I0423 00:48:31.437510 30295 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0423 00:50:13.278357 30295 solver.cpp:228] Iteration 5900, loss = 3.08085
I0423 00:50:13.278514 30295 solver.cpp:244]     Train net output #0: loss = 0.974523 (* 1 = 0.974523 loss)
I0423 00:50:13.278522 30295 solver.cpp:244]     Train net output #1: loss = 0.544491 (* 1 = 0.544491 loss)
I0423 00:50:13.278527 30295 solver.cpp:244]     Train net output #2: loss = 0.904452 (* 1 = 0.904452 loss)
I0423 00:50:13.278532 30295 solver.cpp:244]     Train net output #3: loss = 0.657388 (* 1 = 0.657388 loss)
I0423 00:50:13.278537 30295 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0423 00:51:54.034945 30295 solver.cpp:337] Iteration 6000, Testing net (#0)
I0423 00:51:54.035096 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 00:51:54.035100 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 00:51:54.035104 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 00:51:54.035120 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 00:51:54.035123 30295 net.cpp:693] Ignoring source layer visualize
I0423 00:51:54.035125 30295 net.cpp:693] Ignoring source layer fake
I0423 00:55:32.419443 30295 solver.cpp:404]     Test net output #0: loss = 0.942216 (* 1 = 0.942216 loss)
I0423 00:55:32.419584 30295 solver.cpp:404]     Test net output #1: loss = 0.324473 (* 1 = 0.324473 loss)
I0423 00:55:32.419591 30295 solver.cpp:404]     Test net output #2: loss = 0.794023 (* 1 = 0.794023 loss)
I0423 00:55:32.419596 30295 solver.cpp:404]     Test net output #3: loss = 0.492964 (* 1 = 0.492964 loss)
I0423 00:55:33.087965 30295 solver.cpp:228] Iteration 6000, loss = 2.64711
I0423 00:55:33.088023 30295 solver.cpp:244]     Train net output #0: loss = 0.974669 (* 1 = 0.974669 loss)
I0423 00:55:33.088029 30295 solver.cpp:244]     Train net output #1: loss = 0.374526 (* 1 = 0.374526 loss)
I0423 00:55:33.088049 30295 solver.cpp:244]     Train net output #2: loss = 0.830254 (* 1 = 0.830254 loss)
I0423 00:55:33.088053 30295 solver.cpp:244]     Train net output #3: loss = 0.467661 (* 1 = 0.467661 loss)
I0423 00:55:33.088058 30295 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0423 00:57:12.787331 30295 solver.cpp:228] Iteration 6100, loss = 2.43629
I0423 00:57:12.787488 30295 solver.cpp:244]     Train net output #0: loss = 0.978166 (* 1 = 0.978166 loss)
I0423 00:57:12.787497 30295 solver.cpp:244]     Train net output #1: loss = 0.339412 (* 1 = 0.339412 loss)
I0423 00:57:12.787502 30295 solver.cpp:244]     Train net output #2: loss = 0.765528 (* 1 = 0.765528 loss)
I0423 00:57:12.787506 30295 solver.cpp:244]     Train net output #3: loss = 0.353181 (* 1 = 0.353181 loss)
I0423 00:57:12.787510 30295 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0423 00:58:54.022716 30295 solver.cpp:228] Iteration 6200, loss = 2.54451
I0423 00:58:54.022871 30295 solver.cpp:244]     Train net output #0: loss = 0.964094 (* 1 = 0.964094 loss)
I0423 00:58:54.022887 30295 solver.cpp:244]     Train net output #1: loss = 0.241749 (* 1 = 0.241749 loss)
I0423 00:58:54.022892 30295 solver.cpp:244]     Train net output #2: loss = 0.934102 (* 1 = 0.934102 loss)
I0423 00:58:54.022897 30295 solver.cpp:244]     Train net output #3: loss = 0.404563 (* 1 = 0.404563 loss)
I0423 00:58:54.022902 30295 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0423 01:00:34.998766 30295 solver.cpp:228] Iteration 6300, loss = 2.48076
I0423 01:00:34.998905 30295 solver.cpp:244]     Train net output #0: loss = 0.934718 (* 1 = 0.934718 loss)
I0423 01:00:34.998914 30295 solver.cpp:244]     Train net output #1: loss = 0.269771 (* 1 = 0.269771 loss)
I0423 01:00:34.998917 30295 solver.cpp:244]     Train net output #2: loss = 0.808035 (* 1 = 0.808035 loss)
I0423 01:00:34.998924 30295 solver.cpp:244]     Train net output #3: loss = 0.46824 (* 1 = 0.46824 loss)
I0423 01:00:34.998927 30295 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0423 01:02:16.410013 30295 solver.cpp:228] Iteration 6400, loss = 2.85405
I0423 01:02:16.410163 30295 solver.cpp:244]     Train net output #0: loss = 0.938041 (* 1 = 0.938041 loss)
I0423 01:02:16.410171 30295 solver.cpp:244]     Train net output #1: loss = 0.480551 (* 1 = 0.480551 loss)
I0423 01:02:16.410176 30295 solver.cpp:244]     Train net output #2: loss = 0.763542 (* 1 = 0.763542 loss)
I0423 01:02:16.410181 30295 solver.cpp:244]     Train net output #3: loss = 0.67192 (* 1 = 0.67192 loss)
I0423 01:02:16.410187 30295 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0423 01:03:57.482786 30295 solver.cpp:228] Iteration 6500, loss = 2.62644
I0423 01:03:57.482954 30295 solver.cpp:244]     Train net output #0: loss = 0.931352 (* 1 = 0.931352 loss)
I0423 01:03:57.482961 30295 solver.cpp:244]     Train net output #1: loss = 0.449189 (* 1 = 0.449189 loss)
I0423 01:03:57.482966 30295 solver.cpp:244]     Train net output #2: loss = 0.763986 (* 1 = 0.763986 loss)
I0423 01:03:57.482971 30295 solver.cpp:244]     Train net output #3: loss = 0.481914 (* 1 = 0.481914 loss)
I0423 01:03:57.482977 30295 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0423 01:05:38.702661 30295 solver.cpp:228] Iteration 6600, loss = 2.40285
I0423 01:05:38.702817 30295 solver.cpp:244]     Train net output #0: loss = 0.571122 (* 1 = 0.571122 loss)
I0423 01:05:38.702826 30295 solver.cpp:244]     Train net output #1: loss = 0.48746 (* 1 = 0.48746 loss)
I0423 01:05:38.702831 30295 solver.cpp:244]     Train net output #2: loss = 0.809693 (* 1 = 0.809693 loss)
I0423 01:05:38.702834 30295 solver.cpp:244]     Train net output #3: loss = 0.534577 (* 1 = 0.534577 loss)
I0423 01:05:38.702839 30295 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0423 01:07:18.640120 30295 solver.cpp:228] Iteration 6700, loss = 2.5759
I0423 01:07:18.640275 30295 solver.cpp:244]     Train net output #0: loss = 0.701569 (* 1 = 0.701569 loss)
I0423 01:07:18.640283 30295 solver.cpp:244]     Train net output #1: loss = 0.478325 (* 1 = 0.478325 loss)
I0423 01:07:18.640288 30295 solver.cpp:244]     Train net output #2: loss = 0.85463 (* 1 = 0.85463 loss)
I0423 01:07:18.640293 30295 solver.cpp:244]     Train net output #3: loss = 0.541379 (* 1 = 0.541379 loss)
I0423 01:07:18.640298 30295 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0423 01:08:59.833468 30295 solver.cpp:228] Iteration 6800, loss = 2.86808
I0423 01:08:59.833613 30295 solver.cpp:244]     Train net output #0: loss = 0.93679 (* 1 = 0.93679 loss)
I0423 01:08:59.833621 30295 solver.cpp:244]     Train net output #1: loss = 0.683243 (* 1 = 0.683243 loss)
I0423 01:08:59.833626 30295 solver.cpp:244]     Train net output #2: loss = 0.703086 (* 1 = 0.703086 loss)
I0423 01:08:59.833631 30295 solver.cpp:244]     Train net output #3: loss = 0.544959 (* 1 = 0.544959 loss)
I0423 01:08:59.833636 30295 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0423 01:10:41.412729 30295 solver.cpp:228] Iteration 6900, loss = 3.03258
I0423 01:10:41.412919 30295 solver.cpp:244]     Train net output #0: loss = 0.961238 (* 1 = 0.961238 loss)
I0423 01:10:41.412926 30295 solver.cpp:244]     Train net output #1: loss = 0.669827 (* 1 = 0.669827 loss)
I0423 01:10:41.412931 30295 solver.cpp:244]     Train net output #2: loss = 0.846829 (* 1 = 0.846829 loss)
I0423 01:10:41.412936 30295 solver.cpp:244]     Train net output #3: loss = 0.554681 (* 1 = 0.554681 loss)
I0423 01:10:41.412942 30295 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0423 01:12:21.857084 30295 solver.cpp:337] Iteration 7000, Testing net (#0)
I0423 01:12:21.857229 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 01:12:21.857234 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 01:12:21.857239 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 01:12:21.857254 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 01:12:21.857256 30295 net.cpp:693] Ignoring source layer visualize
I0423 01:12:21.857259 30295 net.cpp:693] Ignoring source layer fake
I0423 01:15:59.573117 30295 solver.cpp:404]     Test net output #0: loss = 0.941491 (* 1 = 0.941491 loss)
I0423 01:15:59.573284 30295 solver.cpp:404]     Test net output #1: loss = 0.329869 (* 1 = 0.329869 loss)
I0423 01:15:59.573292 30295 solver.cpp:404]     Test net output #2: loss = 0.768889 (* 1 = 0.768889 loss)
I0423 01:15:59.573297 30295 solver.cpp:404]     Test net output #3: loss = 0.422636 (* 1 = 0.422636 loss)
I0423 01:16:00.251193 30295 solver.cpp:228] Iteration 7000, loss = 2.56731
I0423 01:16:00.251235 30295 solver.cpp:244]     Train net output #0: loss = 0.971144 (* 1 = 0.971144 loss)
I0423 01:16:00.251240 30295 solver.cpp:244]     Train net output #1: loss = 0.412095 (* 1 = 0.412095 loss)
I0423 01:16:00.251245 30295 solver.cpp:244]     Train net output #2: loss = 0.686036 (* 1 = 0.686036 loss)
I0423 01:16:00.251250 30295 solver.cpp:244]     Train net output #3: loss = 0.498036 (* 1 = 0.498036 loss)
I0423 01:16:00.251255 30295 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0423 01:17:40.002321 30295 solver.cpp:228] Iteration 7100, loss = 2.88045
I0423 01:17:40.002466 30295 solver.cpp:244]     Train net output #0: loss = 0.950144 (* 1 = 0.950144 loss)
I0423 01:17:40.002475 30295 solver.cpp:244]     Train net output #1: loss = 0.3929 (* 1 = 0.3929 loss)
I0423 01:17:40.002480 30295 solver.cpp:244]     Train net output #2: loss = 0.917363 (* 1 = 0.917363 loss)
I0423 01:17:40.002483 30295 solver.cpp:244]     Train net output #3: loss = 0.620046 (* 1 = 0.620046 loss)
I0423 01:17:40.002490 30295 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0423 01:19:21.134923 30295 solver.cpp:228] Iteration 7200, loss = 2.70248
I0423 01:19:21.135071 30295 solver.cpp:244]     Train net output #0: loss = 0.964408 (* 1 = 0.964408 loss)
I0423 01:19:21.135077 30295 solver.cpp:244]     Train net output #1: loss = 0.38416 (* 1 = 0.38416 loss)
I0423 01:19:21.135083 30295 solver.cpp:244]     Train net output #2: loss = 0.75829 (* 1 = 0.75829 loss)
I0423 01:19:21.135089 30295 solver.cpp:244]     Train net output #3: loss = 0.595619 (* 1 = 0.595619 loss)
I0423 01:19:21.135094 30295 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0423 01:21:02.246686 30295 solver.cpp:228] Iteration 7300, loss = 2.56062
I0423 01:21:02.246848 30295 solver.cpp:244]     Train net output #0: loss = 0.985082 (* 1 = 0.985082 loss)
I0423 01:21:02.246855 30295 solver.cpp:244]     Train net output #1: loss = 0.312949 (* 1 = 0.312949 loss)
I0423 01:21:02.246860 30295 solver.cpp:244]     Train net output #2: loss = 0.722255 (* 1 = 0.722255 loss)
I0423 01:21:02.246865 30295 solver.cpp:244]     Train net output #3: loss = 0.540338 (* 1 = 0.540338 loss)
I0423 01:21:02.246870 30295 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0423 01:22:43.351349 30295 solver.cpp:228] Iteration 7400, loss = 2.44246
I0423 01:22:43.351635 30295 solver.cpp:244]     Train net output #0: loss = 0.977819 (* 1 = 0.977819 loss)
I0423 01:22:43.351644 30295 solver.cpp:244]     Train net output #1: loss = 0.334062 (* 1 = 0.334062 loss)
I0423 01:22:43.351649 30295 solver.cpp:244]     Train net output #2: loss = 0.620479 (* 1 = 0.620479 loss)
I0423 01:22:43.351652 30295 solver.cpp:244]     Train net output #3: loss = 0.510099 (* 1 = 0.510099 loss)
I0423 01:22:43.351660 30295 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0423 01:24:24.150534 30295 solver.cpp:228] Iteration 7500, loss = 2.57547
I0423 01:24:24.150694 30295 solver.cpp:244]     Train net output #0: loss = 0.964549 (* 1 = 0.964549 loss)
I0423 01:24:24.150701 30295 solver.cpp:244]     Train net output #1: loss = 0.249474 (* 1 = 0.249474 loss)
I0423 01:24:24.150707 30295 solver.cpp:244]     Train net output #2: loss = 0.910834 (* 1 = 0.910834 loss)
I0423 01:24:24.150710 30295 solver.cpp:244]     Train net output #3: loss = 0.450617 (* 1 = 0.450617 loss)
I0423 01:24:24.150717 30295 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0423 01:26:04.728227 30295 solver.cpp:228] Iteration 7600, loss = 2.48963
I0423 01:26:04.728382 30295 solver.cpp:244]     Train net output #0: loss = 0.92733 (* 1 = 0.92733 loss)
I0423 01:26:04.728390 30295 solver.cpp:244]     Train net output #1: loss = 0.29685 (* 1 = 0.29685 loss)
I0423 01:26:04.728395 30295 solver.cpp:244]     Train net output #2: loss = 0.745197 (* 1 = 0.745197 loss)
I0423 01:26:04.728400 30295 solver.cpp:244]     Train net output #3: loss = 0.520259 (* 1 = 0.520259 loss)
I0423 01:26:04.728405 30295 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0423 01:27:44.437603 30295 solver.cpp:228] Iteration 7700, loss = 2.76079
I0423 01:27:44.437759 30295 solver.cpp:244]     Train net output #0: loss = 0.943048 (* 1 = 0.943048 loss)
I0423 01:27:44.437767 30295 solver.cpp:244]     Train net output #1: loss = 0.377908 (* 1 = 0.377908 loss)
I0423 01:27:44.437772 30295 solver.cpp:244]     Train net output #2: loss = 0.756364 (* 1 = 0.756364 loss)
I0423 01:27:44.437775 30295 solver.cpp:244]     Train net output #3: loss = 0.683465 (* 1 = 0.683465 loss)
I0423 01:27:44.437782 30295 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0423 01:29:25.429544 30295 solver.cpp:228] Iteration 7800, loss = 2.49448
I0423 01:29:25.429692 30295 solver.cpp:244]     Train net output #0: loss = 0.936867 (* 1 = 0.936867 loss)
I0423 01:29:25.429700 30295 solver.cpp:244]     Train net output #1: loss = 0.373271 (* 1 = 0.373271 loss)
I0423 01:29:25.429705 30295 solver.cpp:244]     Train net output #2: loss = 0.764779 (* 1 = 0.764779 loss)
I0423 01:29:25.429709 30295 solver.cpp:244]     Train net output #3: loss = 0.419565 (* 1 = 0.419565 loss)
I0423 01:29:25.429714 30295 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0423 01:31:06.860057 30295 solver.cpp:228] Iteration 7900, loss = 1.5372
I0423 01:31:06.860216 30295 solver.cpp:244]     Train net output #0: loss = 0.969913 (* 1 = 0.969913 loss)
I0423 01:31:06.860224 30295 solver.cpp:244]     Train net output #1: loss = 0.0756056 (* 1 = 0.0756056 loss)
I0423 01:31:06.860229 30295 solver.cpp:244]     Train net output #2: loss = 0.365798 (* 1 = 0.365798 loss)
I0423 01:31:06.860232 30295 solver.cpp:244]     Train net output #3: loss = 0.125883 (* 1 = 0.125883 loss)
I0423 01:31:06.860239 30295 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0423 01:32:47.349771 30295 solver.cpp:337] Iteration 8000, Testing net (#0)
I0423 01:32:47.349913 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 01:32:47.349917 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 01:32:47.349921 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 01:32:47.349937 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 01:32:47.349941 30295 net.cpp:693] Ignoring source layer visualize
I0423 01:32:47.349942 30295 net.cpp:693] Ignoring source layer fake
I0423 01:36:25.181641 30295 solver.cpp:404]     Test net output #0: loss = 0.924711 (* 1 = 0.924711 loss)
I0423 01:36:25.181807 30295 solver.cpp:404]     Test net output #1: loss = 0.383195 (* 1 = 0.383195 loss)
I0423 01:36:25.181814 30295 solver.cpp:404]     Test net output #2: loss = 0.795926 (* 1 = 0.795926 loss)
I0423 01:36:25.181818 30295 solver.cpp:404]     Test net output #3: loss = 0.512902 (* 1 = 0.512902 loss)
I0423 01:36:25.891999 30295 solver.cpp:228] Iteration 8000, loss = 2.73507
I0423 01:36:25.892026 30295 solver.cpp:244]     Train net output #0: loss = 0.896322 (* 1 = 0.896322 loss)
I0423 01:36:25.892047 30295 solver.cpp:244]     Train net output #1: loss = 0.458574 (* 1 = 0.458574 loss)
I0423 01:36:25.892051 30295 solver.cpp:244]     Train net output #2: loss = 0.870729 (* 1 = 0.870729 loss)
I0423 01:36:25.892056 30295 solver.cpp:244]     Train net output #3: loss = 0.509447 (* 1 = 0.509447 loss)
I0423 01:36:25.892060 30295 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0423 01:38:07.511323 30295 solver.cpp:228] Iteration 8100, loss = 3.05363
I0423 01:38:07.511514 30295 solver.cpp:244]     Train net output #0: loss = 0.94999 (* 1 = 0.94999 loss)
I0423 01:38:07.511523 30295 solver.cpp:244]     Train net output #1: loss = 0.525662 (* 1 = 0.525662 loss)
I0423 01:38:07.511528 30295 solver.cpp:244]     Train net output #2: loss = 0.94959 (* 1 = 0.94959 loss)
I0423 01:38:07.511533 30295 solver.cpp:244]     Train net output #3: loss = 0.628392 (* 1 = 0.628392 loss)
I0423 01:38:07.511538 30295 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0423 01:39:47.265300 30295 solver.cpp:228] Iteration 8200, loss = 2.90227
I0423 01:39:47.265451 30295 solver.cpp:244]     Train net output #0: loss = 0.936035 (* 1 = 0.936035 loss)
I0423 01:39:47.265460 30295 solver.cpp:244]     Train net output #1: loss = 0.644167 (* 1 = 0.644167 loss)
I0423 01:39:47.265466 30295 solver.cpp:244]     Train net output #2: loss = 0.864826 (* 1 = 0.864826 loss)
I0423 01:39:47.265471 30295 solver.cpp:244]     Train net output #3: loss = 0.457244 (* 1 = 0.457244 loss)
I0423 01:39:47.265476 30295 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0423 01:41:28.758092 30295 solver.cpp:228] Iteration 8300, loss = 2.85375
I0423 01:41:28.758266 30295 solver.cpp:244]     Train net output #0: loss = 0.974931 (* 1 = 0.974931 loss)
I0423 01:41:28.758275 30295 solver.cpp:244]     Train net output #1: loss = 0.509353 (* 1 = 0.509353 loss)
I0423 01:41:28.758280 30295 solver.cpp:244]     Train net output #2: loss = 0.879471 (* 1 = 0.879471 loss)
I0423 01:41:28.758285 30295 solver.cpp:244]     Train net output #3: loss = 0.489999 (* 1 = 0.489999 loss)
I0423 01:41:28.758288 30295 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0423 01:43:10.104794 30295 solver.cpp:228] Iteration 8400, loss = 2.78737
I0423 01:43:10.104954 30295 solver.cpp:244]     Train net output #0: loss = 0.980812 (* 1 = 0.980812 loss)
I0423 01:43:10.104962 30295 solver.cpp:244]     Train net output #1: loss = 0.472077 (* 1 = 0.472077 loss)
I0423 01:43:10.104967 30295 solver.cpp:244]     Train net output #2: loss = 0.723878 (* 1 = 0.723878 loss)
I0423 01:43:10.104972 30295 solver.cpp:244]     Train net output #3: loss = 0.6106 (* 1 = 0.6106 loss)
I0423 01:43:10.104979 30295 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0423 01:44:51.340481 30295 solver.cpp:228] Iteration 8500, loss = 2.32614
I0423 01:44:51.340627 30295 solver.cpp:244]     Train net output #0: loss = 0.986806 (* 1 = 0.986806 loss)
I0423 01:44:51.340636 30295 solver.cpp:244]     Train net output #1: loss = 0.321901 (* 1 = 0.321901 loss)
I0423 01:44:51.340641 30295 solver.cpp:244]     Train net output #2: loss = 0.627254 (* 1 = 0.627254 loss)
I0423 01:44:51.340644 30295 solver.cpp:244]     Train net output #3: loss = 0.390178 (* 1 = 0.390178 loss)
I0423 01:44:51.340649 30295 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0423 01:46:30.907120 30295 solver.cpp:228] Iteration 8600, loss = 2.61795
I0423 01:46:30.907294 30295 solver.cpp:244]     Train net output #0: loss = 0.977497 (* 1 = 0.977497 loss)
I0423 01:46:30.907301 30295 solver.cpp:244]     Train net output #1: loss = 0.399332 (* 1 = 0.399332 loss)
I0423 01:46:30.907306 30295 solver.cpp:244]     Train net output #2: loss = 0.730752 (* 1 = 0.730752 loss)
I0423 01:46:30.907311 30295 solver.cpp:244]     Train net output #3: loss = 0.510372 (* 1 = 0.510372 loss)
I0423 01:46:30.907315 30295 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0423 01:48:12.024283 30295 solver.cpp:228] Iteration 8700, loss = 2.52717
I0423 01:48:12.024447 30295 solver.cpp:244]     Train net output #0: loss = 0.95977 (* 1 = 0.95977 loss)
I0423 01:48:12.024456 30295 solver.cpp:244]     Train net output #1: loss = 0.255561 (* 1 = 0.255561 loss)
I0423 01:48:12.024461 30295 solver.cpp:244]     Train net output #2: loss = 0.841504 (* 1 = 0.841504 loss)
I0423 01:48:12.024466 30295 solver.cpp:244]     Train net output #3: loss = 0.470331 (* 1 = 0.470331 loss)
I0423 01:48:12.024469 30295 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0423 01:49:52.973256 30295 solver.cpp:228] Iteration 8800, loss = 2.50927
I0423 01:49:52.973423 30295 solver.cpp:244]     Train net output #0: loss = 0.937527 (* 1 = 0.937527 loss)
I0423 01:49:52.973430 30295 solver.cpp:244]     Train net output #1: loss = 0.256858 (* 1 = 0.256858 loss)
I0423 01:49:52.973443 30295 solver.cpp:244]     Train net output #2: loss = 0.859672 (* 1 = 0.859672 loss)
I0423 01:49:52.973449 30295 solver.cpp:244]     Train net output #3: loss = 0.455212 (* 1 = 0.455212 loss)
I0423 01:49:52.973454 30295 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0423 01:51:33.906409 30295 solver.cpp:228] Iteration 8900, loss = 2.88022
I0423 01:51:33.906563 30295 solver.cpp:244]     Train net output #0: loss = 0.938941 (* 1 = 0.938941 loss)
I0423 01:51:33.906572 30295 solver.cpp:244]     Train net output #1: loss = 0.510957 (* 1 = 0.510957 loss)
I0423 01:51:33.906577 30295 solver.cpp:244]     Train net output #2: loss = 0.76167 (* 1 = 0.76167 loss)
I0423 01:51:33.906582 30295 solver.cpp:244]     Train net output #3: loss = 0.668647 (* 1 = 0.668647 loss)
I0423 01:51:33.906587 30295 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0423 01:53:14.059258 30295 solver.cpp:337] Iteration 9000, Testing net (#0)
I0423 01:53:14.059397 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 01:53:14.059401 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 01:53:14.059406 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 01:53:14.059422 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 01:53:14.059424 30295 net.cpp:693] Ignoring source layer visualize
I0423 01:53:14.059427 30295 net.cpp:693] Ignoring source layer fake
I0423 01:56:52.012089 30295 solver.cpp:404]     Test net output #0: loss = 0.87913 (* 1 = 0.87913 loss)
I0423 01:56:52.012230 30295 solver.cpp:404]     Test net output #1: loss = 0.337272 (* 1 = 0.337272 loss)
I0423 01:56:52.012238 30295 solver.cpp:404]     Test net output #2: loss = 0.794993 (* 1 = 0.794993 loss)
I0423 01:56:52.012241 30295 solver.cpp:404]     Test net output #3: loss = 0.515824 (* 1 = 0.515824 loss)
I0423 01:56:52.670042 30295 solver.cpp:228] Iteration 9000, loss = 2.41721
I0423 01:56:52.670085 30295 solver.cpp:244]     Train net output #0: loss = 0.943406 (* 1 = 0.943406 loss)
I0423 01:56:52.670090 30295 solver.cpp:244]     Train net output #1: loss = 0.499296 (* 1 = 0.499296 loss)
I0423 01:56:52.670094 30295 solver.cpp:244]     Train net output #2: loss = 0.583286 (* 1 = 0.583286 loss)
I0423 01:56:52.670099 30295 solver.cpp:244]     Train net output #3: loss = 0.391223 (* 1 = 0.391223 loss)
I0423 01:56:52.670105 30295 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0423 01:58:33.990680 30295 solver.cpp:228] Iteration 9100, loss = 2.5844
I0423 01:58:33.990828 30295 solver.cpp:244]     Train net output #0: loss = 0.870378 (* 1 = 0.870378 loss)
I0423 01:58:33.990834 30295 solver.cpp:244]     Train net output #1: loss = 0.453276 (* 1 = 0.453276 loss)
I0423 01:58:33.990840 30295 solver.cpp:244]     Train net output #2: loss = 0.81304 (* 1 = 0.81304 loss)
I0423 01:58:33.990844 30295 solver.cpp:244]     Train net output #3: loss = 0.447702 (* 1 = 0.447702 loss)
I0423 01:58:33.990850 30295 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0423 02:00:15.620007 30295 solver.cpp:228] Iteration 9200, loss = 2.80008
I0423 02:00:15.620194 30295 solver.cpp:244]     Train net output #0: loss = 0.852806 (* 1 = 0.852806 loss)
I0423 02:00:15.620210 30295 solver.cpp:244]     Train net output #1: loss = 0.463542 (* 1 = 0.463542 loss)
I0423 02:00:15.620215 30295 solver.cpp:244]     Train net output #2: loss = 0.906461 (* 1 = 0.906461 loss)
I0423 02:00:15.620219 30295 solver.cpp:244]     Train net output #3: loss = 0.577273 (* 1 = 0.577273 loss)
I0423 02:00:15.620225 30295 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0423 02:01:55.208602 30295 solver.cpp:228] Iteration 9300, loss = 2.7755
I0423 02:01:55.208782 30295 solver.cpp:244]     Train net output #0: loss = 0.950235 (* 1 = 0.950235 loss)
I0423 02:01:55.208791 30295 solver.cpp:244]     Train net output #1: loss = 0.60961 (* 1 = 0.60961 loss)
I0423 02:01:55.208796 30295 solver.cpp:244]     Train net output #2: loss = 0.687836 (* 1 = 0.687836 loss)
I0423 02:01:55.208801 30295 solver.cpp:244]     Train net output #3: loss = 0.527815 (* 1 = 0.527815 loss)
I0423 02:01:55.208806 30295 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0423 02:03:36.647382 30295 solver.cpp:228] Iteration 9400, loss = 2.77587
I0423 02:03:36.647542 30295 solver.cpp:244]     Train net output #0: loss = 0.956811 (* 1 = 0.956811 loss)
I0423 02:03:36.647550 30295 solver.cpp:244]     Train net output #1: loss = 0.471366 (* 1 = 0.471366 loss)
I0423 02:03:36.647554 30295 solver.cpp:244]     Train net output #2: loss = 0.830586 (* 1 = 0.830586 loss)
I0423 02:03:36.647559 30295 solver.cpp:244]     Train net output #3: loss = 0.517111 (* 1 = 0.517111 loss)
I0423 02:03:36.647565 30295 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0423 02:05:18.008994 30295 solver.cpp:228] Iteration 9500, loss = 2.56287
I0423 02:05:18.009166 30295 solver.cpp:244]     Train net output #0: loss = 0.960281 (* 1 = 0.960281 loss)
I0423 02:05:18.009172 30295 solver.cpp:244]     Train net output #1: loss = 0.392479 (* 1 = 0.392479 loss)
I0423 02:05:18.009178 30295 solver.cpp:244]     Train net output #2: loss = 0.690902 (* 1 = 0.690902 loss)
I0423 02:05:18.009182 30295 solver.cpp:244]     Train net output #3: loss = 0.519208 (* 1 = 0.519208 loss)
I0423 02:05:18.009187 30295 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0423 02:06:57.673923 30295 solver.cpp:228] Iteration 9600, loss = 2.96949
I0423 02:06:57.674095 30295 solver.cpp:244]     Train net output #0: loss = 0.959618 (* 1 = 0.959618 loss)
I0423 02:06:57.674103 30295 solver.cpp:244]     Train net output #1: loss = 0.503434 (* 1 = 0.503434 loss)
I0423 02:06:57.674108 30295 solver.cpp:244]     Train net output #2: loss = 0.916604 (* 1 = 0.916604 loss)
I0423 02:06:57.674113 30295 solver.cpp:244]     Train net output #3: loss = 0.589837 (* 1 = 0.589837 loss)
I0423 02:06:57.674118 30295 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0423 02:08:38.805538 30295 solver.cpp:228] Iteration 9700, loss = 2.90137
I0423 02:08:38.805707 30295 solver.cpp:244]     Train net output #0: loss = 0.954724 (* 1 = 0.954724 loss)
I0423 02:08:38.805714 30295 solver.cpp:244]     Train net output #1: loss = 0.482374 (* 1 = 0.482374 loss)
I0423 02:08:38.805721 30295 solver.cpp:244]     Train net output #2: loss = 0.931647 (* 1 = 0.931647 loss)
I0423 02:08:38.805726 30295 solver.cpp:244]     Train net output #3: loss = 0.53263 (* 1 = 0.53263 loss)
I0423 02:08:38.805730 30295 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0423 02:10:20.005012 30295 solver.cpp:228] Iteration 9800, loss = 2.91088
I0423 02:10:20.005828 30295 solver.cpp:244]     Train net output #0: loss = 0.977175 (* 1 = 0.977175 loss)
I0423 02:10:20.005836 30295 solver.cpp:244]     Train net output #1: loss = 0.47979 (* 1 = 0.47979 loss)
I0423 02:10:20.005841 30295 solver.cpp:244]     Train net output #2: loss = 0.914253 (* 1 = 0.914253 loss)
I0423 02:10:20.005846 30295 solver.cpp:244]     Train net output #3: loss = 0.539657 (* 1 = 0.539657 loss)
I0423 02:10:20.005851 30295 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0423 02:12:01.018167 30295 solver.cpp:228] Iteration 9900, loss = 2.59497
I0423 02:12:01.018355 30295 solver.cpp:244]     Train net output #0: loss = 0.982092 (* 1 = 0.982092 loss)
I0423 02:12:01.018363 30295 solver.cpp:244]     Train net output #1: loss = 0.324425 (* 1 = 0.324425 loss)
I0423 02:12:01.018369 30295 solver.cpp:244]     Train net output #2: loss = 0.790625 (* 1 = 0.790625 loss)
I0423 02:12:01.018373 30295 solver.cpp:244]     Train net output #3: loss = 0.49783 (* 1 = 0.49783 loss)
I0423 02:12:01.018378 30295 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0423 02:13:40.061966 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_10000.caffemodel
I0423 02:13:58.278275 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_10000.solverstate
I0423 02:13:58.475463 30295 solver.cpp:337] Iteration 10000, Testing net (#0)
I0423 02:13:58.475507 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 02:13:58.475509 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 02:13:58.475515 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 02:13:58.475530 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 02:13:58.475533 30295 net.cpp:693] Ignoring source layer visualize
I0423 02:13:58.475534 30295 net.cpp:693] Ignoring source layer fake
I0423 02:17:33.732285 30295 solver.cpp:404]     Test net output #0: loss = 0.945618 (* 1 = 0.945618 loss)
I0423 02:17:33.732483 30295 solver.cpp:404]     Test net output #1: loss = 0.344153 (* 1 = 0.344153 loss)
I0423 02:17:33.732489 30295 solver.cpp:404]     Test net output #2: loss = 0.792902 (* 1 = 0.792902 loss)
I0423 02:17:33.732494 30295 solver.cpp:404]     Test net output #3: loss = 0.508539 (* 1 = 0.508539 loss)
I0423 02:17:34.392904 30295 solver.cpp:228] Iteration 10000, loss = 2.413
I0423 02:17:34.392946 30295 solver.cpp:244]     Train net output #0: loss = 0.937089 (* 1 = 0.937089 loss)
I0423 02:17:34.392952 30295 solver.cpp:244]     Train net output #1: loss = 0.139737 (* 1 = 0.139737 loss)
I0423 02:17:34.392956 30295 solver.cpp:244]     Train net output #2: loss = 0.875165 (* 1 = 0.875165 loss)
I0423 02:17:34.392961 30295 solver.cpp:244]     Train net output #3: loss = 0.461006 (* 1 = 0.461006 loss)
I0423 02:17:34.392964 30295 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0423 02:19:14.844251 30295 solver.cpp:228] Iteration 10100, loss = 2.75289
I0423 02:19:14.844401 30295 solver.cpp:244]     Train net output #0: loss = 0.92918 (* 1 = 0.92918 loss)
I0423 02:19:14.844409 30295 solver.cpp:244]     Train net output #1: loss = 0.400928 (* 1 = 0.400928 loss)
I0423 02:19:14.844414 30295 solver.cpp:244]     Train net output #2: loss = 0.92023 (* 1 = 0.92023 loss)
I0423 02:19:14.844419 30295 solver.cpp:244]     Train net output #3: loss = 0.502553 (* 1 = 0.502553 loss)
I0423 02:19:14.844422 30295 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0423 02:20:53.790041 30295 solver.cpp:228] Iteration 10200, loss = 2.54344
I0423 02:20:53.790176 30295 solver.cpp:244]     Train net output #0: loss = 0.978248 (* 1 = 0.978248 loss)
I0423 02:20:53.790184 30295 solver.cpp:244]     Train net output #1: loss = 0.2902 (* 1 = 0.2902 loss)
I0423 02:20:53.790189 30295 solver.cpp:244]     Train net output #2: loss = 0.732735 (* 1 = 0.732735 loss)
I0423 02:20:53.790194 30295 solver.cpp:244]     Train net output #3: loss = 0.542254 (* 1 = 0.542254 loss)
I0423 02:20:53.790197 30295 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0423 02:22:34.487763 30295 solver.cpp:228] Iteration 10300, loss = 2.75657
I0423 02:22:34.487910 30295 solver.cpp:244]     Train net output #0: loss = 0.959376 (* 1 = 0.959376 loss)
I0423 02:22:34.487917 30295 solver.cpp:244]     Train net output #1: loss = 0.574165 (* 1 = 0.574165 loss)
I0423 02:22:34.487922 30295 solver.cpp:244]     Train net output #2: loss = 0.762453 (* 1 = 0.762453 loss)
I0423 02:22:34.487926 30295 solver.cpp:244]     Train net output #3: loss = 0.460578 (* 1 = 0.460578 loss)
I0423 02:22:34.487931 30295 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0423 02:24:15.285769 30295 solver.cpp:228] Iteration 10400, loss = 1.86814
I0423 02:24:15.285961 30295 solver.cpp:244]     Train net output #0: loss = 0.96361 (* 1 = 0.96361 loss)
I0423 02:24:15.285969 30295 solver.cpp:244]     Train net output #1: loss = 0.0863832 (* 1 = 0.0863832 loss)
I0423 02:24:15.285974 30295 solver.cpp:244]     Train net output #2: loss = 0.714076 (* 1 = 0.714076 loss)
I0423 02:24:15.285979 30295 solver.cpp:244]     Train net output #3: loss = 0.104072 (* 1 = 0.104072 loss)
I0423 02:24:15.285984 30295 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0423 02:25:55.999740 30295 solver.cpp:228] Iteration 10500, loss = 3.07944
I0423 02:25:55.999892 30295 solver.cpp:244]     Train net output #0: loss = 0.964778 (* 1 = 0.964778 loss)
I0423 02:25:55.999902 30295 solver.cpp:244]     Train net output #1: loss = 0.662435 (* 1 = 0.662435 loss)
I0423 02:25:55.999905 30295 solver.cpp:244]     Train net output #2: loss = 0.874847 (* 1 = 0.874847 loss)
I0423 02:25:55.999910 30295 solver.cpp:244]     Train net output #3: loss = 0.577379 (* 1 = 0.577379 loss)
I0423 02:25:55.999915 30295 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0423 02:27:37.218480 30295 solver.cpp:228] Iteration 10600, loss = 2.8857
I0423 02:27:37.218643 30295 solver.cpp:244]     Train net output #0: loss = 0.956924 (* 1 = 0.956924 loss)
I0423 02:27:37.218652 30295 solver.cpp:244]     Train net output #1: loss = 0.566446 (* 1 = 0.566446 loss)
I0423 02:27:37.218657 30295 solver.cpp:244]     Train net output #2: loss = 0.734001 (* 1 = 0.734001 loss)
I0423 02:27:37.218662 30295 solver.cpp:244]     Train net output #3: loss = 0.628334 (* 1 = 0.628334 loss)
I0423 02:27:37.218665 30295 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0423 02:29:16.302785 30295 solver.cpp:228] Iteration 10700, loss = 3.02778
I0423 02:29:16.302947 30295 solver.cpp:244]     Train net output #0: loss = 0.960011 (* 1 = 0.960011 loss)
I0423 02:29:16.302955 30295 solver.cpp:244]     Train net output #1: loss = 0.684108 (* 1 = 0.684108 loss)
I0423 02:29:16.302960 30295 solver.cpp:244]     Train net output #2: loss = 0.851477 (* 1 = 0.851477 loss)
I0423 02:29:16.302964 30295 solver.cpp:244]     Train net output #3: loss = 0.532179 (* 1 = 0.532179 loss)
I0423 02:29:16.302969 30295 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0423 02:30:57.295495 30295 solver.cpp:228] Iteration 10800, loss = 2.78703
I0423 02:30:57.295665 30295 solver.cpp:244]     Train net output #0: loss = 0.980823 (* 1 = 0.980823 loss)
I0423 02:30:57.295672 30295 solver.cpp:244]     Train net output #1: loss = 0.579766 (* 1 = 0.579766 loss)
I0423 02:30:57.295676 30295 solver.cpp:244]     Train net output #2: loss = 0.77053 (* 1 = 0.77053 loss)
I0423 02:30:57.295681 30295 solver.cpp:244]     Train net output #3: loss = 0.455906 (* 1 = 0.455906 loss)
I0423 02:30:57.295686 30295 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0423 02:32:38.160944 30295 solver.cpp:228] Iteration 10900, loss = 2.80615
I0423 02:32:38.161088 30295 solver.cpp:244]     Train net output #0: loss = 0.975256 (* 1 = 0.975256 loss)
I0423 02:32:38.161098 30295 solver.cpp:244]     Train net output #1: loss = 0.510263 (* 1 = 0.510263 loss)
I0423 02:32:38.161101 30295 solver.cpp:244]     Train net output #2: loss = 0.73679 (* 1 = 0.73679 loss)
I0423 02:32:38.161105 30295 solver.cpp:244]     Train net output #3: loss = 0.583841 (* 1 = 0.583841 loss)
I0423 02:32:38.161110 30295 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0423 02:34:18.067883 30295 solver.cpp:337] Iteration 11000, Testing net (#0)
I0423 02:34:18.068023 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 02:34:18.068028 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 02:34:18.068032 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 02:34:18.068048 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 02:34:18.068051 30295 net.cpp:693] Ignoring source layer visualize
I0423 02:34:18.068053 30295 net.cpp:693] Ignoring source layer fake
I0423 02:37:53.945094 30295 solver.cpp:404]     Test net output #0: loss = 0.942368 (* 1 = 0.942368 loss)
I0423 02:37:53.945260 30295 solver.cpp:404]     Test net output #1: loss = 0.386303 (* 1 = 0.386303 loss)
I0423 02:37:53.945266 30295 solver.cpp:404]     Test net output #2: loss = 0.798007 (* 1 = 0.798007 loss)
I0423 02:37:53.945271 30295 solver.cpp:404]     Test net output #3: loss = 0.522747 (* 1 = 0.522747 loss)
I0423 02:37:54.606921 30295 solver.cpp:228] Iteration 11000, loss = 2.79292
I0423 02:37:54.606966 30295 solver.cpp:244]     Train net output #0: loss = 0.978653 (* 1 = 0.978653 loss)
I0423 02:37:54.606971 30295 solver.cpp:244]     Train net output #1: loss = 0.432063 (* 1 = 0.432063 loss)
I0423 02:37:54.606990 30295 solver.cpp:244]     Train net output #2: loss = 0.756185 (* 1 = 0.756185 loss)
I0423 02:37:54.606997 30295 solver.cpp:244]     Train net output #3: loss = 0.626023 (* 1 = 0.626023 loss)
I0423 02:37:54.607002 30295 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0423 02:39:33.660429 30295 solver.cpp:228] Iteration 11100, loss = 3.16723
I0423 02:39:33.660583 30295 solver.cpp:244]     Train net output #0: loss = 0.97867 (* 1 = 0.97867 loss)
I0423 02:39:33.660590 30295 solver.cpp:244]     Train net output #1: loss = 0.595303 (* 1 = 0.595303 loss)
I0423 02:39:33.660596 30295 solver.cpp:244]     Train net output #2: loss = 0.948715 (* 1 = 0.948715 loss)
I0423 02:39:33.660600 30295 solver.cpp:244]     Train net output #3: loss = 0.644539 (* 1 = 0.644539 loss)
I0423 02:39:33.660605 30295 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0423 02:41:14.440215 30295 solver.cpp:228] Iteration 11200, loss = 2.47142
I0423 02:41:14.440804 30295 solver.cpp:244]     Train net output #0: loss = 0.978623 (* 1 = 0.978623 loss)
I0423 02:41:14.440814 30295 solver.cpp:244]     Train net output #1: loss = 0.359725 (* 1 = 0.359725 loss)
I0423 02:41:14.440817 30295 solver.cpp:244]     Train net output #2: loss = 0.647094 (* 1 = 0.647094 loss)
I0423 02:41:14.440821 30295 solver.cpp:244]     Train net output #3: loss = 0.485981 (* 1 = 0.485981 loss)
I0423 02:41:14.440827 30295 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0423 02:42:54.607026 30295 solver.cpp:228] Iteration 11300, loss = 2.42731
I0423 02:42:54.607168 30295 solver.cpp:244]     Train net output #0: loss = 0.951515 (* 1 = 0.951515 loss)
I0423 02:42:54.607175 30295 solver.cpp:244]     Train net output #1: loss = 0.184923 (* 1 = 0.184923 loss)
I0423 02:42:54.607182 30295 solver.cpp:244]     Train net output #2: loss = 0.89938 (* 1 = 0.89938 loss)
I0423 02:42:54.607185 30295 solver.cpp:244]     Train net output #3: loss = 0.391495 (* 1 = 0.391495 loss)
I0423 02:42:54.607190 30295 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0423 02:44:34.940994 30295 solver.cpp:228] Iteration 11400, loss = 2.30613
I0423 02:44:34.941138 30295 solver.cpp:244]     Train net output #0: loss = 0.959574 (* 1 = 0.959574 loss)
I0423 02:44:34.941145 30295 solver.cpp:244]     Train net output #1: loss = 0.357859 (* 1 = 0.357859 loss)
I0423 02:44:34.941150 30295 solver.cpp:244]     Train net output #2: loss = 0.578232 (* 1 = 0.578232 loss)
I0423 02:44:34.941154 30295 solver.cpp:244]     Train net output #3: loss = 0.410468 (* 1 = 0.410468 loss)
I0423 02:44:34.941169 30295 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0423 02:46:15.415560 30295 solver.cpp:228] Iteration 11500, loss = 2.40154
I0423 02:46:15.415716 30295 solver.cpp:244]     Train net output #0: loss = 0.937544 (* 1 = 0.937544 loss)
I0423 02:46:15.415724 30295 solver.cpp:244]     Train net output #1: loss = 0.509479 (* 1 = 0.509479 loss)
I0423 02:46:15.415729 30295 solver.cpp:244]     Train net output #2: loss = 0.552725 (* 1 = 0.552725 loss)
I0423 02:46:15.415735 30295 solver.cpp:244]     Train net output #3: loss = 0.401789 (* 1 = 0.401789 loss)
I0423 02:46:15.415738 30295 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0423 02:47:56.047669 30295 solver.cpp:228] Iteration 11600, loss = 2.19036
I0423 02:47:56.047853 30295 solver.cpp:244]     Train net output #0: loss = 0.949372 (* 1 = 0.949372 loss)
I0423 02:47:56.047861 30295 solver.cpp:244]     Train net output #1: loss = 0.225348 (* 1 = 0.225348 loss)
I0423 02:47:56.047865 30295 solver.cpp:244]     Train net output #2: loss = 0.697529 (* 1 = 0.697529 loss)
I0423 02:47:56.047870 30295 solver.cpp:244]     Train net output #3: loss = 0.31811 (* 1 = 0.31811 loss)
I0423 02:47:56.047875 30295 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0423 02:49:36.770035 30295 solver.cpp:228] Iteration 11700, loss = 2.67686
I0423 02:49:36.770206 30295 solver.cpp:244]     Train net output #0: loss = 0.857394 (* 1 = 0.857394 loss)
I0423 02:49:36.770215 30295 solver.cpp:244]     Train net output #1: loss = 0.413319 (* 1 = 0.413319 loss)
I0423 02:49:36.770220 30295 solver.cpp:244]     Train net output #2: loss = 0.885174 (* 1 = 0.885174 loss)
I0423 02:49:36.770225 30295 solver.cpp:244]     Train net output #3: loss = 0.520971 (* 1 = 0.520971 loss)
I0423 02:49:36.770229 30295 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0423 02:51:15.809883 30295 solver.cpp:228] Iteration 11800, loss = 2.85069
I0423 02:51:15.810029 30295 solver.cpp:244]     Train net output #0: loss = 0.950834 (* 1 = 0.950834 loss)
I0423 02:51:15.810036 30295 solver.cpp:244]     Train net output #1: loss = 0.507233 (* 1 = 0.507233 loss)
I0423 02:51:15.810041 30295 solver.cpp:244]     Train net output #2: loss = 0.862973 (* 1 = 0.862973 loss)
I0423 02:51:15.810045 30295 solver.cpp:244]     Train net output #3: loss = 0.529647 (* 1 = 0.529647 loss)
I0423 02:51:15.810050 30295 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0423 02:52:56.802275 30295 solver.cpp:228] Iteration 11900, loss = 2.67745
I0423 02:52:56.802439 30295 solver.cpp:244]     Train net output #0: loss = 0.950221 (* 1 = 0.950221 loss)
I0423 02:52:56.802448 30295 solver.cpp:244]     Train net output #1: loss = 0.408749 (* 1 = 0.408749 loss)
I0423 02:52:56.802453 30295 solver.cpp:244]     Train net output #2: loss = 0.85339 (* 1 = 0.85339 loss)
I0423 02:52:56.802458 30295 solver.cpp:244]     Train net output #3: loss = 0.465094 (* 1 = 0.465094 loss)
I0423 02:52:56.802461 30295 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0423 02:54:36.728130 30295 solver.cpp:337] Iteration 12000, Testing net (#0)
I0423 02:54:36.728292 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 02:54:36.728296 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 02:54:36.728301 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 02:54:36.728315 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 02:54:36.728319 30295 net.cpp:693] Ignoring source layer visualize
I0423 02:54:36.728322 30295 net.cpp:693] Ignoring source layer fake
I0423 02:58:12.127703 30295 solver.cpp:404]     Test net output #0: loss = 0.938525 (* 1 = 0.938525 loss)
I0423 02:58:12.127827 30295 solver.cpp:404]     Test net output #1: loss = 0.357775 (* 1 = 0.357775 loss)
I0423 02:58:12.127835 30295 solver.cpp:404]     Test net output #2: loss = 0.78076 (* 1 = 0.78076 loss)
I0423 02:58:12.127840 30295 solver.cpp:404]     Test net output #3: loss = 0.471053 (* 1 = 0.471053 loss)
I0423 02:58:12.789144 30295 solver.cpp:228] Iteration 12000, loss = 2.90742
I0423 02:58:12.789186 30295 solver.cpp:244]     Train net output #0: loss = 0.965438 (* 1 = 0.965438 loss)
I0423 02:58:12.789191 30295 solver.cpp:244]     Train net output #1: loss = 0.668329 (* 1 = 0.668329 loss)
I0423 02:58:12.789196 30295 solver.cpp:244]     Train net output #2: loss = 0.710603 (* 1 = 0.710603 loss)
I0423 02:58:12.789199 30295 solver.cpp:244]     Train net output #3: loss = 0.563051 (* 1 = 0.563051 loss)
I0423 02:58:12.789203 30295 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0423 02:59:51.832515 30295 solver.cpp:228] Iteration 12100, loss = 3.00227
I0423 02:59:51.832661 30295 solver.cpp:244]     Train net output #0: loss = 0.984323 (* 1 = 0.984323 loss)
I0423 02:59:51.832669 30295 solver.cpp:244]     Train net output #1: loss = 0.576795 (* 1 = 0.576795 loss)
I0423 02:59:51.832674 30295 solver.cpp:244]     Train net output #2: loss = 0.902916 (* 1 = 0.902916 loss)
I0423 02:59:51.832679 30295 solver.cpp:244]     Train net output #3: loss = 0.538232 (* 1 = 0.538232 loss)
I0423 02:59:51.832682 30295 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0423 03:01:32.444450 30295 solver.cpp:228] Iteration 12200, loss = 2.90993
I0423 03:01:32.445333 30295 solver.cpp:244]     Train net output #0: loss = 0.966755 (* 1 = 0.966755 loss)
I0423 03:01:32.445343 30295 solver.cpp:244]     Train net output #1: loss = 0.479466 (* 1 = 0.479466 loss)
I0423 03:01:32.445346 30295 solver.cpp:244]     Train net output #2: loss = 0.924291 (* 1 = 0.924291 loss)
I0423 03:01:32.445365 30295 solver.cpp:244]     Train net output #3: loss = 0.539418 (* 1 = 0.539418 loss)
I0423 03:01:32.445371 30295 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0423 03:03:13.063519 30295 solver.cpp:228] Iteration 12300, loss = 2.64978
I0423 03:03:13.063668 30295 solver.cpp:244]     Train net output #0: loss = 0.97821 (* 1 = 0.97821 loss)
I0423 03:03:13.063674 30295 solver.cpp:244]     Train net output #1: loss = 0.432566 (* 1 = 0.432566 loss)
I0423 03:03:13.063679 30295 solver.cpp:244]     Train net output #2: loss = 0.841044 (* 1 = 0.841044 loss)
I0423 03:03:13.063684 30295 solver.cpp:244]     Train net output #3: loss = 0.397955 (* 1 = 0.397955 loss)
I0423 03:03:13.063689 30295 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0423 03:04:53.573717 30295 solver.cpp:228] Iteration 12400, loss = 2.74795
I0423 03:04:53.573873 30295 solver.cpp:244]     Train net output #0: loss = 0.969888 (* 1 = 0.969888 loss)
I0423 03:04:53.573880 30295 solver.cpp:244]     Train net output #1: loss = 0.379815 (* 1 = 0.379815 loss)
I0423 03:04:53.573885 30295 solver.cpp:244]     Train net output #2: loss = 0.897088 (* 1 = 0.897088 loss)
I0423 03:04:53.573890 30295 solver.cpp:244]     Train net output #3: loss = 0.501163 (* 1 = 0.501163 loss)
I0423 03:04:53.573895 30295 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0423 03:06:33.697958 30295 solver.cpp:228] Iteration 12500, loss = 2.30615
I0423 03:06:33.698117 30295 solver.cpp:244]     Train net output #0: loss = 0.939022 (* 1 = 0.939022 loss)
I0423 03:06:33.698124 30295 solver.cpp:244]     Train net output #1: loss = 0.142159 (* 1 = 0.142159 loss)
I0423 03:06:33.698129 30295 solver.cpp:244]     Train net output #2: loss = 0.86864 (* 1 = 0.86864 loss)
I0423 03:06:33.698134 30295 solver.cpp:244]     Train net output #3: loss = 0.356327 (* 1 = 0.356327 loss)
I0423 03:06:33.698139 30295 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0423 03:08:14.019243 30295 solver.cpp:228] Iteration 12600, loss = 2.26499
I0423 03:08:14.019392 30295 solver.cpp:244]     Train net output #0: loss = 0.927724 (* 1 = 0.927724 loss)
I0423 03:08:14.019399 30295 solver.cpp:244]     Train net output #1: loss = 0.228343 (* 1 = 0.228343 loss)
I0423 03:08:14.019403 30295 solver.cpp:244]     Train net output #2: loss = 0.578617 (* 1 = 0.578617 loss)
I0423 03:08:14.019407 30295 solver.cpp:244]     Train net output #3: loss = 0.530308 (* 1 = 0.530308 loss)
I0423 03:08:14.019412 30295 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0423 03:09:53.022347 30295 solver.cpp:228] Iteration 12700, loss = 2.7652
I0423 03:09:53.022502 30295 solver.cpp:244]     Train net output #0: loss = 0.941809 (* 1 = 0.941809 loss)
I0423 03:09:53.022509 30295 solver.cpp:244]     Train net output #1: loss = 0.338578 (* 1 = 0.338578 loss)
I0423 03:09:53.022514 30295 solver.cpp:244]     Train net output #2: loss = 0.951503 (* 1 = 0.951503 loss)
I0423 03:09:53.022519 30295 solver.cpp:244]     Train net output #3: loss = 0.533314 (* 1 = 0.533314 loss)
I0423 03:09:53.022533 30295 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0423 03:11:33.364301 30295 solver.cpp:228] Iteration 12800, loss = 2.57953
I0423 03:11:33.364462 30295 solver.cpp:244]     Train net output #0: loss = 0.977581 (* 1 = 0.977581 loss)
I0423 03:11:33.364470 30295 solver.cpp:244]     Train net output #1: loss = 0.463657 (* 1 = 0.463657 loss)
I0423 03:11:33.364475 30295 solver.cpp:244]     Train net output #2: loss = 0.576868 (* 1 = 0.576868 loss)
I0423 03:11:33.364480 30295 solver.cpp:244]     Train net output #3: loss = 0.561426 (* 1 = 0.561426 loss)
I0423 03:11:33.364485 30295 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0423 03:13:14.066150 30295 solver.cpp:228] Iteration 12900, loss = 1.67244
I0423 03:13:14.066301 30295 solver.cpp:244]     Train net output #0: loss = 0.962216 (* 1 = 0.962216 loss)
I0423 03:13:14.066308 30295 solver.cpp:244]     Train net output #1: loss = 0.0656029 (* 1 = 0.0656029 loss)
I0423 03:13:14.066313 30295 solver.cpp:244]     Train net output #2: loss = 0.553253 (* 1 = 0.553253 loss)
I0423 03:13:14.066318 30295 solver.cpp:244]     Train net output #3: loss = 0.0913679 (* 1 = 0.0913679 loss)
I0423 03:13:14.066324 30295 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0423 03:14:53.881049 30295 solver.cpp:337] Iteration 13000, Testing net (#0)
I0423 03:14:53.881188 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 03:14:53.881193 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 03:14:53.881197 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 03:14:53.881212 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 03:14:53.881216 30295 net.cpp:693] Ignoring source layer visualize
I0423 03:14:53.881218 30295 net.cpp:693] Ignoring source layer fake
I0423 03:18:29.686991 30295 solver.cpp:404]     Test net output #0: loss = 0.960965 (* 1 = 0.960965 loss)
I0423 03:18:29.687144 30295 solver.cpp:404]     Test net output #1: loss = 0.44804 (* 1 = 0.44804 loss)
I0423 03:18:29.687151 30295 solver.cpp:404]     Test net output #2: loss = 0.808798 (* 1 = 0.808798 loss)
I0423 03:18:29.687156 30295 solver.cpp:404]     Test net output #3: loss = 0.530218 (* 1 = 0.530218 loss)
I0423 03:18:30.350411 30295 solver.cpp:228] Iteration 13000, loss = 2.78995
I0423 03:18:30.350455 30295 solver.cpp:244]     Train net output #0: loss = 0.961419 (* 1 = 0.961419 loss)
I0423 03:18:30.350461 30295 solver.cpp:244]     Train net output #1: loss = 0.461712 (* 1 = 0.461712 loss)
I0423 03:18:30.350466 30295 solver.cpp:244]     Train net output #2: loss = 0.810754 (* 1 = 0.810754 loss)
I0423 03:18:30.350471 30295 solver.cpp:244]     Train net output #3: loss = 0.556067 (* 1 = 0.556067 loss)
I0423 03:18:30.350474 30295 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0423 03:20:11.096854 30295 solver.cpp:228] Iteration 13100, loss = 2.82998
I0423 03:20:11.096994 30295 solver.cpp:244]     Train net output #0: loss = 0.959148 (* 1 = 0.959148 loss)
I0423 03:20:11.097002 30295 solver.cpp:244]     Train net output #1: loss = 0.496313 (* 1 = 0.496313 loss)
I0423 03:20:11.097007 30295 solver.cpp:244]     Train net output #2: loss = 0.874687 (* 1 = 0.874687 loss)
I0423 03:20:11.097012 30295 solver.cpp:244]     Train net output #3: loss = 0.499828 (* 1 = 0.499828 loss)
I0423 03:20:11.097017 30295 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0423 03:21:50.180044 30295 solver.cpp:228] Iteration 13200, loss = 2.80829
I0423 03:21:50.180183 30295 solver.cpp:244]     Train net output #0: loss = 0.942161 (* 1 = 0.942161 loss)
I0423 03:21:50.180191 30295 solver.cpp:244]     Train net output #1: loss = 0.495206 (* 1 = 0.495206 loss)
I0423 03:21:50.180197 30295 solver.cpp:244]     Train net output #2: loss = 0.900661 (* 1 = 0.900661 loss)
I0423 03:21:50.180200 30295 solver.cpp:244]     Train net output #3: loss = 0.470263 (* 1 = 0.470263 loss)
I0423 03:21:50.180204 30295 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0423 03:23:31.639091 30295 solver.cpp:228] Iteration 13300, loss = 2.65974
I0423 03:23:31.639248 30295 solver.cpp:244]     Train net output #0: loss = 0.974834 (* 1 = 0.974834 loss)
I0423 03:23:31.639256 30295 solver.cpp:244]     Train net output #1: loss = 0.547615 (* 1 = 0.547615 loss)
I0423 03:23:31.639261 30295 solver.cpp:244]     Train net output #2: loss = 0.629691 (* 1 = 0.629691 loss)
I0423 03:23:31.639266 30295 solver.cpp:244]     Train net output #3: loss = 0.507596 (* 1 = 0.507596 loss)
I0423 03:23:31.639271 30295 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0423 03:25:12.548951 30295 solver.cpp:228] Iteration 13400, loss = 2.86854
I0423 03:25:12.549141 30295 solver.cpp:244]     Train net output #0: loss = 0.979209 (* 1 = 0.979209 loss)
I0423 03:25:12.549149 30295 solver.cpp:244]     Train net output #1: loss = 0.661327 (* 1 = 0.661327 loss)
I0423 03:25:12.549155 30295 solver.cpp:244]     Train net output #2: loss = 0.724641 (* 1 = 0.724641 loss)
I0423 03:25:12.549160 30295 solver.cpp:244]     Train net output #3: loss = 0.503361 (* 1 = 0.503361 loss)
I0423 03:25:12.549163 30295 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0423 03:26:53.778323 30295 solver.cpp:228] Iteration 13500, loss = 2.85889
I0423 03:26:53.778476 30295 solver.cpp:244]     Train net output #0: loss = 0.973237 (* 1 = 0.973237 loss)
I0423 03:26:53.778484 30295 solver.cpp:244]     Train net output #1: loss = 0.420822 (* 1 = 0.420822 loss)
I0423 03:26:53.778489 30295 solver.cpp:244]     Train net output #2: loss = 0.928261 (* 1 = 0.928261 loss)
I0423 03:26:53.778493 30295 solver.cpp:244]     Train net output #3: loss = 0.536567 (* 1 = 0.536567 loss)
I0423 03:26:53.778499 30295 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0423 03:28:33.345247 30295 solver.cpp:228] Iteration 13600, loss = 2.83205
I0423 03:28:33.345901 30295 solver.cpp:244]     Train net output #0: loss = 0.974911 (* 1 = 0.974911 loss)
I0423 03:28:33.345909 30295 solver.cpp:244]     Train net output #1: loss = 0.49997 (* 1 = 0.49997 loss)
I0423 03:28:33.345914 30295 solver.cpp:244]     Train net output #2: loss = 0.845201 (* 1 = 0.845201 loss)
I0423 03:28:33.345918 30295 solver.cpp:244]     Train net output #3: loss = 0.511969 (* 1 = 0.511969 loss)
I0423 03:28:33.345922 30295 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0423 03:30:14.564697 30295 solver.cpp:228] Iteration 13700, loss = 2.66463
I0423 03:30:14.564853 30295 solver.cpp:244]     Train net output #0: loss = 0.946162 (* 1 = 0.946162 loss)
I0423 03:30:14.564860 30295 solver.cpp:244]     Train net output #1: loss = 0.311675 (* 1 = 0.311675 loss)
I0423 03:30:14.564865 30295 solver.cpp:244]     Train net output #2: loss = 0.86799 (* 1 = 0.86799 loss)
I0423 03:30:14.564869 30295 solver.cpp:244]     Train net output #3: loss = 0.538798 (* 1 = 0.538798 loss)
I0423 03:30:14.564875 30295 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0423 03:31:55.196950 30295 solver.cpp:228] Iteration 13800, loss = 2.51701
I0423 03:31:55.197098 30295 solver.cpp:244]     Train net output #0: loss = 0.958113 (* 1 = 0.958113 loss)
I0423 03:31:55.197105 30295 solver.cpp:244]     Train net output #1: loss = 0.30644 (* 1 = 0.30644 loss)
I0423 03:31:55.197111 30295 solver.cpp:244]     Train net output #2: loss = 0.893857 (* 1 = 0.893857 loss)
I0423 03:31:55.197115 30295 solver.cpp:244]     Train net output #3: loss = 0.358604 (* 1 = 0.358604 loss)
I0423 03:31:55.197120 30295 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0423 03:33:35.996904 30295 solver.cpp:228] Iteration 13900, loss = 2.77596
I0423 03:33:35.997063 30295 solver.cpp:244]     Train net output #0: loss = 0.957852 (* 1 = 0.957852 loss)
I0423 03:33:35.997071 30295 solver.cpp:244]     Train net output #1: loss = 0.564868 (* 1 = 0.564868 loss)
I0423 03:33:35.997076 30295 solver.cpp:244]     Train net output #2: loss = 0.726737 (* 1 = 0.726737 loss)
I0423 03:33:35.997081 30295 solver.cpp:244]     Train net output #3: loss = 0.5265 (* 1 = 0.5265 loss)
I0423 03:33:35.997087 30295 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0423 03:35:16.008431 30295 solver.cpp:337] Iteration 14000, Testing net (#0)
I0423 03:35:16.008579 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 03:35:16.008582 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 03:35:16.008586 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 03:35:16.008601 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 03:35:16.008605 30295 net.cpp:693] Ignoring source layer visualize
I0423 03:35:16.008607 30295 net.cpp:693] Ignoring source layer fake
I0423 03:38:53.696563 30295 solver.cpp:404]     Test net output #0: loss = 0.931644 (* 1 = 0.931644 loss)
I0423 03:38:53.696734 30295 solver.cpp:404]     Test net output #1: loss = 0.383985 (* 1 = 0.383985 loss)
I0423 03:38:53.696740 30295 solver.cpp:404]     Test net output #2: loss = 0.803406 (* 1 = 0.803406 loss)
I0423 03:38:53.696745 30295 solver.cpp:404]     Test net output #3: loss = 0.523521 (* 1 = 0.523521 loss)
I0423 03:38:54.358505 30295 solver.cpp:228] Iteration 14000, loss = 2.90502
I0423 03:38:54.358546 30295 solver.cpp:244]     Train net output #0: loss = 0.9821 (* 1 = 0.9821 loss)
I0423 03:38:54.358551 30295 solver.cpp:244]     Train net output #1: loss = 0.581548 (* 1 = 0.581548 loss)
I0423 03:38:54.358554 30295 solver.cpp:244]     Train net output #2: loss = 0.748482 (* 1 = 0.748482 loss)
I0423 03:38:54.358559 30295 solver.cpp:244]     Train net output #3: loss = 0.592891 (* 1 = 0.592891 loss)
I0423 03:38:54.358564 30295 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0423 03:40:35.591576 30295 solver.cpp:228] Iteration 14100, loss = 1.76497
I0423 03:40:35.591754 30295 solver.cpp:244]     Train net output #0: loss = 0.954966 (* 1 = 0.954966 loss)
I0423 03:40:35.591763 30295 solver.cpp:244]     Train net output #1: loss = 0.0901497 (* 1 = 0.0901497 loss)
I0423 03:40:35.591768 30295 solver.cpp:244]     Train net output #2: loss = 0.534379 (* 1 = 0.534379 loss)
I0423 03:40:35.591773 30295 solver.cpp:244]     Train net output #3: loss = 0.18548 (* 1 = 0.18548 loss)
I0423 03:40:35.591778 30295 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0423 03:42:16.971366 30295 solver.cpp:228] Iteration 14200, loss = 2.86281
I0423 03:42:16.971524 30295 solver.cpp:244]     Train net output #0: loss = 0.949356 (* 1 = 0.949356 loss)
I0423 03:42:16.971532 30295 solver.cpp:244]     Train net output #1: loss = 0.552985 (* 1 = 0.552985 loss)
I0423 03:42:16.971536 30295 solver.cpp:244]     Train net output #2: loss = 0.872393 (* 1 = 0.872393 loss)
I0423 03:42:16.971541 30295 solver.cpp:244]     Train net output #3: loss = 0.488072 (* 1 = 0.488072 loss)
I0423 03:42:16.971546 30295 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0423 03:43:56.604320 30295 solver.cpp:228] Iteration 14300, loss = 3.03951
I0423 03:43:56.604460 30295 solver.cpp:244]     Train net output #0: loss = 0.959065 (* 1 = 0.959065 loss)
I0423 03:43:56.604467 30295 solver.cpp:244]     Train net output #1: loss = 0.580222 (* 1 = 0.580222 loss)
I0423 03:43:56.604472 30295 solver.cpp:244]     Train net output #2: loss = 0.912139 (* 1 = 0.912139 loss)
I0423 03:43:56.604476 30295 solver.cpp:244]     Train net output #3: loss = 0.588085 (* 1 = 0.588085 loss)
I0423 03:43:56.604481 30295 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0423 03:45:37.923889 30295 solver.cpp:228] Iteration 14400, loss = 3.01661
I0423 03:45:37.924038 30295 solver.cpp:244]     Train net output #0: loss = 0.963656 (* 1 = 0.963656 loss)
I0423 03:45:37.924046 30295 solver.cpp:244]     Train net output #1: loss = 0.578861 (* 1 = 0.578861 loss)
I0423 03:45:37.924051 30295 solver.cpp:244]     Train net output #2: loss = 0.912856 (* 1 = 0.912856 loss)
I0423 03:45:37.924055 30295 solver.cpp:244]     Train net output #3: loss = 0.561234 (* 1 = 0.561234 loss)
I0423 03:45:37.924060 30295 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0423 03:47:19.260540 30295 solver.cpp:228] Iteration 14500, loss = 2.70584
I0423 03:47:19.260735 30295 solver.cpp:244]     Train net output #0: loss = 0.985515 (* 1 = 0.985515 loss)
I0423 03:47:19.260747 30295 solver.cpp:244]     Train net output #1: loss = 0.628568 (* 1 = 0.628568 loss)
I0423 03:47:19.260752 30295 solver.cpp:244]     Train net output #2: loss = 0.533267 (* 1 = 0.533267 loss)
I0423 03:47:19.260759 30295 solver.cpp:244]     Train net output #3: loss = 0.558487 (* 1 = 0.558487 loss)
I0423 03:47:19.260767 30295 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0423 03:48:59.037333 30295 solver.cpp:228] Iteration 14600, loss = 2.80575
I0423 03:48:59.037497 30295 solver.cpp:244]     Train net output #0: loss = 0.982384 (* 1 = 0.982384 loss)
I0423 03:48:59.037504 30295 solver.cpp:244]     Train net output #1: loss = 0.546826 (* 1 = 0.546826 loss)
I0423 03:48:59.037509 30295 solver.cpp:244]     Train net output #2: loss = 0.824567 (* 1 = 0.824567 loss)
I0423 03:48:59.037514 30295 solver.cpp:244]     Train net output #3: loss = 0.451976 (* 1 = 0.451976 loss)
I0423 03:48:59.037519 30295 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0423 03:50:40.211256 30295 solver.cpp:228] Iteration 14700, loss = 2.97702
I0423 03:50:40.211413 30295 solver.cpp:244]     Train net output #0: loss = 0.985896 (* 1 = 0.985896 loss)
I0423 03:50:40.211422 30295 solver.cpp:244]     Train net output #1: loss = 0.616354 (* 1 = 0.616354 loss)
I0423 03:50:40.211426 30295 solver.cpp:244]     Train net output #2: loss = 0.756457 (* 1 = 0.756457 loss)
I0423 03:50:40.211431 30295 solver.cpp:244]     Train net output #3: loss = 0.618314 (* 1 = 0.618314 loss)
I0423 03:50:40.211436 30295 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0423 03:52:21.461895 30295 solver.cpp:228] Iteration 14800, loss = 2.76995
I0423 03:52:21.462047 30295 solver.cpp:244]     Train net output #0: loss = 0.984362 (* 1 = 0.984362 loss)
I0423 03:52:21.462054 30295 solver.cpp:244]     Train net output #1: loss = 0.509427 (* 1 = 0.509427 loss)
I0423 03:52:21.462059 30295 solver.cpp:244]     Train net output #2: loss = 0.826175 (* 1 = 0.826175 loss)
I0423 03:52:21.462064 30295 solver.cpp:244]     Train net output #3: loss = 0.449981 (* 1 = 0.449981 loss)
I0423 03:52:21.462069 30295 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0423 03:54:02.706158 30295 solver.cpp:228] Iteration 14900, loss = 2.55378
I0423 03:54:02.706326 30295 solver.cpp:244]     Train net output #0: loss = 0.982285 (* 1 = 0.982285 loss)
I0423 03:54:02.706336 30295 solver.cpp:244]     Train net output #1: loss = 0.377682 (* 1 = 0.377682 loss)
I0423 03:54:02.706339 30295 solver.cpp:244]     Train net output #2: loss = 0.748117 (* 1 = 0.748117 loss)
I0423 03:54:02.706344 30295 solver.cpp:244]     Train net output #3: loss = 0.445692 (* 1 = 0.445692 loss)
I0423 03:54:02.706348 30295 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0423 03:55:42.707147 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_15000.caffemodel
I0423 03:55:57.069006 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_15000.solverstate
I0423 03:55:57.259771 30295 solver.cpp:337] Iteration 15000, Testing net (#0)
I0423 03:55:57.259812 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 03:55:57.259816 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 03:55:57.259819 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 03:55:57.259834 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 03:55:57.259836 30295 net.cpp:693] Ignoring source layer visualize
I0423 03:55:57.259840 30295 net.cpp:693] Ignoring source layer fake
I0423 03:59:33.975100 30295 solver.cpp:404]     Test net output #0: loss = 0.955896 (* 1 = 0.955896 loss)
I0423 03:59:33.975244 30295 solver.cpp:404]     Test net output #1: loss = 0.406329 (* 1 = 0.406329 loss)
I0423 03:59:33.975250 30295 solver.cpp:404]     Test net output #2: loss = 0.786548 (* 1 = 0.786548 loss)
I0423 03:59:33.975255 30295 solver.cpp:404]     Test net output #3: loss = 0.501945 (* 1 = 0.501945 loss)
I0423 03:59:34.643606 30295 solver.cpp:228] Iteration 15000, loss = 2.64115
I0423 03:59:34.643635 30295 solver.cpp:244]     Train net output #0: loss = 0.947996 (* 1 = 0.947996 loss)
I0423 03:59:34.643640 30295 solver.cpp:244]     Train net output #1: loss = 0.365487 (* 1 = 0.365487 loss)
I0423 03:59:34.643645 30295 solver.cpp:244]     Train net output #2: loss = 0.855352 (* 1 = 0.855352 loss)
I0423 03:59:34.643648 30295 solver.cpp:244]     Train net output #3: loss = 0.472318 (* 1 = 0.472318 loss)
I0423 03:59:34.643653 30295 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0423 04:01:16.017828 30295 solver.cpp:228] Iteration 15100, loss = 2.68011
I0423 04:01:16.017999 30295 solver.cpp:244]     Train net output #0: loss = 0.959893 (* 1 = 0.959893 loss)
I0423 04:01:16.018007 30295 solver.cpp:244]     Train net output #1: loss = 0.373299 (* 1 = 0.373299 loss)
I0423 04:01:16.018013 30295 solver.cpp:244]     Train net output #2: loss = 0.749518 (* 1 = 0.749518 loss)
I0423 04:01:16.018016 30295 solver.cpp:244]     Train net output #3: loss = 0.597402 (* 1 = 0.597402 loss)
I0423 04:01:16.018023 30295 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0423 04:02:55.731377 30295 solver.cpp:228] Iteration 15200, loss = 2.872
I0423 04:02:55.731541 30295 solver.cpp:244]     Train net output #0: loss = 0.953884 (* 1 = 0.953884 loss)
I0423 04:02:55.731549 30295 solver.cpp:244]     Train net output #1: loss = 0.499866 (* 1 = 0.499866 loss)
I0423 04:02:55.731554 30295 solver.cpp:244]     Train net output #2: loss = 0.766089 (* 1 = 0.766089 loss)
I0423 04:02:55.731559 30295 solver.cpp:244]     Train net output #3: loss = 0.65216 (* 1 = 0.65216 loss)
I0423 04:02:55.731564 30295 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0423 04:04:37.575012 30295 solver.cpp:228] Iteration 15300, loss = 2.69894
I0423 04:04:37.575189 30295 solver.cpp:244]     Train net output #0: loss = 0.974897 (* 1 = 0.974897 loss)
I0423 04:04:37.575197 30295 solver.cpp:244]     Train net output #1: loss = 0.332237 (* 1 = 0.332237 loss)
I0423 04:04:37.575202 30295 solver.cpp:244]     Train net output #2: loss = 0.763097 (* 1 = 0.763097 loss)
I0423 04:04:37.575206 30295 solver.cpp:244]     Train net output #3: loss = 0.628705 (* 1 = 0.628705 loss)
I0423 04:04:37.575212 30295 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0423 04:06:19.022965 30295 solver.cpp:228] Iteration 15400, loss = 1.42084
I0423 04:06:19.023108 30295 solver.cpp:244]     Train net output #0: loss = 0.977325 (* 1 = 0.977325 loss)
I0423 04:06:19.023115 30295 solver.cpp:244]     Train net output #1: loss = 0.0403727 (* 1 = 0.0403727 loss)
I0423 04:06:19.023128 30295 solver.cpp:244]     Train net output #2: loss = 0.363754 (* 1 = 0.363754 loss)
I0423 04:06:19.023133 30295 solver.cpp:244]     Train net output #3: loss = 0.0393913 (* 1 = 0.0393913 loss)
I0423 04:06:19.023136 30295 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0423 04:08:00.595536 30295 solver.cpp:228] Iteration 15500, loss = 2.92787
I0423 04:08:00.595715 30295 solver.cpp:244]     Train net output #0: loss = 0.967244 (* 1 = 0.967244 loss)
I0423 04:08:00.595723 30295 solver.cpp:244]     Train net output #1: loss = 0.581326 (* 1 = 0.581326 loss)
I0423 04:08:00.595728 30295 solver.cpp:244]     Train net output #2: loss = 0.849413 (* 1 = 0.849413 loss)
I0423 04:08:00.595732 30295 solver.cpp:244]     Train net output #3: loss = 0.529891 (* 1 = 0.529891 loss)
I0423 04:08:00.595738 30295 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0423 04:09:42.073719 30295 solver.cpp:228] Iteration 15600, loss = 2.66718
I0423 04:09:42.073854 30295 solver.cpp:244]     Train net output #0: loss = 0.956245 (* 1 = 0.956245 loss)
I0423 04:09:42.073863 30295 solver.cpp:244]     Train net output #1: loss = 0.351787 (* 1 = 0.351787 loss)
I0423 04:09:42.073868 30295 solver.cpp:244]     Train net output #2: loss = 0.889832 (* 1 = 0.889832 loss)
I0423 04:09:42.073873 30295 solver.cpp:244]     Train net output #3: loss = 0.469313 (* 1 = 0.469313 loss)
I0423 04:09:42.073876 30295 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0423 04:11:21.815327 30295 solver.cpp:228] Iteration 15700, loss = 3.00757
I0423 04:11:21.815465 30295 solver.cpp:244]     Train net output #0: loss = 0.953032 (* 1 = 0.953032 loss)
I0423 04:11:21.815474 30295 solver.cpp:244]     Train net output #1: loss = 0.56573 (* 1 = 0.56573 loss)
I0423 04:11:21.815479 30295 solver.cpp:244]     Train net output #2: loss = 0.941173 (* 1 = 0.941173 loss)
I0423 04:11:21.815482 30295 solver.cpp:244]     Train net output #3: loss = 0.547631 (* 1 = 0.547631 loss)
I0423 04:11:21.815487 30295 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0423 04:13:03.467355 30295 solver.cpp:228] Iteration 15800, loss = 2.8806
I0423 04:13:03.467546 30295 solver.cpp:244]     Train net output #0: loss = 0.979215 (* 1 = 0.979215 loss)
I0423 04:13:03.467555 30295 solver.cpp:244]     Train net output #1: loss = 0.633311 (* 1 = 0.633311 loss)
I0423 04:13:03.467561 30295 solver.cpp:244]     Train net output #2: loss = 0.74892 (* 1 = 0.74892 loss)
I0423 04:13:03.467564 30295 solver.cpp:244]     Train net output #3: loss = 0.519158 (* 1 = 0.519158 loss)
I0423 04:13:03.467569 30295 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0423 04:14:44.832689 30295 solver.cpp:228] Iteration 15900, loss = 2.95144
I0423 04:14:44.832852 30295 solver.cpp:244]     Train net output #0: loss = 0.990221 (* 1 = 0.990221 loss)
I0423 04:14:44.832860 30295 solver.cpp:244]     Train net output #1: loss = 0.706006 (* 1 = 0.706006 loss)
I0423 04:14:44.832865 30295 solver.cpp:244]     Train net output #2: loss = 0.728005 (* 1 = 0.728005 loss)
I0423 04:14:44.832870 30295 solver.cpp:244]     Train net output #3: loss = 0.527205 (* 1 = 0.527205 loss)
I0423 04:14:44.832875 30295 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0423 04:16:25.263034 30295 solver.cpp:337] Iteration 16000, Testing net (#0)
I0423 04:16:25.263206 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 04:16:25.263211 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 04:16:25.263216 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 04:16:25.263232 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 04:16:25.263236 30295 net.cpp:693] Ignoring source layer visualize
I0423 04:16:25.263237 30295 net.cpp:693] Ignoring source layer fake
I0423 04:20:02.272195 30295 solver.cpp:404]     Test net output #0: loss = 0.969374 (* 1 = 0.969374 loss)
I0423 04:20:02.272310 30295 solver.cpp:404]     Test net output #1: loss = 0.521039 (* 1 = 0.521039 loss)
I0423 04:20:02.272315 30295 solver.cpp:404]     Test net output #2: loss = 0.783663 (* 1 = 0.783663 loss)
I0423 04:20:02.272320 30295 solver.cpp:404]     Test net output #3: loss = 0.550573 (* 1 = 0.550573 loss)
I0423 04:20:02.962321 30295 solver.cpp:228] Iteration 16000, loss = 2.73865
I0423 04:20:02.962362 30295 solver.cpp:244]     Train net output #0: loss = 0.978058 (* 1 = 0.978058 loss)
I0423 04:20:02.962368 30295 solver.cpp:244]     Train net output #1: loss = 0.454723 (* 1 = 0.454723 loss)
I0423 04:20:02.962386 30295 solver.cpp:244]     Train net output #2: loss = 0.909798 (* 1 = 0.909798 loss)
I0423 04:20:02.962391 30295 solver.cpp:244]     Train net output #3: loss = 0.396067 (* 1 = 0.396067 loss)
I0423 04:20:02.962395 30295 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0423 04:21:42.780211 30295 solver.cpp:228] Iteration 16100, loss = 2.75075
I0423 04:21:42.780360 30295 solver.cpp:244]     Train net output #0: loss = 0.980625 (* 1 = 0.980625 loss)
I0423 04:21:42.780369 30295 solver.cpp:244]     Train net output #1: loss = 0.543459 (* 1 = 0.543459 loss)
I0423 04:21:42.780374 30295 solver.cpp:244]     Train net output #2: loss = 0.759486 (* 1 = 0.759486 loss)
I0423 04:21:42.780377 30295 solver.cpp:244]     Train net output #3: loss = 0.467179 (* 1 = 0.467179 loss)
I0423 04:21:42.780382 30295 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0423 04:23:23.861531 30295 solver.cpp:228] Iteration 16200, loss = 2.58576
I0423 04:23:23.861675 30295 solver.cpp:244]     Train net output #0: loss = 0.910252 (* 1 = 0.910252 loss)
I0423 04:23:23.861681 30295 solver.cpp:244]     Train net output #1: loss = 0.291899 (* 1 = 0.291899 loss)
I0423 04:23:23.861686 30295 solver.cpp:244]     Train net output #2: loss = 0.870223 (* 1 = 0.870223 loss)
I0423 04:23:23.861691 30295 solver.cpp:244]     Train net output #3: loss = 0.513386 (* 1 = 0.513386 loss)
I0423 04:23:23.861696 30295 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0423 04:25:04.721483 30295 solver.cpp:228] Iteration 16300, loss = 2.89816
I0423 04:25:04.721673 30295 solver.cpp:244]     Train net output #0: loss = 0.964877 (* 1 = 0.964877 loss)
I0423 04:25:04.721680 30295 solver.cpp:244]     Train net output #1: loss = 0.536471 (* 1 = 0.536471 loss)
I0423 04:25:04.721684 30295 solver.cpp:244]     Train net output #2: loss = 0.933731 (* 1 = 0.933731 loss)
I0423 04:25:04.721689 30295 solver.cpp:244]     Train net output #3: loss = 0.463086 (* 1 = 0.463086 loss)
I0423 04:25:04.721693 30295 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0423 04:26:45.657846 30295 solver.cpp:228] Iteration 16400, loss = 3.29805
I0423 04:26:45.658030 30295 solver.cpp:244]     Train net output #0: loss = 0.952912 (* 1 = 0.952912 loss)
I0423 04:26:45.658037 30295 solver.cpp:244]     Train net output #1: loss = 0.689982 (* 1 = 0.689982 loss)
I0423 04:26:45.658042 30295 solver.cpp:244]     Train net output #2: loss = 0.96196 (* 1 = 0.96196 loss)
I0423 04:26:45.658047 30295 solver.cpp:244]     Train net output #3: loss = 0.693195 (* 1 = 0.693195 loss)
I0423 04:26:45.658052 30295 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0423 04:28:27.073751 30295 solver.cpp:228] Iteration 16500, loss = 2.58716
I0423 04:28:27.076607 30295 solver.cpp:244]     Train net output #0: loss = 0.976386 (* 1 = 0.976386 loss)
I0423 04:28:27.076614 30295 solver.cpp:244]     Train net output #1: loss = 0.53371 (* 1 = 0.53371 loss)
I0423 04:28:27.076618 30295 solver.cpp:244]     Train net output #2: loss = 0.581533 (* 1 = 0.581533 loss)
I0423 04:28:27.076622 30295 solver.cpp:244]     Train net output #3: loss = 0.49553 (* 1 = 0.49553 loss)
I0423 04:28:27.076627 30295 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0423 04:30:08.384083 30295 solver.cpp:228] Iteration 16600, loss = 1.8175
I0423 04:30:08.384238 30295 solver.cpp:244]     Train net output #0: loss = 0.973257 (* 1 = 0.973257 loss)
I0423 04:30:08.384245 30295 solver.cpp:244]     Train net output #1: loss = 0.0648469 (* 1 = 0.0648469 loss)
I0423 04:30:08.384249 30295 solver.cpp:244]     Train net output #2: loss = 0.573655 (* 1 = 0.573655 loss)
I0423 04:30:08.384254 30295 solver.cpp:244]     Train net output #3: loss = 0.205738 (* 1 = 0.205738 loss)
I0423 04:30:08.384259 30295 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0423 04:31:49.743536 30295 solver.cpp:228] Iteration 16700, loss = 3.07666
I0423 04:31:49.743702 30295 solver.cpp:244]     Train net output #0: loss = 0.974869 (* 1 = 0.974869 loss)
I0423 04:31:49.743710 30295 solver.cpp:244]     Train net output #1: loss = 0.660847 (* 1 = 0.660847 loss)
I0423 04:31:49.743715 30295 solver.cpp:244]     Train net output #2: loss = 0.821742 (* 1 = 0.821742 loss)
I0423 04:31:49.743718 30295 solver.cpp:244]     Train net output #3: loss = 0.619199 (* 1 = 0.619199 loss)
I0423 04:31:49.743723 30295 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0423 04:33:29.364584 30295 solver.cpp:228] Iteration 16800, loss = 3.16441
I0423 04:33:29.364898 30295 solver.cpp:244]     Train net output #0: loss = 0.960623 (* 1 = 0.960623 loss)
I0423 04:33:29.364907 30295 solver.cpp:244]     Train net output #1: loss = 0.66029 (* 1 = 0.66029 loss)
I0423 04:33:29.364910 30295 solver.cpp:244]     Train net output #2: loss = 0.936576 (* 1 = 0.936576 loss)
I0423 04:33:29.364915 30295 solver.cpp:244]     Train net output #3: loss = 0.606923 (* 1 = 0.606923 loss)
I0423 04:33:29.364920 30295 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0423 04:35:11.366091 30295 solver.cpp:228] Iteration 16900, loss = 3.19235
I0423 04:35:11.366266 30295 solver.cpp:244]     Train net output #0: loss = 0.963348 (* 1 = 0.963348 loss)
I0423 04:35:11.366276 30295 solver.cpp:244]     Train net output #1: loss = 0.700442 (* 1 = 0.700442 loss)
I0423 04:35:11.366281 30295 solver.cpp:244]     Train net output #2: loss = 0.896028 (* 1 = 0.896028 loss)
I0423 04:35:11.366284 30295 solver.cpp:244]     Train net output #3: loss = 0.632528 (* 1 = 0.632528 loss)
I0423 04:35:11.366289 30295 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0423 04:36:52.175432 30295 solver.cpp:337] Iteration 17000, Testing net (#0)
I0423 04:36:52.175556 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 04:36:52.175560 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 04:36:52.175565 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 04:36:52.175580 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 04:36:52.175583 30295 net.cpp:693] Ignoring source layer visualize
I0423 04:36:52.175585 30295 net.cpp:693] Ignoring source layer fake
I0423 04:40:30.959784 30295 solver.cpp:404]     Test net output #0: loss = 0.968546 (* 1 = 0.968546 loss)
I0423 04:40:30.959934 30295 solver.cpp:404]     Test net output #1: loss = 0.505444 (* 1 = 0.505444 loss)
I0423 04:40:30.959942 30295 solver.cpp:404]     Test net output #2: loss = 0.80247 (* 1 = 0.80247 loss)
I0423 04:40:30.959946 30295 solver.cpp:404]     Test net output #3: loss = 0.516046 (* 1 = 0.516046 loss)
I0423 04:40:31.619700 30295 solver.cpp:228] Iteration 17000, loss = 2.74511
I0423 04:40:31.619729 30295 solver.cpp:244]     Train net output #0: loss = 0.985432 (* 1 = 0.985432 loss)
I0423 04:40:31.619735 30295 solver.cpp:244]     Train net output #1: loss = 0.574018 (* 1 = 0.574018 loss)
I0423 04:40:31.619738 30295 solver.cpp:244]     Train net output #2: loss = 0.678525 (* 1 = 0.678525 loss)
I0423 04:40:31.619741 30295 solver.cpp:244]     Train net output #3: loss = 0.507138 (* 1 = 0.507138 loss)
I0423 04:40:31.619745 30295 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0423 04:42:11.450810 30295 solver.cpp:228] Iteration 17100, loss = 2.84888
I0423 04:42:11.450984 30295 solver.cpp:244]     Train net output #0: loss = 0.984695 (* 1 = 0.984695 loss)
I0423 04:42:11.450991 30295 solver.cpp:244]     Train net output #1: loss = 0.554182 (* 1 = 0.554182 loss)
I0423 04:42:11.450996 30295 solver.cpp:244]     Train net output #2: loss = 0.822508 (* 1 = 0.822508 loss)
I0423 04:42:11.451000 30295 solver.cpp:244]     Train net output #3: loss = 0.487498 (* 1 = 0.487498 loss)
I0423 04:42:11.451005 30295 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0423 04:43:52.637931 30295 solver.cpp:228] Iteration 17200, loss = 3.0959
I0423 04:43:52.638067 30295 solver.cpp:244]     Train net output #0: loss = 0.988132 (* 1 = 0.988132 loss)
I0423 04:43:52.638075 30295 solver.cpp:244]     Train net output #1: loss = 0.696503 (* 1 = 0.696503 loss)
I0423 04:43:52.638079 30295 solver.cpp:244]     Train net output #2: loss = 0.765171 (* 1 = 0.765171 loss)
I0423 04:43:52.638084 30295 solver.cpp:244]     Train net output #3: loss = 0.646093 (* 1 = 0.646093 loss)
I0423 04:43:52.638089 30295 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0423 04:45:34.011405 30295 solver.cpp:228] Iteration 17300, loss = 2.72
I0423 04:45:34.011548 30295 solver.cpp:244]     Train net output #0: loss = 0.982018 (* 1 = 0.982018 loss)
I0423 04:45:34.011555 30295 solver.cpp:244]     Train net output #1: loss = 0.51904 (* 1 = 0.51904 loss)
I0423 04:45:34.011561 30295 solver.cpp:244]     Train net output #2: loss = 0.788361 (* 1 = 0.788361 loss)
I0423 04:45:34.011566 30295 solver.cpp:244]     Train net output #3: loss = 0.430581 (* 1 = 0.430581 loss)
I0423 04:45:34.011571 30295 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0423 04:47:14.899634 30295 solver.cpp:228] Iteration 17400, loss = 2.80136
I0423 04:47:14.899786 30295 solver.cpp:244]     Train net output #0: loss = 0.985268 (* 1 = 0.985268 loss)
I0423 04:47:14.899794 30295 solver.cpp:244]     Train net output #1: loss = 0.422205 (* 1 = 0.422205 loss)
I0423 04:47:14.899799 30295 solver.cpp:244]     Train net output #2: loss = 0.868619 (* 1 = 0.868619 loss)
I0423 04:47:14.899803 30295 solver.cpp:244]     Train net output #3: loss = 0.525269 (* 1 = 0.525269 loss)
I0423 04:47:14.899808 30295 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0423 04:48:55.613782 30295 solver.cpp:228] Iteration 17500, loss = 2.82226
I0423 04:48:55.613930 30295 solver.cpp:244]     Train net output #0: loss = 0.976008 (* 1 = 0.976008 loss)
I0423 04:48:55.613937 30295 solver.cpp:244]     Train net output #1: loss = 0.569115 (* 1 = 0.569115 loss)
I0423 04:48:55.613943 30295 solver.cpp:244]     Train net output #2: loss = 0.886712 (* 1 = 0.886712 loss)
I0423 04:48:55.613947 30295 solver.cpp:244]     Train net output #3: loss = 0.390424 (* 1 = 0.390424 loss)
I0423 04:48:55.613951 30295 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0423 04:50:36.434833 30295 solver.cpp:228] Iteration 17600, loss = 3.16069
I0423 04:50:36.435212 30295 solver.cpp:244]     Train net output #0: loss = 0.967883 (* 1 = 0.967883 loss)
I0423 04:50:36.435220 30295 solver.cpp:244]     Train net output #1: loss = 0.660915 (* 1 = 0.660915 loss)
I0423 04:50:36.435225 30295 solver.cpp:244]     Train net output #2: loss = 0.962024 (* 1 = 0.962024 loss)
I0423 04:50:36.435230 30295 solver.cpp:244]     Train net output #3: loss = 0.56987 (* 1 = 0.56987 loss)
I0423 04:50:36.435235 30295 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0423 04:52:17.618376 30295 solver.cpp:228] Iteration 17700, loss = 2.82262
I0423 04:52:17.618538 30295 solver.cpp:244]     Train net output #0: loss = 0.968608 (* 1 = 0.968608 loss)
I0423 04:52:17.618546 30295 solver.cpp:244]     Train net output #1: loss = 0.575626 (* 1 = 0.575626 loss)
I0423 04:52:17.618551 30295 solver.cpp:244]     Train net output #2: loss = 0.768694 (* 1 = 0.768694 loss)
I0423 04:52:17.618556 30295 solver.cpp:244]     Train net output #3: loss = 0.509689 (* 1 = 0.509689 loss)
I0423 04:52:17.618561 30295 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0423 04:53:57.388981 30295 solver.cpp:228] Iteration 17800, loss = 2.80088
I0423 04:53:57.391139 30295 solver.cpp:244]     Train net output #0: loss = 0.951668 (* 1 = 0.951668 loss)
I0423 04:53:57.391146 30295 solver.cpp:244]     Train net output #1: loss = 0.556395 (* 1 = 0.556395 loss)
I0423 04:53:57.391150 30295 solver.cpp:244]     Train net output #2: loss = 0.771813 (* 1 = 0.771813 loss)
I0423 04:53:57.391155 30295 solver.cpp:244]     Train net output #3: loss = 0.521006 (* 1 = 0.521006 loss)
I0423 04:53:57.391160 30295 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0423 04:55:38.632591 30295 solver.cpp:228] Iteration 17900, loss = 1.7791
I0423 04:55:38.632735 30295 solver.cpp:244]     Train net output #0: loss = 0.971133 (* 1 = 0.971133 loss)
I0423 04:55:38.632742 30295 solver.cpp:244]     Train net output #1: loss = 0.0723488 (* 1 = 0.0723488 loss)
I0423 04:55:38.632748 30295 solver.cpp:244]     Train net output #2: loss = 0.561698 (* 1 = 0.561698 loss)
I0423 04:55:38.632752 30295 solver.cpp:244]     Train net output #3: loss = 0.173917 (* 1 = 0.173917 loss)
I0423 04:55:38.632756 30295 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0423 04:57:19.427722 30295 solver.cpp:337] Iteration 18000, Testing net (#0)
I0423 04:57:19.427855 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 04:57:19.427860 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 04:57:19.427863 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 04:57:19.427878 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 04:57:19.427882 30295 net.cpp:693] Ignoring source layer visualize
I0423 04:57:19.427884 30295 net.cpp:693] Ignoring source layer fake
I0423 05:00:57.587139 30295 solver.cpp:404]     Test net output #0: loss = 0.964768 (* 1 = 0.964768 loss)
I0423 05:00:57.587293 30295 solver.cpp:404]     Test net output #1: loss = 0.460008 (* 1 = 0.460008 loss)
I0423 05:00:57.587301 30295 solver.cpp:404]     Test net output #2: loss = 0.7851 (* 1 = 0.7851 loss)
I0423 05:00:57.587306 30295 solver.cpp:404]     Test net output #3: loss = 0.47826 (* 1 = 0.47826 loss)
I0423 05:00:58.266419 30295 solver.cpp:228] Iteration 18000, loss = 2.94812
I0423 05:00:58.266466 30295 solver.cpp:244]     Train net output #0: loss = 0.971687 (* 1 = 0.971687 loss)
I0423 05:00:58.266472 30295 solver.cpp:244]     Train net output #1: loss = 0.689782 (* 1 = 0.689782 loss)
I0423 05:00:58.266476 30295 solver.cpp:244]     Train net output #2: loss = 0.708342 (* 1 = 0.708342 loss)
I0423 05:00:58.266479 30295 solver.cpp:244]     Train net output #3: loss = 0.578304 (* 1 = 0.578304 loss)
I0423 05:00:58.266484 30295 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0423 05:02:41.014483 30295 solver.cpp:228] Iteration 18100, loss = 3.07449
I0423 05:02:41.014642 30295 solver.cpp:244]     Train net output #0: loss = 0.9728 (* 1 = 0.9728 loss)
I0423 05:02:41.014648 30295 solver.cpp:244]     Train net output #1: loss = 0.573919 (* 1 = 0.573919 loss)
I0423 05:02:41.014653 30295 solver.cpp:244]     Train net output #2: loss = 0.921828 (* 1 = 0.921828 loss)
I0423 05:02:41.014658 30295 solver.cpp:244]     Train net output #3: loss = 0.605947 (* 1 = 0.605947 loss)
I0423 05:02:41.014664 30295 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0423 05:04:20.674680 30295 solver.cpp:228] Iteration 18200, loss = 3.26919
I0423 05:04:20.674870 30295 solver.cpp:244]     Train net output #0: loss = 0.97448 (* 1 = 0.97448 loss)
I0423 05:04:20.674878 30295 solver.cpp:244]     Train net output #1: loss = 0.74975 (* 1 = 0.74975 loss)
I0423 05:04:20.674883 30295 solver.cpp:244]     Train net output #2: loss = 0.911246 (* 1 = 0.911246 loss)
I0423 05:04:20.674887 30295 solver.cpp:244]     Train net output #3: loss = 0.633717 (* 1 = 0.633717 loss)
I0423 05:04:20.674893 30295 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0423 05:06:02.888056 30295 solver.cpp:228] Iteration 18300, loss = 3.2737
I0423 05:06:02.888203 30295 solver.cpp:244]     Train net output #0: loss = 0.987722 (* 1 = 0.987722 loss)
I0423 05:06:02.888211 30295 solver.cpp:244]     Train net output #1: loss = 0.795495 (* 1 = 0.795495 loss)
I0423 05:06:02.888216 30295 solver.cpp:244]     Train net output #2: loss = 0.916478 (* 1 = 0.916478 loss)
I0423 05:06:02.888221 30295 solver.cpp:244]     Train net output #3: loss = 0.574001 (* 1 = 0.574001 loss)
I0423 05:06:02.888226 30295 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0423 05:07:45.214763 30295 solver.cpp:228] Iteration 18400, loss = 3.09841
I0423 05:07:45.214937 30295 solver.cpp:244]     Train net output #0: loss = 0.986313 (* 1 = 0.986313 loss)
I0423 05:07:45.214946 30295 solver.cpp:244]     Train net output #1: loss = 0.666833 (* 1 = 0.666833 loss)
I0423 05:07:45.214951 30295 solver.cpp:244]     Train net output #2: loss = 0.759571 (* 1 = 0.759571 loss)
I0423 05:07:45.214956 30295 solver.cpp:244]     Train net output #3: loss = 0.685697 (* 1 = 0.685697 loss)
I0423 05:07:45.214959 30295 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0423 05:09:27.188170 30295 solver.cpp:228] Iteration 18500, loss = 2.99505
I0423 05:09:27.188325 30295 solver.cpp:244]     Train net output #0: loss = 0.988245 (* 1 = 0.988245 loss)
I0423 05:09:27.188333 30295 solver.cpp:244]     Train net output #1: loss = 0.530295 (* 1 = 0.530295 loss)
I0423 05:09:27.188338 30295 solver.cpp:244]     Train net output #2: loss = 0.955002 (* 1 = 0.955002 loss)
I0423 05:09:27.188343 30295 solver.cpp:244]     Train net output #3: loss = 0.521505 (* 1 = 0.521505 loss)
I0423 05:09:27.188349 30295 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0423 05:11:06.603605 30295 solver.cpp:228] Iteration 18600, loss = 2.9878
I0423 05:11:06.603751 30295 solver.cpp:244]     Train net output #0: loss = 0.989642 (* 1 = 0.989642 loss)
I0423 05:11:06.603760 30295 solver.cpp:244]     Train net output #1: loss = 0.604528 (* 1 = 0.604528 loss)
I0423 05:11:06.603765 30295 solver.cpp:244]     Train net output #2: loss = 0.760193 (* 1 = 0.760193 loss)
I0423 05:11:06.603768 30295 solver.cpp:244]     Train net output #3: loss = 0.633433 (* 1 = 0.633433 loss)
I0423 05:11:06.603773 30295 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0423 05:12:47.873332 30295 solver.cpp:228] Iteration 18700, loss = 2.30116
I0423 05:12:47.873509 30295 solver.cpp:244]     Train net output #0: loss = 0.975023 (* 1 = 0.975023 loss)
I0423 05:12:47.873517 30295 solver.cpp:244]     Train net output #1: loss = 0.356649 (* 1 = 0.356649 loss)
I0423 05:12:47.873522 30295 solver.cpp:244]     Train net output #2: loss = 0.506605 (* 1 = 0.506605 loss)
I0423 05:12:47.873527 30295 solver.cpp:244]     Train net output #3: loss = 0.462881 (* 1 = 0.462881 loss)
I0423 05:12:47.873531 30295 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0423 05:14:28.726337 30295 solver.cpp:228] Iteration 18800, loss = 3.07969
I0423 05:14:28.726508 30295 solver.cpp:244]     Train net output #0: loss = 0.958233 (* 1 = 0.958233 loss)
I0423 05:14:28.726516 30295 solver.cpp:244]     Train net output #1: loss = 0.567875 (* 1 = 0.567875 loss)
I0423 05:14:28.726521 30295 solver.cpp:244]     Train net output #2: loss = 0.931929 (* 1 = 0.931929 loss)
I0423 05:14:28.726526 30295 solver.cpp:244]     Train net output #3: loss = 0.62165 (* 1 = 0.62165 loss)
I0423 05:14:28.726531 30295 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0423 05:16:09.810791 30295 solver.cpp:228] Iteration 18900, loss = 3.27756
I0423 05:16:09.810981 30295 solver.cpp:244]     Train net output #0: loss = 0.953892 (* 1 = 0.953892 loss)
I0423 05:16:09.810988 30295 solver.cpp:244]     Train net output #1: loss = 0.705667 (* 1 = 0.705667 loss)
I0423 05:16:09.810993 30295 solver.cpp:244]     Train net output #2: loss = 0.945991 (* 1 = 0.945991 loss)
I0423 05:16:09.810998 30295 solver.cpp:244]     Train net output #3: loss = 0.672013 (* 1 = 0.672013 loss)
I0423 05:16:09.811003 30295 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0423 05:17:49.903091 30295 solver.cpp:337] Iteration 19000, Testing net (#0)
I0423 05:17:49.903235 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 05:17:49.903239 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 05:17:49.903244 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 05:17:49.903257 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 05:17:49.903261 30295 net.cpp:693] Ignoring source layer visualize
I0423 05:17:49.903264 30295 net.cpp:693] Ignoring source layer fake
I0423 05:21:27.685539 30295 solver.cpp:404]     Test net output #0: loss = 0.964713 (* 1 = 0.964713 loss)
I0423 05:21:27.685674 30295 solver.cpp:404]     Test net output #1: loss = 0.458364 (* 1 = 0.458364 loss)
I0423 05:21:27.685680 30295 solver.cpp:404]     Test net output #2: loss = 0.805492 (* 1 = 0.805492 loss)
I0423 05:21:27.685686 30295 solver.cpp:404]     Test net output #3: loss = 0.539412 (* 1 = 0.539412 loss)
I0423 05:21:28.345707 30295 solver.cpp:228] Iteration 19000, loss = 3.24267
I0423 05:21:28.345752 30295 solver.cpp:244]     Train net output #0: loss = 0.966837 (* 1 = 0.966837 loss)
I0423 05:21:28.345758 30295 solver.cpp:244]     Train net output #1: loss = 0.652053 (* 1 = 0.652053 loss)
I0423 05:21:28.345777 30295 solver.cpp:244]     Train net output #2: loss = 0.965563 (* 1 = 0.965563 loss)
I0423 05:21:28.345782 30295 solver.cpp:244]     Train net output #3: loss = 0.658216 (* 1 = 0.658216 loss)
I0423 05:21:28.345801 30295 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0423 05:23:09.575183 30295 solver.cpp:228] Iteration 19100, loss = 1.5836
I0423 05:23:09.575330 30295 solver.cpp:244]     Train net output #0: loss = 0.969016 (* 1 = 0.969016 loss)
I0423 05:23:09.575338 30295 solver.cpp:244]     Train net output #1: loss = 0.0710355 (* 1 = 0.0710355 loss)
I0423 05:23:09.575343 30295 solver.cpp:244]     Train net output #2: loss = 0.377739 (* 1 = 0.377739 loss)
I0423 05:23:09.575347 30295 solver.cpp:244]     Train net output #3: loss = 0.165809 (* 1 = 0.165809 loss)
I0423 05:23:09.575353 30295 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0423 05:24:51.082532 30295 solver.cpp:228] Iteration 19200, loss = 3.033
I0423 05:24:51.082695 30295 solver.cpp:244]     Train net output #0: loss = 0.960611 (* 1 = 0.960611 loss)
I0423 05:24:51.082702 30295 solver.cpp:244]     Train net output #1: loss = 0.605858 (* 1 = 0.605858 loss)
I0423 05:24:51.082707 30295 solver.cpp:244]     Train net output #2: loss = 0.84084 (* 1 = 0.84084 loss)
I0423 05:24:51.082711 30295 solver.cpp:244]     Train net output #3: loss = 0.62569 (* 1 = 0.62569 loss)
I0423 05:24:51.082716 30295 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0423 05:26:30.664307 30295 solver.cpp:228] Iteration 19300, loss = 3.15884
I0423 05:26:30.664481 30295 solver.cpp:244]     Train net output #0: loss = 0.962715 (* 1 = 0.962715 loss)
I0423 05:26:30.664489 30295 solver.cpp:244]     Train net output #1: loss = 0.674853 (* 1 = 0.674853 loss)
I0423 05:26:30.664494 30295 solver.cpp:244]     Train net output #2: loss = 0.92835 (* 1 = 0.92835 loss)
I0423 05:26:30.664499 30295 solver.cpp:244]     Train net output #3: loss = 0.592918 (* 1 = 0.592918 loss)
I0423 05:26:30.664505 30295 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0423 05:28:12.692236 30295 solver.cpp:228] Iteration 19400, loss = 3.24291
I0423 05:28:12.692425 30295 solver.cpp:244]     Train net output #0: loss = 0.977203 (* 1 = 0.977203 loss)
I0423 05:28:12.692433 30295 solver.cpp:244]     Train net output #1: loss = 0.716836 (* 1 = 0.716836 loss)
I0423 05:28:12.692438 30295 solver.cpp:244]     Train net output #2: loss = 0.92365 (* 1 = 0.92365 loss)
I0423 05:28:12.692443 30295 solver.cpp:244]     Train net output #3: loss = 0.625221 (* 1 = 0.625221 loss)
I0423 05:28:12.692448 30295 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0423 05:29:54.224480 30295 solver.cpp:228] Iteration 19500, loss = 3.06987
I0423 05:29:54.224633 30295 solver.cpp:244]     Train net output #0: loss = 0.984004 (* 1 = 0.984004 loss)
I0423 05:29:54.224642 30295 solver.cpp:244]     Train net output #1: loss = 0.600402 (* 1 = 0.600402 loss)
I0423 05:29:54.224647 30295 solver.cpp:244]     Train net output #2: loss = 0.928406 (* 1 = 0.928406 loss)
I0423 05:29:54.224650 30295 solver.cpp:244]     Train net output #3: loss = 0.557063 (* 1 = 0.557063 loss)
I0423 05:29:54.224656 30295 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0423 05:31:33.956696 30295 solver.cpp:228] Iteration 19600, loss = 3.1688
I0423 05:31:33.956848 30295 solver.cpp:244]     Train net output #0: loss = 0.985481 (* 1 = 0.985481 loss)
I0423 05:31:33.956856 30295 solver.cpp:244]     Train net output #1: loss = 0.733729 (* 1 = 0.733729 loss)
I0423 05:31:33.956862 30295 solver.cpp:244]     Train net output #2: loss = 0.871932 (* 1 = 0.871932 loss)
I0423 05:31:33.956866 30295 solver.cpp:244]     Train net output #3: loss = 0.577656 (* 1 = 0.577656 loss)
I0423 05:31:33.956871 30295 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0423 05:33:15.350927 30295 solver.cpp:228] Iteration 19700, loss = 2.99989
I0423 05:33:15.351094 30295 solver.cpp:244]     Train net output #0: loss = 0.99149 (* 1 = 0.99149 loss)
I0423 05:33:15.351102 30295 solver.cpp:244]     Train net output #1: loss = 0.726322 (* 1 = 0.726322 loss)
I0423 05:33:15.351106 30295 solver.cpp:244]     Train net output #2: loss = 0.772841 (* 1 = 0.772841 loss)
I0423 05:33:15.351110 30295 solver.cpp:244]     Train net output #3: loss = 0.509233 (* 1 = 0.509233 loss)
I0423 05:33:15.351116 30295 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0423 05:34:56.703580 30295 solver.cpp:228] Iteration 19800, loss = 2.42005
I0423 05:34:56.703725 30295 solver.cpp:244]     Train net output #0: loss = 0.982237 (* 1 = 0.982237 loss)
I0423 05:34:56.703733 30295 solver.cpp:244]     Train net output #1: loss = 0.436537 (* 1 = 0.436537 loss)
I0423 05:34:56.703739 30295 solver.cpp:244]     Train net output #2: loss = 0.78379 (* 1 = 0.78379 loss)
I0423 05:34:56.703743 30295 solver.cpp:244]     Train net output #3: loss = 0.217484 (* 1 = 0.217484 loss)
I0423 05:34:56.703748 30295 sgd_solver.cpp:106] Iteration 19800, lr = 0.0001
I0423 05:36:37.702909 30295 solver.cpp:228] Iteration 19900, loss = 2.82525
I0423 05:36:37.703089 30295 solver.cpp:244]     Train net output #0: loss = 0.985154 (* 1 = 0.985154 loss)
I0423 05:36:37.703097 30295 solver.cpp:244]     Train net output #1: loss = 0.5435 (* 1 = 0.5435 loss)
I0423 05:36:37.703102 30295 solver.cpp:244]     Train net output #2: loss = 0.735007 (* 1 = 0.735007 loss)
I0423 05:36:37.703106 30295 solver.cpp:244]     Train net output #3: loss = 0.561591 (* 1 = 0.561591 loss)
I0423 05:36:37.703111 30295 sgd_solver.cpp:106] Iteration 19900, lr = 0.0001
I0423 05:38:17.385246 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_20000.caffemodel
I0423 05:38:31.902247 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_20000.solverstate
I0423 05:38:32.097128 30295 solver.cpp:337] Iteration 20000, Testing net (#0)
I0423 05:38:32.097172 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 05:38:32.097174 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 05:38:32.097177 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 05:38:32.097193 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 05:38:32.097195 30295 net.cpp:693] Ignoring source layer visualize
I0423 05:38:32.097198 30295 net.cpp:693] Ignoring source layer fake
I0423 05:42:08.775059 30295 solver.cpp:404]     Test net output #0: loss = 0.967973 (* 1 = 0.967973 loss)
I0423 05:42:08.775264 30295 solver.cpp:404]     Test net output #1: loss = 0.478223 (* 1 = 0.478223 loss)
I0423 05:42:08.775272 30295 solver.cpp:404]     Test net output #2: loss = 0.796193 (* 1 = 0.796193 loss)
I0423 05:42:08.775277 30295 solver.cpp:404]     Test net output #3: loss = 0.539072 (* 1 = 0.539072 loss)
I0423 05:42:09.462354 30295 solver.cpp:228] Iteration 20000, loss = 3.11383
I0423 05:42:09.462399 30295 solver.cpp:244]     Train net output #0: loss = 0.974701 (* 1 = 0.974701 loss)
I0423 05:42:09.462406 30295 solver.cpp:244]     Train net output #1: loss = 0.664991 (* 1 = 0.664991 loss)
I0423 05:42:09.462410 30295 solver.cpp:244]     Train net output #2: loss = 0.925094 (* 1 = 0.925094 loss)
I0423 05:42:09.462414 30295 solver.cpp:244]     Train net output #3: loss = 0.549045 (* 1 = 0.549045 loss)
I0423 05:42:09.462419 30295 sgd_solver.cpp:106] Iteration 20000, lr = 3e-05
I0423 05:43:50.858758 30295 solver.cpp:228] Iteration 20100, loss = 2.92727
I0423 05:43:50.858918 30295 solver.cpp:244]     Train net output #0: loss = 0.976014 (* 1 = 0.976014 loss)
I0423 05:43:50.858925 30295 solver.cpp:244]     Train net output #1: loss = 0.634643 (* 1 = 0.634643 loss)
I0423 05:43:50.858930 30295 solver.cpp:244]     Train net output #2: loss = 0.70501 (* 1 = 0.70501 loss)
I0423 05:43:50.858935 30295 solver.cpp:244]     Train net output #3: loss = 0.6116 (* 1 = 0.6116 loss)
I0423 05:43:50.858940 30295 sgd_solver.cpp:106] Iteration 20100, lr = 3e-05
I0423 05:45:32.466727 30295 solver.cpp:228] Iteration 20200, loss = 2.70832
I0423 05:45:32.467293 30295 solver.cpp:244]     Train net output #0: loss = 0.981098 (* 1 = 0.981098 loss)
I0423 05:45:32.467303 30295 solver.cpp:244]     Train net output #1: loss = 0.681177 (* 1 = 0.681177 loss)
I0423 05:45:32.467308 30295 solver.cpp:244]     Train net output #2: loss = 0.542597 (* 1 = 0.542597 loss)
I0423 05:45:32.467311 30295 solver.cpp:244]     Train net output #3: loss = 0.503445 (* 1 = 0.503445 loss)
I0423 05:45:32.467315 30295 sgd_solver.cpp:106] Iteration 20200, lr = 3e-05
I0423 05:47:12.147120 30295 solver.cpp:228] Iteration 20300, loss = 3.06776
I0423 05:47:12.147286 30295 solver.cpp:244]     Train net output #0: loss = 0.95503 (* 1 = 0.95503 loss)
I0423 05:47:12.147294 30295 solver.cpp:244]     Train net output #1: loss = 0.687047 (* 1 = 0.687047 loss)
I0423 05:47:12.147299 30295 solver.cpp:244]     Train net output #2: loss = 0.779584 (* 1 = 0.779584 loss)
I0423 05:47:12.147305 30295 solver.cpp:244]     Train net output #3: loss = 0.646102 (* 1 = 0.646102 loss)
I0423 05:47:12.147310 30295 sgd_solver.cpp:106] Iteration 20300, lr = 3e-05
I0423 05:48:53.780786 30295 solver.cpp:228] Iteration 20400, loss = 1.99937
I0423 05:48:53.780936 30295 solver.cpp:244]     Train net output #0: loss = 0.963849 (* 1 = 0.963849 loss)
I0423 05:48:53.780946 30295 solver.cpp:244]     Train net output #1: loss = 0.166657 (* 1 = 0.166657 loss)
I0423 05:48:53.780951 30295 solver.cpp:244]     Train net output #2: loss = 0.576531 (* 1 = 0.576531 loss)
I0423 05:48:53.780954 30295 solver.cpp:244]     Train net output #3: loss = 0.292328 (* 1 = 0.292328 loss)
I0423 05:48:53.780959 30295 sgd_solver.cpp:106] Iteration 20400, lr = 3e-05
I0423 05:50:34.957926 30295 solver.cpp:228] Iteration 20500, loss = 3.01322
I0423 05:50:34.958096 30295 solver.cpp:244]     Train net output #0: loss = 0.960369 (* 1 = 0.960369 loss)
I0423 05:50:34.958104 30295 solver.cpp:244]     Train net output #1: loss = 0.667059 (* 1 = 0.667059 loss)
I0423 05:50:34.958109 30295 solver.cpp:244]     Train net output #2: loss = 0.716964 (* 1 = 0.716964 loss)
I0423 05:50:34.958114 30295 solver.cpp:244]     Train net output #3: loss = 0.668831 (* 1 = 0.668831 loss)
I0423 05:50:34.958118 30295 sgd_solver.cpp:106] Iteration 20500, lr = 3e-05
I0423 05:52:16.652021 30295 solver.cpp:228] Iteration 20600, loss = 3.23398
I0423 05:52:16.652204 30295 solver.cpp:244]     Train net output #0: loss = 0.977618 (* 1 = 0.977618 loss)
I0423 05:52:16.652214 30295 solver.cpp:244]     Train net output #1: loss = 0.722651 (* 1 = 0.722651 loss)
I0423 05:52:16.652217 30295 solver.cpp:244]     Train net output #2: loss = 0.842258 (* 1 = 0.842258 loss)
I0423 05:52:16.652222 30295 solver.cpp:244]     Train net output #3: loss = 0.69145 (* 1 = 0.69145 loss)
I0423 05:52:16.652226 30295 sgd_solver.cpp:106] Iteration 20600, lr = 3e-05
I0423 05:53:56.490419 30295 solver.cpp:228] Iteration 20700, loss = 3.24904
I0423 05:53:56.490581 30295 solver.cpp:244]     Train net output #0: loss = 0.977779 (* 1 = 0.977779 loss)
I0423 05:53:56.490587 30295 solver.cpp:244]     Train net output #1: loss = 0.69758 (* 1 = 0.69758 loss)
I0423 05:53:56.490592 30295 solver.cpp:244]     Train net output #2: loss = 0.920197 (* 1 = 0.920197 loss)
I0423 05:53:56.490597 30295 solver.cpp:244]     Train net output #3: loss = 0.653483 (* 1 = 0.653483 loss)
I0423 05:53:56.490602 30295 sgd_solver.cpp:106] Iteration 20700, lr = 3e-05
I0423 05:55:38.408548 30295 solver.cpp:228] Iteration 20800, loss = 3.18229
I0423 05:55:38.408720 30295 solver.cpp:244]     Train net output #0: loss = 0.992376 (* 1 = 0.992376 loss)
I0423 05:55:38.408730 30295 solver.cpp:244]     Train net output #1: loss = 0.787146 (* 1 = 0.787146 loss)
I0423 05:55:38.408735 30295 solver.cpp:244]     Train net output #2: loss = 0.788746 (* 1 = 0.788746 loss)
I0423 05:55:38.408738 30295 solver.cpp:244]     Train net output #3: loss = 0.614017 (* 1 = 0.614017 loss)
I0423 05:55:38.408743 30295 sgd_solver.cpp:106] Iteration 20800, lr = 3e-05
I0423 05:57:19.998347 30295 solver.cpp:228] Iteration 20900, loss = 3.18103
I0423 05:57:19.998504 30295 solver.cpp:244]     Train net output #0: loss = 0.988573 (* 1 = 0.988573 loss)
I0423 05:57:19.998512 30295 solver.cpp:244]     Train net output #1: loss = 0.769717 (* 1 = 0.769717 loss)
I0423 05:57:19.998517 30295 solver.cpp:244]     Train net output #2: loss = 0.76028 (* 1 = 0.76028 loss)
I0423 05:57:19.998522 30295 solver.cpp:244]     Train net output #3: loss = 0.662465 (* 1 = 0.662465 loss)
I0423 05:57:19.998527 30295 sgd_solver.cpp:106] Iteration 20900, lr = 3e-05
I0423 05:59:00.284759 30295 solver.cpp:337] Iteration 21000, Testing net (#0)
I0423 05:59:00.284927 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 05:59:00.284932 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 05:59:00.284936 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 05:59:00.284952 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 05:59:00.284955 30295 net.cpp:693] Ignoring source layer visualize
I0423 05:59:00.284958 30295 net.cpp:693] Ignoring source layer fake
I0423 06:02:37.920212 30295 solver.cpp:404]     Test net output #0: loss = 0.970319 (* 1 = 0.970319 loss)
I0423 06:02:37.920358 30295 solver.cpp:404]     Test net output #1: loss = 0.544403 (* 1 = 0.544403 loss)
I0423 06:02:37.920366 30295 solver.cpp:404]     Test net output #2: loss = 0.810477 (* 1 = 0.810477 loss)
I0423 06:02:37.920370 30295 solver.cpp:404]     Test net output #3: loss = 0.568465 (* 1 = 0.568465 loss)
I0423 06:02:38.581526 30295 solver.cpp:228] Iteration 21000, loss = 2.41655
I0423 06:02:38.581569 30295 solver.cpp:244]     Train net output #0: loss = 0.991284 (* 1 = 0.991284 loss)
I0423 06:02:38.581575 30295 solver.cpp:244]     Train net output #1: loss = 0.400084 (* 1 = 0.400084 loss)
I0423 06:02:38.581580 30295 solver.cpp:244]     Train net output #2: loss = 0.644282 (* 1 = 0.644282 loss)
I0423 06:02:38.581585 30295 solver.cpp:244]     Train net output #3: loss = 0.380897 (* 1 = 0.380897 loss)
I0423 06:02:38.581589 30295 sgd_solver.cpp:106] Iteration 21000, lr = 3e-05
I0423 06:04:18.098423 30295 solver.cpp:228] Iteration 21100, loss = 2.45323
I0423 06:04:18.098567 30295 solver.cpp:244]     Train net output #0: loss = 0.981833 (* 1 = 0.981833 loss)
I0423 06:04:18.098573 30295 solver.cpp:244]     Train net output #1: loss = 0.441866 (* 1 = 0.441866 loss)
I0423 06:04:18.098578 30295 solver.cpp:244]     Train net output #2: loss = 0.648706 (* 1 = 0.648706 loss)
I0423 06:04:18.098583 30295 solver.cpp:244]     Train net output #3: loss = 0.380823 (* 1 = 0.380823 loss)
I0423 06:04:18.098588 30295 sgd_solver.cpp:106] Iteration 21100, lr = 3e-05
I0423 06:05:59.170949 30295 solver.cpp:228] Iteration 21200, loss = 2.46953
I0423 06:05:59.171115 30295 solver.cpp:244]     Train net output #0: loss = 0.988778 (* 1 = 0.988778 loss)
I0423 06:05:59.171123 30295 solver.cpp:244]     Train net output #1: loss = 0.40956 (* 1 = 0.40956 loss)
I0423 06:05:59.171128 30295 solver.cpp:244]     Train net output #2: loss = 0.524017 (* 1 = 0.524017 loss)
I0423 06:05:59.171133 30295 solver.cpp:244]     Train net output #3: loss = 0.547173 (* 1 = 0.547173 loss)
I0423 06:05:59.171139 30295 sgd_solver.cpp:106] Iteration 21200, lr = 3e-05
I0423 06:07:39.665411 30295 solver.cpp:228] Iteration 21300, loss = 2.70072
I0423 06:07:39.665566 30295 solver.cpp:244]     Train net output #0: loss = 0.974421 (* 1 = 0.974421 loss)
I0423 06:07:39.665575 30295 solver.cpp:244]     Train net output #1: loss = 0.543566 (* 1 = 0.543566 loss)
I0423 06:07:39.665578 30295 solver.cpp:244]     Train net output #2: loss = 0.761999 (* 1 = 0.761999 loss)
I0423 06:07:39.665583 30295 solver.cpp:244]     Train net output #3: loss = 0.420733 (* 1 = 0.420733 loss)
I0423 06:07:39.665588 30295 sgd_solver.cpp:106] Iteration 21300, lr = 3e-05
I0423 06:09:20.515512 30295 solver.cpp:228] Iteration 21400, loss = 3.09374
I0423 06:09:20.515672 30295 solver.cpp:244]     Train net output #0: loss = 0.965912 (* 1 = 0.965912 loss)
I0423 06:09:20.515681 30295 solver.cpp:244]     Train net output #1: loss = 0.63663 (* 1 = 0.63663 loss)
I0423 06:09:20.515686 30295 solver.cpp:244]     Train net output #2: loss = 0.910668 (* 1 = 0.910668 loss)
I0423 06:09:20.515691 30295 solver.cpp:244]     Train net output #3: loss = 0.580527 (* 1 = 0.580527 loss)
I0423 06:09:20.515694 30295 sgd_solver.cpp:106] Iteration 21400, lr = 3e-05
I0423 06:11:02.109652 30295 solver.cpp:228] Iteration 21500, loss = 2.37534
I0423 06:11:02.109844 30295 solver.cpp:244]     Train net output #0: loss = 0.974889 (* 1 = 0.974889 loss)
I0423 06:11:02.109851 30295 solver.cpp:244]     Train net output #1: loss = 0.382273 (* 1 = 0.382273 loss)
I0423 06:11:02.109856 30295 solver.cpp:244]     Train net output #2: loss = 0.582221 (* 1 = 0.582221 loss)
I0423 06:11:02.109861 30295 solver.cpp:244]     Train net output #3: loss = 0.435962 (* 1 = 0.435962 loss)
I0423 06:11:02.109866 30295 sgd_solver.cpp:106] Iteration 21500, lr = 3e-05
I0423 06:12:43.185452 30295 solver.cpp:228] Iteration 21600, loss = 2.23923
I0423 06:12:43.185606 30295 solver.cpp:244]     Train net output #0: loss = 0.959961 (* 1 = 0.959961 loss)
I0423 06:12:43.185619 30295 solver.cpp:244]     Train net output #1: loss = 0.127343 (* 1 = 0.127343 loss)
I0423 06:12:43.185626 30295 solver.cpp:244]     Train net output #2: loss = 0.782149 (* 1 = 0.782149 loss)
I0423 06:12:43.185629 30295 solver.cpp:244]     Train net output #3: loss = 0.369774 (* 1 = 0.369774 loss)
I0423 06:12:43.185634 30295 sgd_solver.cpp:106] Iteration 21600, lr = 3e-05
I0423 06:14:24.576936 30295 solver.cpp:228] Iteration 21700, loss = 3.11129
I0423 06:14:24.577080 30295 solver.cpp:244]     Train net output #0: loss = 0.965657 (* 1 = 0.965657 loss)
I0423 06:14:24.577086 30295 solver.cpp:244]     Train net output #1: loss = 0.699363 (* 1 = 0.699363 loss)
I0423 06:14:24.577091 30295 solver.cpp:244]     Train net output #2: loss = 0.881384 (* 1 = 0.881384 loss)
I0423 06:14:24.577096 30295 solver.cpp:244]     Train net output #3: loss = 0.564883 (* 1 = 0.564883 loss)
I0423 06:14:24.577101 30295 sgd_solver.cpp:106] Iteration 21700, lr = 3e-05
I0423 06:16:04.311398 30295 solver.cpp:228] Iteration 21800, loss = 3.21696
I0423 06:16:04.311550 30295 solver.cpp:244]     Train net output #0: loss = 0.970742 (* 1 = 0.970742 loss)
I0423 06:16:04.311558 30295 solver.cpp:244]     Train net output #1: loss = 0.703151 (* 1 = 0.703151 loss)
I0423 06:16:04.311563 30295 solver.cpp:244]     Train net output #2: loss = 0.92254 (* 1 = 0.92254 loss)
I0423 06:16:04.311568 30295 solver.cpp:244]     Train net output #3: loss = 0.62053 (* 1 = 0.62053 loss)
I0423 06:16:04.311573 30295 sgd_solver.cpp:106] Iteration 21800, lr = 3e-05
I0423 06:17:45.958478 30295 solver.cpp:228] Iteration 21900, loss = 3.08995
I0423 06:17:45.958652 30295 solver.cpp:244]     Train net output #0: loss = 0.976833 (* 1 = 0.976833 loss)
I0423 06:17:45.958660 30295 solver.cpp:244]     Train net output #1: loss = 0.743406 (* 1 = 0.743406 loss)
I0423 06:17:45.958665 30295 solver.cpp:244]     Train net output #2: loss = 0.737882 (* 1 = 0.737882 loss)
I0423 06:17:45.958669 30295 solver.cpp:244]     Train net output #3: loss = 0.631827 (* 1 = 0.631827 loss)
I0423 06:17:45.958674 30295 sgd_solver.cpp:106] Iteration 21900, lr = 3e-05
I0423 06:19:26.190299 30295 solver.cpp:337] Iteration 22000, Testing net (#0)
I0423 06:19:26.190428 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 06:19:26.190431 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 06:19:26.190436 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 06:19:26.190451 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 06:19:26.190454 30295 net.cpp:693] Ignoring source layer visualize
I0423 06:19:26.190456 30295 net.cpp:693] Ignoring source layer fake
I0423 06:23:03.351073 30295 solver.cpp:404]     Test net output #0: loss = 0.967294 (* 1 = 0.967294 loss)
I0423 06:23:03.351215 30295 solver.cpp:404]     Test net output #1: loss = 0.484544 (* 1 = 0.484544 loss)
I0423 06:23:03.351222 30295 solver.cpp:404]     Test net output #2: loss = 0.803429 (* 1 = 0.803429 loss)
I0423 06:23:03.351227 30295 solver.cpp:404]     Test net output #3: loss = 0.502429 (* 1 = 0.502429 loss)
I0423 06:23:04.014081 30295 solver.cpp:228] Iteration 22000, loss = 3.07865
I0423 06:23:04.014124 30295 solver.cpp:244]     Train net output #0: loss = 0.987126 (* 1 = 0.987126 loss)
I0423 06:23:04.014129 30295 solver.cpp:244]     Train net output #1: loss = 0.621975 (* 1 = 0.621975 loss)
I0423 06:23:04.014133 30295 solver.cpp:244]     Train net output #2: loss = 0.87739 (* 1 = 0.87739 loss)
I0423 06:23:04.014138 30295 solver.cpp:244]     Train net output #3: loss = 0.592158 (* 1 = 0.592158 loss)
I0423 06:23:04.014142 30295 sgd_solver.cpp:106] Iteration 22000, lr = 3e-05
I0423 06:24:43.587842 30295 solver.cpp:228] Iteration 22100, loss = 3.14916
I0423 06:24:43.587991 30295 solver.cpp:244]     Train net output #0: loss = 0.990156 (* 1 = 0.990156 loss)
I0423 06:24:43.587999 30295 solver.cpp:244]     Train net output #1: loss = 0.815071 (* 1 = 0.815071 loss)
I0423 06:24:43.588004 30295 solver.cpp:244]     Train net output #2: loss = 0.669928 (* 1 = 0.669928 loss)
I0423 06:24:43.588009 30295 solver.cpp:244]     Train net output #3: loss = 0.674004 (* 1 = 0.674004 loss)
I0423 06:24:43.588013 30295 sgd_solver.cpp:106] Iteration 22100, lr = 3e-05
I0423 06:26:24.739931 30295 solver.cpp:228] Iteration 22200, loss = 3.31278
I0423 06:26:24.742223 30295 solver.cpp:244]     Train net output #0: loss = 0.986914 (* 1 = 0.986914 loss)
I0423 06:26:24.742229 30295 solver.cpp:244]     Train net output #1: loss = 0.696642 (* 1 = 0.696642 loss)
I0423 06:26:24.742234 30295 solver.cpp:244]     Train net output #2: loss = 0.951543 (* 1 = 0.951543 loss)
I0423 06:26:24.742239 30295 solver.cpp:244]     Train net output #3: loss = 0.677682 (* 1 = 0.677682 loss)
I0423 06:26:24.742244 30295 sgd_solver.cpp:106] Iteration 22200, lr = 3e-05
I0423 06:28:05.701582 30295 solver.cpp:228] Iteration 22300, loss = 2.87299
I0423 06:28:05.701735 30295 solver.cpp:244]     Train net output #0: loss = 0.981774 (* 1 = 0.981774 loss)
I0423 06:28:05.701745 30295 solver.cpp:244]     Train net output #1: loss = 0.624208 (* 1 = 0.624208 loss)
I0423 06:28:05.701750 30295 solver.cpp:244]     Train net output #2: loss = 0.766059 (* 1 = 0.766059 loss)
I0423 06:28:05.701753 30295 solver.cpp:244]     Train net output #3: loss = 0.500954 (* 1 = 0.500954 loss)
I0423 06:28:05.701758 30295 sgd_solver.cpp:106] Iteration 22300, lr = 3e-05
I0423 06:29:46.723310 30295 solver.cpp:228] Iteration 22400, loss = 2.45555
I0423 06:29:46.723498 30295 solver.cpp:244]     Train net output #0: loss = 0.977792 (* 1 = 0.977792 loss)
I0423 06:29:46.723506 30295 solver.cpp:244]     Train net output #1: loss = 0.277842 (* 1 = 0.277842 loss)
I0423 06:29:46.723510 30295 solver.cpp:244]     Train net output #2: loss = 0.727251 (* 1 = 0.727251 loss)
I0423 06:29:46.723516 30295 solver.cpp:244]     Train net output #3: loss = 0.472666 (* 1 = 0.472666 loss)
I0423 06:29:46.723520 30295 sgd_solver.cpp:106] Iteration 22400, lr = 3e-05
I0423 06:31:27.286759 30295 solver.cpp:228] Iteration 22500, loss = 2.87274
I0423 06:31:27.286913 30295 solver.cpp:244]     Train net output #0: loss = 0.970195 (* 1 = 0.970195 loss)
I0423 06:31:27.286921 30295 solver.cpp:244]     Train net output #1: loss = 0.491678 (* 1 = 0.491678 loss)
I0423 06:31:27.286926 30295 solver.cpp:244]     Train net output #2: loss = 0.917961 (* 1 = 0.917961 loss)
I0423 06:31:27.286931 30295 solver.cpp:244]     Train net output #3: loss = 0.492901 (* 1 = 0.492901 loss)
I0423 06:31:27.286936 30295 sgd_solver.cpp:106] Iteration 22500, lr = 3e-05
I0423 06:33:08.175752 30295 solver.cpp:228] Iteration 22600, loss = 3.22531
I0423 06:33:08.175911 30295 solver.cpp:244]     Train net output #0: loss = 0.960747 (* 1 = 0.960747 loss)
I0423 06:33:08.175918 30295 solver.cpp:244]     Train net output #1: loss = 0.696739 (* 1 = 0.696739 loss)
I0423 06:33:08.175923 30295 solver.cpp:244]     Train net output #2: loss = 0.913719 (* 1 = 0.913719 loss)
I0423 06:33:08.175928 30295 solver.cpp:244]     Train net output #3: loss = 0.654104 (* 1 = 0.654104 loss)
I0423 06:33:08.175933 30295 sgd_solver.cpp:106] Iteration 22600, lr = 3e-05
I0423 06:34:49.758496 30295 solver.cpp:228] Iteration 22700, loss = 3.04602
I0423 06:34:49.758656 30295 solver.cpp:244]     Train net output #0: loss = 0.976344 (* 1 = 0.976344 loss)
I0423 06:34:49.758666 30295 solver.cpp:244]     Train net output #1: loss = 0.66629 (* 1 = 0.66629 loss)
I0423 06:34:49.758671 30295 solver.cpp:244]     Train net output #2: loss = 0.737191 (* 1 = 0.737191 loss)
I0423 06:34:49.758677 30295 solver.cpp:244]     Train net output #3: loss = 0.666199 (* 1 = 0.666199 loss)
I0423 06:34:49.758682 30295 sgd_solver.cpp:106] Iteration 22700, lr = 3e-05
I0423 06:36:29.415580 30295 solver.cpp:228] Iteration 22800, loss = 2.90596
I0423 06:36:29.415731 30295 solver.cpp:244]     Train net output #0: loss = 0.976361 (* 1 = 0.976361 loss)
I0423 06:36:29.415738 30295 solver.cpp:244]     Train net output #1: loss = 0.667171 (* 1 = 0.667171 loss)
I0423 06:36:29.415743 30295 solver.cpp:244]     Train net output #2: loss = 0.772489 (* 1 = 0.772489 loss)
I0423 06:36:29.415748 30295 solver.cpp:244]     Train net output #3: loss = 0.489943 (* 1 = 0.489943 loss)
I0423 06:36:29.415753 30295 sgd_solver.cpp:106] Iteration 22800, lr = 3e-05
I0423 06:38:10.473443 30295 solver.cpp:228] Iteration 22900, loss = 1.84597
I0423 06:38:10.474898 30295 solver.cpp:244]     Train net output #0: loss = 0.977436 (* 1 = 0.977436 loss)
I0423 06:38:10.474905 30295 solver.cpp:244]     Train net output #1: loss = 0.135822 (* 1 = 0.135822 loss)
I0423 06:38:10.474910 30295 solver.cpp:244]     Train net output #2: loss = 0.535729 (* 1 = 0.535729 loss)
I0423 06:38:10.474913 30295 solver.cpp:244]     Train net output #3: loss = 0.196982 (* 1 = 0.196982 loss)
I0423 06:38:10.474917 30295 sgd_solver.cpp:106] Iteration 22900, lr = 3e-05
I0423 06:39:50.773965 30295 solver.cpp:337] Iteration 23000, Testing net (#0)
I0423 06:39:50.774117 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 06:39:50.774121 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 06:39:50.774125 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 06:39:50.774142 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 06:39:50.774144 30295 net.cpp:693] Ignoring source layer visualize
I0423 06:39:50.774147 30295 net.cpp:693] Ignoring source layer fake
I0423 06:43:27.631014 30295 solver.cpp:404]     Test net output #0: loss = 0.97539 (* 1 = 0.97539 loss)
I0423 06:43:27.631191 30295 solver.cpp:404]     Test net output #1: loss = 0.493171 (* 1 = 0.493171 loss)
I0423 06:43:27.631197 30295 solver.cpp:404]     Test net output #2: loss = 0.784168 (* 1 = 0.784168 loss)
I0423 06:43:27.631202 30295 solver.cpp:404]     Test net output #3: loss = 0.481128 (* 1 = 0.481128 loss)
I0423 06:43:28.291903 30295 solver.cpp:228] Iteration 23000, loss = 3.19151
I0423 06:43:28.291944 30295 solver.cpp:244]     Train net output #0: loss = 0.96644 (* 1 = 0.96644 loss)
I0423 06:43:28.291949 30295 solver.cpp:244]     Train net output #1: loss = 0.717962 (* 1 = 0.717962 loss)
I0423 06:43:28.291954 30295 solver.cpp:244]     Train net output #2: loss = 0.878107 (* 1 = 0.878107 loss)
I0423 06:43:28.291957 30295 solver.cpp:244]     Train net output #3: loss = 0.629005 (* 1 = 0.629005 loss)
I0423 06:43:28.291961 30295 sgd_solver.cpp:106] Iteration 23000, lr = 3e-05
I0423 06:45:10.136267 30295 solver.cpp:228] Iteration 23100, loss = 3.18452
I0423 06:45:10.136420 30295 solver.cpp:244]     Train net output #0: loss = 0.984191 (* 1 = 0.984191 loss)
I0423 06:45:10.136427 30295 solver.cpp:244]     Train net output #1: loss = 0.699072 (* 1 = 0.699072 loss)
I0423 06:45:10.136433 30295 solver.cpp:244]     Train net output #2: loss = 0.889192 (* 1 = 0.889192 loss)
I0423 06:45:10.136437 30295 solver.cpp:244]     Train net output #3: loss = 0.612067 (* 1 = 0.612067 loss)
I0423 06:45:10.136442 30295 sgd_solver.cpp:106] Iteration 23100, lr = 3e-05
I0423 06:46:49.769130 30295 solver.cpp:228] Iteration 23200, loss = 2.97195
I0423 06:46:49.769271 30295 solver.cpp:244]     Train net output #0: loss = 0.969624 (* 1 = 0.969624 loss)
I0423 06:46:49.769279 30295 solver.cpp:244]     Train net output #1: loss = 0.542135 (* 1 = 0.542135 loss)
I0423 06:46:49.769284 30295 solver.cpp:244]     Train net output #2: loss = 0.92473 (* 1 = 0.92473 loss)
I0423 06:46:49.769287 30295 solver.cpp:244]     Train net output #3: loss = 0.535461 (* 1 = 0.535461 loss)
I0423 06:46:49.769294 30295 sgd_solver.cpp:106] Iteration 23200, lr = 3e-05
I0423 06:48:31.303967 30295 solver.cpp:228] Iteration 23300, loss = 2.9946
I0423 06:48:31.304103 30295 solver.cpp:244]     Train net output #0: loss = 0.980122 (* 1 = 0.980122 loss)
I0423 06:48:31.304111 30295 solver.cpp:244]     Train net output #1: loss = 0.622314 (* 1 = 0.622314 loss)
I0423 06:48:31.304116 30295 solver.cpp:244]     Train net output #2: loss = 0.809998 (* 1 = 0.809998 loss)
I0423 06:48:31.304121 30295 solver.cpp:244]     Train net output #3: loss = 0.582163 (* 1 = 0.582163 loss)
I0423 06:48:31.304126 30295 sgd_solver.cpp:106] Iteration 23300, lr = 3e-05
I0423 06:50:12.587667 30295 solver.cpp:228] Iteration 23400, loss = 3.05574
I0423 06:50:12.587831 30295 solver.cpp:244]     Train net output #0: loss = 0.98808 (* 1 = 0.98808 loss)
I0423 06:50:12.587838 30295 solver.cpp:244]     Train net output #1: loss = 0.650704 (* 1 = 0.650704 loss)
I0423 06:50:12.587843 30295 solver.cpp:244]     Train net output #2: loss = 0.768017 (* 1 = 0.768017 loss)
I0423 06:50:12.587847 30295 solver.cpp:244]     Train net output #3: loss = 0.648936 (* 1 = 0.648936 loss)
I0423 06:50:12.587853 30295 sgd_solver.cpp:106] Iteration 23400, lr = 3e-05
I0423 06:51:53.932042 30295 solver.cpp:228] Iteration 23500, loss = 2.11233
I0423 06:51:53.932198 30295 solver.cpp:244]     Train net output #0: loss = 0.986236 (* 1 = 0.986236 loss)
I0423 06:51:53.932204 30295 solver.cpp:244]     Train net output #1: loss = 0.39978 (* 1 = 0.39978 loss)
I0423 06:51:53.932210 30295 solver.cpp:244]     Train net output #2: loss = 0.467144 (* 1 = 0.467144 loss)
I0423 06:51:53.932214 30295 solver.cpp:244]     Train net output #3: loss = 0.259168 (* 1 = 0.259168 loss)
I0423 06:51:53.932219 30295 sgd_solver.cpp:106] Iteration 23500, lr = 3e-05
I0423 06:53:32.983655 30295 solver.cpp:228] Iteration 23600, loss = 2.69954
I0423 06:53:32.983835 30295 solver.cpp:244]     Train net output #0: loss = 0.979585 (* 1 = 0.979585 loss)
I0423 06:53:32.983844 30295 solver.cpp:244]     Train net output #1: loss = 0.534795 (* 1 = 0.534795 loss)
I0423 06:53:32.983849 30295 solver.cpp:244]     Train net output #2: loss = 0.657292 (* 1 = 0.657292 loss)
I0423 06:53:32.983852 30295 solver.cpp:244]     Train net output #3: loss = 0.527869 (* 1 = 0.527869 loss)
I0423 06:53:32.983857 30295 sgd_solver.cpp:106] Iteration 23600, lr = 3e-05
I0423 06:55:13.826040 30295 solver.cpp:228] Iteration 23700, loss = 3.02102
I0423 06:55:13.826185 30295 solver.cpp:244]     Train net output #0: loss = 0.980801 (* 1 = 0.980801 loss)
I0423 06:55:13.826192 30295 solver.cpp:244]     Train net output #1: loss = 0.492618 (* 1 = 0.492618 loss)
I0423 06:55:13.826198 30295 solver.cpp:244]     Train net output #2: loss = 0.896809 (* 1 = 0.896809 loss)
I0423 06:55:13.826202 30295 solver.cpp:244]     Train net output #3: loss = 0.650794 (* 1 = 0.650794 loss)
I0423 06:55:13.826207 30295 sgd_solver.cpp:106] Iteration 23700, lr = 3e-05
I0423 06:56:54.401460 30295 solver.cpp:228] Iteration 23800, loss = 3.07133
I0423 06:56:54.401610 30295 solver.cpp:244]     Train net output #0: loss = 0.976813 (* 1 = 0.976813 loss)
I0423 06:56:54.401618 30295 solver.cpp:244]     Train net output #1: loss = 0.632111 (* 1 = 0.632111 loss)
I0423 06:56:54.401623 30295 solver.cpp:244]     Train net output #2: loss = 0.937088 (* 1 = 0.937088 loss)
I0423 06:56:54.401628 30295 solver.cpp:244]     Train net output #3: loss = 0.525321 (* 1 = 0.525321 loss)
I0423 06:56:54.401633 30295 sgd_solver.cpp:106] Iteration 23800, lr = 3e-05
I0423 06:58:35.401505 30295 solver.cpp:228] Iteration 23900, loss = 2.81248
I0423 06:58:35.401654 30295 solver.cpp:244]     Train net output #0: loss = 0.961908 (* 1 = 0.961908 loss)
I0423 06:58:35.401660 30295 solver.cpp:244]     Train net output #1: loss = 0.560303 (* 1 = 0.560303 loss)
I0423 06:58:35.401666 30295 solver.cpp:244]     Train net output #2: loss = 0.740608 (* 1 = 0.740608 loss)
I0423 06:58:35.401671 30295 solver.cpp:244]     Train net output #3: loss = 0.549665 (* 1 = 0.549665 loss)
I0423 06:58:35.401675 30295 sgd_solver.cpp:106] Iteration 23900, lr = 3e-05
I0423 07:00:15.798800 30295 solver.cpp:337] Iteration 24000, Testing net (#0)
I0423 07:00:15.798962 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 07:00:15.798966 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 07:00:15.798970 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 07:00:15.798985 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 07:00:15.798990 30295 net.cpp:693] Ignoring source layer visualize
I0423 07:00:15.798991 30295 net.cpp:693] Ignoring source layer fake
I0423 07:03:53.402457 30295 solver.cpp:404]     Test net output #0: loss = 0.972458 (* 1 = 0.972458 loss)
I0423 07:03:53.402598 30295 solver.cpp:404]     Test net output #1: loss = 0.512048 (* 1 = 0.512048 loss)
I0423 07:03:53.402606 30295 solver.cpp:404]     Test net output #2: loss = 0.808641 (* 1 = 0.808641 loss)
I0423 07:03:53.402609 30295 solver.cpp:404]     Test net output #3: loss = 0.564683 (* 1 = 0.564683 loss)
I0423 07:03:54.065084 30295 solver.cpp:228] Iteration 24000, loss = 2.24555
I0423 07:03:54.065110 30295 solver.cpp:244]     Train net output #0: loss = 0.974199 (* 1 = 0.974199 loss)
I0423 07:03:54.065132 30295 solver.cpp:244]     Train net output #1: loss = 0.43486 (* 1 = 0.43486 loss)
I0423 07:03:54.065136 30295 solver.cpp:244]     Train net output #2: loss = 0.386722 (* 1 = 0.386722 loss)
I0423 07:03:54.065140 30295 solver.cpp:244]     Train net output #3: loss = 0.449766 (* 1 = 0.449766 loss)
I0423 07:03:54.065145 30295 sgd_solver.cpp:106] Iteration 24000, lr = 3e-05
I0423 07:05:35.206178 30295 solver.cpp:228] Iteration 24100, loss = 2.03742
I0423 07:05:35.206317 30295 solver.cpp:244]     Train net output #0: loss = 0.962145 (* 1 = 0.962145 loss)
I0423 07:05:35.206326 30295 solver.cpp:244]     Train net output #1: loss = 0.0693234 (* 1 = 0.0693234 loss)
I0423 07:05:35.206329 30295 solver.cpp:244]     Train net output #2: loss = 0.738023 (* 1 = 0.738023 loss)
I0423 07:05:35.206334 30295 solver.cpp:244]     Train net output #3: loss = 0.267926 (* 1 = 0.267926 loss)
I0423 07:05:35.206339 30295 sgd_solver.cpp:106] Iteration 24100, lr = 3e-05
I0423 07:07:16.376624 30295 solver.cpp:228] Iteration 24200, loss = 3.18126
I0423 07:07:16.377555 30295 solver.cpp:244]     Train net output #0: loss = 0.979874 (* 1 = 0.979874 loss)
I0423 07:07:16.377565 30295 solver.cpp:244]     Train net output #1: loss = 0.715224 (* 1 = 0.715224 loss)
I0423 07:07:16.377569 30295 solver.cpp:244]     Train net output #2: loss = 0.864658 (* 1 = 0.864658 loss)
I0423 07:07:16.377573 30295 solver.cpp:244]     Train net output #3: loss = 0.621503 (* 1 = 0.621503 loss)
I0423 07:07:16.377578 30295 sgd_solver.cpp:106] Iteration 24200, lr = 3e-05
I0423 07:08:56.046566 30295 solver.cpp:228] Iteration 24300, loss = 3.22345
I0423 07:08:56.047533 30295 solver.cpp:244]     Train net output #0: loss = 0.979511 (* 1 = 0.979511 loss)
I0423 07:08:56.047540 30295 solver.cpp:244]     Train net output #1: loss = 0.703114 (* 1 = 0.703114 loss)
I0423 07:08:56.047545 30295 solver.cpp:244]     Train net output #2: loss = 0.887307 (* 1 = 0.887307 loss)
I0423 07:08:56.047549 30295 solver.cpp:244]     Train net output #3: loss = 0.653514 (* 1 = 0.653514 loss)
I0423 07:08:56.047554 30295 sgd_solver.cpp:106] Iteration 24300, lr = 3e-05
I0423 07:10:37.549389 30295 solver.cpp:228] Iteration 24400, loss = 3.20893
I0423 07:10:37.549576 30295 solver.cpp:244]     Train net output #0: loss = 0.986075 (* 1 = 0.986075 loss)
I0423 07:10:37.549584 30295 solver.cpp:244]     Train net output #1: loss = 0.801101 (* 1 = 0.801101 loss)
I0423 07:10:37.549589 30295 solver.cpp:244]     Train net output #2: loss = 0.71989 (* 1 = 0.71989 loss)
I0423 07:10:37.549593 30295 solver.cpp:244]     Train net output #3: loss = 0.701865 (* 1 = 0.701865 loss)
I0423 07:10:37.549599 30295 sgd_solver.cpp:106] Iteration 24400, lr = 3e-05
I0423 07:12:19.166154 30295 solver.cpp:228] Iteration 24500, loss = 3.18036
I0423 07:12:19.166316 30295 solver.cpp:244]     Train net output #0: loss = 0.987881 (* 1 = 0.987881 loss)
I0423 07:12:19.166323 30295 solver.cpp:244]     Train net output #1: loss = 0.643502 (* 1 = 0.643502 loss)
I0423 07:12:19.166328 30295 solver.cpp:244]     Train net output #2: loss = 0.903621 (* 1 = 0.903621 loss)
I0423 07:12:19.166333 30295 solver.cpp:244]     Train net output #3: loss = 0.64536 (* 1 = 0.64536 loss)
I0423 07:12:19.166338 30295 sgd_solver.cpp:106] Iteration 24500, lr = 3e-05
I0423 07:13:59.024158 30295 solver.cpp:228] Iteration 24600, loss = 3.03906
I0423 07:13:59.024304 30295 solver.cpp:244]     Train net output #0: loss = 0.986303 (* 1 = 0.986303 loss)
I0423 07:13:59.024312 30295 solver.cpp:244]     Train net output #1: loss = 0.738329 (* 1 = 0.738329 loss)
I0423 07:13:59.024317 30295 solver.cpp:244]     Train net output #2: loss = 0.724802 (* 1 = 0.724802 loss)
I0423 07:13:59.024322 30295 solver.cpp:244]     Train net output #3: loss = 0.589624 (* 1 = 0.589624 loss)
I0423 07:13:59.024327 30295 sgd_solver.cpp:106] Iteration 24600, lr = 3e-05
I0423 07:15:40.258885 30295 solver.cpp:228] Iteration 24700, loss = 3.35237
I0423 07:15:40.259038 30295 solver.cpp:244]     Train net output #0: loss = 0.986824 (* 1 = 0.986824 loss)
I0423 07:15:40.259045 30295 solver.cpp:244]     Train net output #1: loss = 0.742119 (* 1 = 0.742119 loss)
I0423 07:15:40.259050 30295 solver.cpp:244]     Train net output #2: loss = 0.950092 (* 1 = 0.950092 loss)
I0423 07:15:40.259055 30295 solver.cpp:244]     Train net output #3: loss = 0.673329 (* 1 = 0.673329 loss)
I0423 07:15:40.259060 30295 sgd_solver.cpp:106] Iteration 24700, lr = 3e-05
I0423 07:17:21.420673 30295 solver.cpp:228] Iteration 24800, loss = 3.14373
I0423 07:17:21.420838 30295 solver.cpp:244]     Train net output #0: loss = 0.984571 (* 1 = 0.984571 loss)
I0423 07:17:21.420846 30295 solver.cpp:244]     Train net output #1: loss = 0.615519 (* 1 = 0.615519 loss)
I0423 07:17:21.420851 30295 solver.cpp:244]     Train net output #2: loss = 0.932171 (* 1 = 0.932171 loss)
I0423 07:17:21.420855 30295 solver.cpp:244]     Train net output #3: loss = 0.611474 (* 1 = 0.611474 loss)
I0423 07:17:21.420861 30295 sgd_solver.cpp:106] Iteration 24800, lr = 3e-05
I0423 07:19:02.194363 30295 solver.cpp:228] Iteration 24900, loss = 2.82978
I0423 07:19:02.194538 30295 solver.cpp:244]     Train net output #0: loss = 0.969256 (* 1 = 0.969256 loss)
I0423 07:19:02.194545 30295 solver.cpp:244]     Train net output #1: loss = 0.420034 (* 1 = 0.420034 loss)
I0423 07:19:02.194550 30295 solver.cpp:244]     Train net output #2: loss = 0.894271 (* 1 = 0.894271 loss)
I0423 07:19:02.194555 30295 solver.cpp:244]     Train net output #3: loss = 0.546222 (* 1 = 0.546222 loss)
I0423 07:19:02.194561 30295 sgd_solver.cpp:106] Iteration 24900, lr = 3e-05
I0423 07:20:41.755223 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_25000.caffemodel
I0423 07:20:51.114262 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_25000.solverstate
I0423 07:20:51.319949 30295 solver.cpp:337] Iteration 25000, Testing net (#0)
I0423 07:20:51.319994 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 07:20:51.319996 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 07:20:51.320000 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 07:20:51.320014 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 07:20:51.320017 30295 net.cpp:693] Ignoring source layer visualize
I0423 07:20:51.320019 30295 net.cpp:693] Ignoring source layer fake
I0423 07:24:28.431041 30295 solver.cpp:404]     Test net output #0: loss = 0.974892 (* 1 = 0.974892 loss)
I0423 07:24:28.431180 30295 solver.cpp:404]     Test net output #1: loss = 0.52794 (* 1 = 0.52794 loss)
I0423 07:24:28.431186 30295 solver.cpp:404]     Test net output #2: loss = 0.800747 (* 1 = 0.800747 loss)
I0423 07:24:28.431191 30295 solver.cpp:404]     Test net output #3: loss = 0.551306 (* 1 = 0.551306 loss)
I0423 07:24:29.096004 30295 solver.cpp:228] Iteration 25000, loss = 3.18155
I0423 07:24:29.096047 30295 solver.cpp:244]     Train net output #0: loss = 0.970779 (* 1 = 0.970779 loss)
I0423 07:24:29.096052 30295 solver.cpp:244]     Train net output #1: loss = 0.630493 (* 1 = 0.630493 loss)
I0423 07:24:29.096056 30295 solver.cpp:244]     Train net output #2: loss = 0.950267 (* 1 = 0.950267 loss)
I0423 07:24:29.096060 30295 solver.cpp:244]     Train net output #3: loss = 0.630008 (* 1 = 0.630008 loss)
I0423 07:24:29.096066 30295 sgd_solver.cpp:106] Iteration 25000, lr = 3e-05
I0423 07:26:10.236179 30295 solver.cpp:228] Iteration 25100, loss = 3.14114
I0423 07:26:10.236351 30295 solver.cpp:244]     Train net output #0: loss = 0.941296 (* 1 = 0.941296 loss)
I0423 07:26:10.236357 30295 solver.cpp:244]     Train net output #1: loss = 0.684545 (* 1 = 0.684545 loss)
I0423 07:26:10.236363 30295 solver.cpp:244]     Train net output #2: loss = 0.878268 (* 1 = 0.878268 loss)
I0423 07:26:10.236367 30295 solver.cpp:244]     Train net output #3: loss = 0.637033 (* 1 = 0.637033 loss)
I0423 07:26:10.236372 30295 sgd_solver.cpp:106] Iteration 25100, lr = 3e-05
I0423 07:27:52.156128 30295 solver.cpp:228] Iteration 25200, loss = 3.03229
I0423 07:27:52.156302 30295 solver.cpp:244]     Train net output #0: loss = 0.975231 (* 1 = 0.975231 loss)
I0423 07:27:52.156309 30295 solver.cpp:244]     Train net output #1: loss = 0.748439 (* 1 = 0.748439 loss)
I0423 07:27:52.156316 30295 solver.cpp:244]     Train net output #2: loss = 0.777305 (* 1 = 0.777305 loss)
I0423 07:27:52.156319 30295 solver.cpp:244]     Train net output #3: loss = 0.531314 (* 1 = 0.531314 loss)
I0423 07:27:52.156324 30295 sgd_solver.cpp:106] Iteration 25200, lr = 3e-05
I0423 07:29:31.735101 30295 solver.cpp:228] Iteration 25300, loss = 2.69467
I0423 07:29:31.735258 30295 solver.cpp:244]     Train net output #0: loss = 0.968555 (* 1 = 0.968555 loss)
I0423 07:29:31.735266 30295 solver.cpp:244]     Train net output #1: loss = 0.747182 (* 1 = 0.747182 loss)
I0423 07:29:31.735271 30295 solver.cpp:244]     Train net output #2: loss = 0.582218 (* 1 = 0.582218 loss)
I0423 07:29:31.735275 30295 solver.cpp:244]     Train net output #3: loss = 0.396717 (* 1 = 0.396717 loss)
I0423 07:29:31.735280 30295 sgd_solver.cpp:106] Iteration 25300, lr = 3e-05
I0423 07:31:12.871080 30295 solver.cpp:228] Iteration 25400, loss = 2.24303
I0423 07:31:12.871253 30295 solver.cpp:244]     Train net output #0: loss = 0.98 (* 1 = 0.98 loss)
I0423 07:31:12.871260 30295 solver.cpp:244]     Train net output #1: loss = 0.280462 (* 1 = 0.280462 loss)
I0423 07:31:12.871265 30295 solver.cpp:244]     Train net output #2: loss = 0.600351 (* 1 = 0.600351 loss)
I0423 07:31:12.871269 30295 solver.cpp:244]     Train net output #3: loss = 0.38222 (* 1 = 0.38222 loss)
I0423 07:31:12.871275 30295 sgd_solver.cpp:106] Iteration 25400, lr = 3e-05
I0423 07:32:54.631922 30295 solver.cpp:228] Iteration 25500, loss = 3.20103
I0423 07:32:54.633219 30295 solver.cpp:244]     Train net output #0: loss = 0.969465 (* 1 = 0.969465 loss)
I0423 07:32:54.633226 30295 solver.cpp:244]     Train net output #1: loss = 0.772185 (* 1 = 0.772185 loss)
I0423 07:32:54.633231 30295 solver.cpp:244]     Train net output #2: loss = 0.868027 (* 1 = 0.868027 loss)
I0423 07:32:54.633235 30295 solver.cpp:244]     Train net output #3: loss = 0.591348 (* 1 = 0.591348 loss)
I0423 07:32:54.633239 30295 sgd_solver.cpp:106] Iteration 25500, lr = 3e-05
I0423 07:34:35.967912 30295 solver.cpp:228] Iteration 25600, loss = 3.12799
I0423 07:34:35.968083 30295 solver.cpp:244]     Train net output #0: loss = 0.990394 (* 1 = 0.990394 loss)
I0423 07:34:35.968091 30295 solver.cpp:244]     Train net output #1: loss = 0.69567 (* 1 = 0.69567 loss)
I0423 07:34:35.968096 30295 solver.cpp:244]     Train net output #2: loss = 0.885098 (* 1 = 0.885098 loss)
I0423 07:34:35.968099 30295 solver.cpp:244]     Train net output #3: loss = 0.556828 (* 1 = 0.556828 loss)
I0423 07:34:35.968104 30295 sgd_solver.cpp:106] Iteration 25600, lr = 3e-05
I0423 07:36:15.722383 30295 solver.cpp:228] Iteration 25700, loss = 3.0349
I0423 07:36:15.722523 30295 solver.cpp:244]     Train net output #0: loss = 0.978934 (* 1 = 0.978934 loss)
I0423 07:36:15.722532 30295 solver.cpp:244]     Train net output #1: loss = 0.652449 (* 1 = 0.652449 loss)
I0423 07:36:15.722537 30295 solver.cpp:244]     Train net output #2: loss = 0.745489 (* 1 = 0.745489 loss)
I0423 07:36:15.722542 30295 solver.cpp:244]     Train net output #3: loss = 0.658028 (* 1 = 0.658028 loss)
I0423 07:36:15.722545 30295 sgd_solver.cpp:106] Iteration 25700, lr = 3e-05
I0423 07:37:57.274243 30295 solver.cpp:228] Iteration 25800, loss = 3.11462
I0423 07:37:57.276187 30295 solver.cpp:244]     Train net output #0: loss = 0.978411 (* 1 = 0.978411 loss)
I0423 07:37:57.276196 30295 solver.cpp:244]     Train net output #1: loss = 0.57318 (* 1 = 0.57318 loss)
I0423 07:37:57.276201 30295 solver.cpp:244]     Train net output #2: loss = 0.930154 (* 1 = 0.930154 loss)
I0423 07:37:57.276204 30295 solver.cpp:244]     Train net output #3: loss = 0.632875 (* 1 = 0.632875 loss)
I0423 07:37:57.276209 30295 sgd_solver.cpp:106] Iteration 25800, lr = 3e-05
I0423 07:39:38.616492 30295 solver.cpp:228] Iteration 25900, loss = 3.1836
I0423 07:39:38.616646 30295 solver.cpp:244]     Train net output #0: loss = 0.983592 (* 1 = 0.983592 loss)
I0423 07:39:38.616653 30295 solver.cpp:244]     Train net output #1: loss = 0.591055 (* 1 = 0.591055 loss)
I0423 07:39:38.616658 30295 solver.cpp:244]     Train net output #2: loss = 0.959288 (* 1 = 0.959288 loss)
I0423 07:39:38.616663 30295 solver.cpp:244]     Train net output #3: loss = 0.649668 (* 1 = 0.649668 loss)
I0423 07:39:38.616667 30295 sgd_solver.cpp:106] Iteration 25900, lr = 3e-05
I0423 07:41:18.790936 30295 solver.cpp:337] Iteration 26000, Testing net (#0)
I0423 07:41:18.791087 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 07:41:18.791091 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 07:41:18.791095 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 07:41:18.791108 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 07:41:18.791112 30295 net.cpp:693] Ignoring source layer visualize
I0423 07:41:18.791115 30295 net.cpp:693] Ignoring source layer fake
I0423 07:44:56.678562 30295 solver.cpp:404]     Test net output #0: loss = 0.971406 (* 1 = 0.971406 loss)
I0423 07:44:56.679605 30295 solver.cpp:404]     Test net output #1: loss = 0.536404 (* 1 = 0.536404 loss)
I0423 07:44:56.679613 30295 solver.cpp:404]     Test net output #2: loss = 0.815942 (* 1 = 0.815942 loss)
I0423 07:44:56.679618 30295 solver.cpp:404]     Test net output #3: loss = 0.571028 (* 1 = 0.571028 loss)
I0423 07:44:57.343137 30295 solver.cpp:228] Iteration 26000, loss = 2.73507
I0423 07:44:57.343179 30295 solver.cpp:244]     Train net output #0: loss = 0.986252 (* 1 = 0.986252 loss)
I0423 07:44:57.343185 30295 solver.cpp:244]     Train net output #1: loss = 0.50171 (* 1 = 0.50171 loss)
I0423 07:44:57.343189 30295 solver.cpp:244]     Train net output #2: loss = 0.743143 (* 1 = 0.743143 loss)
I0423 07:44:57.343194 30295 solver.cpp:244]     Train net output #3: loss = 0.503964 (* 1 = 0.503964 loss)
I0423 07:44:57.343199 30295 sgd_solver.cpp:106] Iteration 26000, lr = 3e-05
I0423 07:46:36.819006 30295 solver.cpp:228] Iteration 26100, loss = 3.02905
I0423 07:46:36.819157 30295 solver.cpp:244]     Train net output #0: loss = 0.986123 (* 1 = 0.986123 loss)
I0423 07:46:36.819165 30295 solver.cpp:244]     Train net output #1: loss = 0.579476 (* 1 = 0.579476 loss)
I0423 07:46:36.819169 30295 solver.cpp:244]     Train net output #2: loss = 0.767691 (* 1 = 0.767691 loss)
I0423 07:46:36.819175 30295 solver.cpp:244]     Train net output #3: loss = 0.695758 (* 1 = 0.695758 loss)
I0423 07:46:36.819180 30295 sgd_solver.cpp:106] Iteration 26100, lr = 3e-05
I0423 07:48:17.617655 30295 solver.cpp:228] Iteration 26200, loss = 2.94248
I0423 07:48:17.619052 30295 solver.cpp:244]     Train net output #0: loss = 0.983231 (* 1 = 0.983231 loss)
I0423 07:48:17.619060 30295 solver.cpp:244]     Train net output #1: loss = 0.5282 (* 1 = 0.5282 loss)
I0423 07:48:17.619066 30295 solver.cpp:244]     Train net output #2: loss = 0.80318 (* 1 = 0.80318 loss)
I0423 07:48:17.619071 30295 solver.cpp:244]     Train net output #3: loss = 0.627868 (* 1 = 0.627868 loss)
I0423 07:48:17.619074 30295 sgd_solver.cpp:106] Iteration 26200, lr = 3e-05
I0423 07:49:58.181812 30295 solver.cpp:228] Iteration 26300, loss = 3.24282
I0423 07:49:58.181982 30295 solver.cpp:244]     Train net output #0: loss = 0.972854 (* 1 = 0.972854 loss)
I0423 07:49:58.181990 30295 solver.cpp:244]     Train net output #1: loss = 0.706487 (* 1 = 0.706487 loss)
I0423 07:49:58.181994 30295 solver.cpp:244]     Train net output #2: loss = 0.950741 (* 1 = 0.950741 loss)
I0423 07:49:58.181999 30295 solver.cpp:244]     Train net output #3: loss = 0.612733 (* 1 = 0.612733 loss)
I0423 07:49:58.182004 30295 sgd_solver.cpp:106] Iteration 26300, lr = 3e-05
I0423 07:51:38.818828 30295 solver.cpp:228] Iteration 26400, loss = 2.76214
I0423 07:51:38.818996 30295 solver.cpp:244]     Train net output #0: loss = 0.968182 (* 1 = 0.968182 loss)
I0423 07:51:38.819005 30295 solver.cpp:244]     Train net output #1: loss = 0.519907 (* 1 = 0.519907 loss)
I0423 07:51:38.819010 30295 solver.cpp:244]     Train net output #2: loss = 0.75667 (* 1 = 0.75667 loss)
I0423 07:51:38.819013 30295 solver.cpp:244]     Train net output #3: loss = 0.517386 (* 1 = 0.517386 loss)
I0423 07:51:38.819017 30295 sgd_solver.cpp:106] Iteration 26400, lr = 3e-05
I0423 07:53:19.753320 30295 solver.cpp:228] Iteration 26500, loss = 2.90179
I0423 07:53:19.753492 30295 solver.cpp:244]     Train net output #0: loss = 0.966685 (* 1 = 0.966685 loss)
I0423 07:53:19.753500 30295 solver.cpp:244]     Train net output #1: loss = 0.465415 (* 1 = 0.465415 loss)
I0423 07:53:19.753504 30295 solver.cpp:244]     Train net output #2: loss = 0.763983 (* 1 = 0.763983 loss)
I0423 07:53:19.753510 30295 solver.cpp:244]     Train net output #3: loss = 0.705709 (* 1 = 0.705709 loss)
I0423 07:53:19.753515 30295 sgd_solver.cpp:106] Iteration 26500, lr = 3e-05
I0423 07:55:01.660912 30295 solver.cpp:228] Iteration 26600, loss = 1.69535
I0423 07:55:01.661077 30295 solver.cpp:244]     Train net output #0: loss = 0.971159 (* 1 = 0.971159 loss)
I0423 07:55:01.661084 30295 solver.cpp:244]     Train net output #1: loss = 0.126996 (* 1 = 0.126996 loss)
I0423 07:55:01.661089 30295 solver.cpp:244]     Train net output #2: loss = 0.373706 (* 1 = 0.373706 loss)
I0423 07:55:01.661093 30295 solver.cpp:244]     Train net output #3: loss = 0.223491 (* 1 = 0.223491 loss)
I0423 07:55:01.661098 30295 sgd_solver.cpp:106] Iteration 26600, lr = 3e-05
I0423 07:56:43.676606 30295 solver.cpp:228] Iteration 26700, loss = 3.09253
I0423 07:56:43.676743 30295 solver.cpp:244]     Train net output #0: loss = 0.979865 (* 1 = 0.979865 loss)
I0423 07:56:43.676751 30295 solver.cpp:244]     Train net output #1: loss = 0.681251 (* 1 = 0.681251 loss)
I0423 07:56:43.676756 30295 solver.cpp:244]     Train net output #2: loss = 0.84261 (* 1 = 0.84261 loss)
I0423 07:56:43.676761 30295 solver.cpp:244]     Train net output #3: loss = 0.588806 (* 1 = 0.588806 loss)
I0423 07:56:43.676766 30295 sgd_solver.cpp:106] Iteration 26700, lr = 3e-05
I0423 07:58:23.378931 30295 solver.cpp:228] Iteration 26800, loss = 3.11508
I0423 07:58:23.379067 30295 solver.cpp:244]     Train net output #0: loss = 0.970883 (* 1 = 0.970883 loss)
I0423 07:58:23.379076 30295 solver.cpp:244]     Train net output #1: loss = 0.629426 (* 1 = 0.629426 loss)
I0423 07:58:23.379079 30295 solver.cpp:244]     Train net output #2: loss = 0.880218 (* 1 = 0.880218 loss)
I0423 07:58:23.379084 30295 solver.cpp:244]     Train net output #3: loss = 0.634554 (* 1 = 0.634554 loss)
I0423 07:58:23.379088 30295 sgd_solver.cpp:106] Iteration 26800, lr = 3e-05
I0423 08:00:04.957661 30295 solver.cpp:228] Iteration 26900, loss = 3.02899
I0423 08:00:04.957816 30295 solver.cpp:244]     Train net output #0: loss = 0.978448 (* 1 = 0.978448 loss)
I0423 08:00:04.957824 30295 solver.cpp:244]     Train net output #1: loss = 0.596902 (* 1 = 0.596902 loss)
I0423 08:00:04.957829 30295 solver.cpp:244]     Train net output #2: loss = 0.91947 (* 1 = 0.91947 loss)
I0423 08:00:04.957834 30295 solver.cpp:244]     Train net output #3: loss = 0.534171 (* 1 = 0.534171 loss)
I0423 08:00:04.957847 30295 sgd_solver.cpp:106] Iteration 26900, lr = 3e-05
I0423 08:01:45.198856 30295 solver.cpp:337] Iteration 27000, Testing net (#0)
I0423 08:01:45.198997 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 08:01:45.199002 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 08:01:45.199004 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 08:01:45.199018 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 08:01:45.199021 30295 net.cpp:693] Ignoring source layer visualize
I0423 08:01:45.199023 30295 net.cpp:693] Ignoring source layer fake
I0423 08:05:22.786309 30295 solver.cpp:404]     Test net output #0: loss = 0.968485 (* 1 = 0.968485 loss)
I0423 08:05:22.786450 30295 solver.cpp:404]     Test net output #1: loss = 0.47573 (* 1 = 0.47573 loss)
I0423 08:05:22.786458 30295 solver.cpp:404]     Test net output #2: loss = 0.800695 (* 1 = 0.800695 loss)
I0423 08:05:22.786463 30295 solver.cpp:404]     Test net output #3: loss = 0.498192 (* 1 = 0.498192 loss)
I0423 08:05:23.448931 30295 solver.cpp:228] Iteration 27000, loss = 3.20289
I0423 08:05:23.448973 30295 solver.cpp:244]     Train net output #0: loss = 0.981207 (* 1 = 0.981207 loss)
I0423 08:05:23.448979 30295 solver.cpp:244]     Train net output #1: loss = 0.66645 (* 1 = 0.66645 loss)
I0423 08:05:23.448984 30295 solver.cpp:244]     Train net output #2: loss = 0.926176 (* 1 = 0.926176 loss)
I0423 08:05:23.448988 30295 solver.cpp:244]     Train net output #3: loss = 0.629059 (* 1 = 0.629059 loss)
I0423 08:05:23.448992 30295 sgd_solver.cpp:106] Iteration 27000, lr = 3e-05
I0423 08:07:02.883919 30295 solver.cpp:228] Iteration 27100, loss = 3.15084
I0423 08:07:02.884076 30295 solver.cpp:244]     Train net output #0: loss = 0.989912 (* 1 = 0.989912 loss)
I0423 08:07:02.884084 30295 solver.cpp:244]     Train net output #1: loss = 0.693003 (* 1 = 0.693003 loss)
I0423 08:07:02.884088 30295 solver.cpp:244]     Train net output #2: loss = 0.901964 (* 1 = 0.901964 loss)
I0423 08:07:02.884093 30295 solver.cpp:244]     Train net output #3: loss = 0.565966 (* 1 = 0.565966 loss)
I0423 08:07:02.884099 30295 sgd_solver.cpp:106] Iteration 27100, lr = 3e-05
I0423 08:08:44.002770 30295 solver.cpp:228] Iteration 27200, loss = 3.08642
I0423 08:08:44.002948 30295 solver.cpp:244]     Train net output #0: loss = 0.989986 (* 1 = 0.989986 loss)
I0423 08:08:44.002955 30295 solver.cpp:244]     Train net output #1: loss = 0.794823 (* 1 = 0.794823 loss)
I0423 08:08:44.002960 30295 solver.cpp:244]     Train net output #2: loss = 0.727496 (* 1 = 0.727496 loss)
I0423 08:08:44.002964 30295 solver.cpp:244]     Train net output #3: loss = 0.574113 (* 1 = 0.574113 loss)
I0423 08:08:44.002969 30295 sgd_solver.cpp:106] Iteration 27200, lr = 3e-05
I0423 08:10:24.944689 30295 solver.cpp:228] Iteration 27300, loss = 2.7742
I0423 08:10:24.944844 30295 solver.cpp:244]     Train net output #0: loss = 0.977118 (* 1 = 0.977118 loss)
I0423 08:10:24.944851 30295 solver.cpp:244]     Train net output #1: loss = 0.52959 (* 1 = 0.52959 loss)
I0423 08:10:24.944856 30295 solver.cpp:244]     Train net output #2: loss = 0.758898 (* 1 = 0.758898 loss)
I0423 08:10:24.944861 30295 solver.cpp:244]     Train net output #3: loss = 0.508596 (* 1 = 0.508596 loss)
I0423 08:10:24.944866 30295 sgd_solver.cpp:106] Iteration 27300, lr = 3e-05
I0423 08:12:05.737826 30295 solver.cpp:228] Iteration 27400, loss = 2.74298
I0423 08:12:05.737987 30295 solver.cpp:244]     Train net output #0: loss = 0.981174 (* 1 = 0.981174 loss)
I0423 08:12:05.737994 30295 solver.cpp:244]     Train net output #1: loss = 0.504115 (* 1 = 0.504115 loss)
I0423 08:12:05.737999 30295 solver.cpp:244]     Train net output #2: loss = 0.740637 (* 1 = 0.740637 loss)
I0423 08:12:05.738003 30295 solver.cpp:244]     Train net output #3: loss = 0.517049 (* 1 = 0.517049 loss)
I0423 08:12:05.738008 30295 sgd_solver.cpp:106] Iteration 27400, lr = 3e-05
I0423 08:13:46.265744 30295 solver.cpp:228] Iteration 27500, loss = 2.92379
I0423 08:13:46.265903 30295 solver.cpp:244]     Train net output #0: loss = 0.986282 (* 1 = 0.986282 loss)
I0423 08:13:46.265910 30295 solver.cpp:244]     Train net output #1: loss = 0.498813 (* 1 = 0.498813 loss)
I0423 08:13:46.265915 30295 solver.cpp:244]     Train net output #2: loss = 0.94951 (* 1 = 0.94951 loss)
I0423 08:13:46.265919 30295 solver.cpp:244]     Train net output #3: loss = 0.489181 (* 1 = 0.489181 loss)
I0423 08:13:46.265925 30295 sgd_solver.cpp:106] Iteration 27500, lr = 3e-05
I0423 08:15:27.094122 30295 solver.cpp:228] Iteration 27600, loss = 3.00101
I0423 08:15:27.094281 30295 solver.cpp:244]     Train net output #0: loss = 0.95316 (* 1 = 0.95316 loss)
I0423 08:15:27.094288 30295 solver.cpp:244]     Train net output #1: loss = 0.525868 (* 1 = 0.525868 loss)
I0423 08:15:27.094293 30295 solver.cpp:244]     Train net output #2: loss = 0.859256 (* 1 = 0.859256 loss)
I0423 08:15:27.094297 30295 solver.cpp:244]     Train net output #3: loss = 0.662729 (* 1 = 0.662729 loss)
I0423 08:15:27.094302 30295 sgd_solver.cpp:106] Iteration 27600, lr = 3e-05
I0423 08:17:08.192137 30295 solver.cpp:228] Iteration 27700, loss = 2.73734
I0423 08:17:08.192302 30295 solver.cpp:244]     Train net output #0: loss = 0.987425 (* 1 = 0.987425 loss)
I0423 08:17:08.192309 30295 solver.cpp:244]     Train net output #1: loss = 0.779396 (* 1 = 0.779396 loss)
I0423 08:17:08.192314 30295 solver.cpp:244]     Train net output #2: loss = 0.564534 (* 1 = 0.564534 loss)
I0423 08:17:08.192318 30295 solver.cpp:244]     Train net output #3: loss = 0.405986 (* 1 = 0.405986 loss)
I0423 08:17:08.192323 30295 sgd_solver.cpp:106] Iteration 27700, lr = 3e-05
I0423 08:18:47.972124 30295 solver.cpp:228] Iteration 27800, loss = 2.83427
I0423 08:18:47.972265 30295 solver.cpp:244]     Train net output #0: loss = 0.966742 (* 1 = 0.966742 loss)
I0423 08:18:47.972271 30295 solver.cpp:244]     Train net output #1: loss = 0.608881 (* 1 = 0.608881 loss)
I0423 08:18:47.972276 30295 solver.cpp:244]     Train net output #2: loss = 0.772953 (* 1 = 0.772953 loss)
I0423 08:18:47.972280 30295 solver.cpp:244]     Train net output #3: loss = 0.485695 (* 1 = 0.485695 loss)
I0423 08:18:47.972285 30295 sgd_solver.cpp:106] Iteration 27800, lr = 3e-05
I0423 08:20:29.276134 30295 solver.cpp:228] Iteration 27900, loss = 3.10924
I0423 08:20:29.276305 30295 solver.cpp:244]     Train net output #0: loss = 0.95997 (* 1 = 0.95997 loss)
I0423 08:20:29.276314 30295 solver.cpp:244]     Train net output #1: loss = 0.661566 (* 1 = 0.661566 loss)
I0423 08:20:29.276317 30295 solver.cpp:244]     Train net output #2: loss = 0.789696 (* 1 = 0.789696 loss)
I0423 08:20:29.276322 30295 solver.cpp:244]     Train net output #3: loss = 0.698007 (* 1 = 0.698007 loss)
I0423 08:20:29.276327 30295 sgd_solver.cpp:106] Iteration 27900, lr = 3e-05
I0423 08:22:09.477291 30295 solver.cpp:337] Iteration 28000, Testing net (#0)
I0423 08:22:09.477453 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 08:22:09.477458 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 08:22:09.477463 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 08:22:09.477478 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 08:22:09.477480 30295 net.cpp:693] Ignoring source layer visualize
I0423 08:22:09.477483 30295 net.cpp:693] Ignoring source layer fake
I0423 08:25:46.763109 30295 solver.cpp:404]     Test net output #0: loss = 0.972944 (* 1 = 0.972944 loss)
I0423 08:25:46.763253 30295 solver.cpp:404]     Test net output #1: loss = 0.452581 (* 1 = 0.452581 loss)
I0423 08:25:46.763259 30295 solver.cpp:404]     Test net output #2: loss = 0.777622 (* 1 = 0.777622 loss)
I0423 08:25:46.763264 30295 solver.cpp:404]     Test net output #3: loss = 0.458312 (* 1 = 0.458312 loss)
I0423 08:25:47.419711 30295 solver.cpp:228] Iteration 28000, loss = 3.23786
I0423 08:25:47.419752 30295 solver.cpp:244]     Train net output #0: loss = 0.979683 (* 1 = 0.979683 loss)
I0423 08:25:47.419757 30295 solver.cpp:244]     Train net output #1: loss = 0.724458 (* 1 = 0.724458 loss)
I0423 08:25:47.419761 30295 solver.cpp:244]     Train net output #2: loss = 0.851301 (* 1 = 0.851301 loss)
I0423 08:25:47.419766 30295 solver.cpp:244]     Train net output #3: loss = 0.682416 (* 1 = 0.682416 loss)
I0423 08:25:47.419772 30295 sgd_solver.cpp:106] Iteration 28000, lr = 3e-05
I0423 08:27:30.040429 30295 solver.cpp:228] Iteration 28100, loss = 3.15153
I0423 08:27:30.040582 30295 solver.cpp:244]     Train net output #0: loss = 0.984658 (* 1 = 0.984658 loss)
I0423 08:27:30.040591 30295 solver.cpp:244]     Train net output #1: loss = 0.694988 (* 1 = 0.694988 loss)
I0423 08:27:30.040596 30295 solver.cpp:244]     Train net output #2: loss = 0.865148 (* 1 = 0.865148 loss)
I0423 08:27:30.040601 30295 solver.cpp:244]     Train net output #3: loss = 0.606739 (* 1 = 0.606739 loss)
I0423 08:27:30.040606 30295 sgd_solver.cpp:106] Iteration 28100, lr = 3e-05
I0423 08:29:09.584317 30295 solver.cpp:228] Iteration 28200, loss = 3.02522
I0423 08:29:09.584486 30295 solver.cpp:244]     Train net output #0: loss = 0.97542 (* 1 = 0.97542 loss)
I0423 08:29:09.584494 30295 solver.cpp:244]     Train net output #1: loss = 0.59246 (* 1 = 0.59246 loss)
I0423 08:29:09.584499 30295 solver.cpp:244]     Train net output #2: loss = 0.913772 (* 1 = 0.913772 loss)
I0423 08:29:09.584504 30295 solver.cpp:244]     Train net output #3: loss = 0.543565 (* 1 = 0.543565 loss)
I0423 08:29:09.584509 30295 sgd_solver.cpp:106] Iteration 28200, lr = 3e-05
I0423 08:30:51.309916 30295 solver.cpp:228] Iteration 28300, loss = 3.2284
I0423 08:30:51.310086 30295 solver.cpp:244]     Train net output #0: loss = 0.986091 (* 1 = 0.986091 loss)
I0423 08:30:51.310094 30295 solver.cpp:244]     Train net output #1: loss = 0.635326 (* 1 = 0.635326 loss)
I0423 08:30:51.310099 30295 solver.cpp:244]     Train net output #2: loss = 0.946382 (* 1 = 0.946382 loss)
I0423 08:30:51.310103 30295 solver.cpp:244]     Train net output #3: loss = 0.660597 (* 1 = 0.660597 loss)
I0423 08:30:51.310108 30295 sgd_solver.cpp:106] Iteration 28300, lr = 3e-05
I0423 08:32:33.256471 30295 solver.cpp:228] Iteration 28400, loss = 3.22126
I0423 08:32:33.256669 30295 solver.cpp:244]     Train net output #0: loss = 0.986649 (* 1 = 0.986649 loss)
I0423 08:32:33.256676 30295 solver.cpp:244]     Train net output #1: loss = 0.757031 (* 1 = 0.757031 loss)
I0423 08:32:33.256681 30295 solver.cpp:244]     Train net output #2: loss = 0.767716 (* 1 = 0.767716 loss)
I0423 08:32:33.256686 30295 solver.cpp:244]     Train net output #3: loss = 0.709862 (* 1 = 0.709862 loss)
I0423 08:32:33.256691 30295 sgd_solver.cpp:106] Iteration 28400, lr = 3e-05
I0423 08:34:15.032516 30295 solver.cpp:228] Iteration 28500, loss = 2.80748
I0423 08:34:15.033737 30295 solver.cpp:244]     Train net output #0: loss = 0.982432 (* 1 = 0.982432 loss)
I0423 08:34:15.033746 30295 solver.cpp:244]     Train net output #1: loss = 0.490803 (* 1 = 0.490803 loss)
I0423 08:34:15.033751 30295 solver.cpp:244]     Train net output #2: loss = 0.751827 (* 1 = 0.751827 loss)
I0423 08:34:15.033754 30295 solver.cpp:244]     Train net output #3: loss = 0.582414 (* 1 = 0.582414 loss)
I0423 08:34:15.033758 30295 sgd_solver.cpp:106] Iteration 28500, lr = 3e-05
I0423 08:35:54.412947 30295 solver.cpp:228] Iteration 28600, loss = 2.4527
I0423 08:35:54.413108 30295 solver.cpp:244]     Train net output #0: loss = 0.983414 (* 1 = 0.983414 loss)
I0423 08:35:54.413116 30295 solver.cpp:244]     Train net output #1: loss = 0.40724 (* 1 = 0.40724 loss)
I0423 08:35:54.413121 30295 solver.cpp:244]     Train net output #2: loss = 0.573277 (* 1 = 0.573277 loss)
I0423 08:35:54.413126 30295 solver.cpp:244]     Train net output #3: loss = 0.488768 (* 1 = 0.488768 loss)
I0423 08:35:54.413131 30295 sgd_solver.cpp:106] Iteration 28600, lr = 3e-05
I0423 08:37:35.875121 30295 solver.cpp:228] Iteration 28700, loss = 2.72252
I0423 08:37:35.875293 30295 solver.cpp:244]     Train net output #0: loss = 0.975685 (* 1 = 0.975685 loss)
I0423 08:37:35.875303 30295 solver.cpp:244]     Train net output #1: loss = 0.495167 (* 1 = 0.495167 loss)
I0423 08:37:35.875306 30295 solver.cpp:244]     Train net output #2: loss = 0.706547 (* 1 = 0.706547 loss)
I0423 08:37:35.875311 30295 solver.cpp:244]     Train net output #3: loss = 0.545119 (* 1 = 0.545119 loss)
I0423 08:37:35.875315 30295 sgd_solver.cpp:106] Iteration 28700, lr = 3e-05
I0423 08:39:16.701414 30295 solver.cpp:228] Iteration 28800, loss = 3.23357
I0423 08:39:16.701601 30295 solver.cpp:244]     Train net output #0: loss = 0.979053 (* 1 = 0.979053 loss)
I0423 08:39:16.701607 30295 solver.cpp:244]     Train net output #1: loss = 0.728017 (* 1 = 0.728017 loss)
I0423 08:39:16.701612 30295 solver.cpp:244]     Train net output #2: loss = 0.938773 (* 1 = 0.938773 loss)
I0423 08:39:16.701617 30295 solver.cpp:244]     Train net output #3: loss = 0.587727 (* 1 = 0.587727 loss)
I0423 08:39:16.701622 30295 sgd_solver.cpp:106] Iteration 28800, lr = 3e-05
I0423 08:40:57.909296 30295 solver.cpp:228] Iteration 28900, loss = 3.03466
I0423 08:40:57.909495 30295 solver.cpp:244]     Train net output #0: loss = 0.965886 (* 1 = 0.965886 loss)
I0423 08:40:57.909503 30295 solver.cpp:244]     Train net output #1: loss = 0.557953 (* 1 = 0.557953 loss)
I0423 08:40:57.909508 30295 solver.cpp:244]     Train net output #2: loss = 0.948765 (* 1 = 0.948765 loss)
I0423 08:40:57.909513 30295 solver.cpp:244]     Train net output #3: loss = 0.562055 (* 1 = 0.562055 loss)
I0423 08:40:57.909518 30295 sgd_solver.cpp:106] Iteration 28900, lr = 3e-05
I0423 08:42:38.244675 30295 solver.cpp:337] Iteration 29000, Testing net (#0)
I0423 08:42:38.245906 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 08:42:38.245911 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 08:42:38.245915 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 08:42:38.245932 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 08:42:38.245935 30295 net.cpp:693] Ignoring source layer visualize
I0423 08:42:38.245936 30295 net.cpp:693] Ignoring source layer fake
I0423 08:46:16.249428 30295 solver.cpp:404]     Test net output #0: loss = 0.973197 (* 1 = 0.973197 loss)
I0423 08:46:16.249594 30295 solver.cpp:404]     Test net output #1: loss = 0.523927 (* 1 = 0.523927 loss)
I0423 08:46:16.249611 30295 solver.cpp:404]     Test net output #2: loss = 0.809649 (* 1 = 0.809649 loss)
I0423 08:46:16.249616 30295 solver.cpp:404]     Test net output #3: loss = 0.57412 (* 1 = 0.57412 loss)
I0423 08:46:16.907893 30295 solver.cpp:228] Iteration 29000, loss = 2.57169
I0423 08:46:16.907935 30295 solver.cpp:244]     Train net output #0: loss = 0.971391 (* 1 = 0.971391 loss)
I0423 08:46:16.907941 30295 solver.cpp:244]     Train net output #1: loss = 0.508771 (* 1 = 0.508771 loss)
I0423 08:46:16.907945 30295 solver.cpp:244]     Train net output #2: loss = 0.579125 (* 1 = 0.579125 loss)
I0423 08:46:16.907949 30295 solver.cpp:244]     Train net output #3: loss = 0.512406 (* 1 = 0.512406 loss)
I0423 08:46:16.907954 30295 sgd_solver.cpp:106] Iteration 29000, lr = 3e-05
I0423 08:47:58.048740 30295 solver.cpp:228] Iteration 29100, loss = 1.92217
I0423 08:47:58.048905 30295 solver.cpp:244]     Train net output #0: loss = 0.972407 (* 1 = 0.972407 loss)
I0423 08:47:58.048913 30295 solver.cpp:244]     Train net output #1: loss = 0.140184 (* 1 = 0.140184 loss)
I0423 08:47:58.048918 30295 solver.cpp:244]     Train net output #2: loss = 0.544955 (* 1 = 0.544955 loss)
I0423 08:47:58.048931 30295 solver.cpp:244]     Train net output #3: loss = 0.264624 (* 1 = 0.264624 loss)
I0423 08:47:58.048938 30295 sgd_solver.cpp:106] Iteration 29100, lr = 3e-05
I0423 08:49:39.232228 30295 solver.cpp:228] Iteration 29200, loss = 3.11875
I0423 08:49:39.232379 30295 solver.cpp:244]     Train net output #0: loss = 0.971825 (* 1 = 0.971825 loss)
I0423 08:49:39.232388 30295 solver.cpp:244]     Train net output #1: loss = 0.691006 (* 1 = 0.691006 loss)
I0423 08:49:39.232393 30295 solver.cpp:244]     Train net output #2: loss = 0.858661 (* 1 = 0.858661 loss)
I0423 08:49:39.232396 30295 solver.cpp:244]     Train net output #3: loss = 0.597256 (* 1 = 0.597256 loss)
I0423 08:49:39.232403 30295 sgd_solver.cpp:106] Iteration 29200, lr = 3e-05
I0423 08:51:18.747702 30295 solver.cpp:228] Iteration 29300, loss = 3.03624
I0423 08:51:18.747851 30295 solver.cpp:244]     Train net output #0: loss = 0.955616 (* 1 = 0.955616 loss)
I0423 08:51:18.747859 30295 solver.cpp:244]     Train net output #1: loss = 0.636363 (* 1 = 0.636363 loss)
I0423 08:51:18.747871 30295 solver.cpp:244]     Train net output #2: loss = 0.898342 (* 1 = 0.898342 loss)
I0423 08:51:18.747875 30295 solver.cpp:244]     Train net output #3: loss = 0.545919 (* 1 = 0.545919 loss)
I0423 08:51:18.747880 30295 sgd_solver.cpp:106] Iteration 29300, lr = 3e-05
I0423 08:53:00.754680 30295 solver.cpp:228] Iteration 29400, loss = 3.08219
I0423 08:53:00.754837 30295 solver.cpp:244]     Train net output #0: loss = 0.979659 (* 1 = 0.979659 loss)
I0423 08:53:00.754844 30295 solver.cpp:244]     Train net output #1: loss = 0.583277 (* 1 = 0.583277 loss)
I0423 08:53:00.754849 30295 solver.cpp:244]     Train net output #2: loss = 0.929806 (* 1 = 0.929806 loss)
I0423 08:53:00.754853 30295 solver.cpp:244]     Train net output #3: loss = 0.589444 (* 1 = 0.589444 loss)
I0423 08:53:00.754858 30295 sgd_solver.cpp:106] Iteration 29400, lr = 3e-05
I0423 08:54:42.544100 30295 solver.cpp:228] Iteration 29500, loss = 3.31299
I0423 08:54:42.544258 30295 solver.cpp:244]     Train net output #0: loss = 0.98142 (* 1 = 0.98142 loss)
I0423 08:54:42.544265 30295 solver.cpp:244]     Train net output #1: loss = 0.749946 (* 1 = 0.749946 loss)
I0423 08:54:42.544271 30295 solver.cpp:244]     Train net output #2: loss = 0.913482 (* 1 = 0.913482 loss)
I0423 08:54:42.544275 30295 solver.cpp:244]     Train net output #3: loss = 0.668139 (* 1 = 0.668139 loss)
I0423 08:54:42.544281 30295 sgd_solver.cpp:106] Iteration 29500, lr = 3e-05
I0423 08:56:22.254839 30295 solver.cpp:228] Iteration 29600, loss = 3.10638
I0423 08:56:22.254986 30295 solver.cpp:244]     Train net output #0: loss = 0.990863 (* 1 = 0.990863 loss)
I0423 08:56:22.254992 30295 solver.cpp:244]     Train net output #1: loss = 0.651678 (* 1 = 0.651678 loss)
I0423 08:56:22.254997 30295 solver.cpp:244]     Train net output #2: loss = 0.864931 (* 1 = 0.864931 loss)
I0423 08:56:22.255002 30295 solver.cpp:244]     Train net output #3: loss = 0.598903 (* 1 = 0.598903 loss)
I0423 08:56:22.255007 30295 sgd_solver.cpp:106] Iteration 29600, lr = 3e-05
I0423 08:58:03.710572 30295 solver.cpp:228] Iteration 29700, loss = 2.93119
I0423 08:58:03.710747 30295 solver.cpp:244]     Train net output #0: loss = 0.98871 (* 1 = 0.98871 loss)
I0423 08:58:03.710753 30295 solver.cpp:244]     Train net output #1: loss = 0.590851 (* 1 = 0.590851 loss)
I0423 08:58:03.710759 30295 solver.cpp:244]     Train net output #2: loss = 0.736204 (* 1 = 0.736204 loss)
I0423 08:58:03.710763 30295 solver.cpp:244]     Train net output #3: loss = 0.615421 (* 1 = 0.615421 loss)
I0423 08:58:03.710767 30295 sgd_solver.cpp:106] Iteration 29700, lr = 3e-05
I0423 08:59:44.925853 30295 solver.cpp:228] Iteration 29800, loss = 2.79701
I0423 08:59:44.926002 30295 solver.cpp:244]     Train net output #0: loss = 0.982535 (* 1 = 0.982535 loss)
I0423 08:59:44.926010 30295 solver.cpp:244]     Train net output #1: loss = 0.530139 (* 1 = 0.530139 loss)
I0423 08:59:44.926014 30295 solver.cpp:244]     Train net output #2: loss = 0.761094 (* 1 = 0.761094 loss)
I0423 08:59:44.926019 30295 solver.cpp:244]     Train net output #3: loss = 0.523242 (* 1 = 0.523242 loss)
I0423 08:59:44.926025 30295 sgd_solver.cpp:106] Iteration 29800, lr = 3e-05
I0423 09:01:25.836526 30295 solver.cpp:228] Iteration 29900, loss = 2.44251
I0423 09:01:25.836675 30295 solver.cpp:244]     Train net output #0: loss = 0.980775 (* 1 = 0.980775 loss)
I0423 09:01:25.836683 30295 solver.cpp:244]     Train net output #1: loss = 0.351743 (* 1 = 0.351743 loss)
I0423 09:01:25.836688 30295 solver.cpp:244]     Train net output #2: loss = 0.747695 (* 1 = 0.747695 loss)
I0423 09:01:25.836693 30295 solver.cpp:244]     Train net output #3: loss = 0.362299 (* 1 = 0.362299 loss)
I0423 09:01:25.836696 30295 sgd_solver.cpp:106] Iteration 29900, lr = 3e-05
I0423 09:03:05.481732 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_30000.caffemodel
I0423 09:03:24.427150 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_30000.solverstate
I0423 09:03:24.618261 30295 solver.cpp:337] Iteration 30000, Testing net (#0)
I0423 09:03:24.618304 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 09:03:24.618306 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 09:03:24.618311 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 09:03:24.618324 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 09:03:24.618326 30295 net.cpp:693] Ignoring source layer visualize
I0423 09:03:24.618329 30295 net.cpp:693] Ignoring source layer fake
I0423 09:07:01.566547 30295 solver.cpp:404]     Test net output #0: loss = 0.975939 (* 1 = 0.975939 loss)
I0423 09:07:01.566692 30295 solver.cpp:404]     Test net output #1: loss = 0.54143 (* 1 = 0.54143 loss)
I0423 09:07:01.566699 30295 solver.cpp:404]     Test net output #2: loss = 0.803157 (* 1 = 0.803157 loss)
I0423 09:07:01.566704 30295 solver.cpp:404]     Test net output #3: loss = 0.562329 (* 1 = 0.562329 loss)
I0423 09:07:02.260222 30295 solver.cpp:228] Iteration 30000, loss = 2.99697
I0423 09:07:02.260265 30295 solver.cpp:244]     Train net output #0: loss = 0.981162 (* 1 = 0.981162 loss)
I0423 09:07:02.260272 30295 solver.cpp:244]     Train net output #1: loss = 0.578651 (* 1 = 0.578651 loss)
I0423 09:07:02.260275 30295 solver.cpp:244]     Train net output #2: loss = 0.943477 (* 1 = 0.943477 loss)
I0423 09:07:02.260280 30295 solver.cpp:244]     Train net output #3: loss = 0.493677 (* 1 = 0.493677 loss)
I0423 09:07:02.260288 30295 sgd_solver.cpp:106] Iteration 30000, lr = 3e-05
I0423 09:08:43.228147 30295 solver.cpp:228] Iteration 30100, loss = 2.75792
I0423 09:08:43.228292 30295 solver.cpp:244]     Train net output #0: loss = 0.96333 (* 1 = 0.96333 loss)
I0423 09:08:43.228301 30295 solver.cpp:244]     Train net output #1: loss = 0.497023 (* 1 = 0.497023 loss)
I0423 09:08:43.228305 30295 solver.cpp:244]     Train net output #2: loss = 0.755944 (* 1 = 0.755944 loss)
I0423 09:08:43.228310 30295 solver.cpp:244]     Train net output #3: loss = 0.541621 (* 1 = 0.541621 loss)
I0423 09:08:43.228314 30295 sgd_solver.cpp:106] Iteration 30100, lr = 3e-05
I0423 09:10:24.167253 30295 solver.cpp:228] Iteration 30200, loss = 3.37953
I0423 09:10:24.167428 30295 solver.cpp:244]     Train net output #0: loss = 0.971034 (* 1 = 0.971034 loss)
I0423 09:10:24.167435 30295 solver.cpp:244]     Train net output #1: loss = 0.753641 (* 1 = 0.753641 loss)
I0423 09:10:24.167439 30295 solver.cpp:244]     Train net output #2: loss = 0.956663 (* 1 = 0.956663 loss)
I0423 09:10:24.167444 30295 solver.cpp:244]     Train net output #3: loss = 0.698191 (* 1 = 0.698191 loss)
I0423 09:10:24.167448 30295 sgd_solver.cpp:106] Iteration 30200, lr = 3e-05
I0423 09:12:03.756515 30295 solver.cpp:228] Iteration 30300, loss = 2.84612
I0423 09:12:03.756690 30295 solver.cpp:244]     Train net output #0: loss = 0.98481 (* 1 = 0.98481 loss)
I0423 09:12:03.756697 30295 solver.cpp:244]     Train net output #1: loss = 0.611349 (* 1 = 0.611349 loss)
I0423 09:12:03.756702 30295 solver.cpp:244]     Train net output #2: loss = 0.764176 (* 1 = 0.764176 loss)
I0423 09:12:03.756706 30295 solver.cpp:244]     Train net output #3: loss = 0.485789 (* 1 = 0.485789 loss)
I0423 09:12:03.756711 30295 sgd_solver.cpp:106] Iteration 30300, lr = 3e-05
I0423 09:13:44.869905 30295 solver.cpp:228] Iteration 30400, loss = 3.21816
I0423 09:13:44.870062 30295 solver.cpp:244]     Train net output #0: loss = 0.947535 (* 1 = 0.947535 loss)
I0423 09:13:44.870069 30295 solver.cpp:244]     Train net output #1: loss = 0.664723 (* 1 = 0.664723 loss)
I0423 09:13:44.870074 30295 solver.cpp:244]     Train net output #2: loss = 0.908105 (* 1 = 0.908105 loss)
I0423 09:13:44.870079 30295 solver.cpp:244]     Train net output #3: loss = 0.697799 (* 1 = 0.697799 loss)
I0423 09:13:44.870085 30295 sgd_solver.cpp:106] Iteration 30400, lr = 3e-05
I0423 09:15:26.090163 30295 solver.cpp:228] Iteration 30500, loss = 3.23503
I0423 09:15:26.091995 30295 solver.cpp:244]     Train net output #0: loss = 0.969451 (* 1 = 0.969451 loss)
I0423 09:15:26.092001 30295 solver.cpp:244]     Train net output #1: loss = 0.713903 (* 1 = 0.713903 loss)
I0423 09:15:26.092005 30295 solver.cpp:244]     Train net output #2: loss = 0.893413 (* 1 = 0.893413 loss)
I0423 09:15:26.092011 30295 solver.cpp:244]     Train net output #3: loss = 0.658267 (* 1 = 0.658267 loss)
I0423 09:15:26.092016 30295 sgd_solver.cpp:106] Iteration 30500, lr = 3e-05
I0423 09:17:07.929000 30295 solver.cpp:228] Iteration 30600, loss = 3.05975
I0423 09:17:07.929136 30295 solver.cpp:244]     Train net output #0: loss = 0.968155 (* 1 = 0.968155 loss)
I0423 09:17:07.929144 30295 solver.cpp:244]     Train net output #1: loss = 0.662707 (* 1 = 0.662707 loss)
I0423 09:17:07.929148 30295 solver.cpp:244]     Train net output #2: loss = 0.862347 (* 1 = 0.862347 loss)
I0423 09:17:07.929153 30295 solver.cpp:244]     Train net output #3: loss = 0.566541 (* 1 = 0.566541 loss)
I0423 09:17:07.929158 30295 sgd_solver.cpp:106] Iteration 30600, lr = 3e-05
I0423 09:18:47.688967 30295 solver.cpp:228] Iteration 30700, loss = 2.91605
I0423 09:18:47.689123 30295 solver.cpp:244]     Train net output #0: loss = 0.975502 (* 1 = 0.975502 loss)
I0423 09:18:47.689131 30295 solver.cpp:244]     Train net output #1: loss = 0.526862 (* 1 = 0.526862 loss)
I0423 09:18:47.689136 30295 solver.cpp:244]     Train net output #2: loss = 0.910571 (* 1 = 0.910571 loss)
I0423 09:18:47.689141 30295 solver.cpp:244]     Train net output #3: loss = 0.503119 (* 1 = 0.503119 loss)
I0423 09:18:47.689144 30295 sgd_solver.cpp:106] Iteration 30700, lr = 3e-05
I0423 09:20:30.244740 30295 solver.cpp:228] Iteration 30800, loss = 3.22334
I0423 09:20:30.246002 30295 solver.cpp:244]     Train net output #0: loss = 0.97749 (* 1 = 0.97749 loss)
I0423 09:20:30.246011 30295 solver.cpp:244]     Train net output #1: loss = 0.620757 (* 1 = 0.620757 loss)
I0423 09:20:30.246016 30295 solver.cpp:244]     Train net output #2: loss = 0.936268 (* 1 = 0.936268 loss)
I0423 09:20:30.246019 30295 solver.cpp:244]     Train net output #3: loss = 0.688828 (* 1 = 0.688828 loss)
I0423 09:20:30.246024 30295 sgd_solver.cpp:106] Iteration 30800, lr = 3e-05
I0423 09:22:11.804247 30295 solver.cpp:228] Iteration 30900, loss = 3.10719
I0423 09:22:11.804435 30295 solver.cpp:244]     Train net output #0: loss = 0.987759 (* 1 = 0.987759 loss)
I0423 09:22:11.804442 30295 solver.cpp:244]     Train net output #1: loss = 0.690048 (* 1 = 0.690048 loss)
I0423 09:22:11.804447 30295 solver.cpp:244]     Train net output #2: loss = 0.728303 (* 1 = 0.728303 loss)
I0423 09:22:11.804451 30295 solver.cpp:244]     Train net output #3: loss = 0.701084 (* 1 = 0.701084 loss)
I0423 09:22:11.804456 30295 sgd_solver.cpp:106] Iteration 30900, lr = 3e-05
I0423 09:23:51.911854 30295 solver.cpp:337] Iteration 31000, Testing net (#0)
I0423 09:23:51.914136 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 09:23:51.914141 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 09:23:51.914145 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 09:23:51.914162 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 09:23:51.914165 30295 net.cpp:693] Ignoring source layer visualize
I0423 09:23:51.914167 30295 net.cpp:693] Ignoring source layer fake
I0423 09:27:29.195966 30295 solver.cpp:404]     Test net output #0: loss = 0.973231 (* 1 = 0.973231 loss)
I0423 09:27:29.196111 30295 solver.cpp:404]     Test net output #1: loss = 0.556624 (* 1 = 0.556624 loss)
I0423 09:27:29.196117 30295 solver.cpp:404]     Test net output #2: loss = 0.814959 (* 1 = 0.814959 loss)
I0423 09:27:29.196122 30295 solver.cpp:404]     Test net output #3: loss = 0.581399 (* 1 = 0.581399 loss)
I0423 09:27:29.867334 30295 solver.cpp:228] Iteration 31000, loss = 2.61563
I0423 09:27:29.867362 30295 solver.cpp:244]     Train net output #0: loss = 0.984731 (* 1 = 0.984731 loss)
I0423 09:27:29.867368 30295 solver.cpp:244]     Train net output #1: loss = 0.508845 (* 1 = 0.508845 loss)
I0423 09:27:29.867372 30295 solver.cpp:244]     Train net output #2: loss = 0.579605 (* 1 = 0.579605 loss)
I0423 09:27:29.867377 30295 solver.cpp:244]     Train net output #3: loss = 0.542446 (* 1 = 0.542446 loss)
I0423 09:27:29.867380 30295 sgd_solver.cpp:106] Iteration 31000, lr = 3e-05
I0423 09:29:09.199030 30295 solver.cpp:228] Iteration 31100, loss = 1.92569
I0423 09:29:09.199980 30295 solver.cpp:244]     Train net output #0: loss = 0.98761 (* 1 = 0.98761 loss)
I0423 09:29:09.199987 30295 solver.cpp:244]     Train net output #1: loss = 0.338822 (* 1 = 0.338822 loss)
I0423 09:29:09.199992 30295 solver.cpp:244]     Train net output #2: loss = 0.192492 (* 1 = 0.192492 loss)
I0423 09:29:09.199996 30295 solver.cpp:244]     Train net output #3: loss = 0.406765 (* 1 = 0.406765 loss)
I0423 09:29:09.200001 30295 sgd_solver.cpp:106] Iteration 31100, lr = 3e-05
I0423 09:30:50.301424 30295 solver.cpp:228] Iteration 31200, loss = 2.99211
I0423 09:30:50.301607 30295 solver.cpp:244]     Train net output #0: loss = 0.983689 (* 1 = 0.983689 loss)
I0423 09:30:50.301615 30295 solver.cpp:244]     Train net output #1: loss = 0.515455 (* 1 = 0.515455 loss)
I0423 09:30:50.301620 30295 solver.cpp:244]     Train net output #2: loss = 0.873264 (* 1 = 0.873264 loss)
I0423 09:30:50.301625 30295 solver.cpp:244]     Train net output #3: loss = 0.619697 (* 1 = 0.619697 loss)
I0423 09:30:50.301630 30295 sgd_solver.cpp:106] Iteration 31200, lr = 3e-05
I0423 09:32:30.619352 30295 solver.cpp:228] Iteration 31300, loss = 3.06478
I0423 09:32:30.619498 30295 solver.cpp:244]     Train net output #0: loss = 0.983345 (* 1 = 0.983345 loss)
I0423 09:32:30.619505 30295 solver.cpp:244]     Train net output #1: loss = 0.729862 (* 1 = 0.729862 loss)
I0423 09:32:30.619511 30295 solver.cpp:244]     Train net output #2: loss = 0.748705 (* 1 = 0.748705 loss)
I0423 09:32:30.619515 30295 solver.cpp:244]     Train net output #3: loss = 0.602864 (* 1 = 0.602864 loss)
I0423 09:32:30.619519 30295 sgd_solver.cpp:106] Iteration 31300, lr = 3e-05
I0423 09:34:11.122668 30295 solver.cpp:228] Iteration 31400, loss = 2.79891
I0423 09:34:11.122835 30295 solver.cpp:244]     Train net output #0: loss = 0.97019 (* 1 = 0.97019 loss)
I0423 09:34:11.122843 30295 solver.cpp:244]     Train net output #1: loss = 0.510751 (* 1 = 0.510751 loss)
I0423 09:34:11.122848 30295 solver.cpp:244]     Train net output #2: loss = 0.711706 (* 1 = 0.711706 loss)
I0423 09:34:11.122853 30295 solver.cpp:244]     Train net output #3: loss = 0.606266 (* 1 = 0.606266 loss)
I0423 09:34:11.122859 30295 sgd_solver.cpp:106] Iteration 31400, lr = 3e-05
I0423 09:35:51.436322 30295 solver.cpp:228] Iteration 31500, loss = 2.31016
I0423 09:35:51.436476 30295 solver.cpp:244]     Train net output #0: loss = 0.989076 (* 1 = 0.989076 loss)
I0423 09:35:51.436484 30295 solver.cpp:244]     Train net output #1: loss = 0.47119 (* 1 = 0.47119 loss)
I0423 09:35:51.436491 30295 solver.cpp:244]     Train net output #2: loss = 0.371821 (* 1 = 0.371821 loss)
I0423 09:35:51.436494 30295 solver.cpp:244]     Train net output #3: loss = 0.478073 (* 1 = 0.478073 loss)
I0423 09:35:51.436499 30295 sgd_solver.cpp:106] Iteration 31500, lr = 3e-05
I0423 09:37:31.771806 30295 solver.cpp:228] Iteration 31600, loss = 2.62931
I0423 09:37:31.771962 30295 solver.cpp:244]     Train net output #0: loss = 0.962852 (* 1 = 0.962852 loss)
I0423 09:37:31.771970 30295 solver.cpp:244]     Train net output #1: loss = 0.315257 (* 1 = 0.315257 loss)
I0423 09:37:31.771975 30295 solver.cpp:244]     Train net output #2: loss = 0.914242 (* 1 = 0.914242 loss)
I0423 09:37:31.771980 30295 solver.cpp:244]     Train net output #3: loss = 0.436962 (* 1 = 0.436962 loss)
I0423 09:37:31.771984 30295 sgd_solver.cpp:106] Iteration 31600, lr = 3e-05
I0423 09:39:12.167398 30295 solver.cpp:228] Iteration 31700, loss = 3.23377
I0423 09:39:12.167549 30295 solver.cpp:244]     Train net output #0: loss = 0.975765 (* 1 = 0.975765 loss)
I0423 09:39:12.167557 30295 solver.cpp:244]     Train net output #1: loss = 0.73162 (* 1 = 0.73162 loss)
I0423 09:39:12.167562 30295 solver.cpp:244]     Train net output #2: loss = 0.869741 (* 1 = 0.869741 loss)
I0423 09:39:12.167567 30295 solver.cpp:244]     Train net output #3: loss = 0.656641 (* 1 = 0.656641 loss)
I0423 09:39:12.167572 30295 sgd_solver.cpp:106] Iteration 31700, lr = 3e-05
I0423 09:40:50.892987 30295 solver.cpp:228] Iteration 31800, loss = 3.2497
I0423 09:40:50.893159 30295 solver.cpp:244]     Train net output #0: loss = 0.9681 (* 1 = 0.9681 loss)
I0423 09:40:50.893167 30295 solver.cpp:244]     Train net output #1: loss = 0.715286 (* 1 = 0.715286 loss)
I0423 09:40:50.893172 30295 solver.cpp:244]     Train net output #2: loss = 0.923284 (* 1 = 0.923284 loss)
I0423 09:40:50.893177 30295 solver.cpp:244]     Train net output #3: loss = 0.643026 (* 1 = 0.643026 loss)
I0423 09:40:50.893182 30295 sgd_solver.cpp:106] Iteration 31800, lr = 3e-05
I0423 09:42:31.337828 30295 solver.cpp:228] Iteration 31900, loss = 3.03797
I0423 09:42:31.337988 30295 solver.cpp:244]     Train net output #0: loss = 0.978811 (* 1 = 0.978811 loss)
I0423 09:42:31.337996 30295 solver.cpp:244]     Train net output #1: loss = 0.684991 (* 1 = 0.684991 loss)
I0423 09:42:31.338001 30295 solver.cpp:244]     Train net output #2: loss = 0.727934 (* 1 = 0.727934 loss)
I0423 09:42:31.338006 30295 solver.cpp:244]     Train net output #3: loss = 0.646231 (* 1 = 0.646231 loss)
I0423 09:42:31.338011 30295 sgd_solver.cpp:106] Iteration 31900, lr = 3e-05
I0423 09:44:10.825103 30295 solver.cpp:337] Iteration 32000, Testing net (#0)
I0423 09:44:10.825248 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 09:44:10.825251 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 09:44:10.825254 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 09:44:10.825269 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 09:44:10.825273 30295 net.cpp:693] Ignoring source layer visualize
I0423 09:44:10.825274 30295 net.cpp:693] Ignoring source layer fake
I0423 09:47:46.065243 30295 solver.cpp:404]     Test net output #0: loss = 0.967728 (* 1 = 0.967728 loss)
I0423 09:47:46.065407 30295 solver.cpp:404]     Test net output #1: loss = 0.472878 (* 1 = 0.472878 loss)
I0423 09:47:46.065414 30295 solver.cpp:404]     Test net output #2: loss = 0.797256 (* 1 = 0.797256 loss)
I0423 09:47:46.065419 30295 solver.cpp:404]     Test net output #3: loss = 0.499773 (* 1 = 0.499773 loss)
I0423 09:47:46.725417 30295 solver.cpp:228] Iteration 32000, loss = 3.26397
I0423 09:47:46.725463 30295 solver.cpp:244]     Train net output #0: loss = 0.975065 (* 1 = 0.975065 loss)
I0423 09:47:46.725471 30295 solver.cpp:244]     Train net output #1: loss = 0.693295 (* 1 = 0.693295 loss)
I0423 09:47:46.725474 30295 solver.cpp:244]     Train net output #2: loss = 0.934847 (* 1 = 0.934847 loss)
I0423 09:47:46.725479 30295 solver.cpp:244]     Train net output #3: loss = 0.660762 (* 1 = 0.660762 loss)
I0423 09:47:46.725484 30295 sgd_solver.cpp:106] Iteration 32000, lr = 3e-05
I0423 09:49:25.773389 30295 solver.cpp:228] Iteration 32100, loss = 3.00787
I0423 09:49:25.773552 30295 solver.cpp:244]     Train net output #0: loss = 0.975392 (* 1 = 0.975392 loss)
I0423 09:49:25.773560 30295 solver.cpp:244]     Train net output #1: loss = 0.533566 (* 1 = 0.533566 loss)
I0423 09:49:25.773564 30295 solver.cpp:244]     Train net output #2: loss = 0.899927 (* 1 = 0.899927 loss)
I0423 09:49:25.773569 30295 solver.cpp:244]     Train net output #3: loss = 0.59899 (* 1 = 0.59899 loss)
I0423 09:49:25.773574 30295 sgd_solver.cpp:106] Iteration 32100, lr = 3e-05
I0423 09:51:06.382683 30295 solver.cpp:228] Iteration 32200, loss = 3.07288
I0423 09:51:06.383229 30295 solver.cpp:244]     Train net output #0: loss = 0.989568 (* 1 = 0.989568 loss)
I0423 09:51:06.383235 30295 solver.cpp:244]     Train net output #1: loss = 0.65914 (* 1 = 0.65914 loss)
I0423 09:51:06.383239 30295 solver.cpp:244]     Train net output #2: loss = 0.772136 (* 1 = 0.772136 loss)
I0423 09:51:06.383242 30295 solver.cpp:244]     Train net output #3: loss = 0.652041 (* 1 = 0.652041 loss)
I0423 09:51:06.383247 30295 sgd_solver.cpp:106] Iteration 32200, lr = 3e-05
I0423 09:52:46.995579 30295 solver.cpp:228] Iteration 32300, loss = 2.83932
I0423 09:52:46.995723 30295 solver.cpp:244]     Train net output #0: loss = 0.982395 (* 1 = 0.982395 loss)
I0423 09:52:46.995730 30295 solver.cpp:244]     Train net output #1: loss = 0.513516 (* 1 = 0.513516 loss)
I0423 09:52:46.995735 30295 solver.cpp:244]     Train net output #2: loss = 0.727949 (* 1 = 0.727949 loss)
I0423 09:52:46.995740 30295 solver.cpp:244]     Train net output #3: loss = 0.615464 (* 1 = 0.615464 loss)
I0423 09:52:46.995744 30295 sgd_solver.cpp:106] Iteration 32300, lr = 3e-05
I0423 09:54:27.437971 30295 solver.cpp:228] Iteration 32400, loss = 2.63987
I0423 09:54:27.438122 30295 solver.cpp:244]     Train net output #0: loss = 0.969265 (* 1 = 0.969265 loss)
I0423 09:54:27.438130 30295 solver.cpp:244]     Train net output #1: loss = 0.293718 (* 1 = 0.293718 loss)
I0423 09:54:27.438135 30295 solver.cpp:244]     Train net output #2: loss = 0.851614 (* 1 = 0.851614 loss)
I0423 09:54:27.438139 30295 solver.cpp:244]     Train net output #3: loss = 0.52527 (* 1 = 0.52527 loss)
I0423 09:54:27.438144 30295 sgd_solver.cpp:106] Iteration 32400, lr = 3e-05
I0423 09:56:07.512693 30295 solver.cpp:228] Iteration 32500, loss = 3.14799
I0423 09:56:07.512845 30295 solver.cpp:244]     Train net output #0: loss = 0.982743 (* 1 = 0.982743 loss)
I0423 09:56:07.512851 30295 solver.cpp:244]     Train net output #1: loss = 0.679576 (* 1 = 0.679576 loss)
I0423 09:56:07.512856 30295 solver.cpp:244]     Train net output #2: loss = 0.934307 (* 1 = 0.934307 loss)
I0423 09:56:07.512861 30295 solver.cpp:244]     Train net output #3: loss = 0.551362 (* 1 = 0.551362 loss)
I0423 09:56:07.512866 30295 sgd_solver.cpp:106] Iteration 32500, lr = 3e-05
I0423 09:57:47.758637 30295 solver.cpp:228] Iteration 32600, loss = 3.05807
I0423 09:57:47.758780 30295 solver.cpp:244]     Train net output #0: loss = 0.97262 (* 1 = 0.97262 loss)
I0423 09:57:47.758787 30295 solver.cpp:244]     Train net output #1: loss = 0.784389 (* 1 = 0.784389 loss)
I0423 09:57:47.758791 30295 solver.cpp:244]     Train net output #2: loss = 0.763433 (* 1 = 0.763433 loss)
I0423 09:57:47.758796 30295 solver.cpp:244]     Train net output #3: loss = 0.537629 (* 1 = 0.537629 loss)
I0423 09:57:47.758800 30295 sgd_solver.cpp:106] Iteration 32600, lr = 3e-05
I0423 09:59:28.228413 30295 solver.cpp:228] Iteration 32700, loss = 3.01155
I0423 09:59:28.228613 30295 solver.cpp:244]     Train net output #0: loss = 0.979836 (* 1 = 0.979836 loss)
I0423 09:59:28.228621 30295 solver.cpp:244]     Train net output #1: loss = 0.720033 (* 1 = 0.720033 loss)
I0423 09:59:28.228626 30295 solver.cpp:244]     Train net output #2: loss = 0.75 (* 1 = 0.75 loss)
I0423 09:59:28.228631 30295 solver.cpp:244]     Train net output #3: loss = 0.561685 (* 1 = 0.561685 loss)
I0423 09:59:28.228636 30295 sgd_solver.cpp:106] Iteration 32700, lr = 3e-05
I0423 10:01:07.307585 30295 solver.cpp:228] Iteration 32800, loss = 2.93351
I0423 10:01:07.308084 30295 solver.cpp:244]     Train net output #0: loss = 0.965352 (* 1 = 0.965352 loss)
I0423 10:01:07.308092 30295 solver.cpp:244]     Train net output #1: loss = 0.649585 (* 1 = 0.649585 loss)
I0423 10:01:07.308096 30295 solver.cpp:244]     Train net output #2: loss = 0.75879 (* 1 = 0.75879 loss)
I0423 10:01:07.308101 30295 solver.cpp:244]     Train net output #3: loss = 0.559787 (* 1 = 0.559787 loss)
I0423 10:01:07.308105 30295 sgd_solver.cpp:106] Iteration 32800, lr = 3e-05
I0423 10:02:47.900502 30295 solver.cpp:228] Iteration 32900, loss = 3.13999
I0423 10:02:47.900653 30295 solver.cpp:244]     Train net output #0: loss = 0.979781 (* 1 = 0.979781 loss)
I0423 10:02:47.900661 30295 solver.cpp:244]     Train net output #1: loss = 0.782072 (* 1 = 0.782072 loss)
I0423 10:02:47.900665 30295 solver.cpp:244]     Train net output #2: loss = 0.634037 (* 1 = 0.634037 loss)
I0423 10:02:47.900671 30295 solver.cpp:244]     Train net output #3: loss = 0.744096 (* 1 = 0.744096 loss)
I0423 10:02:47.900676 30295 sgd_solver.cpp:106] Iteration 32900, lr = 3e-05
I0423 10:04:27.666633 30295 solver.cpp:337] Iteration 33000, Testing net (#0)
I0423 10:04:27.666798 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 10:04:27.666803 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 10:04:27.666806 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 10:04:27.666821 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 10:04:27.666824 30295 net.cpp:693] Ignoring source layer visualize
I0423 10:04:27.666826 30295 net.cpp:693] Ignoring source layer fake
I0423 10:08:03.098201 30295 solver.cpp:404]     Test net output #0: loss = 0.973871 (* 1 = 0.973871 loss)
I0423 10:08:03.098505 30295 solver.cpp:404]     Test net output #1: loss = 0.451798 (* 1 = 0.451798 loss)
I0423 10:08:03.098512 30295 solver.cpp:404]     Test net output #2: loss = 0.772709 (* 1 = 0.772709 loss)
I0423 10:08:03.098518 30295 solver.cpp:404]     Test net output #3: loss = 0.456111 (* 1 = 0.456111 loss)
I0423 10:08:03.761087 30295 solver.cpp:228] Iteration 33000, loss = 3.30155
I0423 10:08:03.761128 30295 solver.cpp:244]     Train net output #0: loss = 0.961228 (* 1 = 0.961228 loss)
I0423 10:08:03.761134 30295 solver.cpp:244]     Train net output #1: loss = 0.72206 (* 1 = 0.72206 loss)
I0423 10:08:03.761138 30295 solver.cpp:244]     Train net output #2: loss = 0.939555 (* 1 = 0.939555 loss)
I0423 10:08:03.761142 30295 solver.cpp:244]     Train net output #3: loss = 0.678712 (* 1 = 0.678712 loss)
I0423 10:08:03.761145 30295 sgd_solver.cpp:106] Iteration 33000, lr = 3e-05
I0423 10:09:44.436375 30295 solver.cpp:228] Iteration 33100, loss = 3.24214
I0423 10:09:44.436511 30295 solver.cpp:244]     Train net output #0: loss = 0.971799 (* 1 = 0.971799 loss)
I0423 10:09:44.436518 30295 solver.cpp:244]     Train net output #1: loss = 0.752877 (* 1 = 0.752877 loss)
I0423 10:09:44.436523 30295 solver.cpp:244]     Train net output #2: loss = 0.905983 (* 1 = 0.905983 loss)
I0423 10:09:44.436527 30295 solver.cpp:244]     Train net output #3: loss = 0.611485 (* 1 = 0.611485 loss)
I0423 10:09:44.436533 30295 sgd_solver.cpp:106] Iteration 33100, lr = 3e-05
I0423 10:11:23.496237 30295 solver.cpp:228] Iteration 33200, loss = 3.11313
I0423 10:11:23.496424 30295 solver.cpp:244]     Train net output #0: loss = 0.987502 (* 1 = 0.987502 loss)
I0423 10:11:23.496431 30295 solver.cpp:244]     Train net output #1: loss = 0.71957 (* 1 = 0.71957 loss)
I0423 10:11:23.496438 30295 solver.cpp:244]     Train net output #2: loss = 0.737537 (* 1 = 0.737537 loss)
I0423 10:11:23.496441 30295 solver.cpp:244]     Train net output #3: loss = 0.668522 (* 1 = 0.668522 loss)
I0423 10:11:23.496446 30295 sgd_solver.cpp:106] Iteration 33200, lr = 3e-05
I0423 10:13:04.261708 30295 solver.cpp:228] Iteration 33300, loss = 3.09784
I0423 10:13:04.261867 30295 solver.cpp:244]     Train net output #0: loss = 0.974707 (* 1 = 0.974707 loss)
I0423 10:13:04.261873 30295 solver.cpp:244]     Train net output #1: loss = 0.582462 (* 1 = 0.582462 loss)
I0423 10:13:04.261878 30295 solver.cpp:244]     Train net output #2: loss = 0.89806 (* 1 = 0.89806 loss)
I0423 10:13:04.261883 30295 solver.cpp:244]     Train net output #3: loss = 0.642611 (* 1 = 0.642611 loss)
I0423 10:13:04.261888 30295 sgd_solver.cpp:106] Iteration 33300, lr = 3e-05
I0423 10:14:45.051095 30295 solver.cpp:228] Iteration 33400, loss = 2.90866
I0423 10:14:45.051242 30295 solver.cpp:244]     Train net output #0: loss = 0.987836 (* 1 = 0.987836 loss)
I0423 10:14:45.051249 30295 solver.cpp:244]     Train net output #1: loss = 0.537722 (* 1 = 0.537722 loss)
I0423 10:14:45.051255 30295 solver.cpp:244]     Train net output #2: loss = 0.776309 (* 1 = 0.776309 loss)
I0423 10:14:45.051259 30295 solver.cpp:244]     Train net output #3: loss = 0.606795 (* 1 = 0.606795 loss)
I0423 10:14:45.051265 30295 sgd_solver.cpp:106] Iteration 33400, lr = 3e-05
I0423 10:16:26.051517 30295 solver.cpp:228] Iteration 33500, loss = 2.62539
I0423 10:16:26.052948 30295 solver.cpp:244]     Train net output #0: loss = 0.99295 (* 1 = 0.99295 loss)
I0423 10:16:26.052956 30295 solver.cpp:244]     Train net output #1: loss = 0.435771 (* 1 = 0.435771 loss)
I0423 10:16:26.052961 30295 solver.cpp:244]     Train net output #2: loss = 0.575497 (* 1 = 0.575497 loss)
I0423 10:16:26.052965 30295 solver.cpp:244]     Train net output #3: loss = 0.621174 (* 1 = 0.621174 loss)
I0423 10:16:26.052986 30295 sgd_solver.cpp:106] Iteration 33500, lr = 3e-05
I0423 10:18:05.022433 30295 solver.cpp:228] Iteration 33600, loss = 2.46964
I0423 10:18:05.022580 30295 solver.cpp:244]     Train net output #0: loss = 0.989744 (* 1 = 0.989744 loss)
I0423 10:18:05.022588 30295 solver.cpp:244]     Train net output #1: loss = 0.390581 (* 1 = 0.390581 loss)
I0423 10:18:05.022593 30295 solver.cpp:244]     Train net output #2: loss = 0.54601 (* 1 = 0.54601 loss)
I0423 10:18:05.022598 30295 solver.cpp:244]     Train net output #3: loss = 0.543305 (* 1 = 0.543305 loss)
I0423 10:18:05.022603 30295 sgd_solver.cpp:106] Iteration 33600, lr = 3e-05
I0423 10:19:47.599840 30295 solver.cpp:228] Iteration 33700, loss = 2.89799
I0423 10:19:47.599995 30295 solver.cpp:244]     Train net output #0: loss = 0.992982 (* 1 = 0.992982 loss)
I0423 10:19:47.600003 30295 solver.cpp:244]     Train net output #1: loss = 0.452762 (* 1 = 0.452762 loss)
I0423 10:19:47.600008 30295 solver.cpp:244]     Train net output #2: loss = 0.829219 (* 1 = 0.829219 loss)
I0423 10:19:47.600013 30295 solver.cpp:244]     Train net output #3: loss = 0.623028 (* 1 = 0.623028 loss)
I0423 10:19:47.600018 30295 sgd_solver.cpp:106] Iteration 33700, lr = 3e-05
I0423 10:21:28.507483 30295 solver.cpp:228] Iteration 33800, loss = 3.01177
I0423 10:21:28.507647 30295 solver.cpp:244]     Train net output #0: loss = 0.982036 (* 1 = 0.982036 loss)
I0423 10:21:28.507654 30295 solver.cpp:244]     Train net output #1: loss = 0.698563 (* 1 = 0.698563 loss)
I0423 10:21:28.507660 30295 solver.cpp:244]     Train net output #2: loss = 0.75511 (* 1 = 0.75511 loss)
I0423 10:21:28.507664 30295 solver.cpp:244]     Train net output #3: loss = 0.576064 (* 1 = 0.576064 loss)
I0423 10:21:28.507669 30295 sgd_solver.cpp:106] Iteration 33800, lr = 3e-05
I0423 10:23:08.582973 30295 solver.cpp:228] Iteration 33900, loss = 3.04211
I0423 10:23:08.583160 30295 solver.cpp:244]     Train net output #0: loss = 0.968087 (* 1 = 0.968087 loss)
I0423 10:23:08.583168 30295 solver.cpp:244]     Train net output #1: loss = 0.519942 (* 1 = 0.519942 loss)
I0423 10:23:08.583173 30295 solver.cpp:244]     Train net output #2: loss = 0.911188 (* 1 = 0.911188 loss)
I0423 10:23:08.583178 30295 solver.cpp:244]     Train net output #3: loss = 0.642894 (* 1 = 0.642894 loss)
I0423 10:23:08.583183 30295 sgd_solver.cpp:106] Iteration 33900, lr = 3e-05
I0423 10:24:49.256968 30295 solver.cpp:337] Iteration 34000, Testing net (#0)
I0423 10:24:49.257117 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 10:24:49.257120 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 10:24:49.257124 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 10:24:49.257138 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 10:24:49.257141 30295 net.cpp:693] Ignoring source layer visualize
I0423 10:24:49.257143 30295 net.cpp:693] Ignoring source layer fake
I0423 10:28:24.401139 30295 solver.cpp:404]     Test net output #0: loss = 0.973444 (* 1 = 0.973444 loss)
I0423 10:28:24.401293 30295 solver.cpp:404]     Test net output #1: loss = 0.51632 (* 1 = 0.51632 loss)
I0423 10:28:24.401300 30295 solver.cpp:404]     Test net output #2: loss = 0.8098 (* 1 = 0.8098 loss)
I0423 10:28:24.401305 30295 solver.cpp:404]     Test net output #3: loss = 0.569806 (* 1 = 0.569806 loss)
I0423 10:28:25.058291 30295 solver.cpp:228] Iteration 34000, loss = 2.78353
I0423 10:28:25.058316 30295 solver.cpp:244]     Train net output #0: loss = 0.967932 (* 1 = 0.967932 loss)
I0423 10:28:25.058338 30295 solver.cpp:244]     Train net output #1: loss = 0.486765 (* 1 = 0.486765 loss)
I0423 10:28:25.058342 30295 solver.cpp:244]     Train net output #2: loss = 0.755737 (* 1 = 0.755737 loss)
I0423 10:28:25.058346 30295 solver.cpp:244]     Train net output #3: loss = 0.573097 (* 1 = 0.573097 loss)
I0423 10:28:25.058351 30295 sgd_solver.cpp:106] Iteration 34000, lr = 3e-05
I0423 10:30:07.745033 30295 solver.cpp:228] Iteration 34100, loss = 3.16325
I0423 10:30:07.745195 30295 solver.cpp:244]     Train net output #0: loss = 0.95817 (* 1 = 0.95817 loss)
I0423 10:30:07.745213 30295 solver.cpp:244]     Train net output #1: loss = 0.669871 (* 1 = 0.669871 loss)
I0423 10:30:07.745218 30295 solver.cpp:244]     Train net output #2: loss = 0.866655 (* 1 = 0.866655 loss)
I0423 10:30:07.745223 30295 solver.cpp:244]     Train net output #3: loss = 0.668551 (* 1 = 0.668551 loss)
I0423 10:30:07.745226 30295 sgd_solver.cpp:106] Iteration 34100, lr = 3e-05
I0423 10:31:48.838109 30295 solver.cpp:228] Iteration 34200, loss = 3.21681
I0423 10:31:48.838246 30295 solver.cpp:244]     Train net output #0: loss = 0.969464 (* 1 = 0.969464 loss)
I0423 10:31:48.838253 30295 solver.cpp:244]     Train net output #1: loss = 0.687696 (* 1 = 0.687696 loss)
I0423 10:31:48.838258 30295 solver.cpp:244]     Train net output #2: loss = 0.890846 (* 1 = 0.890846 loss)
I0423 10:31:48.838263 30295 solver.cpp:244]     Train net output #3: loss = 0.668804 (* 1 = 0.668804 loss)
I0423 10:31:48.838268 30295 sgd_solver.cpp:106] Iteration 34200, lr = 3e-05
I0423 10:33:27.712756 30295 solver.cpp:228] Iteration 34300, loss = 3.23083
I0423 10:33:27.712905 30295 solver.cpp:244]     Train net output #0: loss = 0.973037 (* 1 = 0.973037 loss)
I0423 10:33:27.712913 30295 solver.cpp:244]     Train net output #1: loss = 0.731918 (* 1 = 0.731918 loss)
I0423 10:33:27.712918 30295 solver.cpp:244]     Train net output #2: loss = 0.884934 (* 1 = 0.884934 loss)
I0423 10:33:27.712923 30295 solver.cpp:244]     Train net output #3: loss = 0.640938 (* 1 = 0.640938 loss)
I0423 10:33:27.712927 30295 sgd_solver.cpp:106] Iteration 34300, lr = 3e-05
I0423 10:35:09.279570 30295 solver.cpp:228] Iteration 34400, loss = 3.01124
I0423 10:35:09.279768 30295 solver.cpp:244]     Train net output #0: loss = 0.976854 (* 1 = 0.976854 loss)
I0423 10:35:09.279777 30295 solver.cpp:244]     Train net output #1: loss = 0.644247 (* 1 = 0.644247 loss)
I0423 10:35:09.279781 30295 solver.cpp:244]     Train net output #2: loss = 0.847513 (* 1 = 0.847513 loss)
I0423 10:35:09.279788 30295 solver.cpp:244]     Train net output #3: loss = 0.542625 (* 1 = 0.542625 loss)
I0423 10:35:09.279793 30295 sgd_solver.cpp:106] Iteration 34400, lr = 3e-05
I0423 10:36:50.191632 30295 solver.cpp:228] Iteration 34500, loss = 3.00992
I0423 10:36:50.191821 30295 solver.cpp:244]     Train net output #0: loss = 0.968454 (* 1 = 0.968454 loss)
I0423 10:36:50.191830 30295 solver.cpp:244]     Train net output #1: loss = 0.571314 (* 1 = 0.571314 loss)
I0423 10:36:50.191835 30295 solver.cpp:244]     Train net output #2: loss = 0.865248 (* 1 = 0.865248 loss)
I0423 10:36:50.191839 30295 solver.cpp:244]     Train net output #3: loss = 0.604903 (* 1 = 0.604903 loss)
I0423 10:36:50.191844 30295 sgd_solver.cpp:106] Iteration 34500, lr = 3e-05
I0423 10:38:29.074718 30295 solver.cpp:228] Iteration 34600, loss = 3.27838
I0423 10:38:29.074859 30295 solver.cpp:244]     Train net output #0: loss = 0.987733 (* 1 = 0.987733 loss)
I0423 10:38:29.074867 30295 solver.cpp:244]     Train net output #1: loss = 0.655945 (* 1 = 0.655945 loss)
I0423 10:38:29.074872 30295 solver.cpp:244]     Train net output #2: loss = 0.942873 (* 1 = 0.942873 loss)
I0423 10:38:29.074877 30295 solver.cpp:244]     Train net output #3: loss = 0.691833 (* 1 = 0.691833 loss)
I0423 10:38:29.074882 30295 sgd_solver.cpp:106] Iteration 34600, lr = 3e-05
I0423 10:40:09.628206 30295 solver.cpp:228] Iteration 34700, loss = 3.3575
I0423 10:40:09.628386 30295 solver.cpp:244]     Train net output #0: loss = 0.987028 (* 1 = 0.987028 loss)
I0423 10:40:09.628393 30295 solver.cpp:244]     Train net output #1: loss = 0.731053 (* 1 = 0.731053 loss)
I0423 10:40:09.628398 30295 solver.cpp:244]     Train net output #2: loss = 0.911696 (* 1 = 0.911696 loss)
I0423 10:40:09.628403 30295 solver.cpp:244]     Train net output #3: loss = 0.72772 (* 1 = 0.72772 loss)
I0423 10:40:09.628408 30295 sgd_solver.cpp:106] Iteration 34700, lr = 3e-05
I0423 10:41:50.352552 30295 solver.cpp:228] Iteration 34800, loss = 2.35603
I0423 10:41:50.352705 30295 solver.cpp:244]     Train net output #0: loss = 0.971785 (* 1 = 0.971785 loss)
I0423 10:41:50.352713 30295 solver.cpp:244]     Train net output #1: loss = 0.406528 (* 1 = 0.406528 loss)
I0423 10:41:50.352717 30295 solver.cpp:244]     Train net output #2: loss = 0.560287 (* 1 = 0.560287 loss)
I0423 10:41:50.352722 30295 solver.cpp:244]     Train net output #3: loss = 0.417427 (* 1 = 0.417427 loss)
I0423 10:41:50.352727 30295 sgd_solver.cpp:106] Iteration 34800, lr = 3e-05
I0423 10:43:30.699017 30295 solver.cpp:228] Iteration 34900, loss = 2.81558
I0423 10:43:30.699184 30295 solver.cpp:244]     Train net output #0: loss = 0.979923 (* 1 = 0.979923 loss)
I0423 10:43:30.699193 30295 solver.cpp:244]     Train net output #1: loss = 0.396553 (* 1 = 0.396553 loss)
I0423 10:43:30.699198 30295 solver.cpp:244]     Train net output #2: loss = 0.862872 (* 1 = 0.862872 loss)
I0423 10:43:30.699203 30295 solver.cpp:244]     Train net output #3: loss = 0.576229 (* 1 = 0.576229 loss)
I0423 10:43:30.699206 30295 sgd_solver.cpp:106] Iteration 34900, lr = 3e-05
I0423 10:45:10.064812 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_35000.caffemodel
I0423 10:45:31.860689 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_35000.solverstate
I0423 10:45:32.067028 30295 solver.cpp:337] Iteration 35000, Testing net (#0)
I0423 10:45:32.067066 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 10:45:32.067070 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 10:45:32.067073 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 10:45:32.067086 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 10:45:32.067090 30295 net.cpp:693] Ignoring source layer visualize
I0423 10:45:32.067091 30295 net.cpp:693] Ignoring source layer fake
I0423 10:49:08.291882 30295 solver.cpp:404]     Test net output #0: loss = 0.976105 (* 1 = 0.976105 loss)
I0423 10:49:08.292043 30295 solver.cpp:404]     Test net output #1: loss = 0.541677 (* 1 = 0.541677 loss)
I0423 10:49:08.292050 30295 solver.cpp:404]     Test net output #2: loss = 0.804802 (* 1 = 0.804802 loss)
I0423 10:49:08.292055 30295 solver.cpp:404]     Test net output #3: loss = 0.567108 (* 1 = 0.567108 loss)
I0423 10:49:09.601523 30295 solver.cpp:228] Iteration 35000, loss = 3.13674
I0423 10:49:09.601565 30295 solver.cpp:244]     Train net output #0: loss = 0.970237 (* 1 = 0.970237 loss)
I0423 10:49:09.601570 30295 solver.cpp:244]     Train net output #1: loss = 0.728581 (* 1 = 0.728581 loss)
I0423 10:49:09.601574 30295 solver.cpp:244]     Train net output #2: loss = 0.751781 (* 1 = 0.751781 loss)
I0423 10:49:09.601578 30295 solver.cpp:244]     Train net output #3: loss = 0.686144 (* 1 = 0.686144 loss)
I0423 10:49:09.601584 30295 sgd_solver.cpp:106] Iteration 35000, lr = 3e-05
I0423 10:50:51.076362 30295 solver.cpp:228] Iteration 35100, loss = 3.20973
I0423 10:50:51.076496 30295 solver.cpp:244]     Train net output #0: loss = 0.96611 (* 1 = 0.96611 loss)
I0423 10:50:51.076503 30295 solver.cpp:244]     Train net output #1: loss = 0.597202 (* 1 = 0.597202 loss)
I0423 10:50:51.076508 30295 solver.cpp:244]     Train net output #2: loss = 0.951571 (* 1 = 0.951571 loss)
I0423 10:50:51.076512 30295 solver.cpp:244]     Train net output #3: loss = 0.694843 (* 1 = 0.694843 loss)
I0423 10:50:51.076519 30295 sgd_solver.cpp:106] Iteration 35100, lr = 3e-05
I0423 10:52:32.186308 30295 solver.cpp:228] Iteration 35200, loss = 3.31864
I0423 10:52:32.187909 30295 solver.cpp:244]     Train net output #0: loss = 0.974347 (* 1 = 0.974347 loss)
I0423 10:52:32.187917 30295 solver.cpp:244]     Train net output #1: loss = 0.681102 (* 1 = 0.681102 loss)
I0423 10:52:32.187922 30295 solver.cpp:244]     Train net output #2: loss = 0.951966 (* 1 = 0.951966 loss)
I0423 10:52:32.187927 30295 solver.cpp:244]     Train net output #3: loss = 0.711223 (* 1 = 0.711223 loss)
I0423 10:52:32.187930 30295 sgd_solver.cpp:106] Iteration 35200, lr = 3e-05
I0423 10:54:11.799818 30295 solver.cpp:228] Iteration 35300, loss = 2.90554
I0423 10:54:11.799965 30295 solver.cpp:244]     Train net output #0: loss = 0.977574 (* 1 = 0.977574 loss)
I0423 10:54:11.799973 30295 solver.cpp:244]     Train net output #1: loss = 0.530041 (* 1 = 0.530041 loss)
I0423 10:54:11.799978 30295 solver.cpp:244]     Train net output #2: loss = 0.769211 (* 1 = 0.769211 loss)
I0423 10:54:11.799983 30295 solver.cpp:244]     Train net output #3: loss = 0.628719 (* 1 = 0.628719 loss)
I0423 10:54:11.799988 30295 sgd_solver.cpp:106] Iteration 35300, lr = 3e-05
I0423 10:55:53.218921 30295 solver.cpp:228] Iteration 35400, loss = 3.10839
I0423 10:55:53.219087 30295 solver.cpp:244]     Train net output #0: loss = 0.979927 (* 1 = 0.979927 loss)
I0423 10:55:53.219095 30295 solver.cpp:244]     Train net output #1: loss = 0.791197 (* 1 = 0.791197 loss)
I0423 10:55:53.219101 30295 solver.cpp:244]     Train net output #2: loss = 0.627186 (* 1 = 0.627186 loss)
I0423 10:55:53.219105 30295 solver.cpp:244]     Train net output #3: loss = 0.710076 (* 1 = 0.710076 loss)
I0423 10:55:53.219110 30295 sgd_solver.cpp:106] Iteration 35400, lr = 3e-05
I0423 10:57:35.744287 30295 solver.cpp:228] Iteration 35500, loss = 3.24308
I0423 10:57:35.744429 30295 solver.cpp:244]     Train net output #0: loss = 0.969306 (* 1 = 0.969306 loss)
I0423 10:57:35.744437 30295 solver.cpp:244]     Train net output #1: loss = 0.747208 (* 1 = 0.747208 loss)
I0423 10:57:35.744441 30295 solver.cpp:244]     Train net output #2: loss = 0.936226 (* 1 = 0.936226 loss)
I0423 10:57:35.744446 30295 solver.cpp:244]     Train net output #3: loss = 0.590344 (* 1 = 0.590344 loss)
I0423 10:57:35.744451 30295 sgd_solver.cpp:106] Iteration 35500, lr = 3e-05
I0423 10:59:19.664366 30295 solver.cpp:228] Iteration 35600, loss = 3.41655
I0423 10:59:19.664559 30295 solver.cpp:244]     Train net output #0: loss = 0.982803 (* 1 = 0.982803 loss)
I0423 10:59:19.664567 30295 solver.cpp:244]     Train net output #1: loss = 0.853681 (* 1 = 0.853681 loss)
I0423 10:59:19.664572 30295 solver.cpp:244]     Train net output #2: loss = 0.921991 (* 1 = 0.921991 loss)
I0423 10:59:19.664577 30295 solver.cpp:244]     Train net output #3: loss = 0.658075 (* 1 = 0.658075 loss)
I0423 10:59:19.664582 30295 sgd_solver.cpp:106] Iteration 35600, lr = 3e-05
I0423 11:00:59.225998 30295 solver.cpp:228] Iteration 35700, loss = 2.94844
I0423 11:00:59.226143 30295 solver.cpp:244]     Train net output #0: loss = 0.982199 (* 1 = 0.982199 loss)
I0423 11:00:59.226150 30295 solver.cpp:244]     Train net output #1: loss = 0.673719 (* 1 = 0.673719 loss)
I0423 11:00:59.226155 30295 solver.cpp:244]     Train net output #2: loss = 0.70337 (* 1 = 0.70337 loss)
I0423 11:00:59.226160 30295 solver.cpp:244]     Train net output #3: loss = 0.589155 (* 1 = 0.589155 loss)
I0423 11:00:59.226164 30295 sgd_solver.cpp:106] Iteration 35700, lr = 3e-05
I0423 11:02:41.725525 30295 solver.cpp:228] Iteration 35800, loss = 3.10022
I0423 11:02:41.725689 30295 solver.cpp:244]     Train net output #0: loss = 0.983567 (* 1 = 0.983567 loss)
I0423 11:02:41.725697 30295 solver.cpp:244]     Train net output #1: loss = 0.599953 (* 1 = 0.599953 loss)
I0423 11:02:41.725703 30295 solver.cpp:244]     Train net output #2: loss = 0.894456 (* 1 = 0.894456 loss)
I0423 11:02:41.725708 30295 solver.cpp:244]     Train net output #3: loss = 0.622242 (* 1 = 0.622242 loss)
I0423 11:02:41.725713 30295 sgd_solver.cpp:106] Iteration 35800, lr = 3e-05
I0423 11:04:24.152426 30295 solver.cpp:228] Iteration 35900, loss = 3.17758
I0423 11:04:24.152576 30295 solver.cpp:244]     Train net output #0: loss = 0.984778 (* 1 = 0.984778 loss)
I0423 11:04:24.152585 30295 solver.cpp:244]     Train net output #1: loss = 0.714254 (* 1 = 0.714254 loss)
I0423 11:04:24.152588 30295 solver.cpp:244]     Train net output #2: loss = 0.768126 (* 1 = 0.768126 loss)
I0423 11:04:24.152593 30295 solver.cpp:244]     Train net output #3: loss = 0.710425 (* 1 = 0.710425 loss)
I0423 11:04:24.152598 30295 sgd_solver.cpp:106] Iteration 35900, lr = 3e-05
I0423 11:06:04.774971 30295 solver.cpp:337] Iteration 36000, Testing net (#0)
I0423 11:06:04.775116 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 11:06:04.775121 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 11:06:04.775125 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 11:06:04.775140 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 11:06:04.775142 30295 net.cpp:693] Ignoring source layer visualize
I0423 11:06:04.775144 30295 net.cpp:693] Ignoring source layer fake
I0423 11:09:41.780228 30295 solver.cpp:404]     Test net output #0: loss = 0.974624 (* 1 = 0.974624 loss)
I0423 11:09:41.780366 30295 solver.cpp:404]     Test net output #1: loss = 0.570399 (* 1 = 0.570399 loss)
I0423 11:09:41.780374 30295 solver.cpp:404]     Test net output #2: loss = 0.818075 (* 1 = 0.818075 loss)
I0423 11:09:41.780378 30295 solver.cpp:404]     Test net output #3: loss = 0.590984 (* 1 = 0.590984 loss)
I0423 11:09:42.464520 30295 solver.cpp:228] Iteration 36000, loss = 2.82036
I0423 11:09:42.464562 30295 solver.cpp:244]     Train net output #0: loss = 0.988122 (* 1 = 0.988122 loss)
I0423 11:09:42.464567 30295 solver.cpp:244]     Train net output #1: loss = 0.442252 (* 1 = 0.442252 loss)
I0423 11:09:42.464571 30295 solver.cpp:244]     Train net output #2: loss = 0.741933 (* 1 = 0.741933 loss)
I0423 11:09:42.464576 30295 solver.cpp:244]     Train net output #3: loss = 0.648057 (* 1 = 0.648057 loss)
I0423 11:09:42.464582 30295 sgd_solver.cpp:106] Iteration 36000, lr = 3e-05
I0423 11:11:21.902287 30295 solver.cpp:228] Iteration 36100, loss = 3.01334
I0423 11:11:21.902438 30295 solver.cpp:244]     Train net output #0: loss = 0.986337 (* 1 = 0.986337 loss)
I0423 11:11:21.902446 30295 solver.cpp:244]     Train net output #1: loss = 0.469895 (* 1 = 0.469895 loss)
I0423 11:11:21.902451 30295 solver.cpp:244]     Train net output #2: loss = 0.931307 (* 1 = 0.931307 loss)
I0423 11:11:21.902456 30295 solver.cpp:244]     Train net output #3: loss = 0.625801 (* 1 = 0.625801 loss)
I0423 11:11:21.902460 30295 sgd_solver.cpp:106] Iteration 36100, lr = 3e-05
I0423 11:13:03.158596 30295 solver.cpp:228] Iteration 36200, loss = 2.60884
I0423 11:13:03.158774 30295 solver.cpp:244]     Train net output #0: loss = 0.990919 (* 1 = 0.990919 loss)
I0423 11:13:03.158782 30295 solver.cpp:244]     Train net output #1: loss = 0.377874 (* 1 = 0.377874 loss)
I0423 11:13:03.158787 30295 solver.cpp:244]     Train net output #2: loss = 0.753492 (* 1 = 0.753492 loss)
I0423 11:13:03.158792 30295 solver.cpp:244]     Train net output #3: loss = 0.486553 (* 1 = 0.486553 loss)
I0423 11:13:03.158797 30295 sgd_solver.cpp:106] Iteration 36200, lr = 3e-05
I0423 11:14:43.780122 30295 solver.cpp:228] Iteration 36300, loss = 3.15824
I0423 11:14:43.780297 30295 solver.cpp:244]     Train net output #0: loss = 0.976721 (* 1 = 0.976721 loss)
I0423 11:14:43.780304 30295 solver.cpp:244]     Train net output #1: loss = 0.677053 (* 1 = 0.677053 loss)
I0423 11:14:43.780309 30295 solver.cpp:244]     Train net output #2: loss = 0.950352 (* 1 = 0.950352 loss)
I0423 11:14:43.780313 30295 solver.cpp:244]     Train net output #3: loss = 0.554115 (* 1 = 0.554115 loss)
I0423 11:14:43.780318 30295 sgd_solver.cpp:106] Iteration 36300, lr = 3e-05
I0423 11:16:24.834833 30295 solver.cpp:228] Iteration 36400, loss = 2.97669
I0423 11:16:24.835007 30295 solver.cpp:244]     Train net output #0: loss = 0.962432 (* 1 = 0.962432 loss)
I0423 11:16:24.835014 30295 solver.cpp:244]     Train net output #1: loss = 0.702642 (* 1 = 0.702642 loss)
I0423 11:16:24.835019 30295 solver.cpp:244]     Train net output #2: loss = 0.641407 (* 1 = 0.641407 loss)
I0423 11:16:24.835024 30295 solver.cpp:244]     Train net output #3: loss = 0.670204 (* 1 = 0.670204 loss)
I0423 11:16:24.835029 30295 sgd_solver.cpp:106] Iteration 36400, lr = 3e-05
I0423 11:18:05.968379 30295 solver.cpp:228] Iteration 36500, loss = 2.66531
I0423 11:18:05.968533 30295 solver.cpp:244]     Train net output #0: loss = 0.976472 (* 1 = 0.976472 loss)
I0423 11:18:05.968541 30295 solver.cpp:244]     Train net output #1: loss = 0.528035 (* 1 = 0.528035 loss)
I0423 11:18:05.968545 30295 solver.cpp:244]     Train net output #2: loss = 0.570762 (* 1 = 0.570762 loss)
I0423 11:18:05.968550 30295 solver.cpp:244]     Train net output #3: loss = 0.590041 (* 1 = 0.590041 loss)
I0423 11:18:05.968554 30295 sgd_solver.cpp:106] Iteration 36500, lr = 3e-05
I0423 11:19:47.124127 30295 solver.cpp:228] Iteration 36600, loss = 3.21182
I0423 11:19:47.125569 30295 solver.cpp:244]     Train net output #0: loss = 0.967314 (* 1 = 0.967314 loss)
I0423 11:19:47.125577 30295 solver.cpp:244]     Train net output #1: loss = 0.695042 (* 1 = 0.695042 loss)
I0423 11:19:47.125582 30295 solver.cpp:244]     Train net output #2: loss = 0.889404 (* 1 = 0.889404 loss)
I0423 11:19:47.125586 30295 solver.cpp:244]     Train net output #3: loss = 0.660064 (* 1 = 0.660064 loss)
I0423 11:19:47.125591 30295 sgd_solver.cpp:106] Iteration 36600, lr = 3e-05
I0423 11:21:28.314635 30295 solver.cpp:228] Iteration 36700, loss = 3.2579
I0423 11:21:28.314798 30295 solver.cpp:244]     Train net output #0: loss = 0.961518 (* 1 = 0.961518 loss)
I0423 11:21:28.314806 30295 solver.cpp:244]     Train net output #1: loss = 0.722304 (* 1 = 0.722304 loss)
I0423 11:21:28.314810 30295 solver.cpp:244]     Train net output #2: loss = 0.906139 (* 1 = 0.906139 loss)
I0423 11:21:28.314815 30295 solver.cpp:244]     Train net output #3: loss = 0.667943 (* 1 = 0.667943 loss)
I0423 11:21:28.314820 30295 sgd_solver.cpp:106] Iteration 36700, lr = 3e-05
I0423 11:23:07.892295 30295 solver.cpp:228] Iteration 36800, loss = 3.09173
I0423 11:23:07.892448 30295 solver.cpp:244]     Train net output #0: loss = 0.970929 (* 1 = 0.970929 loss)
I0423 11:23:07.892455 30295 solver.cpp:244]     Train net output #1: loss = 0.739456 (* 1 = 0.739456 loss)
I0423 11:23:07.892460 30295 solver.cpp:244]     Train net output #2: loss = 0.82852 (* 1 = 0.82852 loss)
I0423 11:23:07.892465 30295 solver.cpp:244]     Train net output #3: loss = 0.552822 (* 1 = 0.552822 loss)
I0423 11:23:07.892470 30295 sgd_solver.cpp:106] Iteration 36800, lr = 3e-05
I0423 11:24:49.516924 30295 solver.cpp:228] Iteration 36900, loss = 2.93844
I0423 11:24:49.517107 30295 solver.cpp:244]     Train net output #0: loss = 0.984858 (* 1 = 0.984858 loss)
I0423 11:24:49.517115 30295 solver.cpp:244]     Train net output #1: loss = 0.599513 (* 1 = 0.599513 loss)
I0423 11:24:49.517120 30295 solver.cpp:244]     Train net output #2: loss = 0.870439 (* 1 = 0.870439 loss)
I0423 11:24:49.517124 30295 solver.cpp:244]     Train net output #3: loss = 0.483627 (* 1 = 0.483627 loss)
I0423 11:24:49.517128 30295 sgd_solver.cpp:106] Iteration 36900, lr = 3e-05
I0423 11:26:30.083214 30295 solver.cpp:337] Iteration 37000, Testing net (#0)
I0423 11:26:30.083359 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 11:26:30.083362 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 11:26:30.083366 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 11:26:30.083381 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 11:26:30.083384 30295 net.cpp:693] Ignoring source layer visualize
I0423 11:26:30.083386 30295 net.cpp:693] Ignoring source layer fake
I0423 11:30:07.636657 30295 solver.cpp:404]     Test net output #0: loss = 0.964643 (* 1 = 0.964643 loss)
I0423 11:30:07.636811 30295 solver.cpp:404]     Test net output #1: loss = 0.438531 (* 1 = 0.438531 loss)
I0423 11:30:07.636817 30295 solver.cpp:404]     Test net output #2: loss = 0.787018 (* 1 = 0.787018 loss)
I0423 11:30:07.636822 30295 solver.cpp:404]     Test net output #3: loss = 0.471923 (* 1 = 0.471923 loss)
I0423 11:30:08.296617 30295 solver.cpp:228] Iteration 37000, loss = 2.91543
I0423 11:30:08.296659 30295 solver.cpp:244]     Train net output #0: loss = 0.979787 (* 1 = 0.979787 loss)
I0423 11:30:08.296664 30295 solver.cpp:244]     Train net output #1: loss = 0.544759 (* 1 = 0.544759 loss)
I0423 11:30:08.296669 30295 solver.cpp:244]     Train net output #2: loss = 0.807404 (* 1 = 0.807404 loss)
I0423 11:30:08.296672 30295 solver.cpp:244]     Train net output #3: loss = 0.58348 (* 1 = 0.58348 loss)
I0423 11:30:08.296679 30295 sgd_solver.cpp:106] Iteration 37000, lr = 3e-05
I0423 11:31:48.075330 30295 solver.cpp:228] Iteration 37100, loss = 3.30302
I0423 11:31:48.075465 30295 solver.cpp:244]     Train net output #0: loss = 0.989726 (* 1 = 0.989726 loss)
I0423 11:31:48.075472 30295 solver.cpp:244]     Train net output #1: loss = 0.68665 (* 1 = 0.68665 loss)
I0423 11:31:48.075477 30295 solver.cpp:244]     Train net output #2: loss = 0.928103 (* 1 = 0.928103 loss)
I0423 11:31:48.075482 30295 solver.cpp:244]     Train net output #3: loss = 0.698543 (* 1 = 0.698543 loss)
I0423 11:31:48.075486 30295 sgd_solver.cpp:106] Iteration 37100, lr = 3e-05
I0423 11:33:29.269255 30295 solver.cpp:228] Iteration 37200, loss = 3.00712
I0423 11:33:29.269440 30295 solver.cpp:244]     Train net output #0: loss = 0.985828 (* 1 = 0.985828 loss)
I0423 11:33:29.269449 30295 solver.cpp:244]     Train net output #1: loss = 0.532035 (* 1 = 0.532035 loss)
I0423 11:33:29.269454 30295 solver.cpp:244]     Train net output #2: loss = 0.907102 (* 1 = 0.907102 loss)
I0423 11:33:29.269459 30295 solver.cpp:244]     Train net output #3: loss = 0.582157 (* 1 = 0.582157 loss)
I0423 11:33:29.269464 30295 sgd_solver.cpp:106] Iteration 37200, lr = 3e-05
I0423 11:35:10.314097 30295 solver.cpp:228] Iteration 37300, loss = 2.52448
I0423 11:35:10.314250 30295 solver.cpp:244]     Train net output #0: loss = 0.979283 (* 1 = 0.979283 loss)
I0423 11:35:10.314258 30295 solver.cpp:244]     Train net output #1: loss = 0.445063 (* 1 = 0.445063 loss)
I0423 11:35:10.314263 30295 solver.cpp:244]     Train net output #2: loss = 0.592598 (* 1 = 0.592598 loss)
I0423 11:35:10.314268 30295 solver.cpp:244]     Train net output #3: loss = 0.50754 (* 1 = 0.50754 loss)
I0423 11:35:10.314272 30295 sgd_solver.cpp:106] Iteration 37300, lr = 3e-05
I0423 11:36:51.251818 30295 solver.cpp:228] Iteration 37400, loss = 2.48659
I0423 11:36:51.252018 30295 solver.cpp:244]     Train net output #0: loss = 0.981557 (* 1 = 0.981557 loss)
I0423 11:36:51.252027 30295 solver.cpp:244]     Train net output #1: loss = 0.372162 (* 1 = 0.372162 loss)
I0423 11:36:51.252032 30295 solver.cpp:244]     Train net output #2: loss = 0.70685 (* 1 = 0.70685 loss)
I0423 11:36:51.252035 30295 solver.cpp:244]     Train net output #3: loss = 0.426018 (* 1 = 0.426018 loss)
I0423 11:36:51.252040 30295 sgd_solver.cpp:106] Iteration 37400, lr = 3e-05
I0423 11:38:32.019475 30295 solver.cpp:228] Iteration 37500, loss = 3.14135
I0423 11:38:32.019624 30295 solver.cpp:244]     Train net output #0: loss = 0.978949 (* 1 = 0.978949 loss)
I0423 11:38:32.019631 30295 solver.cpp:244]     Train net output #1: loss = 0.736672 (* 1 = 0.736672 loss)
I0423 11:38:32.019637 30295 solver.cpp:244]     Train net output #2: loss = 0.753169 (* 1 = 0.753169 loss)
I0423 11:38:32.019641 30295 solver.cpp:244]     Train net output #3: loss = 0.672557 (* 1 = 0.672557 loss)
I0423 11:38:32.019645 30295 sgd_solver.cpp:106] Iteration 37500, lr = 3e-05
I0423 11:40:12.973883 30295 solver.cpp:228] Iteration 37600, loss = 2.73776
I0423 11:40:12.974033 30295 solver.cpp:244]     Train net output #0: loss = 0.955017 (* 1 = 0.955017 loss)
I0423 11:40:12.974040 30295 solver.cpp:244]     Train net output #1: loss = 0.382718 (* 1 = 0.382718 loss)
I0423 11:40:12.974045 30295 solver.cpp:244]     Train net output #2: loss = 0.765673 (* 1 = 0.765673 loss)
I0423 11:40:12.974050 30295 solver.cpp:244]     Train net output #3: loss = 0.634355 (* 1 = 0.634355 loss)
I0423 11:40:12.974056 30295 sgd_solver.cpp:106] Iteration 37600, lr = 3e-05
I0423 11:41:54.013603 30295 solver.cpp:228] Iteration 37700, loss = 2.61843
I0423 11:41:54.013737 30295 solver.cpp:244]     Train net output #0: loss = 0.982754 (* 1 = 0.982754 loss)
I0423 11:41:54.013746 30295 solver.cpp:244]     Train net output #1: loss = 0.578649 (* 1 = 0.578649 loss)
I0423 11:41:54.013751 30295 solver.cpp:244]     Train net output #2: loss = 0.578333 (* 1 = 0.578333 loss)
I0423 11:41:54.013754 30295 solver.cpp:244]     Train net output #3: loss = 0.478692 (* 1 = 0.478692 loss)
I0423 11:41:54.013759 30295 sgd_solver.cpp:106] Iteration 37700, lr = 3e-05
I0423 11:43:33.556525 30295 solver.cpp:228] Iteration 37800, loss = 2.86001
I0423 11:43:33.556668 30295 solver.cpp:244]     Train net output #0: loss = 0.980477 (* 1 = 0.980477 loss)
I0423 11:43:33.556675 30295 solver.cpp:244]     Train net output #1: loss = 0.534236 (* 1 = 0.534236 loss)
I0423 11:43:33.556680 30295 solver.cpp:244]     Train net output #2: loss = 0.757462 (* 1 = 0.757462 loss)
I0423 11:43:33.556684 30295 solver.cpp:244]     Train net output #3: loss = 0.587834 (* 1 = 0.587834 loss)
I0423 11:43:33.556689 30295 sgd_solver.cpp:106] Iteration 37800, lr = 3e-05
I0423 11:45:14.652844 30295 solver.cpp:228] Iteration 37900, loss = 3.27598
I0423 11:45:14.652990 30295 solver.cpp:244]     Train net output #0: loss = 0.968654 (* 1 = 0.968654 loss)
I0423 11:45:14.652998 30295 solver.cpp:244]     Train net output #1: loss = 0.749249 (* 1 = 0.749249 loss)
I0423 11:45:14.653003 30295 solver.cpp:244]     Train net output #2: loss = 0.879175 (* 1 = 0.879175 loss)
I0423 11:45:14.653008 30295 solver.cpp:244]     Train net output #3: loss = 0.678905 (* 1 = 0.678905 loss)
I0423 11:45:14.653012 30295 sgd_solver.cpp:106] Iteration 37900, lr = 3e-05
I0423 11:46:55.049288 30295 solver.cpp:337] Iteration 38000, Testing net (#0)
I0423 11:46:55.049448 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 11:46:55.049453 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 11:46:55.049458 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 11:46:55.049470 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 11:46:55.049475 30295 net.cpp:693] Ignoring source layer visualize
I0423 11:46:55.049476 30295 net.cpp:693] Ignoring source layer fake
I0423 11:50:33.001960 30295 solver.cpp:404]     Test net output #0: loss = 0.973627 (* 1 = 0.973627 loss)
I0423 11:50:33.002115 30295 solver.cpp:404]     Test net output #1: loss = 0.441045 (* 1 = 0.441045 loss)
I0423 11:50:33.002123 30295 solver.cpp:404]     Test net output #2: loss = 0.764704 (* 1 = 0.764704 loss)
I0423 11:50:33.002128 30295 solver.cpp:404]     Test net output #3: loss = 0.4438 (* 1 = 0.4438 loss)
I0423 11:50:33.662262 30295 solver.cpp:228] Iteration 38000, loss = 3.26
I0423 11:50:33.662288 30295 solver.cpp:244]     Train net output #0: loss = 0.969559 (* 1 = 0.969559 loss)
I0423 11:50:33.662310 30295 solver.cpp:244]     Train net output #1: loss = 0.716328 (* 1 = 0.716328 loss)
I0423 11:50:33.662313 30295 solver.cpp:244]     Train net output #2: loss = 0.924428 (* 1 = 0.924428 loss)
I0423 11:50:33.662317 30295 solver.cpp:244]     Train net output #3: loss = 0.649684 (* 1 = 0.649684 loss)
I0423 11:50:33.662322 30295 sgd_solver.cpp:106] Iteration 38000, lr = 3e-05
I0423 11:52:15.579406 30295 solver.cpp:228] Iteration 38100, loss = 3.20283
I0423 11:52:15.579560 30295 solver.cpp:244]     Train net output #0: loss = 0.970582 (* 1 = 0.970582 loss)
I0423 11:52:15.579566 30295 solver.cpp:244]     Train net output #1: loss = 0.715199 (* 1 = 0.715199 loss)
I0423 11:52:15.579571 30295 solver.cpp:244]     Train net output #2: loss = 0.895268 (* 1 = 0.895268 loss)
I0423 11:52:15.579576 30295 solver.cpp:244]     Train net output #3: loss = 0.621777 (* 1 = 0.621777 loss)
I0423 11:52:15.579581 30295 sgd_solver.cpp:106] Iteration 38100, lr = 3e-05
I0423 11:53:55.073313 30295 solver.cpp:228] Iteration 38200, loss = 3.008
I0423 11:53:55.073454 30295 solver.cpp:244]     Train net output #0: loss = 0.979802 (* 1 = 0.979802 loss)
I0423 11:53:55.073462 30295 solver.cpp:244]     Train net output #1: loss = 0.607426 (* 1 = 0.607426 loss)
I0423 11:53:55.073467 30295 solver.cpp:244]     Train net output #2: loss = 0.883937 (* 1 = 0.883937 loss)
I0423 11:53:55.073472 30295 solver.cpp:244]     Train net output #3: loss = 0.536837 (* 1 = 0.536837 loss)
I0423 11:53:55.073477 30295 sgd_solver.cpp:106] Iteration 38200, lr = 3e-05
I0423 11:55:36.319648 30295 solver.cpp:228] Iteration 38300, loss = 3.18184
I0423 11:55:36.319803 30295 solver.cpp:244]     Train net output #0: loss = 0.987339 (* 1 = 0.987339 loss)
I0423 11:55:36.319811 30295 solver.cpp:244]     Train net output #1: loss = 0.562293 (* 1 = 0.562293 loss)
I0423 11:55:36.319815 30295 solver.cpp:244]     Train net output #2: loss = 0.934629 (* 1 = 0.934629 loss)
I0423 11:55:36.319821 30295 solver.cpp:244]     Train net output #3: loss = 0.697584 (* 1 = 0.697584 loss)
I0423 11:55:36.319825 30295 sgd_solver.cpp:106] Iteration 38300, lr = 3e-05
I0423 11:57:17.153131 30295 solver.cpp:228] Iteration 38400, loss = 3.22397
I0423 11:57:17.153270 30295 solver.cpp:244]     Train net output #0: loss = 0.984523 (* 1 = 0.984523 loss)
I0423 11:57:17.153277 30295 solver.cpp:244]     Train net output #1: loss = 0.635362 (* 1 = 0.635362 loss)
I0423 11:57:17.153282 30295 solver.cpp:244]     Train net output #2: loss = 0.899743 (* 1 = 0.899743 loss)
I0423 11:57:17.153286 30295 solver.cpp:244]     Train net output #3: loss = 0.704338 (* 1 = 0.704338 loss)
I0423 11:57:17.153291 30295 sgd_solver.cpp:106] Iteration 38400, lr = 3e-05
I0423 11:58:58.376094 30295 solver.cpp:228] Iteration 38500, loss = 2.61945
I0423 11:58:58.376260 30295 solver.cpp:244]     Train net output #0: loss = 0.983634 (* 1 = 0.983634 loss)
I0423 11:58:58.376268 30295 solver.cpp:244]     Train net output #1: loss = 0.492672 (* 1 = 0.492672 loss)
I0423 11:58:58.376272 30295 solver.cpp:244]     Train net output #2: loss = 0.575281 (* 1 = 0.575281 loss)
I0423 11:58:58.376277 30295 solver.cpp:244]     Train net output #3: loss = 0.56786 (* 1 = 0.56786 loss)
I0423 11:58:58.376281 30295 sgd_solver.cpp:106] Iteration 38500, lr = 3e-05
I0423 12:00:37.698098 30295 solver.cpp:228] Iteration 38600, loss = 2.49859
I0423 12:00:37.698259 30295 solver.cpp:244]     Train net output #0: loss = 0.986996 (* 1 = 0.986996 loss)
I0423 12:00:37.698267 30295 solver.cpp:244]     Train net output #1: loss = 0.360355 (* 1 = 0.360355 loss)
I0423 12:00:37.698272 30295 solver.cpp:244]     Train net output #2: loss = 0.578001 (* 1 = 0.578001 loss)
I0423 12:00:37.698276 30295 solver.cpp:244]     Train net output #3: loss = 0.573243 (* 1 = 0.573243 loss)
I0423 12:00:37.698281 30295 sgd_solver.cpp:106] Iteration 38600, lr = 3e-05
I0423 12:02:18.378917 30295 solver.cpp:228] Iteration 38700, loss = 2.6545
I0423 12:02:18.379088 30295 solver.cpp:244]     Train net output #0: loss = 0.990373 (* 1 = 0.990373 loss)
I0423 12:02:18.379096 30295 solver.cpp:244]     Train net output #1: loss = 0.431724 (* 1 = 0.431724 loss)
I0423 12:02:18.379101 30295 solver.cpp:244]     Train net output #2: loss = 0.691249 (* 1 = 0.691249 loss)
I0423 12:02:18.379106 30295 solver.cpp:244]     Train net output #3: loss = 0.541158 (* 1 = 0.541158 loss)
I0423 12:02:18.379111 30295 sgd_solver.cpp:106] Iteration 38700, lr = 3e-05
I0423 12:03:58.775961 30295 solver.cpp:228] Iteration 38800, loss = 3.09721
I0423 12:03:58.776124 30295 solver.cpp:244]     Train net output #0: loss = 0.979167 (* 1 = 0.979167 loss)
I0423 12:03:58.776132 30295 solver.cpp:244]     Train net output #1: loss = 0.67476 (* 1 = 0.67476 loss)
I0423 12:03:58.776137 30295 solver.cpp:244]     Train net output #2: loss = 0.761671 (* 1 = 0.761671 loss)
I0423 12:03:58.776141 30295 solver.cpp:244]     Train net output #3: loss = 0.681609 (* 1 = 0.681609 loss)
I0423 12:03:58.776146 30295 sgd_solver.cpp:106] Iteration 38800, lr = 3e-05
I0423 12:05:39.423528 30295 solver.cpp:228] Iteration 38900, loss = 2.77941
I0423 12:05:39.423691 30295 solver.cpp:244]     Train net output #0: loss = 0.982583 (* 1 = 0.982583 loss)
I0423 12:05:39.423698 30295 solver.cpp:244]     Train net output #1: loss = 0.595678 (* 1 = 0.595678 loss)
I0423 12:05:39.423703 30295 solver.cpp:244]     Train net output #2: loss = 0.593851 (* 1 = 0.593851 loss)
I0423 12:05:39.423708 30295 solver.cpp:244]     Train net output #3: loss = 0.607298 (* 1 = 0.607298 loss)
I0423 12:05:39.423713 30295 sgd_solver.cpp:106] Iteration 38900, lr = 3e-05
I0423 12:07:19.265522 30295 solver.cpp:337] Iteration 39000, Testing net (#0)
I0423 12:07:19.265671 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 12:07:19.265676 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 12:07:19.265681 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 12:07:19.265694 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 12:07:19.265697 30295 net.cpp:693] Ignoring source layer visualize
I0423 12:07:19.265700 30295 net.cpp:693] Ignoring source layer fake
I0423 12:10:56.284121 30295 solver.cpp:404]     Test net output #0: loss = 0.972379 (* 1 = 0.972379 loss)
I0423 12:10:56.284265 30295 solver.cpp:404]     Test net output #1: loss = 0.517809 (* 1 = 0.517809 loss)
I0423 12:10:56.284272 30295 solver.cpp:404]     Test net output #2: loss = 0.808104 (* 1 = 0.808104 loss)
I0423 12:10:56.284277 30295 solver.cpp:404]     Test net output #3: loss = 0.574635 (* 1 = 0.574635 loss)
I0423 12:10:56.968739 30295 solver.cpp:228] Iteration 39000, loss = 3.15094
I0423 12:10:56.968780 30295 solver.cpp:244]     Train net output #0: loss = 0.982195 (* 1 = 0.982195 loss)
I0423 12:10:56.968786 30295 solver.cpp:244]     Train net output #1: loss = 0.723746 (* 1 = 0.723746 loss)
I0423 12:10:56.968789 30295 solver.cpp:244]     Train net output #2: loss = 0.75256 (* 1 = 0.75256 loss)
I0423 12:10:56.968793 30295 solver.cpp:244]     Train net output #3: loss = 0.692442 (* 1 = 0.692442 loss)
I0423 12:10:56.968799 30295 sgd_solver.cpp:106] Iteration 39000, lr = 3e-05
I0423 12:12:38.036768 30295 solver.cpp:228] Iteration 39100, loss = 3.16926
I0423 12:12:38.036931 30295 solver.cpp:244]     Train net output #0: loss = 0.977448 (* 1 = 0.977448 loss)
I0423 12:12:38.036938 30295 solver.cpp:244]     Train net output #1: loss = 0.742522 (* 1 = 0.742522 loss)
I0423 12:12:38.036943 30295 solver.cpp:244]     Train net output #2: loss = 0.725211 (* 1 = 0.725211 loss)
I0423 12:12:38.036947 30295 solver.cpp:244]     Train net output #3: loss = 0.724074 (* 1 = 0.724074 loss)
I0423 12:12:38.036952 30295 sgd_solver.cpp:106] Iteration 39100, lr = 3e-05
I0423 12:14:19.044565 30295 solver.cpp:228] Iteration 39200, loss = 3.33863
I0423 12:14:19.044736 30295 solver.cpp:244]     Train net output #0: loss = 0.969411 (* 1 = 0.969411 loss)
I0423 12:14:19.044744 30295 solver.cpp:244]     Train net output #1: loss = 0.798541 (* 1 = 0.798541 loss)
I0423 12:14:19.044749 30295 solver.cpp:244]     Train net output #2: loss = 0.914884 (* 1 = 0.914884 loss)
I0423 12:14:19.044754 30295 solver.cpp:244]     Train net output #3: loss = 0.655797 (* 1 = 0.655797 loss)
I0423 12:14:19.044759 30295 sgd_solver.cpp:106] Iteration 39200, lr = 3e-05
I0423 12:15:58.542114 30295 solver.cpp:228] Iteration 39300, loss = 3.19436
I0423 12:15:58.542279 30295 solver.cpp:244]     Train net output #0: loss = 0.984027 (* 1 = 0.984027 loss)
I0423 12:15:58.542286 30295 solver.cpp:244]     Train net output #1: loss = 0.736585 (* 1 = 0.736585 loss)
I0423 12:15:58.542290 30295 solver.cpp:244]     Train net output #2: loss = 0.818584 (* 1 = 0.818584 loss)
I0423 12:15:58.542295 30295 solver.cpp:244]     Train net output #3: loss = 0.655166 (* 1 = 0.655166 loss)
I0423 12:15:58.542300 30295 sgd_solver.cpp:106] Iteration 39300, lr = 3e-05
I0423 12:17:40.812503 30295 solver.cpp:228] Iteration 39400, loss = 3.21966
I0423 12:17:40.812675 30295 solver.cpp:244]     Train net output #0: loss = 0.988605 (* 1 = 0.988605 loss)
I0423 12:17:40.812682 30295 solver.cpp:244]     Train net output #1: loss = 0.656444 (* 1 = 0.656444 loss)
I0423 12:17:40.812688 30295 solver.cpp:244]     Train net output #2: loss = 0.935371 (* 1 = 0.935371 loss)
I0423 12:17:40.812692 30295 solver.cpp:244]     Train net output #3: loss = 0.639238 (* 1 = 0.639238 loss)
I0423 12:17:40.812697 30295 sgd_solver.cpp:106] Iteration 39400, lr = 3e-05
I0423 12:19:22.858707 30295 solver.cpp:228] Iteration 39500, loss = 3.18329
I0423 12:19:22.858866 30295 solver.cpp:244]     Train net output #0: loss = 0.982102 (* 1 = 0.982102 loss)
I0423 12:19:22.858873 30295 solver.cpp:244]     Train net output #1: loss = 0.589196 (* 1 = 0.589196 loss)
I0423 12:19:22.858878 30295 solver.cpp:244]     Train net output #2: loss = 0.929503 (* 1 = 0.929503 loss)
I0423 12:19:22.858882 30295 solver.cpp:244]     Train net output #3: loss = 0.682491 (* 1 = 0.682491 loss)
I0423 12:19:22.858887 30295 sgd_solver.cpp:106] Iteration 39500, lr = 3e-05
I0423 12:21:02.464004 30295 solver.cpp:228] Iteration 39600, loss = 3.22041
I0423 12:21:02.464170 30295 solver.cpp:244]     Train net output #0: loss = 0.976412 (* 1 = 0.976412 loss)
I0423 12:21:02.464177 30295 solver.cpp:244]     Train net output #1: loss = 0.651121 (* 1 = 0.651121 loss)
I0423 12:21:02.464184 30295 solver.cpp:244]     Train net output #2: loss = 0.936767 (* 1 = 0.936767 loss)
I0423 12:21:02.464187 30295 solver.cpp:244]     Train net output #3: loss = 0.656114 (* 1 = 0.656114 loss)
I0423 12:21:02.464192 30295 sgd_solver.cpp:106] Iteration 39600, lr = 3e-05
I0423 12:22:43.492418 30295 solver.cpp:228] Iteration 39700, loss = 2.80436
I0423 12:22:43.494231 30295 solver.cpp:244]     Train net output #0: loss = 0.989169 (* 1 = 0.989169 loss)
I0423 12:22:43.494240 30295 solver.cpp:244]     Train net output #1: loss = 0.517196 (* 1 = 0.517196 loss)
I0423 12:22:43.494244 30295 solver.cpp:244]     Train net output #2: loss = 0.762109 (* 1 = 0.762109 loss)
I0423 12:22:43.494248 30295 solver.cpp:244]     Train net output #3: loss = 0.535883 (* 1 = 0.535883 loss)
I0423 12:22:43.494253 30295 sgd_solver.cpp:106] Iteration 39700, lr = 3e-05
I0423 12:24:24.466816 30295 solver.cpp:228] Iteration 39800, loss = 2.92493
I0423 12:24:24.466972 30295 solver.cpp:244]     Train net output #0: loss = 0.987621 (* 1 = 0.987621 loss)
I0423 12:24:24.466979 30295 solver.cpp:244]     Train net output #1: loss = 0.475516 (* 1 = 0.475516 loss)
I0423 12:24:24.466985 30295 solver.cpp:244]     Train net output #2: loss = 0.766061 (* 1 = 0.766061 loss)
I0423 12:24:24.466989 30295 solver.cpp:244]     Train net output #3: loss = 0.695731 (* 1 = 0.695731 loss)
I0423 12:24:24.466994 30295 sgd_solver.cpp:106] Iteration 39800, lr = 3e-05
I0423 12:26:05.325659 30295 solver.cpp:228] Iteration 39900, loss = 2.32423
I0423 12:26:05.325850 30295 solver.cpp:244]     Train net output #0: loss = 0.939794 (* 1 = 0.939794 loss)
I0423 12:26:05.325858 30295 solver.cpp:244]     Train net output #1: loss = 0.288796 (* 1 = 0.288796 loss)
I0423 12:26:05.325863 30295 solver.cpp:244]     Train net output #2: loss = 0.780921 (* 1 = 0.780921 loss)
I0423 12:26:05.325867 30295 solver.cpp:244]     Train net output #3: loss = 0.314717 (* 1 = 0.314717 loss)
I0423 12:26:05.325873 30295 sgd_solver.cpp:106] Iteration 39900, lr = 3e-05
I0423 12:27:45.145197 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_40000.caffemodel
I0423 12:27:58.232208 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_40000.solverstate
I0423 12:27:58.437837 30295 solver.cpp:337] Iteration 40000, Testing net (#0)
I0423 12:27:58.437877 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 12:27:58.437880 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 12:27:58.437883 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 12:27:58.437897 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 12:27:58.437901 30295 net.cpp:693] Ignoring source layer visualize
I0423 12:27:58.437903 30295 net.cpp:693] Ignoring source layer fake
I0423 12:31:35.616353 30295 solver.cpp:404]     Test net output #0: loss = 0.976274 (* 1 = 0.976274 loss)
I0423 12:31:35.616515 30295 solver.cpp:404]     Test net output #1: loss = 0.544471 (* 1 = 0.544471 loss)
I0423 12:31:35.616523 30295 solver.cpp:404]     Test net output #2: loss = 0.809475 (* 1 = 0.809475 loss)
I0423 12:31:35.616528 30295 solver.cpp:404]     Test net output #3: loss = 0.575851 (* 1 = 0.575851 loss)
I0423 12:31:36.272737 30295 solver.cpp:228] Iteration 40000, loss = 3.35342
I0423 12:31:36.272779 30295 solver.cpp:244]     Train net output #0: loss = 0.973578 (* 1 = 0.973578 loss)
I0423 12:31:36.272785 30295 solver.cpp:244]     Train net output #1: loss = 0.758352 (* 1 = 0.758352 loss)
I0423 12:31:36.272789 30295 solver.cpp:244]     Train net output #2: loss = 0.949371 (* 1 = 0.949371 loss)
I0423 12:31:36.272794 30295 solver.cpp:244]     Train net output #3: loss = 0.672123 (* 1 = 0.672123 loss)
I0423 12:31:36.272799 30295 sgd_solver.cpp:106] Iteration 40000, lr = 9e-06
I0423 12:33:17.444499 30295 solver.cpp:228] Iteration 40100, loss = 3.13527
I0423 12:33:17.444663 30295 solver.cpp:244]     Train net output #0: loss = 0.959831 (* 1 = 0.959831 loss)
I0423 12:33:17.444669 30295 solver.cpp:244]     Train net output #1: loss = 0.581732 (* 1 = 0.581732 loss)
I0423 12:33:17.444674 30295 solver.cpp:244]     Train net output #2: loss = 0.938577 (* 1 = 0.938577 loss)
I0423 12:33:17.444679 30295 solver.cpp:244]     Train net output #3: loss = 0.655129 (* 1 = 0.655129 loss)
I0423 12:33:17.444684 30295 sgd_solver.cpp:106] Iteration 40100, lr = 9e-06
I0423 12:34:58.453739 30295 solver.cpp:228] Iteration 40200, loss = 2.93609
I0423 12:34:58.453925 30295 solver.cpp:244]     Train net output #0: loss = 0.986641 (* 1 = 0.986641 loss)
I0423 12:34:58.453934 30295 solver.cpp:244]     Train net output #1: loss = 0.697429 (* 1 = 0.697429 loss)
I0423 12:34:58.453939 30295 solver.cpp:244]     Train net output #2: loss = 0.76496 (* 1 = 0.76496 loss)
I0423 12:34:58.453943 30295 solver.cpp:244]     Train net output #3: loss = 0.487062 (* 1 = 0.487062 loss)
I0423 12:34:58.453948 30295 sgd_solver.cpp:106] Iteration 40200, lr = 9e-06
I0423 12:36:37.903904 30295 solver.cpp:228] Iteration 40300, loss = 3.29315
I0423 12:36:37.904074 30295 solver.cpp:244]     Train net output #0: loss = 0.975586 (* 1 = 0.975586 loss)
I0423 12:36:37.904081 30295 solver.cpp:244]     Train net output #1: loss = 0.699776 (* 1 = 0.699776 loss)
I0423 12:36:37.904086 30295 solver.cpp:244]     Train net output #2: loss = 0.956993 (* 1 = 0.956993 loss)
I0423 12:36:37.904091 30295 solver.cpp:244]     Train net output #3: loss = 0.660799 (* 1 = 0.660799 loss)
I0423 12:36:37.904096 30295 sgd_solver.cpp:106] Iteration 40300, lr = 9e-06
I0423 12:38:18.989037 30295 solver.cpp:228] Iteration 40400, loss = 3.32267
I0423 12:38:18.989203 30295 solver.cpp:244]     Train net output #0: loss = 0.973295 (* 1 = 0.973295 loss)
I0423 12:38:18.989212 30295 solver.cpp:244]     Train net output #1: loss = 0.731749 (* 1 = 0.731749 loss)
I0423 12:38:18.989217 30295 solver.cpp:244]     Train net output #2: loss = 0.885614 (* 1 = 0.885614 loss)
I0423 12:38:18.989220 30295 solver.cpp:244]     Train net output #3: loss = 0.732009 (* 1 = 0.732009 loss)
I0423 12:38:18.989225 30295 sgd_solver.cpp:106] Iteration 40400, lr = 9e-06
I0423 12:40:00.185636 30295 solver.cpp:228] Iteration 40500, loss = 3.29238
I0423 12:40:00.185798 30295 solver.cpp:244]     Train net output #0: loss = 0.971249 (* 1 = 0.971249 loss)
I0423 12:40:00.185806 30295 solver.cpp:244]     Train net output #1: loss = 0.732099 (* 1 = 0.732099 loss)
I0423 12:40:00.185811 30295 solver.cpp:244]     Train net output #2: loss = 0.918324 (* 1 = 0.918324 loss)
I0423 12:40:00.185817 30295 solver.cpp:244]     Train net output #3: loss = 0.670712 (* 1 = 0.670712 loss)
I0423 12:40:00.185820 30295 sgd_solver.cpp:106] Iteration 40500, lr = 9e-06
I0423 12:41:41.874891 30295 solver.cpp:228] Iteration 40600, loss = 3.17582
I0423 12:41:41.875049 30295 solver.cpp:244]     Train net output #0: loss = 0.970385 (* 1 = 0.970385 loss)
I0423 12:41:41.875057 30295 solver.cpp:244]     Train net output #1: loss = 0.661162 (* 1 = 0.661162 loss)
I0423 12:41:41.875062 30295 solver.cpp:244]     Train net output #2: loss = 0.915856 (* 1 = 0.915856 loss)
I0423 12:41:41.875066 30295 solver.cpp:244]     Train net output #3: loss = 0.628417 (* 1 = 0.628417 loss)
I0423 12:41:41.875071 30295 sgd_solver.cpp:106] Iteration 40600, lr = 9e-06
I0423 12:43:21.592928 30295 solver.cpp:228] Iteration 40700, loss = 3.24777
I0423 12:43:21.593094 30295 solver.cpp:244]     Train net output #0: loss = 0.9886 (* 1 = 0.9886 loss)
I0423 12:43:21.593101 30295 solver.cpp:244]     Train net output #1: loss = 0.679008 (* 1 = 0.679008 loss)
I0423 12:43:21.593106 30295 solver.cpp:244]     Train net output #2: loss = 0.925939 (* 1 = 0.925939 loss)
I0423 12:43:21.593111 30295 solver.cpp:244]     Train net output #3: loss = 0.65422 (* 1 = 0.65422 loss)
I0423 12:43:21.593116 30295 sgd_solver.cpp:106] Iteration 40700, lr = 9e-06
I0423 12:45:03.029392 30295 solver.cpp:228] Iteration 40800, loss = 3.05775
I0423 12:45:03.029564 30295 solver.cpp:244]     Train net output #0: loss = 0.987827 (* 1 = 0.987827 loss)
I0423 12:45:03.029573 30295 solver.cpp:244]     Train net output #1: loss = 0.442559 (* 1 = 0.442559 loss)
I0423 12:45:03.029578 30295 solver.cpp:244]     Train net output #2: loss = 0.881579 (* 1 = 0.881579 loss)
I0423 12:45:03.029582 30295 solver.cpp:244]     Train net output #3: loss = 0.745788 (* 1 = 0.745788 loss)
I0423 12:45:03.029587 30295 sgd_solver.cpp:106] Iteration 40800, lr = 9e-06
I0423 12:46:44.623162 30295 solver.cpp:228] Iteration 40900, loss = 2.98083
I0423 12:46:44.623306 30295 solver.cpp:244]     Train net output #0: loss = 0.98104 (* 1 = 0.98104 loss)
I0423 12:46:44.623312 30295 solver.cpp:244]     Train net output #1: loss = 0.521361 (* 1 = 0.521361 loss)
I0423 12:46:44.623317 30295 solver.cpp:244]     Train net output #2: loss = 0.90988 (* 1 = 0.90988 loss)
I0423 12:46:44.623322 30295 solver.cpp:244]     Train net output #3: loss = 0.568547 (* 1 = 0.568547 loss)
I0423 12:46:44.623327 30295 sgd_solver.cpp:106] Iteration 40900, lr = 9e-06
I0423 12:48:25.091864 30295 solver.cpp:337] Iteration 41000, Testing net (#0)
I0423 12:48:25.092013 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 12:48:25.092018 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 12:48:25.092022 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 12:48:25.092036 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 12:48:25.092039 30295 net.cpp:693] Ignoring source layer visualize
I0423 12:48:25.092041 30295 net.cpp:693] Ignoring source layer fake
I0423 12:52:02.424790 30295 solver.cpp:404]     Test net output #0: loss = 0.969771 (* 1 = 0.969771 loss)
I0423 12:52:02.424949 30295 solver.cpp:404]     Test net output #1: loss = 0.541038 (* 1 = 0.541038 loss)
I0423 12:52:02.424957 30295 solver.cpp:404]     Test net output #2: loss = 0.825312 (* 1 = 0.825312 loss)
I0423 12:52:02.424962 30295 solver.cpp:404]     Test net output #3: loss = 0.593314 (* 1 = 0.593314 loss)
I0423 12:52:03.085371 30295 solver.cpp:228] Iteration 41000, loss = 2.79099
I0423 12:52:03.085424 30295 solver.cpp:244]     Train net output #0: loss = 0.985766 (* 1 = 0.985766 loss)
I0423 12:52:03.085430 30295 solver.cpp:244]     Train net output #1: loss = 0.434181 (* 1 = 0.434181 loss)
I0423 12:52:03.085441 30295 solver.cpp:244]     Train net output #2: loss = 0.764224 (* 1 = 0.764224 loss)
I0423 12:52:03.085461 30295 solver.cpp:244]     Train net output #3: loss = 0.606814 (* 1 = 0.606814 loss)
I0423 12:52:03.085467 30295 sgd_solver.cpp:106] Iteration 41000, lr = 9e-06
I0423 12:53:42.492821 30295 solver.cpp:228] Iteration 41100, loss = 2.43499
I0423 12:53:42.492970 30295 solver.cpp:244]     Train net output #0: loss = 0.991105 (* 1 = 0.991105 loss)
I0423 12:53:42.492977 30295 solver.cpp:244]     Train net output #1: loss = 0.341238 (* 1 = 0.341238 loss)
I0423 12:53:42.492982 30295 solver.cpp:244]     Train net output #2: loss = 0.558709 (* 1 = 0.558709 loss)
I0423 12:53:42.492986 30295 solver.cpp:244]     Train net output #3: loss = 0.543934 (* 1 = 0.543934 loss)
I0423 12:53:42.492992 30295 sgd_solver.cpp:106] Iteration 41100, lr = 9e-06
I0423 12:55:24.581846 30295 solver.cpp:228] Iteration 41200, loss = 3.26363
I0423 12:55:24.582007 30295 solver.cpp:244]     Train net output #0: loss = 0.991472 (* 1 = 0.991472 loss)
I0423 12:55:24.582015 30295 solver.cpp:244]     Train net output #1: loss = 0.629185 (* 1 = 0.629185 loss)
I0423 12:55:24.582020 30295 solver.cpp:244]     Train net output #2: loss = 0.947884 (* 1 = 0.947884 loss)
I0423 12:55:24.582025 30295 solver.cpp:244]     Train net output #3: loss = 0.695092 (* 1 = 0.695092 loss)
I0423 12:55:24.582029 30295 sgd_solver.cpp:106] Iteration 41200, lr = 9e-06
I0423 12:57:05.843905 30295 solver.cpp:228] Iteration 41300, loss = 3.27218
I0423 12:57:05.844080 30295 solver.cpp:244]     Train net output #0: loss = 0.975564 (* 1 = 0.975564 loss)
I0423 12:57:05.844089 30295 solver.cpp:244]     Train net output #1: loss = 0.685853 (* 1 = 0.685853 loss)
I0423 12:57:05.844092 30295 solver.cpp:244]     Train net output #2: loss = 0.953605 (* 1 = 0.953605 loss)
I0423 12:57:05.844097 30295 solver.cpp:244]     Train net output #3: loss = 0.657159 (* 1 = 0.657159 loss)
I0423 12:57:05.844102 30295 sgd_solver.cpp:106] Iteration 41300, lr = 9e-06
I0423 12:58:47.476153 30295 solver.cpp:228] Iteration 41400, loss = 2.85736
I0423 12:58:47.476325 30295 solver.cpp:244]     Train net output #0: loss = 0.969699 (* 1 = 0.969699 loss)
I0423 12:58:47.476331 30295 solver.cpp:244]     Train net output #1: loss = 0.530274 (* 1 = 0.530274 loss)
I0423 12:58:47.476337 30295 solver.cpp:244]     Train net output #2: loss = 0.747577 (* 1 = 0.747577 loss)
I0423 12:58:47.476341 30295 solver.cpp:244]     Train net output #3: loss = 0.609812 (* 1 = 0.609812 loss)
I0423 12:58:47.476346 30295 sgd_solver.cpp:106] Iteration 41400, lr = 9e-06
I0423 13:00:29.089987 30295 solver.cpp:228] Iteration 41500, loss = 2.69567
I0423 13:00:29.090142 30295 solver.cpp:244]     Train net output #0: loss = 0.990047 (* 1 = 0.990047 loss)
I0423 13:00:29.090150 30295 solver.cpp:244]     Train net output #1: loss = 0.634036 (* 1 = 0.634036 loss)
I0423 13:00:29.090155 30295 solver.cpp:244]     Train net output #2: loss = 0.576375 (* 1 = 0.576375 loss)
I0423 13:00:29.090160 30295 solver.cpp:244]     Train net output #3: loss = 0.495208 (* 1 = 0.495208 loss)
I0423 13:00:29.090167 30295 sgd_solver.cpp:106] Iteration 41500, lr = 9e-06
I0423 13:02:11.244946 30295 solver.cpp:228] Iteration 41600, loss = 3.18381
I0423 13:02:11.245097 30295 solver.cpp:244]     Train net output #0: loss = 0.965469 (* 1 = 0.965469 loss)
I0423 13:02:11.245105 30295 solver.cpp:244]     Train net output #1: loss = 0.667897 (* 1 = 0.667897 loss)
I0423 13:02:11.245110 30295 solver.cpp:244]     Train net output #2: loss = 0.832013 (* 1 = 0.832013 loss)
I0423 13:02:11.245113 30295 solver.cpp:244]     Train net output #3: loss = 0.718434 (* 1 = 0.718434 loss)
I0423 13:02:11.245118 30295 sgd_solver.cpp:106] Iteration 41600, lr = 9e-06
I0423 13:03:53.832079 30295 solver.cpp:228] Iteration 41700, loss = 3.32768
I0423 13:03:53.832267 30295 solver.cpp:244]     Train net output #0: loss = 0.980864 (* 1 = 0.980864 loss)
I0423 13:03:53.832275 30295 solver.cpp:244]     Train net output #1: loss = 0.821246 (* 1 = 0.821246 loss)
I0423 13:03:53.832279 30295 solver.cpp:244]     Train net output #2: loss = 0.840758 (* 1 = 0.840758 loss)
I0423 13:03:53.832284 30295 solver.cpp:244]     Train net output #3: loss = 0.684814 (* 1 = 0.684814 loss)
I0423 13:03:53.832289 30295 sgd_solver.cpp:106] Iteration 41700, lr = 9e-06
I0423 13:05:33.278494 30295 solver.cpp:228] Iteration 41800, loss = 3.25339
I0423 13:05:33.278627 30295 solver.cpp:244]     Train net output #0: loss = 0.981872 (* 1 = 0.981872 loss)
I0423 13:05:33.278635 30295 solver.cpp:244]     Train net output #1: loss = 0.711668 (* 1 = 0.711668 loss)
I0423 13:05:33.278640 30295 solver.cpp:244]     Train net output #2: loss = 0.901451 (* 1 = 0.901451 loss)
I0423 13:05:33.278645 30295 solver.cpp:244]     Train net output #3: loss = 0.658402 (* 1 = 0.658402 loss)
I0423 13:05:33.278648 30295 sgd_solver.cpp:106] Iteration 41800, lr = 9e-06
I0423 13:07:14.836570 30295 solver.cpp:228] Iteration 41900, loss = 3.23575
I0423 13:07:14.836721 30295 solver.cpp:244]     Train net output #0: loss = 0.975421 (* 1 = 0.975421 loss)
I0423 13:07:14.836729 30295 solver.cpp:244]     Train net output #1: loss = 0.648901 (* 1 = 0.648901 loss)
I0423 13:07:14.836733 30295 solver.cpp:244]     Train net output #2: loss = 0.935283 (* 1 = 0.935283 loss)
I0423 13:07:14.836737 30295 solver.cpp:244]     Train net output #3: loss = 0.676144 (* 1 = 0.676144 loss)
I0423 13:07:14.836743 30295 sgd_solver.cpp:106] Iteration 41900, lr = 9e-06
I0423 13:08:54.912160 30295 solver.cpp:337] Iteration 42000, Testing net (#0)
I0423 13:08:54.912312 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 13:08:54.912315 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 13:08:54.912319 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 13:08:54.912333 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 13:08:54.912336 30295 net.cpp:693] Ignoring source layer visualize
I0423 13:08:54.912338 30295 net.cpp:693] Ignoring source layer fake
I0423 13:12:30.981577 30295 solver.cpp:404]     Test net output #0: loss = 0.972498 (* 1 = 0.972498 loss)
I0423 13:12:30.981727 30295 solver.cpp:404]     Test net output #1: loss = 0.482557 (* 1 = 0.482557 loss)
I0423 13:12:30.981734 30295 solver.cpp:404]     Test net output #2: loss = 0.788791 (* 1 = 0.788791 loss)
I0423 13:12:30.981739 30295 solver.cpp:404]     Test net output #3: loss = 0.494896 (* 1 = 0.494896 loss)
I0423 13:12:31.641366 30295 solver.cpp:228] Iteration 42000, loss = 3.09368
I0423 13:12:31.641407 30295 solver.cpp:244]     Train net output #0: loss = 0.982324 (* 1 = 0.982324 loss)
I0423 13:12:31.641412 30295 solver.cpp:244]     Train net output #1: loss = 0.568225 (* 1 = 0.568225 loss)
I0423 13:12:31.641417 30295 solver.cpp:244]     Train net output #2: loss = 0.884922 (* 1 = 0.884922 loss)
I0423 13:12:31.641423 30295 solver.cpp:244]     Train net output #3: loss = 0.658212 (* 1 = 0.658212 loss)
I0423 13:12:31.641427 30295 sgd_solver.cpp:106] Iteration 42000, lr = 9e-06
I0423 13:14:10.715700 30295 solver.cpp:228] Iteration 42100, loss = 3.11736
I0423 13:14:10.715845 30295 solver.cpp:244]     Train net output #0: loss = 0.972221 (* 1 = 0.972221 loss)
I0423 13:14:10.715853 30295 solver.cpp:244]     Train net output #1: loss = 0.628112 (* 1 = 0.628112 loss)
I0423 13:14:10.715857 30295 solver.cpp:244]     Train net output #2: loss = 0.886668 (* 1 = 0.886668 loss)
I0423 13:14:10.715862 30295 solver.cpp:244]     Train net output #3: loss = 0.630362 (* 1 = 0.630362 loss)
I0423 13:14:10.715867 30295 sgd_solver.cpp:106] Iteration 42100, lr = 9e-06
I0423 13:15:51.382688 30295 solver.cpp:228] Iteration 42200, loss = 3.27404
I0423 13:15:51.382870 30295 solver.cpp:244]     Train net output #0: loss = 0.983483 (* 1 = 0.983483 loss)
I0423 13:15:51.382879 30295 solver.cpp:244]     Train net output #1: loss = 0.682658 (* 1 = 0.682658 loss)
I0423 13:15:51.382884 30295 solver.cpp:244]     Train net output #2: loss = 0.902923 (* 1 = 0.902923 loss)
I0423 13:15:51.382889 30295 solver.cpp:244]     Train net output #3: loss = 0.704974 (* 1 = 0.704974 loss)
I0423 13:15:51.382894 30295 sgd_solver.cpp:106] Iteration 42200, lr = 9e-06
I0423 13:17:31.971345 30295 solver.cpp:228] Iteration 42300, loss = 2.95386
I0423 13:17:31.971491 30295 solver.cpp:244]     Train net output #0: loss = 0.984335 (* 1 = 0.984335 loss)
I0423 13:17:31.971499 30295 solver.cpp:244]     Train net output #1: loss = 0.552078 (* 1 = 0.552078 loss)
I0423 13:17:31.971504 30295 solver.cpp:244]     Train net output #2: loss = 0.761287 (* 1 = 0.761287 loss)
I0423 13:17:31.971509 30295 solver.cpp:244]     Train net output #3: loss = 0.65616 (* 1 = 0.65616 loss)
I0423 13:17:31.971513 30295 sgd_solver.cpp:106] Iteration 42300, lr = 9e-06
I0423 13:19:12.461217 30295 solver.cpp:228] Iteration 42400, loss = 2.67257
I0423 13:19:12.461362 30295 solver.cpp:244]     Train net output #0: loss = 0.956915 (* 1 = 0.956915 loss)
I0423 13:19:12.461369 30295 solver.cpp:244]     Train net output #1: loss = 0.449825 (* 1 = 0.449825 loss)
I0423 13:19:12.461374 30295 solver.cpp:244]     Train net output #2: loss = 0.738023 (* 1 = 0.738023 loss)
I0423 13:19:12.461380 30295 solver.cpp:244]     Train net output #3: loss = 0.527806 (* 1 = 0.527806 loss)
I0423 13:19:12.461385 30295 sgd_solver.cpp:106] Iteration 42400, lr = 9e-06
I0423 13:20:52.576661 30295 solver.cpp:228] Iteration 42500, loss = 3.31635
I0423 13:20:52.576809 30295 solver.cpp:244]     Train net output #0: loss = 0.976832 (* 1 = 0.976832 loss)
I0423 13:20:52.576817 30295 solver.cpp:244]     Train net output #1: loss = 0.714109 (* 1 = 0.714109 loss)
I0423 13:20:52.576822 30295 solver.cpp:244]     Train net output #2: loss = 0.957041 (* 1 = 0.957041 loss)
I0423 13:20:52.576825 30295 solver.cpp:244]     Train net output #3: loss = 0.668365 (* 1 = 0.668365 loss)
I0423 13:20:52.576830 30295 sgd_solver.cpp:106] Iteration 42500, lr = 9e-06
I0423 13:22:32.786670 30295 solver.cpp:228] Iteration 42600, loss = 3.05011
I0423 13:22:32.786828 30295 solver.cpp:244]     Train net output #0: loss = 0.970067 (* 1 = 0.970067 loss)
I0423 13:22:32.786834 30295 solver.cpp:244]     Train net output #1: loss = 0.572154 (* 1 = 0.572154 loss)
I0423 13:22:32.786839 30295 solver.cpp:244]     Train net output #2: loss = 0.931207 (* 1 = 0.931207 loss)
I0423 13:22:32.786844 30295 solver.cpp:244]     Train net output #3: loss = 0.576681 (* 1 = 0.576681 loss)
I0423 13:22:32.786849 30295 sgd_solver.cpp:106] Iteration 42600, lr = 9e-06
I0423 13:24:13.243824 30295 solver.cpp:228] Iteration 42700, loss = 2.99476
I0423 13:24:13.243979 30295 solver.cpp:244]     Train net output #0: loss = 0.984344 (* 1 = 0.984344 loss)
I0423 13:24:13.243988 30295 solver.cpp:244]     Train net output #1: loss = 0.696206 (* 1 = 0.696206 loss)
I0423 13:24:13.243993 30295 solver.cpp:244]     Train net output #2: loss = 0.773419 (* 1 = 0.773419 loss)
I0423 13:24:13.243996 30295 solver.cpp:244]     Train net output #3: loss = 0.540795 (* 1 = 0.540795 loss)
I0423 13:24:13.244001 30295 sgd_solver.cpp:106] Iteration 42700, lr = 9e-06
I0423 13:25:52.325356 30295 solver.cpp:228] Iteration 42800, loss = 2.73211
I0423 13:25:52.326570 30295 solver.cpp:244]     Train net output #0: loss = 0.983656 (* 1 = 0.983656 loss)
I0423 13:25:52.326577 30295 solver.cpp:244]     Train net output #1: loss = 0.616857 (* 1 = 0.616857 loss)
I0423 13:25:52.326581 30295 solver.cpp:244]     Train net output #2: loss = 0.578442 (* 1 = 0.578442 loss)
I0423 13:25:52.326586 30295 solver.cpp:244]     Train net output #3: loss = 0.553155 (* 1 = 0.553155 loss)
I0423 13:25:52.326591 30295 sgd_solver.cpp:106] Iteration 42800, lr = 9e-06
I0423 13:27:33.042191 30295 solver.cpp:228] Iteration 42900, loss = 3.30164
I0423 13:27:33.042363 30295 solver.cpp:244]     Train net output #0: loss = 0.976118 (* 1 = 0.976118 loss)
I0423 13:27:33.042371 30295 solver.cpp:244]     Train net output #1: loss = 0.768866 (* 1 = 0.768866 loss)
I0423 13:27:33.042376 30295 solver.cpp:244]     Train net output #2: loss = 0.851035 (* 1 = 0.851035 loss)
I0423 13:27:33.042381 30295 solver.cpp:244]     Train net output #3: loss = 0.705623 (* 1 = 0.705623 loss)
I0423 13:27:33.042385 30295 sgd_solver.cpp:106] Iteration 42900, lr = 9e-06
I0423 13:29:13.557730 30295 solver.cpp:337] Iteration 43000, Testing net (#0)
I0423 13:29:13.557909 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 13:29:13.557915 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 13:29:13.557920 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 13:29:13.557940 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 13:29:13.557948 30295 net.cpp:693] Ignoring source layer visualize
I0423 13:29:13.557951 30295 net.cpp:693] Ignoring source layer fake
I0423 13:32:48.726306 30295 solver.cpp:404]     Test net output #0: loss = 0.970174 (* 1 = 0.970174 loss)
I0423 13:32:48.726444 30295 solver.cpp:404]     Test net output #1: loss = 0.468798 (* 1 = 0.468798 loss)
I0423 13:32:48.726454 30295 solver.cpp:404]     Test net output #2: loss = 0.810562 (* 1 = 0.810562 loss)
I0423 13:32:48.726461 30295 solver.cpp:404]     Test net output #3: loss = 0.54393 (* 1 = 0.54393 loss)
I0423 13:32:49.386505 30295 solver.cpp:228] Iteration 43000, loss = 3.33488
I0423 13:32:49.386535 30295 solver.cpp:244]     Train net output #0: loss = 0.983955 (* 1 = 0.983955 loss)
I0423 13:32:49.386543 30295 solver.cpp:244]     Train net output #1: loss = 0.776021 (* 1 = 0.776021 loss)
I0423 13:32:49.386548 30295 solver.cpp:244]     Train net output #2: loss = 0.893556 (* 1 = 0.893556 loss)
I0423 13:32:49.386554 30295 solver.cpp:244]     Train net output #3: loss = 0.681351 (* 1 = 0.681351 loss)
I0423 13:32:49.386576 30295 sgd_solver.cpp:106] Iteration 43000, lr = 9e-06
I0423 13:34:30.506320 30295 solver.cpp:228] Iteration 43100, loss = 3.41072
I0423 13:34:30.506482 30295 solver.cpp:244]     Train net output #0: loss = 0.986273 (* 1 = 0.986273 loss)
I0423 13:34:30.506500 30295 solver.cpp:244]     Train net output #1: loss = 0.775506 (* 1 = 0.775506 loss)
I0423 13:34:30.506506 30295 solver.cpp:244]     Train net output #2: loss = 0.938433 (* 1 = 0.938433 loss)
I0423 13:34:30.506510 30295 solver.cpp:244]     Train net output #3: loss = 0.710512 (* 1 = 0.710512 loss)
I0423 13:34:30.506515 30295 sgd_solver.cpp:106] Iteration 43100, lr = 9e-06
I0423 13:36:09.650810 30295 solver.cpp:228] Iteration 43200, loss = 3.39025
I0423 13:36:09.650970 30295 solver.cpp:244]     Train net output #0: loss = 0.982518 (* 1 = 0.982518 loss)
I0423 13:36:09.650979 30295 solver.cpp:244]     Train net output #1: loss = 0.773374 (* 1 = 0.773374 loss)
I0423 13:36:09.650982 30295 solver.cpp:244]     Train net output #2: loss = 0.93812 (* 1 = 0.93812 loss)
I0423 13:36:09.650987 30295 solver.cpp:244]     Train net output #3: loss = 0.696242 (* 1 = 0.696242 loss)
I0423 13:36:09.650992 30295 sgd_solver.cpp:106] Iteration 43200, lr = 9e-06
I0423 13:37:50.737154 30295 solver.cpp:228] Iteration 43300, loss = 3.02853
I0423 13:37:50.737313 30295 solver.cpp:244]     Train net output #0: loss = 0.977244 (* 1 = 0.977244 loss)
I0423 13:37:50.737321 30295 solver.cpp:244]     Train net output #1: loss = 0.491101 (* 1 = 0.491101 loss)
I0423 13:37:50.737327 30295 solver.cpp:244]     Train net output #2: loss = 0.864982 (* 1 = 0.864982 loss)
I0423 13:37:50.737331 30295 solver.cpp:244]     Train net output #3: loss = 0.695205 (* 1 = 0.695205 loss)
I0423 13:37:50.737336 30295 sgd_solver.cpp:106] Iteration 43300, lr = 9e-06
I0423 13:39:33.462388 30295 solver.cpp:228] Iteration 43400, loss = 3.17077
I0423 13:39:33.462574 30295 solver.cpp:244]     Train net output #0: loss = 0.988529 (* 1 = 0.988529 loss)
I0423 13:39:33.462581 30295 solver.cpp:244]     Train net output #1: loss = 0.666805 (* 1 = 0.666805 loss)
I0423 13:39:33.462586 30295 solver.cpp:244]     Train net output #2: loss = 0.953723 (* 1 = 0.953723 loss)
I0423 13:39:33.462590 30295 solver.cpp:244]     Train net output #3: loss = 0.561717 (* 1 = 0.561717 loss)
I0423 13:39:33.462595 30295 sgd_solver.cpp:106] Iteration 43400, lr = 9e-06
I0423 13:41:16.490866 30295 solver.cpp:228] Iteration 43500, loss = 2.82738
I0423 13:41:16.491008 30295 solver.cpp:244]     Train net output #0: loss = 0.989495 (* 1 = 0.989495 loss)
I0423 13:41:16.491014 30295 solver.cpp:244]     Train net output #1: loss = 0.510141 (* 1 = 0.510141 loss)
I0423 13:41:16.491020 30295 solver.cpp:244]     Train net output #2: loss = 0.75239 (* 1 = 0.75239 loss)
I0423 13:41:16.491025 30295 solver.cpp:244]     Train net output #3: loss = 0.575357 (* 1 = 0.575357 loss)
I0423 13:41:16.491029 30295 sgd_solver.cpp:106] Iteration 43500, lr = 9e-06
I0423 13:42:55.297013 30295 solver.cpp:228] Iteration 43600, loss = 2.8585
I0423 13:42:55.297174 30295 solver.cpp:244]     Train net output #0: loss = 0.97837 (* 1 = 0.97837 loss)
I0423 13:42:55.297183 30295 solver.cpp:244]     Train net output #1: loss = 0.557724 (* 1 = 0.557724 loss)
I0423 13:42:55.297186 30295 solver.cpp:244]     Train net output #2: loss = 0.748397 (* 1 = 0.748397 loss)
I0423 13:42:55.297191 30295 solver.cpp:244]     Train net output #3: loss = 0.574009 (* 1 = 0.574009 loss)
I0423 13:42:55.297196 30295 sgd_solver.cpp:106] Iteration 43600, lr = 9e-06
I0423 13:44:42.882452 30295 solver.cpp:228] Iteration 43700, loss = 2.8565
I0423 13:44:42.882621 30295 solver.cpp:244]     Train net output #0: loss = 0.98974 (* 1 = 0.98974 loss)
I0423 13:44:42.882628 30295 solver.cpp:244]     Train net output #1: loss = 0.560715 (* 1 = 0.560715 loss)
I0423 13:44:42.882633 30295 solver.cpp:244]     Train net output #2: loss = 0.744761 (* 1 = 0.744761 loss)
I0423 13:44:42.882638 30295 solver.cpp:244]     Train net output #3: loss = 0.56128 (* 1 = 0.56128 loss)
I0423 13:44:42.882643 30295 sgd_solver.cpp:106] Iteration 43700, lr = 9e-06
I0423 13:46:28.324625 30295 solver.cpp:228] Iteration 43800, loss = 3.15269
I0423 13:46:28.324781 30295 solver.cpp:244]     Train net output #0: loss = 0.969784 (* 1 = 0.969784 loss)
I0423 13:46:28.324789 30295 solver.cpp:244]     Train net output #1: loss = 0.730066 (* 1 = 0.730066 loss)
I0423 13:46:28.324793 30295 solver.cpp:244]     Train net output #2: loss = 0.767551 (* 1 = 0.767551 loss)
I0423 13:46:28.324797 30295 solver.cpp:244]     Train net output #3: loss = 0.685286 (* 1 = 0.685286 loss)
I0423 13:46:28.324802 30295 sgd_solver.cpp:106] Iteration 43800, lr = 9e-06
I0423 13:48:14.216711 30295 solver.cpp:228] Iteration 43900, loss = 2.99841
I0423 13:48:14.216855 30295 solver.cpp:244]     Train net output #0: loss = 0.983252 (* 1 = 0.983252 loss)
I0423 13:48:14.216861 30295 solver.cpp:244]     Train net output #1: loss = 0.643787 (* 1 = 0.643787 loss)
I0423 13:48:14.216867 30295 solver.cpp:244]     Train net output #2: loss = 0.739404 (* 1 = 0.739404 loss)
I0423 13:48:14.216871 30295 solver.cpp:244]     Train net output #3: loss = 0.631968 (* 1 = 0.631968 loss)
I0423 13:48:14.216876 30295 sgd_solver.cpp:106] Iteration 43900, lr = 9e-06
I0423 13:49:55.690815 30295 solver.cpp:337] Iteration 44000, Testing net (#0)
I0423 13:49:55.690963 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 13:49:55.690968 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 13:49:55.690970 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 13:49:55.690984 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 13:49:55.690989 30295 net.cpp:693] Ignoring source layer visualize
I0423 13:49:55.690990 30295 net.cpp:693] Ignoring source layer fake
I0423 13:53:30.914815 30295 solver.cpp:404]     Test net output #0: loss = 0.975034 (* 1 = 0.975034 loss)
I0423 13:53:30.914973 30295 solver.cpp:404]     Test net output #1: loss = 0.53053 (* 1 = 0.53053 loss)
I0423 13:53:30.914980 30295 solver.cpp:404]     Test net output #2: loss = 0.807685 (* 1 = 0.807685 loss)
I0423 13:53:30.914984 30295 solver.cpp:404]     Test net output #3: loss = 0.559345 (* 1 = 0.559345 loss)
I0423 13:53:31.578950 30295 solver.cpp:228] Iteration 44000, loss = 2.54785
I0423 13:53:31.578991 30295 solver.cpp:244]     Train net output #0: loss = 0.981165 (* 1 = 0.981165 loss)
I0423 13:53:31.578997 30295 solver.cpp:244]     Train net output #1: loss = 0.512508 (* 1 = 0.512508 loss)
I0423 13:53:31.579002 30295 solver.cpp:244]     Train net output #2: loss = 0.552482 (* 1 = 0.552482 loss)
I0423 13:53:31.579006 30295 solver.cpp:244]     Train net output #3: loss = 0.501697 (* 1 = 0.501697 loss)
I0423 13:53:31.579010 30295 sgd_solver.cpp:106] Iteration 44000, lr = 9e-06
I0423 13:55:14.667845 30295 solver.cpp:228] Iteration 44100, loss = 3.30248
I0423 13:55:14.667990 30295 solver.cpp:244]     Train net output #0: loss = 0.966123 (* 1 = 0.966123 loss)
I0423 13:55:14.667999 30295 solver.cpp:244]     Train net output #1: loss = 0.716242 (* 1 = 0.716242 loss)
I0423 13:55:14.668002 30295 solver.cpp:244]     Train net output #2: loss = 0.904196 (* 1 = 0.904196 loss)
I0423 13:55:14.668007 30295 solver.cpp:244]     Train net output #3: loss = 0.715915 (* 1 = 0.715915 loss)
I0423 13:55:14.668012 30295 sgd_solver.cpp:106] Iteration 44100, lr = 9e-06
I0423 13:56:57.723335 30295 solver.cpp:228] Iteration 44200, loss = 3.21244
I0423 13:56:57.723489 30295 solver.cpp:244]     Train net output #0: loss = 0.97172 (* 1 = 0.97172 loss)
I0423 13:56:57.723497 30295 solver.cpp:244]     Train net output #1: loss = 0.705708 (* 1 = 0.705708 loss)
I0423 13:56:57.723502 30295 solver.cpp:244]     Train net output #2: loss = 0.869548 (* 1 = 0.869548 loss)
I0423 13:56:57.723507 30295 solver.cpp:244]     Train net output #3: loss = 0.665462 (* 1 = 0.665462 loss)
I0423 13:56:57.723512 30295 sgd_solver.cpp:106] Iteration 44200, lr = 9e-06
I0423 13:58:36.677662 30295 solver.cpp:228] Iteration 44300, loss = 3.28749
I0423 13:58:36.677831 30295 solver.cpp:244]     Train net output #0: loss = 0.971004 (* 1 = 0.971004 loss)
I0423 13:58:36.677839 30295 solver.cpp:244]     Train net output #1: loss = 0.74752 (* 1 = 0.74752 loss)
I0423 13:58:36.677845 30295 solver.cpp:244]     Train net output #2: loss = 0.932514 (* 1 = 0.932514 loss)
I0423 13:58:36.677850 30295 solver.cpp:244]     Train net output #3: loss = 0.636449 (* 1 = 0.636449 loss)
I0423 13:58:36.677855 30295 sgd_solver.cpp:106] Iteration 44300, lr = 9e-06
I0423 14:00:19.216917 30295 solver.cpp:228] Iteration 44400, loss = 3.20963
I0423 14:00:19.217059 30295 solver.cpp:244]     Train net output #0: loss = 0.9738 (* 1 = 0.9738 loss)
I0423 14:00:19.217067 30295 solver.cpp:244]     Train net output #1: loss = 0.664121 (* 1 = 0.664121 loss)
I0423 14:00:19.217072 30295 solver.cpp:244]     Train net output #2: loss = 0.924878 (* 1 = 0.924878 loss)
I0423 14:00:19.217077 30295 solver.cpp:244]     Train net output #3: loss = 0.646832 (* 1 = 0.646832 loss)
I0423 14:00:19.217082 30295 sgd_solver.cpp:106] Iteration 44400, lr = 9e-06
I0423 14:02:02.381312 30295 solver.cpp:228] Iteration 44500, loss = 3.02232
I0423 14:02:02.381497 30295 solver.cpp:244]     Train net output #0: loss = 0.987233 (* 1 = 0.987233 loss)
I0423 14:02:02.381505 30295 solver.cpp:244]     Train net output #1: loss = 0.506512 (* 1 = 0.506512 loss)
I0423 14:02:02.381510 30295 solver.cpp:244]     Train net output #2: loss = 0.852184 (* 1 = 0.852184 loss)
I0423 14:02:02.381515 30295 solver.cpp:244]     Train net output #3: loss = 0.676392 (* 1 = 0.676392 loss)
I0423 14:02:02.381520 30295 sgd_solver.cpp:106] Iteration 44500, lr = 9e-06
I0423 14:03:41.360752 30295 solver.cpp:228] Iteration 44600, loss = 3.01469
I0423 14:03:41.360905 30295 solver.cpp:244]     Train net output #0: loss = 0.982639 (* 1 = 0.982639 loss)
I0423 14:03:41.360913 30295 solver.cpp:244]     Train net output #1: loss = 0.579013 (* 1 = 0.579013 loss)
I0423 14:03:41.360918 30295 solver.cpp:244]     Train net output #2: loss = 0.83821 (* 1 = 0.83821 loss)
I0423 14:03:41.360922 30295 solver.cpp:244]     Train net output #3: loss = 0.614824 (* 1 = 0.614824 loss)
I0423 14:03:41.360926 30295 sgd_solver.cpp:106] Iteration 44600, lr = 9e-06
I0423 14:05:22.467917 30295 solver.cpp:228] Iteration 44700, loss = 3.24483
I0423 14:05:22.468112 30295 solver.cpp:244]     Train net output #0: loss = 0.982005 (* 1 = 0.982005 loss)
I0423 14:05:22.468120 30295 solver.cpp:244]     Train net output #1: loss = 0.653552 (* 1 = 0.653552 loss)
I0423 14:05:22.468125 30295 solver.cpp:244]     Train net output #2: loss = 0.89816 (* 1 = 0.89816 loss)
I0423 14:05:22.468130 30295 solver.cpp:244]     Train net output #3: loss = 0.711115 (* 1 = 0.711115 loss)
I0423 14:05:22.468135 30295 sgd_solver.cpp:106] Iteration 44700, lr = 9e-06
I0423 14:07:02.928591 30295 solver.cpp:228] Iteration 44800, loss = 2.27331
I0423 14:07:02.928763 30295 solver.cpp:244]     Train net output #0: loss = 0.983109 (* 1 = 0.983109 loss)
I0423 14:07:02.928771 30295 solver.cpp:244]     Train net output #1: loss = 0.456513 (* 1 = 0.456513 loss)
I0423 14:07:02.928776 30295 solver.cpp:244]     Train net output #2: loss = 0.376552 (* 1 = 0.376552 loss)
I0423 14:07:02.928781 30295 solver.cpp:244]     Train net output #3: loss = 0.457135 (* 1 = 0.457135 loss)
I0423 14:07:02.928786 30295 sgd_solver.cpp:106] Iteration 44800, lr = 9e-06
I0423 14:08:43.338794 30295 solver.cpp:228] Iteration 44900, loss = 2.85606
I0423 14:08:43.338950 30295 solver.cpp:244]     Train net output #0: loss = 0.986334 (* 1 = 0.986334 loss)
I0423 14:08:43.338958 30295 solver.cpp:244]     Train net output #1: loss = 0.509991 (* 1 = 0.509991 loss)
I0423 14:08:43.338963 30295 solver.cpp:244]     Train net output #2: loss = 0.742616 (* 1 = 0.742616 loss)
I0423 14:08:43.338968 30295 solver.cpp:244]     Train net output #3: loss = 0.617119 (* 1 = 0.617119 loss)
I0423 14:08:43.338973 30295 sgd_solver.cpp:106] Iteration 44900, lr = 9e-06
I0423 14:10:22.697950 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_45000.caffemodel
I0423 14:10:38.835381 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_45000.solverstate
I0423 14:10:39.040987 30295 solver.cpp:337] Iteration 45000, Testing net (#0)
I0423 14:10:39.041009 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 14:10:39.041013 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 14:10:39.041015 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 14:10:39.041028 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 14:10:39.041031 30295 net.cpp:693] Ignoring source layer visualize
I0423 14:10:39.041033 30295 net.cpp:693] Ignoring source layer fake
I0423 14:14:13.681294 30295 solver.cpp:404]     Test net output #0: loss = 0.971612 (* 1 = 0.971612 loss)
I0423 14:14:13.681463 30295 solver.cpp:404]     Test net output #1: loss = 0.50452 (* 1 = 0.50452 loss)
I0423 14:14:13.681469 30295 solver.cpp:404]     Test net output #2: loss = 0.810011 (* 1 = 0.810011 loss)
I0423 14:14:13.681474 30295 solver.cpp:404]     Test net output #3: loss = 0.562792 (* 1 = 0.562792 loss)
I0423 14:14:14.343926 30295 solver.cpp:228] Iteration 45000, loss = 3.09441
I0423 14:14:14.343955 30295 solver.cpp:244]     Train net output #0: loss = 0.980735 (* 1 = 0.980735 loss)
I0423 14:14:14.343976 30295 solver.cpp:244]     Train net output #1: loss = 0.693045 (* 1 = 0.693045 loss)
I0423 14:14:14.343996 30295 solver.cpp:244]     Train net output #2: loss = 0.760244 (* 1 = 0.760244 loss)
I0423 14:14:14.343999 30295 solver.cpp:244]     Train net output #3: loss = 0.660382 (* 1 = 0.660382 loss)
I0423 14:14:14.344004 30295 sgd_solver.cpp:106] Iteration 45000, lr = 9e-06
I0423 14:15:56.915627 30295 solver.cpp:228] Iteration 45100, loss = 3.19118
I0423 14:15:56.915786 30295 solver.cpp:244]     Train net output #0: loss = 0.963823 (* 1 = 0.963823 loss)
I0423 14:15:56.915792 30295 solver.cpp:244]     Train net output #1: loss = 0.729869 (* 1 = 0.729869 loss)
I0423 14:15:56.915798 30295 solver.cpp:244]     Train net output #2: loss = 0.762622 (* 1 = 0.762622 loss)
I0423 14:15:56.915802 30295 solver.cpp:244]     Train net output #3: loss = 0.734868 (* 1 = 0.734868 loss)
I0423 14:15:56.915807 30295 sgd_solver.cpp:106] Iteration 45100, lr = 9e-06
I0423 14:17:38.262673 30295 solver.cpp:228] Iteration 45200, loss = 2.51277
I0423 14:17:38.262847 30295 solver.cpp:244]     Train net output #0: loss = 0.980783 (* 1 = 0.980783 loss)
I0423 14:17:38.262856 30295 solver.cpp:244]     Train net output #1: loss = 0.546896 (* 1 = 0.546896 loss)
I0423 14:17:38.262861 30295 solver.cpp:244]     Train net output #2: loss = 0.574286 (* 1 = 0.574286 loss)
I0423 14:17:38.262864 30295 solver.cpp:244]     Train net output #3: loss = 0.410804 (* 1 = 0.410804 loss)
I0423 14:17:38.262871 30295 sgd_solver.cpp:106] Iteration 45200, lr = 9e-06
I0423 14:19:17.165598 30295 solver.cpp:228] Iteration 45300, loss = 2.4344
I0423 14:19:17.165757 30295 solver.cpp:244]     Train net output #0: loss = 0.980126 (* 1 = 0.980126 loss)
I0423 14:19:17.165766 30295 solver.cpp:244]     Train net output #1: loss = 0.495015 (* 1 = 0.495015 loss)
I0423 14:19:17.165771 30295 solver.cpp:244]     Train net output #2: loss = 0.572531 (* 1 = 0.572531 loss)
I0423 14:19:17.165776 30295 solver.cpp:244]     Train net output #3: loss = 0.386732 (* 1 = 0.386732 loss)
I0423 14:19:17.165779 30295 sgd_solver.cpp:106] Iteration 45300, lr = 9e-06
I0423 14:20:58.547188 30295 solver.cpp:228] Iteration 45400, loss = 3.29968
I0423 14:20:58.547338 30295 solver.cpp:244]     Train net output #0: loss = 0.976279 (* 1 = 0.976279 loss)
I0423 14:20:58.547345 30295 solver.cpp:244]     Train net output #1: loss = 0.794698 (* 1 = 0.794698 loss)
I0423 14:20:58.547350 30295 solver.cpp:244]     Train net output #2: loss = 0.84513 (* 1 = 0.84513 loss)
I0423 14:20:58.547354 30295 solver.cpp:244]     Train net output #3: loss = 0.683571 (* 1 = 0.683571 loss)
I0423 14:20:58.547360 30295 sgd_solver.cpp:106] Iteration 45400, lr = 9e-06
I0423 14:22:40.208195 30295 solver.cpp:228] Iteration 45500, loss = 3.30001
I0423 14:22:40.208348 30295 solver.cpp:244]     Train net output #0: loss = 0.971313 (* 1 = 0.971313 loss)
I0423 14:22:40.208356 30295 solver.cpp:244]     Train net output #1: loss = 0.693971 (* 1 = 0.693971 loss)
I0423 14:22:40.208361 30295 solver.cpp:244]     Train net output #2: loss = 0.918645 (* 1 = 0.918645 loss)
I0423 14:22:40.208366 30295 solver.cpp:244]     Train net output #3: loss = 0.716079 (* 1 = 0.716079 loss)
I0423 14:22:40.208370 30295 sgd_solver.cpp:106] Iteration 45500, lr = 9e-06
I0423 14:24:26.349568 30295 solver.cpp:228] Iteration 45600, loss = 3.1955
I0423 14:24:26.349705 30295 solver.cpp:244]     Train net output #0: loss = 0.961002 (* 1 = 0.961002 loss)
I0423 14:24:26.349712 30295 solver.cpp:244]     Train net output #1: loss = 0.679071 (* 1 = 0.679071 loss)
I0423 14:24:26.349717 30295 solver.cpp:244]     Train net output #2: loss = 0.930843 (* 1 = 0.930843 loss)
I0423 14:24:26.349722 30295 solver.cpp:244]     Train net output #3: loss = 0.624585 (* 1 = 0.624585 loss)
I0423 14:24:26.349727 30295 sgd_solver.cpp:106] Iteration 45600, lr = 9e-06
I0423 14:26:05.691036 30295 solver.cpp:228] Iteration 45700, loss = 3.36731
I0423 14:26:05.691179 30295 solver.cpp:244]     Train net output #0: loss = 0.97381 (* 1 = 0.97381 loss)
I0423 14:26:05.691186 30295 solver.cpp:244]     Train net output #1: loss = 0.780718 (* 1 = 0.780718 loss)
I0423 14:26:05.691192 30295 solver.cpp:244]     Train net output #2: loss = 0.938213 (* 1 = 0.938213 loss)
I0423 14:26:05.691196 30295 solver.cpp:244]     Train net output #3: loss = 0.674572 (* 1 = 0.674572 loss)
I0423 14:26:05.691201 30295 sgd_solver.cpp:106] Iteration 45700, lr = 9e-06
I0423 14:27:48.122217 30295 solver.cpp:228] Iteration 45800, loss = 3.19037
I0423 14:27:48.122366 30295 solver.cpp:244]     Train net output #0: loss = 0.973273 (* 1 = 0.973273 loss)
I0423 14:27:48.122375 30295 solver.cpp:244]     Train net output #1: loss = 0.596018 (* 1 = 0.596018 loss)
I0423 14:27:48.122378 30295 solver.cpp:244]     Train net output #2: loss = 0.92553 (* 1 = 0.92553 loss)
I0423 14:27:48.122383 30295 solver.cpp:244]     Train net output #3: loss = 0.695548 (* 1 = 0.695548 loss)
I0423 14:27:48.122388 30295 sgd_solver.cpp:106] Iteration 45800, lr = 9e-06
I0423 14:29:29.371366 30295 solver.cpp:228] Iteration 45900, loss = 3.37188
I0423 14:29:29.372265 30295 solver.cpp:244]     Train net output #0: loss = 0.98825 (* 1 = 0.98825 loss)
I0423 14:29:29.372273 30295 solver.cpp:244]     Train net output #1: loss = 0.705966 (* 1 = 0.705966 loss)
I0423 14:29:29.372278 30295 solver.cpp:244]     Train net output #2: loss = 0.939581 (* 1 = 0.939581 loss)
I0423 14:29:29.372283 30295 solver.cpp:244]     Train net output #3: loss = 0.73808 (* 1 = 0.73808 loss)
I0423 14:29:29.372287 30295 sgd_solver.cpp:106] Iteration 45900, lr = 9e-06
I0423 14:31:09.525440 30295 solver.cpp:337] Iteration 46000, Testing net (#0)
I0423 14:31:09.525611 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 14:31:09.525615 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 14:31:09.525619 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 14:31:09.525634 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 14:31:09.525637 30295 net.cpp:693] Ignoring source layer visualize
I0423 14:31:09.525640 30295 net.cpp:693] Ignoring source layer fake
I0423 14:34:46.913424 30295 solver.cpp:404]     Test net output #0: loss = 0.968478 (* 1 = 0.968478 loss)
I0423 14:34:46.913607 30295 solver.cpp:404]     Test net output #1: loss = 0.525162 (* 1 = 0.525162 loss)
I0423 14:34:46.913615 30295 solver.cpp:404]     Test net output #2: loss = 0.825932 (* 1 = 0.825932 loss)
I0423 14:34:46.913619 30295 solver.cpp:404]     Test net output #3: loss = 0.586999 (* 1 = 0.586999 loss)
I0423 14:34:47.573608 30295 solver.cpp:228] Iteration 46000, loss = 2.83567
I0423 14:34:47.573632 30295 solver.cpp:244]     Train net output #0: loss = 0.981961 (* 1 = 0.981961 loss)
I0423 14:34:47.573653 30295 solver.cpp:244]     Train net output #1: loss = 0.486287 (* 1 = 0.486287 loss)
I0423 14:34:47.573657 30295 solver.cpp:244]     Train net output #2: loss = 0.749959 (* 1 = 0.749959 loss)
I0423 14:34:47.573660 30295 solver.cpp:244]     Train net output #3: loss = 0.617467 (* 1 = 0.617467 loss)
I0423 14:34:47.573668 30295 sgd_solver.cpp:106] Iteration 46000, lr = 9e-06
I0423 14:36:27.174259 30295 solver.cpp:228] Iteration 46100, loss = 2.80169
I0423 14:36:27.174370 30295 solver.cpp:244]     Train net output #0: loss = 0.978373 (* 1 = 0.978373 loss)
I0423 14:36:27.174391 30295 solver.cpp:244]     Train net output #1: loss = 0.534317 (* 1 = 0.534317 loss)
I0423 14:36:27.174396 30295 solver.cpp:244]     Train net output #2: loss = 0.721083 (* 1 = 0.721083 loss)
I0423 14:36:27.174399 30295 solver.cpp:244]     Train net output #3: loss = 0.567915 (* 1 = 0.567915 loss)
I0423 14:36:27.174404 30295 sgd_solver.cpp:106] Iteration 46100, lr = 9e-06
I0423 14:38:08.910691 30295 solver.cpp:228] Iteration 46200, loss = 2.53119
I0423 14:38:08.910841 30295 solver.cpp:244]     Train net output #0: loss = 0.989279 (* 1 = 0.989279 loss)
I0423 14:38:08.910850 30295 solver.cpp:244]     Train net output #1: loss = 0.390432 (* 1 = 0.390432 loss)
I0423 14:38:08.910854 30295 solver.cpp:244]     Train net output #2: loss = 0.607875 (* 1 = 0.607875 loss)
I0423 14:38:08.910858 30295 solver.cpp:244]     Train net output #3: loss = 0.543601 (* 1 = 0.543601 loss)
I0423 14:38:08.910863 30295 sgd_solver.cpp:106] Iteration 46200, lr = 9e-06
I0423 14:39:49.780932 30295 solver.cpp:228] Iteration 46300, loss = 3.04131
I0423 14:39:49.781086 30295 solver.cpp:244]     Train net output #0: loss = 0.971427 (* 1 = 0.971427 loss)
I0423 14:39:49.781093 30295 solver.cpp:244]     Train net output #1: loss = 0.572289 (* 1 = 0.572289 loss)
I0423 14:39:49.781097 30295 solver.cpp:244]     Train net output #2: loss = 0.939856 (* 1 = 0.939856 loss)
I0423 14:39:49.781102 30295 solver.cpp:244]     Train net output #3: loss = 0.557738 (* 1 = 0.557738 loss)
I0423 14:39:49.781107 30295 sgd_solver.cpp:106] Iteration 46300, lr = 9e-06
I0423 14:41:31.005908 30295 solver.cpp:228] Iteration 46400, loss = 2.96664
I0423 14:41:31.006083 30295 solver.cpp:244]     Train net output #0: loss = 0.966303 (* 1 = 0.966303 loss)
I0423 14:41:31.006091 30295 solver.cpp:244]     Train net output #1: loss = 0.674525 (* 1 = 0.674525 loss)
I0423 14:41:31.006096 30295 solver.cpp:244]     Train net output #2: loss = 0.778759 (* 1 = 0.778759 loss)
I0423 14:41:31.006101 30295 solver.cpp:244]     Train net output #3: loss = 0.54705 (* 1 = 0.54705 loss)
I0423 14:41:31.006105 30295 sgd_solver.cpp:106] Iteration 46400, lr = 9e-06
I0423 14:43:12.574757 30295 solver.cpp:228] Iteration 46500, loss = 2.80215
I0423 14:43:12.574934 30295 solver.cpp:244]     Train net output #0: loss = 0.978994 (* 1 = 0.978994 loss)
I0423 14:43:12.574941 30295 solver.cpp:244]     Train net output #1: loss = 0.410539 (* 1 = 0.410539 loss)
I0423 14:43:12.574946 30295 solver.cpp:244]     Train net output #2: loss = 0.751942 (* 1 = 0.751942 loss)
I0423 14:43:12.574952 30295 solver.cpp:244]     Train net output #3: loss = 0.660673 (* 1 = 0.660673 loss)
I0423 14:43:12.574957 30295 sgd_solver.cpp:106] Iteration 46500, lr = 9e-06
I0423 14:44:54.231470 30295 solver.cpp:228] Iteration 46600, loss = 3.26322
I0423 14:44:54.232983 30295 solver.cpp:244]     Train net output #0: loss = 0.980982 (* 1 = 0.980982 loss)
I0423 14:44:54.232992 30295 solver.cpp:244]     Train net output #1: loss = 0.751434 (* 1 = 0.751434 loss)
I0423 14:44:54.232997 30295 solver.cpp:244]     Train net output #2: loss = 0.772974 (* 1 = 0.772974 loss)
I0423 14:44:54.233001 30295 solver.cpp:244]     Train net output #3: loss = 0.757827 (* 1 = 0.757827 loss)
I0423 14:44:54.233006 30295 sgd_solver.cpp:106] Iteration 46600, lr = 9e-06
I0423 14:46:35.799317 30295 solver.cpp:228] Iteration 46700, loss = 3.21012
I0423 14:46:35.799491 30295 solver.cpp:244]     Train net output #0: loss = 0.96109 (* 1 = 0.96109 loss)
I0423 14:46:35.799499 30295 solver.cpp:244]     Train net output #1: loss = 0.655163 (* 1 = 0.655163 loss)
I0423 14:46:35.799504 30295 solver.cpp:244]     Train net output #2: loss = 0.922955 (* 1 = 0.922955 loss)
I0423 14:46:35.799510 30295 solver.cpp:244]     Train net output #3: loss = 0.670914 (* 1 = 0.670914 loss)
I0423 14:46:35.799515 30295 sgd_solver.cpp:106] Iteration 46700, lr = 9e-06
I0423 14:48:15.461359 30295 solver.cpp:228] Iteration 46800, loss = 3.32604
I0423 14:48:15.461524 30295 solver.cpp:244]     Train net output #0: loss = 0.977264 (* 1 = 0.977264 loss)
I0423 14:48:15.461532 30295 solver.cpp:244]     Train net output #1: loss = 0.823521 (* 1 = 0.823521 loss)
I0423 14:48:15.461536 30295 solver.cpp:244]     Train net output #2: loss = 0.913796 (* 1 = 0.913796 loss)
I0423 14:48:15.461542 30295 solver.cpp:244]     Train net output #3: loss = 0.611456 (* 1 = 0.611456 loss)
I0423 14:48:15.461547 30295 sgd_solver.cpp:106] Iteration 46800, lr = 9e-06
I0423 14:49:58.362409 30295 solver.cpp:228] Iteration 46900, loss = 3.38313
I0423 14:49:58.362464 30295 solver.cpp:244]     Train net output #0: loss = 0.986776 (* 1 = 0.986776 loss)
I0423 14:49:58.362470 30295 solver.cpp:244]     Train net output #1: loss = 0.794456 (* 1 = 0.794456 loss)
I0423 14:49:58.362474 30295 solver.cpp:244]     Train net output #2: loss = 0.916684 (* 1 = 0.916684 loss)
I0423 14:49:58.362479 30295 solver.cpp:244]     Train net output #3: loss = 0.685213 (* 1 = 0.685213 loss)
I0423 14:49:58.362499 30295 sgd_solver.cpp:106] Iteration 46900, lr = 9e-06
I0423 14:51:39.229262 30295 solver.cpp:337] Iteration 47000, Testing net (#0)
I0423 14:51:39.229434 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 14:51:39.229454 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 14:51:39.229457 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 14:51:39.229471 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 14:51:39.229475 30295 net.cpp:693] Ignoring source layer visualize
I0423 14:51:39.229476 30295 net.cpp:693] Ignoring source layer fake
I0423 14:55:16.905633 30295 solver.cpp:404]     Test net output #0: loss = 0.972307 (* 1 = 0.972307 loss)
I0423 14:55:16.905805 30295 solver.cpp:404]     Test net output #1: loss = 0.480177 (* 1 = 0.480177 loss)
I0423 14:55:16.905812 30295 solver.cpp:404]     Test net output #2: loss = 0.782336 (* 1 = 0.782336 loss)
I0423 14:55:16.905817 30295 solver.cpp:404]     Test net output #3: loss = 0.485757 (* 1 = 0.485757 loss)
I0423 14:55:17.566263 30295 solver.cpp:228] Iteration 47000, loss = 3.06391
I0423 14:55:17.566305 30295 solver.cpp:244]     Train net output #0: loss = 0.972142 (* 1 = 0.972142 loss)
I0423 14:55:17.566310 30295 solver.cpp:244]     Train net output #1: loss = 0.526472 (* 1 = 0.526472 loss)
I0423 14:55:17.566315 30295 solver.cpp:244]     Train net output #2: loss = 0.899849 (* 1 = 0.899849 loss)
I0423 14:55:17.566319 30295 solver.cpp:244]     Train net output #3: loss = 0.66545 (* 1 = 0.66545 loss)
I0423 14:55:17.566323 30295 sgd_solver.cpp:106] Iteration 47000, lr = 9e-06
I0423 14:56:57.259402 30295 solver.cpp:228] Iteration 47100, loss = 3.23827
I0423 14:56:57.259582 30295 solver.cpp:244]     Train net output #0: loss = 0.987875 (* 1 = 0.987875 loss)
I0423 14:56:57.259589 30295 solver.cpp:244]     Train net output #1: loss = 0.620885 (* 1 = 0.620885 loss)
I0423 14:56:57.259594 30295 solver.cpp:244]     Train net output #2: loss = 0.929512 (* 1 = 0.929512 loss)
I0423 14:56:57.259598 30295 solver.cpp:244]     Train net output #3: loss = 0.699994 (* 1 = 0.699994 loss)
I0423 14:56:57.259604 30295 sgd_solver.cpp:106] Iteration 47100, lr = 9e-06
I0423 14:58:38.869215 30295 solver.cpp:228] Iteration 47200, loss = 3.27759
I0423 14:58:38.869395 30295 solver.cpp:244]     Train net output #0: loss = 0.977468 (* 1 = 0.977468 loss)
I0423 14:58:38.869405 30295 solver.cpp:244]     Train net output #1: loss = 0.64066 (* 1 = 0.64066 loss)
I0423 14:58:38.869411 30295 solver.cpp:244]     Train net output #2: loss = 0.956229 (* 1 = 0.956229 loss)
I0423 14:58:38.869415 30295 solver.cpp:244]     Train net output #3: loss = 0.703234 (* 1 = 0.703234 loss)
I0423 14:58:38.869420 30295 sgd_solver.cpp:106] Iteration 47200, lr = 9e-06
I0423 15:00:20.519110 30295 solver.cpp:228] Iteration 47300, loss = 2.80934
I0423 15:00:20.519245 30295 solver.cpp:244]     Train net output #0: loss = 0.986892 (* 1 = 0.986892 loss)
I0423 15:00:20.519253 30295 solver.cpp:244]     Train net output #1: loss = 0.521022 (* 1 = 0.521022 loss)
I0423 15:00:20.519258 30295 solver.cpp:244]     Train net output #2: loss = 0.749631 (* 1 = 0.749631 loss)
I0423 15:00:20.519261 30295 solver.cpp:244]     Train net output #3: loss = 0.551799 (* 1 = 0.551799 loss)
I0423 15:00:20.519268 30295 sgd_solver.cpp:106] Iteration 47300, lr = 9e-06
I0423 15:02:01.942246 30295 solver.cpp:228] Iteration 47400, loss = 3.04645
I0423 15:02:01.942396 30295 solver.cpp:244]     Train net output #0: loss = 0.981361 (* 1 = 0.981361 loss)
I0423 15:02:01.942404 30295 solver.cpp:244]     Train net output #1: loss = 0.529053 (* 1 = 0.529053 loss)
I0423 15:02:01.942409 30295 solver.cpp:244]     Train net output #2: loss = 0.938957 (* 1 = 0.938957 loss)
I0423 15:02:01.942414 30295 solver.cpp:244]     Train net output #3: loss = 0.597078 (* 1 = 0.597078 loss)
I0423 15:02:01.942420 30295 sgd_solver.cpp:106] Iteration 47400, lr = 9e-06
I0423 15:03:42.955072 30295 solver.cpp:228] Iteration 47500, loss = 3.23178
I0423 15:03:42.955214 30295 solver.cpp:244]     Train net output #0: loss = 0.966444 (* 1 = 0.966444 loss)
I0423 15:03:42.955220 30295 solver.cpp:244]     Train net output #1: loss = 0.768768 (* 1 = 0.768768 loss)
I0423 15:03:42.955225 30295 solver.cpp:244]     Train net output #2: loss = 0.771808 (* 1 = 0.771808 loss)
I0423 15:03:42.955229 30295 solver.cpp:244]     Train net output #3: loss = 0.724762 (* 1 = 0.724762 loss)
I0423 15:03:42.955235 30295 sgd_solver.cpp:106] Iteration 47500, lr = 9e-06
I0423 15:05:24.919896 30295 solver.cpp:228] Iteration 47600, loss = 3.19108
I0423 15:05:24.920039 30295 solver.cpp:244]     Train net output #0: loss = 0.980906 (* 1 = 0.980906 loss)
I0423 15:05:24.920047 30295 solver.cpp:244]     Train net output #1: loss = 0.717044 (* 1 = 0.717044 loss)
I0423 15:05:24.920052 30295 solver.cpp:244]     Train net output #2: loss = 0.773571 (* 1 = 0.773571 loss)
I0423 15:05:24.920056 30295 solver.cpp:244]     Train net output #3: loss = 0.719563 (* 1 = 0.719563 loss)
I0423 15:05:24.920060 30295 sgd_solver.cpp:106] Iteration 47600, lr = 9e-06
I0423 15:07:06.925432 30295 solver.cpp:228] Iteration 47700, loss = 2.3341
I0423 15:07:06.925604 30295 solver.cpp:244]     Train net output #0: loss = 0.983899 (* 1 = 0.983899 loss)
I0423 15:07:06.925612 30295 solver.cpp:244]     Train net output #1: loss = 0.383231 (* 1 = 0.383231 loss)
I0423 15:07:06.925616 30295 solver.cpp:244]     Train net output #2: loss = 0.575396 (* 1 = 0.575396 loss)
I0423 15:07:06.925621 30295 solver.cpp:244]     Train net output #3: loss = 0.391576 (* 1 = 0.391576 loss)
I0423 15:07:06.925626 30295 sgd_solver.cpp:106] Iteration 47700, lr = 9e-06
I0423 15:08:46.510082 30295 solver.cpp:228] Iteration 47800, loss = 2.91201
I0423 15:08:46.510234 30295 solver.cpp:244]     Train net output #0: loss = 0.974252 (* 1 = 0.974252 loss)
I0423 15:08:46.510242 30295 solver.cpp:244]     Train net output #1: loss = 0.598496 (* 1 = 0.598496 loss)
I0423 15:08:46.510247 30295 solver.cpp:244]     Train net output #2: loss = 0.772105 (* 1 = 0.772105 loss)
I0423 15:08:46.510252 30295 solver.cpp:244]     Train net output #3: loss = 0.567159 (* 1 = 0.567159 loss)
I0423 15:08:46.510257 30295 sgd_solver.cpp:106] Iteration 47800, lr = 9e-06
I0423 15:10:27.829243 30295 solver.cpp:228] Iteration 47900, loss = 3.28622
I0423 15:10:27.829385 30295 solver.cpp:244]     Train net output #0: loss = 0.974812 (* 1 = 0.974812 loss)
I0423 15:10:27.829393 30295 solver.cpp:244]     Train net output #1: loss = 0.802561 (* 1 = 0.802561 loss)
I0423 15:10:27.829398 30295 solver.cpp:244]     Train net output #2: loss = 0.846953 (* 1 = 0.846953 loss)
I0423 15:10:27.829402 30295 solver.cpp:244]     Train net output #3: loss = 0.66189 (* 1 = 0.66189 loss)
I0423 15:10:27.829407 30295 sgd_solver.cpp:106] Iteration 47900, lr = 9e-06
I0423 15:12:09.020926 30295 solver.cpp:337] Iteration 48000, Testing net (#0)
I0423 15:12:09.021078 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 15:12:09.021082 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 15:12:09.021087 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 15:12:09.021101 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 15:12:09.021105 30295 net.cpp:693] Ignoring source layer visualize
I0423 15:12:09.021107 30295 net.cpp:693] Ignoring source layer fake
I0423 15:15:47.457509 30295 solver.cpp:404]     Test net output #0: loss = 0.971918 (* 1 = 0.971918 loss)
I0423 15:15:47.457644 30295 solver.cpp:404]     Test net output #1: loss = 0.486185 (* 1 = 0.486185 loss)
I0423 15:15:47.457651 30295 solver.cpp:404]     Test net output #2: loss = 0.81004 (* 1 = 0.81004 loss)
I0423 15:15:47.457655 30295 solver.cpp:404]     Test net output #3: loss = 0.552221 (* 1 = 0.552221 loss)
I0423 15:15:48.121233 30295 solver.cpp:228] Iteration 48000, loss = 3.2986
I0423 15:15:48.121275 30295 solver.cpp:244]     Train net output #0: loss = 0.973431 (* 1 = 0.973431 loss)
I0423 15:15:48.121281 30295 solver.cpp:244]     Train net output #1: loss = 0.702465 (* 1 = 0.702465 loss)
I0423 15:15:48.121285 30295 solver.cpp:244]     Train net output #2: loss = 0.925079 (* 1 = 0.925079 loss)
I0423 15:15:48.121289 30295 solver.cpp:244]     Train net output #3: loss = 0.69763 (* 1 = 0.69763 loss)
I0423 15:15:48.121295 30295 sgd_solver.cpp:106] Iteration 48000, lr = 9e-06
I0423 15:17:31.231380 30295 solver.cpp:228] Iteration 48100, loss = 3.26302
I0423 15:17:31.231542 30295 solver.cpp:244]     Train net output #0: loss = 0.963422 (* 1 = 0.963422 loss)
I0423 15:17:31.231551 30295 solver.cpp:244]     Train net output #1: loss = 0.800063 (* 1 = 0.800063 loss)
I0423 15:17:31.231556 30295 solver.cpp:244]     Train net output #2: loss = 0.88085 (* 1 = 0.88085 loss)
I0423 15:17:31.231560 30295 solver.cpp:244]     Train net output #3: loss = 0.618687 (* 1 = 0.618687 loss)
I0423 15:17:31.231565 30295 sgd_solver.cpp:106] Iteration 48100, lr = 9e-06
I0423 15:19:11.076612 30295 solver.cpp:228] Iteration 48200, loss = 3.37768
I0423 15:19:11.076782 30295 solver.cpp:244]     Train net output #0: loss = 0.973909 (* 1 = 0.973909 loss)
I0423 15:19:11.076789 30295 solver.cpp:244]     Train net output #1: loss = 0.832569 (* 1 = 0.832569 loss)
I0423 15:19:11.076794 30295 solver.cpp:244]     Train net output #2: loss = 0.909384 (* 1 = 0.909384 loss)
I0423 15:19:11.076799 30295 solver.cpp:244]     Train net output #3: loss = 0.661819 (* 1 = 0.661819 loss)
I0423 15:19:11.076804 30295 sgd_solver.cpp:106] Iteration 48200, lr = 9e-06
I0423 15:20:58.453284 30295 solver.cpp:228] Iteration 48300, loss = 3.08362
I0423 15:20:58.453447 30295 solver.cpp:244]     Train net output #0: loss = 0.984847 (* 1 = 0.984847 loss)
I0423 15:20:58.453456 30295 solver.cpp:244]     Train net output #1: loss = 0.488288 (* 1 = 0.488288 loss)
I0423 15:20:58.453461 30295 solver.cpp:244]     Train net output #2: loss = 0.900936 (* 1 = 0.900936 loss)
I0423 15:20:58.453466 30295 solver.cpp:244]     Train net output #3: loss = 0.709547 (* 1 = 0.709547 loss)
I0423 15:20:58.453471 30295 sgd_solver.cpp:106] Iteration 48300, lr = 9e-06
I0423 15:22:44.880491 30295 solver.cpp:228] Iteration 48400, loss = 3.28343
I0423 15:22:44.880633 30295 solver.cpp:244]     Train net output #0: loss = 0.982322 (* 1 = 0.982322 loss)
I0423 15:22:44.880640 30295 solver.cpp:244]     Train net output #1: loss = 0.63198 (* 1 = 0.63198 loss)
I0423 15:22:44.880645 30295 solver.cpp:244]     Train net output #2: loss = 0.944955 (* 1 = 0.944955 loss)
I0423 15:22:44.880650 30295 solver.cpp:244]     Train net output #3: loss = 0.724171 (* 1 = 0.724171 loss)
I0423 15:22:44.880656 30295 sgd_solver.cpp:106] Iteration 48400, lr = 9e-06
I0423 15:24:30.798995 30295 solver.cpp:228] Iteration 48500, loss = 3.04723
I0423 15:24:30.799140 30295 solver.cpp:244]     Train net output #0: loss = 0.987269 (* 1 = 0.987269 loss)
I0423 15:24:30.799149 30295 solver.cpp:244]     Train net output #1: loss = 0.441623 (* 1 = 0.441623 loss)
I0423 15:24:30.799154 30295 solver.cpp:244]     Train net output #2: loss = 0.919563 (* 1 = 0.919563 loss)
I0423 15:24:30.799157 30295 solver.cpp:244]     Train net output #3: loss = 0.698771 (* 1 = 0.698771 loss)
I0423 15:24:30.799162 30295 sgd_solver.cpp:106] Iteration 48500, lr = 9e-06
I0423 15:26:10.073199 30295 solver.cpp:228] Iteration 48600, loss = 2.96275
I0423 15:26:10.073357 30295 solver.cpp:244]     Train net output #0: loss = 0.989213 (* 1 = 0.989213 loss)
I0423 15:26:10.073365 30295 solver.cpp:244]     Train net output #1: loss = 0.459665 (* 1 = 0.459665 loss)
I0423 15:26:10.073369 30295 solver.cpp:244]     Train net output #2: loss = 0.887456 (* 1 = 0.887456 loss)
I0423 15:26:10.073375 30295 solver.cpp:244]     Train net output #3: loss = 0.626419 (* 1 = 0.626419 loss)
I0423 15:26:10.073382 30295 sgd_solver.cpp:106] Iteration 48600, lr = 9e-06
I0423 15:27:54.322304 30295 solver.cpp:228] Iteration 48700, loss = 3.03796
I0423 15:27:54.322448 30295 solver.cpp:244]     Train net output #0: loss = 0.986266 (* 1 = 0.986266 loss)
I0423 15:27:54.322456 30295 solver.cpp:244]     Train net output #1: loss = 0.536095 (* 1 = 0.536095 loss)
I0423 15:27:54.322461 30295 solver.cpp:244]     Train net output #2: loss = 0.963192 (* 1 = 0.963192 loss)
I0423 15:27:54.322466 30295 solver.cpp:244]     Train net output #3: loss = 0.552403 (* 1 = 0.552403 loss)
I0423 15:27:54.322470 30295 sgd_solver.cpp:106] Iteration 48700, lr = 9e-06
I0423 15:29:36.768143 30295 solver.cpp:228] Iteration 48800, loss = 3.06123
I0423 15:29:36.768303 30295 solver.cpp:244]     Train net output #0: loss = 0.973124 (* 1 = 0.973124 loss)
I0423 15:29:36.768311 30295 solver.cpp:244]     Train net output #1: loss = 0.609602 (* 1 = 0.609602 loss)
I0423 15:29:36.768316 30295 solver.cpp:244]     Train net output #2: loss = 0.942814 (* 1 = 0.942814 loss)
I0423 15:29:36.768321 30295 solver.cpp:244]     Train net output #3: loss = 0.53569 (* 1 = 0.53569 loss)
I0423 15:29:36.768324 30295 sgd_solver.cpp:106] Iteration 48800, lr = 9e-06
I0423 15:31:17.993228 30295 solver.cpp:228] Iteration 48900, loss = 2.81802
I0423 15:31:17.993402 30295 solver.cpp:244]     Train net output #0: loss = 0.978539 (* 1 = 0.978539 loss)
I0423 15:31:17.993410 30295 solver.cpp:244]     Train net output #1: loss = 0.721051 (* 1 = 0.721051 loss)
I0423 15:31:17.993415 30295 solver.cpp:244]     Train net output #2: loss = 0.569798 (* 1 = 0.569798 loss)
I0423 15:31:17.993419 30295 solver.cpp:244]     Train net output #3: loss = 0.548631 (* 1 = 0.548631 loss)
I0423 15:31:17.993424 30295 sgd_solver.cpp:106] Iteration 48900, lr = 9e-06
I0423 15:32:58.313024 30295 solver.cpp:337] Iteration 49000, Testing net (#0)
I0423 15:32:58.313170 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 15:32:58.313174 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 15:32:58.313177 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 15:32:58.313192 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 15:32:58.313195 30295 net.cpp:693] Ignoring source layer visualize
I0423 15:32:58.313197 30295 net.cpp:693] Ignoring source layer fake
I0423 15:36:40.691721 30295 solver.cpp:404]     Test net output #0: loss = 0.974547 (* 1 = 0.974547 loss)
I0423 15:36:40.691872 30295 solver.cpp:404]     Test net output #1: loss = 0.532592 (* 1 = 0.532592 loss)
I0423 15:36:40.691879 30295 solver.cpp:404]     Test net output #2: loss = 0.808417 (* 1 = 0.808417 loss)
I0423 15:36:40.691884 30295 solver.cpp:404]     Test net output #3: loss = 0.564107 (* 1 = 0.564107 loss)
I0423 15:36:41.354715 30295 solver.cpp:228] Iteration 49000, loss = 2.75703
I0423 15:36:41.354759 30295 solver.cpp:244]     Train net output #0: loss = 0.983171 (* 1 = 0.983171 loss)
I0423 15:36:41.354765 30295 solver.cpp:244]     Train net output #1: loss = 0.582325 (* 1 = 0.582325 loss)
I0423 15:36:41.354769 30295 solver.cpp:244]     Train net output #2: loss = 0.585268 (* 1 = 0.585268 loss)
I0423 15:36:41.354773 30295 solver.cpp:244]     Train net output #3: loss = 0.606262 (* 1 = 0.606262 loss)
I0423 15:36:41.354779 30295 sgd_solver.cpp:106] Iteration 49000, lr = 9e-06
I0423 15:38:26.596671 30295 solver.cpp:228] Iteration 49100, loss = 3.08588
I0423 15:38:26.596839 30295 solver.cpp:244]     Train net output #0: loss = 0.979791 (* 1 = 0.979791 loss)
I0423 15:38:26.596848 30295 solver.cpp:244]     Train net output #1: loss = 0.724637 (* 1 = 0.724637 loss)
I0423 15:38:26.596853 30295 solver.cpp:244]     Train net output #2: loss = 0.709737 (* 1 = 0.709737 loss)
I0423 15:38:26.596858 30295 solver.cpp:244]     Train net output #3: loss = 0.671712 (* 1 = 0.671712 loss)
I0423 15:38:26.596863 30295 sgd_solver.cpp:106] Iteration 49100, lr = 9e-06
I0423 15:40:09.845007 30295 solver.cpp:228] Iteration 49200, loss = 3.27615
I0423 15:40:09.845172 30295 solver.cpp:244]     Train net output #0: loss = 0.976613 (* 1 = 0.976613 loss)
I0423 15:40:09.845180 30295 solver.cpp:244]     Train net output #1: loss = 0.788321 (* 1 = 0.788321 loss)
I0423 15:40:09.845185 30295 solver.cpp:244]     Train net output #2: loss = 0.814421 (* 1 = 0.814421 loss)
I0423 15:40:09.845190 30295 solver.cpp:244]     Train net output #3: loss = 0.696798 (* 1 = 0.696798 loss)
I0423 15:40:09.845194 30295 sgd_solver.cpp:106] Iteration 49200, lr = 9e-06
I0423 15:41:49.547037 30295 solver.cpp:228] Iteration 49300, loss = 3.31316
I0423 15:41:49.548257 30295 solver.cpp:244]     Train net output #0: loss = 0.97816 (* 1 = 0.97816 loss)
I0423 15:41:49.548265 30295 solver.cpp:244]     Train net output #1: loss = 0.78379 (* 1 = 0.78379 loss)
I0423 15:41:49.548272 30295 solver.cpp:244]     Train net output #2: loss = 0.900179 (* 1 = 0.900179 loss)
I0423 15:41:49.548276 30295 solver.cpp:244]     Train net output #3: loss = 0.651034 (* 1 = 0.651034 loss)
I0423 15:41:49.548280 30295 sgd_solver.cpp:106] Iteration 49300, lr = 9e-06
I0423 15:43:34.173391 30295 solver.cpp:228] Iteration 49400, loss = 3.234
I0423 15:43:34.173532 30295 solver.cpp:244]     Train net output #0: loss = 0.983754 (* 1 = 0.983754 loss)
I0423 15:43:34.173540 30295 solver.cpp:244]     Train net output #1: loss = 0.705246 (* 1 = 0.705246 loss)
I0423 15:43:34.173545 30295 solver.cpp:244]     Train net output #2: loss = 0.894059 (* 1 = 0.894059 loss)
I0423 15:43:34.173549 30295 solver.cpp:244]     Train net output #3: loss = 0.650941 (* 1 = 0.650941 loss)
I0423 15:43:34.173554 30295 sgd_solver.cpp:106] Iteration 49400, lr = 9e-06
I0423 15:45:17.384413 30295 solver.cpp:228] Iteration 49500, loss = 3.0176
I0423 15:45:17.384624 30295 solver.cpp:244]     Train net output #0: loss = 0.982155 (* 1 = 0.982155 loss)
I0423 15:45:17.384632 30295 solver.cpp:244]     Train net output #1: loss = 0.486971 (* 1 = 0.486971 loss)
I0423 15:45:17.384637 30295 solver.cpp:244]     Train net output #2: loss = 0.919791 (* 1 = 0.919791 loss)
I0423 15:45:17.384642 30295 solver.cpp:244]     Train net output #3: loss = 0.628688 (* 1 = 0.628688 loss)
I0423 15:45:17.384646 30295 sgd_solver.cpp:106] Iteration 49500, lr = 9e-06
I0423 15:46:57.058622 30295 solver.cpp:228] Iteration 49600, loss = 3.08046
I0423 15:46:57.058769 30295 solver.cpp:244]     Train net output #0: loss = 0.986698 (* 1 = 0.986698 loss)
I0423 15:46:57.058778 30295 solver.cpp:244]     Train net output #1: loss = 0.561242 (* 1 = 0.561242 loss)
I0423 15:46:57.058782 30295 solver.cpp:244]     Train net output #2: loss = 0.880869 (* 1 = 0.880869 loss)
I0423 15:46:57.058786 30295 solver.cpp:244]     Train net output #3: loss = 0.651648 (* 1 = 0.651648 loss)
I0423 15:46:57.058792 30295 sgd_solver.cpp:106] Iteration 49600, lr = 9e-06
I0423 15:48:39.186081 30295 solver.cpp:228] Iteration 49700, loss = 3.36449
I0423 15:48:39.186256 30295 solver.cpp:244]     Train net output #0: loss = 0.987035 (* 1 = 0.987035 loss)
I0423 15:48:39.186264 30295 solver.cpp:244]     Train net output #1: loss = 0.726342 (* 1 = 0.726342 loss)
I0423 15:48:39.186270 30295 solver.cpp:244]     Train net output #2: loss = 0.9175 (* 1 = 0.9175 loss)
I0423 15:48:39.186275 30295 solver.cpp:244]     Train net output #3: loss = 0.733608 (* 1 = 0.733608 loss)
I0423 15:48:39.186280 30295 sgd_solver.cpp:106] Iteration 49700, lr = 9e-06
I0423 15:50:21.140204 30295 solver.cpp:228] Iteration 49800, loss = 2.88683
I0423 15:50:21.140367 30295 solver.cpp:244]     Train net output #0: loss = 0.988132 (* 1 = 0.988132 loss)
I0423 15:50:21.140374 30295 solver.cpp:244]     Train net output #1: loss = 0.58423 (* 1 = 0.58423 loss)
I0423 15:50:21.140378 30295 solver.cpp:244]     Train net output #2: loss = 0.74517 (* 1 = 0.74517 loss)
I0423 15:50:21.140383 30295 solver.cpp:244]     Train net output #3: loss = 0.569302 (* 1 = 0.569302 loss)
I0423 15:50:21.140388 30295 sgd_solver.cpp:106] Iteration 49800, lr = 9e-06
I0423 15:52:02.307252 30295 solver.cpp:228] Iteration 49900, loss = 2.90339
I0423 15:52:02.307412 30295 solver.cpp:244]     Train net output #0: loss = 0.981345 (* 1 = 0.981345 loss)
I0423 15:52:02.307420 30295 solver.cpp:244]     Train net output #1: loss = 0.530769 (* 1 = 0.530769 loss)
I0423 15:52:02.307425 30295 solver.cpp:244]     Train net output #2: loss = 0.771149 (* 1 = 0.771149 loss)
I0423 15:52:02.307430 30295 solver.cpp:244]     Train net output #3: loss = 0.620127 (* 1 = 0.620127 loss)
I0423 15:52:02.307436 30295 sgd_solver.cpp:106] Iteration 49900, lr = 9e-06
I0423 15:53:43.041816 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_50000.caffemodel
I0423 15:53:57.590756 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_50000.solverstate
I0423 15:53:57.878053 30295 solver.cpp:337] Iteration 50000, Testing net (#0)
I0423 15:53:57.878098 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 15:53:57.878100 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 15:53:57.878105 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 15:53:57.878123 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 15:53:57.878126 30295 net.cpp:693] Ignoring source layer visualize
I0423 15:53:57.878129 30295 net.cpp:693] Ignoring source layer fake
I0423 15:57:34.452839 30295 solver.cpp:404]     Test net output #0: loss = 0.971807 (* 1 = 0.971807 loss)
I0423 15:57:34.452992 30295 solver.cpp:404]     Test net output #1: loss = 0.507609 (* 1 = 0.507609 loss)
I0423 15:57:34.452998 30295 solver.cpp:404]     Test net output #2: loss = 0.813903 (* 1 = 0.813903 loss)
I0423 15:57:34.453003 30295 solver.cpp:404]     Test net output #3: loss = 0.568679 (* 1 = 0.568679 loss)
I0423 15:57:35.123430 30295 solver.cpp:228] Iteration 50000, loss = 2.97082
I0423 15:57:35.123452 30295 solver.cpp:244]     Train net output #0: loss = 0.978677 (* 1 = 0.978677 loss)
I0423 15:57:35.123474 30295 solver.cpp:244]     Train net output #1: loss = 0.624579 (* 1 = 0.624579 loss)
I0423 15:57:35.123477 30295 solver.cpp:244]     Train net output #2: loss = 0.937075 (* 1 = 0.937075 loss)
I0423 15:57:35.123483 30295 solver.cpp:244]     Train net output #3: loss = 0.430491 (* 1 = 0.430491 loss)
I0423 15:57:35.123486 30295 sgd_solver.cpp:106] Iteration 50000, lr = 9e-06
I0423 15:59:16.829708 30295 solver.cpp:228] Iteration 50100, loss = 3.08043
I0423 15:59:16.829900 30295 solver.cpp:244]     Train net output #0: loss = 0.965028 (* 1 = 0.965028 loss)
I0423 15:59:16.829908 30295 solver.cpp:244]     Train net output #1: loss = 0.768667 (* 1 = 0.768667 loss)
I0423 15:59:16.829913 30295 solver.cpp:244]     Train net output #2: loss = 0.773872 (* 1 = 0.773872 loss)
I0423 15:59:16.829917 30295 solver.cpp:244]     Train net output #3: loss = 0.57286 (* 1 = 0.57286 loss)
I0423 15:59:16.829922 30295 sgd_solver.cpp:106] Iteration 50100, lr = 9e-06
I0423 16:00:58.326529 30295 solver.cpp:228] Iteration 50200, loss = 2.18129
I0423 16:00:58.326700 30295 solver.cpp:244]     Train net output #0: loss = 0.995879 (* 1 = 0.995879 loss)
I0423 16:00:58.326707 30295 solver.cpp:244]     Train net output #1: loss = 0.470676 (* 1 = 0.470676 loss)
I0423 16:00:58.326712 30295 solver.cpp:244]     Train net output #2: loss = 0.387602 (* 1 = 0.387602 loss)
I0423 16:00:58.326717 30295 solver.cpp:244]     Train net output #3: loss = 0.327136 (* 1 = 0.327136 loss)
I0423 16:00:58.326721 30295 sgd_solver.cpp:106] Iteration 50200, lr = 9e-06
I0423 16:02:38.027546 30295 solver.cpp:228] Iteration 50300, loss = 2.93255
I0423 16:02:38.027686 30295 solver.cpp:244]     Train net output #0: loss = 0.966591 (* 1 = 0.966591 loss)
I0423 16:02:38.027694 30295 solver.cpp:244]     Train net output #1: loss = 0.54546 (* 1 = 0.54546 loss)
I0423 16:02:38.027699 30295 solver.cpp:244]     Train net output #2: loss = 0.77286 (* 1 = 0.77286 loss)
I0423 16:02:38.027704 30295 solver.cpp:244]     Train net output #3: loss = 0.647638 (* 1 = 0.647638 loss)
I0423 16:02:38.027709 30295 sgd_solver.cpp:106] Iteration 50300, lr = 9e-06
I0423 16:04:19.898988 30295 solver.cpp:228] Iteration 50400, loss = 3.08441
I0423 16:04:19.899140 30295 solver.cpp:244]     Train net output #0: loss = 0.985783 (* 1 = 0.985783 loss)
I0423 16:04:19.899148 30295 solver.cpp:244]     Train net output #1: loss = 0.766182 (* 1 = 0.766182 loss)
I0423 16:04:19.899153 30295 solver.cpp:244]     Train net output #2: loss = 0.634893 (* 1 = 0.634893 loss)
I0423 16:04:19.899158 30295 solver.cpp:244]     Train net output #3: loss = 0.697556 (* 1 = 0.697556 loss)
I0423 16:04:19.899163 30295 sgd_solver.cpp:106] Iteration 50400, lr = 9e-06
I0423 16:06:02.443555 30295 solver.cpp:228] Iteration 50500, loss = 3.23705
I0423 16:06:02.443714 30295 solver.cpp:244]     Train net output #0: loss = 0.985205 (* 1 = 0.985205 loss)
I0423 16:06:02.443728 30295 solver.cpp:244]     Train net output #1: loss = 0.796044 (* 1 = 0.796044 loss)
I0423 16:06:02.443733 30295 solver.cpp:244]     Train net output #2: loss = 0.786458 (* 1 = 0.786458 loss)
I0423 16:06:02.443737 30295 solver.cpp:244]     Train net output #3: loss = 0.669339 (* 1 = 0.669339 loss)
I0423 16:06:02.443743 30295 sgd_solver.cpp:106] Iteration 50500, lr = 9e-06
I0423 16:07:48.804448 30295 solver.cpp:228] Iteration 50600, loss = 3.43331
I0423 16:07:48.804615 30295 solver.cpp:244]     Train net output #0: loss = 0.977732 (* 1 = 0.977732 loss)
I0423 16:07:48.804623 30295 solver.cpp:244]     Train net output #1: loss = 0.796152 (* 1 = 0.796152 loss)
I0423 16:07:48.804638 30295 solver.cpp:244]     Train net output #2: loss = 0.919456 (* 1 = 0.919456 loss)
I0423 16:07:48.804644 30295 solver.cpp:244]     Train net output #3: loss = 0.73997 (* 1 = 0.73997 loss)
I0423 16:07:48.804649 30295 sgd_solver.cpp:106] Iteration 50600, lr = 9e-06
I0423 16:09:28.296000 30295 solver.cpp:228] Iteration 50700, loss = 3.40595
I0423 16:09:28.296172 30295 solver.cpp:244]     Train net output #0: loss = 0.984189 (* 1 = 0.984189 loss)
I0423 16:09:28.296180 30295 solver.cpp:244]     Train net output #1: loss = 0.826117 (* 1 = 0.826117 loss)
I0423 16:09:28.296185 30295 solver.cpp:244]     Train net output #2: loss = 0.905428 (* 1 = 0.905428 loss)
I0423 16:09:28.296190 30295 solver.cpp:244]     Train net output #3: loss = 0.690214 (* 1 = 0.690214 loss)
I0423 16:09:28.296195 30295 sgd_solver.cpp:106] Iteration 50700, lr = 9e-06
I0423 16:11:11.197481 30295 solver.cpp:228] Iteration 50800, loss = 3.17008
I0423 16:11:11.197628 30295 solver.cpp:244]     Train net output #0: loss = 0.989562 (* 1 = 0.989562 loss)
I0423 16:11:11.197634 30295 solver.cpp:244]     Train net output #1: loss = 0.603205 (* 1 = 0.603205 loss)
I0423 16:11:11.197639 30295 solver.cpp:244]     Train net output #2: loss = 0.873642 (* 1 = 0.873642 loss)
I0423 16:11:11.197644 30295 solver.cpp:244]     Train net output #3: loss = 0.70367 (* 1 = 0.70367 loss)
I0423 16:11:11.197649 30295 sgd_solver.cpp:106] Iteration 50800, lr = 9e-06
I0423 16:12:53.293349 30295 solver.cpp:228] Iteration 50900, loss = 3.35028
I0423 16:12:53.293506 30295 solver.cpp:244]     Train net output #0: loss = 0.988006 (* 1 = 0.988006 loss)
I0423 16:12:53.293515 30295 solver.cpp:244]     Train net output #1: loss = 0.719422 (* 1 = 0.719422 loss)
I0423 16:12:53.293519 30295 solver.cpp:244]     Train net output #2: loss = 0.944048 (* 1 = 0.944048 loss)
I0423 16:12:53.293524 30295 solver.cpp:244]     Train net output #3: loss = 0.698804 (* 1 = 0.698804 loss)
I0423 16:12:53.293529 30295 sgd_solver.cpp:106] Iteration 50900, lr = 9e-06
I0423 16:14:34.407107 30295 solver.cpp:337] Iteration 51000, Testing net (#0)
I0423 16:14:34.407650 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 16:14:34.407655 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 16:14:34.407660 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 16:14:34.407675 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 16:14:34.407678 30295 net.cpp:693] Ignoring source layer visualize
I0423 16:14:34.407680 30295 net.cpp:693] Ignoring source layer fake
I0423 16:18:14.345986 30295 solver.cpp:404]     Test net output #0: loss = 0.968712 (* 1 = 0.968712 loss)
I0423 16:18:14.346119 30295 solver.cpp:404]     Test net output #1: loss = 0.52935 (* 1 = 0.52935 loss)
I0423 16:18:14.346127 30295 solver.cpp:404]     Test net output #2: loss = 0.826705 (* 1 = 0.826705 loss)
I0423 16:18:14.346132 30295 solver.cpp:404]     Test net output #3: loss = 0.591196 (* 1 = 0.591196 loss)
I0423 16:18:15.008885 30295 solver.cpp:228] Iteration 51000, loss = 2.90357
I0423 16:18:15.008914 30295 solver.cpp:244]     Train net output #0: loss = 0.987538 (* 1 = 0.987538 loss)
I0423 16:18:15.008919 30295 solver.cpp:244]     Train net output #1: loss = 0.455605 (* 1 = 0.455605 loss)
I0423 16:18:15.008924 30295 solver.cpp:244]     Train net output #2: loss = 0.749546 (* 1 = 0.749546 loss)
I0423 16:18:15.008927 30295 solver.cpp:244]     Train net output #3: loss = 0.710883 (* 1 = 0.710883 loss)
I0423 16:18:15.008931 30295 sgd_solver.cpp:106] Iteration 51000, lr = 9e-06
I0423 16:19:54.596067 30295 solver.cpp:228] Iteration 51100, loss = 2.87041
I0423 16:19:54.598228 30295 solver.cpp:244]     Train net output #0: loss = 0.987059 (* 1 = 0.987059 loss)
I0423 16:19:54.598237 30295 solver.cpp:244]     Train net output #1: loss = 0.446109 (* 1 = 0.446109 loss)
I0423 16:19:54.598242 30295 solver.cpp:244]     Train net output #2: loss = 0.728893 (* 1 = 0.728893 loss)
I0423 16:19:54.598245 30295 solver.cpp:244]     Train net output #3: loss = 0.708347 (* 1 = 0.708347 loss)
I0423 16:19:54.598249 30295 sgd_solver.cpp:106] Iteration 51100, lr = 9e-06
I0423 16:21:37.803679 30295 solver.cpp:228] Iteration 51200, loss = 2.76014
I0423 16:21:37.803874 30295 solver.cpp:244]     Train net output #0: loss = 0.984613 (* 1 = 0.984613 loss)
I0423 16:21:37.803880 30295 solver.cpp:244]     Train net output #1: loss = 0.516086 (* 1 = 0.516086 loss)
I0423 16:21:37.803885 30295 solver.cpp:244]     Train net output #2: loss = 0.735801 (* 1 = 0.735801 loss)
I0423 16:21:37.803890 30295 solver.cpp:244]     Train net output #3: loss = 0.52364 (* 1 = 0.52364 loss)
I0423 16:21:37.803895 30295 sgd_solver.cpp:106] Iteration 51200, lr = 9e-06
I0423 16:23:20.408010 30295 solver.cpp:228] Iteration 51300, loss = 2.81723
I0423 16:23:20.408179 30295 solver.cpp:244]     Train net output #0: loss = 0.984709 (* 1 = 0.984709 loss)
I0423 16:23:20.408187 30295 solver.cpp:244]     Train net output #1: loss = 0.486868 (* 1 = 0.486868 loss)
I0423 16:23:20.408192 30295 solver.cpp:244]     Train net output #2: loss = 0.92332 (* 1 = 0.92332 loss)
I0423 16:23:20.408196 30295 solver.cpp:244]     Train net output #3: loss = 0.422337 (* 1 = 0.422337 loss)
I0423 16:23:20.408201 30295 sgd_solver.cpp:106] Iteration 51300, lr = 9e-06
I0423 16:25:02.825330 30295 solver.cpp:228] Iteration 51400, loss = 3.19188
I0423 16:25:02.825496 30295 solver.cpp:244]     Train net output #0: loss = 0.980353 (* 1 = 0.980353 loss)
I0423 16:25:02.825503 30295 solver.cpp:244]     Train net output #1: loss = 0.728907 (* 1 = 0.728907 loss)
I0423 16:25:02.825508 30295 solver.cpp:244]     Train net output #2: loss = 0.77138 (* 1 = 0.77138 loss)
I0423 16:25:02.825512 30295 solver.cpp:244]     Train net output #3: loss = 0.711239 (* 1 = 0.711239 loss)
I0423 16:25:02.825517 30295 sgd_solver.cpp:106] Iteration 51400, lr = 9e-06
I0423 16:26:51.374070 30295 solver.cpp:228] Iteration 51500, loss = 2.72809
I0423 16:26:51.374243 30295 solver.cpp:244]     Train net output #0: loss = 0.985669 (* 1 = 0.985669 loss)
I0423 16:26:51.374250 30295 solver.cpp:244]     Train net output #1: loss = 0.681204 (* 1 = 0.681204 loss)
I0423 16:26:51.374255 30295 solver.cpp:244]     Train net output #2: loss = 0.500999 (* 1 = 0.500999 loss)
I0423 16:26:51.374260 30295 solver.cpp:244]     Train net output #3: loss = 0.560222 (* 1 = 0.560222 loss)
I0423 16:26:51.374264 30295 sgd_solver.cpp:106] Iteration 51500, lr = 9e-06
I0423 16:28:39.287142 30295 solver.cpp:228] Iteration 51600, loss = 3.18004
I0423 16:28:39.287320 30295 solver.cpp:244]     Train net output #0: loss = 0.976535 (* 1 = 0.976535 loss)
I0423 16:28:39.287328 30295 solver.cpp:244]     Train net output #1: loss = 0.701511 (* 1 = 0.701511 loss)
I0423 16:28:39.287333 30295 solver.cpp:244]     Train net output #2: loss = 0.838437 (* 1 = 0.838437 loss)
I0423 16:28:39.287338 30295 solver.cpp:244]     Train net output #3: loss = 0.66356 (* 1 = 0.66356 loss)
I0423 16:28:39.287343 30295 sgd_solver.cpp:106] Iteration 51600, lr = 9e-06
I0423 16:30:23.562368 30295 solver.cpp:228] Iteration 51700, loss = 3.2319
I0423 16:30:23.562557 30295 solver.cpp:244]     Train net output #0: loss = 0.976992 (* 1 = 0.976992 loss)
I0423 16:30:23.562566 30295 solver.cpp:244]     Train net output #1: loss = 0.759075 (* 1 = 0.759075 loss)
I0423 16:30:23.562572 30295 solver.cpp:244]     Train net output #2: loss = 0.859373 (* 1 = 0.859373 loss)
I0423 16:30:23.562575 30295 solver.cpp:244]     Train net output #3: loss = 0.636464 (* 1 = 0.636464 loss)
I0423 16:30:23.562584 30295 sgd_solver.cpp:106] Iteration 51700, lr = 9e-06
I0423 16:32:03.141067 30295 solver.cpp:228] Iteration 51800, loss = 3.29658
I0423 16:32:03.141229 30295 solver.cpp:244]     Train net output #0: loss = 0.970385 (* 1 = 0.970385 loss)
I0423 16:32:03.141237 30295 solver.cpp:244]     Train net output #1: loss = 0.720991 (* 1 = 0.720991 loss)
I0423 16:32:03.141242 30295 solver.cpp:244]     Train net output #2: loss = 0.920273 (* 1 = 0.920273 loss)
I0423 16:32:03.141247 30295 solver.cpp:244]     Train net output #3: loss = 0.684928 (* 1 = 0.684928 loss)
I0423 16:32:03.141252 30295 sgd_solver.cpp:106] Iteration 51800, lr = 9e-06
I0423 16:33:48.163444 30295 solver.cpp:228] Iteration 51900, loss = 3.00104
I0423 16:33:48.163621 30295 solver.cpp:244]     Train net output #0: loss = 0.970369 (* 1 = 0.970369 loss)
I0423 16:33:48.163630 30295 solver.cpp:244]     Train net output #1: loss = 0.503096 (* 1 = 0.503096 loss)
I0423 16:33:48.163635 30295 solver.cpp:244]     Train net output #2: loss = 0.890506 (* 1 = 0.890506 loss)
I0423 16:33:48.163638 30295 solver.cpp:244]     Train net output #3: loss = 0.637071 (* 1 = 0.637071 loss)
I0423 16:33:48.163643 30295 sgd_solver.cpp:106] Iteration 51900, lr = 9e-06
I0423 16:35:35.211674 30295 solver.cpp:337] Iteration 52000, Testing net (#0)
I0423 16:35:35.211832 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 16:35:35.211836 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 16:35:35.211839 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 16:35:35.211854 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 16:35:35.211858 30295 net.cpp:693] Ignoring source layer visualize
I0423 16:35:35.211860 30295 net.cpp:693] Ignoring source layer fake
I0423 16:39:13.182229 30295 solver.cpp:404]     Test net output #0: loss = 0.9725 (* 1 = 0.9725 loss)
I0423 16:39:13.182374 30295 solver.cpp:404]     Test net output #1: loss = 0.481487 (* 1 = 0.481487 loss)
I0423 16:39:13.182382 30295 solver.cpp:404]     Test net output #2: loss = 0.78211 (* 1 = 0.78211 loss)
I0423 16:39:13.182386 30295 solver.cpp:404]     Test net output #3: loss = 0.488017 (* 1 = 0.488017 loss)
I0423 16:39:13.843963 30295 solver.cpp:228] Iteration 52000, loss = 3.0801
I0423 16:39:13.843991 30295 solver.cpp:244]     Train net output #0: loss = 0.986962 (* 1 = 0.986962 loss)
I0423 16:39:13.843997 30295 solver.cpp:244]     Train net output #1: loss = 0.541306 (* 1 = 0.541306 loss)
I0423 16:39:13.844002 30295 solver.cpp:244]     Train net output #2: loss = 0.89718 (* 1 = 0.89718 loss)
I0423 16:39:13.844005 30295 solver.cpp:244]     Train net output #3: loss = 0.654649 (* 1 = 0.654649 loss)
I0423 16:39:13.844009 30295 sgd_solver.cpp:106] Iteration 52000, lr = 9e-06
I0423 16:40:53.641628 30295 solver.cpp:228] Iteration 52100, loss = 3.11402
I0423 16:40:53.641917 30295 solver.cpp:244]     Train net output #0: loss = 0.986924 (* 1 = 0.986924 loss)
I0423 16:40:53.641924 30295 solver.cpp:244]     Train net output #1: loss = 0.594907 (* 1 = 0.594907 loss)
I0423 16:40:53.641929 30295 solver.cpp:244]     Train net output #2: loss = 0.881663 (* 1 = 0.881663 loss)
I0423 16:40:53.641934 30295 solver.cpp:244]     Train net output #3: loss = 0.650521 (* 1 = 0.650521 loss)
I0423 16:40:53.641940 30295 sgd_solver.cpp:106] Iteration 52100, lr = 9e-06
I0423 16:42:42.405654 30295 solver.cpp:228] Iteration 52200, loss = 3.30543
I0423 16:42:42.405812 30295 solver.cpp:244]     Train net output #0: loss = 0.982515 (* 1 = 0.982515 loss)
I0423 16:42:42.405822 30295 solver.cpp:244]     Train net output #1: loss = 0.673823 (* 1 = 0.673823 loss)
I0423 16:42:42.405825 30295 solver.cpp:244]     Train net output #2: loss = 0.910954 (* 1 = 0.910954 loss)
I0423 16:42:42.405830 30295 solver.cpp:244]     Train net output #3: loss = 0.738142 (* 1 = 0.738142 loss)
I0423 16:42:42.405835 30295 sgd_solver.cpp:106] Iteration 52200, lr = 9e-06
I0423 16:44:32.669225 30295 solver.cpp:228] Iteration 52300, loss = 2.44403
I0423 16:44:32.669374 30295 solver.cpp:244]     Train net output #0: loss = 0.988577 (* 1 = 0.988577 loss)
I0423 16:44:32.669381 30295 solver.cpp:244]     Train net output #1: loss = 0.377146 (* 1 = 0.377146 loss)
I0423 16:44:32.669386 30295 solver.cpp:244]     Train net output #2: loss = 0.556401 (* 1 = 0.556401 loss)
I0423 16:44:32.669391 30295 solver.cpp:244]     Train net output #3: loss = 0.521907 (* 1 = 0.521907 loss)
I0423 16:44:32.669395 30295 sgd_solver.cpp:106] Iteration 52300, lr = 9e-06
I0423 16:46:15.517007 30295 solver.cpp:228] Iteration 52400, loss = 2.66253
I0423 16:46:15.517174 30295 solver.cpp:244]     Train net output #0: loss = 0.974187 (* 1 = 0.974187 loss)
I0423 16:46:15.517182 30295 solver.cpp:244]     Train net output #1: loss = 0.513584 (* 1 = 0.513584 loss)
I0423 16:46:15.517187 30295 solver.cpp:244]     Train net output #2: loss = 0.652382 (* 1 = 0.652382 loss)
I0423 16:46:15.517191 30295 solver.cpp:244]     Train net output #3: loss = 0.52238 (* 1 = 0.52238 loss)
I0423 16:46:15.517195 30295 sgd_solver.cpp:106] Iteration 52400, lr = 9e-06
I0423 16:47:57.655100 30295 solver.cpp:228] Iteration 52500, loss = 2.97939
I0423 16:47:57.655236 30295 solver.cpp:244]     Train net output #0: loss = 0.9829 (* 1 = 0.9829 loss)
I0423 16:47:57.655244 30295 solver.cpp:244]     Train net output #1: loss = 0.639967 (* 1 = 0.639967 loss)
I0423 16:47:57.655248 30295 solver.cpp:244]     Train net output #2: loss = 0.940185 (* 1 = 0.940185 loss)
I0423 16:47:57.655253 30295 solver.cpp:244]     Train net output #3: loss = 0.416339 (* 1 = 0.416339 loss)
I0423 16:47:57.655258 30295 sgd_solver.cpp:106] Iteration 52500, lr = 9e-06
I0423 16:49:40.234570 30295 solver.cpp:228] Iteration 52600, loss = 2.67358
I0423 16:49:40.234725 30295 solver.cpp:244]     Train net output #0: loss = 0.970714 (* 1 = 0.970714 loss)
I0423 16:49:40.234733 30295 solver.cpp:244]     Train net output #1: loss = 0.568009 (* 1 = 0.568009 loss)
I0423 16:49:40.234738 30295 solver.cpp:244]     Train net output #2: loss = 0.625999 (* 1 = 0.625999 loss)
I0423 16:49:40.234743 30295 solver.cpp:244]     Train net output #3: loss = 0.508862 (* 1 = 0.508862 loss)
I0423 16:49:40.234747 30295 sgd_solver.cpp:106] Iteration 52600, lr = 9e-06
I0423 16:51:22.845547 30295 solver.cpp:228] Iteration 52700, loss = 2.55648
I0423 16:51:22.845719 30295 solver.cpp:244]     Train net output #0: loss = 0.977666 (* 1 = 0.977666 loss)
I0423 16:51:22.845727 30295 solver.cpp:244]     Train net output #1: loss = 0.561777 (* 1 = 0.561777 loss)
I0423 16:51:22.845731 30295 solver.cpp:244]     Train net output #2: loss = 0.562283 (* 1 = 0.562283 loss)
I0423 16:51:22.845737 30295 solver.cpp:244]     Train net output #3: loss = 0.454755 (* 1 = 0.454755 loss)
I0423 16:51:22.845741 30295 sgd_solver.cpp:106] Iteration 52700, lr = 9e-06
I0423 16:53:02.414608 30295 solver.cpp:228] Iteration 52800, loss = 2.90639
I0423 16:53:02.414772 30295 solver.cpp:244]     Train net output #0: loss = 0.973978 (* 1 = 0.973978 loss)
I0423 16:53:02.414779 30295 solver.cpp:244]     Train net output #1: loss = 0.456502 (* 1 = 0.456502 loss)
I0423 16:53:02.414784 30295 solver.cpp:244]     Train net output #2: loss = 0.765586 (* 1 = 0.765586 loss)
I0423 16:53:02.414788 30295 solver.cpp:244]     Train net output #3: loss = 0.710321 (* 1 = 0.710321 loss)
I0423 16:53:02.414794 30295 sgd_solver.cpp:106] Iteration 52800, lr = 9e-06
I0423 16:54:45.815781 30295 solver.cpp:228] Iteration 52900, loss = 3.24999
I0423 16:54:45.815927 30295 solver.cpp:244]     Train net output #0: loss = 0.967797 (* 1 = 0.967797 loss)
I0423 16:54:45.815935 30295 solver.cpp:244]     Train net output #1: loss = 0.724703 (* 1 = 0.724703 loss)
I0423 16:54:45.815939 30295 solver.cpp:244]     Train net output #2: loss = 0.879937 (* 1 = 0.879937 loss)
I0423 16:54:45.815945 30295 solver.cpp:244]     Train net output #3: loss = 0.67755 (* 1 = 0.67755 loss)
I0423 16:54:45.815949 30295 sgd_solver.cpp:106] Iteration 52900, lr = 9e-06
I0423 16:56:28.869192 30295 solver.cpp:337] Iteration 53000, Testing net (#0)
I0423 16:56:28.869329 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 16:56:28.869334 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 16:56:28.869338 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 16:56:28.869351 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 16:56:28.869354 30295 net.cpp:693] Ignoring source layer visualize
I0423 16:56:28.869357 30295 net.cpp:693] Ignoring source layer fake
I0423 17:00:06.293558 30295 solver.cpp:404]     Test net output #0: loss = 0.972232 (* 1 = 0.972232 loss)
I0423 17:00:06.294623 30295 solver.cpp:404]     Test net output #1: loss = 0.489204 (* 1 = 0.489204 loss)
I0423 17:00:06.294633 30295 solver.cpp:404]     Test net output #2: loss = 0.811066 (* 1 = 0.811066 loss)
I0423 17:00:06.294638 30295 solver.cpp:404]     Test net output #3: loss = 0.552846 (* 1 = 0.552846 loss)
I0423 17:00:06.953708 30295 solver.cpp:228] Iteration 53000, loss = 3.1813
I0423 17:00:06.953752 30295 solver.cpp:244]     Train net output #0: loss = 0.984065 (* 1 = 0.984065 loss)
I0423 17:00:06.953757 30295 solver.cpp:244]     Train net output #1: loss = 0.775718 (* 1 = 0.775718 loss)
I0423 17:00:06.953760 30295 solver.cpp:244]     Train net output #2: loss = 0.776535 (* 1 = 0.776535 loss)
I0423 17:00:06.953764 30295 solver.cpp:244]     Train net output #3: loss = 0.644984 (* 1 = 0.644984 loss)
I0423 17:00:06.953768 30295 sgd_solver.cpp:106] Iteration 53000, lr = 9e-06
I0423 17:01:55.046695 30295 solver.cpp:228] Iteration 53100, loss = 3.17476
I0423 17:01:55.046878 30295 solver.cpp:244]     Train net output #0: loss = 0.974718 (* 1 = 0.974718 loss)
I0423 17:01:55.046886 30295 solver.cpp:244]     Train net output #1: loss = 0.60533 (* 1 = 0.60533 loss)
I0423 17:01:55.046890 30295 solver.cpp:244]     Train net output #2: loss = 0.912317 (* 1 = 0.912317 loss)
I0423 17:01:55.046895 30295 solver.cpp:244]     Train net output #3: loss = 0.682399 (* 1 = 0.682399 loss)
I0423 17:01:55.046900 30295 sgd_solver.cpp:106] Iteration 53100, lr = 9e-06
I0423 17:03:34.652117 30295 solver.cpp:228] Iteration 53200, loss = 3.16753
I0423 17:03:34.652982 30295 solver.cpp:244]     Train net output #0: loss = 0.96265 (* 1 = 0.96265 loss)
I0423 17:03:34.652988 30295 solver.cpp:244]     Train net output #1: loss = 0.60037 (* 1 = 0.60037 loss)
I0423 17:03:34.652995 30295 solver.cpp:244]     Train net output #2: loss = 0.921787 (* 1 = 0.921787 loss)
I0423 17:03:34.653000 30295 solver.cpp:244]     Train net output #3: loss = 0.682724 (* 1 = 0.682724 loss)
I0423 17:03:34.653004 30295 sgd_solver.cpp:106] Iteration 53200, lr = 9e-06
I0423 17:05:16.788761 30295 solver.cpp:228] Iteration 53300, loss = 3.28054
I0423 17:05:16.788913 30295 solver.cpp:244]     Train net output #0: loss = 0.985646 (* 1 = 0.985646 loss)
I0423 17:05:16.788920 30295 solver.cpp:244]     Train net output #1: loss = 0.766215 (* 1 = 0.766215 loss)
I0423 17:05:16.788925 30295 solver.cpp:244]     Train net output #2: loss = 0.932143 (* 1 = 0.932143 loss)
I0423 17:05:16.788929 30295 solver.cpp:244]     Train net output #3: loss = 0.596532 (* 1 = 0.596532 loss)
I0423 17:05:16.788935 30295 sgd_solver.cpp:106] Iteration 53300, lr = 9e-06
I0423 17:07:00.622747 30295 solver.cpp:228] Iteration 53400, loss = 3.35802
I0423 17:07:00.624835 30295 solver.cpp:244]     Train net output #0: loss = 0.991296 (* 1 = 0.991296 loss)
I0423 17:07:00.624842 30295 solver.cpp:244]     Train net output #1: loss = 0.710625 (* 1 = 0.710625 loss)
I0423 17:07:00.624847 30295 solver.cpp:244]     Train net output #2: loss = 0.938877 (* 1 = 0.938877 loss)
I0423 17:07:00.624851 30295 solver.cpp:244]     Train net output #3: loss = 0.717219 (* 1 = 0.717219 loss)
I0423 17:07:00.624855 30295 sgd_solver.cpp:106] Iteration 53400, lr = 9e-06
I0423 17:08:44.239019 30295 solver.cpp:228] Iteration 53500, loss = 2.98852
I0423 17:08:44.239207 30295 solver.cpp:244]     Train net output #0: loss = 0.988029 (* 1 = 0.988029 loss)
I0423 17:08:44.239215 30295 solver.cpp:244]     Train net output #1: loss = 0.538252 (* 1 = 0.538252 loss)
I0423 17:08:44.239219 30295 solver.cpp:244]     Train net output #2: loss = 0.764773 (* 1 = 0.764773 loss)
I0423 17:08:44.239224 30295 solver.cpp:244]     Train net output #3: loss = 0.697461 (* 1 = 0.697461 loss)
I0423 17:08:44.239231 30295 sgd_solver.cpp:106] Iteration 53500, lr = 9e-06
I0423 17:10:23.364344 30295 solver.cpp:228] Iteration 53600, loss = 3.03575
I0423 17:10:23.364521 30295 solver.cpp:244]     Train net output #0: loss = 0.979006 (* 1 = 0.979006 loss)
I0423 17:10:23.364529 30295 solver.cpp:244]     Train net output #1: loss = 0.629956 (* 1 = 0.629956 loss)
I0423 17:10:23.364536 30295 solver.cpp:244]     Train net output #2: loss = 0.748654 (* 1 = 0.748654 loss)
I0423 17:10:23.364539 30295 solver.cpp:244]     Train net output #3: loss = 0.678135 (* 1 = 0.678135 loss)
I0423 17:10:23.364543 30295 sgd_solver.cpp:106] Iteration 53600, lr = 9e-06
I0423 17:12:10.999063 30295 solver.cpp:228] Iteration 53700, loss = 2.44547
I0423 17:12:10.999246 30295 solver.cpp:244]     Train net output #0: loss = 0.986663 (* 1 = 0.986663 loss)
I0423 17:12:10.999254 30295 solver.cpp:244]     Train net output #1: loss = 0.348565 (* 1 = 0.348565 loss)
I0423 17:12:10.999258 30295 solver.cpp:244]     Train net output #2: loss = 0.716143 (* 1 = 0.716143 loss)
I0423 17:12:10.999264 30295 solver.cpp:244]     Train net output #3: loss = 0.394096 (* 1 = 0.394096 loss)
I0423 17:12:10.999269 30295 sgd_solver.cpp:106] Iteration 53700, lr = 9e-06
I0423 17:13:56.358423 30295 solver.cpp:228] Iteration 53800, loss = 2.86771
I0423 17:13:56.358570 30295 solver.cpp:244]     Train net output #0: loss = 0.970867 (* 1 = 0.970867 loss)
I0423 17:13:56.358577 30295 solver.cpp:244]     Train net output #1: loss = 0.516289 (* 1 = 0.516289 loss)
I0423 17:13:56.358583 30295 solver.cpp:244]     Train net output #2: loss = 0.935158 (* 1 = 0.935158 loss)
I0423 17:13:56.358587 30295 solver.cpp:244]     Train net output #3: loss = 0.445394 (* 1 = 0.445394 loss)
I0423 17:13:56.358592 30295 sgd_solver.cpp:106] Iteration 53800, lr = 9e-06
I0423 17:15:42.495709 30295 solver.cpp:228] Iteration 53900, loss = 2.95311
I0423 17:15:42.495885 30295 solver.cpp:244]     Train net output #0: loss = 0.973836 (* 1 = 0.973836 loss)
I0423 17:15:42.495896 30295 solver.cpp:244]     Train net output #1: loss = 0.556189 (* 1 = 0.556189 loss)
I0423 17:15:42.495904 30295 solver.cpp:244]     Train net output #2: loss = 0.77414 (* 1 = 0.77414 loss)
I0423 17:15:42.495913 30295 solver.cpp:244]     Train net output #3: loss = 0.648943 (* 1 = 0.648943 loss)
I0423 17:15:42.495920 30295 sgd_solver.cpp:106] Iteration 53900, lr = 9e-06
I0423 17:17:24.031349 30295 solver.cpp:337] Iteration 54000, Testing net (#0)
I0423 17:17:24.031494 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 17:17:24.031498 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 17:17:24.031502 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 17:17:24.031517 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 17:17:24.031519 30295 net.cpp:693] Ignoring source layer visualize
I0423 17:17:24.031522 30295 net.cpp:693] Ignoring source layer fake
I0423 17:21:01.321921 30295 solver.cpp:404]     Test net output #0: loss = 0.97422 (* 1 = 0.97422 loss)
I0423 17:21:01.322053 30295 solver.cpp:404]     Test net output #1: loss = 0.527997 (* 1 = 0.527997 loss)
I0423 17:21:01.322060 30295 solver.cpp:404]     Test net output #2: loss = 0.80885 (* 1 = 0.80885 loss)
I0423 17:21:01.322064 30295 solver.cpp:404]     Test net output #3: loss = 0.562971 (* 1 = 0.562971 loss)
I0423 17:21:01.984627 30295 solver.cpp:228] Iteration 54000, loss = 2.91396
I0423 17:21:01.984686 30295 solver.cpp:244]     Train net output #0: loss = 0.982228 (* 1 = 0.982228 loss)
I0423 17:21:01.984691 30295 solver.cpp:244]     Train net output #1: loss = 0.634381 (* 1 = 0.634381 loss)
I0423 17:21:01.984711 30295 solver.cpp:244]     Train net output #2: loss = 0.686116 (* 1 = 0.686116 loss)
I0423 17:21:01.984717 30295 solver.cpp:244]     Train net output #3: loss = 0.611231 (* 1 = 0.611231 loss)
I0423 17:21:01.984721 30295 sgd_solver.cpp:106] Iteration 54000, lr = 9e-06
I0423 17:22:45.676923 30295 solver.cpp:228] Iteration 54100, loss = 3.0988
I0423 17:22:45.677081 30295 solver.cpp:244]     Train net output #0: loss = 0.979224 (* 1 = 0.979224 loss)
I0423 17:22:45.677089 30295 solver.cpp:244]     Train net output #1: loss = 0.694646 (* 1 = 0.694646 loss)
I0423 17:22:45.677094 30295 solver.cpp:244]     Train net output #2: loss = 0.704118 (* 1 = 0.704118 loss)
I0423 17:22:45.677098 30295 solver.cpp:244]     Train net output #3: loss = 0.720814 (* 1 = 0.720814 loss)
I0423 17:22:45.677103 30295 sgd_solver.cpp:106] Iteration 54100, lr = 9e-06
I0423 17:24:27.393988 30295 solver.cpp:228] Iteration 54200, loss = 3.25305
I0423 17:24:27.394181 30295 solver.cpp:244]     Train net output #0: loss = 0.97726 (* 1 = 0.97726 loss)
I0423 17:24:27.394188 30295 solver.cpp:244]     Train net output #1: loss = 0.715739 (* 1 = 0.715739 loss)
I0423 17:24:27.394193 30295 solver.cpp:244]     Train net output #2: loss = 0.889702 (* 1 = 0.889702 loss)
I0423 17:24:27.394198 30295 solver.cpp:244]     Train net output #3: loss = 0.670348 (* 1 = 0.670348 loss)
I0423 17:24:27.394203 30295 sgd_solver.cpp:106] Iteration 54200, lr = 9e-06
I0423 17:26:07.172310 30295 solver.cpp:228] Iteration 54300, loss = 3.36582
I0423 17:26:07.172461 30295 solver.cpp:244]     Train net output #0: loss = 0.964495 (* 1 = 0.964495 loss)
I0423 17:26:07.172469 30295 solver.cpp:244]     Train net output #1: loss = 0.748733 (* 1 = 0.748733 loss)
I0423 17:26:07.172473 30295 solver.cpp:244]     Train net output #2: loss = 0.941448 (* 1 = 0.941448 loss)
I0423 17:26:07.172478 30295 solver.cpp:244]     Train net output #3: loss = 0.711147 (* 1 = 0.711147 loss)
I0423 17:26:07.172482 30295 sgd_solver.cpp:106] Iteration 54300, lr = 9e-06
I0423 17:27:48.730825 30295 solver.cpp:228] Iteration 54400, loss = 3.20024
I0423 17:27:48.730986 30295 solver.cpp:244]     Train net output #0: loss = 0.973544 (* 1 = 0.973544 loss)
I0423 17:27:48.730993 30295 solver.cpp:244]     Train net output #1: loss = 0.643241 (* 1 = 0.643241 loss)
I0423 17:27:48.730998 30295 solver.cpp:244]     Train net output #2: loss = 0.913366 (* 1 = 0.913366 loss)
I0423 17:27:48.731003 30295 solver.cpp:244]     Train net output #3: loss = 0.670084 (* 1 = 0.670084 loss)
I0423 17:27:48.731009 30295 sgd_solver.cpp:106] Iteration 54400, lr = 9e-06
I0423 17:29:30.314519 30295 solver.cpp:228] Iteration 54500, loss = 3.12867
I0423 17:29:30.314693 30295 solver.cpp:244]     Train net output #0: loss = 0.98142 (* 1 = 0.98142 loss)
I0423 17:29:30.314702 30295 solver.cpp:244]     Train net output #1: loss = 0.663186 (* 1 = 0.663186 loss)
I0423 17:29:30.314707 30295 solver.cpp:244]     Train net output #2: loss = 0.917967 (* 1 = 0.917967 loss)
I0423 17:29:30.314710 30295 solver.cpp:244]     Train net output #3: loss = 0.566093 (* 1 = 0.566093 loss)
I0423 17:29:30.314714 30295 sgd_solver.cpp:106] Iteration 54500, lr = 9e-06
I0423 17:31:09.732142 30295 solver.cpp:228] Iteration 54600, loss = 3.14834
I0423 17:31:09.732311 30295 solver.cpp:244]     Train net output #0: loss = 0.973703 (* 1 = 0.973703 loss)
I0423 17:31:09.732318 30295 solver.cpp:244]     Train net output #1: loss = 0.564733 (* 1 = 0.564733 loss)
I0423 17:31:09.732323 30295 solver.cpp:244]     Train net output #2: loss = 0.923094 (* 1 = 0.923094 loss)
I0423 17:31:09.732328 30295 solver.cpp:244]     Train net output #3: loss = 0.686809 (* 1 = 0.686809 loss)
I0423 17:31:09.732333 30295 sgd_solver.cpp:106] Iteration 54600, lr = 9e-06
I0423 17:32:51.203233 30295 solver.cpp:228] Iteration 54700, loss = 3.3001
I0423 17:32:51.203372 30295 solver.cpp:244]     Train net output #0: loss = 0.980254 (* 1 = 0.980254 loss)
I0423 17:32:51.203379 30295 solver.cpp:244]     Train net output #1: loss = 0.644284 (* 1 = 0.644284 loss)
I0423 17:32:51.203383 30295 solver.cpp:244]     Train net output #2: loss = 0.957104 (* 1 = 0.957104 loss)
I0423 17:32:51.203387 30295 solver.cpp:244]     Train net output #3: loss = 0.718459 (* 1 = 0.718459 loss)
I0423 17:32:51.203393 30295 sgd_solver.cpp:106] Iteration 54700, lr = 9e-06
I0423 17:34:32.547601 30295 solver.cpp:228] Iteration 54800, loss = 3.00458
I0423 17:34:32.547742 30295 solver.cpp:244]     Train net output #0: loss = 0.986904 (* 1 = 0.986904 loss)
I0423 17:34:32.547750 30295 solver.cpp:244]     Train net output #1: loss = 0.436701 (* 1 = 0.436701 loss)
I0423 17:34:32.547755 30295 solver.cpp:244]     Train net output #2: loss = 0.908644 (* 1 = 0.908644 loss)
I0423 17:34:32.547760 30295 solver.cpp:244]     Train net output #3: loss = 0.672336 (* 1 = 0.672336 loss)
I0423 17:34:32.547765 30295 sgd_solver.cpp:106] Iteration 54800, lr = 9e-06
I0423 17:36:13.765327 30295 solver.cpp:228] Iteration 54900, loss = 3.00649
I0423 17:36:13.766922 30295 solver.cpp:244]     Train net output #0: loss = 0.985685 (* 1 = 0.985685 loss)
I0423 17:36:13.766932 30295 solver.cpp:244]     Train net output #1: loss = 0.569647 (* 1 = 0.569647 loss)
I0423 17:36:13.766935 30295 solver.cpp:244]     Train net output #2: loss = 0.868477 (* 1 = 0.868477 loss)
I0423 17:36:13.766939 30295 solver.cpp:244]     Train net output #3: loss = 0.582683 (* 1 = 0.582683 loss)
I0423 17:36:13.766944 30295 sgd_solver.cpp:106] Iteration 54900, lr = 9e-06
I0423 17:37:53.286522 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_55000.caffemodel
I0423 17:38:09.267869 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_55000.solverstate
I0423 17:38:09.457357 30295 solver.cpp:337] Iteration 55000, Testing net (#0)
I0423 17:38:09.457399 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 17:38:09.457402 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 17:38:09.457406 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 17:38:09.457418 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 17:38:09.457422 30295 net.cpp:693] Ignoring source layer visualize
I0423 17:38:09.457423 30295 net.cpp:693] Ignoring source layer fake
I0423 17:41:46.169458 30295 solver.cpp:404]     Test net output #0: loss = 0.970386 (* 1 = 0.970386 loss)
I0423 17:41:46.169594 30295 solver.cpp:404]     Test net output #1: loss = 0.5057 (* 1 = 0.5057 loss)
I0423 17:41:46.169600 30295 solver.cpp:404]     Test net output #2: loss = 0.815597 (* 1 = 0.815597 loss)
I0423 17:41:46.169605 30295 solver.cpp:404]     Test net output #3: loss = 0.572836 (* 1 = 0.572836 loss)
I0423 17:41:46.834694 30295 solver.cpp:228] Iteration 55000, loss = 2.79777
I0423 17:41:46.834720 30295 solver.cpp:244]     Train net output #0: loss = 0.98283 (* 1 = 0.98283 loss)
I0423 17:41:46.834725 30295 solver.cpp:244]     Train net output #1: loss = 0.447405 (* 1 = 0.447405 loss)
I0423 17:41:46.834729 30295 solver.cpp:244]     Train net output #2: loss = 0.939694 (* 1 = 0.939694 loss)
I0423 17:41:46.834733 30295 solver.cpp:244]     Train net output #3: loss = 0.427839 (* 1 = 0.427839 loss)
I0423 17:41:46.834738 30295 sgd_solver.cpp:106] Iteration 55000, lr = 9e-06
I0423 17:43:28.783628 30295 solver.cpp:228] Iteration 55100, loss = 3.24054
I0423 17:43:28.783776 30295 solver.cpp:244]     Train net output #0: loss = 0.960677 (* 1 = 0.960677 loss)
I0423 17:43:28.783782 30295 solver.cpp:244]     Train net output #1: loss = 0.642368 (* 1 = 0.642368 loss)
I0423 17:43:28.783787 30295 solver.cpp:244]     Train net output #2: loss = 0.95546 (* 1 = 0.95546 loss)
I0423 17:43:28.783792 30295 solver.cpp:244]     Train net output #3: loss = 0.682037 (* 1 = 0.682037 loss)
I0423 17:43:28.783802 30295 sgd_solver.cpp:106] Iteration 55100, lr = 9e-06
I0423 17:45:11.489070 30295 solver.cpp:228] Iteration 55200, loss = 3.2251
I0423 17:45:11.489635 30295 solver.cpp:244]     Train net output #0: loss = 0.973561 (* 1 = 0.973561 loss)
I0423 17:45:11.489645 30295 solver.cpp:244]     Train net output #1: loss = 0.622335 (* 1 = 0.622335 loss)
I0423 17:45:11.489650 30295 solver.cpp:244]     Train net output #2: loss = 0.948948 (* 1 = 0.948948 loss)
I0423 17:45:11.489655 30295 solver.cpp:244]     Train net output #3: loss = 0.680259 (* 1 = 0.680259 loss)
I0423 17:45:11.489658 30295 sgd_solver.cpp:106] Iteration 55200, lr = 9e-06
I0423 17:46:51.170161 30295 solver.cpp:228] Iteration 55300, loss = 3.05923
I0423 17:46:51.170317 30295 solver.cpp:244]     Train net output #0: loss = 0.984498 (* 1 = 0.984498 loss)
I0423 17:46:51.170325 30295 solver.cpp:244]     Train net output #1: loss = 0.567072 (* 1 = 0.567072 loss)
I0423 17:46:51.170330 30295 solver.cpp:244]     Train net output #2: loss = 0.759957 (* 1 = 0.759957 loss)
I0423 17:46:51.170333 30295 solver.cpp:244]     Train net output #3: loss = 0.7477 (* 1 = 0.7477 loss)
I0423 17:46:51.170339 30295 sgd_solver.cpp:106] Iteration 55300, lr = 9e-06
I0423 17:48:32.959380 30295 solver.cpp:228] Iteration 55400, loss = 3.35642
I0423 17:48:32.959550 30295 solver.cpp:244]     Train net output #0: loss = 0.964775 (* 1 = 0.964775 loss)
I0423 17:48:32.959558 30295 solver.cpp:244]     Train net output #1: loss = 0.765255 (* 1 = 0.765255 loss)
I0423 17:48:32.959563 30295 solver.cpp:244]     Train net output #2: loss = 0.933264 (* 1 = 0.933264 loss)
I0423 17:48:32.959568 30295 solver.cpp:244]     Train net output #3: loss = 0.693128 (* 1 = 0.693128 loss)
I0423 17:48:32.959583 30295 sgd_solver.cpp:106] Iteration 55400, lr = 9e-06
I0423 17:50:15.139891 30295 solver.cpp:228] Iteration 55500, loss = 3.26283
I0423 17:50:15.140063 30295 solver.cpp:244]     Train net output #0: loss = 0.976499 (* 1 = 0.976499 loss)
I0423 17:50:15.140070 30295 solver.cpp:244]     Train net output #1: loss = 0.725769 (* 1 = 0.725769 loss)
I0423 17:50:15.140074 30295 solver.cpp:244]     Train net output #2: loss = 0.878921 (* 1 = 0.878921 loss)
I0423 17:50:15.140079 30295 solver.cpp:244]     Train net output #3: loss = 0.681644 (* 1 = 0.681644 loss)
I0423 17:50:15.140085 30295 sgd_solver.cpp:106] Iteration 55500, lr = 9e-06
I0423 17:51:57.208760 30295 solver.cpp:228] Iteration 55600, loss = 3.04243
I0423 17:51:57.208900 30295 solver.cpp:244]     Train net output #0: loss = 0.972402 (* 1 = 0.972402 loss)
I0423 17:51:57.208907 30295 solver.cpp:244]     Train net output #1: loss = 0.533493 (* 1 = 0.533493 loss)
I0423 17:51:57.208914 30295 solver.cpp:244]     Train net output #2: loss = 0.881746 (* 1 = 0.881746 loss)
I0423 17:51:57.208917 30295 solver.cpp:244]     Train net output #3: loss = 0.654794 (* 1 = 0.654794 loss)
I0423 17:51:57.208922 30295 sgd_solver.cpp:106] Iteration 55600, lr = 9e-06
I0423 17:53:37.013468 30295 solver.cpp:228] Iteration 55700, loss = 3.16722
I0423 17:53:37.013612 30295 solver.cpp:244]     Train net output #0: loss = 0.955094 (* 1 = 0.955094 loss)
I0423 17:53:37.013619 30295 solver.cpp:244]     Train net output #1: loss = 0.581113 (* 1 = 0.581113 loss)
I0423 17:53:37.013624 30295 solver.cpp:244]     Train net output #2: loss = 0.942235 (* 1 = 0.942235 loss)
I0423 17:53:37.013628 30295 solver.cpp:244]     Train net output #3: loss = 0.68878 (* 1 = 0.68878 loss)
I0423 17:53:37.013633 30295 sgd_solver.cpp:106] Iteration 55700, lr = 9e-06
I0423 17:55:19.865806 30295 solver.cpp:228] Iteration 55800, loss = 3.07649
I0423 17:55:19.865950 30295 solver.cpp:244]     Train net output #0: loss = 0.986686 (* 1 = 0.986686 loss)
I0423 17:55:19.865958 30295 solver.cpp:244]     Train net output #1: loss = 0.616035 (* 1 = 0.616035 loss)
I0423 17:55:19.865964 30295 solver.cpp:244]     Train net output #2: loss = 0.92719 (* 1 = 0.92719 loss)
I0423 17:55:19.865968 30295 solver.cpp:244]     Train net output #3: loss = 0.54658 (* 1 = 0.54658 loss)
I0423 17:55:19.865973 30295 sgd_solver.cpp:106] Iteration 55800, lr = 9e-06
I0423 17:57:02.680485 30295 solver.cpp:228] Iteration 55900, loss = 3.4334
I0423 17:57:02.680650 30295 solver.cpp:244]     Train net output #0: loss = 0.98945 (* 1 = 0.98945 loss)
I0423 17:57:02.680658 30295 solver.cpp:244]     Train net output #1: loss = 0.718161 (* 1 = 0.718161 loss)
I0423 17:57:02.680663 30295 solver.cpp:244]     Train net output #2: loss = 0.967362 (* 1 = 0.967362 loss)
I0423 17:57:02.680667 30295 solver.cpp:244]     Train net output #3: loss = 0.758431 (* 1 = 0.758431 loss)
I0423 17:57:02.680673 30295 sgd_solver.cpp:106] Iteration 55900, lr = 9e-06
I0423 17:58:45.284945 30295 solver.cpp:337] Iteration 56000, Testing net (#0)
I0423 17:58:45.285104 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 17:58:45.285109 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 17:58:45.285112 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 17:58:45.285126 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 17:58:45.285130 30295 net.cpp:693] Ignoring source layer visualize
I0423 17:58:45.285132 30295 net.cpp:693] Ignoring source layer fake
I0423 18:02:23.032378 30295 solver.cpp:404]     Test net output #0: loss = 0.969637 (* 1 = 0.969637 loss)
I0423 18:02:23.032532 30295 solver.cpp:404]     Test net output #1: loss = 0.526125 (* 1 = 0.526125 loss)
I0423 18:02:23.032539 30295 solver.cpp:404]     Test net output #2: loss = 0.826336 (* 1 = 0.826336 loss)
I0423 18:02:23.032543 30295 solver.cpp:404]     Test net output #3: loss = 0.588818 (* 1 = 0.588818 loss)
I0423 18:02:23.709491 30295 solver.cpp:228] Iteration 56000, loss = 3.32299
I0423 18:02:23.709516 30295 solver.cpp:244]     Train net output #0: loss = 0.986202 (* 1 = 0.986202 loss)
I0423 18:02:23.709537 30295 solver.cpp:244]     Train net output #1: loss = 0.697756 (* 1 = 0.697756 loss)
I0423 18:02:23.709540 30295 solver.cpp:244]     Train net output #2: loss = 0.921862 (* 1 = 0.921862 loss)
I0423 18:02:23.709544 30295 solver.cpp:244]     Train net output #3: loss = 0.717164 (* 1 = 0.717164 loss)
I0423 18:02:23.709548 30295 sgd_solver.cpp:106] Iteration 56000, lr = 9e-06
I0423 18:04:03.247162 30295 solver.cpp:228] Iteration 56100, loss = 3.33701
I0423 18:04:03.247330 30295 solver.cpp:244]     Train net output #0: loss = 0.98515 (* 1 = 0.98515 loss)
I0423 18:04:03.247337 30295 solver.cpp:244]     Train net output #1: loss = 0.701078 (* 1 = 0.701078 loss)
I0423 18:04:03.247342 30295 solver.cpp:244]     Train net output #2: loss = 0.921668 (* 1 = 0.921668 loss)
I0423 18:04:03.247347 30295 solver.cpp:244]     Train net output #3: loss = 0.729112 (* 1 = 0.729112 loss)
I0423 18:04:03.247352 30295 sgd_solver.cpp:106] Iteration 56100, lr = 9e-06
I0423 18:05:48.121243 30295 solver.cpp:228] Iteration 56200, loss = 3.02355
I0423 18:05:48.121402 30295 solver.cpp:244]     Train net output #0: loss = 0.984971 (* 1 = 0.984971 loss)
I0423 18:05:48.121409 30295 solver.cpp:244]     Train net output #1: loss = 0.532393 (* 1 = 0.532393 loss)
I0423 18:05:48.121414 30295 solver.cpp:244]     Train net output #2: loss = 0.899635 (* 1 = 0.899635 loss)
I0423 18:05:48.121419 30295 solver.cpp:244]     Train net output #3: loss = 0.606547 (* 1 = 0.606547 loss)
I0423 18:05:48.121424 30295 sgd_solver.cpp:106] Iteration 56200, lr = 9e-06
I0423 18:07:30.017233 30295 solver.cpp:228] Iteration 56300, loss = 3.20659
I0423 18:07:30.017377 30295 solver.cpp:244]     Train net output #0: loss = 0.965964 (* 1 = 0.965964 loss)
I0423 18:07:30.017386 30295 solver.cpp:244]     Train net output #1: loss = 0.68643 (* 1 = 0.68643 loss)
I0423 18:07:30.017390 30295 solver.cpp:244]     Train net output #2: loss = 0.958557 (* 1 = 0.958557 loss)
I0423 18:07:30.017395 30295 solver.cpp:244]     Train net output #3: loss = 0.595634 (* 1 = 0.595634 loss)
I0423 18:07:30.017400 30295 sgd_solver.cpp:106] Iteration 56300, lr = 9e-06
I0423 18:09:11.557935 30295 solver.cpp:228] Iteration 56400, loss = 2.60045
I0423 18:09:11.558101 30295 solver.cpp:244]     Train net output #0: loss = 0.985487 (* 1 = 0.985487 loss)
I0423 18:09:11.558109 30295 solver.cpp:244]     Train net output #1: loss = 0.4454 (* 1 = 0.4454 loss)
I0423 18:09:11.558113 30295 solver.cpp:244]     Train net output #2: loss = 0.556933 (* 1 = 0.556933 loss)
I0423 18:09:11.558118 30295 solver.cpp:244]     Train net output #3: loss = 0.612626 (* 1 = 0.612626 loss)
I0423 18:09:11.558123 30295 sgd_solver.cpp:106] Iteration 56400, lr = 9e-06
I0423 18:10:52.513494 30295 solver.cpp:228] Iteration 56500, loss = 2.97223
I0423 18:10:52.514479 30295 solver.cpp:244]     Train net output #0: loss = 0.979704 (* 1 = 0.979704 loss)
I0423 18:10:52.514488 30295 solver.cpp:244]     Train net output #1: loss = 0.755031 (* 1 = 0.755031 loss)
I0423 18:10:52.514492 30295 solver.cpp:244]     Train net output #2: loss = 0.766132 (* 1 = 0.766132 loss)
I0423 18:10:52.514497 30295 solver.cpp:244]     Train net output #3: loss = 0.47136 (* 1 = 0.47136 loss)
I0423 18:10:52.514500 30295 sgd_solver.cpp:106] Iteration 56500, lr = 9e-06
I0423 18:12:34.018628 30295 solver.cpp:228] Iteration 56600, loss = 3.12152
I0423 18:12:34.018782 30295 solver.cpp:244]     Train net output #0: loss = 0.975268 (* 1 = 0.975268 loss)
I0423 18:12:34.018790 30295 solver.cpp:244]     Train net output #1: loss = 0.732168 (* 1 = 0.732168 loss)
I0423 18:12:34.018795 30295 solver.cpp:244]     Train net output #2: loss = 0.701868 (* 1 = 0.701868 loss)
I0423 18:12:34.018800 30295 solver.cpp:244]     Train net output #3: loss = 0.712218 (* 1 = 0.712218 loss)
I0423 18:12:34.018805 30295 sgd_solver.cpp:106] Iteration 56600, lr = 9e-06
I0423 18:14:17.569494 30295 solver.cpp:228] Iteration 56700, loss = 3.09322
I0423 18:14:17.569664 30295 solver.cpp:244]     Train net output #0: loss = 0.984379 (* 1 = 0.984379 loss)
I0423 18:14:17.569671 30295 solver.cpp:244]     Train net output #1: loss = 0.720717 (* 1 = 0.720717 loss)
I0423 18:14:17.569676 30295 solver.cpp:244]     Train net output #2: loss = 0.721642 (* 1 = 0.721642 loss)
I0423 18:14:17.569681 30295 solver.cpp:244]     Train net output #3: loss = 0.66648 (* 1 = 0.66648 loss)
I0423 18:14:17.569686 30295 sgd_solver.cpp:106] Iteration 56700, lr = 9e-06
I0423 18:15:56.976780 30295 solver.cpp:228] Iteration 56800, loss = 3.39595
I0423 18:15:56.976907 30295 solver.cpp:244]     Train net output #0: loss = 0.968147 (* 1 = 0.968147 loss)
I0423 18:15:56.976913 30295 solver.cpp:244]     Train net output #1: loss = 0.745004 (* 1 = 0.745004 loss)
I0423 18:15:56.976918 30295 solver.cpp:244]     Train net output #2: loss = 0.943668 (* 1 = 0.943668 loss)
I0423 18:15:56.976923 30295 solver.cpp:244]     Train net output #3: loss = 0.739129 (* 1 = 0.739129 loss)
I0423 18:15:56.976928 30295 sgd_solver.cpp:106] Iteration 56800, lr = 9e-06
I0423 18:17:39.082063 30295 solver.cpp:228] Iteration 56900, loss = 3.38178
I0423 18:17:39.082214 30295 solver.cpp:244]     Train net output #0: loss = 0.976741 (* 1 = 0.976741 loss)
I0423 18:17:39.082222 30295 solver.cpp:244]     Train net output #1: loss = 0.805918 (* 1 = 0.805918 loss)
I0423 18:17:39.082227 30295 solver.cpp:244]     Train net output #2: loss = 0.926307 (* 1 = 0.926307 loss)
I0423 18:17:39.082231 30295 solver.cpp:244]     Train net output #3: loss = 0.672819 (* 1 = 0.672819 loss)
I0423 18:17:39.082237 30295 sgd_solver.cpp:106] Iteration 56900, lr = 9e-06
I0423 18:19:21.149616 30295 solver.cpp:337] Iteration 57000, Testing net (#0)
I0423 18:19:21.149788 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 18:19:21.149793 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 18:19:21.149796 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 18:19:21.149811 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 18:19:21.149814 30295 net.cpp:693] Ignoring source layer visualize
I0423 18:19:21.149816 30295 net.cpp:693] Ignoring source layer fake
I0423 18:22:59.407588 30295 solver.cpp:404]     Test net output #0: loss = 0.97125 (* 1 = 0.97125 loss)
I0423 18:22:59.407738 30295 solver.cpp:404]     Test net output #1: loss = 0.484701 (* 1 = 0.484701 loss)
I0423 18:22:59.407745 30295 solver.cpp:404]     Test net output #2: loss = 0.782724 (* 1 = 0.782724 loss)
I0423 18:22:59.407760 30295 solver.cpp:404]     Test net output #3: loss = 0.494182 (* 1 = 0.494182 loss)
I0423 18:23:00.068413 30295 solver.cpp:228] Iteration 57000, loss = 3.13145
I0423 18:23:00.068456 30295 solver.cpp:244]     Train net output #0: loss = 0.987177 (* 1 = 0.987177 loss)
I0423 18:23:00.068461 30295 solver.cpp:244]     Train net output #1: loss = 0.655945 (* 1 = 0.655945 loss)
I0423 18:23:00.068480 30295 solver.cpp:244]     Train net output #2: loss = 0.929574 (* 1 = 0.929574 loss)
I0423 18:23:00.068485 30295 solver.cpp:244]     Train net output #3: loss = 0.558751 (* 1 = 0.558751 loss)
I0423 18:23:00.068490 30295 sgd_solver.cpp:106] Iteration 57000, lr = 9e-06
I0423 18:24:39.991644 30295 solver.cpp:228] Iteration 57100, loss = 3.09769
I0423 18:24:39.991798 30295 solver.cpp:244]     Train net output #0: loss = 0.981704 (* 1 = 0.981704 loss)
I0423 18:24:39.991806 30295 solver.cpp:244]     Train net output #1: loss = 0.589551 (* 1 = 0.589551 loss)
I0423 18:24:39.991811 30295 solver.cpp:244]     Train net output #2: loss = 0.87868 (* 1 = 0.87868 loss)
I0423 18:24:39.991816 30295 solver.cpp:244]     Train net output #3: loss = 0.647759 (* 1 = 0.647759 loss)
I0423 18:24:39.991822 30295 sgd_solver.cpp:106] Iteration 57100, lr = 9e-06
I0423 18:26:25.458583 30295 solver.cpp:228] Iteration 57200, loss = 3.15729
I0423 18:26:25.458773 30295 solver.cpp:244]     Train net output #0: loss = 0.992187 (* 1 = 0.992187 loss)
I0423 18:26:25.458781 30295 solver.cpp:244]     Train net output #1: loss = 0.583663 (* 1 = 0.583663 loss)
I0423 18:26:25.458786 30295 solver.cpp:244]     Train net output #2: loss = 0.910441 (* 1 = 0.910441 loss)
I0423 18:26:25.458791 30295 solver.cpp:244]     Train net output #3: loss = 0.670996 (* 1 = 0.670996 loss)
I0423 18:26:25.458796 30295 sgd_solver.cpp:106] Iteration 57200, lr = 9e-06
I0423 18:28:07.835840 30295 solver.cpp:228] Iteration 57300, loss = 3.16758
I0423 18:28:07.835989 30295 solver.cpp:244]     Train net output #0: loss = 0.987477 (* 1 = 0.987477 loss)
I0423 18:28:07.835997 30295 solver.cpp:244]     Train net output #1: loss = 0.559932 (* 1 = 0.559932 loss)
I0423 18:28:07.836002 30295 solver.cpp:244]     Train net output #2: loss = 0.928737 (* 1 = 0.928737 loss)
I0423 18:28:07.836007 30295 solver.cpp:244]     Train net output #3: loss = 0.69143 (* 1 = 0.69143 loss)
I0423 18:28:07.836012 30295 sgd_solver.cpp:106] Iteration 57300, lr = 9e-06
I0423 18:29:50.752120 30295 solver.cpp:228] Iteration 57400, loss = 2.77669
I0423 18:29:50.752285 30295 solver.cpp:244]     Train net output #0: loss = 0.993805 (* 1 = 0.993805 loss)
I0423 18:29:50.752292 30295 solver.cpp:244]     Train net output #1: loss = 0.431062 (* 1 = 0.431062 loss)
I0423 18:29:50.752297 30295 solver.cpp:244]     Train net output #2: loss = 0.736277 (* 1 = 0.736277 loss)
I0423 18:29:50.752301 30295 solver.cpp:244]     Train net output #3: loss = 0.615547 (* 1 = 0.615547 loss)
I0423 18:29:50.752307 30295 sgd_solver.cpp:106] Iteration 57400, lr = 9e-06
I0423 18:31:32.952702 30295 solver.cpp:228] Iteration 57500, loss = 3.05317
I0423 18:31:32.952888 30295 solver.cpp:244]     Train net output #0: loss = 0.970204 (* 1 = 0.970204 loss)
I0423 18:31:32.952895 30295 solver.cpp:244]     Train net output #1: loss = 0.546154 (* 1 = 0.546154 loss)
I0423 18:31:32.952900 30295 solver.cpp:244]     Train net output #2: loss = 0.962105 (* 1 = 0.962105 loss)
I0423 18:31:32.952904 30295 solver.cpp:244]     Train net output #3: loss = 0.574708 (* 1 = 0.574708 loss)
I0423 18:31:32.952909 30295 sgd_solver.cpp:106] Iteration 57500, lr = 9e-06
I0423 18:33:15.756399 30295 solver.cpp:228] Iteration 57600, loss = 3.04131
I0423 18:33:15.756568 30295 solver.cpp:244]     Train net output #0: loss = 0.962282 (* 1 = 0.962282 loss)
I0423 18:33:15.756577 30295 solver.cpp:244]     Train net output #1: loss = 0.783349 (* 1 = 0.783349 loss)
I0423 18:33:15.756582 30295 solver.cpp:244]     Train net output #2: loss = 0.725896 (* 1 = 0.725896 loss)
I0423 18:33:15.756585 30295 solver.cpp:244]     Train net output #3: loss = 0.569781 (* 1 = 0.569781 loss)
I0423 18:33:15.756592 30295 sgd_solver.cpp:106] Iteration 57600, lr = 9e-06
I0423 18:34:58.865857 30295 solver.cpp:228] Iteration 57700, loss = 2.74796
I0423 18:34:58.866013 30295 solver.cpp:244]     Train net output #0: loss = 0.993177 (* 1 = 0.993177 loss)
I0423 18:34:58.866019 30295 solver.cpp:244]     Train net output #1: loss = 0.600604 (* 1 = 0.600604 loss)
I0423 18:34:58.866025 30295 solver.cpp:244]     Train net output #2: loss = 0.577326 (* 1 = 0.577326 loss)
I0423 18:34:58.866029 30295 solver.cpp:244]     Train net output #3: loss = 0.576858 (* 1 = 0.576858 loss)
I0423 18:34:58.866034 30295 sgd_solver.cpp:106] Iteration 57700, lr = 9e-06
I0423 18:36:38.202028 30295 solver.cpp:228] Iteration 57800, loss = 2.705
I0423 18:36:38.202183 30295 solver.cpp:244]     Train net output #0: loss = 0.982506 (* 1 = 0.982506 loss)
I0423 18:36:38.202189 30295 solver.cpp:244]     Train net output #1: loss = 0.428765 (* 1 = 0.428765 loss)
I0423 18:36:38.202193 30295 solver.cpp:244]     Train net output #2: loss = 0.575588 (* 1 = 0.575588 loss)
I0423 18:36:38.202198 30295 solver.cpp:244]     Train net output #3: loss = 0.718145 (* 1 = 0.718145 loss)
I0423 18:36:38.202203 30295 sgd_solver.cpp:106] Iteration 57800, lr = 9e-06
I0423 18:38:21.649670 30295 solver.cpp:228] Iteration 57900, loss = 3.49895
I0423 18:38:21.649883 30295 solver.cpp:244]     Train net output #0: loss = 0.9806 (* 1 = 0.9806 loss)
I0423 18:38:21.649900 30295 solver.cpp:244]     Train net output #1: loss = 0.831693 (* 1 = 0.831693 loss)
I0423 18:38:21.649912 30295 solver.cpp:244]     Train net output #2: loss = 0.938486 (* 1 = 0.938486 loss)
I0423 18:38:21.649921 30295 solver.cpp:244]     Train net output #3: loss = 0.748174 (* 1 = 0.748174 loss)
I0423 18:38:21.649930 30295 sgd_solver.cpp:106] Iteration 57900, lr = 9e-06
I0423 18:40:04.300793 30295 solver.cpp:337] Iteration 58000, Testing net (#0)
I0423 18:40:04.300925 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 18:40:04.300930 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 18:40:04.300932 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 18:40:04.300946 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 18:40:04.300951 30295 net.cpp:693] Ignoring source layer visualize
I0423 18:40:04.300952 30295 net.cpp:693] Ignoring source layer fake
I0423 18:43:42.420097 30295 solver.cpp:404]     Test net output #0: loss = 0.971115 (* 1 = 0.971115 loss)
I0423 18:43:42.420253 30295 solver.cpp:404]     Test net output #1: loss = 0.482576 (* 1 = 0.482576 loss)
I0423 18:43:42.420260 30295 solver.cpp:404]     Test net output #2: loss = 0.810715 (* 1 = 0.810715 loss)
I0423 18:43:42.420264 30295 solver.cpp:404]     Test net output #3: loss = 0.545747 (* 1 = 0.545747 loss)
I0423 18:43:43.083816 30295 solver.cpp:228] Iteration 58000, loss = 3.34513
I0423 18:43:43.083858 30295 solver.cpp:244]     Train net output #0: loss = 0.982341 (* 1 = 0.982341 loss)
I0423 18:43:43.083864 30295 solver.cpp:244]     Train net output #1: loss = 0.75179 (* 1 = 0.75179 loss)
I0423 18:43:43.083868 30295 solver.cpp:244]     Train net output #2: loss = 0.908721 (* 1 = 0.908721 loss)
I0423 18:43:43.083871 30295 solver.cpp:244]     Train net output #3: loss = 0.702276 (* 1 = 0.702276 loss)
I0423 18:43:43.083874 30295 sgd_solver.cpp:106] Iteration 58000, lr = 9e-06
I0423 18:45:28.116578 30295 solver.cpp:228] Iteration 58100, loss = 3.25757
I0423 18:45:28.116744 30295 solver.cpp:244]     Train net output #0: loss = 0.978136 (* 1 = 0.978136 loss)
I0423 18:45:28.116751 30295 solver.cpp:244]     Train net output #1: loss = 0.664502 (* 1 = 0.664502 loss)
I0423 18:45:28.116756 30295 solver.cpp:244]     Train net output #2: loss = 0.929572 (* 1 = 0.929572 loss)
I0423 18:45:28.116761 30295 solver.cpp:244]     Train net output #3: loss = 0.685359 (* 1 = 0.685359 loss)
I0423 18:45:28.116766 30295 sgd_solver.cpp:106] Iteration 58100, lr = 9e-06
I0423 18:47:07.689007 30295 solver.cpp:228] Iteration 58200, loss = 3.41489
I0423 18:47:07.689213 30295 solver.cpp:244]     Train net output #0: loss = 0.980156 (* 1 = 0.980156 loss)
I0423 18:47:07.689234 30295 solver.cpp:244]     Train net output #1: loss = 0.80549 (* 1 = 0.80549 loss)
I0423 18:47:07.689244 30295 solver.cpp:244]     Train net output #2: loss = 0.947196 (* 1 = 0.947196 loss)
I0423 18:47:07.689255 30295 solver.cpp:244]     Train net output #3: loss = 0.682048 (* 1 = 0.682048 loss)
I0423 18:47:07.689265 30295 sgd_solver.cpp:106] Iteration 58200, lr = 9e-06
I0423 18:48:52.574275 30295 solver.cpp:228] Iteration 58300, loss = 3.0658
I0423 18:48:52.574439 30295 solver.cpp:244]     Train net output #0: loss = 0.98733 (* 1 = 0.98733 loss)
I0423 18:48:52.574445 30295 solver.cpp:244]     Train net output #1: loss = 0.624739 (* 1 = 0.624739 loss)
I0423 18:48:52.574450 30295 solver.cpp:244]     Train net output #2: loss = 0.803806 (* 1 = 0.803806 loss)
I0423 18:48:52.574455 30295 solver.cpp:244]     Train net output #3: loss = 0.649927 (* 1 = 0.649927 loss)
I0423 18:48:52.574460 30295 sgd_solver.cpp:106] Iteration 58300, lr = 9e-06
I0423 18:50:36.704473 30295 solver.cpp:228] Iteration 58400, loss = 3.25284
I0423 18:50:36.704618 30295 solver.cpp:244]     Train net output #0: loss = 0.98925 (* 1 = 0.98925 loss)
I0423 18:50:36.704627 30295 solver.cpp:244]     Train net output #1: loss = 0.677648 (* 1 = 0.677648 loss)
I0423 18:50:36.704632 30295 solver.cpp:244]     Train net output #2: loss = 0.967168 (* 1 = 0.967168 loss)
I0423 18:50:36.704635 30295 solver.cpp:244]     Train net output #3: loss = 0.618774 (* 1 = 0.618774 loss)
I0423 18:50:36.704640 30295 sgd_solver.cpp:106] Iteration 58400, lr = 9e-06
I0423 18:52:20.918020 30295 solver.cpp:228] Iteration 58500, loss = 3.02202
I0423 18:52:20.918176 30295 solver.cpp:244]     Train net output #0: loss = 0.99122 (* 1 = 0.99122 loss)
I0423 18:52:20.918184 30295 solver.cpp:244]     Train net output #1: loss = 0.581228 (* 1 = 0.581228 loss)
I0423 18:52:20.918189 30295 solver.cpp:244]     Train net output #2: loss = 0.845809 (* 1 = 0.845809 loss)
I0423 18:52:20.918193 30295 solver.cpp:244]     Train net output #3: loss = 0.603762 (* 1 = 0.603762 loss)
I0423 18:52:20.918197 30295 sgd_solver.cpp:106] Iteration 58500, lr = 9e-06
I0423 18:54:00.240221 30295 solver.cpp:228] Iteration 58600, loss = 3.07555
I0423 18:54:00.240382 30295 solver.cpp:244]     Train net output #0: loss = 0.990076 (* 1 = 0.990076 loss)
I0423 18:54:00.240391 30295 solver.cpp:244]     Train net output #1: loss = 0.592275 (* 1 = 0.592275 loss)
I0423 18:54:00.240396 30295 solver.cpp:244]     Train net output #2: loss = 0.87274 (* 1 = 0.87274 loss)
I0423 18:54:00.240399 30295 solver.cpp:244]     Train net output #3: loss = 0.620461 (* 1 = 0.620461 loss)
I0423 18:54:00.240404 30295 sgd_solver.cpp:106] Iteration 58600, lr = 9e-06
I0423 18:55:44.127276 30295 solver.cpp:228] Iteration 58700, loss = 2.89987
I0423 18:55:44.127411 30295 solver.cpp:244]     Train net output #0: loss = 0.987461 (* 1 = 0.987461 loss)
I0423 18:55:44.127418 30295 solver.cpp:244]     Train net output #1: loss = 0.581391 (* 1 = 0.581391 loss)
I0423 18:55:44.127424 30295 solver.cpp:244]     Train net output #2: loss = 0.73997 (* 1 = 0.73997 loss)
I0423 18:55:44.127429 30295 solver.cpp:244]     Train net output #3: loss = 0.591049 (* 1 = 0.591049 loss)
I0423 18:55:44.127434 30295 sgd_solver.cpp:106] Iteration 58700, lr = 9e-06
I0423 18:57:26.831240 30295 solver.cpp:228] Iteration 58800, loss = 2.97033
I0423 18:57:26.831399 30295 solver.cpp:244]     Train net output #0: loss = 0.971748 (* 1 = 0.971748 loss)
I0423 18:57:26.831408 30295 solver.cpp:244]     Train net output #1: loss = 0.620222 (* 1 = 0.620222 loss)
I0423 18:57:26.831413 30295 solver.cpp:244]     Train net output #2: loss = 0.921042 (* 1 = 0.921042 loss)
I0423 18:57:26.831416 30295 solver.cpp:244]     Train net output #3: loss = 0.457315 (* 1 = 0.457315 loss)
I0423 18:57:26.831421 30295 sgd_solver.cpp:106] Iteration 58800, lr = 9e-06
I0423 18:59:07.923998 30295 solver.cpp:228] Iteration 58900, loss = 3.16892
I0423 18:59:07.924165 30295 solver.cpp:244]     Train net output #0: loss = 0.967815 (* 1 = 0.967815 loss)
I0423 18:59:07.924172 30295 solver.cpp:244]     Train net output #1: loss = 0.577224 (* 1 = 0.577224 loss)
I0423 18:59:07.924177 30295 solver.cpp:244]     Train net output #2: loss = 0.939071 (* 1 = 0.939071 loss)
I0423 18:59:07.924183 30295 solver.cpp:244]     Train net output #3: loss = 0.68481 (* 1 = 0.68481 loss)
I0423 18:59:07.924188 30295 sgd_solver.cpp:106] Iteration 58900, lr = 9e-06
I0423 19:00:54.217655 30295 solver.cpp:337] Iteration 59000, Testing net (#0)
I0423 19:00:54.217820 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 19:00:54.217825 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 19:00:54.217829 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 19:00:54.217844 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 19:00:54.217846 30295 net.cpp:693] Ignoring source layer visualize
I0423 19:00:54.217849 30295 net.cpp:693] Ignoring source layer fake
I0423 19:04:31.913044 30295 solver.cpp:404]     Test net output #0: loss = 0.973986 (* 1 = 0.973986 loss)
I0423 19:04:31.913206 30295 solver.cpp:404]     Test net output #1: loss = 0.528681 (* 1 = 0.528681 loss)
I0423 19:04:31.913213 30295 solver.cpp:404]     Test net output #2: loss = 0.805793 (* 1 = 0.805793 loss)
I0423 19:04:31.913218 30295 solver.cpp:404]     Test net output #3: loss = 0.566257 (* 1 = 0.566257 loss)
I0423 19:04:32.575832 30295 solver.cpp:228] Iteration 59000, loss = 2.82826
I0423 19:04:32.575875 30295 solver.cpp:244]     Train net output #0: loss = 0.961688 (* 1 = 0.961688 loss)
I0423 19:04:32.575880 30295 solver.cpp:244]     Train net output #1: loss = 0.75469 (* 1 = 0.75469 loss)
I0423 19:04:32.575884 30295 solver.cpp:244]     Train net output #2: loss = 0.576006 (* 1 = 0.576006 loss)
I0423 19:04:32.575888 30295 solver.cpp:244]     Train net output #3: loss = 0.535874 (* 1 = 0.535874 loss)
I0423 19:04:32.575893 30295 sgd_solver.cpp:106] Iteration 59000, lr = 9e-06
I0423 19:06:20.782199 30295 solver.cpp:228] Iteration 59100, loss = 3.27709
I0423 19:06:20.782369 30295 solver.cpp:244]     Train net output #0: loss = 0.970064 (* 1 = 0.970064 loss)
I0423 19:06:20.782377 30295 solver.cpp:244]     Train net output #1: loss = 0.769137 (* 1 = 0.769137 loss)
I0423 19:06:20.782380 30295 solver.cpp:244]     Train net output #2: loss = 0.852382 (* 1 = 0.852382 loss)
I0423 19:06:20.782384 30295 solver.cpp:244]     Train net output #3: loss = 0.685503 (* 1 = 0.685503 loss)
I0423 19:06:20.782390 30295 sgd_solver.cpp:106] Iteration 59100, lr = 9e-06
I0423 19:08:06.938446 30295 solver.cpp:228] Iteration 59200, loss = 3.22307
I0423 19:08:06.938622 30295 solver.cpp:244]     Train net output #0: loss = 0.981102 (* 1 = 0.981102 loss)
I0423 19:08:06.938629 30295 solver.cpp:244]     Train net output #1: loss = 0.669502 (* 1 = 0.669502 loss)
I0423 19:08:06.938634 30295 solver.cpp:244]     Train net output #2: loss = 0.912502 (* 1 = 0.912502 loss)
I0423 19:08:06.938639 30295 solver.cpp:244]     Train net output #3: loss = 0.659967 (* 1 = 0.659967 loss)
I0423 19:08:06.938644 30295 sgd_solver.cpp:106] Iteration 59200, lr = 9e-06
I0423 19:09:46.546661 30295 solver.cpp:228] Iteration 59300, loss = 3.35575
I0423 19:09:46.548271 30295 solver.cpp:244]     Train net output #0: loss = 0.966657 (* 1 = 0.966657 loss)
I0423 19:09:46.548280 30295 solver.cpp:244]     Train net output #1: loss = 0.726221 (* 1 = 0.726221 loss)
I0423 19:09:46.548285 30295 solver.cpp:244]     Train net output #2: loss = 0.930057 (* 1 = 0.930057 loss)
I0423 19:09:46.548290 30295 solver.cpp:244]     Train net output #3: loss = 0.732818 (* 1 = 0.732818 loss)
I0423 19:09:46.548295 30295 sgd_solver.cpp:106] Iteration 59300, lr = 9e-06
I0423 19:11:33.130931 30295 solver.cpp:228] Iteration 59400, loss = 3.37272
I0423 19:11:33.131091 30295 solver.cpp:244]     Train net output #0: loss = 0.976017 (* 1 = 0.976017 loss)
I0423 19:11:33.131098 30295 solver.cpp:244]     Train net output #1: loss = 0.825643 (* 1 = 0.825643 loss)
I0423 19:11:33.131104 30295 solver.cpp:244]     Train net output #2: loss = 0.915812 (* 1 = 0.915812 loss)
I0423 19:11:33.131108 30295 solver.cpp:244]     Train net output #3: loss = 0.655252 (* 1 = 0.655252 loss)
I0423 19:11:33.131112 30295 sgd_solver.cpp:106] Iteration 59400, lr = 9e-06
I0423 19:13:15.119933 30295 solver.cpp:228] Iteration 59500, loss = 3.15092
I0423 19:13:15.120092 30295 solver.cpp:244]     Train net output #0: loss = 0.990938 (* 1 = 0.990938 loss)
I0423 19:13:15.120100 30295 solver.cpp:244]     Train net output #1: loss = 0.771455 (* 1 = 0.771455 loss)
I0423 19:13:15.120105 30295 solver.cpp:244]     Train net output #2: loss = 0.727995 (* 1 = 0.727995 loss)
I0423 19:13:15.120108 30295 solver.cpp:244]     Train net output #3: loss = 0.660533 (* 1 = 0.660533 loss)
I0423 19:13:15.120115 30295 sgd_solver.cpp:106] Iteration 59500, lr = 9e-06
I0423 19:14:56.602854 30295 solver.cpp:228] Iteration 59600, loss = 3.13868
I0423 19:14:56.603020 30295 solver.cpp:244]     Train net output #0: loss = 0.990308 (* 1 = 0.990308 loss)
I0423 19:14:56.603029 30295 solver.cpp:244]     Train net output #1: loss = 0.612814 (* 1 = 0.612814 loss)
I0423 19:14:56.603035 30295 solver.cpp:244]     Train net output #2: loss = 0.851743 (* 1 = 0.851743 loss)
I0423 19:14:56.603040 30295 solver.cpp:244]     Train net output #3: loss = 0.683814 (* 1 = 0.683814 loss)
I0423 19:14:56.603046 30295 sgd_solver.cpp:106] Iteration 59600, lr = 9e-06
I0423 19:16:36.167832 30295 solver.cpp:228] Iteration 59700, loss = 3.13792
I0423 19:16:36.168789 30295 solver.cpp:244]     Train net output #0: loss = 0.991353 (* 1 = 0.991353 loss)
I0423 19:16:36.168797 30295 solver.cpp:244]     Train net output #1: loss = 0.570438 (* 1 = 0.570438 loss)
I0423 19:16:36.168802 30295 solver.cpp:244]     Train net output #2: loss = 0.889334 (* 1 = 0.889334 loss)
I0423 19:16:36.168807 30295 solver.cpp:244]     Train net output #3: loss = 0.686792 (* 1 = 0.686792 loss)
I0423 19:16:36.168812 30295 sgd_solver.cpp:106] Iteration 59700, lr = 9e-06
I0423 19:18:17.488656 30295 solver.cpp:228] Iteration 59800, loss = 3.15566
I0423 19:18:17.488816 30295 solver.cpp:244]     Train net output #0: loss = 0.987078 (* 1 = 0.987078 loss)
I0423 19:18:17.488823 30295 solver.cpp:244]     Train net output #1: loss = 0.601056 (* 1 = 0.601056 loss)
I0423 19:18:17.488828 30295 solver.cpp:244]     Train net output #2: loss = 0.896829 (* 1 = 0.896829 loss)
I0423 19:18:17.488832 30295 solver.cpp:244]     Train net output #3: loss = 0.670697 (* 1 = 0.670697 loss)
I0423 19:18:17.488837 30295 sgd_solver.cpp:106] Iteration 59800, lr = 9e-06
I0423 19:19:58.419164 30295 solver.cpp:228] Iteration 59900, loss = 2.43177
I0423 19:19:58.419324 30295 solver.cpp:244]     Train net output #0: loss = 0.990456 (* 1 = 0.990456 loss)
I0423 19:19:58.419332 30295 solver.cpp:244]     Train net output #1: loss = 0.342212 (* 1 = 0.342212 loss)
I0423 19:19:58.419337 30295 solver.cpp:244]     Train net output #2: loss = 0.636167 (* 1 = 0.636167 loss)
I0423 19:19:58.419342 30295 solver.cpp:244]     Train net output #3: loss = 0.462933 (* 1 = 0.462933 loss)
I0423 19:19:58.419347 30295 sgd_solver.cpp:106] Iteration 59900, lr = 9e-06
I0423 19:21:37.962405 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_60000.caffemodel
I0423 19:21:52.488266 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_60000.solverstate
I0423 19:21:52.680022 30295 solver.cpp:337] Iteration 60000, Testing net (#0)
I0423 19:21:52.680066 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 19:21:52.680068 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 19:21:52.680073 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 19:21:52.680085 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 19:21:52.680089 30295 net.cpp:693] Ignoring source layer visualize
I0423 19:21:52.680091 30295 net.cpp:693] Ignoring source layer fake
I0423 19:25:29.619308 30295 solver.cpp:404]     Test net output #0: loss = 0.970958 (* 1 = 0.970958 loss)
I0423 19:25:29.619451 30295 solver.cpp:404]     Test net output #1: loss = 0.510639 (* 1 = 0.510639 loss)
I0423 19:25:29.619459 30295 solver.cpp:404]     Test net output #2: loss = 0.8189 (* 1 = 0.8189 loss)
I0423 19:25:29.619464 30295 solver.cpp:404]     Test net output #3: loss = 0.573542 (* 1 = 0.573542 loss)
I0423 19:25:30.288180 30295 solver.cpp:228] Iteration 60000, loss = 3.4782
I0423 19:25:30.288221 30295 solver.cpp:244]     Train net output #0: loss = 0.975812 (* 1 = 0.975812 loss)
I0423 19:25:30.288228 30295 solver.cpp:244]     Train net output #1: loss = 0.790312 (* 1 = 0.790312 loss)
I0423 19:25:30.288231 30295 solver.cpp:244]     Train net output #2: loss = 0.972914 (* 1 = 0.972914 loss)
I0423 19:25:30.288236 30295 solver.cpp:244]     Train net output #3: loss = 0.739162 (* 1 = 0.739162 loss)
I0423 19:25:30.288244 30295 sgd_solver.cpp:106] Iteration 60000, lr = 2.7e-06
I0423 19:27:11.287302 30295 solver.cpp:228] Iteration 60100, loss = 3.21794
I0423 19:27:11.287457 30295 solver.cpp:244]     Train net output #0: loss = 0.971709 (* 1 = 0.971709 loss)
I0423 19:27:11.287464 30295 solver.cpp:244]     Train net output #1: loss = 0.683177 (* 1 = 0.683177 loss)
I0423 19:27:11.287469 30295 solver.cpp:244]     Train net output #2: loss = 0.896494 (* 1 = 0.896494 loss)
I0423 19:27:11.287474 30295 solver.cpp:244]     Train net output #3: loss = 0.666557 (* 1 = 0.666557 loss)
I0423 19:27:11.287479 30295 sgd_solver.cpp:106] Iteration 60100, lr = 2.7e-06
I0423 19:28:52.390904 30295 solver.cpp:228] Iteration 60200, loss = 2.99641
I0423 19:28:52.391064 30295 solver.cpp:244]     Train net output #0: loss = 0.983159 (* 1 = 0.983159 loss)
I0423 19:28:52.391073 30295 solver.cpp:244]     Train net output #1: loss = 0.738366 (* 1 = 0.738366 loss)
I0423 19:28:52.391077 30295 solver.cpp:244]     Train net output #2: loss = 0.75635 (* 1 = 0.75635 loss)
I0423 19:28:52.391083 30295 solver.cpp:244]     Train net output #3: loss = 0.518535 (* 1 = 0.518535 loss)
I0423 19:28:52.391088 30295 sgd_solver.cpp:106] Iteration 60200, lr = 2.7e-06
I0423 19:30:32.186342 30295 solver.cpp:228] Iteration 60300, loss = 2.85346
I0423 19:30:32.186487 30295 solver.cpp:244]     Train net output #0: loss = 0.987793 (* 1 = 0.987793 loss)
I0423 19:30:32.186494 30295 solver.cpp:244]     Train net output #1: loss = 0.529723 (* 1 = 0.529723 loss)
I0423 19:30:32.186499 30295 solver.cpp:244]     Train net output #2: loss = 0.748625 (* 1 = 0.748625 loss)
I0423 19:30:32.186504 30295 solver.cpp:244]     Train net output #3: loss = 0.587316 (* 1 = 0.587316 loss)
I0423 19:30:32.186509 30295 sgd_solver.cpp:106] Iteration 60300, lr = 2.7e-06
I0423 19:32:13.606132 30295 solver.cpp:228] Iteration 60400, loss = 3.31156
I0423 19:32:13.606292 30295 solver.cpp:244]     Train net output #0: loss = 0.964704 (* 1 = 0.964704 loss)
I0423 19:32:13.606302 30295 solver.cpp:244]     Train net output #1: loss = 0.73992 (* 1 = 0.73992 loss)
I0423 19:32:13.606305 30295 solver.cpp:244]     Train net output #2: loss = 0.920292 (* 1 = 0.920292 loss)
I0423 19:32:13.606310 30295 solver.cpp:244]     Train net output #3: loss = 0.686642 (* 1 = 0.686642 loss)
I0423 19:32:13.606315 30295 sgd_solver.cpp:106] Iteration 60400, lr = 2.7e-06
I0423 19:33:55.096500 30295 solver.cpp:228] Iteration 60500, loss = 3.43284
I0423 19:33:55.096652 30295 solver.cpp:244]     Train net output #0: loss = 0.986038 (* 1 = 0.986038 loss)
I0423 19:33:55.096658 30295 solver.cpp:244]     Train net output #1: loss = 0.796479 (* 1 = 0.796479 loss)
I0423 19:33:55.096663 30295 solver.cpp:244]     Train net output #2: loss = 0.934943 (* 1 = 0.934943 loss)
I0423 19:33:55.096668 30295 solver.cpp:244]     Train net output #3: loss = 0.71538 (* 1 = 0.71538 loss)
I0423 19:33:55.096673 30295 sgd_solver.cpp:106] Iteration 60500, lr = 2.7e-06
I0423 19:35:36.516180 30295 solver.cpp:228] Iteration 60600, loss = 3.40581
I0423 19:35:36.516331 30295 solver.cpp:244]     Train net output #0: loss = 0.981527 (* 1 = 0.981527 loss)
I0423 19:35:36.516340 30295 solver.cpp:244]     Train net output #1: loss = 0.749316 (* 1 = 0.749316 loss)
I0423 19:35:36.516345 30295 solver.cpp:244]     Train net output #2: loss = 0.932721 (* 1 = 0.932721 loss)
I0423 19:35:36.516348 30295 solver.cpp:244]     Train net output #3: loss = 0.742249 (* 1 = 0.742249 loss)
I0423 19:35:36.516353 30295 sgd_solver.cpp:106] Iteration 60600, lr = 2.7e-06
I0423 19:37:16.379606 30295 solver.cpp:228] Iteration 60700, loss = 3.24291
I0423 19:37:16.379765 30295 solver.cpp:244]     Train net output #0: loss = 0.969205 (* 1 = 0.969205 loss)
I0423 19:37:16.379771 30295 solver.cpp:244]     Train net output #1: loss = 0.711487 (* 1 = 0.711487 loss)
I0423 19:37:16.379776 30295 solver.cpp:244]     Train net output #2: loss = 0.926268 (* 1 = 0.926268 loss)
I0423 19:37:16.379781 30295 solver.cpp:244]     Train net output #3: loss = 0.635947 (* 1 = 0.635947 loss)
I0423 19:37:16.379786 30295 sgd_solver.cpp:106] Iteration 60700, lr = 2.7e-06
I0423 19:38:57.556586 30295 solver.cpp:228] Iteration 60800, loss = 3.02438
I0423 19:38:57.556937 30295 solver.cpp:244]     Train net output #0: loss = 0.983689 (* 1 = 0.983689 loss)
I0423 19:38:57.556946 30295 solver.cpp:244]     Train net output #1: loss = 0.552029 (* 1 = 0.552029 loss)
I0423 19:38:57.556951 30295 solver.cpp:244]     Train net output #2: loss = 0.931533 (* 1 = 0.931533 loss)
I0423 19:38:57.556954 30295 solver.cpp:244]     Train net output #3: loss = 0.557125 (* 1 = 0.557125 loss)
I0423 19:38:57.556959 30295 sgd_solver.cpp:106] Iteration 60800, lr = 2.7e-06
I0423 19:40:39.048137 30295 solver.cpp:228] Iteration 60900, loss = 3.1604
I0423 19:40:39.048318 30295 solver.cpp:244]     Train net output #0: loss = 0.989362 (* 1 = 0.989362 loss)
I0423 19:40:39.048326 30295 solver.cpp:244]     Train net output #1: loss = 0.630375 (* 1 = 0.630375 loss)
I0423 19:40:39.048331 30295 solver.cpp:244]     Train net output #2: loss = 0.911252 (* 1 = 0.911252 loss)
I0423 19:40:39.048336 30295 solver.cpp:244]     Train net output #3: loss = 0.629409 (* 1 = 0.629409 loss)
I0423 19:40:39.048341 30295 sgd_solver.cpp:106] Iteration 60900, lr = 2.7e-06
I0423 19:42:19.372624 30295 solver.cpp:337] Iteration 61000, Testing net (#0)
I0423 19:42:19.372774 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 19:42:19.372779 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 19:42:19.372782 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 19:42:19.372797 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 19:42:19.372799 30295 net.cpp:693] Ignoring source layer visualize
I0423 19:42:19.372802 30295 net.cpp:693] Ignoring source layer fake
I0423 19:45:57.821133 30295 solver.cpp:404]     Test net output #0: loss = 0.971575 (* 1 = 0.971575 loss)
I0423 19:45:57.821300 30295 solver.cpp:404]     Test net output #1: loss = 0.551459 (* 1 = 0.551459 loss)
I0423 19:45:57.821306 30295 solver.cpp:404]     Test net output #2: loss = 0.826167 (* 1 = 0.826167 loss)
I0423 19:45:57.821311 30295 solver.cpp:404]     Test net output #3: loss = 0.598599 (* 1 = 0.598599 loss)
I0423 19:45:58.486737 30295 solver.cpp:228] Iteration 61000, loss = 2.57752
I0423 19:45:58.486778 30295 solver.cpp:244]     Train net output #0: loss = 0.992354 (* 1 = 0.992354 loss)
I0423 19:45:58.486784 30295 solver.cpp:244]     Train net output #1: loss = 0.450186 (* 1 = 0.450186 loss)
I0423 19:45:58.486789 30295 solver.cpp:244]     Train net output #2: loss = 0.614124 (* 1 = 0.614124 loss)
I0423 19:45:58.486793 30295 solver.cpp:244]     Train net output #3: loss = 0.520854 (* 1 = 0.520854 loss)
I0423 19:45:58.486798 30295 sgd_solver.cpp:106] Iteration 61000, lr = 2.7e-06
I0423 19:47:38.210954 30295 solver.cpp:228] Iteration 61100, loss = 2.80961
I0423 19:47:38.211103 30295 solver.cpp:244]     Train net output #0: loss = 0.990252 (* 1 = 0.990252 loss)
I0423 19:47:38.211110 30295 solver.cpp:244]     Train net output #1: loss = 0.577915 (* 1 = 0.577915 loss)
I0423 19:47:38.211114 30295 solver.cpp:244]     Train net output #2: loss = 0.683843 (* 1 = 0.683843 loss)
I0423 19:47:38.211119 30295 solver.cpp:244]     Train net output #3: loss = 0.557595 (* 1 = 0.557595 loss)
I0423 19:47:38.211124 30295 sgd_solver.cpp:106] Iteration 61100, lr = 2.7e-06
I0423 19:49:19.187834 30295 solver.cpp:228] Iteration 61200, loss = 2.68512
I0423 19:49:19.187995 30295 solver.cpp:244]     Train net output #0: loss = 0.9814 (* 1 = 0.9814 loss)
I0423 19:49:19.188002 30295 solver.cpp:244]     Train net output #1: loss = 0.418775 (* 1 = 0.418775 loss)
I0423 19:49:19.188009 30295 solver.cpp:244]     Train net output #2: loss = 0.758138 (* 1 = 0.758138 loss)
I0423 19:49:19.188012 30295 solver.cpp:244]     Train net output #3: loss = 0.52681 (* 1 = 0.52681 loss)
I0423 19:49:19.188017 30295 sgd_solver.cpp:106] Iteration 61200, lr = 2.7e-06
I0423 19:50:59.890765 30295 solver.cpp:228] Iteration 61300, loss = 3.19445
I0423 19:50:59.890911 30295 solver.cpp:244]     Train net output #0: loss = 0.959789 (* 1 = 0.959789 loss)
I0423 19:50:59.890918 30295 solver.cpp:244]     Train net output #1: loss = 0.727413 (* 1 = 0.727413 loss)
I0423 19:50:59.890923 30295 solver.cpp:244]     Train net output #2: loss = 0.957125 (* 1 = 0.957125 loss)
I0423 19:50:59.890928 30295 solver.cpp:244]     Train net output #3: loss = 0.550125 (* 1 = 0.550125 loss)
I0423 19:50:59.890933 30295 sgd_solver.cpp:106] Iteration 61300, lr = 2.7e-06
I0423 19:52:40.525547 30295 solver.cpp:228] Iteration 61400, loss = 3.28735
I0423 19:52:40.525712 30295 solver.cpp:244]     Train net output #0: loss = 0.941935 (* 1 = 0.941935 loss)
I0423 19:52:40.525719 30295 solver.cpp:244]     Train net output #1: loss = 0.663543 (* 1 = 0.663543 loss)
I0423 19:52:40.525725 30295 solver.cpp:244]     Train net output #2: loss = 0.956199 (* 1 = 0.956199 loss)
I0423 19:52:40.525729 30295 solver.cpp:244]     Train net output #3: loss = 0.725671 (* 1 = 0.725671 loss)
I0423 19:52:40.525735 30295 sgd_solver.cpp:106] Iteration 61400, lr = 2.7e-06
I0423 19:54:21.499873 30295 solver.cpp:228] Iteration 61500, loss = 2.90647
I0423 19:54:21.500037 30295 solver.cpp:244]     Train net output #0: loss = 0.988835 (* 1 = 0.988835 loss)
I0423 19:54:21.500044 30295 solver.cpp:244]     Train net output #1: loss = 0.649342 (* 1 = 0.649342 loss)
I0423 19:54:21.500049 30295 solver.cpp:244]     Train net output #2: loss = 0.732153 (* 1 = 0.732153 loss)
I0423 19:54:21.500054 30295 solver.cpp:244]     Train net output #3: loss = 0.536144 (* 1 = 0.536144 loss)
I0423 19:54:21.500059 30295 sgd_solver.cpp:106] Iteration 61500, lr = 2.7e-06
I0423 19:56:02.728562 30295 solver.cpp:228] Iteration 61600, loss = 3.37239
I0423 19:56:02.728740 30295 solver.cpp:244]     Train net output #0: loss = 0.972021 (* 1 = 0.972021 loss)
I0423 19:56:02.728749 30295 solver.cpp:244]     Train net output #1: loss = 0.809312 (* 1 = 0.809312 loss)
I0423 19:56:02.728757 30295 solver.cpp:244]     Train net output #2: loss = 0.894947 (* 1 = 0.894947 loss)
I0423 19:56:02.728765 30295 solver.cpp:244]     Train net output #3: loss = 0.696109 (* 1 = 0.696109 loss)
I0423 19:56:02.728772 30295 sgd_solver.cpp:106] Iteration 61600, lr = 2.7e-06
I0423 19:57:43.925457 30295 solver.cpp:228] Iteration 61700, loss = 3.22448
I0423 19:57:43.925622 30295 solver.cpp:244]     Train net output #0: loss = 0.981573 (* 1 = 0.981573 loss)
I0423 19:57:43.925631 30295 solver.cpp:244]     Train net output #1: loss = 0.70454 (* 1 = 0.70454 loss)
I0423 19:57:43.925634 30295 solver.cpp:244]     Train net output #2: loss = 0.903328 (* 1 = 0.903328 loss)
I0423 19:57:43.925639 30295 solver.cpp:244]     Train net output #3: loss = 0.635041 (* 1 = 0.635041 loss)
I0423 19:57:43.925644 30295 sgd_solver.cpp:106] Iteration 61700, lr = 2.7e-06
I0423 19:59:23.719761 30295 solver.cpp:228] Iteration 61800, loss = 3.28762
I0423 19:59:23.719910 30295 solver.cpp:244]     Train net output #0: loss = 0.964779 (* 1 = 0.964779 loss)
I0423 19:59:23.719918 30295 solver.cpp:244]     Train net output #1: loss = 0.69868 (* 1 = 0.69868 loss)
I0423 19:59:23.719923 30295 solver.cpp:244]     Train net output #2: loss = 0.933773 (* 1 = 0.933773 loss)
I0423 19:59:23.719928 30295 solver.cpp:244]     Train net output #3: loss = 0.690386 (* 1 = 0.690386 loss)
I0423 19:59:23.719933 30295 sgd_solver.cpp:106] Iteration 61800, lr = 2.7e-06
I0423 20:01:04.994469 30295 solver.cpp:228] Iteration 61900, loss = 3.28445
I0423 20:01:04.996935 30295 solver.cpp:244]     Train net output #0: loss = 0.972917 (* 1 = 0.972917 loss)
I0423 20:01:04.996944 30295 solver.cpp:244]     Train net output #1: loss = 0.759262 (* 1 = 0.759262 loss)
I0423 20:01:04.996948 30295 solver.cpp:244]     Train net output #2: loss = 0.868611 (* 1 = 0.868611 loss)
I0423 20:01:04.996953 30295 solver.cpp:244]     Train net output #3: loss = 0.68366 (* 1 = 0.68366 loss)
I0423 20:01:04.996958 30295 sgd_solver.cpp:106] Iteration 61900, lr = 2.7e-06
I0423 20:02:45.338083 30295 solver.cpp:337] Iteration 62000, Testing net (#0)
I0423 20:02:45.338243 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 20:02:45.338248 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 20:02:45.338251 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 20:02:45.338265 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 20:02:45.338268 30295 net.cpp:693] Ignoring source layer visualize
I0423 20:02:45.338270 30295 net.cpp:693] Ignoring source layer fake
I0423 20:06:23.275635 30295 solver.cpp:404]     Test net output #0: loss = 0.974455 (* 1 = 0.974455 loss)
I0423 20:06:23.275786 30295 solver.cpp:404]     Test net output #1: loss = 0.512905 (* 1 = 0.512905 loss)
I0423 20:06:23.275794 30295 solver.cpp:404]     Test net output #2: loss = 0.789545 (* 1 = 0.789545 loss)
I0423 20:06:23.275799 30295 solver.cpp:404]     Test net output #3: loss = 0.519507 (* 1 = 0.519507 loss)
I0423 20:06:23.974375 30295 solver.cpp:228] Iteration 62000, loss = 2.90157
I0423 20:06:23.974416 30295 solver.cpp:244]     Train net output #0: loss = 0.98724 (* 1 = 0.98724 loss)
I0423 20:06:23.974422 30295 solver.cpp:244]     Train net output #1: loss = 0.667841 (* 1 = 0.667841 loss)
I0423 20:06:23.974426 30295 solver.cpp:244]     Train net output #2: loss = 0.703943 (* 1 = 0.703943 loss)
I0423 20:06:23.974431 30295 solver.cpp:244]     Train net output #3: loss = 0.542542 (* 1 = 0.542542 loss)
I0423 20:06:23.974436 30295 sgd_solver.cpp:106] Iteration 62000, lr = 2.7e-06
I0423 20:08:05.447012 30295 solver.cpp:228] Iteration 62100, loss = 3.27594
I0423 20:08:05.448117 30295 solver.cpp:244]     Train net output #0: loss = 0.987189 (* 1 = 0.987189 loss)
I0423 20:08:05.448124 30295 solver.cpp:244]     Train net output #1: loss = 0.650683 (* 1 = 0.650683 loss)
I0423 20:08:05.448128 30295 solver.cpp:244]     Train net output #2: loss = 0.894091 (* 1 = 0.894091 loss)
I0423 20:08:05.448134 30295 solver.cpp:244]     Train net output #3: loss = 0.743973 (* 1 = 0.743973 loss)
I0423 20:08:05.448139 30295 sgd_solver.cpp:106] Iteration 62100, lr = 2.7e-06
I0423 20:09:45.026101 30295 solver.cpp:228] Iteration 62200, loss = 3.31551
I0423 20:09:45.026252 30295 solver.cpp:244]     Train net output #0: loss = 0.989041 (* 1 = 0.989041 loss)
I0423 20:09:45.026258 30295 solver.cpp:244]     Train net output #1: loss = 0.65299 (* 1 = 0.65299 loss)
I0423 20:09:45.026263 30295 solver.cpp:244]     Train net output #2: loss = 0.940388 (* 1 = 0.940388 loss)
I0423 20:09:45.026268 30295 solver.cpp:244]     Train net output #3: loss = 0.733086 (* 1 = 0.733086 loss)
I0423 20:09:45.026273 30295 sgd_solver.cpp:106] Iteration 62200, lr = 2.7e-06
I0423 20:11:26.092303 30295 solver.cpp:228] Iteration 62300, loss = 3.33459
I0423 20:11:26.092438 30295 solver.cpp:244]     Train net output #0: loss = 0.987971 (* 1 = 0.987971 loss)
I0423 20:11:26.092447 30295 solver.cpp:244]     Train net output #1: loss = 0.711204 (* 1 = 0.711204 loss)
I0423 20:11:26.092452 30295 solver.cpp:244]     Train net output #2: loss = 0.919226 (* 1 = 0.919226 loss)
I0423 20:11:26.092456 30295 solver.cpp:244]     Train net output #3: loss = 0.71619 (* 1 = 0.71619 loss)
I0423 20:11:26.092461 30295 sgd_solver.cpp:106] Iteration 62300, lr = 2.7e-06
I0423 20:13:07.097276 30295 solver.cpp:228] Iteration 62400, loss = 2.48956
I0423 20:13:07.097452 30295 solver.cpp:244]     Train net output #0: loss = 0.989827 (* 1 = 0.989827 loss)
I0423 20:13:07.097460 30295 solver.cpp:244]     Train net output #1: loss = 0.405925 (* 1 = 0.405925 loss)
I0423 20:13:07.097465 30295 solver.cpp:244]     Train net output #2: loss = 0.697029 (* 1 = 0.697029 loss)
I0423 20:13:07.097470 30295 solver.cpp:244]     Train net output #3: loss = 0.396774 (* 1 = 0.396774 loss)
I0423 20:13:07.097476 30295 sgd_solver.cpp:106] Iteration 62400, lr = 2.7e-06
I0423 20:14:47.661931 30295 solver.cpp:228] Iteration 62500, loss = 3.26592
I0423 20:14:47.662083 30295 solver.cpp:244]     Train net output #0: loss = 0.960706 (* 1 = 0.960706 loss)
I0423 20:14:47.662091 30295 solver.cpp:244]     Train net output #1: loss = 0.753413 (* 1 = 0.753413 loss)
I0423 20:14:47.662096 30295 solver.cpp:244]     Train net output #2: loss = 0.967526 (* 1 = 0.967526 loss)
I0423 20:14:47.662099 30295 solver.cpp:244]     Train net output #3: loss = 0.584274 (* 1 = 0.584274 loss)
I0423 20:14:47.662104 30295 sgd_solver.cpp:106] Iteration 62500, lr = 2.7e-06
I0423 20:16:28.610836 30295 solver.cpp:228] Iteration 62600, loss = 3.28787
I0423 20:16:28.611006 30295 solver.cpp:244]     Train net output #0: loss = 0.982685 (* 1 = 0.982685 loss)
I0423 20:16:28.611013 30295 solver.cpp:244]     Train net output #1: loss = 0.821571 (* 1 = 0.821571 loss)
I0423 20:16:28.611018 30295 solver.cpp:244]     Train net output #2: loss = 0.770288 (* 1 = 0.770288 loss)
I0423 20:16:28.611023 30295 solver.cpp:244]     Train net output #3: loss = 0.713326 (* 1 = 0.713326 loss)
I0423 20:16:28.611029 30295 sgd_solver.cpp:106] Iteration 62600, lr = 2.7e-06
I0423 20:18:09.758937 30295 solver.cpp:228] Iteration 62700, loss = 2.94147
I0423 20:18:09.759136 30295 solver.cpp:244]     Train net output #0: loss = 0.989122 (* 1 = 0.989122 loss)
I0423 20:18:09.759145 30295 solver.cpp:244]     Train net output #1: loss = 0.557085 (* 1 = 0.557085 loss)
I0423 20:18:09.759150 30295 solver.cpp:244]     Train net output #2: loss = 0.753007 (* 1 = 0.753007 loss)
I0423 20:18:09.759155 30295 solver.cpp:244]     Train net output #3: loss = 0.64226 (* 1 = 0.64226 loss)
I0423 20:18:09.759160 30295 sgd_solver.cpp:106] Iteration 62700, lr = 2.7e-06
I0423 20:19:49.463364 30295 solver.cpp:228] Iteration 62800, loss = 2.88138
I0423 20:19:49.463518 30295 solver.cpp:244]     Train net output #0: loss = 0.980177 (* 1 = 0.980177 loss)
I0423 20:19:49.463526 30295 solver.cpp:244]     Train net output #1: loss = 0.520436 (* 1 = 0.520436 loss)
I0423 20:19:49.463531 30295 solver.cpp:244]     Train net output #2: loss = 0.759216 (* 1 = 0.759216 loss)
I0423 20:19:49.463536 30295 solver.cpp:244]     Train net output #3: loss = 0.621553 (* 1 = 0.621553 loss)
I0423 20:19:49.463541 30295 sgd_solver.cpp:106] Iteration 62800, lr = 2.7e-06
I0423 20:21:30.731535 30295 solver.cpp:228] Iteration 62900, loss = 3.22364
I0423 20:21:30.731708 30295 solver.cpp:244]     Train net output #0: loss = 0.966247 (* 1 = 0.966247 loss)
I0423 20:21:30.731715 30295 solver.cpp:244]     Train net output #1: loss = 0.724855 (* 1 = 0.724855 loss)
I0423 20:21:30.731720 30295 solver.cpp:244]     Train net output #2: loss = 0.906031 (* 1 = 0.906031 loss)
I0423 20:21:30.731724 30295 solver.cpp:244]     Train net output #3: loss = 0.626505 (* 1 = 0.626505 loss)
I0423 20:21:30.731729 30295 sgd_solver.cpp:106] Iteration 62900, lr = 2.7e-06
I0423 20:23:11.296643 30295 solver.cpp:337] Iteration 63000, Testing net (#0)
I0423 20:23:11.296777 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 20:23:11.296782 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 20:23:11.296784 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 20:23:11.296800 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 20:23:11.296803 30295 net.cpp:693] Ignoring source layer visualize
I0423 20:23:11.296805 30295 net.cpp:693] Ignoring source layer fake
I0423 20:26:49.703436 30295 solver.cpp:404]     Test net output #0: loss = 0.969965 (* 1 = 0.969965 loss)
I0423 20:26:49.703567 30295 solver.cpp:404]     Test net output #1: loss = 0.483183 (* 1 = 0.483183 loss)
I0423 20:26:49.703573 30295 solver.cpp:404]     Test net output #2: loss = 0.815438 (* 1 = 0.815438 loss)
I0423 20:26:49.703578 30295 solver.cpp:404]     Test net output #3: loss = 0.556543 (* 1 = 0.556543 loss)
I0423 20:26:50.370115 30295 solver.cpp:228] Iteration 63000, loss = 3.40322
I0423 20:26:50.370156 30295 solver.cpp:244]     Train net output #0: loss = 0.979675 (* 1 = 0.979675 loss)
I0423 20:26:50.370162 30295 solver.cpp:244]     Train net output #1: loss = 0.777216 (* 1 = 0.777216 loss)
I0423 20:26:50.370165 30295 solver.cpp:244]     Train net output #2: loss = 0.932413 (* 1 = 0.932413 loss)
I0423 20:26:50.370168 30295 solver.cpp:244]     Train net output #3: loss = 0.713916 (* 1 = 0.713916 loss)
I0423 20:26:50.370173 30295 sgd_solver.cpp:106] Iteration 63000, lr = 2.7e-06
I0423 20:28:32.124446 30295 solver.cpp:228] Iteration 63100, loss = 3.25684
I0423 20:28:32.126477 30295 solver.cpp:244]     Train net output #0: loss = 0.976188 (* 1 = 0.976188 loss)
I0423 20:28:32.126493 30295 solver.cpp:244]     Train net output #1: loss = 0.757852 (* 1 = 0.757852 loss)
I0423 20:28:32.126505 30295 solver.cpp:244]     Train net output #2: loss = 0.888008 (* 1 = 0.888008 loss)
I0423 20:28:32.126513 30295 solver.cpp:244]     Train net output #3: loss = 0.634796 (* 1 = 0.634796 loss)
I0423 20:28:32.126528 30295 sgd_solver.cpp:106] Iteration 63100, lr = 2.7e-06
I0423 20:30:12.092417 30295 solver.cpp:228] Iteration 63200, loss = 3.08117
I0423 20:30:12.092576 30295 solver.cpp:244]     Train net output #0: loss = 0.965724 (* 1 = 0.965724 loss)
I0423 20:30:12.092584 30295 solver.cpp:244]     Train net output #1: loss = 0.610522 (* 1 = 0.610522 loss)
I0423 20:30:12.092588 30295 solver.cpp:244]     Train net output #2: loss = 0.880681 (* 1 = 0.880681 loss)
I0423 20:30:12.092592 30295 solver.cpp:244]     Train net output #3: loss = 0.624241 (* 1 = 0.624241 loss)
I0423 20:30:12.092598 30295 sgd_solver.cpp:106] Iteration 63200, lr = 2.7e-06
I0423 20:31:53.512370 30295 solver.cpp:228] Iteration 63300, loss = 3.05566
I0423 20:31:53.512549 30295 solver.cpp:244]     Train net output #0: loss = 0.987783 (* 1 = 0.987783 loss)
I0423 20:31:53.512557 30295 solver.cpp:244]     Train net output #1: loss = 0.581668 (* 1 = 0.581668 loss)
I0423 20:31:53.512562 30295 solver.cpp:244]     Train net output #2: loss = 0.933283 (* 1 = 0.933283 loss)
I0423 20:31:53.512567 30295 solver.cpp:244]     Train net output #3: loss = 0.552927 (* 1 = 0.552927 loss)
I0423 20:31:53.512573 30295 sgd_solver.cpp:106] Iteration 63300, lr = 2.7e-06
I0423 20:33:35.151882 30295 solver.cpp:228] Iteration 63400, loss = 3.35444
I0423 20:33:35.152032 30295 solver.cpp:244]     Train net output #0: loss = 0.989845 (* 1 = 0.989845 loss)
I0423 20:33:35.152040 30295 solver.cpp:244]     Train net output #1: loss = 0.699701 (* 1 = 0.699701 loss)
I0423 20:33:35.152045 30295 solver.cpp:244]     Train net output #2: loss = 0.954082 (* 1 = 0.954082 loss)
I0423 20:33:35.152050 30295 solver.cpp:244]     Train net output #3: loss = 0.710815 (* 1 = 0.710815 loss)
I0423 20:33:35.152055 30295 sgd_solver.cpp:106] Iteration 63400, lr = 2.7e-06
I0423 20:35:16.744822 30295 solver.cpp:228] Iteration 63500, loss = 2.8255
I0423 20:35:16.744976 30295 solver.cpp:244]     Train net output #0: loss = 0.989824 (* 1 = 0.989824 loss)
I0423 20:35:16.744983 30295 solver.cpp:244]     Train net output #1: loss = 0.513595 (* 1 = 0.513595 loss)
I0423 20:35:16.744988 30295 solver.cpp:244]     Train net output #2: loss = 0.669266 (* 1 = 0.669266 loss)
I0423 20:35:16.744993 30295 solver.cpp:244]     Train net output #3: loss = 0.652816 (* 1 = 0.652816 loss)
I0423 20:35:16.744998 30295 sgd_solver.cpp:106] Iteration 63500, lr = 2.7e-06
I0423 20:36:56.248066 30295 solver.cpp:228] Iteration 63600, loss = 3.17081
I0423 20:36:56.248222 30295 solver.cpp:244]     Train net output #0: loss = 0.983953 (* 1 = 0.983953 loss)
I0423 20:36:56.248229 30295 solver.cpp:244]     Train net output #1: loss = 0.691056 (* 1 = 0.691056 loss)
I0423 20:36:56.248234 30295 solver.cpp:244]     Train net output #2: loss = 0.76653 (* 1 = 0.76653 loss)
I0423 20:36:56.248239 30295 solver.cpp:244]     Train net output #3: loss = 0.729267 (* 1 = 0.729267 loss)
I0423 20:36:56.248245 30295 sgd_solver.cpp:106] Iteration 63600, lr = 2.7e-06
I0423 20:38:37.678146 30295 solver.cpp:228] Iteration 63700, loss = 3.11991
I0423 20:38:37.678313 30295 solver.cpp:244]     Train net output #0: loss = 0.975114 (* 1 = 0.975114 loss)
I0423 20:38:37.678319 30295 solver.cpp:244]     Train net output #1: loss = 0.551175 (* 1 = 0.551175 loss)
I0423 20:38:37.678325 30295 solver.cpp:244]     Train net output #2: loss = 0.934247 (* 1 = 0.934247 loss)
I0423 20:38:37.678329 30295 solver.cpp:244]     Train net output #3: loss = 0.659373 (* 1 = 0.659373 loss)
I0423 20:38:37.678334 30295 sgd_solver.cpp:106] Iteration 63700, lr = 2.7e-06
I0423 20:40:18.980243 30295 solver.cpp:228] Iteration 63800, loss = 3.0303
I0423 20:40:18.980386 30295 solver.cpp:244]     Train net output #0: loss = 0.977049 (* 1 = 0.977049 loss)
I0423 20:40:18.980393 30295 solver.cpp:244]     Train net output #1: loss = 0.582981 (* 1 = 0.582981 loss)
I0423 20:40:18.980398 30295 solver.cpp:244]     Train net output #2: loss = 0.95735 (* 1 = 0.95735 loss)
I0423 20:40:18.980402 30295 solver.cpp:244]     Train net output #3: loss = 0.512922 (* 1 = 0.512922 loss)
I0423 20:40:18.980408 30295 sgd_solver.cpp:106] Iteration 63800, lr = 2.7e-06
I0423 20:42:00.254958 30295 solver.cpp:228] Iteration 63900, loss = 3.24156
I0423 20:42:00.255125 30295 solver.cpp:244]     Train net output #0: loss = 0.954206 (* 1 = 0.954206 loss)
I0423 20:42:00.255132 30295 solver.cpp:244]     Train net output #1: loss = 0.634137 (* 1 = 0.634137 loss)
I0423 20:42:00.255138 30295 solver.cpp:244]     Train net output #2: loss = 0.960818 (* 1 = 0.960818 loss)
I0423 20:42:00.255142 30295 solver.cpp:244]     Train net output #3: loss = 0.692396 (* 1 = 0.692396 loss)
I0423 20:42:00.255147 30295 sgd_solver.cpp:106] Iteration 63900, lr = 2.7e-06
I0423 20:43:40.847910 30295 solver.cpp:337] Iteration 64000, Testing net (#0)
I0423 20:43:40.848067 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 20:43:40.848071 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 20:43:40.848075 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 20:43:40.848089 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 20:43:40.848093 30295 net.cpp:693] Ignoring source layer visualize
I0423 20:43:40.848095 30295 net.cpp:693] Ignoring source layer fake
I0423 20:47:19.408020 30295 solver.cpp:404]     Test net output #0: loss = 0.974399 (* 1 = 0.974399 loss)
I0423 20:47:19.408157 30295 solver.cpp:404]     Test net output #1: loss = 0.498946 (* 1 = 0.498946 loss)
I0423 20:47:19.408164 30295 solver.cpp:404]     Test net output #2: loss = 0.798822 (* 1 = 0.798822 loss)
I0423 20:47:19.408169 30295 solver.cpp:404]     Test net output #3: loss = 0.543254 (* 1 = 0.543254 loss)
I0423 20:47:20.068593 30295 solver.cpp:228] Iteration 64000, loss = 2.64163
I0423 20:47:20.068635 30295 solver.cpp:244]     Train net output #0: loss = 0.951435 (* 1 = 0.951435 loss)
I0423 20:47:20.068640 30295 solver.cpp:244]     Train net output #1: loss = 0.513143 (* 1 = 0.513143 loss)
I0423 20:47:20.068645 30295 solver.cpp:244]     Train net output #2: loss = 0.741229 (* 1 = 0.741229 loss)
I0423 20:47:20.068648 30295 solver.cpp:244]     Train net output #3: loss = 0.435821 (* 1 = 0.435821 loss)
I0423 20:47:20.068652 30295 sgd_solver.cpp:106] Iteration 64000, lr = 2.7e-06
I0423 20:49:02.179122 30295 solver.cpp:228] Iteration 64100, loss = 3.35484
I0423 20:49:02.179280 30295 solver.cpp:244]     Train net output #0: loss = 0.985543 (* 1 = 0.985543 loss)
I0423 20:49:02.179286 30295 solver.cpp:244]     Train net output #1: loss = 0.76937 (* 1 = 0.76937 loss)
I0423 20:49:02.179291 30295 solver.cpp:244]     Train net output #2: loss = 0.8521 (* 1 = 0.8521 loss)
I0423 20:49:02.179296 30295 solver.cpp:244]     Train net output #3: loss = 0.747823 (* 1 = 0.747823 loss)
I0423 20:49:02.179301 30295 sgd_solver.cpp:106] Iteration 64100, lr = 2.7e-06
I0423 20:50:44.212283 30295 solver.cpp:228] Iteration 64200, loss = 3.13102
I0423 20:50:44.212435 30295 solver.cpp:244]     Train net output #0: loss = 0.990567 (* 1 = 0.990567 loss)
I0423 20:50:44.212443 30295 solver.cpp:244]     Train net output #1: loss = 0.780521 (* 1 = 0.780521 loss)
I0423 20:50:44.212448 30295 solver.cpp:244]     Train net output #2: loss = 0.701076 (* 1 = 0.701076 loss)
I0423 20:50:44.212452 30295 solver.cpp:244]     Train net output #3: loss = 0.658853 (* 1 = 0.658853 loss)
I0423 20:50:44.212457 30295 sgd_solver.cpp:106] Iteration 64200, lr = 2.7e-06
I0423 20:52:24.078186 30295 solver.cpp:228] Iteration 64300, loss = 3.29331
I0423 20:52:24.079452 30295 solver.cpp:244]     Train net output #0: loss = 0.979838 (* 1 = 0.979838 loss)
I0423 20:52:24.079457 30295 solver.cpp:244]     Train net output #1: loss = 0.734892 (* 1 = 0.734892 loss)
I0423 20:52:24.079462 30295 solver.cpp:244]     Train net output #2: loss = 0.889488 (* 1 = 0.889488 loss)
I0423 20:52:24.079468 30295 solver.cpp:244]     Train net output #3: loss = 0.68909 (* 1 = 0.68909 loss)
I0423 20:52:24.079473 30295 sgd_solver.cpp:106] Iteration 64300, lr = 2.7e-06
I0423 20:54:06.077569 30295 solver.cpp:228] Iteration 64400, loss = 3.43924
I0423 20:54:06.077719 30295 solver.cpp:244]     Train net output #0: loss = 0.983624 (* 1 = 0.983624 loss)
I0423 20:54:06.077728 30295 solver.cpp:244]     Train net output #1: loss = 0.788691 (* 1 = 0.788691 loss)
I0423 20:54:06.077733 30295 solver.cpp:244]     Train net output #2: loss = 0.891761 (* 1 = 0.891761 loss)
I0423 20:54:06.077738 30295 solver.cpp:244]     Train net output #3: loss = 0.775161 (* 1 = 0.775161 loss)
I0423 20:54:06.077742 30295 sgd_solver.cpp:106] Iteration 64400, lr = 2.7e-06
I0423 20:55:47.856339 30295 solver.cpp:228] Iteration 64500, loss = 2.97522
I0423 20:55:47.856539 30295 solver.cpp:244]     Train net output #0: loss = 0.986755 (* 1 = 0.986755 loss)
I0423 20:55:47.856547 30295 solver.cpp:244]     Train net output #1: loss = 0.521883 (* 1 = 0.521883 loss)
I0423 20:55:47.856552 30295 solver.cpp:244]     Train net output #2: loss = 0.925191 (* 1 = 0.925191 loss)
I0423 20:55:47.856557 30295 solver.cpp:244]     Train net output #3: loss = 0.541391 (* 1 = 0.541391 loss)
I0423 20:55:47.856562 30295 sgd_solver.cpp:106] Iteration 64500, lr = 2.7e-06
I0423 20:57:28.931493 30295 solver.cpp:228] Iteration 64600, loss = 3.18337
I0423 20:57:28.931640 30295 solver.cpp:244]     Train net output #0: loss = 0.987341 (* 1 = 0.987341 loss)
I0423 20:57:28.931648 30295 solver.cpp:244]     Train net output #1: loss = 0.607523 (* 1 = 0.607523 loss)
I0423 20:57:28.931653 30295 solver.cpp:244]     Train net output #2: loss = 0.939796 (* 1 = 0.939796 loss)
I0423 20:57:28.931658 30295 solver.cpp:244]     Train net output #3: loss = 0.648707 (* 1 = 0.648707 loss)
I0423 20:57:28.931663 30295 sgd_solver.cpp:106] Iteration 64600, lr = 2.7e-06
I0423 20:59:08.353272 30295 solver.cpp:228] Iteration 64700, loss = 3.13845
I0423 20:59:08.353413 30295 solver.cpp:244]     Train net output #0: loss = 0.98714 (* 1 = 0.98714 loss)
I0423 20:59:08.353420 30295 solver.cpp:244]     Train net output #1: loss = 0.62321 (* 1 = 0.62321 loss)
I0423 20:59:08.353425 30295 solver.cpp:244]     Train net output #2: loss = 0.896824 (* 1 = 0.896824 loss)
I0423 20:59:08.353430 30295 solver.cpp:244]     Train net output #3: loss = 0.631279 (* 1 = 0.631279 loss)
I0423 20:59:08.353444 30295 sgd_solver.cpp:106] Iteration 64700, lr = 2.7e-06
I0423 21:00:49.354414 30295 solver.cpp:228] Iteration 64800, loss = 3.26888
I0423 21:00:49.354554 30295 solver.cpp:244]     Train net output #0: loss = 0.988085 (* 1 = 0.988085 loss)
I0423 21:00:49.354562 30295 solver.cpp:244]     Train net output #1: loss = 0.692114 (* 1 = 0.692114 loss)
I0423 21:00:49.354568 30295 solver.cpp:244]     Train net output #2: loss = 0.96041 (* 1 = 0.96041 loss)
I0423 21:00:49.354571 30295 solver.cpp:244]     Train net output #3: loss = 0.62827 (* 1 = 0.62827 loss)
I0423 21:00:49.354576 30295 sgd_solver.cpp:106] Iteration 64800, lr = 2.7e-06
I0423 21:02:30.310606 30295 solver.cpp:228] Iteration 64900, loss = 3.26727
I0423 21:02:30.310761 30295 solver.cpp:244]     Train net output #0: loss = 0.991255 (* 1 = 0.991255 loss)
I0423 21:02:30.310770 30295 solver.cpp:244]     Train net output #1: loss = 0.641453 (* 1 = 0.641453 loss)
I0423 21:02:30.310773 30295 solver.cpp:244]     Train net output #2: loss = 0.942692 (* 1 = 0.942692 loss)
I0423 21:02:30.310780 30295 solver.cpp:244]     Train net output #3: loss = 0.691871 (* 1 = 0.691871 loss)
I0423 21:02:30.310784 30295 sgd_solver.cpp:106] Iteration 64900, lr = 2.7e-06
I0423 21:04:10.017611 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_65000.caffemodel
I0423 21:04:24.544793 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_65000.solverstate
I0423 21:04:24.748631 30295 solver.cpp:337] Iteration 65000, Testing net (#0)
I0423 21:04:24.748674 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 21:04:24.748677 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 21:04:24.748679 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 21:04:24.748694 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 21:04:24.748697 30295 net.cpp:693] Ignoring source layer visualize
I0423 21:04:24.748698 30295 net.cpp:693] Ignoring source layer fake
I0423 21:08:01.336765 30295 solver.cpp:404]     Test net output #0: loss = 0.966081 (* 1 = 0.966081 loss)
I0423 21:08:01.336930 30295 solver.cpp:404]     Test net output #1: loss = 0.49143 (* 1 = 0.49143 loss)
I0423 21:08:01.336936 30295 solver.cpp:404]     Test net output #2: loss = 0.815748 (* 1 = 0.815748 loss)
I0423 21:08:01.336941 30295 solver.cpp:404]     Test net output #3: loss = 0.564836 (* 1 = 0.564836 loss)
I0423 21:08:01.994266 30295 solver.cpp:228] Iteration 65000, loss = 3.11048
I0423 21:08:01.994309 30295 solver.cpp:244]     Train net output #0: loss = 0.972885 (* 1 = 0.972885 loss)
I0423 21:08:01.994314 30295 solver.cpp:244]     Train net output #1: loss = 0.644231 (* 1 = 0.644231 loss)
I0423 21:08:01.994318 30295 solver.cpp:244]     Train net output #2: loss = 0.940331 (* 1 = 0.940331 loss)
I0423 21:08:01.994323 30295 solver.cpp:244]     Train net output #3: loss = 0.553036 (* 1 = 0.553036 loss)
I0423 21:08:01.994328 30295 sgd_solver.cpp:106] Iteration 65000, lr = 2.7e-06
I0423 21:09:43.294066 30295 solver.cpp:228] Iteration 65100, loss = 3.08585
I0423 21:09:43.294211 30295 solver.cpp:244]     Train net output #0: loss = 0.979541 (* 1 = 0.979541 loss)
I0423 21:09:43.294219 30295 solver.cpp:244]     Train net output #1: loss = 0.722547 (* 1 = 0.722547 loss)
I0423 21:09:43.294224 30295 solver.cpp:244]     Train net output #2: loss = 0.763389 (* 1 = 0.763389 loss)
I0423 21:09:43.294229 30295 solver.cpp:244]     Train net output #3: loss = 0.620369 (* 1 = 0.620369 loss)
I0423 21:09:43.294234 30295 sgd_solver.cpp:106] Iteration 65100, lr = 2.7e-06
I0423 21:11:24.767464 30295 solver.cpp:228] Iteration 65200, loss = 2.83461
I0423 21:11:24.767609 30295 solver.cpp:244]     Train net output #0: loss = 0.988798 (* 1 = 0.988798 loss)
I0423 21:11:24.767616 30295 solver.cpp:244]     Train net output #1: loss = 0.630661 (* 1 = 0.630661 loss)
I0423 21:11:24.767621 30295 solver.cpp:244]     Train net output #2: loss = 0.573568 (* 1 = 0.573568 loss)
I0423 21:11:24.767626 30295 solver.cpp:244]     Train net output #3: loss = 0.641581 (* 1 = 0.641581 loss)
I0423 21:11:24.767632 30295 sgd_solver.cpp:106] Iteration 65200, lr = 2.7e-06
I0423 21:13:04.449265 30295 solver.cpp:228] Iteration 65300, loss = 2.57029
I0423 21:13:04.449410 30295 solver.cpp:244]     Train net output #0: loss = 0.986879 (* 1 = 0.986879 loss)
I0423 21:13:04.449419 30295 solver.cpp:244]     Train net output #1: loss = 0.427972 (* 1 = 0.427972 loss)
I0423 21:13:04.449424 30295 solver.cpp:244]     Train net output #2: loss = 0.556114 (* 1 = 0.556114 loss)
I0423 21:13:04.449427 30295 solver.cpp:244]     Train net output #3: loss = 0.599328 (* 1 = 0.599328 loss)
I0423 21:13:04.449431 30295 sgd_solver.cpp:106] Iteration 65300, lr = 2.7e-06
I0423 21:14:45.629276 30295 solver.cpp:228] Iteration 65400, loss = 3.24379
I0423 21:14:45.629425 30295 solver.cpp:244]     Train net output #0: loss = 0.979605 (* 1 = 0.979605 loss)
I0423 21:14:45.629431 30295 solver.cpp:244]     Train net output #1: loss = 0.756084 (* 1 = 0.756084 loss)
I0423 21:14:45.629444 30295 solver.cpp:244]     Train net output #2: loss = 0.827808 (* 1 = 0.827808 loss)
I0423 21:14:45.629449 30295 solver.cpp:244]     Train net output #3: loss = 0.680293 (* 1 = 0.680293 loss)
I0423 21:14:45.629454 30295 sgd_solver.cpp:106] Iteration 65400, lr = 2.7e-06
I0423 21:16:26.959631 30295 solver.cpp:228] Iteration 65500, loss = 3.28641
I0423 21:16:26.959784 30295 solver.cpp:244]     Train net output #0: loss = 0.982933 (* 1 = 0.982933 loss)
I0423 21:16:26.959791 30295 solver.cpp:244]     Train net output #1: loss = 0.835207 (* 1 = 0.835207 loss)
I0423 21:16:26.959796 30295 solver.cpp:244]     Train net output #2: loss = 0.820453 (* 1 = 0.820453 loss)
I0423 21:16:26.959800 30295 solver.cpp:244]     Train net output #3: loss = 0.64782 (* 1 = 0.64782 loss)
I0423 21:16:26.959805 30295 sgd_solver.cpp:106] Iteration 65500, lr = 2.7e-06
I0423 21:18:09.552613 30295 solver.cpp:228] Iteration 65600, loss = 3.29518
I0423 21:18:09.552779 30295 solver.cpp:244]     Train net output #0: loss = 0.983319 (* 1 = 0.983319 loss)
I0423 21:18:09.552786 30295 solver.cpp:244]     Train net output #1: loss = 0.793183 (* 1 = 0.793183 loss)
I0423 21:18:09.552791 30295 solver.cpp:244]     Train net output #2: loss = 0.855889 (* 1 = 0.855889 loss)
I0423 21:18:09.552795 30295 solver.cpp:244]     Train net output #3: loss = 0.662793 (* 1 = 0.662793 loss)
I0423 21:18:09.552801 30295 sgd_solver.cpp:106] Iteration 65600, lr = 2.7e-06
I0423 21:19:49.393160 30295 solver.cpp:228] Iteration 65700, loss = 3.34728
I0423 21:19:49.393347 30295 solver.cpp:244]     Train net output #0: loss = 0.981639 (* 1 = 0.981639 loss)
I0423 21:19:49.393353 30295 solver.cpp:244]     Train net output #1: loss = 0.675475 (* 1 = 0.675475 loss)
I0423 21:19:49.393358 30295 solver.cpp:244]     Train net output #2: loss = 0.925193 (* 1 = 0.925193 loss)
I0423 21:19:49.393362 30295 solver.cpp:244]     Train net output #3: loss = 0.764972 (* 1 = 0.764972 loss)
I0423 21:19:49.393368 30295 sgd_solver.cpp:106] Iteration 65700, lr = 2.7e-06
I0423 21:21:31.238337 30295 solver.cpp:228] Iteration 65800, loss = 3.18961
I0423 21:21:31.238503 30295 solver.cpp:244]     Train net output #0: loss = 0.988977 (* 1 = 0.988977 loss)
I0423 21:21:31.238512 30295 solver.cpp:244]     Train net output #1: loss = 0.718416 (* 1 = 0.718416 loss)
I0423 21:21:31.238515 30295 solver.cpp:244]     Train net output #2: loss = 0.889643 (* 1 = 0.889643 loss)
I0423 21:21:31.238520 30295 solver.cpp:244]     Train net output #3: loss = 0.592574 (* 1 = 0.592574 loss)
I0423 21:21:31.238526 30295 sgd_solver.cpp:106] Iteration 65800, lr = 2.7e-06
I0423 21:23:12.511147 30295 solver.cpp:228] Iteration 65900, loss = 3.22557
I0423 21:23:12.511320 30295 solver.cpp:244]     Train net output #0: loss = 0.984032 (* 1 = 0.984032 loss)
I0423 21:23:12.511327 30295 solver.cpp:244]     Train net output #1: loss = 0.70864 (* 1 = 0.70864 loss)
I0423 21:23:12.511333 30295 solver.cpp:244]     Train net output #2: loss = 0.952589 (* 1 = 0.952589 loss)
I0423 21:23:12.511337 30295 solver.cpp:244]     Train net output #3: loss = 0.580313 (* 1 = 0.580313 loss)
I0423 21:23:12.511343 30295 sgd_solver.cpp:106] Iteration 65900, lr = 2.7e-06
I0423 21:24:52.738127 30295 solver.cpp:337] Iteration 66000, Testing net (#0)
I0423 21:24:52.738291 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 21:24:52.738294 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 21:24:52.738298 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 21:24:52.738312 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 21:24:52.738317 30295 net.cpp:693] Ignoring source layer visualize
I0423 21:24:52.738317 30295 net.cpp:693] Ignoring source layer fake
I0423 21:28:31.315975 30295 solver.cpp:404]     Test net output #0: loss = 0.972761 (* 1 = 0.972761 loss)
I0423 21:28:31.316107 30295 solver.cpp:404]     Test net output #1: loss = 0.549547 (* 1 = 0.549547 loss)
I0423 21:28:31.316115 30295 solver.cpp:404]     Test net output #2: loss = 0.82534 (* 1 = 0.82534 loss)
I0423 21:28:31.316120 30295 solver.cpp:404]     Test net output #3: loss = 0.593083 (* 1 = 0.593083 loss)
I0423 21:28:32.022523 30295 solver.cpp:228] Iteration 66000, loss = 2.97578
I0423 21:28:32.022567 30295 solver.cpp:244]     Train net output #0: loss = 0.989412 (* 1 = 0.989412 loss)
I0423 21:28:32.022572 30295 solver.cpp:244]     Train net output #1: loss = 0.594541 (* 1 = 0.594541 loss)
I0423 21:28:32.022577 30295 solver.cpp:244]     Train net output #2: loss = 0.828442 (* 1 = 0.828442 loss)
I0423 21:28:32.022580 30295 solver.cpp:244]     Train net output #3: loss = 0.563384 (* 1 = 0.563384 loss)
I0423 21:28:32.022586 30295 sgd_solver.cpp:106] Iteration 66000, lr = 2.7e-06
I0423 21:30:11.956755 30295 solver.cpp:228] Iteration 66100, loss = 3.0641
I0423 21:30:11.956905 30295 solver.cpp:244]     Train net output #0: loss = 0.985019 (* 1 = 0.985019 loss)
I0423 21:30:11.956912 30295 solver.cpp:244]     Train net output #1: loss = 0.597179 (* 1 = 0.597179 loss)
I0423 21:30:11.956918 30295 solver.cpp:244]     Train net output #2: loss = 0.894471 (* 1 = 0.894471 loss)
I0423 21:30:11.956923 30295 solver.cpp:244]     Train net output #3: loss = 0.587434 (* 1 = 0.587434 loss)
I0423 21:30:11.956926 30295 sgd_solver.cpp:106] Iteration 66100, lr = 2.7e-06
I0423 21:31:53.052278 30295 solver.cpp:228] Iteration 66200, loss = 2.8665
I0423 21:31:53.052460 30295 solver.cpp:244]     Train net output #0: loss = 0.982385 (* 1 = 0.982385 loss)
I0423 21:31:53.052469 30295 solver.cpp:244]     Train net output #1: loss = 0.542393 (* 1 = 0.542393 loss)
I0423 21:31:53.052474 30295 solver.cpp:244]     Train net output #2: loss = 0.746546 (* 1 = 0.746546 loss)
I0423 21:31:53.052479 30295 solver.cpp:244]     Train net output #3: loss = 0.595173 (* 1 = 0.595173 loss)
I0423 21:31:53.052484 30295 sgd_solver.cpp:106] Iteration 66200, lr = 2.7e-06
I0423 21:33:33.894153 30295 solver.cpp:228] Iteration 66300, loss = 3.02149
I0423 21:33:33.894301 30295 solver.cpp:244]     Train net output #0: loss = 0.983264 (* 1 = 0.983264 loss)
I0423 21:33:33.894309 30295 solver.cpp:244]     Train net output #1: loss = 0.619143 (* 1 = 0.619143 loss)
I0423 21:33:33.894314 30295 solver.cpp:244]     Train net output #2: loss = 0.956008 (* 1 = 0.956008 loss)
I0423 21:33:33.894320 30295 solver.cpp:244]     Train net output #3: loss = 0.463071 (* 1 = 0.463071 loss)
I0423 21:33:33.894325 30295 sgd_solver.cpp:106] Iteration 66300, lr = 2.7e-06
I0423 21:35:14.845270 30295 solver.cpp:228] Iteration 66400, loss = 2.7734
I0423 21:35:14.845427 30295 solver.cpp:244]     Train net output #0: loss = 0.969762 (* 1 = 0.969762 loss)
I0423 21:35:14.845446 30295 solver.cpp:244]     Train net output #1: loss = 0.500063 (* 1 = 0.500063 loss)
I0423 21:35:14.845451 30295 solver.cpp:244]     Train net output #2: loss = 0.762109 (* 1 = 0.762109 loss)
I0423 21:35:14.845456 30295 solver.cpp:244]     Train net output #3: loss = 0.541464 (* 1 = 0.541464 loss)
I0423 21:35:14.845461 30295 sgd_solver.cpp:106] Iteration 66400, lr = 2.7e-06
I0423 21:36:56.363692 30295 solver.cpp:228] Iteration 66500, loss = 2.81863
I0423 21:36:56.363867 30295 solver.cpp:244]     Train net output #0: loss = 0.945595 (* 1 = 0.945595 loss)
I0423 21:36:56.363874 30295 solver.cpp:244]     Train net output #1: loss = 0.548514 (* 1 = 0.548514 loss)
I0423 21:36:56.363879 30295 solver.cpp:244]     Train net output #2: loss = 0.76809 (* 1 = 0.76809 loss)
I0423 21:36:56.363885 30295 solver.cpp:244]     Train net output #3: loss = 0.556427 (* 1 = 0.556427 loss)
I0423 21:36:56.363890 30295 sgd_solver.cpp:106] Iteration 66500, lr = 2.7e-06
I0423 21:38:37.507159 30295 solver.cpp:228] Iteration 66600, loss = 3.24773
I0423 21:38:37.507319 30295 solver.cpp:244]     Train net output #0: loss = 0.962236 (* 1 = 0.962236 loss)
I0423 21:38:37.507328 30295 solver.cpp:244]     Train net output #1: loss = 0.70329 (* 1 = 0.70329 loss)
I0423 21:38:37.507333 30295 solver.cpp:244]     Train net output #2: loss = 0.907004 (* 1 = 0.907004 loss)
I0423 21:38:37.507338 30295 solver.cpp:244]     Train net output #3: loss = 0.675202 (* 1 = 0.675202 loss)
I0423 21:38:37.507342 30295 sgd_solver.cpp:106] Iteration 66600, lr = 2.7e-06
I0423 21:40:18.877527 30295 solver.cpp:228] Iteration 66700, loss = 3.03742
I0423 21:40:18.877691 30295 solver.cpp:244]     Train net output #0: loss = 0.980767 (* 1 = 0.980767 loss)
I0423 21:40:18.877697 30295 solver.cpp:244]     Train net output #1: loss = 0.691154 (* 1 = 0.691154 loss)
I0423 21:40:18.877702 30295 solver.cpp:244]     Train net output #2: loss = 0.719382 (* 1 = 0.719382 loss)
I0423 21:40:18.877707 30295 solver.cpp:244]     Train net output #3: loss = 0.646113 (* 1 = 0.646113 loss)
I0423 21:40:18.877713 30295 sgd_solver.cpp:106] Iteration 66700, lr = 2.7e-06
I0423 21:41:58.590590 30295 solver.cpp:228] Iteration 66800, loss = 3.19288
I0423 21:41:58.590740 30295 solver.cpp:244]     Train net output #0: loss = 0.975043 (* 1 = 0.975043 loss)
I0423 21:41:58.590749 30295 solver.cpp:244]     Train net output #1: loss = 0.655439 (* 1 = 0.655439 loss)
I0423 21:41:58.590752 30295 solver.cpp:244]     Train net output #2: loss = 0.886987 (* 1 = 0.886987 loss)
I0423 21:41:58.590757 30295 solver.cpp:244]     Train net output #3: loss = 0.67541 (* 1 = 0.67541 loss)
I0423 21:41:58.590761 30295 sgd_solver.cpp:106] Iteration 66800, lr = 2.7e-06
I0423 21:43:40.048717 30295 solver.cpp:228] Iteration 66900, loss = 3.20092
I0423 21:43:40.048893 30295 solver.cpp:244]     Train net output #0: loss = 0.970485 (* 1 = 0.970485 loss)
I0423 21:43:40.048900 30295 solver.cpp:244]     Train net output #1: loss = 0.646986 (* 1 = 0.646986 loss)
I0423 21:43:40.048905 30295 solver.cpp:244]     Train net output #2: loss = 0.932888 (* 1 = 0.932888 loss)
I0423 21:43:40.048910 30295 solver.cpp:244]     Train net output #3: loss = 0.650561 (* 1 = 0.650561 loss)
I0423 21:43:40.048918 30295 sgd_solver.cpp:106] Iteration 66900, lr = 2.7e-06
I0423 21:45:20.452494 30295 solver.cpp:337] Iteration 67000, Testing net (#0)
I0423 21:45:20.452647 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 21:45:20.452652 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 21:45:20.452656 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 21:45:20.452669 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 21:45:20.452672 30295 net.cpp:693] Ignoring source layer visualize
I0423 21:45:20.452674 30295 net.cpp:693] Ignoring source layer fake
I0423 21:48:58.651621 30295 solver.cpp:404]     Test net output #0: loss = 0.974114 (* 1 = 0.974114 loss)
I0423 21:48:58.651743 30295 solver.cpp:404]     Test net output #1: loss = 0.505276 (* 1 = 0.505276 loss)
I0423 21:48:58.651751 30295 solver.cpp:404]     Test net output #2: loss = 0.786691 (* 1 = 0.786691 loss)
I0423 21:48:58.651756 30295 solver.cpp:404]     Test net output #3: loss = 0.514213 (* 1 = 0.514213 loss)
I0423 21:48:59.308778 30295 solver.cpp:228] Iteration 67000, loss = 3.1271
I0423 21:48:59.308820 30295 solver.cpp:244]     Train net output #0: loss = 0.987411 (* 1 = 0.987411 loss)
I0423 21:48:59.308825 30295 solver.cpp:244]     Train net output #1: loss = 0.597341 (* 1 = 0.597341 loss)
I0423 21:48:59.308830 30295 solver.cpp:244]     Train net output #2: loss = 0.921683 (* 1 = 0.921683 loss)
I0423 21:48:59.308833 30295 solver.cpp:244]     Train net output #3: loss = 0.620667 (* 1 = 0.620667 loss)
I0423 21:48:59.308837 30295 sgd_solver.cpp:106] Iteration 67000, lr = 2.7e-06
I0423 21:50:40.714731 30295 solver.cpp:228] Iteration 67100, loss = 3.16173
I0423 21:50:40.714884 30295 solver.cpp:244]     Train net output #0: loss = 0.988777 (* 1 = 0.988777 loss)
I0423 21:50:40.714892 30295 solver.cpp:244]     Train net output #1: loss = 0.612103 (* 1 = 0.612103 loss)
I0423 21:50:40.714896 30295 solver.cpp:244]     Train net output #2: loss = 0.929887 (* 1 = 0.929887 loss)
I0423 21:50:40.714901 30295 solver.cpp:244]     Train net output #3: loss = 0.630964 (* 1 = 0.630964 loss)
I0423 21:50:40.714907 30295 sgd_solver.cpp:106] Iteration 67100, lr = 2.7e-06
I0423 21:52:20.182415 30295 solver.cpp:228] Iteration 67200, loss = 3.21368
I0423 21:52:20.182561 30295 solver.cpp:244]     Train net output #0: loss = 0.985606 (* 1 = 0.985606 loss)
I0423 21:52:20.182569 30295 solver.cpp:244]     Train net output #1: loss = 0.667596 (* 1 = 0.667596 loss)
I0423 21:52:20.182574 30295 solver.cpp:244]     Train net output #2: loss = 0.907996 (* 1 = 0.907996 loss)
I0423 21:52:20.182577 30295 solver.cpp:244]     Train net output #3: loss = 0.652478 (* 1 = 0.652478 loss)
I0423 21:52:20.182582 30295 sgd_solver.cpp:106] Iteration 67200, lr = 2.7e-06
I0423 21:54:01.401638 30295 solver.cpp:228] Iteration 67300, loss = 3.0461
I0423 21:54:01.401788 30295 solver.cpp:244]     Train net output #0: loss = 0.984185 (* 1 = 0.984185 loss)
I0423 21:54:01.401798 30295 solver.cpp:244]     Train net output #1: loss = 0.603586 (* 1 = 0.603586 loss)
I0423 21:54:01.401803 30295 solver.cpp:244]     Train net output #2: loss = 0.924104 (* 1 = 0.924104 loss)
I0423 21:54:01.401806 30295 solver.cpp:244]     Train net output #3: loss = 0.534224 (* 1 = 0.534224 loss)
I0423 21:54:01.401811 30295 sgd_solver.cpp:106] Iteration 67300, lr = 2.7e-06
I0423 21:55:42.358438 30295 solver.cpp:228] Iteration 67400, loss = 2.93083
I0423 21:55:42.358628 30295 solver.cpp:244]     Train net output #0: loss = 0.988732 (* 1 = 0.988732 loss)
I0423 21:55:42.358636 30295 solver.cpp:244]     Train net output #1: loss = 0.60864 (* 1 = 0.60864 loss)
I0423 21:55:42.358640 30295 solver.cpp:244]     Train net output #2: loss = 0.776719 (* 1 = 0.776719 loss)
I0423 21:55:42.358654 30295 solver.cpp:244]     Train net output #3: loss = 0.556742 (* 1 = 0.556742 loss)
I0423 21:55:42.358659 30295 sgd_solver.cpp:106] Iteration 67400, lr = 2.7e-06
I0423 21:57:22.980597 30295 solver.cpp:228] Iteration 67500, loss = 2.96991
I0423 21:57:22.980739 30295 solver.cpp:244]     Train net output #0: loss = 0.968013 (* 1 = 0.968013 loss)
I0423 21:57:22.980748 30295 solver.cpp:244]     Train net output #1: loss = 0.579267 (* 1 = 0.579267 loss)
I0423 21:57:22.980762 30295 solver.cpp:244]     Train net output #2: loss = 0.951696 (* 1 = 0.951696 loss)
I0423 21:57:22.980765 30295 solver.cpp:244]     Train net output #3: loss = 0.470934 (* 1 = 0.470934 loss)
I0423 21:57:22.980770 30295 sgd_solver.cpp:106] Iteration 67500, lr = 2.7e-06
I0423 21:59:03.728453 30295 solver.cpp:228] Iteration 67600, loss = 2.80593
I0423 21:59:03.728605 30295 solver.cpp:244]     Train net output #0: loss = 0.963403 (* 1 = 0.963403 loss)
I0423 21:59:03.728611 30295 solver.cpp:244]     Train net output #1: loss = 0.520463 (* 1 = 0.520463 loss)
I0423 21:59:03.728616 30295 solver.cpp:244]     Train net output #2: loss = 0.773272 (* 1 = 0.773272 loss)
I0423 21:59:03.728621 30295 solver.cpp:244]     Train net output #3: loss = 0.548793 (* 1 = 0.548793 loss)
I0423 21:59:03.728626 30295 sgd_solver.cpp:106] Iteration 67600, lr = 2.7e-06
I0423 22:00:44.750679 30295 solver.cpp:228] Iteration 67700, loss = 3.26819
I0423 22:00:44.750831 30295 solver.cpp:244]     Train net output #0: loss = 0.981587 (* 1 = 0.981587 loss)
I0423 22:00:44.750839 30295 solver.cpp:244]     Train net output #1: loss = 0.687462 (* 1 = 0.687462 loss)
I0423 22:00:44.750844 30295 solver.cpp:244]     Train net output #2: loss = 0.931636 (* 1 = 0.931636 loss)
I0423 22:00:44.750849 30295 solver.cpp:244]     Train net output #3: loss = 0.667501 (* 1 = 0.667501 loss)
I0423 22:00:44.750854 30295 sgd_solver.cpp:106] Iteration 67700, lr = 2.7e-06
I0423 22:02:24.427299 30295 solver.cpp:228] Iteration 67800, loss = 3.00368
I0423 22:02:24.427443 30295 solver.cpp:244]     Train net output #0: loss = 0.982845 (* 1 = 0.982845 loss)
I0423 22:02:24.427449 30295 solver.cpp:244]     Train net output #1: loss = 0.593722 (* 1 = 0.593722 loss)
I0423 22:02:24.427454 30295 solver.cpp:244]     Train net output #2: loss = 0.751817 (* 1 = 0.751817 loss)
I0423 22:02:24.427459 30295 solver.cpp:244]     Train net output #3: loss = 0.6753 (* 1 = 0.6753 loss)
I0423 22:02:24.427464 30295 sgd_solver.cpp:106] Iteration 67800, lr = 2.7e-06
I0423 22:04:05.842025 30295 solver.cpp:228] Iteration 67900, loss = 3.34917
I0423 22:04:05.842167 30295 solver.cpp:244]     Train net output #0: loss = 0.981111 (* 1 = 0.981111 loss)
I0423 22:04:05.842175 30295 solver.cpp:244]     Train net output #1: loss = 0.741576 (* 1 = 0.741576 loss)
I0423 22:04:05.842180 30295 solver.cpp:244]     Train net output #2: loss = 0.90404 (* 1 = 0.90404 loss)
I0423 22:04:05.842185 30295 solver.cpp:244]     Train net output #3: loss = 0.722444 (* 1 = 0.722444 loss)
I0423 22:04:05.842190 30295 sgd_solver.cpp:106] Iteration 67900, lr = 2.7e-06
I0423 22:05:46.168041 30295 solver.cpp:337] Iteration 68000, Testing net (#0)
I0423 22:05:46.168182 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 22:05:46.168186 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 22:05:46.168190 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 22:05:46.168205 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 22:05:46.168208 30295 net.cpp:693] Ignoring source layer visualize
I0423 22:05:46.168210 30295 net.cpp:693] Ignoring source layer fake
I0423 22:09:24.017387 30295 solver.cpp:404]     Test net output #0: loss = 0.969779 (* 1 = 0.969779 loss)
I0423 22:09:24.017591 30295 solver.cpp:404]     Test net output #1: loss = 0.484822 (* 1 = 0.484822 loss)
I0423 22:09:24.017598 30295 solver.cpp:404]     Test net output #2: loss = 0.816435 (* 1 = 0.816435 loss)
I0423 22:09:24.017603 30295 solver.cpp:404]     Test net output #3: loss = 0.557052 (* 1 = 0.557052 loss)
I0423 22:09:24.690953 30295 solver.cpp:228] Iteration 68000, loss = 3.29927
I0423 22:09:24.690994 30295 solver.cpp:244]     Train net output #0: loss = 0.989498 (* 1 = 0.989498 loss)
I0423 22:09:24.691000 30295 solver.cpp:244]     Train net output #1: loss = 0.818444 (* 1 = 0.818444 loss)
I0423 22:09:24.691004 30295 solver.cpp:244]     Train net output #2: loss = 0.819337 (* 1 = 0.819337 loss)
I0423 22:09:24.691007 30295 solver.cpp:244]     Train net output #3: loss = 0.67199 (* 1 = 0.67199 loss)
I0423 22:09:24.691012 30295 sgd_solver.cpp:106] Iteration 68000, lr = 2.7e-06
I0423 22:11:07.204133 30295 solver.cpp:228] Iteration 68100, loss = 3.12717
I0423 22:11:07.204291 30295 solver.cpp:244]     Train net output #0: loss = 0.983027 (* 1 = 0.983027 loss)
I0423 22:11:07.204298 30295 solver.cpp:244]     Train net output #1: loss = 0.667598 (* 1 = 0.667598 loss)
I0423 22:11:07.204304 30295 solver.cpp:244]     Train net output #2: loss = 0.864341 (* 1 = 0.864341 loss)
I0423 22:11:07.204308 30295 solver.cpp:244]     Train net output #3: loss = 0.612209 (* 1 = 0.612209 loss)
I0423 22:11:07.204313 30295 sgd_solver.cpp:106] Iteration 68100, lr = 2.7e-06
I0423 22:12:47.015308 30295 solver.cpp:228] Iteration 68200, loss = 3.2146
I0423 22:12:47.015452 30295 solver.cpp:244]     Train net output #0: loss = 0.97274 (* 1 = 0.97274 loss)
I0423 22:12:47.015460 30295 solver.cpp:244]     Train net output #1: loss = 0.598149 (* 1 = 0.598149 loss)
I0423 22:12:47.015465 30295 solver.cpp:244]     Train net output #2: loss = 0.935988 (* 1 = 0.935988 loss)
I0423 22:12:47.015468 30295 solver.cpp:244]     Train net output #3: loss = 0.707723 (* 1 = 0.707723 loss)
I0423 22:12:47.015475 30295 sgd_solver.cpp:106] Iteration 68200, lr = 2.7e-06
I0423 22:14:29.876271 30295 solver.cpp:228] Iteration 68300, loss = 2.94751
I0423 22:14:29.876425 30295 solver.cpp:244]     Train net output #0: loss = 0.984969 (* 1 = 0.984969 loss)
I0423 22:14:29.876433 30295 solver.cpp:244]     Train net output #1: loss = 0.568463 (* 1 = 0.568463 loss)
I0423 22:14:29.876438 30295 solver.cpp:244]     Train net output #2: loss = 0.876279 (* 1 = 0.876279 loss)
I0423 22:14:29.876442 30295 solver.cpp:244]     Train net output #3: loss = 0.517801 (* 1 = 0.517801 loss)
I0423 22:14:29.876447 30295 sgd_solver.cpp:106] Iteration 68300, lr = 2.7e-06
I0423 22:16:11.681030 30295 solver.cpp:228] Iteration 68400, loss = 3.10755
I0423 22:16:11.681849 30295 solver.cpp:244]     Train net output #0: loss = 0.984341 (* 1 = 0.984341 loss)
I0423 22:16:11.681856 30295 solver.cpp:244]     Train net output #1: loss = 0.606191 (* 1 = 0.606191 loss)
I0423 22:16:11.681860 30295 solver.cpp:244]     Train net output #2: loss = 0.906333 (* 1 = 0.906333 loss)
I0423 22:16:11.681865 30295 solver.cpp:244]     Train net output #3: loss = 0.610685 (* 1 = 0.610685 loss)
I0423 22:16:11.681870 30295 sgd_solver.cpp:106] Iteration 68400, lr = 2.7e-06
I0423 22:17:52.789525 30295 solver.cpp:228] Iteration 68500, loss = 2.70814
I0423 22:17:52.789672 30295 solver.cpp:244]     Train net output #0: loss = 0.989935 (* 1 = 0.989935 loss)
I0423 22:17:52.789680 30295 solver.cpp:244]     Train net output #1: loss = 0.541542 (* 1 = 0.541542 loss)
I0423 22:17:52.789685 30295 solver.cpp:244]     Train net output #2: loss = 0.704 (* 1 = 0.704 loss)
I0423 22:17:52.789690 30295 solver.cpp:244]     Train net output #3: loss = 0.47266 (* 1 = 0.47266 loss)
I0423 22:17:52.789695 30295 sgd_solver.cpp:106] Iteration 68500, lr = 2.7e-06
I0423 22:19:32.242650 30295 solver.cpp:228] Iteration 68600, loss = 2.63723
I0423 22:19:32.242807 30295 solver.cpp:244]     Train net output #0: loss = 0.98915 (* 1 = 0.98915 loss)
I0423 22:19:32.242815 30295 solver.cpp:244]     Train net output #1: loss = 0.466988 (* 1 = 0.466988 loss)
I0423 22:19:32.242820 30295 solver.cpp:244]     Train net output #2: loss = 0.605086 (* 1 = 0.605086 loss)
I0423 22:19:32.242823 30295 solver.cpp:244]     Train net output #3: loss = 0.57601 (* 1 = 0.57601 loss)
I0423 22:19:32.242830 30295 sgd_solver.cpp:106] Iteration 68600, lr = 2.7e-06
I0423 22:21:13.132254 30295 solver.cpp:228] Iteration 68700, loss = 2.99076
I0423 22:21:13.132436 30295 solver.cpp:244]     Train net output #0: loss = 0.980737 (* 1 = 0.980737 loss)
I0423 22:21:13.132443 30295 solver.cpp:244]     Train net output #1: loss = 0.508732 (* 1 = 0.508732 loss)
I0423 22:21:13.132449 30295 solver.cpp:244]     Train net output #2: loss = 0.942834 (* 1 = 0.942834 loss)
I0423 22:21:13.132453 30295 solver.cpp:244]     Train net output #3: loss = 0.558453 (* 1 = 0.558453 loss)
I0423 22:21:13.132457 30295 sgd_solver.cpp:106] Iteration 68700, lr = 2.7e-06
I0423 22:22:53.804060 30295 solver.cpp:228] Iteration 68800, loss = 3.01601
I0423 22:22:53.804200 30295 solver.cpp:244]     Train net output #0: loss = 0.976545 (* 1 = 0.976545 loss)
I0423 22:22:53.804208 30295 solver.cpp:244]     Train net output #1: loss = 0.51349 (* 1 = 0.51349 loss)
I0423 22:22:53.804213 30295 solver.cpp:244]     Train net output #2: loss = 0.947887 (* 1 = 0.947887 loss)
I0423 22:22:53.804217 30295 solver.cpp:244]     Train net output #3: loss = 0.578091 (* 1 = 0.578091 loss)
I0423 22:22:53.804222 30295 sgd_solver.cpp:106] Iteration 68800, lr = 2.7e-06
I0423 22:24:34.622089 30295 solver.cpp:228] Iteration 68900, loss = 2.98885
I0423 22:24:34.622262 30295 solver.cpp:244]     Train net output #0: loss = 0.956879 (* 1 = 0.956879 loss)
I0423 22:24:34.622269 30295 solver.cpp:244]     Train net output #1: loss = 0.708462 (* 1 = 0.708462 loss)
I0423 22:24:34.622275 30295 solver.cpp:244]     Train net output #2: loss = 0.771955 (* 1 = 0.771955 loss)
I0423 22:24:34.622279 30295 solver.cpp:244]     Train net output #3: loss = 0.551554 (* 1 = 0.551554 loss)
I0423 22:24:34.622284 30295 sgd_solver.cpp:106] Iteration 68900, lr = 2.7e-06
I0423 22:26:14.678920 30295 solver.cpp:337] Iteration 69000, Testing net (#0)
I0423 22:26:14.679059 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 22:26:14.679062 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 22:26:14.679065 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 22:26:14.679080 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 22:26:14.679085 30295 net.cpp:693] Ignoring source layer visualize
I0423 22:26:14.679085 30295 net.cpp:693] Ignoring source layer fake
I0423 22:29:52.590452 30295 solver.cpp:404]     Test net output #0: loss = 0.973981 (* 1 = 0.973981 loss)
I0423 22:29:52.590626 30295 solver.cpp:404]     Test net output #1: loss = 0.491898 (* 1 = 0.491898 loss)
I0423 22:29:52.590633 30295 solver.cpp:404]     Test net output #2: loss = 0.797183 (* 1 = 0.797183 loss)
I0423 22:29:52.590638 30295 solver.cpp:404]     Test net output #3: loss = 0.539931 (* 1 = 0.539931 loss)
I0423 22:29:53.276804 30295 solver.cpp:228] Iteration 69000, loss = 2.65352
I0423 22:29:53.276846 30295 solver.cpp:244]     Train net output #0: loss = 0.974618 (* 1 = 0.974618 loss)
I0423 22:29:53.276852 30295 solver.cpp:244]     Train net output #1: loss = 0.563631 (* 1 = 0.563631 loss)
I0423 22:29:53.276856 30295 solver.cpp:244]     Train net output #2: loss = 0.58402 (* 1 = 0.58402 loss)
I0423 22:29:53.276860 30295 solver.cpp:244]     Train net output #3: loss = 0.53125 (* 1 = 0.53125 loss)
I0423 22:29:53.276865 30295 sgd_solver.cpp:106] Iteration 69000, lr = 2.7e-06
I0423 22:31:34.407660 30295 solver.cpp:228] Iteration 69100, loss = 3.24092
I0423 22:31:34.407827 30295 solver.cpp:244]     Train net output #0: loss = 0.957253 (* 1 = 0.957253 loss)
I0423 22:31:34.407835 30295 solver.cpp:244]     Train net output #1: loss = 0.736711 (* 1 = 0.736711 loss)
I0423 22:31:34.407838 30295 solver.cpp:244]     Train net output #2: loss = 0.90873 (* 1 = 0.90873 loss)
I0423 22:31:34.407843 30295 solver.cpp:244]     Train net output #3: loss = 0.638229 (* 1 = 0.638229 loss)
I0423 22:31:34.407850 30295 sgd_solver.cpp:106] Iteration 69100, lr = 2.7e-06
I0423 22:33:15.754220 30295 solver.cpp:228] Iteration 69200, loss = 3.12623
I0423 22:33:15.754420 30295 solver.cpp:244]     Train net output #0: loss = 0.971976 (* 1 = 0.971976 loss)
I0423 22:33:15.754427 30295 solver.cpp:244]     Train net output #1: loss = 0.583153 (* 1 = 0.583153 loss)
I0423 22:33:15.754432 30295 solver.cpp:244]     Train net output #2: loss = 0.912559 (* 1 = 0.912559 loss)
I0423 22:33:15.754436 30295 solver.cpp:244]     Train net output #3: loss = 0.658542 (* 1 = 0.658542 loss)
I0423 22:33:15.754441 30295 sgd_solver.cpp:106] Iteration 69200, lr = 2.7e-06
I0423 22:34:55.591871 30295 solver.cpp:228] Iteration 69300, loss = 3.2192
I0423 22:34:55.592038 30295 solver.cpp:244]     Train net output #0: loss = 0.965359 (* 1 = 0.965359 loss)
I0423 22:34:55.592046 30295 solver.cpp:244]     Train net output #1: loss = 0.631203 (* 1 = 0.631203 loss)
I0423 22:34:55.592051 30295 solver.cpp:244]     Train net output #2: loss = 0.939043 (* 1 = 0.939043 loss)
I0423 22:34:55.592056 30295 solver.cpp:244]     Train net output #3: loss = 0.68359 (* 1 = 0.68359 loss)
I0423 22:34:55.592061 30295 sgd_solver.cpp:106] Iteration 69300, lr = 2.7e-06
I0423 22:36:36.998330 30295 solver.cpp:228] Iteration 69400, loss = 3.20747
I0423 22:36:36.998473 30295 solver.cpp:244]     Train net output #0: loss = 0.970475 (* 1 = 0.970475 loss)
I0423 22:36:36.998481 30295 solver.cpp:244]     Train net output #1: loss = 0.678668 (* 1 = 0.678668 loss)
I0423 22:36:36.998486 30295 solver.cpp:244]     Train net output #2: loss = 0.940903 (* 1 = 0.940903 loss)
I0423 22:36:36.998495 30295 solver.cpp:244]     Train net output #3: loss = 0.617424 (* 1 = 0.617424 loss)
I0423 22:36:36.998499 30295 sgd_solver.cpp:106] Iteration 69400, lr = 2.7e-06
I0423 22:38:18.474587 30295 solver.cpp:228] Iteration 69500, loss = 3.20415
I0423 22:38:18.474750 30295 solver.cpp:244]     Train net output #0: loss = 0.98285 (* 1 = 0.98285 loss)
I0423 22:38:18.474758 30295 solver.cpp:244]     Train net output #1: loss = 0.665306 (* 1 = 0.665306 loss)
I0423 22:38:18.474763 30295 solver.cpp:244]     Train net output #2: loss = 0.912325 (* 1 = 0.912325 loss)
I0423 22:38:18.474768 30295 solver.cpp:244]     Train net output #3: loss = 0.643664 (* 1 = 0.643664 loss)
I0423 22:38:18.474773 30295 sgd_solver.cpp:106] Iteration 69500, lr = 2.7e-06
I0423 22:39:59.863668 30295 solver.cpp:228] Iteration 69600, loss = 3.32833
I0423 22:39:59.863809 30295 solver.cpp:244]     Train net output #0: loss = 0.982872 (* 1 = 0.982872 loss)
I0423 22:39:59.863817 30295 solver.cpp:244]     Train net output #1: loss = 0.693404 (* 1 = 0.693404 loss)
I0423 22:39:59.863822 30295 solver.cpp:244]     Train net output #2: loss = 0.946144 (* 1 = 0.946144 loss)
I0423 22:39:59.863826 30295 solver.cpp:244]     Train net output #3: loss = 0.705915 (* 1 = 0.705915 loss)
I0423 22:39:59.863832 30295 sgd_solver.cpp:106] Iteration 69600, lr = 2.7e-06
I0423 22:41:39.455484 30295 solver.cpp:228] Iteration 69700, loss = 3.31885
I0423 22:41:39.456241 30295 solver.cpp:244]     Train net output #0: loss = 0.982572 (* 1 = 0.982572 loss)
I0423 22:41:39.456250 30295 solver.cpp:244]     Train net output #1: loss = 0.684307 (* 1 = 0.684307 loss)
I0423 22:41:39.456254 30295 solver.cpp:244]     Train net output #2: loss = 0.9324 (* 1 = 0.9324 loss)
I0423 22:41:39.456259 30295 solver.cpp:244]     Train net output #3: loss = 0.719573 (* 1 = 0.719573 loss)
I0423 22:41:39.456264 30295 sgd_solver.cpp:106] Iteration 69700, lr = 2.7e-06
I0423 22:43:20.507395 30295 solver.cpp:228] Iteration 69800, loss = 3.21707
I0423 22:43:20.507567 30295 solver.cpp:244]     Train net output #0: loss = 0.985253 (* 1 = 0.985253 loss)
I0423 22:43:20.507575 30295 solver.cpp:244]     Train net output #1: loss = 0.627494 (* 1 = 0.627494 loss)
I0423 22:43:20.507580 30295 solver.cpp:244]     Train net output #2: loss = 0.928412 (* 1 = 0.928412 loss)
I0423 22:43:20.507585 30295 solver.cpp:244]     Train net output #3: loss = 0.675915 (* 1 = 0.675915 loss)
I0423 22:43:20.507589 30295 sgd_solver.cpp:106] Iteration 69800, lr = 2.7e-06
I0423 22:45:01.375459 30295 solver.cpp:228] Iteration 69900, loss = 2.62246
I0423 22:45:01.377178 30295 solver.cpp:244]     Train net output #0: loss = 0.98895 (* 1 = 0.98895 loss)
I0423 22:45:01.377187 30295 solver.cpp:244]     Train net output #1: loss = 0.488524 (* 1 = 0.488524 loss)
I0423 22:45:01.377190 30295 solver.cpp:244]     Train net output #2: loss = 0.63333 (* 1 = 0.63333 loss)
I0423 22:45:01.377195 30295 solver.cpp:244]     Train net output #3: loss = 0.51166 (* 1 = 0.51166 loss)
I0423 22:45:01.377199 30295 sgd_solver.cpp:106] Iteration 69900, lr = 2.7e-06
I0423 22:46:41.143156 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_70000.caffemodel
I0423 22:47:04.952303 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_70000.solverstate
I0423 22:47:05.158836 30295 solver.cpp:337] Iteration 70000, Testing net (#0)
I0423 22:47:05.158875 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 22:47:05.158877 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 22:47:05.158880 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 22:47:05.158895 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 22:47:05.158897 30295 net.cpp:693] Ignoring source layer visualize
I0423 22:47:05.158900 30295 net.cpp:693] Ignoring source layer fake
I0423 22:50:41.949952 30295 solver.cpp:404]     Test net output #0: loss = 0.966778 (* 1 = 0.966778 loss)
I0423 22:50:41.950091 30295 solver.cpp:404]     Test net output #1: loss = 0.491477 (* 1 = 0.491477 loss)
I0423 22:50:41.950098 30295 solver.cpp:404]     Test net output #2: loss = 0.815559 (* 1 = 0.815559 loss)
I0423 22:50:41.950103 30295 solver.cpp:404]     Test net output #3: loss = 0.56079 (* 1 = 0.56079 loss)
I0423 22:50:42.642416 30295 solver.cpp:228] Iteration 70000, loss = 3.30876
I0423 22:50:42.642446 30295 solver.cpp:244]     Train net output #0: loss = 0.965527 (* 1 = 0.965527 loss)
I0423 22:50:42.642452 30295 solver.cpp:244]     Train net output #1: loss = 0.715725 (* 1 = 0.715725 loss)
I0423 22:50:42.642455 30295 solver.cpp:244]     Train net output #2: loss = 0.969161 (* 1 = 0.969161 loss)
I0423 22:50:42.642459 30295 solver.cpp:244]     Train net output #3: loss = 0.658345 (* 1 = 0.658345 loss)
I0423 22:50:42.642465 30295 sgd_solver.cpp:106] Iteration 70000, lr = 2.7e-06
I0423 22:52:23.538642 30295 solver.cpp:228] Iteration 70100, loss = 2.56763
I0423 22:52:23.538808 30295 solver.cpp:244]     Train net output #0: loss = 0.986411 (* 1 = 0.986411 loss)
I0423 22:52:23.538815 30295 solver.cpp:244]     Train net output #1: loss = 0.395435 (* 1 = 0.395435 loss)
I0423 22:52:23.538821 30295 solver.cpp:244]     Train net output #2: loss = 0.571538 (* 1 = 0.571538 loss)
I0423 22:52:23.538825 30295 solver.cpp:244]     Train net output #3: loss = 0.614241 (* 1 = 0.614241 loss)
I0423 22:52:23.538830 30295 sgd_solver.cpp:106] Iteration 70100, lr = 2.7e-06
I0423 22:54:04.545289 30295 solver.cpp:228] Iteration 70200, loss = 2.86022
I0423 22:54:04.545449 30295 solver.cpp:244]     Train net output #0: loss = 0.990858 (* 1 = 0.990858 loss)
I0423 22:54:04.545457 30295 solver.cpp:244]     Train net output #1: loss = 0.631803 (* 1 = 0.631803 loss)
I0423 22:54:04.545462 30295 solver.cpp:244]     Train net output #2: loss = 0.580933 (* 1 = 0.580933 loss)
I0423 22:54:04.545467 30295 solver.cpp:244]     Train net output #3: loss = 0.65663 (* 1 = 0.65663 loss)
I0423 22:54:04.545472 30295 sgd_solver.cpp:106] Iteration 70200, lr = 2.7e-06
I0423 22:55:44.233088 30295 solver.cpp:228] Iteration 70300, loss = 3.11611
I0423 22:55:44.233244 30295 solver.cpp:244]     Train net output #0: loss = 0.977946 (* 1 = 0.977946 loss)
I0423 22:55:44.233252 30295 solver.cpp:244]     Train net output #1: loss = 0.685086 (* 1 = 0.685086 loss)
I0423 22:55:44.233258 30295 solver.cpp:244]     Train net output #2: loss = 0.765963 (* 1 = 0.765963 loss)
I0423 22:55:44.233261 30295 solver.cpp:244]     Train net output #3: loss = 0.687118 (* 1 = 0.687118 loss)
I0423 22:55:44.233266 30295 sgd_solver.cpp:106] Iteration 70300, lr = 2.7e-06
I0423 22:57:25.586129 30295 solver.cpp:228] Iteration 70400, loss = 3.3314
I0423 22:57:25.586302 30295 solver.cpp:244]     Train net output #0: loss = 0.971531 (* 1 = 0.971531 loss)
I0423 22:57:25.586309 30295 solver.cpp:244]     Train net output #1: loss = 0.742577 (* 1 = 0.742577 loss)
I0423 22:57:25.586313 30295 solver.cpp:244]     Train net output #2: loss = 0.916641 (* 1 = 0.916641 loss)
I0423 22:57:25.586318 30295 solver.cpp:244]     Train net output #3: loss = 0.70065 (* 1 = 0.70065 loss)
I0423 22:57:25.586323 30295 sgd_solver.cpp:106] Iteration 70400, lr = 2.7e-06
I0423 22:59:06.926487 30295 solver.cpp:228] Iteration 70500, loss = 3.2092
I0423 22:59:06.926659 30295 solver.cpp:244]     Train net output #0: loss = 0.972026 (* 1 = 0.972026 loss)
I0423 22:59:06.926667 30295 solver.cpp:244]     Train net output #1: loss = 0.653421 (* 1 = 0.653421 loss)
I0423 22:59:06.926672 30295 solver.cpp:244]     Train net output #2: loss = 0.929811 (* 1 = 0.929811 loss)
I0423 22:59:06.926677 30295 solver.cpp:244]     Train net output #3: loss = 0.653943 (* 1 = 0.653943 loss)
I0423 22:59:06.926682 30295 sgd_solver.cpp:106] Iteration 70500, lr = 2.7e-06
I0423 23:00:48.629331 30295 solver.cpp:228] Iteration 70600, loss = 2.92399
I0423 23:00:48.629514 30295 solver.cpp:244]     Train net output #0: loss = 0.972438 (* 1 = 0.972438 loss)
I0423 23:00:48.629521 30295 solver.cpp:244]     Train net output #1: loss = 0.537166 (* 1 = 0.537166 loss)
I0423 23:00:48.629526 30295 solver.cpp:244]     Train net output #2: loss = 0.903324 (* 1 = 0.903324 loss)
I0423 23:00:48.629530 30295 solver.cpp:244]     Train net output #3: loss = 0.511061 (* 1 = 0.511061 loss)
I0423 23:00:48.629536 30295 sgd_solver.cpp:106] Iteration 70600, lr = 2.7e-06
I0423 23:02:28.442106 30295 solver.cpp:228] Iteration 70700, loss = 3.10399
I0423 23:02:28.442256 30295 solver.cpp:244]     Train net output #0: loss = 0.972836 (* 1 = 0.972836 loss)
I0423 23:02:28.442265 30295 solver.cpp:244]     Train net output #1: loss = 0.628316 (* 1 = 0.628316 loss)
I0423 23:02:28.442270 30295 solver.cpp:244]     Train net output #2: loss = 0.889025 (* 1 = 0.889025 loss)
I0423 23:02:28.442275 30295 solver.cpp:244]     Train net output #3: loss = 0.613809 (* 1 = 0.613809 loss)
I0423 23:02:28.442279 30295 sgd_solver.cpp:106] Iteration 70700, lr = 2.7e-06
I0423 23:04:09.747032 30295 solver.cpp:228] Iteration 70800, loss = 2.98904
I0423 23:04:09.747174 30295 solver.cpp:244]     Train net output #0: loss = 0.986588 (* 1 = 0.986588 loss)
I0423 23:04:09.747181 30295 solver.cpp:244]     Train net output #1: loss = 0.522794 (* 1 = 0.522794 loss)
I0423 23:04:09.747186 30295 solver.cpp:244]     Train net output #2: loss = 0.915896 (* 1 = 0.915896 loss)
I0423 23:04:09.747190 30295 solver.cpp:244]     Train net output #3: loss = 0.563759 (* 1 = 0.563759 loss)
I0423 23:04:09.747196 30295 sgd_solver.cpp:106] Iteration 70800, lr = 2.7e-06
I0423 23:05:50.944906 30295 solver.cpp:228] Iteration 70900, loss = 3.20028
I0423 23:05:50.945057 30295 solver.cpp:244]     Train net output #0: loss = 0.987694 (* 1 = 0.987694 loss)
I0423 23:05:50.945065 30295 solver.cpp:244]     Train net output #1: loss = 0.651761 (* 1 = 0.651761 loss)
I0423 23:05:50.945070 30295 solver.cpp:244]     Train net output #2: loss = 0.765513 (* 1 = 0.765513 loss)
I0423 23:05:50.945075 30295 solver.cpp:244]     Train net output #3: loss = 0.795312 (* 1 = 0.795312 loss)
I0423 23:05:50.945080 30295 sgd_solver.cpp:106] Iteration 70900, lr = 2.7e-06
I0423 23:07:31.195214 30295 solver.cpp:337] Iteration 71000, Testing net (#0)
I0423 23:07:31.195356 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 23:07:31.195360 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 23:07:31.195364 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 23:07:31.195377 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 23:07:31.195381 30295 net.cpp:693] Ignoring source layer visualize
I0423 23:07:31.195384 30295 net.cpp:693] Ignoring source layer fake
I0423 23:11:09.043977 30295 solver.cpp:404]     Test net output #0: loss = 0.973511 (* 1 = 0.973511 loss)
I0423 23:11:09.044185 30295 solver.cpp:404]     Test net output #1: loss = 0.550272 (* 1 = 0.550272 loss)
I0423 23:11:09.044193 30295 solver.cpp:404]     Test net output #2: loss = 0.824423 (* 1 = 0.824423 loss)
I0423 23:11:09.044198 30295 solver.cpp:404]     Test net output #3: loss = 0.590916 (* 1 = 0.590916 loss)
I0423 23:11:09.705057 30295 solver.cpp:228] Iteration 71000, loss = 2.95847
I0423 23:11:09.705085 30295 solver.cpp:244]     Train net output #0: loss = 0.987106 (* 1 = 0.987106 loss)
I0423 23:11:09.705090 30295 solver.cpp:244]     Train net output #1: loss = 0.564204 (* 1 = 0.564204 loss)
I0423 23:11:09.705094 30295 solver.cpp:244]     Train net output #2: loss = 0.81573 (* 1 = 0.81573 loss)
I0423 23:11:09.705098 30295 solver.cpp:244]     Train net output #3: loss = 0.59143 (* 1 = 0.59143 loss)
I0423 23:11:09.705102 30295 sgd_solver.cpp:106] Iteration 71000, lr = 2.7e-06
I0423 23:12:49.265720 30295 solver.cpp:228] Iteration 71100, loss = 2.94517
I0423 23:12:49.265872 30295 solver.cpp:244]     Train net output #0: loss = 0.993803 (* 1 = 0.993803 loss)
I0423 23:12:49.265879 30295 solver.cpp:244]     Train net output #1: loss = 0.570425 (* 1 = 0.570425 loss)
I0423 23:12:49.265884 30295 solver.cpp:244]     Train net output #2: loss = 0.667577 (* 1 = 0.667577 loss)
I0423 23:12:49.265889 30295 solver.cpp:244]     Train net output #3: loss = 0.71336 (* 1 = 0.71336 loss)
I0423 23:12:49.265894 30295 sgd_solver.cpp:106] Iteration 71100, lr = 2.7e-06
I0423 23:14:33.401654 30295 solver.cpp:228] Iteration 71200, loss = 3.02653
I0423 23:14:33.401815 30295 solver.cpp:244]     Train net output #0: loss = 0.970816 (* 1 = 0.970816 loss)
I0423 23:14:33.401823 30295 solver.cpp:244]     Train net output #1: loss = 0.499994 (* 1 = 0.499994 loss)
I0423 23:14:33.401828 30295 solver.cpp:244]     Train net output #2: loss = 0.913556 (* 1 = 0.913556 loss)
I0423 23:14:33.401832 30295 solver.cpp:244]     Train net output #3: loss = 0.642168 (* 1 = 0.642168 loss)
I0423 23:14:33.401837 30295 sgd_solver.cpp:106] Iteration 71200, lr = 2.7e-06
I0423 23:16:14.567447 30295 solver.cpp:228] Iteration 71300, loss = 3.00223
I0423 23:16:14.567596 30295 solver.cpp:244]     Train net output #0: loss = 0.97116 (* 1 = 0.97116 loss)
I0423 23:16:14.567605 30295 solver.cpp:244]     Train net output #1: loss = 0.606264 (* 1 = 0.606264 loss)
I0423 23:16:14.567608 30295 solver.cpp:244]     Train net output #2: loss = 0.957151 (* 1 = 0.957151 loss)
I0423 23:16:14.567613 30295 solver.cpp:244]     Train net output #3: loss = 0.467652 (* 1 = 0.467652 loss)
I0423 23:16:14.567618 30295 sgd_solver.cpp:106] Iteration 71300, lr = 2.7e-06
I0423 23:17:55.409344 30295 solver.cpp:228] Iteration 71400, loss = 3.16311
I0423 23:17:55.409503 30295 solver.cpp:244]     Train net output #0: loss = 0.961511 (* 1 = 0.961511 loss)
I0423 23:17:55.409512 30295 solver.cpp:244]     Train net output #1: loss = 0.612425 (* 1 = 0.612425 loss)
I0423 23:17:55.409517 30295 solver.cpp:244]     Train net output #2: loss = 0.945382 (* 1 = 0.945382 loss)
I0423 23:17:55.409520 30295 solver.cpp:244]     Train net output #3: loss = 0.643793 (* 1 = 0.643793 loss)
I0423 23:17:55.409525 30295 sgd_solver.cpp:106] Iteration 71400, lr = 2.7e-06
I0423 23:19:36.405264 30295 solver.cpp:228] Iteration 71500, loss = 2.66171
I0423 23:19:36.405413 30295 solver.cpp:244]     Train net output #0: loss = 0.988363 (* 1 = 0.988363 loss)
I0423 23:19:36.405421 30295 solver.cpp:244]     Train net output #1: loss = 0.613414 (* 1 = 0.613414 loss)
I0423 23:19:36.405426 30295 solver.cpp:244]     Train net output #2: loss = 0.556621 (* 1 = 0.556621 loss)
I0423 23:19:36.405431 30295 solver.cpp:244]     Train net output #3: loss = 0.503314 (* 1 = 0.503314 loss)
I0423 23:19:36.405443 30295 sgd_solver.cpp:106] Iteration 71500, lr = 2.7e-06
I0423 23:21:17.551983 30295 solver.cpp:228] Iteration 71600, loss = 3.37541
I0423 23:21:17.552145 30295 solver.cpp:244]     Train net output #0: loss = 0.978822 (* 1 = 0.978822 loss)
I0423 23:21:17.552153 30295 solver.cpp:244]     Train net output #1: loss = 0.816551 (* 1 = 0.816551 loss)
I0423 23:21:17.552157 30295 solver.cpp:244]     Train net output #2: loss = 0.907453 (* 1 = 0.907453 loss)
I0423 23:21:17.552162 30295 solver.cpp:244]     Train net output #3: loss = 0.672589 (* 1 = 0.672589 loss)
I0423 23:21:17.552167 30295 sgd_solver.cpp:106] Iteration 71600, lr = 2.7e-06
I0423 23:22:58.856847 30295 solver.cpp:228] Iteration 71700, loss = 3.22297
I0423 23:22:58.857040 30295 solver.cpp:244]     Train net output #0: loss = 0.9775 (* 1 = 0.9775 loss)
I0423 23:22:58.857048 30295 solver.cpp:244]     Train net output #1: loss = 0.687861 (* 1 = 0.687861 loss)
I0423 23:22:58.857053 30295 solver.cpp:244]     Train net output #2: loss = 0.912228 (* 1 = 0.912228 loss)
I0423 23:22:58.857059 30295 solver.cpp:244]     Train net output #3: loss = 0.64538 (* 1 = 0.64538 loss)
I0423 23:22:58.857062 30295 sgd_solver.cpp:106] Iteration 71700, lr = 2.7e-06
I0423 23:24:38.783042 30295 solver.cpp:228] Iteration 71800, loss = 3.21056
I0423 23:24:38.783202 30295 solver.cpp:244]     Train net output #0: loss = 0.980024 (* 1 = 0.980024 loss)
I0423 23:24:38.783210 30295 solver.cpp:244]     Train net output #1: loss = 0.741684 (* 1 = 0.741684 loss)
I0423 23:24:38.783215 30295 solver.cpp:244]     Train net output #2: loss = 0.849853 (* 1 = 0.849853 loss)
I0423 23:24:38.783219 30295 solver.cpp:244]     Train net output #3: loss = 0.638995 (* 1 = 0.638995 loss)
I0423 23:24:38.783224 30295 sgd_solver.cpp:106] Iteration 71800, lr = 2.7e-06
I0423 23:26:20.469312 30295 solver.cpp:228] Iteration 71900, loss = 3.4067
I0423 23:26:20.469493 30295 solver.cpp:244]     Train net output #0: loss = 0.980833 (* 1 = 0.980833 loss)
I0423 23:26:20.469501 30295 solver.cpp:244]     Train net output #1: loss = 0.778565 (* 1 = 0.778565 loss)
I0423 23:26:20.469506 30295 solver.cpp:244]     Train net output #2: loss = 0.935166 (* 1 = 0.935166 loss)
I0423 23:26:20.469511 30295 solver.cpp:244]     Train net output #3: loss = 0.712137 (* 1 = 0.712137 loss)
I0423 23:26:20.469516 30295 sgd_solver.cpp:106] Iteration 71900, lr = 2.7e-06
I0423 23:28:01.028486 30295 solver.cpp:337] Iteration 72000, Testing net (#0)
I0423 23:28:01.028626 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 23:28:01.028631 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 23:28:01.028635 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 23:28:01.028650 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 23:28:01.028653 30295 net.cpp:693] Ignoring source layer visualize
I0423 23:28:01.028656 30295 net.cpp:693] Ignoring source layer fake
I0423 23:31:38.926283 30295 solver.cpp:404]     Test net output #0: loss = 0.973593 (* 1 = 0.973593 loss)
I0423 23:31:38.926429 30295 solver.cpp:404]     Test net output #1: loss = 0.500545 (* 1 = 0.500545 loss)
I0423 23:31:38.926435 30295 solver.cpp:404]     Test net output #2: loss = 0.785145 (* 1 = 0.785145 loss)
I0423 23:31:38.926441 30295 solver.cpp:404]     Test net output #3: loss = 0.511373 (* 1 = 0.511373 loss)
I0423 23:31:39.585224 30295 solver.cpp:228] Iteration 72000, loss = 3.38154
I0423 23:31:39.585268 30295 solver.cpp:244]     Train net output #0: loss = 0.988648 (* 1 = 0.988648 loss)
I0423 23:31:39.585274 30295 solver.cpp:244]     Train net output #1: loss = 0.767352 (* 1 = 0.767352 loss)
I0423 23:31:39.585278 30295 solver.cpp:244]     Train net output #2: loss = 0.936315 (* 1 = 0.936315 loss)
I0423 23:31:39.585283 30295 solver.cpp:244]     Train net output #3: loss = 0.689226 (* 1 = 0.689226 loss)
I0423 23:31:39.585289 30295 sgd_solver.cpp:106] Iteration 72000, lr = 2.7e-06
I0423 23:33:21.018314 30295 solver.cpp:228] Iteration 72100, loss = 3.24387
I0423 23:33:21.018465 30295 solver.cpp:244]     Train net output #0: loss = 0.979984 (* 1 = 0.979984 loss)
I0423 23:33:21.018472 30295 solver.cpp:244]     Train net output #1: loss = 0.678314 (* 1 = 0.678314 loss)
I0423 23:33:21.018476 30295 solver.cpp:244]     Train net output #2: loss = 0.880709 (* 1 = 0.880709 loss)
I0423 23:33:21.018481 30295 solver.cpp:244]     Train net output #3: loss = 0.704863 (* 1 = 0.704863 loss)
I0423 23:33:21.018487 30295 sgd_solver.cpp:106] Iteration 72100, lr = 2.7e-06
I0423 23:35:00.515034 30295 solver.cpp:228] Iteration 72200, loss = 3.25197
I0423 23:35:00.515206 30295 solver.cpp:244]     Train net output #0: loss = 0.988315 (* 1 = 0.988315 loss)
I0423 23:35:00.515213 30295 solver.cpp:244]     Train net output #1: loss = 0.67254 (* 1 = 0.67254 loss)
I0423 23:35:00.515219 30295 solver.cpp:244]     Train net output #2: loss = 0.944984 (* 1 = 0.944984 loss)
I0423 23:35:00.515223 30295 solver.cpp:244]     Train net output #3: loss = 0.646134 (* 1 = 0.646134 loss)
I0423 23:35:00.515228 30295 sgd_solver.cpp:106] Iteration 72200, lr = 2.7e-06
I0423 23:36:41.617841 30295 solver.cpp:228] Iteration 72300, loss = 2.74621
I0423 23:36:41.617996 30295 solver.cpp:244]     Train net output #0: loss = 0.988142 (* 1 = 0.988142 loss)
I0423 23:36:41.618003 30295 solver.cpp:244]     Train net output #1: loss = 0.531525 (* 1 = 0.531525 loss)
I0423 23:36:41.618008 30295 solver.cpp:244]     Train net output #2: loss = 0.793595 (* 1 = 0.793595 loss)
I0423 23:36:41.618012 30295 solver.cpp:244]     Train net output #3: loss = 0.432952 (* 1 = 0.432952 loss)
I0423 23:36:41.618024 30295 sgd_solver.cpp:106] Iteration 72300, lr = 2.7e-06
I0423 23:38:22.455374 30295 solver.cpp:228] Iteration 72400, loss = 3.00617
I0423 23:38:22.455524 30295 solver.cpp:244]     Train net output #0: loss = 0.987448 (* 1 = 0.987448 loss)
I0423 23:38:22.455531 30295 solver.cpp:244]     Train net output #1: loss = 0.553282 (* 1 = 0.553282 loss)
I0423 23:38:22.455538 30295 solver.cpp:244]     Train net output #2: loss = 0.947179 (* 1 = 0.947179 loss)
I0423 23:38:22.455541 30295 solver.cpp:244]     Train net output #3: loss = 0.518262 (* 1 = 0.518262 loss)
I0423 23:38:22.455546 30295 sgd_solver.cpp:106] Iteration 72400, lr = 2.7e-06
I0423 23:40:03.148547 30295 solver.cpp:228] Iteration 72500, loss = 3.12812
I0423 23:40:03.148695 30295 solver.cpp:244]     Train net output #0: loss = 0.980345 (* 1 = 0.980345 loss)
I0423 23:40:03.148702 30295 solver.cpp:244]     Train net output #1: loss = 0.594363 (* 1 = 0.594363 loss)
I0423 23:40:03.148706 30295 solver.cpp:244]     Train net output #2: loss = 0.954089 (* 1 = 0.954089 loss)
I0423 23:40:03.148711 30295 solver.cpp:244]     Train net output #3: loss = 0.599322 (* 1 = 0.599322 loss)
I0423 23:40:03.148716 30295 sgd_solver.cpp:106] Iteration 72500, lr = 2.7e-06
I0423 23:41:43.932703 30295 solver.cpp:228] Iteration 72600, loss = 3.2049
I0423 23:41:43.932858 30295 solver.cpp:244]     Train net output #0: loss = 0.970249 (* 1 = 0.970249 loss)
I0423 23:41:43.932865 30295 solver.cpp:244]     Train net output #1: loss = 0.614933 (* 1 = 0.614933 loss)
I0423 23:41:43.932870 30295 solver.cpp:244]     Train net output #2: loss = 0.949474 (* 1 = 0.949474 loss)
I0423 23:41:43.932875 30295 solver.cpp:244]     Train net output #3: loss = 0.670246 (* 1 = 0.670246 loss)
I0423 23:41:43.932880 30295 sgd_solver.cpp:106] Iteration 72600, lr = 2.7e-06
I0423 23:43:25.307725 30295 solver.cpp:228] Iteration 72700, loss = 2.7431
I0423 23:43:25.307871 30295 solver.cpp:244]     Train net output #0: loss = 0.984776 (* 1 = 0.984776 loss)
I0423 23:43:25.307879 30295 solver.cpp:244]     Train net output #1: loss = 0.55933 (* 1 = 0.55933 loss)
I0423 23:43:25.307883 30295 solver.cpp:244]     Train net output #2: loss = 0.545968 (* 1 = 0.545968 loss)
I0423 23:43:25.307888 30295 solver.cpp:244]     Train net output #3: loss = 0.653028 (* 1 = 0.653028 loss)
I0423 23:43:25.307894 30295 sgd_solver.cpp:106] Iteration 72700, lr = 2.7e-06
I0423 23:45:05.062930 30295 solver.cpp:228] Iteration 72800, loss = 2.93693
I0423 23:45:05.063062 30295 solver.cpp:244]     Train net output #0: loss = 0.983184 (* 1 = 0.983184 loss)
I0423 23:45:05.063069 30295 solver.cpp:244]     Train net output #1: loss = 0.495976 (* 1 = 0.495976 loss)
I0423 23:45:05.063076 30295 solver.cpp:244]     Train net output #2: loss = 0.752616 (* 1 = 0.752616 loss)
I0423 23:45:05.063079 30295 solver.cpp:244]     Train net output #3: loss = 0.705154 (* 1 = 0.705154 loss)
I0423 23:45:05.063084 30295 sgd_solver.cpp:106] Iteration 72800, lr = 2.7e-06
I0423 23:46:46.546309 30295 solver.cpp:228] Iteration 72900, loss = 3.37425
I0423 23:46:46.546478 30295 solver.cpp:244]     Train net output #0: loss = 0.977798 (* 1 = 0.977798 loss)
I0423 23:46:46.546486 30295 solver.cpp:244]     Train net output #1: loss = 0.70923 (* 1 = 0.70923 loss)
I0423 23:46:46.546491 30295 solver.cpp:244]     Train net output #2: loss = 0.929353 (* 1 = 0.929353 loss)
I0423 23:46:46.546495 30295 solver.cpp:244]     Train net output #3: loss = 0.757867 (* 1 = 0.757867 loss)
I0423 23:46:46.546501 30295 sgd_solver.cpp:106] Iteration 72900, lr = 2.7e-06
I0423 23:48:26.947667 30295 solver.cpp:337] Iteration 73000, Testing net (#0)
I0423 23:48:26.948092 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0423 23:48:26.948096 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 23:48:26.948114 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0423 23:48:26.948127 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 23:48:26.948129 30295 net.cpp:693] Ignoring source layer visualize
I0423 23:48:26.948132 30295 net.cpp:693] Ignoring source layer fake
I0423 23:52:05.457406 30295 solver.cpp:404]     Test net output #0: loss = 0.969213 (* 1 = 0.969213 loss)
I0423 23:52:05.457530 30295 solver.cpp:404]     Test net output #1: loss = 0.477533 (* 1 = 0.477533 loss)
I0423 23:52:05.457537 30295 solver.cpp:404]     Test net output #2: loss = 0.814669 (* 1 = 0.814669 loss)
I0423 23:52:05.457541 30295 solver.cpp:404]     Test net output #3: loss = 0.551055 (* 1 = 0.551055 loss)
I0423 23:52:06.124752 30295 solver.cpp:228] Iteration 73000, loss = 3.20042
I0423 23:52:06.124795 30295 solver.cpp:244]     Train net output #0: loss = 0.965915 (* 1 = 0.965915 loss)
I0423 23:52:06.124800 30295 solver.cpp:244]     Train net output #1: loss = 0.641164 (* 1 = 0.641164 loss)
I0423 23:52:06.124805 30295 solver.cpp:244]     Train net output #2: loss = 0.94432 (* 1 = 0.94432 loss)
I0423 23:52:06.124810 30295 solver.cpp:244]     Train net output #3: loss = 0.649018 (* 1 = 0.649018 loss)
I0423 23:52:06.124816 30295 sgd_solver.cpp:106] Iteration 73000, lr = 2.7e-06
I0423 23:53:47.887290 30295 solver.cpp:228] Iteration 73100, loss = 3.16452
I0423 23:53:47.887446 30295 solver.cpp:244]     Train net output #0: loss = 0.98037 (* 1 = 0.98037 loss)
I0423 23:53:47.887455 30295 solver.cpp:244]     Train net output #1: loss = 0.705495 (* 1 = 0.705495 loss)
I0423 23:53:47.887460 30295 solver.cpp:244]     Train net output #2: loss = 0.889651 (* 1 = 0.889651 loss)
I0423 23:53:47.887465 30295 solver.cpp:244]     Train net output #3: loss = 0.589 (* 1 = 0.589 loss)
I0423 23:53:47.887471 30295 sgd_solver.cpp:106] Iteration 73100, lr = 2.7e-06
I0423 23:55:27.670452 30295 solver.cpp:228] Iteration 73200, loss = 3.39582
I0423 23:55:27.671394 30295 solver.cpp:244]     Train net output #0: loss = 0.988388 (* 1 = 0.988388 loss)
I0423 23:55:27.671403 30295 solver.cpp:244]     Train net output #1: loss = 0.798544 (* 1 = 0.798544 loss)
I0423 23:55:27.671408 30295 solver.cpp:244]     Train net output #2: loss = 0.887756 (* 1 = 0.887756 loss)
I0423 23:55:27.671413 30295 solver.cpp:244]     Train net output #3: loss = 0.721132 (* 1 = 0.721132 loss)
I0423 23:55:27.671419 30295 sgd_solver.cpp:106] Iteration 73200, lr = 2.7e-06
I0423 23:57:09.179141 30295 solver.cpp:228] Iteration 73300, loss = 3.19773
I0423 23:57:09.179286 30295 solver.cpp:244]     Train net output #0: loss = 0.989819 (* 1 = 0.989819 loss)
I0423 23:57:09.179293 30295 solver.cpp:244]     Train net output #1: loss = 0.675686 (* 1 = 0.675686 loss)
I0423 23:57:09.179298 30295 solver.cpp:244]     Train net output #2: loss = 0.90625 (* 1 = 0.90625 loss)
I0423 23:57:09.179302 30295 solver.cpp:244]     Train net output #3: loss = 0.625972 (* 1 = 0.625972 loss)
I0423 23:57:09.179316 30295 sgd_solver.cpp:106] Iteration 73300, lr = 2.7e-06
I0423 23:58:50.457139 30295 solver.cpp:228] Iteration 73400, loss = 3.28746
I0423 23:58:50.457309 30295 solver.cpp:244]     Train net output #0: loss = 0.985936 (* 1 = 0.985936 loss)
I0423 23:58:50.457315 30295 solver.cpp:244]     Train net output #1: loss = 0.749079 (* 1 = 0.749079 loss)
I0423 23:58:50.457320 30295 solver.cpp:244]     Train net output #2: loss = 0.770024 (* 1 = 0.770024 loss)
I0423 23:58:50.457325 30295 solver.cpp:244]     Train net output #3: loss = 0.78242 (* 1 = 0.78242 loss)
I0423 23:58:50.457331 30295 sgd_solver.cpp:106] Iteration 73400, lr = 2.7e-06
I0424 00:00:31.638173 30295 solver.cpp:228] Iteration 73500, loss = 3.22862
I0424 00:00:31.638680 30295 solver.cpp:244]     Train net output #0: loss = 0.987811 (* 1 = 0.987811 loss)
I0424 00:00:31.638702 30295 solver.cpp:244]     Train net output #1: loss = 0.677039 (* 1 = 0.677039 loss)
I0424 00:00:31.638708 30295 solver.cpp:244]     Train net output #2: loss = 0.868314 (* 1 = 0.868314 loss)
I0424 00:00:31.638711 30295 solver.cpp:244]     Train net output #3: loss = 0.695451 (* 1 = 0.695451 loss)
I0424 00:00:31.638718 30295 sgd_solver.cpp:106] Iteration 73500, lr = 2.7e-06
I0424 00:02:11.196950 30295 solver.cpp:228] Iteration 73600, loss = 3.0094
I0424 00:02:11.197448 30295 solver.cpp:244]     Train net output #0: loss = 0.989651 (* 1 = 0.989651 loss)
I0424 00:02:11.197454 30295 solver.cpp:244]     Train net output #1: loss = 0.605663 (* 1 = 0.605663 loss)
I0424 00:02:11.197459 30295 solver.cpp:244]     Train net output #2: loss = 0.835754 (* 1 = 0.835754 loss)
I0424 00:02:11.197463 30295 solver.cpp:244]     Train net output #3: loss = 0.578336 (* 1 = 0.578336 loss)
I0424 00:02:11.197468 30295 sgd_solver.cpp:106] Iteration 73600, lr = 2.7e-06
I0424 00:03:52.204427 30295 solver.cpp:228] Iteration 73700, loss = 2.48956
I0424 00:03:52.205395 30295 solver.cpp:244]     Train net output #0: loss = 0.976989 (* 1 = 0.976989 loss)
I0424 00:03:52.205404 30295 solver.cpp:244]     Train net output #1: loss = 0.343879 (* 1 = 0.343879 loss)
I0424 00:03:52.205409 30295 solver.cpp:244]     Train net output #2: loss = 0.680241 (* 1 = 0.680241 loss)
I0424 00:03:52.205412 30295 solver.cpp:244]     Train net output #3: loss = 0.488451 (* 1 = 0.488451 loss)
I0424 00:03:52.205432 30295 sgd_solver.cpp:106] Iteration 73700, lr = 2.7e-06
I0424 00:05:33.104712 30295 solver.cpp:228] Iteration 73800, loss = 3.18535
I0424 00:05:33.104866 30295 solver.cpp:244]     Train net output #0: loss = 0.969804 (* 1 = 0.969804 loss)
I0424 00:05:33.104884 30295 solver.cpp:244]     Train net output #1: loss = 0.688635 (* 1 = 0.688635 loss)
I0424 00:05:33.104889 30295 solver.cpp:244]     Train net output #2: loss = 0.953246 (* 1 = 0.953246 loss)
I0424 00:05:33.104894 30295 solver.cpp:244]     Train net output #3: loss = 0.57367 (* 1 = 0.57367 loss)
I0424 00:05:33.104900 30295 sgd_solver.cpp:106] Iteration 73800, lr = 2.7e-06
I0424 00:07:14.241333 30295 solver.cpp:228] Iteration 73900, loss = 3.03868
I0424 00:07:14.243479 30295 solver.cpp:244]     Train net output #0: loss = 0.963277 (* 1 = 0.963277 loss)
I0424 00:07:14.243485 30295 solver.cpp:244]     Train net output #1: loss = 0.750264 (* 1 = 0.750264 loss)
I0424 00:07:14.243490 30295 solver.cpp:244]     Train net output #2: loss = 0.743354 (* 1 = 0.743354 loss)
I0424 00:07:14.243494 30295 solver.cpp:244]     Train net output #3: loss = 0.581787 (* 1 = 0.581787 loss)
I0424 00:07:14.243499 30295 sgd_solver.cpp:106] Iteration 73900, lr = 2.7e-06
I0424 00:08:54.601881 30295 solver.cpp:337] Iteration 74000, Testing net (#0)
I0424 00:08:54.602036 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0424 00:08:54.602041 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0424 00:08:54.602044 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0424 00:08:54.602059 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0424 00:08:54.602062 30295 net.cpp:693] Ignoring source layer visualize
I0424 00:08:54.602064 30295 net.cpp:693] Ignoring source layer fake
I0424 00:12:34.014430 30295 solver.cpp:404]     Test net output #0: loss = 0.973866 (* 1 = 0.973866 loss)
I0424 00:12:34.014631 30295 solver.cpp:404]     Test net output #1: loss = 0.491808 (* 1 = 0.491808 loss)
I0424 00:12:34.014638 30295 solver.cpp:404]     Test net output #2: loss = 0.796885 (* 1 = 0.796885 loss)
I0424 00:12:34.014642 30295 solver.cpp:404]     Test net output #3: loss = 0.540243 (* 1 = 0.540243 loss)
I0424 00:12:34.675465 30295 solver.cpp:228] Iteration 74000, loss = 3.09979
I0424 00:12:34.675509 30295 solver.cpp:244]     Train net output #0: loss = 0.988079 (* 1 = 0.988079 loss)
I0424 00:12:34.675515 30295 solver.cpp:244]     Train net output #1: loss = 0.677638 (* 1 = 0.677638 loss)
I0424 00:12:34.675519 30295 solver.cpp:244]     Train net output #2: loss = 0.754501 (* 1 = 0.754501 loss)
I0424 00:12:34.675523 30295 solver.cpp:244]     Train net output #3: loss = 0.679569 (* 1 = 0.679569 loss)
I0424 00:12:34.675531 30295 sgd_solver.cpp:106] Iteration 74000, lr = 2.7e-06
I0424 00:14:15.928225 30295 solver.cpp:228] Iteration 74100, loss = 3.33623
I0424 00:14:15.928390 30295 solver.cpp:244]     Train net output #0: loss = 0.968613 (* 1 = 0.968613 loss)
I0424 00:14:15.928398 30295 solver.cpp:244]     Train net output #1: loss = 0.762156 (* 1 = 0.762156 loss)
I0424 00:14:15.928405 30295 solver.cpp:244]     Train net output #2: loss = 0.912971 (* 1 = 0.912971 loss)
I0424 00:14:15.928408 30295 solver.cpp:244]     Train net output #3: loss = 0.692492 (* 1 = 0.692492 loss)
I0424 00:14:15.928414 30295 sgd_solver.cpp:106] Iteration 74100, lr = 2.7e-06
I0424 00:15:57.397598 30295 solver.cpp:228] Iteration 74200, loss = 3.28683
I0424 00:15:57.397768 30295 solver.cpp:244]     Train net output #0: loss = 0.976159 (* 1 = 0.976159 loss)
I0424 00:15:57.397774 30295 solver.cpp:244]     Train net output #1: loss = 0.764527 (* 1 = 0.764527 loss)
I0424 00:15:57.397779 30295 solver.cpp:244]     Train net output #2: loss = 0.916795 (* 1 = 0.916795 loss)
I0424 00:15:57.397783 30295 solver.cpp:244]     Train net output #3: loss = 0.629347 (* 1 = 0.629347 loss)
I0424 00:15:57.397789 30295 sgd_solver.cpp:106] Iteration 74200, lr = 2.7e-06
I0424 00:17:36.980089 30295 solver.cpp:228] Iteration 74300, loss = 3.20469
I0424 00:17:36.981303 30295 solver.cpp:244]     Train net output #0: loss = 0.987266 (* 1 = 0.987266 loss)
I0424 00:17:36.981310 30295 solver.cpp:244]     Train net output #1: loss = 0.76955 (* 1 = 0.76955 loss)
I0424 00:17:36.981315 30295 solver.cpp:244]     Train net output #2: loss = 0.847615 (* 1 = 0.847615 loss)
I0424 00:17:36.981320 30295 solver.cpp:244]     Train net output #3: loss = 0.600263 (* 1 = 0.600263 loss)
I0424 00:17:36.981326 30295 sgd_solver.cpp:106] Iteration 74300, lr = 2.7e-06
I0424 00:19:18.352007 30295 solver.cpp:228] Iteration 74400, loss = 3.18565
I0424 00:19:18.352160 30295 solver.cpp:244]     Train net output #0: loss = 0.975652 (* 1 = 0.975652 loss)
I0424 00:19:18.352167 30295 solver.cpp:244]     Train net output #1: loss = 0.720102 (* 1 = 0.720102 loss)
I0424 00:19:18.352172 30295 solver.cpp:244]     Train net output #2: loss = 0.903902 (* 1 = 0.903902 loss)
I0424 00:19:18.352176 30295 solver.cpp:244]     Train net output #3: loss = 0.585998 (* 1 = 0.585998 loss)
I0424 00:19:18.352182 30295 sgd_solver.cpp:106] Iteration 74400, lr = 2.7e-06
I0424 00:20:59.692646 30295 solver.cpp:228] Iteration 74500, loss = 3.38555
I0424 00:20:59.692801 30295 solver.cpp:244]     Train net output #0: loss = 0.992896 (* 1 = 0.992896 loss)
I0424 00:20:59.692809 30295 solver.cpp:244]     Train net output #1: loss = 0.780436 (* 1 = 0.780436 loss)
I0424 00:20:59.692816 30295 solver.cpp:244]     Train net output #2: loss = 0.93523 (* 1 = 0.93523 loss)
I0424 00:20:59.692819 30295 solver.cpp:244]     Train net output #3: loss = 0.676984 (* 1 = 0.676984 loss)
I0424 00:20:59.692826 30295 sgd_solver.cpp:106] Iteration 74500, lr = 2.7e-06
I0424 00:22:40.977403 30295 solver.cpp:228] Iteration 74600, loss = 3.17308
I0424 00:22:40.977565 30295 solver.cpp:244]     Train net output #0: loss = 0.981692 (* 1 = 0.981692 loss)
I0424 00:22:40.977572 30295 solver.cpp:244]     Train net output #1: loss = 0.608718 (* 1 = 0.608718 loss)
I0424 00:22:40.977577 30295 solver.cpp:244]     Train net output #2: loss = 0.886984 (* 1 = 0.886984 loss)
I0424 00:22:40.977581 30295 solver.cpp:244]     Train net output #3: loss = 0.695685 (* 1 = 0.695685 loss)
I0424 00:22:40.977587 30295 sgd_solver.cpp:106] Iteration 74600, lr = 2.7e-06
I0424 00:24:20.432374 30295 solver.cpp:228] Iteration 74700, loss = 3.22754
I0424 00:24:20.432556 30295 solver.cpp:244]     Train net output #0: loss = 0.990235 (* 1 = 0.990235 loss)
I0424 00:24:20.432564 30295 solver.cpp:244]     Train net output #1: loss = 0.609467 (* 1 = 0.609467 loss)
I0424 00:24:20.432570 30295 solver.cpp:244]     Train net output #2: loss = 0.962384 (* 1 = 0.962384 loss)
I0424 00:24:20.432574 30295 solver.cpp:244]     Train net output #3: loss = 0.665452 (* 1 = 0.665452 loss)
I0424 00:24:20.432579 30295 sgd_solver.cpp:106] Iteration 74700, lr = 2.7e-06
I0424 00:26:01.825283 30295 solver.cpp:228] Iteration 74800, loss = 2.69256
I0424 00:26:01.825443 30295 solver.cpp:244]     Train net output #0: loss = 0.990584 (* 1 = 0.990584 loss)
I0424 00:26:01.825453 30295 solver.cpp:244]     Train net output #1: loss = 0.542835 (* 1 = 0.542835 loss)
I0424 00:26:01.825456 30295 solver.cpp:244]     Train net output #2: loss = 0.677751 (* 1 = 0.677751 loss)
I0424 00:26:01.825461 30295 solver.cpp:244]     Train net output #3: loss = 0.481391 (* 1 = 0.481391 loss)
I0424 00:26:01.825467 30295 sgd_solver.cpp:106] Iteration 74800, lr = 2.7e-06
I0424 00:27:42.821370 30295 solver.cpp:228] Iteration 74900, loss = 2.8078
I0424 00:27:42.821542 30295 solver.cpp:244]     Train net output #0: loss = 0.986232 (* 1 = 0.986232 loss)
I0424 00:27:42.821549 30295 solver.cpp:244]     Train net output #1: loss = 0.574705 (* 1 = 0.574705 loss)
I0424 00:27:42.821555 30295 solver.cpp:244]     Train net output #2: loss = 0.728167 (* 1 = 0.728167 loss)
I0424 00:27:42.821559 30295 solver.cpp:244]     Train net output #3: loss = 0.5187 (* 1 = 0.5187 loss)
I0424 00:27:42.821564 30295 sgd_solver.cpp:106] Iteration 74900, lr = 2.7e-06
I0424 00:29:22.324064 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_75000.caffemodel
I0424 00:29:42.904456 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_75000.solverstate
I0424 00:29:43.105803 30295 solver.cpp:337] Iteration 75000, Testing net (#0)
I0424 00:29:43.105841 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0424 00:29:43.105844 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0424 00:29:43.105847 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0424 00:29:43.105860 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0424 00:29:43.105864 30295 net.cpp:693] Ignoring source layer visualize
I0424 00:29:43.105865 30295 net.cpp:693] Ignoring source layer fake
I0424 00:33:20.245932 30295 solver.cpp:404]     Test net output #0: loss = 0.968894 (* 1 = 0.968894 loss)
I0424 00:33:20.246050 30295 solver.cpp:404]     Test net output #1: loss = 0.508089 (* 1 = 0.508089 loss)
I0424 00:33:20.246057 30295 solver.cpp:404]     Test net output #2: loss = 0.819614 (* 1 = 0.819614 loss)
I0424 00:33:20.246062 30295 solver.cpp:404]     Test net output #3: loss = 0.56985 (* 1 = 0.56985 loss)
I0424 00:33:20.910404 30295 solver.cpp:228] Iteration 75000, loss = 3.01715
I0424 00:33:20.910449 30295 solver.cpp:244]     Train net output #0: loss = 0.981572 (* 1 = 0.981572 loss)
I0424 00:33:20.910454 30295 solver.cpp:244]     Train net output #1: loss = 0.598525 (* 1 = 0.598525 loss)
I0424 00:33:20.910457 30295 solver.cpp:244]     Train net output #2: loss = 0.944099 (* 1 = 0.944099 loss)
I0424 00:33:20.910462 30295 solver.cpp:244]     Train net output #3: loss = 0.492955 (* 1 = 0.492955 loss)
I0424 00:33:20.910467 30295 sgd_solver.cpp:106] Iteration 75000, lr = 2.7e-06
I0424 00:35:01.824889 30295 solver.cpp:228] Iteration 75100, loss = 3.36784
I0424 00:35:01.825042 30295 solver.cpp:244]     Train net output #0: loss = 0.966939 (* 1 = 0.966939 loss)
I0424 00:35:01.825053 30295 solver.cpp:244]     Train net output #1: loss = 0.774254 (* 1 = 0.774254 loss)
I0424 00:35:01.825062 30295 solver.cpp:244]     Train net output #2: loss = 0.928929 (* 1 = 0.928929 loss)
I0424 00:35:01.825069 30295 solver.cpp:244]     Train net output #3: loss = 0.697718 (* 1 = 0.697718 loss)
I0424 00:35:01.825078 30295 sgd_solver.cpp:106] Iteration 75100, lr = 2.7e-06
I0424 00:36:43.164978 30295 solver.cpp:228] Iteration 75200, loss = 3.07562
I0424 00:36:43.165158 30295 solver.cpp:244]     Train net output #0: loss = 0.979882 (* 1 = 0.979882 loss)
I0424 00:36:43.165165 30295 solver.cpp:244]     Train net output #1: loss = 0.49352 (* 1 = 0.49352 loss)
I0424 00:36:43.165169 30295 solver.cpp:244]     Train net output #2: loss = 0.93195 (* 1 = 0.93195 loss)
I0424 00:36:43.165174 30295 solver.cpp:244]     Train net output #3: loss = 0.670263 (* 1 = 0.670263 loss)
I0424 00:36:43.165179 30295 sgd_solver.cpp:106] Iteration 75200, lr = 2.7e-06
I0424 00:38:24.203621 30295 solver.cpp:228] Iteration 75300, loss = 2.31085
I0424 00:38:24.216100 30295 solver.cpp:244]     Train net output #0: loss = 0.976035 (* 1 = 0.976035 loss)
I0424 00:38:24.216120 30295 solver.cpp:244]     Train net output #1: loss = 0.252835 (* 1 = 0.252835 loss)
I0424 00:38:24.216138 30295 solver.cpp:244]     Train net output #2: loss = 0.559698 (* 1 = 0.559698 loss)
I0424 00:38:24.216147 30295 solver.cpp:244]     Train net output #3: loss = 0.522282 (* 1 = 0.522282 loss)
I0424 00:38:24.216159 30295 sgd_solver.cpp:106] Iteration 75300, lr = 2.7e-06
I0424 00:40:03.675210 30295 solver.cpp:228] Iteration 75400, loss = 2.44925
I0424 00:40:03.676430 30295 solver.cpp:244]     Train net output #0: loss = 0.974106 (* 1 = 0.974106 loss)
I0424 00:40:03.676439 30295 solver.cpp:244]     Train net output #1: loss = 0.325031 (* 1 = 0.325031 loss)
I0424 00:40:03.676445 30295 solver.cpp:244]     Train net output #2: loss = 0.570837 (* 1 = 0.570837 loss)
I0424 00:40:03.676450 30295 solver.cpp:244]     Train net output #3: loss = 0.579277 (* 1 = 0.579277 loss)
I0424 00:40:03.676453 30295 sgd_solver.cpp:106] Iteration 75400, lr = 2.7e-06
I0424 00:41:44.954041 30295 solver.cpp:228] Iteration 75500, loss = 3.44514
I0424 00:41:44.954197 30295 solver.cpp:244]     Train net output #0: loss = 0.983139 (* 1 = 0.983139 loss)
I0424 00:41:44.954206 30295 solver.cpp:244]     Train net output #1: loss = 0.802728 (* 1 = 0.802728 loss)
I0424 00:41:44.954211 30295 solver.cpp:244]     Train net output #2: loss = 0.951255 (* 1 = 0.951255 loss)
I0424 00:41:44.954216 30295 solver.cpp:244]     Train net output #3: loss = 0.708022 (* 1 = 0.708022 loss)
I0424 00:41:44.954221 30295 sgd_solver.cpp:106] Iteration 75500, lr = 2.7e-06
I0424 00:43:26.173691 30295 solver.cpp:228] Iteration 75600, loss = 3.42507
I0424 00:43:26.174418 30295 solver.cpp:244]     Train net output #0: loss = 0.988437 (* 1 = 0.988437 loss)
I0424 00:43:26.174427 30295 solver.cpp:244]     Train net output #1: loss = 0.850976 (* 1 = 0.850976 loss)
I0424 00:43:26.174432 30295 solver.cpp:244]     Train net output #2: loss = 0.884845 (* 1 = 0.884845 loss)
I0424 00:43:26.174437 30295 solver.cpp:244]     Train net output #3: loss = 0.700811 (* 1 = 0.700811 loss)
I0424 00:43:26.174441 30295 sgd_solver.cpp:106] Iteration 75600, lr = 2.7e-06
I0424 00:45:05.702059 30295 solver.cpp:228] Iteration 75700, loss = 3.38812
I0424 00:45:05.702219 30295 solver.cpp:244]     Train net output #0: loss = 0.986182 (* 1 = 0.986182 loss)
I0424 00:45:05.702227 30295 solver.cpp:244]     Train net output #1: loss = 0.749636 (* 1 = 0.749636 loss)
I0424 00:45:05.702231 30295 solver.cpp:244]     Train net output #2: loss = 0.910418 (* 1 = 0.910418 loss)
I0424 00:45:05.702236 30295 solver.cpp:244]     Train net output #3: loss = 0.741883 (* 1 = 0.741883 loss)
I0424 00:45:05.702241 30295 sgd_solver.cpp:106] Iteration 75700, lr = 2.7e-06
I0424 00:46:51.243129 30295 solver.cpp:228] Iteration 75800, loss = 3.31811
I0424 00:46:51.243270 30295 solver.cpp:244]     Train net output #0: loss = 0.989552 (* 1 = 0.989552 loss)
I0424 00:46:51.243278 30295 solver.cpp:244]     Train net output #1: loss = 0.767228 (* 1 = 0.767228 loss)
I0424 00:46:51.243283 30295 solver.cpp:244]     Train net output #2: loss = 0.873417 (* 1 = 0.873417 loss)
I0424 00:46:51.243288 30295 solver.cpp:244]     Train net output #3: loss = 0.687909 (* 1 = 0.687909 loss)
I0424 00:46:51.243294 30295 sgd_solver.cpp:106] Iteration 75800, lr = 2.7e-06
I0424 00:48:35.819145 30295 solver.cpp:228] Iteration 75900, loss = 3.33871
I0424 00:48:35.819306 30295 solver.cpp:244]     Train net output #0: loss = 0.991923 (* 1 = 0.991923 loss)
I0424 00:48:35.819314 30295 solver.cpp:244]     Train net output #1: loss = 0.778723 (* 1 = 0.778723 loss)
I0424 00:48:35.819319 30295 solver.cpp:244]     Train net output #2: loss = 0.952679 (* 1 = 0.952679 loss)
I0424 00:48:35.819324 30295 solver.cpp:244]     Train net output #3: loss = 0.615382 (* 1 = 0.615382 loss)
I0424 00:48:35.819329 30295 sgd_solver.cpp:106] Iteration 75900, lr = 2.7e-06
I0424 00:50:19.175109 30295 solver.cpp:337] Iteration 76000, Testing net (#0)
I0424 00:50:19.176625 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0424 00:50:19.176630 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0424 00:50:19.176635 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0424 00:50:19.176651 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0424 00:50:19.176653 30295 net.cpp:693] Ignoring source layer visualize
I0424 00:50:19.176656 30295 net.cpp:693] Ignoring source layer fake
I0424 00:53:57.351830 30295 solver.cpp:404]     Test net output #0: loss = 0.973026 (* 1 = 0.973026 loss)
I0424 00:53:57.351970 30295 solver.cpp:404]     Test net output #1: loss = 0.543335 (* 1 = 0.543335 loss)
I0424 00:53:57.351976 30295 solver.cpp:404]     Test net output #2: loss = 0.823085 (* 1 = 0.823085 loss)
I0424 00:53:57.351981 30295 solver.cpp:404]     Test net output #3: loss = 0.586744 (* 1 = 0.586744 loss)
I0424 00:53:58.016927 30295 solver.cpp:228] Iteration 76000, loss = 2.73838
I0424 00:53:58.016970 30295 solver.cpp:244]     Train net output #0: loss = 0.985615 (* 1 = 0.985615 loss)
I0424 00:53:58.016976 30295 solver.cpp:244]     Train net output #1: loss = 0.514226 (* 1 = 0.514226 loss)
I0424 00:53:58.016980 30295 solver.cpp:244]     Train net output #2: loss = 0.814203 (* 1 = 0.814203 loss)
I0424 00:53:58.016985 30295 solver.cpp:244]     Train net output #3: loss = 0.42434 (* 1 = 0.42434 loss)
I0424 00:53:58.016991 30295 sgd_solver.cpp:106] Iteration 76000, lr = 2.7e-06
I0424 00:55:37.332921 30295 solver.cpp:228] Iteration 76100, loss = 2.71059
I0424 00:55:37.333061 30295 solver.cpp:244]     Train net output #0: loss = 0.985093 (* 1 = 0.985093 loss)
I0424 00:55:37.333070 30295 solver.cpp:244]     Train net output #1: loss = 0.565911 (* 1 = 0.565911 loss)
I0424 00:55:37.333076 30295 solver.cpp:244]     Train net output #2: loss = 0.654321 (* 1 = 0.654321 loss)
I0424 00:55:37.333081 30295 solver.cpp:244]     Train net output #3: loss = 0.505262 (* 1 = 0.505262 loss)
I0424 00:55:37.333086 30295 sgd_solver.cpp:106] Iteration 76100, lr = 2.7e-06
I0424 00:57:18.133756 30295 solver.cpp:228] Iteration 76200, loss = 2.65665
I0424 00:57:18.133929 30295 solver.cpp:244]     Train net output #0: loss = 0.963478 (* 1 = 0.963478 loss)
I0424 00:57:18.133935 30295 solver.cpp:244]     Train net output #1: loss = 0.352301 (* 1 = 0.352301 loss)
I0424 00:57:18.133939 30295 solver.cpp:244]     Train net output #2: loss = 0.872814 (* 1 = 0.872814 loss)
I0424 00:57:18.133944 30295 solver.cpp:244]     Train net output #3: loss = 0.468055 (* 1 = 0.468055 loss)
I0424 00:57:18.133950 30295 sgd_solver.cpp:106] Iteration 76200, lr = 2.7e-06
I0424 00:58:58.591549 30295 solver.cpp:228] Iteration 76300, loss = 2.98502
I0424 00:58:58.592625 30295 solver.cpp:244]     Train net output #0: loss = 0.982776 (* 1 = 0.982776 loss)
I0424 00:58:58.592633 30295 solver.cpp:244]     Train net output #1: loss = 0.519888 (* 1 = 0.519888 loss)
I0424 00:58:58.592638 30295 solver.cpp:244]     Train net output #2: loss = 0.933664 (* 1 = 0.933664 loss)
I0424 00:58:58.592643 30295 solver.cpp:244]     Train net output #3: loss = 0.548689 (* 1 = 0.548689 loss)
I0424 00:58:58.592648 30295 sgd_solver.cpp:106] Iteration 76300, lr = 2.7e-06
I0424 01:00:39.155886 30295 solver.cpp:228] Iteration 76400, loss = 2.88142
I0424 01:00:39.157127 30295 solver.cpp:244]     Train net output #0: loss = 0.987269 (* 1 = 0.987269 loss)
I0424 01:00:39.157150 30295 solver.cpp:244]     Train net output #1: loss = 0.690871 (* 1 = 0.690871 loss)
I0424 01:00:39.157155 30295 solver.cpp:244]     Train net output #2: loss = 0.728076 (* 1 = 0.728076 loss)
I0424 01:00:39.157160 30295 solver.cpp:244]     Train net output #3: loss = 0.475206 (* 1 = 0.475206 loss)
I0424 01:00:39.157165 30295 sgd_solver.cpp:106] Iteration 76400, lr = 2.7e-06
I0424 01:02:20.140996 30295 solver.cpp:228] Iteration 76500, loss = 2.76893
I0424 01:02:20.141188 30295 solver.cpp:244]     Train net output #0: loss = 0.98708 (* 1 = 0.98708 loss)
I0424 01:02:20.141196 30295 solver.cpp:244]     Train net output #1: loss = 0.676358 (* 1 = 0.676358 loss)
I0424 01:02:20.141202 30295 solver.cpp:244]     Train net output #2: loss = 0.577955 (* 1 = 0.577955 loss)
I0424 01:02:20.141206 30295 solver.cpp:244]     Train net output #3: loss = 0.527541 (* 1 = 0.527541 loss)
I0424 01:02:20.141212 30295 sgd_solver.cpp:106] Iteration 76500, lr = 2.7e-06
I0424 01:04:01.193779 30295 solver.cpp:228] Iteration 76600, loss = 3.32696
I0424 01:04:01.193927 30295 solver.cpp:244]     Train net output #0: loss = 0.969534 (* 1 = 0.969534 loss)
I0424 01:04:01.193934 30295 solver.cpp:244]     Train net output #1: loss = 0.752261 (* 1 = 0.752261 loss)
I0424 01:04:01.193938 30295 solver.cpp:244]     Train net output #2: loss = 0.909527 (* 1 = 0.909527 loss)
I0424 01:04:01.193943 30295 solver.cpp:244]     Train net output #3: loss = 0.695633 (* 1 = 0.695633 loss)
I0424 01:04:01.193949 30295 sgd_solver.cpp:106] Iteration 76600, lr = 2.7e-06
I0424 01:05:42.388625 30295 solver.cpp:228] Iteration 76700, loss = 3.31754
I0424 01:05:42.388809 30295 solver.cpp:244]     Train net output #0: loss = 0.974351 (* 1 = 0.974351 loss)
I0424 01:05:42.388816 30295 solver.cpp:244]     Train net output #1: loss = 0.768885 (* 1 = 0.768885 loss)
I0424 01:05:42.388823 30295 solver.cpp:244]     Train net output #2: loss = 0.92197 (* 1 = 0.92197 loss)
I0424 01:05:42.388826 30295 solver.cpp:244]     Train net output #3: loss = 0.652332 (* 1 = 0.652332 loss)
I0424 01:05:42.388831 30295 sgd_solver.cpp:106] Iteration 76700, lr = 2.7e-06
I0424 01:07:21.986570 30295 solver.cpp:228] Iteration 76800, loss = 3.19203
I0424 01:07:21.986730 30295 solver.cpp:244]     Train net output #0: loss = 0.977552 (* 1 = 0.977552 loss)
I0424 01:07:21.986737 30295 solver.cpp:244]     Train net output #1: loss = 0.7185 (* 1 = 0.7185 loss)
I0424 01:07:21.986742 30295 solver.cpp:244]     Train net output #2: loss = 0.882847 (* 1 = 0.882847 loss)
I0424 01:07:21.986747 30295 solver.cpp:244]     Train net output #3: loss = 0.613133 (* 1 = 0.613133 loss)
I0424 01:07:21.986752 30295 sgd_solver.cpp:106] Iteration 76800, lr = 2.7e-06
I0424 01:09:03.207811 30295 solver.cpp:228] Iteration 76900, loss = 3.04571
I0424 01:09:03.207947 30295 solver.cpp:244]     Train net output #0: loss = 0.972268 (* 1 = 0.972268 loss)
I0424 01:09:03.207953 30295 solver.cpp:244]     Train net output #1: loss = 0.610568 (* 1 = 0.610568 loss)
I0424 01:09:03.207959 30295 solver.cpp:244]     Train net output #2: loss = 0.889368 (* 1 = 0.889368 loss)
I0424 01:09:03.207963 30295 solver.cpp:244]     Train net output #3: loss = 0.573505 (* 1 = 0.573505 loss)
I0424 01:09:03.207968 30295 sgd_solver.cpp:106] Iteration 76900, lr = 2.7e-06
I0424 01:10:43.442905 30295 solver.cpp:337] Iteration 77000, Testing net (#0)
I0424 01:10:43.443049 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0424 01:10:43.443053 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0424 01:10:43.443056 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0424 01:10:43.443070 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0424 01:10:43.443075 30295 net.cpp:693] Ignoring source layer visualize
I0424 01:10:43.443078 30295 net.cpp:693] Ignoring source layer fake
I0424 01:14:21.824708 30295 solver.cpp:404]     Test net output #0: loss = 0.973737 (* 1 = 0.973737 loss)
I0424 01:14:21.824878 30295 solver.cpp:404]     Test net output #1: loss = 0.501315 (* 1 = 0.501315 loss)
I0424 01:14:21.824885 30295 solver.cpp:404]     Test net output #2: loss = 0.785208 (* 1 = 0.785208 loss)
I0424 01:14:21.824890 30295 solver.cpp:404]     Test net output #3: loss = 0.512638 (* 1 = 0.512638 loss)
I0424 01:14:22.484956 30295 solver.cpp:228] Iteration 77000, loss = 3.34452
I0424 01:14:22.484983 30295 solver.cpp:244]     Train net output #0: loss = 0.99068 (* 1 = 0.99068 loss)
I0424 01:14:22.484989 30295 solver.cpp:244]     Train net output #1: loss = 0.764327 (* 1 = 0.764327 loss)
I0424 01:14:22.484993 30295 solver.cpp:244]     Train net output #2: loss = 0.899603 (* 1 = 0.899603 loss)
I0424 01:14:22.484997 30295 solver.cpp:244]     Train net output #3: loss = 0.689909 (* 1 = 0.689909 loss)
I0424 01:14:22.485002 30295 sgd_solver.cpp:106] Iteration 77000, lr = 2.7e-06
I0424 01:16:03.599153 30295 solver.cpp:228] Iteration 77100, loss = 3.07863
I0424 01:16:03.599323 30295 solver.cpp:244]     Train net output #0: loss = 0.983037 (* 1 = 0.983037 loss)
I0424 01:16:03.599329 30295 solver.cpp:244]     Train net output #1: loss = 0.601925 (* 1 = 0.601925 loss)
I0424 01:16:03.599334 30295 solver.cpp:244]     Train net output #2: loss = 0.760292 (* 1 = 0.760292 loss)
I0424 01:16:03.599339 30295 solver.cpp:244]     Train net output #3: loss = 0.733372 (* 1 = 0.733372 loss)
I0424 01:16:03.599344 30295 sgd_solver.cpp:106] Iteration 77100, lr = 2.7e-06
I0424 01:17:42.992405 30295 solver.cpp:228] Iteration 77200, loss = 3.33306
I0424 01:17:42.992537 30295 solver.cpp:244]     Train net output #0: loss = 0.982024 (* 1 = 0.982024 loss)
I0424 01:17:42.992544 30295 solver.cpp:244]     Train net output #1: loss = 0.646625 (* 1 = 0.646625 loss)
I0424 01:17:42.992548 30295 solver.cpp:244]     Train net output #2: loss = 0.961838 (* 1 = 0.961838 loss)
I0424 01:17:42.992553 30295 solver.cpp:244]     Train net output #3: loss = 0.742572 (* 1 = 0.742572 loss)
I0424 01:17:42.992558 30295 sgd_solver.cpp:106] Iteration 77200, lr = 2.7e-06
I0424 01:19:24.029927 30295 solver.cpp:228] Iteration 77300, loss = 3.21682
I0424 01:19:24.030055 30295 solver.cpp:244]     Train net output #0: loss = 0.984277 (* 1 = 0.984277 loss)
I0424 01:19:24.030061 30295 solver.cpp:244]     Train net output #1: loss = 0.724265 (* 1 = 0.724265 loss)
I0424 01:19:24.030066 30295 solver.cpp:244]     Train net output #2: loss = 0.772209 (* 1 = 0.772209 loss)
I0424 01:19:24.030071 30295 solver.cpp:244]     Train net output #3: loss = 0.736067 (* 1 = 0.736067 loss)
I0424 01:19:24.030076 30295 sgd_solver.cpp:106] Iteration 77300, lr = 2.7e-06
I0424 01:21:04.889639 30295 solver.cpp:228] Iteration 77400, loss = 2.43107
I0424 01:21:04.889767 30295 solver.cpp:244]     Train net output #0: loss = 0.987291 (* 1 = 0.987291 loss)
I0424 01:21:04.889775 30295 solver.cpp:244]     Train net output #1: loss = 0.38486 (* 1 = 0.38486 loss)
I0424 01:21:04.889780 30295 solver.cpp:244]     Train net output #2: loss = 0.695887 (* 1 = 0.695887 loss)
I0424 01:21:04.889785 30295 solver.cpp:244]     Train net output #3: loss = 0.363028 (* 1 = 0.363028 loss)
I0424 01:21:04.889789 30295 sgd_solver.cpp:106] Iteration 77400, lr = 2.7e-06
I0424 01:22:45.564916 30295 solver.cpp:228] Iteration 77500, loss = 2.97802
I0424 01:22:45.565099 30295 solver.cpp:244]     Train net output #0: loss = 0.978917 (* 1 = 0.978917 loss)
I0424 01:22:45.565117 30295 solver.cpp:244]     Train net output #1: loss = 0.529413 (* 1 = 0.529413 loss)
I0424 01:22:45.565126 30295 solver.cpp:244]     Train net output #2: loss = 0.924226 (* 1 = 0.924226 loss)
I0424 01:22:45.565132 30295 solver.cpp:244]     Train net output #3: loss = 0.545465 (* 1 = 0.545465 loss)
I0424 01:22:45.565141 30295 sgd_solver.cpp:106] Iteration 77500, lr = 2.7e-06
I0424 01:24:26.055831 30295 solver.cpp:228] Iteration 77600, loss = 3.20566
I0424 01:24:26.055971 30295 solver.cpp:244]     Train net output #0: loss = 0.973375 (* 1 = 0.973375 loss)
I0424 01:24:26.055979 30295 solver.cpp:244]     Train net output #1: loss = 0.632762 (* 1 = 0.632762 loss)
I0424 01:24:26.055984 30295 solver.cpp:244]     Train net output #2: loss = 0.915181 (* 1 = 0.915181 loss)
I0424 01:24:26.055989 30295 solver.cpp:244]     Train net output #3: loss = 0.684337 (* 1 = 0.684337 loss)
I0424 01:24:26.055994 30295 sgd_solver.cpp:106] Iteration 77600, lr = 2.7e-06
I0424 01:26:06.099699 30295 solver.cpp:228] Iteration 77700, loss = 2.89288
I0424 01:26:06.099982 30295 solver.cpp:244]     Train net output #0: loss = 0.985724 (* 1 = 0.985724 loss)
I0424 01:26:06.099989 30295 solver.cpp:244]     Train net output #1: loss = 0.6189 (* 1 = 0.6189 loss)
I0424 01:26:06.099994 30295 solver.cpp:244]     Train net output #2: loss = 0.770874 (* 1 = 0.770874 loss)
I0424 01:26:06.099999 30295 solver.cpp:244]     Train net output #3: loss = 0.517386 (* 1 = 0.517386 loss)
I0424 01:26:06.100004 30295 sgd_solver.cpp:106] Iteration 77700, lr = 2.7e-06
I0424 01:27:46.299008 30295 solver.cpp:228] Iteration 77800, loss = 2.01363
I0424 01:27:46.299178 30295 solver.cpp:244]     Train net output #0: loss = 0.976487 (* 1 = 0.976487 loss)
I0424 01:27:46.299186 30295 solver.cpp:244]     Train net output #1: loss = 0.114432 (* 1 = 0.114432 loss)
I0424 01:27:46.299191 30295 solver.cpp:244]     Train net output #2: loss = 0.37025 (* 1 = 0.37025 loss)
I0424 01:27:46.299196 30295 solver.cpp:244]     Train net output #3: loss = 0.552465 (* 1 = 0.552465 loss)
I0424 01:27:46.299201 30295 sgd_solver.cpp:106] Iteration 77800, lr = 2.7e-06
I0424 01:29:24.658824 30295 solver.cpp:228] Iteration 77900, loss = 2.38042
I0424 01:29:24.658973 30295 solver.cpp:244]     Train net output #0: loss = 0.957092 (* 1 = 0.957092 loss)
I0424 01:29:24.658980 30295 solver.cpp:244]     Train net output #1: loss = 0.166764 (* 1 = 0.166764 loss)
I0424 01:29:24.658985 30295 solver.cpp:244]     Train net output #2: loss = 0.750498 (* 1 = 0.750498 loss)
I0424 01:29:24.658989 30295 solver.cpp:244]     Train net output #3: loss = 0.506065 (* 1 = 0.506065 loss)
I0424 01:29:24.658995 30295 sgd_solver.cpp:106] Iteration 77900, lr = 2.7e-06
I0424 01:31:03.675402 30295 solver.cpp:337] Iteration 78000, Testing net (#0)
I0424 01:31:03.675562 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0424 01:31:03.675566 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0424 01:31:03.675570 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0424 01:31:03.675585 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0424 01:31:03.675587 30295 net.cpp:693] Ignoring source layer visualize
I0424 01:31:03.675590 30295 net.cpp:693] Ignoring source layer fake
I0424 01:34:36.498471 30295 solver.cpp:404]     Test net output #0: loss = 0.96841 (* 1 = 0.96841 loss)
I0424 01:34:36.498623 30295 solver.cpp:404]     Test net output #1: loss = 0.471812 (* 1 = 0.471812 loss)
I0424 01:34:36.498630 30295 solver.cpp:404]     Test net output #2: loss = 0.81329 (* 1 = 0.81329 loss)
I0424 01:34:36.498634 30295 solver.cpp:404]     Test net output #3: loss = 0.543906 (* 1 = 0.543906 loss)
I0424 01:34:37.156623 30295 solver.cpp:228] Iteration 78000, loss = 3.30906
I0424 01:34:37.156666 30295 solver.cpp:244]     Train net output #0: loss = 0.978327 (* 1 = 0.978327 loss)
I0424 01:34:37.156671 30295 solver.cpp:244]     Train net output #1: loss = 0.750137 (* 1 = 0.750137 loss)
I0424 01:34:37.156675 30295 solver.cpp:244]     Train net output #2: loss = 0.926988 (* 1 = 0.926988 loss)
I0424 01:34:37.156679 30295 solver.cpp:244]     Train net output #3: loss = 0.65361 (* 1 = 0.65361 loss)
I0424 01:34:37.156683 30295 sgd_solver.cpp:106] Iteration 78000, lr = 2.7e-06
I0424 01:36:17.202801 30295 solver.cpp:228] Iteration 78100, loss = 3.29026
I0424 01:36:17.202965 30295 solver.cpp:244]     Train net output #0: loss = 0.98466 (* 1 = 0.98466 loss)
I0424 01:36:17.202971 30295 solver.cpp:244]     Train net output #1: loss = 0.759394 (* 1 = 0.759394 loss)
I0424 01:36:17.202976 30295 solver.cpp:244]     Train net output #2: loss = 0.916476 (* 1 = 0.916476 loss)
I0424 01:36:17.202980 30295 solver.cpp:244]     Train net output #3: loss = 0.629735 (* 1 = 0.629735 loss)
I0424 01:36:17.202986 30295 sgd_solver.cpp:106] Iteration 78100, lr = 2.7e-06
I0424 01:37:55.541074 30295 solver.cpp:228] Iteration 78200, loss = 3.1448
I0424 01:37:55.541245 30295 solver.cpp:244]     Train net output #0: loss = 0.975101 (* 1 = 0.975101 loss)
I0424 01:37:55.541254 30295 solver.cpp:244]     Train net output #1: loss = 0.654126 (* 1 = 0.654126 loss)
I0424 01:37:55.541259 30295 solver.cpp:244]     Train net output #2: loss = 0.867565 (* 1 = 0.867565 loss)
I0424 01:37:55.541262 30295 solver.cpp:244]     Train net output #3: loss = 0.648004 (* 1 = 0.648004 loss)
I0424 01:37:55.541267 30295 sgd_solver.cpp:106] Iteration 78200, lr = 2.7e-06
I0424 01:39:35.486944 30295 solver.cpp:228] Iteration 78300, loss = 3.36042
I0424 01:39:35.487124 30295 solver.cpp:244]     Train net output #0: loss = 0.990428 (* 1 = 0.990428 loss)
I0424 01:39:35.487131 30295 solver.cpp:244]     Train net output #1: loss = 0.775882 (* 1 = 0.775882 loss)
I0424 01:39:35.487136 30295 solver.cpp:244]     Train net output #2: loss = 0.893612 (* 1 = 0.893612 loss)
I0424 01:39:35.487140 30295 solver.cpp:244]     Train net output #3: loss = 0.7005 (* 1 = 0.7005 loss)
I0424 01:39:35.487146 30295 sgd_solver.cpp:106] Iteration 78300, lr = 2.7e-06
I0424 01:41:15.402686 30295 solver.cpp:228] Iteration 78400, loss = 3.43534
I0424 01:41:15.402827 30295 solver.cpp:244]     Train net output #0: loss = 0.988929 (* 1 = 0.988929 loss)
I0424 01:41:15.402834 30295 solver.cpp:244]     Train net output #1: loss = 0.734474 (* 1 = 0.734474 loss)
I0424 01:41:15.402840 30295 solver.cpp:244]     Train net output #2: loss = 0.963431 (* 1 = 0.963431 loss)
I0424 01:41:15.402844 30295 solver.cpp:244]     Train net output #3: loss = 0.748507 (* 1 = 0.748507 loss)
I0424 01:41:15.402849 30295 sgd_solver.cpp:106] Iteration 78400, lr = 2.7e-06
I0424 01:42:55.239585 30295 solver.cpp:228] Iteration 78500, loss = 2.82053
I0424 01:42:55.239730 30295 solver.cpp:244]     Train net output #0: loss = 0.985632 (* 1 = 0.985632 loss)
I0424 01:42:55.239738 30295 solver.cpp:244]     Train net output #1: loss = 0.562967 (* 1 = 0.562967 loss)
I0424 01:42:55.239742 30295 solver.cpp:244]     Train net output #2: loss = 0.743371 (* 1 = 0.743371 loss)
I0424 01:42:55.239747 30295 solver.cpp:244]     Train net output #3: loss = 0.528558 (* 1 = 0.528558 loss)
I0424 01:42:55.239753 30295 sgd_solver.cpp:106] Iteration 78500, lr = 2.7e-06
I0424 01:44:33.429278 30295 solver.cpp:228] Iteration 78600, loss = 3.02245
I0424 01:44:33.429412 30295 solver.cpp:244]     Train net output #0: loss = 0.988341 (* 1 = 0.988341 loss)
I0424 01:44:33.429419 30295 solver.cpp:244]     Train net output #1: loss = 0.638813 (* 1 = 0.638813 loss)
I0424 01:44:33.429425 30295 solver.cpp:244]     Train net output #2: loss = 0.769375 (* 1 = 0.769375 loss)
I0424 01:44:33.429428 30295 solver.cpp:244]     Train net output #3: loss = 0.625917 (* 1 = 0.625917 loss)
I0424 01:44:33.429441 30295 sgd_solver.cpp:106] Iteration 78600, lr = 2.7e-06
I0424 01:46:13.056622 30295 solver.cpp:228] Iteration 78700, loss = 2.68027
I0424 01:46:13.056751 30295 solver.cpp:244]     Train net output #0: loss = 0.92402 (* 1 = 0.92402 loss)
I0424 01:46:13.056757 30295 solver.cpp:244]     Train net output #1: loss = 0.377729 (* 1 = 0.377729 loss)
I0424 01:46:13.056762 30295 solver.cpp:244]     Train net output #2: loss = 0.865414 (* 1 = 0.865414 loss)
I0424 01:46:13.056766 30295 solver.cpp:244]     Train net output #3: loss = 0.513102 (* 1 = 0.513102 loss)
I0424 01:46:13.056772 30295 sgd_solver.cpp:106] Iteration 78700, lr = 2.7e-06
I0424 01:47:52.390162 30295 solver.cpp:228] Iteration 78800, loss = 3.14292
I0424 01:47:52.390306 30295 solver.cpp:244]     Train net output #0: loss = 0.981449 (* 1 = 0.981449 loss)
I0424 01:47:52.390314 30295 solver.cpp:244]     Train net output #1: loss = 0.638979 (* 1 = 0.638979 loss)
I0424 01:47:52.390319 30295 solver.cpp:244]     Train net output #2: loss = 0.946856 (* 1 = 0.946856 loss)
I0424 01:47:52.390323 30295 solver.cpp:244]     Train net output #3: loss = 0.575636 (* 1 = 0.575636 loss)
I0424 01:47:52.390328 30295 sgd_solver.cpp:106] Iteration 78800, lr = 2.7e-06
I0424 01:49:31.823550 30295 solver.cpp:228] Iteration 78900, loss = 2.94606
I0424 01:49:31.823720 30295 solver.cpp:244]     Train net output #0: loss = 0.960285 (* 1 = 0.960285 loss)
I0424 01:49:31.823729 30295 solver.cpp:244]     Train net output #1: loss = 0.58477 (* 1 = 0.58477 loss)
I0424 01:49:31.823734 30295 solver.cpp:244]     Train net output #2: loss = 0.749975 (* 1 = 0.749975 loss)
I0424 01:49:31.823737 30295 solver.cpp:244]     Train net output #3: loss = 0.65103 (* 1 = 0.65103 loss)
I0424 01:49:31.823743 30295 sgd_solver.cpp:106] Iteration 78900, lr = 2.7e-06
I0424 01:51:10.508488 30295 solver.cpp:337] Iteration 79000, Testing net (#0)
I0424 01:51:10.508633 30295 net.cpp:693] Ignoring source layer dropout_d3c
I0424 01:51:10.508637 30295 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0424 01:51:10.508642 30295 net.cpp:693] Ignoring source layer dropout_d4c
I0424 01:51:10.508656 30295 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0424 01:51:10.508659 30295 net.cpp:693] Ignoring source layer visualize
I0424 01:51:10.508661 30295 net.cpp:693] Ignoring source layer fake
I0424 01:54:43.588866 30295 solver.cpp:404]     Test net output #0: loss = 0.974261 (* 1 = 0.974261 loss)
I0424 01:54:43.588994 30295 solver.cpp:404]     Test net output #1: loss = 0.496361 (* 1 = 0.496361 loss)
I0424 01:54:43.588999 30295 solver.cpp:404]     Test net output #2: loss = 0.796467 (* 1 = 0.796467 loss)
I0424 01:54:43.589004 30295 solver.cpp:404]     Test net output #3: loss = 0.54097 (* 1 = 0.54097 loss)
I0424 01:54:44.244393 30295 solver.cpp:228] Iteration 79000, loss = 3.3205
I0424 01:54:44.244433 30295 solver.cpp:244]     Train net output #0: loss = 0.977278 (* 1 = 0.977278 loss)
I0424 01:54:44.244438 30295 solver.cpp:244]     Train net output #1: loss = 0.724641 (* 1 = 0.724641 loss)
I0424 01:54:44.244442 30295 solver.cpp:244]     Train net output #2: loss = 0.952322 (* 1 = 0.952322 loss)
I0424 01:54:44.244446 30295 solver.cpp:244]     Train net output #3: loss = 0.66626 (* 1 = 0.66626 loss)
I0424 01:54:44.244451 30295 sgd_solver.cpp:106] Iteration 79000, lr = 2.7e-06
I0424 01:56:24.088507 30295 solver.cpp:228] Iteration 79100, loss = 3.12999
I0424 01:56:24.088650 30295 solver.cpp:244]     Train net output #0: loss = 0.964201 (* 1 = 0.964201 loss)
I0424 01:56:24.088657 30295 solver.cpp:244]     Train net output #1: loss = 0.53644 (* 1 = 0.53644 loss)
I0424 01:56:24.088662 30295 solver.cpp:244]     Train net output #2: loss = 0.933564 (* 1 = 0.933564 loss)
I0424 01:56:24.088666 30295 solver.cpp:244]     Train net output #3: loss = 0.695784 (* 1 = 0.695784 loss)
I0424 01:56:24.088671 30295 sgd_solver.cpp:106] Iteration 79100, lr = 2.7e-06
I0424 01:58:04.010884 30295 solver.cpp:228] Iteration 79200, loss = 3.33613
I0424 01:58:04.011041 30295 solver.cpp:244]     Train net output #0: loss = 0.981803 (* 1 = 0.981803 loss)
I0424 01:58:04.011049 30295 solver.cpp:244]     Train net output #1: loss = 0.830166 (* 1 = 0.830166 loss)
I0424 01:58:04.011052 30295 solver.cpp:244]     Train net output #2: loss = 0.885263 (* 1 = 0.885263 loss)
I0424 01:58:04.011059 30295 solver.cpp:244]     Train net output #3: loss = 0.638896 (* 1 = 0.638896 loss)
I0424 01:58:04.011063 30295 sgd_solver.cpp:106] Iteration 79200, lr = 2.7e-06
I0424 01:59:42.382467 30295 solver.cpp:228] Iteration 79300, loss = 3.25323
I0424 01:59:42.382624 30295 solver.cpp:244]     Train net output #0: loss = 0.985897 (* 1 = 0.985897 loss)
I0424 01:59:42.382632 30295 solver.cpp:244]     Train net output #1: loss = 0.695035 (* 1 = 0.695035 loss)
I0424 01:59:42.382637 30295 solver.cpp:244]     Train net output #2: loss = 0.867208 (* 1 = 0.867208 loss)
I0424 01:59:42.382642 30295 solver.cpp:244]     Train net output #3: loss = 0.705094 (* 1 = 0.705094 loss)
I0424 01:59:42.382648 30295 sgd_solver.cpp:106] Iteration 79300, lr = 2.7e-06
I0424 02:01:22.312831 30295 solver.cpp:228] Iteration 79400, loss = 3.24171
I0424 02:01:22.313011 30295 solver.cpp:244]     Train net output #0: loss = 0.978269 (* 1 = 0.978269 loss)
I0424 02:01:22.313019 30295 solver.cpp:244]     Train net output #1: loss = 0.657904 (* 1 = 0.657904 loss)
I0424 02:01:22.313024 30295 solver.cpp:244]     Train net output #2: loss = 0.916312 (* 1 = 0.916312 loss)
I0424 02:01:22.313029 30295 solver.cpp:244]     Train net output #3: loss = 0.689229 (* 1 = 0.689229 loss)
I0424 02:01:22.313033 30295 sgd_solver.cpp:106] Iteration 79400, lr = 2.7e-06
I0424 02:03:02.224912 30295 solver.cpp:228] Iteration 79500, loss = 3.09015
I0424 02:03:02.225052 30295 solver.cpp:244]     Train net output #0: loss = 0.986462 (* 1 = 0.986462 loss)
I0424 02:03:02.225060 30295 solver.cpp:244]     Train net output #1: loss = 0.587951 (* 1 = 0.587951 loss)
I0424 02:03:02.225065 30295 solver.cpp:244]     Train net output #2: loss = 0.910454 (* 1 = 0.910454 loss)
I0424 02:03:02.225070 30295 solver.cpp:244]     Train net output #3: loss = 0.605279 (* 1 = 0.605279 loss)
I0424 02:03:02.225075 30295 sgd_solver.cpp:106] Iteration 79500, lr = 2.7e-06
I0424 02:04:42.123576 30295 solver.cpp:228] Iteration 79600, loss = 3.26129
I0424 02:04:42.123720 30295 solver.cpp:244]     Train net output #0: loss = 0.982737 (* 1 = 0.982737 loss)
I0424 02:04:42.123728 30295 solver.cpp:244]     Train net output #1: loss = 0.729675 (* 1 = 0.729675 loss)
I0424 02:04:42.123733 30295 solver.cpp:244]     Train net output #2: loss = 0.939021 (* 1 = 0.939021 loss)
I0424 02:04:42.123738 30295 solver.cpp:244]     Train net output #3: loss = 0.609854 (* 1 = 0.609854 loss)
I0424 02:04:42.123742 30295 sgd_solver.cpp:106] Iteration 79600, lr = 2.7e-06
I0424 02:06:20.393128 30295 solver.cpp:228] Iteration 79700, loss = 3.28611
I0424 02:06:20.393280 30295 solver.cpp:244]     Train net output #0: loss = 0.989003 (* 1 = 0.989003 loss)
I0424 02:06:20.393288 30295 solver.cpp:244]     Train net output #1: loss = 0.75206 (* 1 = 0.75206 loss)
I0424 02:06:20.393293 30295 solver.cpp:244]     Train net output #2: loss = 0.921429 (* 1 = 0.921429 loss)
I0424 02:06:20.393297 30295 solver.cpp:244]     Train net output #3: loss = 0.623619 (* 1 = 0.623619 loss)
I0424 02:06:20.393302 30295 sgd_solver.cpp:106] Iteration 79700, lr = 2.7e-06
I0424 02:08:00.218315 30295 solver.cpp:228] Iteration 79800, loss = 3.17416
I0424 02:08:00.218472 30295 solver.cpp:244]     Train net output #0: loss = 0.980404 (* 1 = 0.980404 loss)
I0424 02:08:00.218478 30295 solver.cpp:244]     Train net output #1: loss = 0.663541 (* 1 = 0.663541 loss)
I0424 02:08:00.218483 30295 solver.cpp:244]     Train net output #2: loss = 0.864841 (* 1 = 0.864841 loss)
I0424 02:08:00.218488 30295 solver.cpp:244]     Train net output #3: loss = 0.665378 (* 1 = 0.665378 loss)
I0424 02:08:00.218494 30295 sgd_solver.cpp:106] Iteration 79800, lr = 2.7e-06
I0424 02:09:39.946754 30295 solver.cpp:228] Iteration 79900, loss = 2.96382
I0424 02:09:39.947932 30295 solver.cpp:244]     Train net output #0: loss = 0.985269 (* 1 = 0.985269 loss)
I0424 02:09:39.947939 30295 solver.cpp:244]     Train net output #1: loss = 0.533037 (* 1 = 0.533037 loss)
I0424 02:09:39.947944 30295 solver.cpp:244]     Train net output #2: loss = 0.878898 (* 1 = 0.878898 loss)
I0424 02:09:39.947948 30295 solver.cpp:244]     Train net output #3: loss = 0.566613 (* 1 = 0.566613 loss)
I0424 02:09:39.947952 30295 sgd_solver.cpp:106] Iteration 79900, lr = 2.7e-06
I0424 02:11:18.310477 30295 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_80000.caffemodel
I0424 02:11:21.550503 30295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_4/unet_f1_4_iter_80000.solverstate
