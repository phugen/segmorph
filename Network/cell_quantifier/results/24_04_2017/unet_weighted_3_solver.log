I0421 20:12:20.992017  6613 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3456
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.99
stepsize: 20000
snapshot: 5000
snapshot_prefix: "./snapshots/unet_weighted_3/unet_weighted_3"
solver_mode: GPU
net: "./unet_weighted_3/unet_weighted_3.prototxt"
regularization_type: "L2"
test_initialization: true
iter_size: 1
I0421 20:12:20.992233  6613 solver.cpp:91] Creating training net from net file: ./unet_weighted_3/unet_weighted_3.prototxt
I0421 20:12:20.992691  6613 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer loaddata
I0421 20:12:20.993247  6613 net.cpp:58] Initializing net from parameters: 
name: "unet_weighted_3"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  top: "weights"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "caffeHDF5_3.txt"
    batch_size: 5
  }
}
layer {
  name: "conv_d0a-b"
  type: "Convolution"
  bottom: "data"
  top: "d0b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0b"
  type: "ReLU"
  bottom: "d0b"
  top: "d0b"
}
layer {
  name: "conv_d0b-c"
  type: "Convolution"
  bottom: "d0b"
  top: "d0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0c"
  type: "ReLU"
  bottom: "d0c"
  top: "d0c"
}
layer {
  name: "pool_d0c-1a"
  type: "Pooling"
  bottom: "d0c"
  top: "d1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d1a-b"
  type: "Convolution"
  bottom: "d1a"
  top: "d1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1b"
  type: "ReLU"
  bottom: "d1b"
  top: "d1b"
}
layer {
  name: "conv_d1b-c"
  type: "Convolution"
  bottom: "d1b"
  top: "d1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1c"
  type: "ReLU"
  bottom: "d1c"
  top: "d1c"
}
layer {
  name: "pool_d1c-2a"
  type: "Pooling"
  bottom: "d1c"
  top: "d2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d2a-b"
  type: "Convolution"
  bottom: "d2a"
  top: "d2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2b"
  type: "ReLU"
  bottom: "d2b"
  top: "d2b"
}
layer {
  name: "conv_d2b-c"
  type: "Convolution"
  bottom: "d2b"
  top: "d2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2c"
  type: "ReLU"
  bottom: "d2c"
  top: "d2c"
}
layer {
  name: "pool_d2c-3a"
  type: "Pooling"
  bottom: "d2c"
  top: "d3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d3a-b"
  type: "Convolution"
  bottom: "d3a"
  top: "d3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3b"
  type: "ReLU"
  bottom: "d3b"
  top: "d3b"
}
layer {
  name: "conv_d3b-c"
  type: "Convolution"
  bottom: "d3b"
  top: "d3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3c"
  type: "ReLU"
  bottom: "d3c"
  top: "d3c"
}
layer {
  name: "dropout_d3c"
  type: "Dropout"
  bottom: "d3c"
  top: "d3c"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool_d3c-4a"
  type: "Pooling"
  bottom: "d3c"
  top: "d4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d4a-b"
  type: "Convolution"
  bottom: "d4a"
  top: "d4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4b"
  type: "ReLU"
  bottom: "d4b"
  top: "d4b"
}
layer {
  name: "conv_d4b-c"
  type: "Convolution"
  bottom: "d4b"
  top: "d4c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4c"
  type: "ReLU"
  bottom: "d4c"
  top: "d4c"
}
layer {
  name: "dropout_d4c"
  type: "Dropout"
  bottom: "d4c"
  top: "d4c"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upconv_d4c_u3a"
  type: "Deconvolution"
  bottom: "d4c"
  top: "u3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u3a"
  type: "ReLU"
  bottom: "u3a"
  top: "u3a"
}
layer {
  name: "crop_d3c-d3cc"
  type: "Crop"
  bottom: "d3c"
  bottom: "u3a"
  top: "d3cc"
  crop_param {
    axis: 2
    offset: 4
  }
}
layer {
  name: "concat_d3cc_u3a-b"
  type: "Concat"
  bottom: "u3a"
  bottom: "d3cc"
  top: "u3b"
}
layer {
  name: "conv_u3b-c"
  type: "Convolution"
  bottom: "u3b"
  top: "u3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3c"
  type: "ReLU"
  bottom: "u3c"
  top: "u3c"
}
layer {
  name: "conv_u3c-d"
  type: "Convolution"
  bottom: "u3c"
  top: "u3d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3d"
  type: "ReLU"
  bottom: "u3d"
  top: "u3d"
}
layer {
  name: "upconv_u3d_u2a"
  type: "Deconvolution"
  bottom: "u3d"
  top: "u2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u2a"
  type: "ReLU"
  bottom: "u2a"
  top: "u2a"
}
layer {
  name: "crop_d2c-d2cc"
  type: "Crop"
  bottom: "d2c"
  bottom: "u2a"
  top: "d2cc"
  crop_param {
    axis: 2
    offset: 16
  }
}
layer {
  name: "concat_d2cc_u2a-b"
  type: "Concat"
  bottom: "u2a"
  bottom: "d2cc"
  top: "u2b"
}
layer {
  name: "conv_u2b-c"
  type: "Convolution"
  bottom: "u2b"
  top: "u2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2c"
  type: "ReLU"
  bottom: "u2c"
  top: "u2c"
}
layer {
  name: "conv_u2c-d"
  type: "Convolution"
  bottom: "u2c"
  top: "u2d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2d"
  type: "ReLU"
  bottom: "u2d"
  top: "u2d"
}
layer {
  name: "upconv_u2d_u1a"
  type: "Deconvolution"
  bottom: "u2d"
  top: "u1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u1a"
  type: "ReLU"
  bottom: "u1a"
  top: "u1a"
}
layer {
  name: "crop_d1c-d1cc"
  type: "Crop"
  bottom: "d1c"
  bottom: "u1a"
  top: "d1cc"
  crop_param {
    axis: 2
    offset: 40
  }
}
layer {
  name: "concat_d1cc_u1a-b"
  type: "Concat"
  bottom: "u1a"
  bottom: "d1cc"
  top: "u1b"
}
layer {
  name: "conv_u1b-c"
  type: "Convolution"
  bottom: "u1b"
  top: "u1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1c"
  type: "ReLU"
  bottom: "u1c"
  top: "u1c"
}
layer {
  name: "conv_u1c-d"
  type: "Convolution"
  bottom: "u1c"
  top: "u1d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1d"
  type: "ReLU"
  bottom: "u1d"
  top: "u1d"
}
layer {
  name: "upconv_u1d_u0a"
  type: "Deconvolution"
  bottom: "u1d"
  top: "u0a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u0a"
  type: "ReLU"
  bottom: "u0a"
  top: "u0a"
}
layer {
  name: "crop_d0c-d0cc"
  type: "Crop"
  bottom: "d0c"
  bottom: "u0a"
  top: "d0cc"
  crop_param {
    axis: 2
    offset: 88
  }
}
layer {
  name: "concat_d0cc_u0a-b"
  type: "Concat"
  bottom: "u0a"
  bottom: "d0cc"
  top: "u0b"
}
layer {
  name: "conv_u0b-c"
  type: "Convolution"
  bottom: "u0b"
  top: "u0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0c"
  type: "ReLU"
  bottom: "u0c"
  top: "u0c"
}
layer {
  name: "conv_u0c-d"
  type: "Convolution"
  bottom: "u0c"
  top: "u0d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0d"
  type: "ReLU"
  bottom: "u0d"
  top: "u0d"
}
layer {
  name: "conv_u0d-score"
  type: "Convolution"
  bottom: "u0d"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  bottom: "weights"
  top: "loss"
  loss_weight: 1
}
layer {
  name: "visualize"
  type: "Softmax"
  bottom: "score"
  top: "visualize_out"
  include {
    phase: TRAIN
  }
}
layer {
  name: "fake"
  type: "Silence"
  bottom: "visualize_out"
  include {
    phase: TRAIN
  }
}
I0421 20:12:20.993567  6613 layer_factory.hpp:77] Creating layer loaddata
I0421 20:12:20.993579  6613 net.cpp:100] Creating Layer loaddata
I0421 20:12:20.993583  6613 net.cpp:408] loaddata -> data
I0421 20:12:20.993592  6613 net.cpp:408] loaddata -> label
I0421 20:12:20.993597  6613 net.cpp:408] loaddata -> weights
I0421 20:12:20.993607  6613 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: caffeHDF5_3.txt
I0421 20:12:20.993635  6613 hdf5_data_layer.cpp:93] Number of HDF5 files: 20
I0421 20:12:20.994560  6613 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0421 20:12:21.928633  6613 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0421 20:12:22.141600  6613 net.cpp:150] Setting up loaddata
I0421 20:12:22.141641  6613 net.cpp:157] Top shape: 5 3 428 428 (2747760)
I0421 20:12:22.141646  6613 net.cpp:157] Top shape: 5 244 244 (297680)
I0421 20:12:22.141649  6613 net.cpp:157] Top shape: 5 244 244 (297680)
I0421 20:12:22.141652  6613 net.cpp:165] Memory required for data: 13372480
I0421 20:12:22.141657  6613 layer_factory.hpp:77] Creating layer conv_d0a-b
I0421 20:12:22.141674  6613 net.cpp:100] Creating Layer conv_d0a-b
I0421 20:12:22.141679  6613 net.cpp:434] conv_d0a-b <- data
I0421 20:12:22.141685  6613 net.cpp:408] conv_d0a-b -> d0b
I0421 20:12:22.144137  6613 net.cpp:150] Setting up conv_d0a-b
I0421 20:12:22.144150  6613 net.cpp:157] Top shape: 5 64 426 426 (58072320)
I0421 20:12:22.144170  6613 net.cpp:165] Memory required for data: 245661760
I0421 20:12:22.144179  6613 layer_factory.hpp:77] Creating layer relu_d0b
I0421 20:12:22.144186  6613 net.cpp:100] Creating Layer relu_d0b
I0421 20:12:22.144188  6613 net.cpp:434] relu_d0b <- d0b
I0421 20:12:22.144192  6613 net.cpp:395] relu_d0b -> d0b (in-place)
I0421 20:12:22.636473  6613 net.cpp:150] Setting up relu_d0b
I0421 20:12:22.636512  6613 net.cpp:157] Top shape: 5 64 426 426 (58072320)
I0421 20:12:22.636515  6613 net.cpp:165] Memory required for data: 477951040
I0421 20:12:22.636519  6613 layer_factory.hpp:77] Creating layer conv_d0b-c
I0421 20:12:22.636534  6613 net.cpp:100] Creating Layer conv_d0b-c
I0421 20:12:22.636538  6613 net.cpp:434] conv_d0b-c <- d0b
I0421 20:12:22.636545  6613 net.cpp:408] conv_d0b-c -> d0c
I0421 20:12:22.638165  6613 net.cpp:150] Setting up conv_d0b-c
I0421 20:12:22.638180  6613 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0421 20:12:22.638183  6613 net.cpp:165] Memory required for data: 708064320
I0421 20:12:22.638208  6613 layer_factory.hpp:77] Creating layer relu_d0c
I0421 20:12:22.638217  6613 net.cpp:100] Creating Layer relu_d0c
I0421 20:12:22.638221  6613 net.cpp:434] relu_d0c <- d0c
I0421 20:12:22.638226  6613 net.cpp:395] relu_d0c -> d0c (in-place)
I0421 20:12:22.639009  6613 net.cpp:150] Setting up relu_d0c
I0421 20:12:22.639021  6613 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0421 20:12:22.639024  6613 net.cpp:165] Memory required for data: 938177600
I0421 20:12:22.639044  6613 layer_factory.hpp:77] Creating layer d0c_relu_d0c_0_split
I0421 20:12:22.639048  6613 net.cpp:100] Creating Layer d0c_relu_d0c_0_split
I0421 20:12:22.639050  6613 net.cpp:434] d0c_relu_d0c_0_split <- d0c
I0421 20:12:22.639055  6613 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_0
I0421 20:12:22.639061  6613 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_1
I0421 20:12:22.639113  6613 net.cpp:150] Setting up d0c_relu_d0c_0_split
I0421 20:12:22.639134  6613 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0421 20:12:22.639139  6613 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0421 20:12:22.639142  6613 net.cpp:165] Memory required for data: 1398404160
I0421 20:12:22.639143  6613 layer_factory.hpp:77] Creating layer pool_d0c-1a
I0421 20:12:22.639149  6613 net.cpp:100] Creating Layer pool_d0c-1a
I0421 20:12:22.639153  6613 net.cpp:434] pool_d0c-1a <- d0c_relu_d0c_0_split_0
I0421 20:12:22.639158  6613 net.cpp:408] pool_d0c-1a -> d1a
I0421 20:12:22.639189  6613 net.cpp:150] Setting up pool_d0c-1a
I0421 20:12:22.639195  6613 net.cpp:157] Top shape: 5 64 212 212 (14382080)
I0421 20:12:22.639199  6613 net.cpp:165] Memory required for data: 1455932480
I0421 20:12:22.639200  6613 layer_factory.hpp:77] Creating layer conv_d1a-b
I0421 20:12:22.639207  6613 net.cpp:100] Creating Layer conv_d1a-b
I0421 20:12:22.639210  6613 net.cpp:434] conv_d1a-b <- d1a
I0421 20:12:22.639215  6613 net.cpp:408] conv_d1a-b -> d1b
I0421 20:12:22.639910  6613 net.cpp:150] Setting up conv_d1a-b
I0421 20:12:22.639919  6613 net.cpp:157] Top shape: 5 128 210 210 (28224000)
I0421 20:12:22.639920  6613 net.cpp:165] Memory required for data: 1568828480
I0421 20:12:22.639943  6613 layer_factory.hpp:77] Creating layer relu_d1b
I0421 20:12:22.639967  6613 net.cpp:100] Creating Layer relu_d1b
I0421 20:12:22.639986  6613 net.cpp:434] relu_d1b <- d1b
I0421 20:12:22.639991  6613 net.cpp:395] relu_d1b -> d1b (in-place)
I0421 20:12:22.640156  6613 net.cpp:150] Setting up relu_d1b
I0421 20:12:22.640166  6613 net.cpp:157] Top shape: 5 128 210 210 (28224000)
I0421 20:12:22.640167  6613 net.cpp:165] Memory required for data: 1681724480
I0421 20:12:22.640171  6613 layer_factory.hpp:77] Creating layer conv_d1b-c
I0421 20:12:22.640178  6613 net.cpp:100] Creating Layer conv_d1b-c
I0421 20:12:22.640180  6613 net.cpp:434] conv_d1b-c <- d1b
I0421 20:12:22.640185  6613 net.cpp:408] conv_d1b-c -> d1c
I0421 20:12:22.642242  6613 net.cpp:150] Setting up conv_d1b-c
I0421 20:12:22.642273  6613 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0421 20:12:22.642277  6613 net.cpp:165] Memory required for data: 1792480320
I0421 20:12:22.642282  6613 layer_factory.hpp:77] Creating layer relu_d1c
I0421 20:12:22.642287  6613 net.cpp:100] Creating Layer relu_d1c
I0421 20:12:22.642292  6613 net.cpp:434] relu_d1c <- d1c
I0421 20:12:22.642295  6613 net.cpp:395] relu_d1c -> d1c (in-place)
I0421 20:12:22.642467  6613 net.cpp:150] Setting up relu_d1c
I0421 20:12:22.642475  6613 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0421 20:12:22.642479  6613 net.cpp:165] Memory required for data: 1903236160
I0421 20:12:22.642482  6613 layer_factory.hpp:77] Creating layer d1c_relu_d1c_0_split
I0421 20:12:22.642488  6613 net.cpp:100] Creating Layer d1c_relu_d1c_0_split
I0421 20:12:22.642489  6613 net.cpp:434] d1c_relu_d1c_0_split <- d1c
I0421 20:12:22.642494  6613 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_0
I0421 20:12:22.642500  6613 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_1
I0421 20:12:22.642535  6613 net.cpp:150] Setting up d1c_relu_d1c_0_split
I0421 20:12:22.642540  6613 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0421 20:12:22.642544  6613 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0421 20:12:22.642546  6613 net.cpp:165] Memory required for data: 2124747840
I0421 20:12:22.642549  6613 layer_factory.hpp:77] Creating layer pool_d1c-2a
I0421 20:12:22.642554  6613 net.cpp:100] Creating Layer pool_d1c-2a
I0421 20:12:22.642556  6613 net.cpp:434] pool_d1c-2a <- d1c_relu_d1c_0_split_0
I0421 20:12:22.642560  6613 net.cpp:408] pool_d1c-2a -> d2a
I0421 20:12:22.642588  6613 net.cpp:150] Setting up pool_d1c-2a
I0421 20:12:22.642592  6613 net.cpp:157] Top shape: 5 128 104 104 (6922240)
I0421 20:12:22.642596  6613 net.cpp:165] Memory required for data: 2152436800
I0421 20:12:22.642598  6613 layer_factory.hpp:77] Creating layer conv_d2a-b
I0421 20:12:22.642604  6613 net.cpp:100] Creating Layer conv_d2a-b
I0421 20:12:22.642607  6613 net.cpp:434] conv_d2a-b <- d2a
I0421 20:12:22.642612  6613 net.cpp:408] conv_d2a-b -> d2b
I0421 20:12:22.645318  6613 net.cpp:150] Setting up conv_d2a-b
I0421 20:12:22.645329  6613 net.cpp:157] Top shape: 5 256 102 102 (13317120)
I0421 20:12:22.645332  6613 net.cpp:165] Memory required for data: 2205705280
I0421 20:12:22.645352  6613 layer_factory.hpp:77] Creating layer relu_d2b
I0421 20:12:22.645359  6613 net.cpp:100] Creating Layer relu_d2b
I0421 20:12:22.645361  6613 net.cpp:434] relu_d2b <- d2b
I0421 20:12:22.645365  6613 net.cpp:395] relu_d2b -> d2b (in-place)
I0421 20:12:22.645553  6613 net.cpp:150] Setting up relu_d2b
I0421 20:12:22.645563  6613 net.cpp:157] Top shape: 5 256 102 102 (13317120)
I0421 20:12:22.645565  6613 net.cpp:165] Memory required for data: 2258973760
I0421 20:12:22.645568  6613 layer_factory.hpp:77] Creating layer conv_d2b-c
I0421 20:12:22.645576  6613 net.cpp:100] Creating Layer conv_d2b-c
I0421 20:12:22.645579  6613 net.cpp:434] conv_d2b-c <- d2b
I0421 20:12:22.645584  6613 net.cpp:408] conv_d2b-c -> d2c
I0421 20:12:22.649909  6613 net.cpp:150] Setting up conv_d2b-c
I0421 20:12:22.649921  6613 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0421 20:12:22.649924  6613 net.cpp:165] Memory required for data: 2310173760
I0421 20:12:22.649945  6613 layer_factory.hpp:77] Creating layer relu_d2c
I0421 20:12:22.649983  6613 net.cpp:100] Creating Layer relu_d2c
I0421 20:12:22.649987  6613 net.cpp:434] relu_d2c <- d2c
I0421 20:12:22.649992  6613 net.cpp:395] relu_d2c -> d2c (in-place)
I0421 20:12:22.650709  6613 net.cpp:150] Setting up relu_d2c
I0421 20:12:22.650720  6613 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0421 20:12:22.650723  6613 net.cpp:165] Memory required for data: 2361373760
I0421 20:12:22.650743  6613 layer_factory.hpp:77] Creating layer d2c_relu_d2c_0_split
I0421 20:12:22.650748  6613 net.cpp:100] Creating Layer d2c_relu_d2c_0_split
I0421 20:12:22.650750  6613 net.cpp:434] d2c_relu_d2c_0_split <- d2c
I0421 20:12:22.650760  6613 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_0
I0421 20:12:22.650766  6613 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_1
I0421 20:12:22.650820  6613 net.cpp:150] Setting up d2c_relu_d2c_0_split
I0421 20:12:22.650827  6613 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0421 20:12:22.650847  6613 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0421 20:12:22.650849  6613 net.cpp:165] Memory required for data: 2463773760
I0421 20:12:22.650852  6613 layer_factory.hpp:77] Creating layer pool_d2c-3a
I0421 20:12:22.650857  6613 net.cpp:100] Creating Layer pool_d2c-3a
I0421 20:12:22.650861  6613 net.cpp:434] pool_d2c-3a <- d2c_relu_d2c_0_split_0
I0421 20:12:22.650864  6613 net.cpp:408] pool_d2c-3a -> d3a
I0421 20:12:22.650897  6613 net.cpp:150] Setting up pool_d2c-3a
I0421 20:12:22.650902  6613 net.cpp:157] Top shape: 5 256 50 50 (3200000)
I0421 20:12:22.650905  6613 net.cpp:165] Memory required for data: 2476573760
I0421 20:12:22.650907  6613 layer_factory.hpp:77] Creating layer conv_d3a-b
I0421 20:12:22.650916  6613 net.cpp:100] Creating Layer conv_d3a-b
I0421 20:12:22.650919  6613 net.cpp:434] conv_d3a-b <- d3a
I0421 20:12:22.650924  6613 net.cpp:408] conv_d3a-b -> d3b
I0421 20:12:22.660017  6613 net.cpp:150] Setting up conv_d3a-b
I0421 20:12:22.660029  6613 net.cpp:157] Top shape: 5 512 48 48 (5898240)
I0421 20:12:22.660048  6613 net.cpp:165] Memory required for data: 2500166720
I0421 20:12:22.660054  6613 layer_factory.hpp:77] Creating layer relu_d3b
I0421 20:12:22.660060  6613 net.cpp:100] Creating Layer relu_d3b
I0421 20:12:22.660063  6613 net.cpp:434] relu_d3b <- d3b
I0421 20:12:22.660068  6613 net.cpp:395] relu_d3b -> d3b (in-place)
I0421 20:12:22.660284  6613 net.cpp:150] Setting up relu_d3b
I0421 20:12:22.660293  6613 net.cpp:157] Top shape: 5 512 48 48 (5898240)
I0421 20:12:22.660296  6613 net.cpp:165] Memory required for data: 2523759680
I0421 20:12:22.660298  6613 layer_factory.hpp:77] Creating layer conv_d3b-c
I0421 20:12:22.660307  6613 net.cpp:100] Creating Layer conv_d3b-c
I0421 20:12:22.660310  6613 net.cpp:434] conv_d3b-c <- d3b
I0421 20:12:22.660316  6613 net.cpp:408] conv_d3b-c -> d3c
I0421 20:12:22.675648  6613 net.cpp:150] Setting up conv_d3b-c
I0421 20:12:22.675662  6613 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0421 20:12:22.675679  6613 net.cpp:165] Memory required for data: 2545427520
I0421 20:12:22.675684  6613 layer_factory.hpp:77] Creating layer relu_d3c
I0421 20:12:22.675691  6613 net.cpp:100] Creating Layer relu_d3c
I0421 20:12:22.675694  6613 net.cpp:434] relu_d3c <- d3c
I0421 20:12:22.675698  6613 net.cpp:395] relu_d3c -> d3c (in-place)
I0421 20:12:22.675915  6613 net.cpp:150] Setting up relu_d3c
I0421 20:12:22.675925  6613 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0421 20:12:22.675928  6613 net.cpp:165] Memory required for data: 2567095360
I0421 20:12:22.675931  6613 layer_factory.hpp:77] Creating layer dropout_d3c
I0421 20:12:22.675937  6613 net.cpp:100] Creating Layer dropout_d3c
I0421 20:12:22.675940  6613 net.cpp:434] dropout_d3c <- d3c
I0421 20:12:22.675945  6613 net.cpp:395] dropout_d3c -> d3c (in-place)
I0421 20:12:22.675972  6613 net.cpp:150] Setting up dropout_d3c
I0421 20:12:22.675979  6613 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0421 20:12:22.675981  6613 net.cpp:165] Memory required for data: 2588763200
I0421 20:12:22.675984  6613 layer_factory.hpp:77] Creating layer d3c_dropout_d3c_0_split
I0421 20:12:22.676007  6613 net.cpp:100] Creating Layer d3c_dropout_d3c_0_split
I0421 20:12:22.676020  6613 net.cpp:434] d3c_dropout_d3c_0_split <- d3c
I0421 20:12:22.676024  6613 net.cpp:408] d3c_dropout_d3c_0_split -> d3c_dropout_d3c_0_split_0
I0421 20:12:22.676031  6613 net.cpp:408] d3c_dropout_d3c_0_split -> d3c_dropout_d3c_0_split_1
I0421 20:12:22.676070  6613 net.cpp:150] Setting up d3c_dropout_d3c_0_split
I0421 20:12:22.676077  6613 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0421 20:12:22.676080  6613 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0421 20:12:22.676084  6613 net.cpp:165] Memory required for data: 2632098880
I0421 20:12:22.676085  6613 layer_factory.hpp:77] Creating layer pool_d3c-4a
I0421 20:12:22.676092  6613 net.cpp:100] Creating Layer pool_d3c-4a
I0421 20:12:22.676095  6613 net.cpp:434] pool_d3c-4a <- d3c_dropout_d3c_0_split_0
I0421 20:12:22.676100  6613 net.cpp:408] pool_d3c-4a -> d4a
I0421 20:12:22.676136  6613 net.cpp:150] Setting up pool_d3c-4a
I0421 20:12:22.676141  6613 net.cpp:157] Top shape: 5 512 23 23 (1354240)
I0421 20:12:22.676143  6613 net.cpp:165] Memory required for data: 2637515840
I0421 20:12:22.676146  6613 layer_factory.hpp:77] Creating layer conv_d4a-b
I0421 20:12:22.676156  6613 net.cpp:100] Creating Layer conv_d4a-b
I0421 20:12:22.676158  6613 net.cpp:434] conv_d4a-b <- d4a
I0421 20:12:22.676162  6613 net.cpp:408] conv_d4a-b -> d4b
I0421 20:12:22.706478  6613 net.cpp:150] Setting up conv_d4a-b
I0421 20:12:22.706496  6613 net.cpp:157] Top shape: 5 1024 21 21 (2257920)
I0421 20:12:22.706497  6613 net.cpp:165] Memory required for data: 2646547520
I0421 20:12:22.706524  6613 layer_factory.hpp:77] Creating layer relu_d4b
I0421 20:12:22.706534  6613 net.cpp:100] Creating Layer relu_d4b
I0421 20:12:22.706538  6613 net.cpp:434] relu_d4b <- d4b
I0421 20:12:22.706543  6613 net.cpp:395] relu_d4b -> d4b (in-place)
I0421 20:12:22.707360  6613 net.cpp:150] Setting up relu_d4b
I0421 20:12:22.707375  6613 net.cpp:157] Top shape: 5 1024 21 21 (2257920)
I0421 20:12:22.707376  6613 net.cpp:165] Memory required for data: 2655579200
I0421 20:12:22.707379  6613 layer_factory.hpp:77] Creating layer conv_d4b-c
I0421 20:12:22.707389  6613 net.cpp:100] Creating Layer conv_d4b-c
I0421 20:12:22.707409  6613 net.cpp:434] conv_d4b-c <- d4b
I0421 20:12:22.707419  6613 net.cpp:408] conv_d4b-c -> d4c
I0421 20:12:22.770171  6613 net.cpp:150] Setting up conv_d4b-c
I0421 20:12:22.770207  6613 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0421 20:12:22.770210  6613 net.cpp:165] Memory required for data: 2662972480
I0421 20:12:22.770218  6613 layer_factory.hpp:77] Creating layer relu_d4c
I0421 20:12:22.770226  6613 net.cpp:100] Creating Layer relu_d4c
I0421 20:12:22.770231  6613 net.cpp:434] relu_d4c <- d4c
I0421 20:12:22.770237  6613 net.cpp:395] relu_d4c -> d4c (in-place)
I0421 20:12:22.770486  6613 net.cpp:150] Setting up relu_d4c
I0421 20:12:22.770496  6613 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0421 20:12:22.770498  6613 net.cpp:165] Memory required for data: 2670365760
I0421 20:12:22.770501  6613 layer_factory.hpp:77] Creating layer dropout_d4c
I0421 20:12:22.770509  6613 net.cpp:100] Creating Layer dropout_d4c
I0421 20:12:22.770511  6613 net.cpp:434] dropout_d4c <- d4c
I0421 20:12:22.770516  6613 net.cpp:395] dropout_d4c -> d4c (in-place)
I0421 20:12:22.770546  6613 net.cpp:150] Setting up dropout_d4c
I0421 20:12:22.770553  6613 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0421 20:12:22.770555  6613 net.cpp:165] Memory required for data: 2677759040
I0421 20:12:22.770557  6613 layer_factory.hpp:77] Creating layer upconv_d4c_u3a
I0421 20:12:22.770568  6613 net.cpp:100] Creating Layer upconv_d4c_u3a
I0421 20:12:22.770572  6613 net.cpp:434] upconv_d4c_u3a <- d4c
I0421 20:12:22.770578  6613 net.cpp:408] upconv_d4c_u3a -> u3a
I0421 20:12:22.784807  6613 net.cpp:150] Setting up upconv_d4c_u3a
I0421 20:12:22.784821  6613 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0421 20:12:22.784838  6613 net.cpp:165] Memory required for data: 2692545600
I0421 20:12:22.784844  6613 layer_factory.hpp:77] Creating layer relu_u3a
I0421 20:12:22.784889  6613 net.cpp:100] Creating Layer relu_u3a
I0421 20:12:22.784893  6613 net.cpp:434] relu_u3a <- u3a
I0421 20:12:22.784899  6613 net.cpp:395] relu_u3a -> u3a (in-place)
I0421 20:12:22.785120  6613 net.cpp:150] Setting up relu_u3a
I0421 20:12:22.785130  6613 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0421 20:12:22.785133  6613 net.cpp:165] Memory required for data: 2707332160
I0421 20:12:22.785136  6613 layer_factory.hpp:77] Creating layer u3a_relu_u3a_0_split
I0421 20:12:22.785142  6613 net.cpp:100] Creating Layer u3a_relu_u3a_0_split
I0421 20:12:22.785145  6613 net.cpp:434] u3a_relu_u3a_0_split <- u3a
I0421 20:12:22.785154  6613 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_0
I0421 20:12:22.785162  6613 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_1
I0421 20:12:22.785205  6613 net.cpp:150] Setting up u3a_relu_u3a_0_split
I0421 20:12:22.785212  6613 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0421 20:12:22.785217  6613 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0421 20:12:22.785218  6613 net.cpp:165] Memory required for data: 2736905280
I0421 20:12:22.785221  6613 layer_factory.hpp:77] Creating layer crop_d3c-d3cc
I0421 20:12:22.785228  6613 net.cpp:100] Creating Layer crop_d3c-d3cc
I0421 20:12:22.785231  6613 net.cpp:434] crop_d3c-d3cc <- d3c_dropout_d3c_0_split_1
I0421 20:12:22.785236  6613 net.cpp:434] crop_d3c-d3cc <- u3a_relu_u3a_0_split_0
I0421 20:12:22.785243  6613 net.cpp:408] crop_d3c-d3cc -> d3cc
I0421 20:12:22.785267  6613 net.cpp:150] Setting up crop_d3c-d3cc
I0421 20:12:22.785275  6613 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0421 20:12:22.785277  6613 net.cpp:165] Memory required for data: 2751691840
I0421 20:12:22.785280  6613 layer_factory.hpp:77] Creating layer concat_d3cc_u3a-b
I0421 20:12:22.785285  6613 net.cpp:100] Creating Layer concat_d3cc_u3a-b
I0421 20:12:22.785290  6613 net.cpp:434] concat_d3cc_u3a-b <- u3a_relu_u3a_0_split_1
I0421 20:12:22.785293  6613 net.cpp:434] concat_d3cc_u3a-b <- d3cc
I0421 20:12:22.785298  6613 net.cpp:408] concat_d3cc_u3a-b -> u3b
I0421 20:12:22.785323  6613 net.cpp:150] Setting up concat_d3cc_u3a-b
I0421 20:12:22.785331  6613 net.cpp:157] Top shape: 5 1024 38 38 (7393280)
I0421 20:12:22.785333  6613 net.cpp:165] Memory required for data: 2781264960
I0421 20:12:22.785336  6613 layer_factory.hpp:77] Creating layer conv_u3b-c
I0421 20:12:22.785346  6613 net.cpp:100] Creating Layer conv_u3b-c
I0421 20:12:22.785349  6613 net.cpp:434] conv_u3b-c <- u3b
I0421 20:12:22.785356  6613 net.cpp:408] conv_u3b-c -> u3c
I0421 20:12:22.815407  6613 net.cpp:150] Setting up conv_u3b-c
I0421 20:12:22.815423  6613 net.cpp:157] Top shape: 5 512 36 36 (3317760)
I0421 20:12:22.815441  6613 net.cpp:165] Memory required for data: 2794536000
I0421 20:12:22.815448  6613 layer_factory.hpp:77] Creating layer relu_u3c
I0421 20:12:22.815454  6613 net.cpp:100] Creating Layer relu_u3c
I0421 20:12:22.815457  6613 net.cpp:434] relu_u3c <- u3c
I0421 20:12:22.815464  6613 net.cpp:395] relu_u3c -> u3c (in-place)
I0421 20:12:22.815706  6613 net.cpp:150] Setting up relu_u3c
I0421 20:12:22.815716  6613 net.cpp:157] Top shape: 5 512 36 36 (3317760)
I0421 20:12:22.815717  6613 net.cpp:165] Memory required for data: 2807807040
I0421 20:12:22.815721  6613 layer_factory.hpp:77] Creating layer conv_u3c-d
I0421 20:12:22.815731  6613 net.cpp:100] Creating Layer conv_u3c-d
I0421 20:12:22.815733  6613 net.cpp:434] conv_u3c-d <- u3c
I0421 20:12:22.815740  6613 net.cpp:408] conv_u3c-d -> u3d
I0421 20:12:22.831324  6613 net.cpp:150] Setting up conv_u3c-d
I0421 20:12:22.831338  6613 net.cpp:157] Top shape: 5 512 34 34 (2959360)
I0421 20:12:22.831341  6613 net.cpp:165] Memory required for data: 2819644480
I0421 20:12:22.831346  6613 layer_factory.hpp:77] Creating layer relu_u3d
I0421 20:12:22.831353  6613 net.cpp:100] Creating Layer relu_u3d
I0421 20:12:22.831373  6613 net.cpp:434] relu_u3d <- u3d
I0421 20:12:22.831377  6613 net.cpp:395] relu_u3d -> u3d (in-place)
I0421 20:12:22.832193  6613 net.cpp:150] Setting up relu_u3d
I0421 20:12:22.832254  6613 net.cpp:157] Top shape: 5 512 34 34 (2959360)
I0421 20:12:22.832257  6613 net.cpp:165] Memory required for data: 2831481920
I0421 20:12:22.832260  6613 layer_factory.hpp:77] Creating layer upconv_u3d_u2a
I0421 20:12:22.832267  6613 net.cpp:100] Creating Layer upconv_u3d_u2a
I0421 20:12:22.832273  6613 net.cpp:434] upconv_u3d_u2a <- u3d
I0421 20:12:22.832278  6613 net.cpp:408] upconv_u3d_u2a -> u2a
I0421 20:12:22.836130  6613 net.cpp:150] Setting up upconv_u3d_u2a
I0421 20:12:22.836143  6613 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0421 20:12:22.836161  6613 net.cpp:165] Memory required for data: 2855156800
I0421 20:12:22.836166  6613 layer_factory.hpp:77] Creating layer relu_u2a
I0421 20:12:22.836171  6613 net.cpp:100] Creating Layer relu_u2a
I0421 20:12:22.836174  6613 net.cpp:434] relu_u2a <- u2a
I0421 20:12:22.836180  6613 net.cpp:395] relu_u2a -> u2a (in-place)
I0421 20:12:22.836393  6613 net.cpp:150] Setting up relu_u2a
I0421 20:12:22.836402  6613 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0421 20:12:22.836405  6613 net.cpp:165] Memory required for data: 2878831680
I0421 20:12:22.836408  6613 layer_factory.hpp:77] Creating layer u2a_relu_u2a_0_split
I0421 20:12:22.836414  6613 net.cpp:100] Creating Layer u2a_relu_u2a_0_split
I0421 20:12:22.836416  6613 net.cpp:434] u2a_relu_u2a_0_split <- u2a
I0421 20:12:22.836423  6613 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_0
I0421 20:12:22.836432  6613 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_1
I0421 20:12:22.836477  6613 net.cpp:150] Setting up u2a_relu_u2a_0_split
I0421 20:12:22.836484  6613 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0421 20:12:22.836488  6613 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0421 20:12:22.836490  6613 net.cpp:165] Memory required for data: 2926181440
I0421 20:12:22.836493  6613 layer_factory.hpp:77] Creating layer crop_d2c-d2cc
I0421 20:12:22.836500  6613 net.cpp:100] Creating Layer crop_d2c-d2cc
I0421 20:12:22.836503  6613 net.cpp:434] crop_d2c-d2cc <- d2c_relu_d2c_0_split_1
I0421 20:12:22.836509  6613 net.cpp:434] crop_d2c-d2cc <- u2a_relu_u2a_0_split_0
I0421 20:12:22.836515  6613 net.cpp:408] crop_d2c-d2cc -> d2cc
I0421 20:12:22.836540  6613 net.cpp:150] Setting up crop_d2c-d2cc
I0421 20:12:22.836549  6613 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0421 20:12:22.836551  6613 net.cpp:165] Memory required for data: 2949856320
I0421 20:12:22.836554  6613 layer_factory.hpp:77] Creating layer concat_d2cc_u2a-b
I0421 20:12:22.836558  6613 net.cpp:100] Creating Layer concat_d2cc_u2a-b
I0421 20:12:22.836561  6613 net.cpp:434] concat_d2cc_u2a-b <- u2a_relu_u2a_0_split_1
I0421 20:12:22.836566  6613 net.cpp:434] concat_d2cc_u2a-b <- d2cc
I0421 20:12:22.836580  6613 net.cpp:408] concat_d2cc_u2a-b -> u2b
I0421 20:12:22.836602  6613 net.cpp:150] Setting up concat_d2cc_u2a-b
I0421 20:12:22.836608  6613 net.cpp:157] Top shape: 5 512 68 68 (11837440)
I0421 20:12:22.836612  6613 net.cpp:165] Memory required for data: 2997206080
I0421 20:12:22.836616  6613 layer_factory.hpp:77] Creating layer conv_u2b-c
I0421 20:12:22.836625  6613 net.cpp:100] Creating Layer conv_u2b-c
I0421 20:12:22.836628  6613 net.cpp:434] conv_u2b-c <- u2b
I0421 20:12:22.836637  6613 net.cpp:408] conv_u2b-c -> u2c
I0421 20:12:22.844576  6613 net.cpp:150] Setting up conv_u2b-c
I0421 20:12:22.844588  6613 net.cpp:157] Top shape: 5 256 66 66 (5575680)
I0421 20:12:22.844591  6613 net.cpp:165] Memory required for data: 3019508800
I0421 20:12:22.844612  6613 layer_factory.hpp:77] Creating layer relu_u2c
I0421 20:12:22.844619  6613 net.cpp:100] Creating Layer relu_u2c
I0421 20:12:22.844620  6613 net.cpp:434] relu_u2c <- u2c
I0421 20:12:22.844626  6613 net.cpp:395] relu_u2c -> u2c (in-place)
I0421 20:12:22.844848  6613 net.cpp:150] Setting up relu_u2c
I0421 20:12:22.844858  6613 net.cpp:157] Top shape: 5 256 66 66 (5575680)
I0421 20:12:22.844861  6613 net.cpp:165] Memory required for data: 3041811520
I0421 20:12:22.844863  6613 layer_factory.hpp:77] Creating layer conv_u2c-d
I0421 20:12:22.844873  6613 net.cpp:100] Creating Layer conv_u2c-d
I0421 20:12:22.844893  6613 net.cpp:434] conv_u2c-d <- u2c
I0421 20:12:22.844900  6613 net.cpp:408] conv_u2c-d -> u2d
I0421 20:12:22.849285  6613 net.cpp:150] Setting up conv_u2c-d
I0421 20:12:22.849298  6613 net.cpp:157] Top shape: 5 256 64 64 (5242880)
I0421 20:12:22.849301  6613 net.cpp:165] Memory required for data: 3062783040
I0421 20:12:22.849323  6613 layer_factory.hpp:77] Creating layer relu_u2d
I0421 20:12:22.849328  6613 net.cpp:100] Creating Layer relu_u2d
I0421 20:12:22.849331  6613 net.cpp:434] relu_u2d <- u2d
I0421 20:12:22.849336  6613 net.cpp:395] relu_u2d -> u2d (in-place)
I0421 20:12:22.849555  6613 net.cpp:150] Setting up relu_u2d
I0421 20:12:22.849565  6613 net.cpp:157] Top shape: 5 256 64 64 (5242880)
I0421 20:12:22.849567  6613 net.cpp:165] Memory required for data: 3083754560
I0421 20:12:22.849570  6613 layer_factory.hpp:77] Creating layer upconv_u2d_u1a
I0421 20:12:22.849578  6613 net.cpp:100] Creating Layer upconv_u2d_u1a
I0421 20:12:22.849582  6613 net.cpp:434] upconv_u2d_u1a <- u2d
I0421 20:12:22.849588  6613 net.cpp:408] upconv_u2d_u1a -> u1a
I0421 20:12:22.851519  6613 net.cpp:150] Setting up upconv_u2d_u1a
I0421 20:12:22.851532  6613 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0421 20:12:22.851534  6613 net.cpp:165] Memory required for data: 3125697600
I0421 20:12:22.851562  6613 layer_factory.hpp:77] Creating layer relu_u1a
I0421 20:12:22.851567  6613 net.cpp:100] Creating Layer relu_u1a
I0421 20:12:22.851570  6613 net.cpp:434] relu_u1a <- u1a
I0421 20:12:22.851574  6613 net.cpp:395] relu_u1a -> u1a (in-place)
I0421 20:12:22.852412  6613 net.cpp:150] Setting up relu_u1a
I0421 20:12:22.852427  6613 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0421 20:12:22.852444  6613 net.cpp:165] Memory required for data: 3167640640
I0421 20:12:22.852447  6613 layer_factory.hpp:77] Creating layer u1a_relu_u1a_0_split
I0421 20:12:22.852453  6613 net.cpp:100] Creating Layer u1a_relu_u1a_0_split
I0421 20:12:22.852457  6613 net.cpp:434] u1a_relu_u1a_0_split <- u1a
I0421 20:12:22.852463  6613 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_0
I0421 20:12:22.852469  6613 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_1
I0421 20:12:22.852517  6613 net.cpp:150] Setting up u1a_relu_u1a_0_split
I0421 20:12:22.852526  6613 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0421 20:12:22.852530  6613 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0421 20:12:22.852532  6613 net.cpp:165] Memory required for data: 3251526720
I0421 20:12:22.852536  6613 layer_factory.hpp:77] Creating layer crop_d1c-d1cc
I0421 20:12:22.852543  6613 net.cpp:100] Creating Layer crop_d1c-d1cc
I0421 20:12:22.852547  6613 net.cpp:434] crop_d1c-d1cc <- d1c_relu_d1c_0_split_1
I0421 20:12:22.852551  6613 net.cpp:434] crop_d1c-d1cc <- u1a_relu_u1a_0_split_0
I0421 20:12:22.852558  6613 net.cpp:408] crop_d1c-d1cc -> d1cc
I0421 20:12:22.852583  6613 net.cpp:150] Setting up crop_d1c-d1cc
I0421 20:12:22.852589  6613 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0421 20:12:22.852592  6613 net.cpp:165] Memory required for data: 3293469760
I0421 20:12:22.852596  6613 layer_factory.hpp:77] Creating layer concat_d1cc_u1a-b
I0421 20:12:22.852602  6613 net.cpp:100] Creating Layer concat_d1cc_u1a-b
I0421 20:12:22.852604  6613 net.cpp:434] concat_d1cc_u1a-b <- u1a_relu_u1a_0_split_1
I0421 20:12:22.852608  6613 net.cpp:434] concat_d1cc_u1a-b <- d1cc
I0421 20:12:22.852613  6613 net.cpp:408] concat_d1cc_u1a-b -> u1b
I0421 20:12:22.852638  6613 net.cpp:150] Setting up concat_d1cc_u1a-b
I0421 20:12:22.852644  6613 net.cpp:157] Top shape: 5 256 128 128 (20971520)
I0421 20:12:22.852648  6613 net.cpp:165] Memory required for data: 3377355840
I0421 20:12:22.852650  6613 layer_factory.hpp:77] Creating layer conv_u1b-c
I0421 20:12:22.852659  6613 net.cpp:100] Creating Layer conv_u1b-c
I0421 20:12:22.852663  6613 net.cpp:434] conv_u1b-c <- u1b
I0421 20:12:22.852669  6613 net.cpp:408] conv_u1b-c -> u1c
I0421 20:12:22.854638  6613 net.cpp:150] Setting up conv_u1b-c
I0421 20:12:22.854647  6613 net.cpp:157] Top shape: 5 128 126 126 (10160640)
I0421 20:12:22.854662  6613 net.cpp:165] Memory required for data: 3417998400
I0421 20:12:22.854668  6613 layer_factory.hpp:77] Creating layer relu_u1c
I0421 20:12:22.854673  6613 net.cpp:100] Creating Layer relu_u1c
I0421 20:12:22.854676  6613 net.cpp:434] relu_u1c <- u1c
I0421 20:12:22.854681  6613 net.cpp:395] relu_u1c -> u1c (in-place)
I0421 20:12:22.854863  6613 net.cpp:150] Setting up relu_u1c
I0421 20:12:22.854872  6613 net.cpp:157] Top shape: 5 128 126 126 (10160640)
I0421 20:12:22.854876  6613 net.cpp:165] Memory required for data: 3458640960
I0421 20:12:22.854877  6613 layer_factory.hpp:77] Creating layer conv_u1c-d
I0421 20:12:22.854887  6613 net.cpp:100] Creating Layer conv_u1c-d
I0421 20:12:22.854892  6613 net.cpp:434] conv_u1c-d <- u1c
I0421 20:12:22.854898  6613 net.cpp:408] conv_u1c-d -> u1d
I0421 20:12:22.856897  6613 net.cpp:150] Setting up conv_u1c-d
I0421 20:12:22.856909  6613 net.cpp:157] Top shape: 5 128 124 124 (9840640)
I0421 20:12:22.856912  6613 net.cpp:165] Memory required for data: 3498003520
I0421 20:12:22.856932  6613 layer_factory.hpp:77] Creating layer relu_u1d
I0421 20:12:22.856940  6613 net.cpp:100] Creating Layer relu_u1d
I0421 20:12:22.856942  6613 net.cpp:434] relu_u1d <- u1d
I0421 20:12:22.856947  6613 net.cpp:395] relu_u1d -> u1d (in-place)
I0421 20:12:22.857149  6613 net.cpp:150] Setting up relu_u1d
I0421 20:12:22.857159  6613 net.cpp:157] Top shape: 5 128 124 124 (9840640)
I0421 20:12:22.857162  6613 net.cpp:165] Memory required for data: 3537366080
I0421 20:12:22.857165  6613 layer_factory.hpp:77] Creating layer upconv_u1d_u0a
I0421 20:12:22.857172  6613 net.cpp:100] Creating Layer upconv_u1d_u0a
I0421 20:12:22.857177  6613 net.cpp:434] upconv_u1d_u0a <- u1d
I0421 20:12:22.857183  6613 net.cpp:408] upconv_u1d_u0a -> u0a
I0421 20:12:22.857900  6613 net.cpp:150] Setting up upconv_u1d_u0a
I0421 20:12:22.857909  6613 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0421 20:12:22.857911  6613 net.cpp:165] Memory required for data: 3694816320
I0421 20:12:22.857931  6613 layer_factory.hpp:77] Creating layer relu_u0a
I0421 20:12:22.857938  6613 net.cpp:100] Creating Layer relu_u0a
I0421 20:12:22.857939  6613 net.cpp:434] relu_u0a <- u0a
I0421 20:12:22.857944  6613 net.cpp:395] relu_u0a -> u0a (in-place)
I0421 20:12:22.858356  6613 net.cpp:150] Setting up relu_u0a
I0421 20:12:22.858379  6613 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0421 20:12:22.858382  6613 net.cpp:165] Memory required for data: 3852266560
I0421 20:12:22.858384  6613 layer_factory.hpp:77] Creating layer u0a_relu_u0a_0_split
I0421 20:12:22.858404  6613 net.cpp:100] Creating Layer u0a_relu_u0a_0_split
I0421 20:12:22.858407  6613 net.cpp:434] u0a_relu_u0a_0_split <- u0a
I0421 20:12:22.858412  6613 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_0
I0421 20:12:22.858418  6613 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_1
I0421 20:12:22.858464  6613 net.cpp:150] Setting up u0a_relu_u0a_0_split
I0421 20:12:22.858471  6613 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0421 20:12:22.858474  6613 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0421 20:12:22.858477  6613 net.cpp:165] Memory required for data: 4167167040
I0421 20:12:22.858479  6613 layer_factory.hpp:77] Creating layer crop_d0c-d0cc
I0421 20:12:22.858487  6613 net.cpp:100] Creating Layer crop_d0c-d0cc
I0421 20:12:22.858490  6613 net.cpp:434] crop_d0c-d0cc <- d0c_relu_d0c_0_split_1
I0421 20:12:22.858495  6613 net.cpp:434] crop_d0c-d0cc <- u0a_relu_u0a_0_split_0
I0421 20:12:22.858500  6613 net.cpp:408] crop_d0c-d0cc -> d0cc
I0421 20:12:22.858525  6613 net.cpp:150] Setting up crop_d0c-d0cc
I0421 20:12:22.858530  6613 net.cpp:157] Top shape: 5 64 248 248 (19681280)
I0421 20:12:22.858532  6613 net.cpp:165] Memory required for data: 4245892160
I0421 20:12:22.858551  6613 layer_factory.hpp:77] Creating layer concat_d0cc_u0a-b
I0421 20:12:22.858556  6613 net.cpp:100] Creating Layer concat_d0cc_u0a-b
I0421 20:12:22.858559  6613 net.cpp:434] concat_d0cc_u0a-b <- u0a_relu_u0a_0_split_1
I0421 20:12:22.858562  6613 net.cpp:434] concat_d0cc_u0a-b <- d0cc
I0421 20:12:22.858583  6613 net.cpp:408] concat_d0cc_u0a-b -> u0b
I0421 20:12:22.858613  6613 net.cpp:150] Setting up concat_d0cc_u0a-b
I0421 20:12:22.858621  6613 net.cpp:157] Top shape: 5 192 248 248 (59043840)
I0421 20:12:22.858623  6613 net.cpp:165] Memory required for data: 4482067520
I0421 20:12:22.858626  6613 layer_factory.hpp:77] Creating layer conv_u0b-c
I0421 20:12:22.858635  6613 net.cpp:100] Creating Layer conv_u0b-c
I0421 20:12:22.858639  6613 net.cpp:434] conv_u0b-c <- u0b
I0421 20:12:22.858644  6613 net.cpp:408] conv_u0b-c -> u0c
I0421 20:12:22.859591  6613 net.cpp:150] Setting up conv_u0b-c
I0421 20:12:22.859599  6613 net.cpp:157] Top shape: 5 64 246 246 (19365120)
I0421 20:12:22.859601  6613 net.cpp:165] Memory required for data: 4559528000
I0421 20:12:22.859606  6613 layer_factory.hpp:77] Creating layer relu_u0c
I0421 20:12:22.859621  6613 net.cpp:100] Creating Layer relu_u0c
I0421 20:12:22.859623  6613 net.cpp:434] relu_u0c <- u0c
I0421 20:12:22.859627  6613 net.cpp:395] relu_u0c -> u0c (in-place)
I0421 20:12:22.860594  6613 net.cpp:150] Setting up relu_u0c
I0421 20:12:22.860605  6613 net.cpp:157] Top shape: 5 64 246 246 (19365120)
I0421 20:12:22.860625  6613 net.cpp:165] Memory required for data: 4636988480
I0421 20:12:22.860628  6613 layer_factory.hpp:77] Creating layer conv_u0c-d
I0421 20:12:22.860636  6613 net.cpp:100] Creating Layer conv_u0c-d
I0421 20:12:22.860641  6613 net.cpp:434] conv_u0c-d <- u0c
I0421 20:12:22.860646  6613 net.cpp:408] conv_u0c-d -> u0d
I0421 20:12:22.861182  6613 net.cpp:150] Setting up conv_u0c-d
I0421 20:12:22.861191  6613 net.cpp:157] Top shape: 5 64 244 244 (19051520)
I0421 20:12:22.861192  6613 net.cpp:165] Memory required for data: 4713194560
I0421 20:12:22.861213  6613 layer_factory.hpp:77] Creating layer relu_u0d
I0421 20:12:22.861218  6613 net.cpp:100] Creating Layer relu_u0d
I0421 20:12:22.861235  6613 net.cpp:434] relu_u0d <- u0d
I0421 20:12:22.861239  6613 net.cpp:395] relu_u0d -> u0d (in-place)
I0421 20:12:22.861412  6613 net.cpp:150] Setting up relu_u0d
I0421 20:12:22.861419  6613 net.cpp:157] Top shape: 5 64 244 244 (19051520)
I0421 20:12:22.861421  6613 net.cpp:165] Memory required for data: 4789400640
I0421 20:12:22.861424  6613 layer_factory.hpp:77] Creating layer conv_u0d-score
I0421 20:12:22.861433  6613 net.cpp:100] Creating Layer conv_u0d-score
I0421 20:12:22.861443  6613 net.cpp:434] conv_u0d-score <- u0d
I0421 20:12:22.861466  6613 net.cpp:408] conv_u0d-score -> score
I0421 20:12:22.861781  6613 net.cpp:150] Setting up conv_u0d-score
I0421 20:12:22.861804  6613 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0421 20:12:22.861806  6613 net.cpp:165] Memory required for data: 4792972800
I0421 20:12:22.861825  6613 layer_factory.hpp:77] Creating layer score_conv_u0d-score_0_split
I0421 20:12:22.861830  6613 net.cpp:100] Creating Layer score_conv_u0d-score_0_split
I0421 20:12:22.861834  6613 net.cpp:434] score_conv_u0d-score_0_split <- score
I0421 20:12:22.861838  6613 net.cpp:408] score_conv_u0d-score_0_split -> score_conv_u0d-score_0_split_0
I0421 20:12:22.861845  6613 net.cpp:408] score_conv_u0d-score_0_split -> score_conv_u0d-score_0_split_1
I0421 20:12:22.861886  6613 net.cpp:150] Setting up score_conv_u0d-score_0_split
I0421 20:12:22.861892  6613 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0421 20:12:22.861896  6613 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0421 20:12:22.861897  6613 net.cpp:165] Memory required for data: 4800117120
I0421 20:12:22.861901  6613 layer_factory.hpp:77] Creating layer loss
I0421 20:12:22.861906  6613 net.cpp:100] Creating Layer loss
I0421 20:12:22.861908  6613 net.cpp:434] loss <- score_conv_u0d-score_0_split_0
I0421 20:12:22.861912  6613 net.cpp:434] loss <- label
I0421 20:12:22.861917  6613 net.cpp:434] loss <- weights
I0421 20:12:22.861923  6613 net.cpp:408] loss -> loss
I0421 20:12:22.861929  6613 layer_factory.hpp:77] Creating layer loss
I0421 20:12:22.864424  6613 net.cpp:150] Setting up loss
I0421 20:12:22.864435  6613 net.cpp:157] Top shape: (1)
I0421 20:12:22.864437  6613 net.cpp:160]     with loss weight 1
I0421 20:12:22.864478  6613 net.cpp:165] Memory required for data: 4800117124
I0421 20:12:22.864482  6613 layer_factory.hpp:77] Creating layer visualize
I0421 20:12:22.864490  6613 net.cpp:100] Creating Layer visualize
I0421 20:12:22.864495  6613 net.cpp:434] visualize <- score_conv_u0d-score_0_split_1
I0421 20:12:22.864500  6613 net.cpp:408] visualize -> visualize_out
I0421 20:12:22.865286  6613 net.cpp:150] Setting up visualize
I0421 20:12:22.865298  6613 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0421 20:12:22.865316  6613 net.cpp:165] Memory required for data: 4803689284
I0421 20:12:22.865319  6613 layer_factory.hpp:77] Creating layer fake
I0421 20:12:22.865325  6613 net.cpp:100] Creating Layer fake
I0421 20:12:22.865327  6613 net.cpp:434] fake <- visualize_out
I0421 20:12:22.865332  6613 net.cpp:150] Setting up fake
I0421 20:12:22.865334  6613 net.cpp:165] Memory required for data: 4803689284
I0421 20:12:22.865336  6613 net.cpp:228] fake does not need backward computation.
I0421 20:12:22.865339  6613 net.cpp:228] visualize does not need backward computation.
I0421 20:12:22.865345  6613 net.cpp:226] loss needs backward computation.
I0421 20:12:22.865347  6613 net.cpp:226] score_conv_u0d-score_0_split needs backward computation.
I0421 20:12:22.865350  6613 net.cpp:226] conv_u0d-score needs backward computation.
I0421 20:12:22.865353  6613 net.cpp:226] relu_u0d needs backward computation.
I0421 20:12:22.865356  6613 net.cpp:226] conv_u0c-d needs backward computation.
I0421 20:12:22.865358  6613 net.cpp:226] relu_u0c needs backward computation.
I0421 20:12:22.865360  6613 net.cpp:226] conv_u0b-c needs backward computation.
I0421 20:12:22.865363  6613 net.cpp:226] concat_d0cc_u0a-b needs backward computation.
I0421 20:12:22.865367  6613 net.cpp:226] crop_d0c-d0cc needs backward computation.
I0421 20:12:22.865371  6613 net.cpp:226] u0a_relu_u0a_0_split needs backward computation.
I0421 20:12:22.865375  6613 net.cpp:226] relu_u0a needs backward computation.
I0421 20:12:22.865377  6613 net.cpp:226] upconv_u1d_u0a needs backward computation.
I0421 20:12:22.865381  6613 net.cpp:226] relu_u1d needs backward computation.
I0421 20:12:22.865383  6613 net.cpp:226] conv_u1c-d needs backward computation.
I0421 20:12:22.865386  6613 net.cpp:226] relu_u1c needs backward computation.
I0421 20:12:22.865388  6613 net.cpp:226] conv_u1b-c needs backward computation.
I0421 20:12:22.865392  6613 net.cpp:226] concat_d1cc_u1a-b needs backward computation.
I0421 20:12:22.865396  6613 net.cpp:226] crop_d1c-d1cc needs backward computation.
I0421 20:12:22.865399  6613 net.cpp:226] u1a_relu_u1a_0_split needs backward computation.
I0421 20:12:22.865402  6613 net.cpp:226] relu_u1a needs backward computation.
I0421 20:12:22.865406  6613 net.cpp:226] upconv_u2d_u1a needs backward computation.
I0421 20:12:22.865408  6613 net.cpp:226] relu_u2d needs backward computation.
I0421 20:12:22.865411  6613 net.cpp:226] conv_u2c-d needs backward computation.
I0421 20:12:22.865413  6613 net.cpp:226] relu_u2c needs backward computation.
I0421 20:12:22.865417  6613 net.cpp:226] conv_u2b-c needs backward computation.
I0421 20:12:22.865422  6613 net.cpp:226] concat_d2cc_u2a-b needs backward computation.
I0421 20:12:22.865424  6613 net.cpp:226] crop_d2c-d2cc needs backward computation.
I0421 20:12:22.865428  6613 net.cpp:226] u2a_relu_u2a_0_split needs backward computation.
I0421 20:12:22.865432  6613 net.cpp:226] relu_u2a needs backward computation.
I0421 20:12:22.865461  6613 net.cpp:226] upconv_u3d_u2a needs backward computation.
I0421 20:12:22.865464  6613 net.cpp:226] relu_u3d needs backward computation.
I0421 20:12:22.865484  6613 net.cpp:226] conv_u3c-d needs backward computation.
I0421 20:12:22.865489  6613 net.cpp:226] relu_u3c needs backward computation.
I0421 20:12:22.865491  6613 net.cpp:226] conv_u3b-c needs backward computation.
I0421 20:12:22.865495  6613 net.cpp:226] concat_d3cc_u3a-b needs backward computation.
I0421 20:12:22.865499  6613 net.cpp:226] crop_d3c-d3cc needs backward computation.
I0421 20:12:22.865504  6613 net.cpp:226] u3a_relu_u3a_0_split needs backward computation.
I0421 20:12:22.865526  6613 net.cpp:226] relu_u3a needs backward computation.
I0421 20:12:22.865530  6613 net.cpp:226] upconv_d4c_u3a needs backward computation.
I0421 20:12:22.865532  6613 net.cpp:226] dropout_d4c needs backward computation.
I0421 20:12:22.865536  6613 net.cpp:226] relu_d4c needs backward computation.
I0421 20:12:22.865540  6613 net.cpp:226] conv_d4b-c needs backward computation.
I0421 20:12:22.865542  6613 net.cpp:226] relu_d4b needs backward computation.
I0421 20:12:22.865545  6613 net.cpp:226] conv_d4a-b needs backward computation.
I0421 20:12:22.865550  6613 net.cpp:226] pool_d3c-4a needs backward computation.
I0421 20:12:22.865553  6613 net.cpp:226] d3c_dropout_d3c_0_split needs backward computation.
I0421 20:12:22.865556  6613 net.cpp:226] dropout_d3c needs backward computation.
I0421 20:12:22.865559  6613 net.cpp:226] relu_d3c needs backward computation.
I0421 20:12:22.865563  6613 net.cpp:226] conv_d3b-c needs backward computation.
I0421 20:12:22.865567  6613 net.cpp:226] relu_d3b needs backward computation.
I0421 20:12:22.865571  6613 net.cpp:226] conv_d3a-b needs backward computation.
I0421 20:12:22.865574  6613 net.cpp:226] pool_d2c-3a needs backward computation.
I0421 20:12:22.865578  6613 net.cpp:226] d2c_relu_d2c_0_split needs backward computation.
I0421 20:12:22.865582  6613 net.cpp:226] relu_d2c needs backward computation.
I0421 20:12:22.865584  6613 net.cpp:226] conv_d2b-c needs backward computation.
I0421 20:12:22.865588  6613 net.cpp:226] relu_d2b needs backward computation.
I0421 20:12:22.865592  6613 net.cpp:226] conv_d2a-b needs backward computation.
I0421 20:12:22.865595  6613 net.cpp:226] pool_d1c-2a needs backward computation.
I0421 20:12:22.865598  6613 net.cpp:226] d1c_relu_d1c_0_split needs backward computation.
I0421 20:12:22.865602  6613 net.cpp:226] relu_d1c needs backward computation.
I0421 20:12:22.865605  6613 net.cpp:226] conv_d1b-c needs backward computation.
I0421 20:12:22.865607  6613 net.cpp:226] relu_d1b needs backward computation.
I0421 20:12:22.865610  6613 net.cpp:226] conv_d1a-b needs backward computation.
I0421 20:12:22.865612  6613 net.cpp:226] pool_d0c-1a needs backward computation.
I0421 20:12:22.865617  6613 net.cpp:226] d0c_relu_d0c_0_split needs backward computation.
I0421 20:12:22.865618  6613 net.cpp:226] relu_d0c needs backward computation.
I0421 20:12:22.865622  6613 net.cpp:226] conv_d0b-c needs backward computation.
I0421 20:12:22.865624  6613 net.cpp:226] relu_d0b needs backward computation.
I0421 20:12:22.865628  6613 net.cpp:226] conv_d0a-b needs backward computation.
I0421 20:12:22.865633  6613 net.cpp:228] loaddata does not need backward computation.
I0421 20:12:22.865640  6613 net.cpp:270] This network produces output loss
I0421 20:12:22.865696  6613 net.cpp:283] Network initialization done.
I0421 20:12:22.866245  6613 solver.cpp:181] Creating test net (#0) specified by net file: ./unet_weighted_3/unet_weighted_3.prototxt
I0421 20:12:22.866313  6613 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer loaddata
I0421 20:12:22.866331  6613 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer dropout_d3c
I0421 20:12:22.866336  6613 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer dropout_d4c
I0421 20:12:22.866353  6613 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer visualize
I0421 20:12:22.866358  6613 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer fake
I0421 20:12:22.866612  6613 net.cpp:58] Initializing net from parameters: 
name: "unet_weighted_3"
force_backward: true
state {
  phase: TEST
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  top: "weights"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "caffeHDF5_validation_3.txt"
    batch_size: 1
  }
}
layer {
  name: "conv_d0a-b"
  type: "Convolution"
  bottom: "data"
  top: "d0b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0b"
  type: "ReLU"
  bottom: "d0b"
  top: "d0b"
}
layer {
  name: "conv_d0b-c"
  type: "Convolution"
  bottom: "d0b"
  top: "d0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0c"
  type: "ReLU"
  bottom: "d0c"
  top: "d0c"
}
layer {
  name: "pool_d0c-1a"
  type: "Pooling"
  bottom: "d0c"
  top: "d1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d1a-b"
  type: "Convolution"
  bottom: "d1a"
  top: "d1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1b"
  type: "ReLU"
  bottom: "d1b"
  top: "d1b"
}
layer {
  name: "conv_d1b-c"
  type: "Convolution"
  bottom: "d1b"
  top: "d1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1c"
  type: "ReLU"
  bottom: "d1c"
  top: "d1c"
}
layer {
  name: "pool_d1c-2a"
  type: "Pooling"
  bottom: "d1c"
  top: "d2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d2a-b"
  type: "Convolution"
  bottom: "d2a"
  top: "d2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2b"
  type: "ReLU"
  bottom: "d2b"
  top: "d2b"
}
layer {
  name: "conv_d2b-c"
  type: "Convolution"
  bottom: "d2b"
  top: "d2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2c"
  type: "ReLU"
  bottom: "d2c"
  top: "d2c"
}
layer {
  name: "pool_d2c-3a"
  type: "Pooling"
  bottom: "d2c"
  top: "d3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d3a-b"
  type: "Convolution"
  bottom: "d3a"
  top: "d3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3b"
  type: "ReLU"
  bottom: "d3b"
  top: "d3b"
}
layer {
  name: "conv_d3b-c"
  type: "Convolution"
  bottom: "d3b"
  top: "d3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3c"
  type: "ReLU"
  bottom: "d3c"
  top: "d3c"
}
layer {
  name: "pool_d3c-4a"
  type: "Pooling"
  bottom: "d3c"
  top: "d4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d4a-b"
  type: "Convolution"
  bottom: "d4a"
  top: "d4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4b"
  type: "ReLU"
  bottom: "d4b"
  top: "d4b"
}
layer {
  name: "conv_d4b-c"
  type: "Convolution"
  bottom: "d4b"
  top: "d4c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4c"
  type: "ReLU"
  bottom: "d4c"
  top: "d4c"
}
layer {
  name: "upconv_d4c_u3a"
  type: "Deconvolution"
  bottom: "d4c"
  top: "u3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u3a"
  type: "ReLU"
  bottom: "u3a"
  top: "u3a"
}
layer {
  name: "crop_d3c-d3cc"
  type: "Crop"
  bottom: "d3c"
  bottom: "u3a"
  top: "d3cc"
  crop_param {
    axis: 2
    offset: 4
  }
}
layer {
  name: "concat_d3cc_u3a-b"
  type: "Concat"
  bottom: "u3a"
  bottom: "d3cc"
  top: "u3b"
}
layer {
  name: "conv_u3b-c"
  type: "Convolution"
  bottom: "u3b"
  top: "u3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3c"
  type: "ReLU"
  bottom: "u3c"
  top: "u3c"
}
layer {
  name: "conv_u3c-d"
  type: "Convolution"
  bottom: "u3c"
  top: "u3d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3d"
  type: "ReLU"
  bottom: "u3d"
  top: "u3d"
}
layer {
  name: "upconv_u3d_u2a"
  type: "Deconvolution"
  bottom: "u3d"
  top: "u2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u2a"
  type: "ReLU"
  bottom: "u2a"
  top: "u2a"
}
layer {
  name: "crop_d2c-d2cc"
  type: "Crop"
  bottom: "d2c"
  bottom: "u2a"
  top: "d2cc"
  crop_param {
    axis: 2
    offset: 16
  }
}
layer {
  name: "concat_d2cc_u2a-b"
  type: "Concat"
  bottom: "u2a"
  bottom: "d2cc"
  top: "u2b"
}
layer {
  name: "conv_u2b-c"
  type: "Convolution"
  bottom: "u2b"
  top: "u2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2c"
  type: "ReLU"
  bottom: "u2c"
  top: "u2c"
}
layer {
  name: "conv_u2c-d"
  type: "Convolution"
  bottom: "u2c"
  top: "u2d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2d"
  type: "ReLU"
  bottom: "u2d"
  top: "u2d"
}
layer {
  name: "upconv_u2d_u1a"
  type: "Deconvolution"
  bottom: "u2d"
  top: "u1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u1a"
  type: "ReLU"
  bottom: "u1a"
  top: "u1a"
}
layer {
  name: "crop_d1c-d1cc"
  type: "Crop"
  bottom: "d1c"
  bottom: "u1a"
  top: "d1cc"
  crop_param {
    axis: 2
    offset: 40
  }
}
layer {
  name: "concat_d1cc_u1a-b"
  type: "Concat"
  bottom: "u1a"
  bottom: "d1cc"
  top: "u1b"
}
layer {
  name: "conv_u1b-c"
  type: "Convolution"
  bottom: "u1b"
  top: "u1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1c"
  type: "ReLU"
  bottom: "u1c"
  top: "u1c"
}
layer {
  name: "conv_u1c-d"
  type: "Convolution"
  bottom: "u1c"
  top: "u1d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1d"
  type: "ReLU"
  bottom: "u1d"
  top: "u1d"
}
layer {
  name: "upconv_u1d_u0a"
  type: "Deconvolution"
  bottom: "u1d"
  top: "u0a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u0a"
  type: "ReLU"
  bottom: "u0a"
  top: "u0a"
}
layer {
  name: "crop_d0c-d0cc"
  type: "Crop"
  bottom: "d0c"
  bottom: "u0a"
  top: "d0cc"
  crop_param {
    axis: 2
    offset: 88
  }
}
layer {
  name: "concat_d0cc_u0a-b"
  type: "Concat"
  bottom: "u0a"
  bottom: "d0cc"
  top: "u0b"
}
layer {
  name: "conv_u0b-c"
  type: "Convolution"
  bottom: "u0b"
  top: "u0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0c"
  type: "ReLU"
  bottom: "u0c"
  top: "u0c"
}
layer {
  name: "conv_u0c-d"
  type: "Convolution"
  bottom: "u0c"
  top: "u0d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0d"
  type: "ReLU"
  bottom: "u0d"
  top: "u0d"
}
layer {
  name: "conv_u0d-score"
  type: "Convolution"
  bottom: "u0d"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  bottom: "weights"
  top: "loss"
  loss_weight: 1
}
I0421 20:12:22.866847  6613 layer_factory.hpp:77] Creating layer loaddata
I0421 20:12:22.866858  6613 net.cpp:100] Creating Layer loaddata
I0421 20:12:22.866861  6613 net.cpp:408] loaddata -> data
I0421 20:12:22.866869  6613 net.cpp:408] loaddata -> label
I0421 20:12:22.866874  6613 net.cpp:408] loaddata -> weights
I0421 20:12:22.866880  6613 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: caffeHDF5_validation_3.txt
I0421 20:12:22.866906  6613 hdf5_data_layer.cpp:93] Number of HDF5 files: 10
I0421 20:12:23.149178  6613 net.cpp:150] Setting up loaddata
I0421 20:12:23.149219  6613 net.cpp:157] Top shape: 1 3 428 428 (549552)
I0421 20:12:23.149224  6613 net.cpp:157] Top shape: 1 244 244 (59536)
I0421 20:12:23.149226  6613 net.cpp:157] Top shape: 1 244 244 (59536)
I0421 20:12:23.149229  6613 net.cpp:165] Memory required for data: 2674496
I0421 20:12:23.149235  6613 layer_factory.hpp:77] Creating layer conv_d0a-b
I0421 20:12:23.149250  6613 net.cpp:100] Creating Layer conv_d0a-b
I0421 20:12:23.149253  6613 net.cpp:434] conv_d0a-b <- data
I0421 20:12:23.149260  6613 net.cpp:408] conv_d0a-b -> d0b
I0421 20:12:23.149751  6613 net.cpp:150] Setting up conv_d0a-b
I0421 20:12:23.149761  6613 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0421 20:12:23.149777  6613 net.cpp:165] Memory required for data: 49132352
I0421 20:12:23.149785  6613 layer_factory.hpp:77] Creating layer relu_d0b
I0421 20:12:23.149806  6613 net.cpp:100] Creating Layer relu_d0b
I0421 20:12:23.149809  6613 net.cpp:434] relu_d0b <- d0b
I0421 20:12:23.149813  6613 net.cpp:395] relu_d0b -> d0b (in-place)
I0421 20:12:23.150044  6613 net.cpp:150] Setting up relu_d0b
I0421 20:12:23.150053  6613 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0421 20:12:23.150079  6613 net.cpp:165] Memory required for data: 95590208
I0421 20:12:23.150081  6613 layer_factory.hpp:77] Creating layer conv_d0b-c
I0421 20:12:23.150105  6613 net.cpp:100] Creating Layer conv_d0b-c
I0421 20:12:23.150107  6613 net.cpp:434] conv_d0b-c <- d0b
I0421 20:12:23.150115  6613 net.cpp:408] conv_d0b-c -> d0c
I0421 20:12:23.151613  6613 net.cpp:150] Setting up conv_d0b-c
I0421 20:12:23.151626  6613 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0421 20:12:23.151628  6613 net.cpp:165] Memory required for data: 141612864
I0421 20:12:23.151654  6613 layer_factory.hpp:77] Creating layer relu_d0c
I0421 20:12:23.151659  6613 net.cpp:100] Creating Layer relu_d0c
I0421 20:12:23.151664  6613 net.cpp:434] relu_d0c <- d0c
I0421 20:12:23.151669  6613 net.cpp:395] relu_d0c -> d0c (in-place)
I0421 20:12:23.151849  6613 net.cpp:150] Setting up relu_d0c
I0421 20:12:23.151857  6613 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0421 20:12:23.151860  6613 net.cpp:165] Memory required for data: 187635520
I0421 20:12:23.151862  6613 layer_factory.hpp:77] Creating layer d0c_relu_d0c_0_split
I0421 20:12:23.151868  6613 net.cpp:100] Creating Layer d0c_relu_d0c_0_split
I0421 20:12:23.151870  6613 net.cpp:434] d0c_relu_d0c_0_split <- d0c
I0421 20:12:23.151875  6613 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_0
I0421 20:12:23.151880  6613 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_1
I0421 20:12:23.151922  6613 net.cpp:150] Setting up d0c_relu_d0c_0_split
I0421 20:12:23.151928  6613 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0421 20:12:23.151932  6613 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0421 20:12:23.151933  6613 net.cpp:165] Memory required for data: 279680832
I0421 20:12:23.151937  6613 layer_factory.hpp:77] Creating layer pool_d0c-1a
I0421 20:12:23.151942  6613 net.cpp:100] Creating Layer pool_d0c-1a
I0421 20:12:23.151944  6613 net.cpp:434] pool_d0c-1a <- d0c_relu_d0c_0_split_0
I0421 20:12:23.151948  6613 net.cpp:408] pool_d0c-1a -> d1a
I0421 20:12:23.151983  6613 net.cpp:150] Setting up pool_d0c-1a
I0421 20:12:23.151988  6613 net.cpp:157] Top shape: 1 64 212 212 (2876416)
I0421 20:12:23.151991  6613 net.cpp:165] Memory required for data: 291186496
I0421 20:12:23.151993  6613 layer_factory.hpp:77] Creating layer conv_d1a-b
I0421 20:12:23.152000  6613 net.cpp:100] Creating Layer conv_d1a-b
I0421 20:12:23.152004  6613 net.cpp:434] conv_d1a-b <- d1a
I0421 20:12:23.152009  6613 net.cpp:408] conv_d1a-b -> d1b
I0421 20:12:23.153496  6613 net.cpp:150] Setting up conv_d1a-b
I0421 20:12:23.153508  6613 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0421 20:12:23.153528  6613 net.cpp:165] Memory required for data: 313765696
I0421 20:12:23.153537  6613 layer_factory.hpp:77] Creating layer relu_d1b
I0421 20:12:23.153543  6613 net.cpp:100] Creating Layer relu_d1b
I0421 20:12:23.153547  6613 net.cpp:434] relu_d1b <- d1b
I0421 20:12:23.153551  6613 net.cpp:395] relu_d1b -> d1b (in-place)
I0421 20:12:23.153743  6613 net.cpp:150] Setting up relu_d1b
I0421 20:12:23.153753  6613 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0421 20:12:23.153770  6613 net.cpp:165] Memory required for data: 336344896
I0421 20:12:23.153774  6613 layer_factory.hpp:77] Creating layer conv_d1b-c
I0421 20:12:23.153796  6613 net.cpp:100] Creating Layer conv_d1b-c
I0421 20:12:23.153798  6613 net.cpp:434] conv_d1b-c <- d1b
I0421 20:12:23.153805  6613 net.cpp:408] conv_d1b-c -> d1c
I0421 20:12:23.154829  6613 net.cpp:150] Setting up conv_d1b-c
I0421 20:12:23.154836  6613 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0421 20:12:23.154839  6613 net.cpp:165] Memory required for data: 358496064
I0421 20:12:23.154860  6613 layer_factory.hpp:77] Creating layer relu_d1c
I0421 20:12:23.154865  6613 net.cpp:100] Creating Layer relu_d1c
I0421 20:12:23.154866  6613 net.cpp:434] relu_d1c <- d1c
I0421 20:12:23.154870  6613 net.cpp:395] relu_d1c -> d1c (in-place)
I0421 20:12:23.155614  6613 net.cpp:150] Setting up relu_d1c
I0421 20:12:23.155627  6613 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0421 20:12:23.155628  6613 net.cpp:165] Memory required for data: 380647232
I0421 20:12:23.155663  6613 layer_factory.hpp:77] Creating layer d1c_relu_d1c_0_split
I0421 20:12:23.155684  6613 net.cpp:100] Creating Layer d1c_relu_d1c_0_split
I0421 20:12:23.155688  6613 net.cpp:434] d1c_relu_d1c_0_split <- d1c
I0421 20:12:23.155694  6613 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_0
I0421 20:12:23.155699  6613 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_1
I0421 20:12:23.155745  6613 net.cpp:150] Setting up d1c_relu_d1c_0_split
I0421 20:12:23.155752  6613 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0421 20:12:23.155755  6613 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0421 20:12:23.155757  6613 net.cpp:165] Memory required for data: 424949568
I0421 20:12:23.155761  6613 layer_factory.hpp:77] Creating layer pool_d1c-2a
I0421 20:12:23.155766  6613 net.cpp:100] Creating Layer pool_d1c-2a
I0421 20:12:23.155767  6613 net.cpp:434] pool_d1c-2a <- d1c_relu_d1c_0_split_0
I0421 20:12:23.155772  6613 net.cpp:408] pool_d1c-2a -> d2a
I0421 20:12:23.155807  6613 net.cpp:150] Setting up pool_d1c-2a
I0421 20:12:23.155813  6613 net.cpp:157] Top shape: 1 128 104 104 (1384448)
I0421 20:12:23.155817  6613 net.cpp:165] Memory required for data: 430487360
I0421 20:12:23.155818  6613 layer_factory.hpp:77] Creating layer conv_d2a-b
I0421 20:12:23.155825  6613 net.cpp:100] Creating Layer conv_d2a-b
I0421 20:12:23.155828  6613 net.cpp:434] conv_d2a-b <- d2a
I0421 20:12:23.155833  6613 net.cpp:408] conv_d2a-b -> d2b
I0421 20:12:23.158521  6613 net.cpp:150] Setting up conv_d2a-b
I0421 20:12:23.158535  6613 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0421 20:12:23.158536  6613 net.cpp:165] Memory required for data: 441141056
I0421 20:12:23.158561  6613 layer_factory.hpp:77] Creating layer relu_d2b
I0421 20:12:23.158566  6613 net.cpp:100] Creating Layer relu_d2b
I0421 20:12:23.158570  6613 net.cpp:434] relu_d2b <- d2b
I0421 20:12:23.158574  6613 net.cpp:395] relu_d2b -> d2b (in-place)
I0421 20:12:23.158751  6613 net.cpp:150] Setting up relu_d2b
I0421 20:12:23.158761  6613 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0421 20:12:23.158764  6613 net.cpp:165] Memory required for data: 451794752
I0421 20:12:23.158767  6613 layer_factory.hpp:77] Creating layer conv_d2b-c
I0421 20:12:23.158774  6613 net.cpp:100] Creating Layer conv_d2b-c
I0421 20:12:23.158776  6613 net.cpp:434] conv_d2b-c <- d2b
I0421 20:12:23.158782  6613 net.cpp:408] conv_d2b-c -> d2c
I0421 20:12:23.163045  6613 net.cpp:150] Setting up conv_d2b-c
I0421 20:12:23.163058  6613 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0421 20:12:23.163061  6613 net.cpp:165] Memory required for data: 462034752
I0421 20:12:23.163084  6613 layer_factory.hpp:77] Creating layer relu_d2c
I0421 20:12:23.163090  6613 net.cpp:100] Creating Layer relu_d2c
I0421 20:12:23.163094  6613 net.cpp:434] relu_d2c <- d2c
I0421 20:12:23.163097  6613 net.cpp:395] relu_d2c -> d2c (in-place)
I0421 20:12:23.163278  6613 net.cpp:150] Setting up relu_d2c
I0421 20:12:23.163288  6613 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0421 20:12:23.163290  6613 net.cpp:165] Memory required for data: 472274752
I0421 20:12:23.163293  6613 layer_factory.hpp:77] Creating layer d2c_relu_d2c_0_split
I0421 20:12:23.163298  6613 net.cpp:100] Creating Layer d2c_relu_d2c_0_split
I0421 20:12:23.163301  6613 net.cpp:434] d2c_relu_d2c_0_split <- d2c
I0421 20:12:23.163306  6613 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_0
I0421 20:12:23.163312  6613 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_1
I0421 20:12:23.163357  6613 net.cpp:150] Setting up d2c_relu_d2c_0_split
I0421 20:12:23.163363  6613 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0421 20:12:23.163367  6613 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0421 20:12:23.163368  6613 net.cpp:165] Memory required for data: 492754752
I0421 20:12:23.163372  6613 layer_factory.hpp:77] Creating layer pool_d2c-3a
I0421 20:12:23.163377  6613 net.cpp:100] Creating Layer pool_d2c-3a
I0421 20:12:23.163379  6613 net.cpp:434] pool_d2c-3a <- d2c_relu_d2c_0_split_0
I0421 20:12:23.163398  6613 net.cpp:408] pool_d2c-3a -> d3a
I0421 20:12:23.163435  6613 net.cpp:150] Setting up pool_d2c-3a
I0421 20:12:23.163442  6613 net.cpp:157] Top shape: 1 256 50 50 (640000)
I0421 20:12:23.163445  6613 net.cpp:165] Memory required for data: 495314752
I0421 20:12:23.163447  6613 layer_factory.hpp:77] Creating layer conv_d3a-b
I0421 20:12:23.163455  6613 net.cpp:100] Creating Layer conv_d3a-b
I0421 20:12:23.163457  6613 net.cpp:434] conv_d3a-b <- d3a
I0421 20:12:23.163462  6613 net.cpp:408] conv_d3a-b -> d3b
I0421 20:12:23.171247  6613 net.cpp:150] Setting up conv_d3a-b
I0421 20:12:23.171260  6613 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0421 20:12:23.171262  6613 net.cpp:165] Memory required for data: 500033344
I0421 20:12:23.171284  6613 layer_factory.hpp:77] Creating layer relu_d3b
I0421 20:12:23.171288  6613 net.cpp:100] Creating Layer relu_d3b
I0421 20:12:23.171293  6613 net.cpp:434] relu_d3b <- d3b
I0421 20:12:23.171296  6613 net.cpp:395] relu_d3b -> d3b (in-place)
I0421 20:12:23.171473  6613 net.cpp:150] Setting up relu_d3b
I0421 20:12:23.171481  6613 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0421 20:12:23.171483  6613 net.cpp:165] Memory required for data: 504751936
I0421 20:12:23.171486  6613 layer_factory.hpp:77] Creating layer conv_d3b-c
I0421 20:12:23.171494  6613 net.cpp:100] Creating Layer conv_d3b-c
I0421 20:12:23.171496  6613 net.cpp:434] conv_d3b-c <- d3b
I0421 20:12:23.171501  6613 net.cpp:408] conv_d3b-c -> d3c
I0421 20:12:23.186830  6613 net.cpp:150] Setting up conv_d3b-c
I0421 20:12:23.186841  6613 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0421 20:12:23.186843  6613 net.cpp:165] Memory required for data: 509085504
I0421 20:12:23.186866  6613 layer_factory.hpp:77] Creating layer relu_d3c
I0421 20:12:23.186870  6613 net.cpp:100] Creating Layer relu_d3c
I0421 20:12:23.186873  6613 net.cpp:434] relu_d3c <- d3c
I0421 20:12:23.186877  6613 net.cpp:395] relu_d3c -> d3c (in-place)
I0421 20:12:23.187623  6613 net.cpp:150] Setting up relu_d3c
I0421 20:12:23.187633  6613 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0421 20:12:23.187636  6613 net.cpp:165] Memory required for data: 513419072
I0421 20:12:23.187654  6613 layer_factory.hpp:77] Creating layer d3c_relu_d3c_0_split
I0421 20:12:23.187660  6613 net.cpp:100] Creating Layer d3c_relu_d3c_0_split
I0421 20:12:23.187664  6613 net.cpp:434] d3c_relu_d3c_0_split <- d3c
I0421 20:12:23.187669  6613 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_0
I0421 20:12:23.187675  6613 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_1
I0421 20:12:23.187718  6613 net.cpp:150] Setting up d3c_relu_d3c_0_split
I0421 20:12:23.187723  6613 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0421 20:12:23.187726  6613 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0421 20:12:23.187728  6613 net.cpp:165] Memory required for data: 522086208
I0421 20:12:23.187731  6613 layer_factory.hpp:77] Creating layer pool_d3c-4a
I0421 20:12:23.187736  6613 net.cpp:100] Creating Layer pool_d3c-4a
I0421 20:12:23.187738  6613 net.cpp:434] pool_d3c-4a <- d3c_relu_d3c_0_split_0
I0421 20:12:23.187742  6613 net.cpp:408] pool_d3c-4a -> d4a
I0421 20:12:23.187775  6613 net.cpp:150] Setting up pool_d3c-4a
I0421 20:12:23.187779  6613 net.cpp:157] Top shape: 1 512 23 23 (270848)
I0421 20:12:23.187782  6613 net.cpp:165] Memory required for data: 523169600
I0421 20:12:23.187783  6613 layer_factory.hpp:77] Creating layer conv_d4a-b
I0421 20:12:23.187791  6613 net.cpp:100] Creating Layer conv_d4a-b
I0421 20:12:23.187793  6613 net.cpp:434] conv_d4a-b <- d4a
I0421 20:12:23.187798  6613 net.cpp:408] conv_d4a-b -> d4b
I0421 20:12:23.217059  6613 net.cpp:150] Setting up conv_d4a-b
I0421 20:12:23.217070  6613 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0421 20:12:23.217072  6613 net.cpp:165] Memory required for data: 524975936
I0421 20:12:23.217082  6613 layer_factory.hpp:77] Creating layer relu_d4b
I0421 20:12:23.217087  6613 net.cpp:100] Creating Layer relu_d4b
I0421 20:12:23.217092  6613 net.cpp:434] relu_d4b <- d4b
I0421 20:12:23.217095  6613 net.cpp:395] relu_d4b -> d4b (in-place)
I0421 20:12:23.217280  6613 net.cpp:150] Setting up relu_d4b
I0421 20:12:23.217288  6613 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0421 20:12:23.217290  6613 net.cpp:165] Memory required for data: 526782272
I0421 20:12:23.217293  6613 layer_factory.hpp:77] Creating layer conv_d4b-c
I0421 20:12:23.217300  6613 net.cpp:100] Creating Layer conv_d4b-c
I0421 20:12:23.217303  6613 net.cpp:434] conv_d4b-c <- d4b
I0421 20:12:23.217308  6613 net.cpp:408] conv_d4b-c -> d4c
I0421 20:12:23.276298  6613 net.cpp:150] Setting up conv_d4b-c
I0421 20:12:23.276317  6613 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0421 20:12:23.276319  6613 net.cpp:165] Memory required for data: 528260928
I0421 20:12:23.276327  6613 layer_factory.hpp:77] Creating layer relu_d4c
I0421 20:12:23.276335  6613 net.cpp:100] Creating Layer relu_d4c
I0421 20:12:23.276340  6613 net.cpp:434] relu_d4c <- d4c
I0421 20:12:23.276345  6613 net.cpp:395] relu_d4c -> d4c (in-place)
I0421 20:12:23.276583  6613 net.cpp:150] Setting up relu_d4c
I0421 20:12:23.276589  6613 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0421 20:12:23.276592  6613 net.cpp:165] Memory required for data: 529739584
I0421 20:12:23.276594  6613 layer_factory.hpp:77] Creating layer upconv_d4c_u3a
I0421 20:12:23.276602  6613 net.cpp:100] Creating Layer upconv_d4c_u3a
I0421 20:12:23.276604  6613 net.cpp:434] upconv_d4c_u3a <- d4c
I0421 20:12:23.276610  6613 net.cpp:408] upconv_d4c_u3a -> u3a
I0421 20:12:23.290032  6613 net.cpp:150] Setting up upconv_d4c_u3a
I0421 20:12:23.290043  6613 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0421 20:12:23.290045  6613 net.cpp:165] Memory required for data: 532696896
I0421 20:12:23.290050  6613 layer_factory.hpp:77] Creating layer relu_u3a
I0421 20:12:23.290055  6613 net.cpp:100] Creating Layer relu_u3a
I0421 20:12:23.290058  6613 net.cpp:434] relu_u3a <- u3a
I0421 20:12:23.290062  6613 net.cpp:395] relu_u3a -> u3a (in-place)
I0421 20:12:23.290233  6613 net.cpp:150] Setting up relu_u3a
I0421 20:12:23.290240  6613 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0421 20:12:23.290242  6613 net.cpp:165] Memory required for data: 535654208
I0421 20:12:23.290244  6613 layer_factory.hpp:77] Creating layer u3a_relu_u3a_0_split
I0421 20:12:23.290249  6613 net.cpp:100] Creating Layer u3a_relu_u3a_0_split
I0421 20:12:23.290251  6613 net.cpp:434] u3a_relu_u3a_0_split <- u3a
I0421 20:12:23.290256  6613 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_0
I0421 20:12:23.290262  6613 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_1
I0421 20:12:23.290300  6613 net.cpp:150] Setting up u3a_relu_u3a_0_split
I0421 20:12:23.290305  6613 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0421 20:12:23.290310  6613 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0421 20:12:23.290311  6613 net.cpp:165] Memory required for data: 541568832
I0421 20:12:23.290313  6613 layer_factory.hpp:77] Creating layer crop_d3c-d3cc
I0421 20:12:23.290323  6613 net.cpp:100] Creating Layer crop_d3c-d3cc
I0421 20:12:23.290328  6613 net.cpp:434] crop_d3c-d3cc <- d3c_relu_d3c_0_split_1
I0421 20:12:23.290330  6613 net.cpp:434] crop_d3c-d3cc <- u3a_relu_u3a_0_split_0
I0421 20:12:23.290334  6613 net.cpp:408] crop_d3c-d3cc -> d3cc
I0421 20:12:23.290355  6613 net.cpp:150] Setting up crop_d3c-d3cc
I0421 20:12:23.290360  6613 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0421 20:12:23.290362  6613 net.cpp:165] Memory required for data: 544526144
I0421 20:12:23.290364  6613 layer_factory.hpp:77] Creating layer concat_d3cc_u3a-b
I0421 20:12:23.290369  6613 net.cpp:100] Creating Layer concat_d3cc_u3a-b
I0421 20:12:23.290371  6613 net.cpp:434] concat_d3cc_u3a-b <- u3a_relu_u3a_0_split_1
I0421 20:12:23.290374  6613 net.cpp:434] concat_d3cc_u3a-b <- d3cc
I0421 20:12:23.290379  6613 net.cpp:408] concat_d3cc_u3a-b -> u3b
I0421 20:12:23.290397  6613 net.cpp:150] Setting up concat_d3cc_u3a-b
I0421 20:12:23.290401  6613 net.cpp:157] Top shape: 1 1024 38 38 (1478656)
I0421 20:12:23.290403  6613 net.cpp:165] Memory required for data: 550440768
I0421 20:12:23.290405  6613 layer_factory.hpp:77] Creating layer conv_u3b-c
I0421 20:12:23.290447  6613 net.cpp:100] Creating Layer conv_u3b-c
I0421 20:12:23.290452  6613 net.cpp:434] conv_u3b-c <- u3b
I0421 20:12:23.290457  6613 net.cpp:408] conv_u3b-c -> u3c
I0421 20:12:23.319391  6613 net.cpp:150] Setting up conv_u3b-c
I0421 20:12:23.319402  6613 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0421 20:12:23.319406  6613 net.cpp:165] Memory required for data: 553094976
I0421 20:12:23.319411  6613 layer_factory.hpp:77] Creating layer relu_u3c
I0421 20:12:23.319416  6613 net.cpp:100] Creating Layer relu_u3c
I0421 20:12:23.319418  6613 net.cpp:434] relu_u3c <- u3c
I0421 20:12:23.319423  6613 net.cpp:395] relu_u3c -> u3c (in-place)
I0421 20:12:23.320152  6613 net.cpp:150] Setting up relu_u3c
I0421 20:12:23.320163  6613 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0421 20:12:23.320164  6613 net.cpp:165] Memory required for data: 555749184
I0421 20:12:23.320168  6613 layer_factory.hpp:77] Creating layer conv_u3c-d
I0421 20:12:23.320175  6613 net.cpp:100] Creating Layer conv_u3c-d
I0421 20:12:23.320178  6613 net.cpp:434] conv_u3c-d <- u3c
I0421 20:12:23.320184  6613 net.cpp:408] conv_u3c-d -> u3d
I0421 20:12:23.334777  6613 net.cpp:150] Setting up conv_u3c-d
I0421 20:12:23.334787  6613 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0421 20:12:23.334789  6613 net.cpp:165] Memory required for data: 558116672
I0421 20:12:23.334794  6613 layer_factory.hpp:77] Creating layer relu_u3d
I0421 20:12:23.334800  6613 net.cpp:100] Creating Layer relu_u3d
I0421 20:12:23.334802  6613 net.cpp:434] relu_u3d <- u3d
I0421 20:12:23.334806  6613 net.cpp:395] relu_u3d -> u3d (in-place)
I0421 20:12:23.334971  6613 net.cpp:150] Setting up relu_u3d
I0421 20:12:23.334978  6613 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0421 20:12:23.334980  6613 net.cpp:165] Memory required for data: 560484160
I0421 20:12:23.334983  6613 layer_factory.hpp:77] Creating layer upconv_u3d_u2a
I0421 20:12:23.334988  6613 net.cpp:100] Creating Layer upconv_u3d_u2a
I0421 20:12:23.334991  6613 net.cpp:434] upconv_u3d_u2a <- u3d
I0421 20:12:23.334996  6613 net.cpp:408] upconv_u3d_u2a -> u2a
I0421 20:12:23.338717  6613 net.cpp:150] Setting up upconv_u3d_u2a
I0421 20:12:23.338727  6613 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0421 20:12:23.338731  6613 net.cpp:165] Memory required for data: 565219136
I0421 20:12:23.338735  6613 layer_factory.hpp:77] Creating layer relu_u2a
I0421 20:12:23.338740  6613 net.cpp:100] Creating Layer relu_u2a
I0421 20:12:23.338743  6613 net.cpp:434] relu_u2a <- u2a
I0421 20:12:23.338748  6613 net.cpp:395] relu_u2a -> u2a (in-place)
I0421 20:12:23.338953  6613 net.cpp:150] Setting up relu_u2a
I0421 20:12:23.338960  6613 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0421 20:12:23.338963  6613 net.cpp:165] Memory required for data: 569954112
I0421 20:12:23.338965  6613 layer_factory.hpp:77] Creating layer u2a_relu_u2a_0_split
I0421 20:12:23.338970  6613 net.cpp:100] Creating Layer u2a_relu_u2a_0_split
I0421 20:12:23.338973  6613 net.cpp:434] u2a_relu_u2a_0_split <- u2a
I0421 20:12:23.338979  6613 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_0
I0421 20:12:23.338985  6613 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_1
I0421 20:12:23.339027  6613 net.cpp:150] Setting up u2a_relu_u2a_0_split
I0421 20:12:23.339031  6613 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0421 20:12:23.339035  6613 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0421 20:12:23.339037  6613 net.cpp:165] Memory required for data: 579424064
I0421 20:12:23.339040  6613 layer_factory.hpp:77] Creating layer crop_d2c-d2cc
I0421 20:12:23.339046  6613 net.cpp:100] Creating Layer crop_d2c-d2cc
I0421 20:12:23.339048  6613 net.cpp:434] crop_d2c-d2cc <- d2c_relu_d2c_0_split_1
I0421 20:12:23.339052  6613 net.cpp:434] crop_d2c-d2cc <- u2a_relu_u2a_0_split_0
I0421 20:12:23.339056  6613 net.cpp:408] crop_d2c-d2cc -> d2cc
I0421 20:12:23.339078  6613 net.cpp:150] Setting up crop_d2c-d2cc
I0421 20:12:23.339083  6613 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0421 20:12:23.339085  6613 net.cpp:165] Memory required for data: 584159040
I0421 20:12:23.339108  6613 layer_factory.hpp:77] Creating layer concat_d2cc_u2a-b
I0421 20:12:23.339113  6613 net.cpp:100] Creating Layer concat_d2cc_u2a-b
I0421 20:12:23.339115  6613 net.cpp:434] concat_d2cc_u2a-b <- u2a_relu_u2a_0_split_1
I0421 20:12:23.339120  6613 net.cpp:434] concat_d2cc_u2a-b <- d2cc
I0421 20:12:23.339125  6613 net.cpp:408] concat_d2cc_u2a-b -> u2b
I0421 20:12:23.339149  6613 net.cpp:150] Setting up concat_d2cc_u2a-b
I0421 20:12:23.339154  6613 net.cpp:157] Top shape: 1 512 68 68 (2367488)
I0421 20:12:23.339156  6613 net.cpp:165] Memory required for data: 593628992
I0421 20:12:23.339159  6613 layer_factory.hpp:77] Creating layer conv_u2b-c
I0421 20:12:23.339165  6613 net.cpp:100] Creating Layer conv_u2b-c
I0421 20:12:23.339169  6613 net.cpp:434] conv_u2b-c <- u2b
I0421 20:12:23.339174  6613 net.cpp:408] conv_u2b-c -> u2c
I0421 20:12:23.347573  6613 net.cpp:150] Setting up conv_u2b-c
I0421 20:12:23.347584  6613 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0421 20:12:23.347585  6613 net.cpp:165] Memory required for data: 598089536
I0421 20:12:23.347591  6613 layer_factory.hpp:77] Creating layer relu_u2c
I0421 20:12:23.347596  6613 net.cpp:100] Creating Layer relu_u2c
I0421 20:12:23.347599  6613 net.cpp:434] relu_u2c <- u2c
I0421 20:12:23.347604  6613 net.cpp:395] relu_u2c -> u2c (in-place)
I0421 20:12:23.348393  6613 net.cpp:150] Setting up relu_u2c
I0421 20:12:23.348403  6613 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0421 20:12:23.348405  6613 net.cpp:165] Memory required for data: 602550080
I0421 20:12:23.348408  6613 layer_factory.hpp:77] Creating layer conv_u2c-d
I0421 20:12:23.348417  6613 net.cpp:100] Creating Layer conv_u2c-d
I0421 20:12:23.348420  6613 net.cpp:434] conv_u2c-d <- u2c
I0421 20:12:23.348426  6613 net.cpp:408] conv_u2c-d -> u2d
I0421 20:12:23.353037  6613 net.cpp:150] Setting up conv_u2c-d
I0421 20:12:23.353049  6613 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0421 20:12:23.353050  6613 net.cpp:165] Memory required for data: 606744384
I0421 20:12:23.353056  6613 layer_factory.hpp:77] Creating layer relu_u2d
I0421 20:12:23.353061  6613 net.cpp:100] Creating Layer relu_u2d
I0421 20:12:23.353065  6613 net.cpp:434] relu_u2d <- u2d
I0421 20:12:23.353070  6613 net.cpp:395] relu_u2d -> u2d (in-place)
I0421 20:12:23.353241  6613 net.cpp:150] Setting up relu_u2d
I0421 20:12:23.353248  6613 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0421 20:12:23.353251  6613 net.cpp:165] Memory required for data: 610938688
I0421 20:12:23.353253  6613 layer_factory.hpp:77] Creating layer upconv_u2d_u1a
I0421 20:12:23.353260  6613 net.cpp:100] Creating Layer upconv_u2d_u1a
I0421 20:12:23.353263  6613 net.cpp:434] upconv_u2d_u1a <- u2d
I0421 20:12:23.353269  6613 net.cpp:408] upconv_u2d_u1a -> u1a
I0421 20:12:23.354315  6613 net.cpp:150] Setting up upconv_u2d_u1a
I0421 20:12:23.354321  6613 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0421 20:12:23.354323  6613 net.cpp:165] Memory required for data: 619327296
I0421 20:12:23.354334  6613 layer_factory.hpp:77] Creating layer relu_u1a
I0421 20:12:23.354339  6613 net.cpp:100] Creating Layer relu_u1a
I0421 20:12:23.354341  6613 net.cpp:434] relu_u1a <- u1a
I0421 20:12:23.354346  6613 net.cpp:395] relu_u1a -> u1a (in-place)
I0421 20:12:23.354517  6613 net.cpp:150] Setting up relu_u1a
I0421 20:12:23.354523  6613 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0421 20:12:23.354526  6613 net.cpp:165] Memory required for data: 627715904
I0421 20:12:23.354528  6613 layer_factory.hpp:77] Creating layer u1a_relu_u1a_0_split
I0421 20:12:23.354533  6613 net.cpp:100] Creating Layer u1a_relu_u1a_0_split
I0421 20:12:23.354537  6613 net.cpp:434] u1a_relu_u1a_0_split <- u1a
I0421 20:12:23.354540  6613 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_0
I0421 20:12:23.354547  6613 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_1
I0421 20:12:23.354589  6613 net.cpp:150] Setting up u1a_relu_u1a_0_split
I0421 20:12:23.354593  6613 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0421 20:12:23.354596  6613 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0421 20:12:23.354614  6613 net.cpp:165] Memory required for data: 644493120
I0421 20:12:23.354617  6613 layer_factory.hpp:77] Creating layer crop_d1c-d1cc
I0421 20:12:23.354638  6613 net.cpp:100] Creating Layer crop_d1c-d1cc
I0421 20:12:23.354641  6613 net.cpp:434] crop_d1c-d1cc <- d1c_relu_d1c_0_split_1
I0421 20:12:23.354645  6613 net.cpp:434] crop_d1c-d1cc <- u1a_relu_u1a_0_split_0
I0421 20:12:23.354651  6613 net.cpp:408] crop_d1c-d1cc -> d1cc
I0421 20:12:23.354692  6613 net.cpp:150] Setting up crop_d1c-d1cc
I0421 20:12:23.354696  6613 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0421 20:12:23.354698  6613 net.cpp:165] Memory required for data: 652881728
I0421 20:12:23.354701  6613 layer_factory.hpp:77] Creating layer concat_d1cc_u1a-b
I0421 20:12:23.354707  6613 net.cpp:100] Creating Layer concat_d1cc_u1a-b
I0421 20:12:23.354708  6613 net.cpp:434] concat_d1cc_u1a-b <- u1a_relu_u1a_0_split_1
I0421 20:12:23.354712  6613 net.cpp:434] concat_d1cc_u1a-b <- d1cc
I0421 20:12:23.354717  6613 net.cpp:408] concat_d1cc_u1a-b -> u1b
I0421 20:12:23.354737  6613 net.cpp:150] Setting up concat_d1cc_u1a-b
I0421 20:12:23.354742  6613 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0421 20:12:23.354743  6613 net.cpp:165] Memory required for data: 669658944
I0421 20:12:23.354746  6613 layer_factory.hpp:77] Creating layer conv_u1b-c
I0421 20:12:23.354753  6613 net.cpp:100] Creating Layer conv_u1b-c
I0421 20:12:23.354755  6613 net.cpp:434] conv_u1b-c <- u1b
I0421 20:12:23.354760  6613 net.cpp:408] conv_u1b-c -> u1c
I0421 20:12:23.357636  6613 net.cpp:150] Setting up conv_u1b-c
I0421 20:12:23.357647  6613 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0421 20:12:23.357650  6613 net.cpp:165] Memory required for data: 677787456
I0421 20:12:23.357656  6613 layer_factory.hpp:77] Creating layer relu_u1c
I0421 20:12:23.357661  6613 net.cpp:100] Creating Layer relu_u1c
I0421 20:12:23.357666  6613 net.cpp:434] relu_u1c <- u1c
I0421 20:12:23.357669  6613 net.cpp:395] relu_u1c -> u1c (in-place)
I0421 20:12:23.357861  6613 net.cpp:150] Setting up relu_u1c
I0421 20:12:23.357867  6613 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0421 20:12:23.357870  6613 net.cpp:165] Memory required for data: 685915968
I0421 20:12:23.357872  6613 layer_factory.hpp:77] Creating layer conv_u1c-d
I0421 20:12:23.357880  6613 net.cpp:100] Creating Layer conv_u1c-d
I0421 20:12:23.357883  6613 net.cpp:434] conv_u1c-d <- u1c
I0421 20:12:23.357889  6613 net.cpp:408] conv_u1c-d -> u1d
I0421 20:12:23.359010  6613 net.cpp:150] Setting up conv_u1c-d
I0421 20:12:23.359017  6613 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0421 20:12:23.359020  6613 net.cpp:165] Memory required for data: 693788480
I0421 20:12:23.359025  6613 layer_factory.hpp:77] Creating layer relu_u1d
I0421 20:12:23.359028  6613 net.cpp:100] Creating Layer relu_u1d
I0421 20:12:23.359031  6613 net.cpp:434] relu_u1d <- u1d
I0421 20:12:23.359036  6613 net.cpp:395] relu_u1d -> u1d (in-place)
I0421 20:12:23.359839  6613 net.cpp:150] Setting up relu_u1d
I0421 20:12:23.359853  6613 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0421 20:12:23.359855  6613 net.cpp:165] Memory required for data: 701660992
I0421 20:12:23.359874  6613 layer_factory.hpp:77] Creating layer upconv_u1d_u0a
I0421 20:12:23.359882  6613 net.cpp:100] Creating Layer upconv_u1d_u0a
I0421 20:12:23.359885  6613 net.cpp:434] upconv_u1d_u0a <- u1d
I0421 20:12:23.359891  6613 net.cpp:408] upconv_u1d_u0a -> u0a
I0421 20:12:23.360591  6613 net.cpp:150] Setting up upconv_u1d_u0a
I0421 20:12:23.360600  6613 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0421 20:12:23.360602  6613 net.cpp:165] Memory required for data: 733151040
I0421 20:12:23.360607  6613 layer_factory.hpp:77] Creating layer relu_u0a
I0421 20:12:23.360613  6613 net.cpp:100] Creating Layer relu_u0a
I0421 20:12:23.360616  6613 net.cpp:434] relu_u0a <- u0a
I0421 20:12:23.360620  6613 net.cpp:395] relu_u0a -> u0a (in-place)
I0421 20:12:23.360795  6613 net.cpp:150] Setting up relu_u0a
I0421 20:12:23.360803  6613 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0421 20:12:23.360821  6613 net.cpp:165] Memory required for data: 764641088
I0421 20:12:23.360824  6613 layer_factory.hpp:77] Creating layer u0a_relu_u0a_0_split
I0421 20:12:23.360829  6613 net.cpp:100] Creating Layer u0a_relu_u0a_0_split
I0421 20:12:23.360833  6613 net.cpp:434] u0a_relu_u0a_0_split <- u0a
I0421 20:12:23.360838  6613 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_0
I0421 20:12:23.360846  6613 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_1
I0421 20:12:23.360904  6613 net.cpp:150] Setting up u0a_relu_u0a_0_split
I0421 20:12:23.360911  6613 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0421 20:12:23.360914  6613 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0421 20:12:23.360916  6613 net.cpp:165] Memory required for data: 827621184
I0421 20:12:23.360919  6613 layer_factory.hpp:77] Creating layer crop_d0c-d0cc
I0421 20:12:23.360924  6613 net.cpp:100] Creating Layer crop_d0c-d0cc
I0421 20:12:23.360927  6613 net.cpp:434] crop_d0c-d0cc <- d0c_relu_d0c_0_split_1
I0421 20:12:23.360931  6613 net.cpp:434] crop_d0c-d0cc <- u0a_relu_u0a_0_split_0
I0421 20:12:23.360936  6613 net.cpp:408] crop_d0c-d0cc -> d0cc
I0421 20:12:23.360960  6613 net.cpp:150] Setting up crop_d0c-d0cc
I0421 20:12:23.360965  6613 net.cpp:157] Top shape: 1 64 248 248 (3936256)
I0421 20:12:23.360966  6613 net.cpp:165] Memory required for data: 843366208
I0421 20:12:23.360968  6613 layer_factory.hpp:77] Creating layer concat_d0cc_u0a-b
I0421 20:12:23.360973  6613 net.cpp:100] Creating Layer concat_d0cc_u0a-b
I0421 20:12:23.360975  6613 net.cpp:434] concat_d0cc_u0a-b <- u0a_relu_u0a_0_split_1
I0421 20:12:23.360980  6613 net.cpp:434] concat_d0cc_u0a-b <- d0cc
I0421 20:12:23.360983  6613 net.cpp:408] concat_d0cc_u0a-b -> u0b
I0421 20:12:23.361006  6613 net.cpp:150] Setting up concat_d0cc_u0a-b
I0421 20:12:23.361009  6613 net.cpp:157] Top shape: 1 192 248 248 (11808768)
I0421 20:12:23.361011  6613 net.cpp:165] Memory required for data: 890601280
I0421 20:12:23.361013  6613 layer_factory.hpp:77] Creating layer conv_u0b-c
I0421 20:12:23.361021  6613 net.cpp:100] Creating Layer conv_u0b-c
I0421 20:12:23.361024  6613 net.cpp:434] conv_u0b-c <- u0b
I0421 20:12:23.361029  6613 net.cpp:408] conv_u0b-c -> u0c
I0421 20:12:23.361970  6613 net.cpp:150] Setting up conv_u0b-c
I0421 20:12:23.361979  6613 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0421 20:12:23.361980  6613 net.cpp:165] Memory required for data: 906093376
I0421 20:12:23.362001  6613 layer_factory.hpp:77] Creating layer relu_u0c
I0421 20:12:23.362005  6613 net.cpp:100] Creating Layer relu_u0c
I0421 20:12:23.362009  6613 net.cpp:434] relu_u0c <- u0c
I0421 20:12:23.362012  6613 net.cpp:395] relu_u0c -> u0c (in-place)
I0421 20:12:23.362180  6613 net.cpp:150] Setting up relu_u0c
I0421 20:12:23.362190  6613 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0421 20:12:23.362192  6613 net.cpp:165] Memory required for data: 921585472
I0421 20:12:23.362195  6613 layer_factory.hpp:77] Creating layer conv_u0c-d
I0421 20:12:23.362200  6613 net.cpp:100] Creating Layer conv_u0c-d
I0421 20:12:23.362202  6613 net.cpp:434] conv_u0c-d <- u0c
I0421 20:12:23.362208  6613 net.cpp:408] conv_u0c-d -> u0d
I0421 20:12:23.362700  6613 net.cpp:150] Setting up conv_u0c-d
I0421 20:12:23.362707  6613 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0421 20:12:23.362709  6613 net.cpp:165] Memory required for data: 936826688
I0421 20:12:23.362730  6613 layer_factory.hpp:77] Creating layer relu_u0d
I0421 20:12:23.362741  6613 net.cpp:100] Creating Layer relu_u0d
I0421 20:12:23.362746  6613 net.cpp:434] relu_u0d <- u0d
I0421 20:12:23.362749  6613 net.cpp:395] relu_u0d -> u0d (in-place)
I0421 20:12:23.363596  6613 net.cpp:150] Setting up relu_u0d
I0421 20:12:23.363605  6613 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0421 20:12:23.363607  6613 net.cpp:165] Memory required for data: 952067904
I0421 20:12:23.363626  6613 layer_factory.hpp:77] Creating layer conv_u0d-score
I0421 20:12:23.363633  6613 net.cpp:100] Creating Layer conv_u0d-score
I0421 20:12:23.363636  6613 net.cpp:434] conv_u0d-score <- u0d
I0421 20:12:23.363652  6613 net.cpp:408] conv_u0d-score -> score
I0421 20:12:23.363946  6613 net.cpp:150] Setting up conv_u0d-score
I0421 20:12:23.363955  6613 net.cpp:157] Top shape: 1 3 244 244 (178608)
I0421 20:12:23.363958  6613 net.cpp:165] Memory required for data: 952782336
I0421 20:12:23.363963  6613 layer_factory.hpp:77] Creating layer loss
I0421 20:12:23.363968  6613 net.cpp:100] Creating Layer loss
I0421 20:12:23.363971  6613 net.cpp:434] loss <- score
I0421 20:12:23.363976  6613 net.cpp:434] loss <- label
I0421 20:12:23.363978  6613 net.cpp:434] loss <- weights
I0421 20:12:23.363983  6613 net.cpp:408] loss -> loss
I0421 20:12:23.363991  6613 layer_factory.hpp:77] Creating layer loss
I0421 20:12:23.366830  6613 net.cpp:150] Setting up loss
I0421 20:12:23.366842  6613 net.cpp:157] Top shape: (1)
I0421 20:12:23.366845  6613 net.cpp:160]     with loss weight 1
I0421 20:12:23.366870  6613 net.cpp:165] Memory required for data: 952782340
I0421 20:12:23.366873  6613 net.cpp:226] loss needs backward computation.
I0421 20:12:23.366878  6613 net.cpp:226] conv_u0d-score needs backward computation.
I0421 20:12:23.366880  6613 net.cpp:226] relu_u0d needs backward computation.
I0421 20:12:23.366883  6613 net.cpp:226] conv_u0c-d needs backward computation.
I0421 20:12:23.366885  6613 net.cpp:226] relu_u0c needs backward computation.
I0421 20:12:23.366888  6613 net.cpp:226] conv_u0b-c needs backward computation.
I0421 20:12:23.366890  6613 net.cpp:226] concat_d0cc_u0a-b needs backward computation.
I0421 20:12:23.366894  6613 net.cpp:226] crop_d0c-d0cc needs backward computation.
I0421 20:12:23.366896  6613 net.cpp:226] u0a_relu_u0a_0_split needs backward computation.
I0421 20:12:23.366899  6613 net.cpp:226] relu_u0a needs backward computation.
I0421 20:12:23.366901  6613 net.cpp:226] upconv_u1d_u0a needs backward computation.
I0421 20:12:23.366904  6613 net.cpp:226] relu_u1d needs backward computation.
I0421 20:12:23.366906  6613 net.cpp:226] conv_u1c-d needs backward computation.
I0421 20:12:23.366909  6613 net.cpp:226] relu_u1c needs backward computation.
I0421 20:12:23.366911  6613 net.cpp:226] conv_u1b-c needs backward computation.
I0421 20:12:23.366914  6613 net.cpp:226] concat_d1cc_u1a-b needs backward computation.
I0421 20:12:23.366916  6613 net.cpp:226] crop_d1c-d1cc needs backward computation.
I0421 20:12:23.366920  6613 net.cpp:226] u1a_relu_u1a_0_split needs backward computation.
I0421 20:12:23.366922  6613 net.cpp:226] relu_u1a needs backward computation.
I0421 20:12:23.366925  6613 net.cpp:226] upconv_u2d_u1a needs backward computation.
I0421 20:12:23.366927  6613 net.cpp:226] relu_u2d needs backward computation.
I0421 20:12:23.366930  6613 net.cpp:226] conv_u2c-d needs backward computation.
I0421 20:12:23.366932  6613 net.cpp:226] relu_u2c needs backward computation.
I0421 20:12:23.366935  6613 net.cpp:226] conv_u2b-c needs backward computation.
I0421 20:12:23.366937  6613 net.cpp:226] concat_d2cc_u2a-b needs backward computation.
I0421 20:12:23.366940  6613 net.cpp:226] crop_d2c-d2cc needs backward computation.
I0421 20:12:23.366943  6613 net.cpp:226] u2a_relu_u2a_0_split needs backward computation.
I0421 20:12:23.366946  6613 net.cpp:226] relu_u2a needs backward computation.
I0421 20:12:23.366950  6613 net.cpp:226] upconv_u3d_u2a needs backward computation.
I0421 20:12:23.366951  6613 net.cpp:226] relu_u3d needs backward computation.
I0421 20:12:23.366953  6613 net.cpp:226] conv_u3c-d needs backward computation.
I0421 20:12:23.366956  6613 net.cpp:226] relu_u3c needs backward computation.
I0421 20:12:23.366960  6613 net.cpp:226] conv_u3b-c needs backward computation.
I0421 20:12:23.366961  6613 net.cpp:226] concat_d3cc_u3a-b needs backward computation.
I0421 20:12:23.366966  6613 net.cpp:226] crop_d3c-d3cc needs backward computation.
I0421 20:12:23.366968  6613 net.cpp:226] u3a_relu_u3a_0_split needs backward computation.
I0421 20:12:23.366971  6613 net.cpp:226] relu_u3a needs backward computation.
I0421 20:12:23.366973  6613 net.cpp:226] upconv_d4c_u3a needs backward computation.
I0421 20:12:23.366976  6613 net.cpp:226] relu_d4c needs backward computation.
I0421 20:12:23.366991  6613 net.cpp:226] conv_d4b-c needs backward computation.
I0421 20:12:23.366994  6613 net.cpp:226] relu_d4b needs backward computation.
I0421 20:12:23.366997  6613 net.cpp:226] conv_d4a-b needs backward computation.
I0421 20:12:23.366999  6613 net.cpp:226] pool_d3c-4a needs backward computation.
I0421 20:12:23.367003  6613 net.cpp:226] d3c_relu_d3c_0_split needs backward computation.
I0421 20:12:23.367007  6613 net.cpp:226] relu_d3c needs backward computation.
I0421 20:12:23.367008  6613 net.cpp:226] conv_d3b-c needs backward computation.
I0421 20:12:23.367012  6613 net.cpp:226] relu_d3b needs backward computation.
I0421 20:12:23.367014  6613 net.cpp:226] conv_d3a-b needs backward computation.
I0421 20:12:23.367017  6613 net.cpp:226] pool_d2c-3a needs backward computation.
I0421 20:12:23.367019  6613 net.cpp:226] d2c_relu_d2c_0_split needs backward computation.
I0421 20:12:23.367022  6613 net.cpp:226] relu_d2c needs backward computation.
I0421 20:12:23.367025  6613 net.cpp:226] conv_d2b-c needs backward computation.
I0421 20:12:23.367027  6613 net.cpp:226] relu_d2b needs backward computation.
I0421 20:12:23.367029  6613 net.cpp:226] conv_d2a-b needs backward computation.
I0421 20:12:23.367033  6613 net.cpp:226] pool_d1c-2a needs backward computation.
I0421 20:12:23.367035  6613 net.cpp:226] d1c_relu_d1c_0_split needs backward computation.
I0421 20:12:23.367038  6613 net.cpp:226] relu_d1c needs backward computation.
I0421 20:12:23.367040  6613 net.cpp:226] conv_d1b-c needs backward computation.
I0421 20:12:23.367043  6613 net.cpp:226] relu_d1b needs backward computation.
I0421 20:12:23.367046  6613 net.cpp:226] conv_d1a-b needs backward computation.
I0421 20:12:23.367048  6613 net.cpp:226] pool_d0c-1a needs backward computation.
I0421 20:12:23.367051  6613 net.cpp:226] d0c_relu_d0c_0_split needs backward computation.
I0421 20:12:23.367054  6613 net.cpp:226] relu_d0c needs backward computation.
I0421 20:12:23.367058  6613 net.cpp:226] conv_d0b-c needs backward computation.
I0421 20:12:23.367059  6613 net.cpp:226] relu_d0b needs backward computation.
I0421 20:12:23.367061  6613 net.cpp:226] conv_d0a-b needs backward computation.
I0421 20:12:23.367065  6613 net.cpp:228] loaddata does not need backward computation.
I0421 20:12:23.367072  6613 net.cpp:270] This network produces output loss
I0421 20:12:23.367126  6613 net.cpp:283] Network initialization done.
I0421 20:12:23.367311  6613 solver.cpp:60] Solver scaffolding done.
I0421 20:12:23.385977  6613 solver.cpp:337] Iteration 0, Testing net (#0)
I0421 20:12:23.391429  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 20:12:23.391436  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 20:12:23.398994  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 20:12:23.406337  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 20:12:23.406344  6613 net.cpp:693] Ignoring source layer visualize
I0421 20:12:23.406347  6613 net.cpp:693] Ignoring source layer fake
I0421 20:16:21.449297  6613 solver.cpp:404]     Test net output #0: loss = 1.08927 (* 1 = 1.08927 loss)
I0421 20:16:22.134507  6613 solver.cpp:228] Iteration 0, loss = 1.08189
I0421 20:16:22.134547  6613 solver.cpp:244]     Train net output #0: loss = 1.08189 (* 1 = 1.08189 loss)
I0421 20:16:22.134553  6613 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0421 20:18:12.427376  6613 solver.cpp:228] Iteration 100, loss = 0.41078
I0421 20:18:12.427533  6613 solver.cpp:244]     Train net output #0: loss = 0.41078 (* 1 = 0.41078 loss)
I0421 20:18:12.427541  6613 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0421 20:19:47.658689  6613 solver.cpp:228] Iteration 200, loss = 0.374984
I0421 20:19:47.658830  6613 solver.cpp:244]     Train net output #0: loss = 0.374984 (* 1 = 0.374984 loss)
I0421 20:19:47.658838  6613 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0421 20:21:37.609077  6613 solver.cpp:228] Iteration 300, loss = 0.309927
I0421 20:21:37.609227  6613 solver.cpp:244]     Train net output #0: loss = 0.309927 (* 1 = 0.309927 loss)
I0421 20:21:37.609236  6613 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0421 20:23:29.699992  6613 solver.cpp:228] Iteration 400, loss = 0.932074
I0421 20:23:29.700153  6613 solver.cpp:244]     Train net output #0: loss = 0.932074 (* 1 = 0.932074 loss)
I0421 20:23:29.700160  6613 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0421 20:25:23.487359  6613 solver.cpp:228] Iteration 500, loss = 0.468678
I0421 20:25:23.487515  6613 solver.cpp:244]     Train net output #0: loss = 0.468678 (* 1 = 0.468678 loss)
I0421 20:25:23.487524  6613 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0421 20:27:17.579319  6613 solver.cpp:228] Iteration 600, loss = 0.306926
I0421 20:27:17.579464  6613 solver.cpp:244]     Train net output #0: loss = 0.306926 (* 1 = 0.306926 loss)
I0421 20:27:17.579473  6613 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0421 20:28:52.860556  6613 solver.cpp:228] Iteration 700, loss = 0.377977
I0421 20:28:52.860697  6613 solver.cpp:244]     Train net output #0: loss = 0.377977 (* 1 = 0.377977 loss)
I0421 20:28:52.860703  6613 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0421 20:30:45.403995  6613 solver.cpp:228] Iteration 800, loss = 0.471538
I0421 20:30:45.404140  6613 solver.cpp:244]     Train net output #0: loss = 0.471538 (* 1 = 0.471538 loss)
I0421 20:30:45.404148  6613 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0421 20:32:37.856973  6613 solver.cpp:228] Iteration 900, loss = 0.341196
I0421 20:32:37.857128  6613 solver.cpp:244]     Train net output #0: loss = 0.341196 (* 1 = 0.341196 loss)
I0421 20:32:37.857136  6613 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0421 20:34:29.621819  6613 solver.cpp:337] Iteration 1000, Testing net (#0)
I0421 20:34:29.621958  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 20:34:29.621963  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 20:34:29.621968  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 20:34:29.621986  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 20:34:29.621989  6613 net.cpp:693] Ignoring source layer visualize
I0421 20:34:29.621991  6613 net.cpp:693] Ignoring source layer fake
I0421 20:37:50.724012  6613 solver.cpp:404]     Test net output #0: loss = 0.44987 (* 1 = 0.44987 loss)
I0421 20:37:51.362730  6613 solver.cpp:228] Iteration 1000, loss = 0.330201
I0421 20:37:51.362751  6613 solver.cpp:244]     Train net output #0: loss = 0.330201 (* 1 = 0.330201 loss)
I0421 20:37:51.362773  6613 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0421 20:39:26.905952  6613 solver.cpp:228] Iteration 1100, loss = 0.261798
I0421 20:39:26.906108  6613 solver.cpp:244]     Train net output #0: loss = 0.261798 (* 1 = 0.261798 loss)
I0421 20:39:26.906116  6613 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0421 20:41:17.887054  6613 solver.cpp:228] Iteration 1200, loss = 0.30059
I0421 20:41:17.887223  6613 solver.cpp:244]     Train net output #0: loss = 0.30059 (* 1 = 0.30059 loss)
I0421 20:41:17.887228  6613 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0421 20:43:08.940984  6613 solver.cpp:228] Iteration 1300, loss = 0.346416
I0421 20:43:08.941165  6613 solver.cpp:244]     Train net output #0: loss = 0.346416 (* 1 = 0.346416 loss)
I0421 20:43:08.941174  6613 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0421 20:44:58.526654  6613 solver.cpp:228] Iteration 1400, loss = 0.26687
I0421 20:44:58.526795  6613 solver.cpp:244]     Train net output #0: loss = 0.26687 (* 1 = 0.26687 loss)
I0421 20:44:58.526803  6613 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0421 20:46:49.472160  6613 solver.cpp:228] Iteration 1500, loss = 0.236258
I0421 20:46:49.472322  6613 solver.cpp:244]     Train net output #0: loss = 0.236258 (* 1 = 0.236258 loss)
I0421 20:46:49.472331  6613 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0421 20:48:41.951474  6613 solver.cpp:228] Iteration 1600, loss = 0.630083
I0421 20:48:41.951642  6613 solver.cpp:244]     Train net output #0: loss = 0.630083 (* 1 = 0.630083 loss)
I0421 20:48:41.951650  6613 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0421 20:50:17.303555  6613 solver.cpp:228] Iteration 1700, loss = 0.460278
I0421 20:50:17.303685  6613 solver.cpp:244]     Train net output #0: loss = 0.460278 (* 1 = 0.460278 loss)
I0421 20:50:17.303694  6613 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0421 20:52:10.900988  6613 solver.cpp:228] Iteration 1800, loss = 0.374407
I0421 20:52:10.901149  6613 solver.cpp:244]     Train net output #0: loss = 0.374407 (* 1 = 0.374407 loss)
I0421 20:52:10.901155  6613 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0421 20:54:04.191321  6613 solver.cpp:228] Iteration 1900, loss = 0.447323
I0421 20:54:04.191810  6613 solver.cpp:244]     Train net output #0: loss = 0.447323 (* 1 = 0.447323 loss)
I0421 20:54:04.191819  6613 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0421 20:55:56.287596  6613 solver.cpp:337] Iteration 2000, Testing net (#0)
I0421 20:55:56.289474  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 20:55:56.289479  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 20:55:56.289482  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 20:55:56.289502  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 20:55:56.289510  6613 net.cpp:693] Ignoring source layer visualize
I0421 20:55:56.289511  6613 net.cpp:693] Ignoring source layer fake
I0421 20:59:17.267050  6613 solver.cpp:404]     Test net output #0: loss = 0.574069 (* 1 = 0.574069 loss)
I0421 20:59:17.892735  6613 solver.cpp:228] Iteration 2000, loss = 0.410665
I0421 20:59:17.892755  6613 solver.cpp:244]     Train net output #0: loss = 0.410665 (* 1 = 0.410665 loss)
I0421 20:59:17.892761  6613 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0421 21:00:53.326036  6613 solver.cpp:228] Iteration 2100, loss = 0.430264
I0421 21:00:53.327579  6613 solver.cpp:244]     Train net output #0: loss = 0.430264 (* 1 = 0.430264 loss)
I0421 21:00:53.327589  6613 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0421 21:02:46.133687  6613 solver.cpp:228] Iteration 2200, loss = 0.342303
I0421 21:02:46.133832  6613 solver.cpp:244]     Train net output #0: loss = 0.342303 (* 1 = 0.342303 loss)
I0421 21:02:46.133839  6613 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0421 21:04:39.080512  6613 solver.cpp:228] Iteration 2300, loss = 0.455197
I0421 21:04:39.080775  6613 solver.cpp:244]     Train net output #0: loss = 0.455197 (* 1 = 0.455197 loss)
I0421 21:04:39.080783  6613 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0421 21:06:30.129590  6613 solver.cpp:228] Iteration 2400, loss = 0.21991
I0421 21:06:30.137540  6613 solver.cpp:244]     Train net output #0: loss = 0.21991 (* 1 = 0.21991 loss)
I0421 21:06:30.137548  6613 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0421 21:08:06.574254  6613 solver.cpp:228] Iteration 2500, loss = 0.325763
I0421 21:08:06.574401  6613 solver.cpp:244]     Train net output #0: loss = 0.325763 (* 1 = 0.325763 loss)
I0421 21:08:06.574409  6613 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0421 21:09:55.616580  6613 solver.cpp:228] Iteration 2600, loss = 0.181303
I0421 21:09:55.616721  6613 solver.cpp:244]     Train net output #0: loss = 0.181303 (* 1 = 0.181303 loss)
I0421 21:09:55.616729  6613 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0421 21:11:30.784762  6613 solver.cpp:228] Iteration 2700, loss = 0.169533
I0421 21:11:30.784910  6613 solver.cpp:244]     Train net output #0: loss = 0.169533 (* 1 = 0.169533 loss)
I0421 21:11:30.784919  6613 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0421 21:13:20.455394  6613 solver.cpp:228] Iteration 2800, loss = 0.206399
I0421 21:13:20.455569  6613 solver.cpp:244]     Train net output #0: loss = 0.206399 (* 1 = 0.206399 loss)
I0421 21:13:20.455576  6613 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0421 21:15:12.233544  6613 solver.cpp:228] Iteration 2900, loss = 0.500926
I0421 21:15:12.233727  6613 solver.cpp:244]     Train net output #0: loss = 0.500926 (* 1 = 0.500926 loss)
I0421 21:15:12.233736  6613 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0421 21:17:04.365157  6613 solver.cpp:337] Iteration 3000, Testing net (#0)
I0421 21:17:04.365304  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 21:17:04.365310  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 21:17:04.365316  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 21:17:04.365339  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 21:17:04.365342  6613 net.cpp:693] Ignoring source layer visualize
I0421 21:17:04.365345  6613 net.cpp:693] Ignoring source layer fake
I0421 21:20:24.819200  6613 solver.cpp:404]     Test net output #0: loss = 0.393586 (* 1 = 0.393586 loss)
I0421 21:20:25.445205  6613 solver.cpp:228] Iteration 3000, loss = 0.354058
I0421 21:20:25.445224  6613 solver.cpp:244]     Train net output #0: loss = 0.354058 (* 1 = 0.354058 loss)
I0421 21:20:25.445245  6613 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0421 21:22:19.380405  6613 solver.cpp:228] Iteration 3100, loss = 0.292265
I0421 21:22:19.380553  6613 solver.cpp:244]     Train net output #0: loss = 0.292265 (* 1 = 0.292265 loss)
I0421 21:22:19.380559  6613 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0421 21:23:54.556007  6613 solver.cpp:228] Iteration 3200, loss = 0.323281
I0421 21:23:54.556138  6613 solver.cpp:244]     Train net output #0: loss = 0.323281 (* 1 = 0.323281 loss)
I0421 21:23:54.556145  6613 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0421 21:25:46.775228  6613 solver.cpp:228] Iteration 3300, loss = 0.322847
I0421 21:25:46.775372  6613 solver.cpp:244]     Train net output #0: loss = 0.322847 (* 1 = 0.322847 loss)
I0421 21:25:46.775380  6613 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0421 21:27:38.609570  6613 solver.cpp:228] Iteration 3400, loss = 0.222074
I0421 21:27:38.609690  6613 solver.cpp:244]     Train net output #0: loss = 0.222074 (* 1 = 0.222074 loss)
I0421 21:27:38.609696  6613 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0421 21:29:31.091845  6613 solver.cpp:228] Iteration 3500, loss = 0.234419
I0421 21:29:31.091986  6613 solver.cpp:244]     Train net output #0: loss = 0.234419 (* 1 = 0.234419 loss)
I0421 21:29:31.091994  6613 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0421 21:31:06.284116  6613 solver.cpp:228] Iteration 3600, loss = 0.198825
I0421 21:31:06.284267  6613 solver.cpp:244]     Train net output #0: loss = 0.198825 (* 1 = 0.198825 loss)
I0421 21:31:06.284274  6613 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0421 21:32:57.222355  6613 solver.cpp:228] Iteration 3700, loss = 0.192005
I0421 21:32:57.222491  6613 solver.cpp:244]     Train net output #0: loss = 0.192005 (* 1 = 0.192005 loss)
I0421 21:32:57.222497  6613 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0421 21:34:45.044186  6613 solver.cpp:228] Iteration 3800, loss = 0.20394
I0421 21:34:45.044324  6613 solver.cpp:244]     Train net output #0: loss = 0.20394 (* 1 = 0.20394 loss)
I0421 21:34:45.044332  6613 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0421 21:36:33.688141  6613 solver.cpp:228] Iteration 3900, loss = 0.16784
I0421 21:36:33.688283  6613 solver.cpp:244]     Train net output #0: loss = 0.16784 (* 1 = 0.16784 loss)
I0421 21:36:33.688292  6613 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0421 21:38:23.185515  6613 solver.cpp:337] Iteration 4000, Testing net (#0)
I0421 21:38:23.185662  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 21:38:23.185667  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 21:38:23.185672  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 21:38:23.185690  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 21:38:23.185693  6613 net.cpp:693] Ignoring source layer visualize
I0421 21:38:23.185695  6613 net.cpp:693] Ignoring source layer fake
I0421 21:41:43.587378  6613 solver.cpp:404]     Test net output #0: loss = 0.274527 (* 1 = 0.274527 loss)
I0421 21:41:44.209969  6613 solver.cpp:228] Iteration 4000, loss = 0.15777
I0421 21:41:44.210007  6613 solver.cpp:244]     Train net output #0: loss = 0.15777 (* 1 = 0.15777 loss)
I0421 21:41:44.210014  6613 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0421 21:43:36.876891  6613 solver.cpp:228] Iteration 4100, loss = 0.39466
I0421 21:43:36.877032  6613 solver.cpp:244]     Train net output #0: loss = 0.39466 (* 1 = 0.39466 loss)
I0421 21:43:36.877039  6613 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0421 21:45:12.083809  6613 solver.cpp:228] Iteration 4200, loss = 0.329708
I0421 21:45:12.083930  6613 solver.cpp:244]     Train net output #0: loss = 0.329708 (* 1 = 0.329708 loss)
I0421 21:45:12.083937  6613 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0421 21:47:04.215093  6613 solver.cpp:228] Iteration 4300, loss = 0.262599
I0421 21:47:04.215243  6613 solver.cpp:244]     Train net output #0: loss = 0.262599 (* 1 = 0.262599 loss)
I0421 21:47:04.215251  6613 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0421 21:48:43.491757  6613 solver.cpp:228] Iteration 4400, loss = 0.295197
I0421 21:48:43.491890  6613 solver.cpp:244]     Train net output #0: loss = 0.295197 (* 1 = 0.295197 loss)
I0421 21:48:43.491897  6613 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0421 21:50:21.646112  6613 solver.cpp:228] Iteration 4500, loss = 0.206135
I0421 21:50:21.646267  6613 solver.cpp:244]     Train net output #0: loss = 0.206135 (* 1 = 0.206135 loss)
I0421 21:50:21.646275  6613 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0421 21:51:57.035574  6613 solver.cpp:228] Iteration 4600, loss = 0.201431
I0421 21:51:57.035724  6613 solver.cpp:244]     Train net output #0: loss = 0.201431 (* 1 = 0.201431 loss)
I0421 21:51:57.035732  6613 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0421 21:53:34.224934  6613 solver.cpp:228] Iteration 4700, loss = 0.235391
I0421 21:53:34.225086  6613 solver.cpp:244]     Train net output #0: loss = 0.235391 (* 1 = 0.235391 loss)
I0421 21:53:34.225092  6613 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0421 21:55:12.060353  6613 solver.cpp:228] Iteration 4800, loss = 0.150501
I0421 21:55:12.060500  6613 solver.cpp:244]     Train net output #0: loss = 0.150501 (* 1 = 0.150501 loss)
I0421 21:55:12.060508  6613 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0421 21:56:49.483399  6613 solver.cpp:228] Iteration 4900, loss = 0.120706
I0421 21:56:49.483577  6613 solver.cpp:244]     Train net output #0: loss = 0.120706 (* 1 = 0.120706 loss)
I0421 21:56:49.483584  6613 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0421 21:58:25.217058  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_5000.caffemodel
I0421 21:58:37.334591  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_5000.solverstate
I0421 21:58:37.523252  6613 solver.cpp:337] Iteration 5000, Testing net (#0)
I0421 21:58:37.523296  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 21:58:37.523299  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 21:58:37.523303  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 21:58:37.523321  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 21:58:37.523324  6613 net.cpp:693] Ignoring source layer visualize
I0421 21:58:37.523326  6613 net.cpp:693] Ignoring source layer fake
I0421 22:01:57.947238  6613 solver.cpp:404]     Test net output #0: loss = 0.26771 (* 1 = 0.26771 loss)
I0421 22:01:58.572973  6613 solver.cpp:228] Iteration 5000, loss = 0.182882
I0421 22:01:58.572994  6613 solver.cpp:244]     Train net output #0: loss = 0.182882 (* 1 = 0.182882 loss)
I0421 22:01:58.573016  6613 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0421 22:03:37.110371  6613 solver.cpp:228] Iteration 5100, loss = 0.176668
I0421 22:03:37.111850  6613 solver.cpp:244]     Train net output #0: loss = 0.176668 (* 1 = 0.176668 loss)
I0421 22:03:37.111860  6613 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
I0421 22:05:12.488445  6613 solver.cpp:228] Iteration 5200, loss = 0.155775
I0421 22:05:12.488593  6613 solver.cpp:244]     Train net output #0: loss = 0.155775 (* 1 = 0.155775 loss)
I0421 22:05:12.488600  6613 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0421 22:06:49.578649  6613 solver.cpp:228] Iteration 5300, loss = 0.174579
I0421 22:06:49.579660  6613 solver.cpp:244]     Train net output #0: loss = 0.174579 (* 1 = 0.174579 loss)
I0421 22:06:49.579666  6613 sgd_solver.cpp:106] Iteration 5300, lr = 0.001
I0421 22:08:27.928210  6613 solver.cpp:228] Iteration 5400, loss = 0.361321
I0421 22:08:27.929343  6613 solver.cpp:244]     Train net output #0: loss = 0.361321 (* 1 = 0.361321 loss)
I0421 22:08:27.929352  6613 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0421 22:10:05.781257  6613 solver.cpp:228] Iteration 5500, loss = 0.24703
I0421 22:10:05.781406  6613 solver.cpp:244]     Train net output #0: loss = 0.24703 (* 1 = 0.24703 loss)
I0421 22:10:05.781415  6613 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
I0421 22:11:43.469188  6613 solver.cpp:228] Iteration 5600, loss = 0.218756
I0421 22:11:43.469332  6613 solver.cpp:244]     Train net output #0: loss = 0.218756 (* 1 = 0.218756 loss)
I0421 22:11:43.469341  6613 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0421 22:13:18.959771  6613 solver.cpp:228] Iteration 5700, loss = 0.263072
I0421 22:13:18.962045  6613 solver.cpp:244]     Train net output #0: loss = 0.263072 (* 1 = 0.263072 loss)
I0421 22:13:18.962054  6613 sgd_solver.cpp:106] Iteration 5700, lr = 0.001
I0421 22:14:56.997385  6613 solver.cpp:228] Iteration 5800, loss = 0.153636
I0421 22:14:56.997575  6613 solver.cpp:244]     Train net output #0: loss = 0.153636 (* 1 = 0.153636 loss)
I0421 22:14:56.997581  6613 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0421 22:16:34.595590  6613 solver.cpp:228] Iteration 5900, loss = 0.232394
I0421 22:16:34.595741  6613 solver.cpp:244]     Train net output #0: loss = 0.232394 (* 1 = 0.232394 loss)
I0421 22:16:34.595749  6613 sgd_solver.cpp:106] Iteration 5900, lr = 0.001
I0421 22:18:11.219887  6613 solver.cpp:337] Iteration 6000, Testing net (#0)
I0421 22:18:11.220036  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 22:18:11.220039  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 22:18:11.220044  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 22:18:11.220062  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 22:18:11.220067  6613 net.cpp:693] Ignoring source layer visualize
I0421 22:18:11.220068  6613 net.cpp:693] Ignoring source layer fake
I0421 22:21:31.703738  6613 solver.cpp:404]     Test net output #0: loss = 0.302306 (* 1 = 0.302306 loss)
I0421 22:21:32.333346  6613 solver.cpp:228] Iteration 6000, loss = 0.185423
I0421 22:21:32.333385  6613 solver.cpp:244]     Train net output #0: loss = 0.185423 (* 1 = 0.185423 loss)
I0421 22:21:32.333391  6613 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0421 22:23:07.754168  6613 solver.cpp:228] Iteration 6100, loss = 0.209421
I0421 22:23:07.754323  6613 solver.cpp:244]     Train net output #0: loss = 0.209421 (* 1 = 0.209421 loss)
I0421 22:23:07.754330  6613 sgd_solver.cpp:106] Iteration 6100, lr = 0.001
I0421 22:24:45.365047  6613 solver.cpp:228] Iteration 6200, loss = 0.129353
I0421 22:24:45.365213  6613 solver.cpp:244]     Train net output #0: loss = 0.129353 (* 1 = 0.129353 loss)
I0421 22:24:45.365221  6613 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I0421 22:26:22.416551  6613 solver.cpp:228] Iteration 6300, loss = 0.188599
I0421 22:26:22.416707  6613 solver.cpp:244]     Train net output #0: loss = 0.188599 (* 1 = 0.188599 loss)
I0421 22:26:22.416714  6613 sgd_solver.cpp:106] Iteration 6300, lr = 0.001
I0421 22:27:59.445175  6613 solver.cpp:228] Iteration 6400, loss = 0.221546
I0421 22:27:59.446514  6613 solver.cpp:244]     Train net output #0: loss = 0.221546 (* 1 = 0.221546 loss)
I0421 22:27:59.446521  6613 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I0421 22:29:36.763689  6613 solver.cpp:228] Iteration 6500, loss = 0.132287
I0421 22:29:36.763855  6613 solver.cpp:244]     Train net output #0: loss = 0.132287 (* 1 = 0.132287 loss)
I0421 22:29:36.763862  6613 sgd_solver.cpp:106] Iteration 6500, lr = 0.001
I0421 22:31:14.072398  6613 solver.cpp:228] Iteration 6600, loss = 0.337853
I0421 22:31:14.072573  6613 solver.cpp:244]     Train net output #0: loss = 0.337853 (* 1 = 0.337853 loss)
I0421 22:31:14.072580  6613 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0421 22:32:49.431542  6613 solver.cpp:228] Iteration 6700, loss = 0.297669
I0421 22:32:49.432071  6613 solver.cpp:244]     Train net output #0: loss = 0.297669 (* 1 = 0.297669 loss)
I0421 22:32:49.432080  6613 sgd_solver.cpp:106] Iteration 6700, lr = 0.001
I0421 22:34:26.712312  6613 solver.cpp:228] Iteration 6800, loss = 0.171277
I0421 22:34:26.712442  6613 solver.cpp:244]     Train net output #0: loss = 0.171277 (* 1 = 0.171277 loss)
I0421 22:34:26.712450  6613 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I0421 22:36:04.138695  6613 solver.cpp:228] Iteration 6900, loss = 0.181613
I0421 22:36:04.139801  6613 solver.cpp:244]     Train net output #0: loss = 0.181613 (* 1 = 0.181613 loss)
I0421 22:36:04.139809  6613 sgd_solver.cpp:106] Iteration 6900, lr = 0.001
I0421 22:37:40.566503  6613 solver.cpp:337] Iteration 7000, Testing net (#0)
I0421 22:37:40.566639  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 22:37:40.566644  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 22:37:40.566648  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 22:37:40.566665  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 22:37:40.566668  6613 net.cpp:693] Ignoring source layer visualize
I0421 22:37:40.566670  6613 net.cpp:693] Ignoring source layer fake
I0421 22:41:01.408536  6613 solver.cpp:404]     Test net output #0: loss = 0.257307 (* 1 = 0.257307 loss)
I0421 22:41:02.038347  6613 solver.cpp:228] Iteration 7000, loss = 0.184068
I0421 22:41:02.038367  6613 solver.cpp:244]     Train net output #0: loss = 0.184068 (* 1 = 0.184068 loss)
I0421 22:41:02.038388  6613 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0421 22:42:37.474459  6613 solver.cpp:228] Iteration 7100, loss = 0.152919
I0421 22:42:37.474601  6613 solver.cpp:244]     Train net output #0: loss = 0.152919 (* 1 = 0.152919 loss)
I0421 22:42:37.474609  6613 sgd_solver.cpp:106] Iteration 7100, lr = 0.001
I0421 22:44:15.031930  6613 solver.cpp:228] Iteration 7200, loss = 0.14016
I0421 22:44:15.032086  6613 solver.cpp:244]     Train net output #0: loss = 0.14016 (* 1 = 0.14016 loss)
I0421 22:44:15.032094  6613 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0421 22:45:52.293845  6613 solver.cpp:228] Iteration 7300, loss = 0.101503
I0421 22:45:52.293987  6613 solver.cpp:244]     Train net output #0: loss = 0.101503 (* 1 = 0.101503 loss)
I0421 22:45:52.293994  6613 sgd_solver.cpp:106] Iteration 7300, lr = 0.001
I0421 22:47:29.353003  6613 solver.cpp:228] Iteration 7400, loss = 0.148783
I0421 22:47:29.353147  6613 solver.cpp:244]     Train net output #0: loss = 0.148783 (* 1 = 0.148783 loss)
I0421 22:47:29.353153  6613 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I0421 22:49:06.366991  6613 solver.cpp:228] Iteration 7500, loss = 0.176838
I0421 22:49:06.367128  6613 solver.cpp:244]     Train net output #0: loss = 0.176838 (* 1 = 0.176838 loss)
I0421 22:49:06.367136  6613 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I0421 22:50:43.394073  6613 solver.cpp:228] Iteration 7600, loss = 0.160909
I0421 22:50:43.394204  6613 solver.cpp:244]     Train net output #0: loss = 0.160909 (* 1 = 0.160909 loss)
I0421 22:50:43.394212  6613 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0421 22:52:18.747757  6613 solver.cpp:228] Iteration 7700, loss = 0.165761
I0421 22:52:18.747906  6613 solver.cpp:244]     Train net output #0: loss = 0.165761 (* 1 = 0.165761 loss)
I0421 22:52:18.747912  6613 sgd_solver.cpp:106] Iteration 7700, lr = 0.001
I0421 22:53:56.296787  6613 solver.cpp:228] Iteration 7800, loss = 0.154041
I0421 22:53:56.297505  6613 solver.cpp:244]     Train net output #0: loss = 0.154041 (* 1 = 0.154041 loss)
I0421 22:53:56.297514  6613 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0421 22:55:34.193598  6613 solver.cpp:228] Iteration 7900, loss = 0.227845
I0421 22:55:34.193748  6613 solver.cpp:244]     Train net output #0: loss = 0.227845 (* 1 = 0.227845 loss)
I0421 22:55:34.193756  6613 sgd_solver.cpp:106] Iteration 7900, lr = 0.001
I0421 22:57:10.973654  6613 solver.cpp:337] Iteration 8000, Testing net (#0)
I0421 22:57:10.973795  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 22:57:10.973799  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 22:57:10.973804  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 22:57:10.973821  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 22:57:10.973824  6613 net.cpp:693] Ignoring source layer visualize
I0421 22:57:10.973825  6613 net.cpp:693] Ignoring source layer fake
I0421 23:00:31.913400  6613 solver.cpp:404]     Test net output #0: loss = 0.243504 (* 1 = 0.243504 loss)
I0421 23:00:32.544296  6613 solver.cpp:228] Iteration 8000, loss = 0.204758
I0421 23:00:32.544317  6613 solver.cpp:244]     Train net output #0: loss = 0.204758 (* 1 = 0.204758 loss)
I0421 23:00:32.544338  6613 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0421 23:02:10.681839  6613 solver.cpp:228] Iteration 8100, loss = 0.162808
I0421 23:02:10.682026  6613 solver.cpp:244]     Train net output #0: loss = 0.162808 (* 1 = 0.162808 loss)
I0421 23:02:10.682035  6613 sgd_solver.cpp:106] Iteration 8100, lr = 0.001
I0421 23:03:46.110550  6613 solver.cpp:228] Iteration 8200, loss = 0.179058
I0421 23:03:46.110690  6613 solver.cpp:244]     Train net output #0: loss = 0.179058 (* 1 = 0.179058 loss)
I0421 23:03:46.110698  6613 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0421 23:05:23.937567  6613 solver.cpp:228] Iteration 8300, loss = 0.147332
I0421 23:05:23.937714  6613 solver.cpp:244]     Train net output #0: loss = 0.147332 (* 1 = 0.147332 loss)
I0421 23:05:23.937722  6613 sgd_solver.cpp:106] Iteration 8300, lr = 0.001
I0421 23:07:01.610255  6613 solver.cpp:228] Iteration 8400, loss = 0.180638
I0421 23:07:01.610395  6613 solver.cpp:244]     Train net output #0: loss = 0.180638 (* 1 = 0.180638 loss)
I0421 23:07:01.610402  6613 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0421 23:08:39.621322  6613 solver.cpp:228] Iteration 8500, loss = 0.116571
I0421 23:08:39.621486  6613 solver.cpp:244]     Train net output #0: loss = 0.116571 (* 1 = 0.116571 loss)
I0421 23:08:39.621493  6613 sgd_solver.cpp:106] Iteration 8500, lr = 0.001
I0421 23:10:14.967001  6613 solver.cpp:228] Iteration 8600, loss = 0.14837
I0421 23:10:14.967151  6613 solver.cpp:244]     Train net output #0: loss = 0.14837 (* 1 = 0.14837 loss)
I0421 23:10:14.967157  6613 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0421 23:11:52.095788  6613 solver.cpp:228] Iteration 8700, loss = 0.174625
I0421 23:11:52.097443  6613 solver.cpp:244]     Train net output #0: loss = 0.174625 (* 1 = 0.174625 loss)
I0421 23:11:52.097452  6613 sgd_solver.cpp:106] Iteration 8700, lr = 0.001
I0421 23:13:28.912156  6613 solver.cpp:228] Iteration 8800, loss = 0.216619
I0421 23:13:28.912307  6613 solver.cpp:244]     Train net output #0: loss = 0.216619 (* 1 = 0.216619 loss)
I0421 23:13:28.912313  6613 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0421 23:15:05.576302  6613 solver.cpp:228] Iteration 8900, loss = 0.183631
I0421 23:15:05.576434  6613 solver.cpp:244]     Train net output #0: loss = 0.183631 (* 1 = 0.183631 loss)
I0421 23:15:05.576442  6613 sgd_solver.cpp:106] Iteration 8900, lr = 0.001
I0421 23:16:41.493396  6613 solver.cpp:337] Iteration 9000, Testing net (#0)
I0421 23:16:41.493546  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 23:16:41.493551  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 23:16:41.493554  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 23:16:41.493571  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 23:16:41.493576  6613 net.cpp:693] Ignoring source layer visualize
I0421 23:16:41.493577  6613 net.cpp:693] Ignoring source layer fake
I0421 23:20:01.660359  6613 solver.cpp:404]     Test net output #0: loss = 0.211586 (* 1 = 0.211586 loss)
I0421 23:20:02.288724  6613 solver.cpp:228] Iteration 9000, loss = 0.122725
I0421 23:20:02.288745  6613 solver.cpp:244]     Train net output #0: loss = 0.122725 (* 1 = 0.122725 loss)
I0421 23:20:02.288751  6613 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0421 23:21:39.755698  6613 solver.cpp:228] Iteration 9100, loss = 0.270125
I0421 23:21:39.757277  6613 solver.cpp:244]     Train net output #0: loss = 0.270125 (* 1 = 0.270125 loss)
I0421 23:21:39.757284  6613 sgd_solver.cpp:106] Iteration 9100, lr = 0.001
I0421 23:23:17.004099  6613 solver.cpp:228] Iteration 9200, loss = 0.225339
I0421 23:23:17.004256  6613 solver.cpp:244]     Train net output #0: loss = 0.225339 (* 1 = 0.225339 loss)
I0421 23:23:17.004267  6613 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0421 23:24:52.390254  6613 solver.cpp:228] Iteration 9300, loss = 0.162244
I0421 23:24:52.390385  6613 solver.cpp:244]     Train net output #0: loss = 0.162244 (* 1 = 0.162244 loss)
I0421 23:24:52.390393  6613 sgd_solver.cpp:106] Iteration 9300, lr = 0.001
I0421 23:26:29.900266  6613 solver.cpp:228] Iteration 9400, loss = 0.199188
I0421 23:26:29.900400  6613 solver.cpp:244]     Train net output #0: loss = 0.199188 (* 1 = 0.199188 loss)
I0421 23:26:29.900408  6613 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0421 23:28:07.136289  6613 solver.cpp:228] Iteration 9500, loss = 0.152028
I0421 23:28:07.136430  6613 solver.cpp:244]     Train net output #0: loss = 0.152028 (* 1 = 0.152028 loss)
I0421 23:28:07.136436  6613 sgd_solver.cpp:106] Iteration 9500, lr = 0.001
I0421 23:29:42.518982  6613 solver.cpp:228] Iteration 9600, loss = 0.139085
I0421 23:29:42.519132  6613 solver.cpp:244]     Train net output #0: loss = 0.139085 (* 1 = 0.139085 loss)
I0421 23:29:42.519140  6613 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0421 23:31:19.638672  6613 solver.cpp:228] Iteration 9700, loss = 0.17298
I0421 23:31:19.638809  6613 solver.cpp:244]     Train net output #0: loss = 0.17298 (* 1 = 0.17298 loss)
I0421 23:31:19.638816  6613 sgd_solver.cpp:106] Iteration 9700, lr = 0.001
I0421 23:32:57.084820  6613 solver.cpp:228] Iteration 9800, loss = 0.106938
I0421 23:32:57.084961  6613 solver.cpp:244]     Train net output #0: loss = 0.106938 (* 1 = 0.106938 loss)
I0421 23:32:57.084967  6613 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0421 23:34:34.045359  6613 solver.cpp:228] Iteration 9900, loss = 0.11932
I0421 23:34:34.045502  6613 solver.cpp:244]     Train net output #0: loss = 0.11932 (* 1 = 0.11932 loss)
I0421 23:34:34.045509  6613 sgd_solver.cpp:106] Iteration 9900, lr = 0.001
I0421 23:36:09.688771  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_10000.caffemodel
I0421 23:36:20.433084  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_10000.solverstate
I0421 23:36:20.636622  6613 solver.cpp:337] Iteration 10000, Testing net (#0)
I0421 23:36:20.636664  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 23:36:20.636667  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 23:36:20.636672  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 23:36:20.636688  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 23:36:20.636692  6613 net.cpp:693] Ignoring source layer visualize
I0421 23:36:20.636693  6613 net.cpp:693] Ignoring source layer fake
I0421 23:39:41.328006  6613 solver.cpp:404]     Test net output #0: loss = 0.203209 (* 1 = 0.203209 loss)
I0421 23:39:41.960378  6613 solver.cpp:228] Iteration 10000, loss = 0.255411
I0421 23:39:41.960422  6613 solver.cpp:244]     Train net output #0: loss = 0.255411 (* 1 = 0.255411 loss)
I0421 23:39:41.960428  6613 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0421 23:41:18.706790  6613 solver.cpp:228] Iteration 10100, loss = 0.231211
I0421 23:41:18.706969  6613 solver.cpp:244]     Train net output #0: loss = 0.231211 (* 1 = 0.231211 loss)
I0421 23:41:18.706976  6613 sgd_solver.cpp:106] Iteration 10100, lr = 0.001
I0421 23:42:54.029567  6613 solver.cpp:228] Iteration 10200, loss = 0.0913415
I0421 23:42:54.029706  6613 solver.cpp:244]     Train net output #0: loss = 0.0913415 (* 1 = 0.0913415 loss)
I0421 23:42:54.029712  6613 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0421 23:44:30.893016  6613 solver.cpp:228] Iteration 10300, loss = 0.129197
I0421 23:44:30.893172  6613 solver.cpp:244]     Train net output #0: loss = 0.129197 (* 1 = 0.129197 loss)
I0421 23:44:30.893178  6613 sgd_solver.cpp:106] Iteration 10300, lr = 0.001
I0421 23:46:08.011696  6613 solver.cpp:228] Iteration 10400, loss = 0.219996
I0421 23:46:08.011839  6613 solver.cpp:244]     Train net output #0: loss = 0.219996 (* 1 = 0.219996 loss)
I0421 23:46:08.011847  6613 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I0421 23:47:45.258849  6613 solver.cpp:228] Iteration 10500, loss = 0.133589
I0421 23:47:45.258987  6613 solver.cpp:244]     Train net output #0: loss = 0.133589 (* 1 = 0.133589 loss)
I0421 23:47:45.258996  6613 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I0421 23:49:22.545120  6613 solver.cpp:228] Iteration 10600, loss = 0.126742
I0421 23:49:22.545265  6613 solver.cpp:244]     Train net output #0: loss = 0.126742 (* 1 = 0.126742 loss)
I0421 23:49:22.545272  6613 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I0421 23:50:57.898125  6613 solver.cpp:228] Iteration 10700, loss = 0.15145
I0421 23:50:57.899564  6613 solver.cpp:244]     Train net output #0: loss = 0.15145 (* 1 = 0.15145 loss)
I0421 23:50:57.899586  6613 sgd_solver.cpp:106] Iteration 10700, lr = 0.001
I0421 23:52:38.320806  6613 solver.cpp:228] Iteration 10800, loss = 0.166044
I0421 23:52:38.320936  6613 solver.cpp:244]     Train net output #0: loss = 0.166044 (* 1 = 0.166044 loss)
I0421 23:52:38.320943  6613 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0421 23:54:15.552033  6613 solver.cpp:228] Iteration 10900, loss = 0.151444
I0421 23:54:15.552181  6613 solver.cpp:244]     Train net output #0: loss = 0.151444 (* 1 = 0.151444 loss)
I0421 23:54:15.552189  6613 sgd_solver.cpp:106] Iteration 10900, lr = 0.001
I0421 23:55:51.840872  6613 solver.cpp:337] Iteration 11000, Testing net (#0)
I0421 23:55:51.841001  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0421 23:55:51.841006  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0421 23:55:51.841011  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0421 23:55:51.841027  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0421 23:55:51.841029  6613 net.cpp:693] Ignoring source layer visualize
I0421 23:55:51.841032  6613 net.cpp:693] Ignoring source layer fake
I0421 23:59:12.685307  6613 solver.cpp:404]     Test net output #0: loss = 0.30729 (* 1 = 0.30729 loss)
I0421 23:59:13.311174  6613 solver.cpp:228] Iteration 11000, loss = 0.103877
I0421 23:59:13.311213  6613 solver.cpp:244]     Train net output #0: loss = 0.103877 (* 1 = 0.103877 loss)
I0421 23:59:13.311219  6613 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0422 00:00:48.690588  6613 solver.cpp:228] Iteration 11100, loss = 0.104226
I0422 00:00:48.690726  6613 solver.cpp:244]     Train net output #0: loss = 0.104226 (* 1 = 0.104226 loss)
I0422 00:00:48.690732  6613 sgd_solver.cpp:106] Iteration 11100, lr = 0.001
I0422 00:02:25.739337  6613 solver.cpp:228] Iteration 11200, loss = 0.301577
I0422 00:02:25.739701  6613 solver.cpp:244]     Train net output #0: loss = 0.301577 (* 1 = 0.301577 loss)
I0422 00:02:25.739708  6613 sgd_solver.cpp:106] Iteration 11200, lr = 0.001
I0422 00:04:02.403066  6613 solver.cpp:228] Iteration 11300, loss = 0.130308
I0422 00:04:02.403213  6613 solver.cpp:244]     Train net output #0: loss = 0.130308 (* 1 = 0.130308 loss)
I0422 00:04:02.403220  6613 sgd_solver.cpp:106] Iteration 11300, lr = 0.001
I0422 00:05:39.105551  6613 solver.cpp:228] Iteration 11400, loss = 0.140958
I0422 00:05:39.105722  6613 solver.cpp:244]     Train net output #0: loss = 0.140958 (* 1 = 0.140958 loss)
I0422 00:05:39.105731  6613 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I0422 00:07:16.187484  6613 solver.cpp:228] Iteration 11500, loss = 0.122671
I0422 00:07:16.187630  6613 solver.cpp:244]     Train net output #0: loss = 0.122671 (* 1 = 0.122671 loss)
I0422 00:07:16.187638  6613 sgd_solver.cpp:106] Iteration 11500, lr = 0.001
I0422 00:08:54.743480  6613 solver.cpp:228] Iteration 11600, loss = 0.277798
I0422 00:08:54.743623  6613 solver.cpp:244]     Train net output #0: loss = 0.277798 (* 1 = 0.277798 loss)
I0422 00:08:54.743630  6613 sgd_solver.cpp:106] Iteration 11600, lr = 0.001
I0422 00:10:32.702237  6613 solver.cpp:228] Iteration 11700, loss = 0.218502
I0422 00:10:32.702404  6613 solver.cpp:244]     Train net output #0: loss = 0.218502 (* 1 = 0.218502 loss)
I0422 00:10:32.702414  6613 sgd_solver.cpp:106] Iteration 11700, lr = 0.001
I0422 00:12:08.093951  6613 solver.cpp:228] Iteration 11800, loss = 0.194714
I0422 00:12:08.094101  6613 solver.cpp:244]     Train net output #0: loss = 0.194714 (* 1 = 0.194714 loss)
I0422 00:12:08.094108  6613 sgd_solver.cpp:106] Iteration 11800, lr = 0.001
I0422 00:13:45.467767  6613 solver.cpp:228] Iteration 11900, loss = 0.205036
I0422 00:13:45.467912  6613 solver.cpp:244]     Train net output #0: loss = 0.205036 (* 1 = 0.205036 loss)
I0422 00:13:45.467919  6613 sgd_solver.cpp:106] Iteration 11900, lr = 0.001
I0422 00:15:21.820979  6613 solver.cpp:337] Iteration 12000, Testing net (#0)
I0422 00:15:21.821116  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 00:15:21.821120  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 00:15:21.821125  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 00:15:21.821143  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 00:15:21.821146  6613 net.cpp:693] Ignoring source layer visualize
I0422 00:15:21.821148  6613 net.cpp:693] Ignoring source layer fake
I0422 00:18:42.457123  6613 solver.cpp:404]     Test net output #0: loss = 0.252913 (* 1 = 0.252913 loss)
I0422 00:18:43.089243  6613 solver.cpp:228] Iteration 12000, loss = 0.209004
I0422 00:18:43.089284  6613 solver.cpp:244]     Train net output #0: loss = 0.209004 (* 1 = 0.209004 loss)
I0422 00:18:43.089290  6613 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0422 00:20:18.483474  6613 solver.cpp:228] Iteration 12100, loss = 0.107212
I0422 00:20:18.483623  6613 solver.cpp:244]     Train net output #0: loss = 0.107212 (* 1 = 0.107212 loss)
I0422 00:20:18.483630  6613 sgd_solver.cpp:106] Iteration 12100, lr = 0.001
I0422 00:21:55.674026  6613 solver.cpp:228] Iteration 12200, loss = 0.173546
I0422 00:21:55.674885  6613 solver.cpp:244]     Train net output #0: loss = 0.173546 (* 1 = 0.173546 loss)
I0422 00:21:55.674890  6613 sgd_solver.cpp:106] Iteration 12200, lr = 0.001
I0422 00:23:32.891496  6613 solver.cpp:228] Iteration 12300, loss = 0.167619
I0422 00:23:32.891649  6613 solver.cpp:244]     Train net output #0: loss = 0.167619 (* 1 = 0.167619 loss)
I0422 00:23:32.891655  6613 sgd_solver.cpp:106] Iteration 12300, lr = 0.001
I0422 00:25:09.919466  6613 solver.cpp:228] Iteration 12400, loss = 0.128794
I0422 00:25:09.919621  6613 solver.cpp:244]     Train net output #0: loss = 0.128794 (* 1 = 0.128794 loss)
I0422 00:25:09.919630  6613 sgd_solver.cpp:106] Iteration 12400, lr = 0.001
I0422 00:26:46.609746  6613 solver.cpp:228] Iteration 12500, loss = 0.144978
I0422 00:26:46.609910  6613 solver.cpp:244]     Train net output #0: loss = 0.144978 (* 1 = 0.144978 loss)
I0422 00:26:46.609917  6613 sgd_solver.cpp:106] Iteration 12500, lr = 0.001
I0422 00:28:23.343854  6613 solver.cpp:228] Iteration 12600, loss = 0.251631
I0422 00:28:23.344007  6613 solver.cpp:244]     Train net output #0: loss = 0.251631 (* 1 = 0.251631 loss)
I0422 00:28:23.344013  6613 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I0422 00:29:58.739478  6613 solver.cpp:228] Iteration 12700, loss = 0.16162
I0422 00:29:58.739636  6613 solver.cpp:244]     Train net output #0: loss = 0.16162 (* 1 = 0.16162 loss)
I0422 00:29:58.739644  6613 sgd_solver.cpp:106] Iteration 12700, lr = 0.001
I0422 00:31:35.716573  6613 solver.cpp:228] Iteration 12800, loss = 0.129343
I0422 00:31:35.716718  6613 solver.cpp:244]     Train net output #0: loss = 0.129343 (* 1 = 0.129343 loss)
I0422 00:31:35.716727  6613 sgd_solver.cpp:106] Iteration 12800, lr = 0.001
I0422 00:33:12.880924  6613 solver.cpp:228] Iteration 12900, loss = 0.433009
I0422 00:33:12.881068  6613 solver.cpp:244]     Train net output #0: loss = 0.433009 (* 1 = 0.433009 loss)
I0422 00:33:12.881077  6613 sgd_solver.cpp:106] Iteration 12900, lr = 0.001
I0422 00:34:49.254631  6613 solver.cpp:337] Iteration 13000, Testing net (#0)
I0422 00:34:49.254763  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 00:34:49.254767  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 00:34:49.254773  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 00:34:49.254789  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 00:34:49.254792  6613 net.cpp:693] Ignoring source layer visualize
I0422 00:34:49.254794  6613 net.cpp:693] Ignoring source layer fake
I0422 00:38:10.046584  6613 solver.cpp:404]     Test net output #0: loss = 0.207862 (* 1 = 0.207862 loss)
I0422 00:38:10.673171  6613 solver.cpp:228] Iteration 13000, loss = 0.18209
I0422 00:38:10.673190  6613 solver.cpp:244]     Train net output #0: loss = 0.18209 (* 1 = 0.18209 loss)
I0422 00:38:10.673212  6613 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0422 00:39:48.070492  6613 solver.cpp:228] Iteration 13100, loss = 0.140544
I0422 00:39:48.070647  6613 solver.cpp:244]     Train net output #0: loss = 0.140544 (* 1 = 0.140544 loss)
I0422 00:39:48.070653  6613 sgd_solver.cpp:106] Iteration 13100, lr = 0.001
I0422 00:41:23.424573  6613 solver.cpp:228] Iteration 13200, loss = 0.182403
I0422 00:41:23.424765  6613 solver.cpp:244]     Train net output #0: loss = 0.182403 (* 1 = 0.182403 loss)
I0422 00:41:23.424773  6613 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I0422 00:43:00.645865  6613 solver.cpp:228] Iteration 13300, loss = 0.109955
I0422 00:43:00.646342  6613 solver.cpp:244]     Train net output #0: loss = 0.109955 (* 1 = 0.109955 loss)
I0422 00:43:00.646351  6613 sgd_solver.cpp:106] Iteration 13300, lr = 0.001
I0422 00:44:37.856545  6613 solver.cpp:228] Iteration 13400, loss = 0.151845
I0422 00:44:37.856680  6613 solver.cpp:244]     Train net output #0: loss = 0.151845 (* 1 = 0.151845 loss)
I0422 00:44:37.856688  6613 sgd_solver.cpp:106] Iteration 13400, lr = 0.001
I0422 00:46:15.020359  6613 solver.cpp:228] Iteration 13500, loss = 0.150402
I0422 00:46:15.020506  6613 solver.cpp:244]     Train net output #0: loss = 0.150402 (* 1 = 0.150402 loss)
I0422 00:46:15.020514  6613 sgd_solver.cpp:106] Iteration 13500, lr = 0.001
I0422 00:47:50.317889  6613 solver.cpp:228] Iteration 13600, loss = 0.155256
I0422 00:47:50.318037  6613 solver.cpp:244]     Train net output #0: loss = 0.155256 (* 1 = 0.155256 loss)
I0422 00:47:50.318044  6613 sgd_solver.cpp:106] Iteration 13600, lr = 0.001
I0422 00:49:27.334082  6613 solver.cpp:228] Iteration 13700, loss = 0.349248
I0422 00:49:27.334210  6613 solver.cpp:244]     Train net output #0: loss = 0.349248 (* 1 = 0.349248 loss)
I0422 00:49:27.334218  6613 sgd_solver.cpp:106] Iteration 13700, lr = 0.001
I0422 00:51:04.030434  6613 solver.cpp:228] Iteration 13800, loss = 0.29067
I0422 00:51:04.030572  6613 solver.cpp:244]     Train net output #0: loss = 0.29067 (* 1 = 0.29067 loss)
I0422 00:51:04.030580  6613 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I0422 00:52:40.768267  6613 solver.cpp:228] Iteration 13900, loss = 0.222263
I0422 00:52:40.768422  6613 solver.cpp:244]     Train net output #0: loss = 0.222263 (* 1 = 0.222263 loss)
I0422 00:52:40.768429  6613 sgd_solver.cpp:106] Iteration 13900, lr = 0.001
I0422 00:54:16.774081  6613 solver.cpp:337] Iteration 14000, Testing net (#0)
I0422 00:54:16.774215  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 00:54:16.774219  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 00:54:16.774224  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 00:54:16.774242  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 00:54:16.774245  6613 net.cpp:693] Ignoring source layer visualize
I0422 00:54:16.774247  6613 net.cpp:693] Ignoring source layer fake
I0422 00:57:37.204988  6613 solver.cpp:404]     Test net output #0: loss = 0.203077 (* 1 = 0.203077 loss)
I0422 00:57:37.833369  6613 solver.cpp:228] Iteration 14000, loss = 0.120392
I0422 00:57:37.833408  6613 solver.cpp:244]     Train net output #0: loss = 0.120392 (* 1 = 0.120392 loss)
I0422 00:57:37.833415  6613 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0422 00:59:15.041525  6613 solver.cpp:228] Iteration 14100, loss = 0.323775
I0422 00:59:15.042295  6613 solver.cpp:244]     Train net output #0: loss = 0.323775 (* 1 = 0.323775 loss)
I0422 00:59:15.042304  6613 sgd_solver.cpp:106] Iteration 14100, lr = 0.001
I0422 01:00:52.352053  6613 solver.cpp:228] Iteration 14200, loss = 0.193955
I0422 01:00:52.352205  6613 solver.cpp:244]     Train net output #0: loss = 0.193955 (* 1 = 0.193955 loss)
I0422 01:00:52.352213  6613 sgd_solver.cpp:106] Iteration 14200, lr = 0.001
I0422 01:02:27.717952  6613 solver.cpp:228] Iteration 14300, loss = 0.197057
I0422 01:02:27.718107  6613 solver.cpp:244]     Train net output #0: loss = 0.197057 (* 1 = 0.197057 loss)
I0422 01:02:27.718114  6613 sgd_solver.cpp:106] Iteration 14300, lr = 0.001
I0422 01:04:05.034617  6613 solver.cpp:228] Iteration 14400, loss = 0.144398
I0422 01:04:05.034768  6613 solver.cpp:244]     Train net output #0: loss = 0.144398 (* 1 = 0.144398 loss)
I0422 01:04:05.034775  6613 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I0422 01:05:42.338995  6613 solver.cpp:228] Iteration 14500, loss = 0.104508
I0422 01:05:42.339161  6613 solver.cpp:244]     Train net output #0: loss = 0.104508 (* 1 = 0.104508 loss)
I0422 01:05:42.339169  6613 sgd_solver.cpp:106] Iteration 14500, lr = 0.001
I0422 01:07:17.702826  6613 solver.cpp:228] Iteration 14600, loss = 0.124404
I0422 01:07:17.702982  6613 solver.cpp:244]     Train net output #0: loss = 0.124404 (* 1 = 0.124404 loss)
I0422 01:07:17.702989  6613 sgd_solver.cpp:106] Iteration 14600, lr = 0.001
I0422 01:08:54.923614  6613 solver.cpp:228] Iteration 14700, loss = 0.109202
I0422 01:08:54.923760  6613 solver.cpp:244]     Train net output #0: loss = 0.109202 (* 1 = 0.109202 loss)
I0422 01:08:54.923768  6613 sgd_solver.cpp:106] Iteration 14700, lr = 0.001
I0422 01:10:32.143671  6613 solver.cpp:228] Iteration 14800, loss = 0.124552
I0422 01:10:32.143823  6613 solver.cpp:244]     Train net output #0: loss = 0.124552 (* 1 = 0.124552 loss)
I0422 01:10:32.143831  6613 sgd_solver.cpp:106] Iteration 14800, lr = 0.001
I0422 01:12:09.157042  6613 solver.cpp:228] Iteration 14900, loss = 0.106409
I0422 01:12:09.157213  6613 solver.cpp:244]     Train net output #0: loss = 0.106409 (* 1 = 0.106409 loss)
I0422 01:12:09.157220  6613 sgd_solver.cpp:106] Iteration 14900, lr = 0.001
I0422 01:13:44.837987  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_15000.caffemodel
I0422 01:13:53.514488  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_15000.solverstate
I0422 01:13:53.717821  6613 solver.cpp:337] Iteration 15000, Testing net (#0)
I0422 01:13:53.717864  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 01:13:53.717866  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 01:13:53.717870  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 01:13:53.717886  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 01:13:53.717890  6613 net.cpp:693] Ignoring source layer visualize
I0422 01:13:53.717891  6613 net.cpp:693] Ignoring source layer fake
I0422 01:17:13.961983  6613 solver.cpp:404]     Test net output #0: loss = 0.176637 (* 1 = 0.176637 loss)
I0422 01:17:14.589699  6613 solver.cpp:228] Iteration 15000, loss = 0.144018
I0422 01:17:14.589736  6613 solver.cpp:244]     Train net output #0: loss = 0.144018 (* 1 = 0.144018 loss)
I0422 01:17:14.589743  6613 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0422 01:18:51.315294  6613 solver.cpp:228] Iteration 15100, loss = 0.162753
I0422 01:18:51.315464  6613 solver.cpp:244]     Train net output #0: loss = 0.162753 (* 1 = 0.162753 loss)
I0422 01:18:51.315472  6613 sgd_solver.cpp:106] Iteration 15100, lr = 0.001
I0422 01:20:26.671121  6613 solver.cpp:228] Iteration 15200, loss = 0.136513
I0422 01:20:26.672817  6613 solver.cpp:244]     Train net output #0: loss = 0.136513 (* 1 = 0.136513 loss)
I0422 01:20:26.672827  6613 sgd_solver.cpp:106] Iteration 15200, lr = 0.001
I0422 01:22:03.585149  6613 solver.cpp:228] Iteration 15300, loss = 0.136814
I0422 01:22:03.585275  6613 solver.cpp:244]     Train net output #0: loss = 0.136814 (* 1 = 0.136814 loss)
I0422 01:22:03.585283  6613 sgd_solver.cpp:106] Iteration 15300, lr = 0.001
I0422 01:23:40.692934  6613 solver.cpp:228] Iteration 15400, loss = 0.190846
I0422 01:23:40.693078  6613 solver.cpp:244]     Train net output #0: loss = 0.190846 (* 1 = 0.190846 loss)
I0422 01:23:40.693086  6613 sgd_solver.cpp:106] Iteration 15400, lr = 0.001
I0422 01:25:17.927065  6613 solver.cpp:228] Iteration 15500, loss = 0.215
I0422 01:25:17.927206  6613 solver.cpp:244]     Train net output #0: loss = 0.215 (* 1 = 0.215 loss)
I0422 01:25:17.927213  6613 sgd_solver.cpp:106] Iteration 15500, lr = 0.001
I0422 01:26:55.205314  6613 solver.cpp:228] Iteration 15600, loss = 0.184448
I0422 01:26:55.205456  6613 solver.cpp:244]     Train net output #0: loss = 0.184448 (* 1 = 0.184448 loss)
I0422 01:26:55.205464  6613 sgd_solver.cpp:106] Iteration 15600, lr = 0.001
I0422 01:28:30.565973  6613 solver.cpp:228] Iteration 15700, loss = 0.135604
I0422 01:28:30.566108  6613 solver.cpp:244]     Train net output #0: loss = 0.135604 (* 1 = 0.135604 loss)
I0422 01:28:30.566115  6613 sgd_solver.cpp:106] Iteration 15700, lr = 0.001
I0422 01:30:07.815364  6613 solver.cpp:228] Iteration 15800, loss = 0.134101
I0422 01:30:07.815510  6613 solver.cpp:244]     Train net output #0: loss = 0.134101 (* 1 = 0.134101 loss)
I0422 01:30:07.815516  6613 sgd_solver.cpp:106] Iteration 15800, lr = 0.001
I0422 01:31:44.925060  6613 solver.cpp:228] Iteration 15900, loss = 0.107944
I0422 01:31:44.925199  6613 solver.cpp:244]     Train net output #0: loss = 0.107944 (* 1 = 0.107944 loss)
I0422 01:31:44.925205  6613 sgd_solver.cpp:106] Iteration 15900, lr = 0.001
I0422 01:33:21.411172  6613 solver.cpp:337] Iteration 16000, Testing net (#0)
I0422 01:33:21.411298  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 01:33:21.411301  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 01:33:21.411306  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 01:33:21.411324  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 01:33:21.411327  6613 net.cpp:693] Ignoring source layer visualize
I0422 01:33:21.411329  6613 net.cpp:693] Ignoring source layer fake
I0422 01:36:41.523830  6613 solver.cpp:404]     Test net output #0: loss = 0.256875 (* 1 = 0.256875 loss)
I0422 01:36:42.154541  6613 solver.cpp:228] Iteration 16000, loss = 0.179701
I0422 01:36:42.154562  6613 solver.cpp:244]     Train net output #0: loss = 0.179701 (* 1 = 0.179701 loss)
I0422 01:36:42.154584  6613 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I0422 01:38:17.492038  6613 solver.cpp:228] Iteration 16100, loss = 0.137422
I0422 01:38:17.492192  6613 solver.cpp:244]     Train net output #0: loss = 0.137422 (* 1 = 0.137422 loss)
I0422 01:38:17.492198  6613 sgd_solver.cpp:106] Iteration 16100, lr = 0.001
I0422 01:39:54.450141  6613 solver.cpp:228] Iteration 16200, loss = 0.379511
I0422 01:39:54.450289  6613 solver.cpp:244]     Train net output #0: loss = 0.379511 (* 1 = 0.379511 loss)
I0422 01:39:54.450295  6613 sgd_solver.cpp:106] Iteration 16200, lr = 0.001
I0422 01:41:31.311425  6613 solver.cpp:228] Iteration 16300, loss = 0.3069
I0422 01:41:31.311563  6613 solver.cpp:244]     Train net output #0: loss = 0.3069 (* 1 = 0.3069 loss)
I0422 01:41:31.311570  6613 sgd_solver.cpp:106] Iteration 16300, lr = 0.001
I0422 01:43:07.980157  6613 solver.cpp:228] Iteration 16400, loss = 0.187292
I0422 01:43:07.980314  6613 solver.cpp:244]     Train net output #0: loss = 0.187292 (* 1 = 0.187292 loss)
I0422 01:43:07.980320  6613 sgd_solver.cpp:106] Iteration 16400, lr = 0.001
I0422 01:44:46.912663  6613 solver.cpp:228] Iteration 16500, loss = 0.157712
I0422 01:44:46.912807  6613 solver.cpp:244]     Train net output #0: loss = 0.157712 (* 1 = 0.157712 loss)
I0422 01:44:46.912814  6613 sgd_solver.cpp:106] Iteration 16500, lr = 0.001
I0422 01:46:24.337832  6613 solver.cpp:228] Iteration 16600, loss = 0.221144
I0422 01:46:24.337973  6613 solver.cpp:244]     Train net output #0: loss = 0.221144 (* 1 = 0.221144 loss)
I0422 01:46:24.337980  6613 sgd_solver.cpp:106] Iteration 16600, lr = 0.001
I0422 01:48:01.603070  6613 solver.cpp:228] Iteration 16700, loss = 0.155788
I0422 01:48:01.603214  6613 solver.cpp:244]     Train net output #0: loss = 0.155788 (* 1 = 0.155788 loss)
I0422 01:48:01.603220  6613 sgd_solver.cpp:106] Iteration 16700, lr = 0.001
I0422 01:49:37.003480  6613 solver.cpp:228] Iteration 16800, loss = 0.110412
I0422 01:49:37.003612  6613 solver.cpp:244]     Train net output #0: loss = 0.110412 (* 1 = 0.110412 loss)
I0422 01:49:37.003618  6613 sgd_solver.cpp:106] Iteration 16800, lr = 0.001
I0422 01:51:14.693720  6613 solver.cpp:228] Iteration 16900, loss = 0.120827
I0422 01:51:14.693864  6613 solver.cpp:244]     Train net output #0: loss = 0.120827 (* 1 = 0.120827 loss)
I0422 01:51:14.693872  6613 sgd_solver.cpp:106] Iteration 16900, lr = 0.001
I0422 01:52:51.229576  6613 solver.cpp:337] Iteration 17000, Testing net (#0)
I0422 01:52:51.229717  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 01:52:51.229722  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 01:52:51.229727  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 01:52:51.229745  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 01:52:51.229748  6613 net.cpp:693] Ignoring source layer visualize
I0422 01:52:51.229750  6613 net.cpp:693] Ignoring source layer fake
I0422 01:56:12.236941  6613 solver.cpp:404]     Test net output #0: loss = 0.172832 (* 1 = 0.172832 loss)
I0422 01:56:12.866528  6613 solver.cpp:228] Iteration 17000, loss = 0.153196
I0422 01:56:12.866571  6613 solver.cpp:244]     Train net output #0: loss = 0.153196 (* 1 = 0.153196 loss)
I0422 01:56:12.866577  6613 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I0422 01:57:48.266774  6613 solver.cpp:228] Iteration 17100, loss = 0.140917
I0422 01:57:48.266912  6613 solver.cpp:244]     Train net output #0: loss = 0.140917 (* 1 = 0.140917 loss)
I0422 01:57:48.266921  6613 sgd_solver.cpp:106] Iteration 17100, lr = 0.001
I0422 01:59:25.874927  6613 solver.cpp:228] Iteration 17200, loss = 0.0924727
I0422 01:59:25.875071  6613 solver.cpp:244]     Train net output #0: loss = 0.0924727 (* 1 = 0.0924727 loss)
I0422 01:59:25.875077  6613 sgd_solver.cpp:106] Iteration 17200, lr = 0.001
I0422 02:01:03.491088  6613 solver.cpp:228] Iteration 17300, loss = 0.102673
I0422 02:01:03.491261  6613 solver.cpp:244]     Train net output #0: loss = 0.102673 (* 1 = 0.102673 loss)
I0422 02:01:03.491269  6613 sgd_solver.cpp:106] Iteration 17300, lr = 0.001
I0422 02:02:40.807569  6613 solver.cpp:228] Iteration 17400, loss = 0.097647
I0422 02:02:40.807703  6613 solver.cpp:244]     Train net output #0: loss = 0.097647 (* 1 = 0.097647 loss)
I0422 02:02:40.807710  6613 sgd_solver.cpp:106] Iteration 17400, lr = 0.001
I0422 02:04:17.620445  6613 solver.cpp:228] Iteration 17500, loss = 0.121417
I0422 02:04:17.620578  6613 solver.cpp:244]     Train net output #0: loss = 0.121417 (* 1 = 0.121417 loss)
I0422 02:04:17.620585  6613 sgd_solver.cpp:106] Iteration 17500, lr = 0.001
I0422 02:05:54.684384  6613 solver.cpp:228] Iteration 17600, loss = 0.112611
I0422 02:05:54.684535  6613 solver.cpp:244]     Train net output #0: loss = 0.112611 (* 1 = 0.112611 loss)
I0422 02:05:54.684543  6613 sgd_solver.cpp:106] Iteration 17600, lr = 0.001
I0422 02:07:31.544080  6613 solver.cpp:228] Iteration 17700, loss = 0.117455
I0422 02:07:31.544260  6613 solver.cpp:244]     Train net output #0: loss = 0.117455 (* 1 = 0.117455 loss)
I0422 02:07:31.544268  6613 sgd_solver.cpp:106] Iteration 17700, lr = 0.001
I0422 02:09:06.909236  6613 solver.cpp:228] Iteration 17800, loss = 0.188211
I0422 02:09:06.909377  6613 solver.cpp:244]     Train net output #0: loss = 0.188211 (* 1 = 0.188211 loss)
I0422 02:09:06.909384  6613 sgd_solver.cpp:106] Iteration 17800, lr = 0.001
I0422 02:10:43.979635  6613 solver.cpp:228] Iteration 17900, loss = 0.134227
I0422 02:10:43.979770  6613 solver.cpp:244]     Train net output #0: loss = 0.134227 (* 1 = 0.134227 loss)
I0422 02:10:43.979779  6613 sgd_solver.cpp:106] Iteration 17900, lr = 0.001
I0422 02:12:20.352246  6613 solver.cpp:337] Iteration 18000, Testing net (#0)
I0422 02:12:20.352382  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 02:12:20.352386  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 02:12:20.352391  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 02:12:20.352407  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 02:12:20.352411  6613 net.cpp:693] Ignoring source layer visualize
I0422 02:12:20.352412  6613 net.cpp:693] Ignoring source layer fake
I0422 02:15:40.840839  6613 solver.cpp:404]     Test net output #0: loss = 0.178489 (* 1 = 0.178489 loss)
I0422 02:15:41.468402  6613 solver.cpp:228] Iteration 18000, loss = 0.126327
I0422 02:15:41.468423  6613 solver.cpp:244]     Train net output #0: loss = 0.126327 (* 1 = 0.126327 loss)
I0422 02:15:41.468446  6613 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0422 02:17:19.434032  6613 solver.cpp:228] Iteration 18100, loss = 0.231465
I0422 02:17:19.434186  6613 solver.cpp:244]     Train net output #0: loss = 0.231465 (* 1 = 0.231465 loss)
I0422 02:17:19.434200  6613 sgd_solver.cpp:106] Iteration 18100, lr = 0.001
I0422 02:18:54.813923  6613 solver.cpp:228] Iteration 18200, loss = 0.0981535
I0422 02:18:54.814075  6613 solver.cpp:244]     Train net output #0: loss = 0.0981535 (* 1 = 0.0981535 loss)
I0422 02:18:54.814083  6613 sgd_solver.cpp:106] Iteration 18200, lr = 0.001
I0422 02:20:32.564744  6613 solver.cpp:228] Iteration 18300, loss = 0.130222
I0422 02:20:32.564893  6613 solver.cpp:244]     Train net output #0: loss = 0.130222 (* 1 = 0.130222 loss)
I0422 02:20:32.564903  6613 sgd_solver.cpp:106] Iteration 18300, lr = 0.001
I0422 02:22:10.129269  6613 solver.cpp:228] Iteration 18400, loss = 0.10618
I0422 02:22:10.130599  6613 solver.cpp:244]     Train net output #0: loss = 0.10618 (* 1 = 0.10618 loss)
I0422 02:22:10.130606  6613 sgd_solver.cpp:106] Iteration 18400, lr = 0.001
I0422 02:23:47.717723  6613 solver.cpp:228] Iteration 18500, loss = 0.134213
I0422 02:23:47.717890  6613 solver.cpp:244]     Train net output #0: loss = 0.134213 (* 1 = 0.134213 loss)
I0422 02:23:47.717897  6613 sgd_solver.cpp:106] Iteration 18500, lr = 0.001
I0422 02:25:23.026749  6613 solver.cpp:228] Iteration 18600, loss = 0.103753
I0422 02:25:23.026895  6613 solver.cpp:244]     Train net output #0: loss = 0.103753 (* 1 = 0.103753 loss)
I0422 02:25:23.026907  6613 sgd_solver.cpp:106] Iteration 18600, lr = 0.001
I0422 02:27:00.391082  6613 solver.cpp:228] Iteration 18700, loss = 0.176571
I0422 02:27:00.391234  6613 solver.cpp:244]     Train net output #0: loss = 0.176571 (* 1 = 0.176571 loss)
I0422 02:27:00.391242  6613 sgd_solver.cpp:106] Iteration 18700, lr = 0.001
I0422 02:28:37.020473  6613 solver.cpp:228] Iteration 18800, loss = 0.171946
I0422 02:28:37.020620  6613 solver.cpp:244]     Train net output #0: loss = 0.171946 (* 1 = 0.171946 loss)
I0422 02:28:37.020627  6613 sgd_solver.cpp:106] Iteration 18800, lr = 0.001
I0422 02:30:13.777523  6613 solver.cpp:228] Iteration 18900, loss = 0.176442
I0422 02:30:13.777659  6613 solver.cpp:244]     Train net output #0: loss = 0.176442 (* 1 = 0.176442 loss)
I0422 02:30:13.777667  6613 sgd_solver.cpp:106] Iteration 18900, lr = 0.001
I0422 02:31:49.692935  6613 solver.cpp:337] Iteration 19000, Testing net (#0)
I0422 02:31:49.693815  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 02:31:49.693821  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 02:31:49.693825  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 02:31:49.693841  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 02:31:49.693845  6613 net.cpp:693] Ignoring source layer visualize
I0422 02:31:49.693861  6613 net.cpp:693] Ignoring source layer fake
I0422 02:35:10.155053  6613 solver.cpp:404]     Test net output #0: loss = 0.174599 (* 1 = 0.174599 loss)
I0422 02:35:10.783927  6613 solver.cpp:228] Iteration 19000, loss = 0.161198
I0422 02:35:10.783947  6613 solver.cpp:244]     Train net output #0: loss = 0.161198 (* 1 = 0.161198 loss)
I0422 02:35:10.783970  6613 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I0422 02:36:50.401614  6613 solver.cpp:228] Iteration 19100, loss = 0.191282
I0422 02:36:50.401767  6613 solver.cpp:244]     Train net output #0: loss = 0.191282 (* 1 = 0.191282 loss)
I0422 02:36:50.401774  6613 sgd_solver.cpp:106] Iteration 19100, lr = 0.001
I0422 02:38:28.072190  6613 solver.cpp:228] Iteration 19200, loss = 0.179634
I0422 02:38:28.072334  6613 solver.cpp:244]     Train net output #0: loss = 0.179634 (* 1 = 0.179634 loss)
I0422 02:38:28.072347  6613 sgd_solver.cpp:106] Iteration 19200, lr = 0.001
I0422 02:40:03.430112  6613 solver.cpp:228] Iteration 19300, loss = 0.137391
I0422 02:40:03.430260  6613 solver.cpp:244]     Train net output #0: loss = 0.137391 (* 1 = 0.137391 loss)
I0422 02:40:03.430268  6613 sgd_solver.cpp:106] Iteration 19300, lr = 0.001
I0422 02:41:40.854956  6613 solver.cpp:228] Iteration 19400, loss = 0.156045
I0422 02:41:40.855106  6613 solver.cpp:244]     Train net output #0: loss = 0.156045 (* 1 = 0.156045 loss)
I0422 02:41:40.855115  6613 sgd_solver.cpp:106] Iteration 19400, lr = 0.001
I0422 02:43:18.217898  6613 solver.cpp:228] Iteration 19500, loss = 0.146077
I0422 02:43:18.218046  6613 solver.cpp:244]     Train net output #0: loss = 0.146077 (* 1 = 0.146077 loss)
I0422 02:43:18.218055  6613 sgd_solver.cpp:106] Iteration 19500, lr = 0.001
I0422 02:44:53.574434  6613 solver.cpp:228] Iteration 19600, loss = 0.161766
I0422 02:44:53.574578  6613 solver.cpp:244]     Train net output #0: loss = 0.161766 (* 1 = 0.161766 loss)
I0422 02:44:53.574584  6613 sgd_solver.cpp:106] Iteration 19600, lr = 0.001
I0422 02:46:31.172847  6613 solver.cpp:228] Iteration 19700, loss = 0.0682797
I0422 02:46:31.173001  6613 solver.cpp:244]     Train net output #0: loss = 0.0682797 (* 1 = 0.0682797 loss)
I0422 02:46:31.173007  6613 sgd_solver.cpp:106] Iteration 19700, lr = 0.001
I0422 02:48:08.495245  6613 solver.cpp:228] Iteration 19800, loss = 0.120081
I0422 02:48:08.495393  6613 solver.cpp:244]     Train net output #0: loss = 0.120081 (* 1 = 0.120081 loss)
I0422 02:48:08.495399  6613 sgd_solver.cpp:106] Iteration 19800, lr = 0.001
I0422 02:49:45.715831  6613 solver.cpp:228] Iteration 19900, loss = 0.115593
I0422 02:49:45.716207  6613 solver.cpp:244]     Train net output #0: loss = 0.115593 (* 1 = 0.115593 loss)
I0422 02:49:45.716215  6613 sgd_solver.cpp:106] Iteration 19900, lr = 0.001
I0422 02:51:21.504518  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_20000.caffemodel
I0422 02:51:32.081147  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_20000.solverstate
I0422 02:51:32.284337  6613 solver.cpp:337] Iteration 20000, Testing net (#0)
I0422 02:51:32.284366  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 02:51:32.284369  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 02:51:32.284373  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 02:51:32.284406  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 02:51:32.284409  6613 net.cpp:693] Ignoring source layer visualize
I0422 02:51:32.284411  6613 net.cpp:693] Ignoring source layer fake
I0422 02:54:52.640370  6613 solver.cpp:404]     Test net output #0: loss = 0.156789 (* 1 = 0.156789 loss)
I0422 02:54:53.263480  6613 solver.cpp:228] Iteration 20000, loss = 0.12806
I0422 02:54:53.263520  6613 solver.cpp:244]     Train net output #0: loss = 0.12806 (* 1 = 0.12806 loss)
I0422 02:54:53.263526  6613 sgd_solver.cpp:106] Iteration 20000, lr = 0.0001
I0422 02:56:30.085780  6613 solver.cpp:228] Iteration 20100, loss = 0.105336
I0422 02:56:30.085937  6613 solver.cpp:244]     Train net output #0: loss = 0.105336 (* 1 = 0.105336 loss)
I0422 02:56:30.085944  6613 sgd_solver.cpp:106] Iteration 20100, lr = 0.0001
I0422 02:58:07.266623  6613 solver.cpp:228] Iteration 20200, loss = 0.0868407
I0422 02:58:07.266820  6613 solver.cpp:244]     Train net output #0: loss = 0.0868407 (* 1 = 0.0868407 loss)
I0422 02:58:07.266829  6613 sgd_solver.cpp:106] Iteration 20200, lr = 0.0001
I0422 02:59:42.607555  6613 solver.cpp:228] Iteration 20300, loss = 0.210284
I0422 02:59:42.607705  6613 solver.cpp:244]     Train net output #0: loss = 0.210284 (* 1 = 0.210284 loss)
I0422 02:59:42.607712  6613 sgd_solver.cpp:106] Iteration 20300, lr = 0.0001
I0422 03:01:20.003183  6613 solver.cpp:228] Iteration 20400, loss = 0.201055
I0422 03:01:20.003336  6613 solver.cpp:244]     Train net output #0: loss = 0.201055 (* 1 = 0.201055 loss)
I0422 03:01:20.003343  6613 sgd_solver.cpp:106] Iteration 20400, lr = 0.0001
I0422 03:02:57.421428  6613 solver.cpp:228] Iteration 20500, loss = 0.212643
I0422 03:02:57.421574  6613 solver.cpp:244]     Train net output #0: loss = 0.212643 (* 1 = 0.212643 loss)
I0422 03:02:57.421582  6613 sgd_solver.cpp:106] Iteration 20500, lr = 0.0001
I0422 03:04:34.656011  6613 solver.cpp:228] Iteration 20600, loss = 0.17277
I0422 03:04:34.656177  6613 solver.cpp:244]     Train net output #0: loss = 0.17277 (* 1 = 0.17277 loss)
I0422 03:04:34.656183  6613 sgd_solver.cpp:106] Iteration 20600, lr = 0.0001
I0422 03:06:10.038784  6613 solver.cpp:228] Iteration 20700, loss = 0.127333
I0422 03:06:10.038926  6613 solver.cpp:244]     Train net output #0: loss = 0.127333 (* 1 = 0.127333 loss)
I0422 03:06:10.038933  6613 sgd_solver.cpp:106] Iteration 20700, lr = 0.0001
I0422 03:07:47.273350  6613 solver.cpp:228] Iteration 20800, loss = 0.102444
I0422 03:07:47.273490  6613 solver.cpp:244]     Train net output #0: loss = 0.102444 (* 1 = 0.102444 loss)
I0422 03:07:47.273497  6613 sgd_solver.cpp:106] Iteration 20800, lr = 0.0001
I0422 03:09:24.419890  6613 solver.cpp:228] Iteration 20900, loss = 0.0937471
I0422 03:09:24.420027  6613 solver.cpp:244]     Train net output #0: loss = 0.0937471 (* 1 = 0.0937471 loss)
I0422 03:09:24.420034  6613 sgd_solver.cpp:106] Iteration 20900, lr = 0.0001
I0422 03:11:00.606223  6613 solver.cpp:337] Iteration 21000, Testing net (#0)
I0422 03:11:00.606369  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 03:11:00.606374  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 03:11:00.606379  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 03:11:00.606396  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 03:11:00.606400  6613 net.cpp:693] Ignoring source layer visualize
I0422 03:11:00.606401  6613 net.cpp:693] Ignoring source layer fake
I0422 03:14:21.080698  6613 solver.cpp:404]     Test net output #0: loss = 0.13207 (* 1 = 0.13207 loss)
I0422 03:14:21.706657  6613 solver.cpp:228] Iteration 21000, loss = 0.0769612
I0422 03:14:21.706679  6613 solver.cpp:244]     Train net output #0: loss = 0.0769612 (* 1 = 0.0769612 loss)
I0422 03:14:21.706701  6613 sgd_solver.cpp:106] Iteration 21000, lr = 0.0001
I0422 03:15:57.091970  6613 solver.cpp:228] Iteration 21100, loss = 0.107351
I0422 03:15:57.092115  6613 solver.cpp:244]     Train net output #0: loss = 0.107351 (* 1 = 0.107351 loss)
I0422 03:15:57.092121  6613 sgd_solver.cpp:106] Iteration 21100, lr = 0.0001
I0422 03:17:34.072846  6613 solver.cpp:228] Iteration 21200, loss = 0.0937717
I0422 03:17:34.073000  6613 solver.cpp:244]     Train net output #0: loss = 0.0937717 (* 1 = 0.0937717 loss)
I0422 03:17:34.073007  6613 sgd_solver.cpp:106] Iteration 21200, lr = 0.0001
I0422 03:19:10.886052  6613 solver.cpp:228] Iteration 21300, loss = 0.199952
I0422 03:19:10.886229  6613 solver.cpp:244]     Train net output #0: loss = 0.199952 (* 1 = 0.199952 loss)
I0422 03:19:10.886237  6613 sgd_solver.cpp:106] Iteration 21300, lr = 0.0001
I0422 03:20:47.592550  6613 solver.cpp:228] Iteration 21400, loss = 0.184149
I0422 03:20:47.594282  6613 solver.cpp:244]     Train net output #0: loss = 0.184149 (* 1 = 0.184149 loss)
I0422 03:20:47.594290  6613 sgd_solver.cpp:106] Iteration 21400, lr = 0.0001
I0422 03:22:24.483662  6613 solver.cpp:228] Iteration 21500, loss = 0.118041
I0422 03:22:24.483803  6613 solver.cpp:244]     Train net output #0: loss = 0.118041 (* 1 = 0.118041 loss)
I0422 03:22:24.483809  6613 sgd_solver.cpp:106] Iteration 21500, lr = 0.0001
I0422 03:24:01.810366  6613 solver.cpp:228] Iteration 21600, loss = 0.278043
I0422 03:24:01.810523  6613 solver.cpp:244]     Train net output #0: loss = 0.278043 (* 1 = 0.278043 loss)
I0422 03:24:01.810529  6613 sgd_solver.cpp:106] Iteration 21600, lr = 0.0001
I0422 03:25:39.143512  6613 solver.cpp:228] Iteration 21700, loss = 0.188041
I0422 03:25:39.143656  6613 solver.cpp:244]     Train net output #0: loss = 0.188041 (* 1 = 0.188041 loss)
I0422 03:25:39.143663  6613 sgd_solver.cpp:106] Iteration 21700, lr = 0.0001
I0422 03:27:14.506505  6613 solver.cpp:228] Iteration 21800, loss = 0.137417
I0422 03:27:14.506642  6613 solver.cpp:244]     Train net output #0: loss = 0.137417 (* 1 = 0.137417 loss)
I0422 03:27:14.506649  6613 sgd_solver.cpp:106] Iteration 21800, lr = 0.0001
I0422 03:28:51.821940  6613 solver.cpp:228] Iteration 21900, loss = 0.16567
I0422 03:28:51.822088  6613 solver.cpp:244]     Train net output #0: loss = 0.16567 (* 1 = 0.16567 loss)
I0422 03:28:51.822094  6613 sgd_solver.cpp:106] Iteration 21900, lr = 0.0001
I0422 03:30:28.202069  6613 solver.cpp:337] Iteration 22000, Testing net (#0)
I0422 03:30:28.202205  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 03:30:28.202209  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 03:30:28.202214  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 03:30:28.202231  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 03:30:28.202234  6613 net.cpp:693] Ignoring source layer visualize
I0422 03:30:28.202236  6613 net.cpp:693] Ignoring source layer fake
I0422 03:33:48.959662  6613 solver.cpp:404]     Test net output #0: loss = 0.155653 (* 1 = 0.155653 loss)
I0422 03:33:49.585618  6613 solver.cpp:228] Iteration 22000, loss = 0.121352
I0422 03:33:49.585644  6613 solver.cpp:244]     Train net output #0: loss = 0.121352 (* 1 = 0.121352 loss)
I0422 03:33:49.585665  6613 sgd_solver.cpp:106] Iteration 22000, lr = 0.0001
I0422 03:35:24.995465  6613 solver.cpp:228] Iteration 22100, loss = 0.078987
I0422 03:35:24.995613  6613 solver.cpp:244]     Train net output #0: loss = 0.078987 (* 1 = 0.078987 loss)
I0422 03:35:24.995621  6613 sgd_solver.cpp:106] Iteration 22100, lr = 0.0001
I0422 03:37:08.744725  6613 solver.cpp:228] Iteration 22200, loss = 0.102793
I0422 03:37:08.744877  6613 solver.cpp:244]     Train net output #0: loss = 0.102793 (* 1 = 0.102793 loss)
I0422 03:37:08.744885  6613 sgd_solver.cpp:106] Iteration 22200, lr = 0.0001
I0422 03:38:45.904491  6613 solver.cpp:228] Iteration 22300, loss = 0.131273
I0422 03:38:45.904641  6613 solver.cpp:244]     Train net output #0: loss = 0.131273 (* 1 = 0.131273 loss)
I0422 03:38:45.904649  6613 sgd_solver.cpp:106] Iteration 22300, lr = 0.0001
I0422 03:40:23.406057  6613 solver.cpp:228] Iteration 22400, loss = 0.127688
I0422 03:40:23.406198  6613 solver.cpp:244]     Train net output #0: loss = 0.127688 (* 1 = 0.127688 loss)
I0422 03:40:23.406205  6613 sgd_solver.cpp:106] Iteration 22400, lr = 0.0001
I0422 03:42:00.647342  6613 solver.cpp:228] Iteration 22500, loss = 0.144066
I0422 03:42:00.647493  6613 solver.cpp:244]     Train net output #0: loss = 0.144066 (* 1 = 0.144066 loss)
I0422 03:42:00.647500  6613 sgd_solver.cpp:106] Iteration 22500, lr = 0.0001
I0422 03:43:38.131382  6613 solver.cpp:228] Iteration 22600, loss = 0.188562
I0422 03:43:38.131538  6613 solver.cpp:244]     Train net output #0: loss = 0.188562 (* 1 = 0.188562 loss)
I0422 03:43:38.131546  6613 sgd_solver.cpp:106] Iteration 22600, lr = 0.0001
I0422 03:45:15.446882  6613 solver.cpp:228] Iteration 22700, loss = 0.183283
I0422 03:45:15.447031  6613 solver.cpp:244]     Train net output #0: loss = 0.183283 (* 1 = 0.183283 loss)
I0422 03:45:15.447037  6613 sgd_solver.cpp:106] Iteration 22700, lr = 0.0001
I0422 03:46:50.839056  6613 solver.cpp:228] Iteration 22800, loss = 0.14956
I0422 03:46:50.839190  6613 solver.cpp:244]     Train net output #0: loss = 0.14956 (* 1 = 0.14956 loss)
I0422 03:46:50.839196  6613 sgd_solver.cpp:106] Iteration 22800, lr = 0.0001
I0422 03:48:28.457001  6613 solver.cpp:228] Iteration 22900, loss = 0.177142
I0422 03:48:28.457151  6613 solver.cpp:244]     Train net output #0: loss = 0.177142 (* 1 = 0.177142 loss)
I0422 03:48:28.457159  6613 sgd_solver.cpp:106] Iteration 22900, lr = 0.0001
I0422 03:50:04.785536  6613 solver.cpp:337] Iteration 23000, Testing net (#0)
I0422 03:50:04.785676  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 03:50:04.785679  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 03:50:04.785684  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 03:50:04.785701  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 03:50:04.785704  6613 net.cpp:693] Ignoring source layer visualize
I0422 03:50:04.785706  6613 net.cpp:693] Ignoring source layer fake
I0422 03:53:24.855478  6613 solver.cpp:404]     Test net output #0: loss = 0.15863 (* 1 = 0.15863 loss)
I0422 03:53:25.480152  6613 solver.cpp:228] Iteration 23000, loss = 0.146789
I0422 03:53:25.480193  6613 solver.cpp:244]     Train net output #0: loss = 0.146789 (* 1 = 0.146789 loss)
I0422 03:53:25.480199  6613 sgd_solver.cpp:106] Iteration 23000, lr = 0.0001
I0422 03:55:03.432855  6613 solver.cpp:228] Iteration 23100, loss = 0.100765
I0422 03:55:03.433003  6613 solver.cpp:244]     Train net output #0: loss = 0.100765 (* 1 = 0.100765 loss)
I0422 03:55:03.433010  6613 sgd_solver.cpp:106] Iteration 23100, lr = 0.0001
I0422 03:56:38.798225  6613 solver.cpp:228] Iteration 23200, loss = 0.167597
I0422 03:56:38.798360  6613 solver.cpp:244]     Train net output #0: loss = 0.167597 (* 1 = 0.167597 loss)
I0422 03:56:38.798367  6613 sgd_solver.cpp:106] Iteration 23200, lr = 0.0001
I0422 03:58:16.639912  6613 solver.cpp:228] Iteration 23300, loss = 0.129492
I0422 03:58:16.641772  6613 solver.cpp:244]     Train net output #0: loss = 0.129492 (* 1 = 0.129492 loss)
I0422 03:58:16.641782  6613 sgd_solver.cpp:106] Iteration 23300, lr = 0.0001
I0422 03:59:54.084334  6613 solver.cpp:228] Iteration 23400, loss = 0.0892907
I0422 03:59:54.085058  6613 solver.cpp:244]     Train net output #0: loss = 0.0892907 (* 1 = 0.0892907 loss)
I0422 03:59:54.085067  6613 sgd_solver.cpp:106] Iteration 23400, lr = 0.0001
I0422 04:01:31.455371  6613 solver.cpp:228] Iteration 23500, loss = 0.0923178
I0422 04:01:31.455502  6613 solver.cpp:244]     Train net output #0: loss = 0.0923178 (* 1 = 0.0923178 loss)
I0422 04:01:31.455510  6613 sgd_solver.cpp:106] Iteration 23500, lr = 0.0001
I0422 04:03:06.779691  6613 solver.cpp:228] Iteration 23600, loss = 0.106785
I0422 04:03:06.779832  6613 solver.cpp:244]     Train net output #0: loss = 0.106785 (* 1 = 0.106785 loss)
I0422 04:03:06.779839  6613 sgd_solver.cpp:106] Iteration 23600, lr = 0.0001
I0422 04:04:43.866233  6613 solver.cpp:228] Iteration 23700, loss = 0.106592
I0422 04:04:43.866369  6613 solver.cpp:244]     Train net output #0: loss = 0.106592 (* 1 = 0.106592 loss)
I0422 04:04:43.866376  6613 sgd_solver.cpp:106] Iteration 23700, lr = 0.0001
I0422 04:06:20.592510  6613 solver.cpp:228] Iteration 23800, loss = 0.168009
I0422 04:06:20.592669  6613 solver.cpp:244]     Train net output #0: loss = 0.168009 (* 1 = 0.168009 loss)
I0422 04:06:20.592677  6613 sgd_solver.cpp:106] Iteration 23800, lr = 0.0001
I0422 04:07:57.388608  6613 solver.cpp:228] Iteration 23900, loss = 0.152294
I0422 04:07:57.388762  6613 solver.cpp:244]     Train net output #0: loss = 0.152294 (* 1 = 0.152294 loss)
I0422 04:07:57.388770  6613 sgd_solver.cpp:106] Iteration 23900, lr = 0.0001
I0422 04:09:33.463027  6613 solver.cpp:337] Iteration 24000, Testing net (#0)
I0422 04:09:33.463083  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 04:09:33.463086  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 04:09:33.463090  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 04:09:33.463107  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 04:09:33.463110  6613 net.cpp:693] Ignoring source layer visualize
I0422 04:09:33.463112  6613 net.cpp:693] Ignoring source layer fake
I0422 04:12:54.645543  6613 solver.cpp:404]     Test net output #0: loss = 0.142232 (* 1 = 0.142232 loss)
I0422 04:12:55.276093  6613 solver.cpp:228] Iteration 24000, loss = 0.12619
I0422 04:12:55.276136  6613 solver.cpp:244]     Train net output #0: loss = 0.12619 (* 1 = 0.12619 loss)
I0422 04:12:55.276142  6613 sgd_solver.cpp:106] Iteration 24000, lr = 0.0001
I0422 04:14:32.599372  6613 solver.cpp:228] Iteration 24100, loss = 0.201089
I0422 04:14:32.599521  6613 solver.cpp:244]     Train net output #0: loss = 0.201089 (* 1 = 0.201089 loss)
I0422 04:14:32.599530  6613 sgd_solver.cpp:106] Iteration 24100, lr = 0.0001
I0422 04:16:10.116255  6613 solver.cpp:228] Iteration 24200, loss = 0.112288
I0422 04:16:10.116412  6613 solver.cpp:244]     Train net output #0: loss = 0.112288 (* 1 = 0.112288 loss)
I0422 04:16:10.116420  6613 sgd_solver.cpp:106] Iteration 24200, lr = 0.0001
I0422 04:17:45.494328  6613 solver.cpp:228] Iteration 24300, loss = 0.110591
I0422 04:17:45.494482  6613 solver.cpp:244]     Train net output #0: loss = 0.110591 (* 1 = 0.110591 loss)
I0422 04:17:45.494488  6613 sgd_solver.cpp:106] Iteration 24300, lr = 0.0001
I0422 04:19:22.969224  6613 solver.cpp:228] Iteration 24400, loss = 0.0967557
I0422 04:19:22.969964  6613 solver.cpp:244]     Train net output #0: loss = 0.0967557 (* 1 = 0.0967557 loss)
I0422 04:19:22.969971  6613 sgd_solver.cpp:106] Iteration 24400, lr = 0.0001
I0422 04:21:00.365525  6613 solver.cpp:228] Iteration 24500, loss = 0.108053
I0422 04:21:00.365650  6613 solver.cpp:244]     Train net output #0: loss = 0.108053 (* 1 = 0.108053 loss)
I0422 04:21:00.365659  6613 sgd_solver.cpp:106] Iteration 24500, lr = 0.0001
I0422 04:22:35.734819  6613 solver.cpp:228] Iteration 24600, loss = 0.117361
I0422 04:22:35.734956  6613 solver.cpp:244]     Train net output #0: loss = 0.117361 (* 1 = 0.117361 loss)
I0422 04:22:35.734963  6613 sgd_solver.cpp:106] Iteration 24600, lr = 0.0001
I0422 04:24:13.023124  6613 solver.cpp:228] Iteration 24700, loss = 0.104282
I0422 04:24:13.023263  6613 solver.cpp:244]     Train net output #0: loss = 0.104282 (* 1 = 0.104282 loss)
I0422 04:24:13.023270  6613 sgd_solver.cpp:106] Iteration 24700, lr = 0.0001
I0422 04:25:50.921969  6613 solver.cpp:228] Iteration 24800, loss = 0.122983
I0422 04:25:50.922142  6613 solver.cpp:244]     Train net output #0: loss = 0.122983 (* 1 = 0.122983 loss)
I0422 04:25:50.922152  6613 sgd_solver.cpp:106] Iteration 24800, lr = 0.0001
I0422 04:27:28.174051  6613 solver.cpp:228] Iteration 24900, loss = 0.175805
I0422 04:27:28.174188  6613 solver.cpp:244]     Train net output #0: loss = 0.175805 (* 1 = 0.175805 loss)
I0422 04:27:28.174196  6613 sgd_solver.cpp:106] Iteration 24900, lr = 0.0001
I0422 04:29:04.869942  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_25000.caffemodel
I0422 04:29:10.917845  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_25000.solverstate
I0422 04:29:11.111549  6613 solver.cpp:337] Iteration 25000, Testing net (#0)
I0422 04:29:11.111594  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 04:29:11.111598  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 04:29:11.111600  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 04:29:11.111618  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 04:29:11.111620  6613 net.cpp:693] Ignoring source layer visualize
I0422 04:29:11.111623  6613 net.cpp:693] Ignoring source layer fake
I0422 04:32:31.778983  6613 solver.cpp:404]     Test net output #0: loss = 0.137529 (* 1 = 0.137529 loss)
I0422 04:32:32.404626  6613 solver.cpp:228] Iteration 25000, loss = 0.145738
I0422 04:32:32.404669  6613 solver.cpp:244]     Train net output #0: loss = 0.145738 (* 1 = 0.145738 loss)
I0422 04:32:32.404675  6613 sgd_solver.cpp:106] Iteration 25000, lr = 0.0001
I0422 04:34:09.390455  6613 solver.cpp:228] Iteration 25100, loss = 0.197439
I0422 04:34:09.391247  6613 solver.cpp:244]     Train net output #0: loss = 0.197439 (* 1 = 0.197439 loss)
I0422 04:34:09.391257  6613 sgd_solver.cpp:106] Iteration 25100, lr = 0.0001
I0422 04:35:46.377264  6613 solver.cpp:228] Iteration 25200, loss = 0.167689
I0422 04:35:46.377427  6613 solver.cpp:244]     Train net output #0: loss = 0.167689 (* 1 = 0.167689 loss)
I0422 04:35:46.377441  6613 sgd_solver.cpp:106] Iteration 25200, lr = 0.0001
I0422 04:37:21.723091  6613 solver.cpp:228] Iteration 25300, loss = 0.121207
I0422 04:37:21.723254  6613 solver.cpp:244]     Train net output #0: loss = 0.121207 (* 1 = 0.121207 loss)
I0422 04:37:21.723263  6613 sgd_solver.cpp:106] Iteration 25300, lr = 0.0001
I0422 04:38:59.134289  6613 solver.cpp:228] Iteration 25400, loss = 0.126357
I0422 04:38:59.134440  6613 solver.cpp:244]     Train net output #0: loss = 0.126357 (* 1 = 0.126357 loss)
I0422 04:38:59.134449  6613 sgd_solver.cpp:106] Iteration 25400, lr = 0.0001
I0422 04:40:36.402658  6613 solver.cpp:228] Iteration 25500, loss = 0.146163
I0422 04:40:36.402803  6613 solver.cpp:244]     Train net output #0: loss = 0.146163 (* 1 = 0.146163 loss)
I0422 04:40:36.402812  6613 sgd_solver.cpp:106] Iteration 25500, lr = 0.0001
I0422 04:42:13.739857  6613 solver.cpp:228] Iteration 25600, loss = 0.0802736
I0422 04:42:13.740005  6613 solver.cpp:244]     Train net output #0: loss = 0.0802736 (* 1 = 0.0802736 loss)
I0422 04:42:13.740012  6613 sgd_solver.cpp:106] Iteration 25600, lr = 0.0001
I0422 04:43:49.115257  6613 solver.cpp:228] Iteration 25700, loss = 0.138466
I0422 04:43:49.115396  6613 solver.cpp:244]     Train net output #0: loss = 0.138466 (* 1 = 0.138466 loss)
I0422 04:43:49.115402  6613 sgd_solver.cpp:106] Iteration 25700, lr = 0.0001
I0422 04:45:26.309778  6613 solver.cpp:228] Iteration 25800, loss = 0.136207
I0422 04:45:26.309926  6613 solver.cpp:244]     Train net output #0: loss = 0.136207 (* 1 = 0.136207 loss)
I0422 04:45:26.309933  6613 sgd_solver.cpp:106] Iteration 25800, lr = 0.0001
I0422 04:47:03.475795  6613 solver.cpp:228] Iteration 25900, loss = 0.104234
I0422 04:47:03.475962  6613 solver.cpp:244]     Train net output #0: loss = 0.104234 (* 1 = 0.104234 loss)
I0422 04:47:03.475970  6613 sgd_solver.cpp:106] Iteration 25900, lr = 0.0001
I0422 04:48:39.641914  6613 solver.cpp:337] Iteration 26000, Testing net (#0)
I0422 04:48:39.642050  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 04:48:39.642053  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 04:48:39.642058  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 04:48:39.642076  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 04:48:39.642078  6613 net.cpp:693] Ignoring source layer visualize
I0422 04:48:39.642081  6613 net.cpp:693] Ignoring source layer fake
I0422 04:52:00.132328  6613 solver.cpp:404]     Test net output #0: loss = 0.128709 (* 1 = 0.128709 loss)
I0422 04:52:00.758095  6613 solver.cpp:228] Iteration 26000, loss = 0.131191
I0422 04:52:00.758136  6613 solver.cpp:244]     Train net output #0: loss = 0.131191 (* 1 = 0.131191 loss)
I0422 04:52:00.758141  6613 sgd_solver.cpp:106] Iteration 26000, lr = 0.0001
I0422 04:53:36.158495  6613 solver.cpp:228] Iteration 26100, loss = 0.0936993
I0422 04:53:36.158624  6613 solver.cpp:244]     Train net output #0: loss = 0.0936993 (* 1 = 0.0936993 loss)
I0422 04:53:36.158632  6613 sgd_solver.cpp:106] Iteration 26100, lr = 0.0001
I0422 04:55:13.100535  6613 solver.cpp:228] Iteration 26200, loss = 0.0981545
I0422 04:55:13.100687  6613 solver.cpp:244]     Train net output #0: loss = 0.0981545 (* 1 = 0.0981545 loss)
I0422 04:55:13.100693  6613 sgd_solver.cpp:106] Iteration 26200, lr = 0.0001
I0422 04:56:49.731568  6613 solver.cpp:228] Iteration 26300, loss = 0.167925
I0422 04:56:49.731751  6613 solver.cpp:244]     Train net output #0: loss = 0.167925 (* 1 = 0.167925 loss)
I0422 04:56:49.731761  6613 sgd_solver.cpp:106] Iteration 26300, lr = 0.0001
I0422 04:58:26.414664  6613 solver.cpp:228] Iteration 26400, loss = 0.168204
I0422 04:58:26.414822  6613 solver.cpp:244]     Train net output #0: loss = 0.168204 (* 1 = 0.168204 loss)
I0422 04:58:26.414829  6613 sgd_solver.cpp:106] Iteration 26400, lr = 0.0001
I0422 05:00:03.340359  6613 solver.cpp:228] Iteration 26500, loss = 0.17159
I0422 05:00:03.340497  6613 solver.cpp:244]     Train net output #0: loss = 0.17159 (* 1 = 0.17159 loss)
I0422 05:00:03.340513  6613 sgd_solver.cpp:106] Iteration 26500, lr = 0.0001
I0422 05:01:40.623752  6613 solver.cpp:228] Iteration 26600, loss = 0.128845
I0422 05:01:40.623900  6613 solver.cpp:244]     Train net output #0: loss = 0.128845 (* 1 = 0.128845 loss)
I0422 05:01:40.623908  6613 sgd_solver.cpp:106] Iteration 26600, lr = 0.0001
I0422 05:03:19.128782  6613 solver.cpp:228] Iteration 26700, loss = 0.152449
I0422 05:03:19.128924  6613 solver.cpp:244]     Train net output #0: loss = 0.152449 (* 1 = 0.152449 loss)
I0422 05:03:19.128932  6613 sgd_solver.cpp:106] Iteration 26700, lr = 0.0001
I0422 05:04:54.528704  6613 solver.cpp:228] Iteration 26800, loss = 0.162036
I0422 05:04:54.528854  6613 solver.cpp:244]     Train net output #0: loss = 0.162036 (* 1 = 0.162036 loss)
I0422 05:04:54.528861  6613 sgd_solver.cpp:106] Iteration 26800, lr = 0.0001
I0422 05:06:32.762064  6613 solver.cpp:228] Iteration 26900, loss = 0.131848
I0422 05:06:32.762212  6613 solver.cpp:244]     Train net output #0: loss = 0.131848 (* 1 = 0.131848 loss)
I0422 05:06:32.762218  6613 sgd_solver.cpp:106] Iteration 26900, lr = 0.0001
I0422 05:08:09.771136  6613 solver.cpp:337] Iteration 27000, Testing net (#0)
I0422 05:08:09.771297  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 05:08:09.771301  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 05:08:09.771306  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 05:08:09.771323  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 05:08:09.771327  6613 net.cpp:693] Ignoring source layer visualize
I0422 05:08:09.771328  6613 net.cpp:693] Ignoring source layer fake
I0422 05:11:30.638957  6613 solver.cpp:404]     Test net output #0: loss = 0.15098 (* 1 = 0.15098 loss)
I0422 05:11:31.265887  6613 solver.cpp:228] Iteration 27000, loss = 0.126098
I0422 05:11:31.265929  6613 solver.cpp:244]     Train net output #0: loss = 0.126098 (* 1 = 0.126098 loss)
I0422 05:11:31.265935  6613 sgd_solver.cpp:106] Iteration 27000, lr = 0.0001
I0422 05:13:06.717348  6613 solver.cpp:228] Iteration 27100, loss = 0.0985113
I0422 05:13:06.717499  6613 solver.cpp:244]     Train net output #0: loss = 0.0985113 (* 1 = 0.0985113 loss)
I0422 05:13:06.717507  6613 sgd_solver.cpp:106] Iteration 27100, lr = 0.0001
I0422 05:14:45.319394  6613 solver.cpp:228] Iteration 27200, loss = 0.102825
I0422 05:14:45.319538  6613 solver.cpp:244]     Train net output #0: loss = 0.102825 (* 1 = 0.102825 loss)
I0422 05:14:45.319545  6613 sgd_solver.cpp:106] Iteration 27200, lr = 0.0001
I0422 05:16:23.173995  6613 solver.cpp:228] Iteration 27300, loss = 0.132852
I0422 05:16:23.174141  6613 solver.cpp:244]     Train net output #0: loss = 0.132852 (* 1 = 0.132852 loss)
I0422 05:16:23.174149  6613 sgd_solver.cpp:106] Iteration 27300, lr = 0.0001
I0422 05:18:00.493355  6613 solver.cpp:228] Iteration 27400, loss = 0.117647
I0422 05:18:00.493521  6613 solver.cpp:244]     Train net output #0: loss = 0.117647 (* 1 = 0.117647 loss)
I0422 05:18:00.493528  6613 sgd_solver.cpp:106] Iteration 27400, lr = 0.0001
I0422 05:19:37.531828  6613 solver.cpp:228] Iteration 27500, loss = 0.123016
I0422 05:19:37.532001  6613 solver.cpp:244]     Train net output #0: loss = 0.123016 (* 1 = 0.123016 loss)
I0422 05:19:37.532008  6613 sgd_solver.cpp:106] Iteration 27500, lr = 0.0001
I0422 05:21:15.408174  6613 solver.cpp:228] Iteration 27600, loss = 0.121857
I0422 05:21:15.408331  6613 solver.cpp:244]     Train net output #0: loss = 0.121857 (* 1 = 0.121857 loss)
I0422 05:21:15.408339  6613 sgd_solver.cpp:106] Iteration 27600, lr = 0.0001
I0422 05:22:53.115872  6613 solver.cpp:228] Iteration 27700, loss = 0.0725235
I0422 05:22:53.116024  6613 solver.cpp:244]     Train net output #0: loss = 0.0725235 (* 1 = 0.0725235 loss)
I0422 05:22:53.116031  6613 sgd_solver.cpp:106] Iteration 27700, lr = 0.0001
I0422 05:24:28.467371  6613 solver.cpp:228] Iteration 27800, loss = 0.133704
I0422 05:24:28.467500  6613 solver.cpp:244]     Train net output #0: loss = 0.133704 (* 1 = 0.133704 loss)
I0422 05:24:28.467507  6613 sgd_solver.cpp:106] Iteration 27800, lr = 0.0001
I0422 05:26:06.156219  6613 solver.cpp:228] Iteration 27900, loss = 0.138447
I0422 05:26:06.156363  6613 solver.cpp:244]     Train net output #0: loss = 0.138447 (* 1 = 0.138447 loss)
I0422 05:26:06.156371  6613 sgd_solver.cpp:106] Iteration 27900, lr = 0.0001
I0422 05:27:45.045742  6613 solver.cpp:337] Iteration 28000, Testing net (#0)
I0422 05:27:45.045863  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 05:27:45.045867  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 05:27:45.045877  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 05:27:45.045894  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 05:27:45.045897  6613 net.cpp:693] Ignoring source layer visualize
I0422 05:27:45.045898  6613 net.cpp:693] Ignoring source layer fake
I0422 05:31:05.355057  6613 solver.cpp:404]     Test net output #0: loss = 0.170719 (* 1 = 0.170719 loss)
I0422 05:31:05.984191  6613 solver.cpp:228] Iteration 28000, loss = 0.119548
I0422 05:31:05.984210  6613 solver.cpp:244]     Train net output #0: loss = 0.119548 (* 1 = 0.119548 loss)
I0422 05:31:05.984215  6613 sgd_solver.cpp:106] Iteration 28000, lr = 0.0001
I0422 05:32:44.366475  6613 solver.cpp:228] Iteration 28100, loss = 0.136107
I0422 05:32:44.366631  6613 solver.cpp:244]     Train net output #0: loss = 0.136107 (* 1 = 0.136107 loss)
I0422 05:32:44.366638  6613 sgd_solver.cpp:106] Iteration 28100, lr = 0.0001
I0422 05:34:19.761855  6613 solver.cpp:228] Iteration 28200, loss = 0.126186
I0422 05:34:19.762694  6613 solver.cpp:244]     Train net output #0: loss = 0.126186 (* 1 = 0.126186 loss)
I0422 05:34:19.762702  6613 sgd_solver.cpp:106] Iteration 28200, lr = 0.0001
I0422 05:36:01.053498  6613 solver.cpp:228] Iteration 28300, loss = 0.120339
I0422 05:36:01.054683  6613 solver.cpp:244]     Train net output #0: loss = 0.120339 (* 1 = 0.120339 loss)
I0422 05:36:01.054692  6613 sgd_solver.cpp:106] Iteration 28300, lr = 0.0001
I0422 05:37:39.463119  6613 solver.cpp:228] Iteration 28400, loss = 0.0924599
I0422 05:37:39.463261  6613 solver.cpp:244]     Train net output #0: loss = 0.0924599 (* 1 = 0.0924599 loss)
I0422 05:37:39.463279  6613 sgd_solver.cpp:106] Iteration 28400, lr = 0.0001
I0422 05:39:16.610299  6613 solver.cpp:228] Iteration 28500, loss = 0.136968
I0422 05:39:16.610431  6613 solver.cpp:244]     Train net output #0: loss = 0.136968 (* 1 = 0.136968 loss)
I0422 05:39:16.610440  6613 sgd_solver.cpp:106] Iteration 28500, lr = 0.0001
I0422 05:40:51.931429  6613 solver.cpp:228] Iteration 28600, loss = 0.0987637
I0422 05:40:51.931557  6613 solver.cpp:244]     Train net output #0: loss = 0.0987637 (* 1 = 0.0987637 loss)
I0422 05:40:51.931565  6613 sgd_solver.cpp:106] Iteration 28600, lr = 0.0001
I0422 05:42:28.969940  6613 solver.cpp:228] Iteration 28700, loss = 0.141191
I0422 05:42:28.970089  6613 solver.cpp:244]     Train net output #0: loss = 0.141191 (* 1 = 0.141191 loss)
I0422 05:42:28.970096  6613 sgd_solver.cpp:106] Iteration 28700, lr = 0.0001
I0422 05:44:05.696300  6613 solver.cpp:228] Iteration 28800, loss = 0.137321
I0422 05:44:05.696446  6613 solver.cpp:244]     Train net output #0: loss = 0.137321 (* 1 = 0.137321 loss)
I0422 05:44:05.696455  6613 sgd_solver.cpp:106] Iteration 28800, lr = 0.0001
I0422 05:45:42.427579  6613 solver.cpp:228] Iteration 28900, loss = 0.188397
I0422 05:45:42.427717  6613 solver.cpp:244]     Train net output #0: loss = 0.188397 (* 1 = 0.188397 loss)
I0422 05:45:42.427724  6613 sgd_solver.cpp:106] Iteration 28900, lr = 0.0001
I0422 05:47:18.380969  6613 solver.cpp:337] Iteration 29000, Testing net (#0)
I0422 05:47:18.381101  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 05:47:18.381105  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 05:47:18.381110  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 05:47:18.381127  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 05:47:18.381130  6613 net.cpp:693] Ignoring source layer visualize
I0422 05:47:18.381132  6613 net.cpp:693] Ignoring source layer fake
I0422 05:50:38.530465  6613 solver.cpp:404]     Test net output #0: loss = 0.136825 (* 1 = 0.136825 loss)
I0422 05:50:39.162626  6613 solver.cpp:228] Iteration 29000, loss = 0.142131
I0422 05:50:39.162644  6613 solver.cpp:244]     Train net output #0: loss = 0.142131 (* 1 = 0.142131 loss)
I0422 05:50:39.162665  6613 sgd_solver.cpp:106] Iteration 29000, lr = 0.0001
I0422 05:52:17.275099  6613 solver.cpp:228] Iteration 29100, loss = 0.154442
I0422 05:52:17.275254  6613 solver.cpp:244]     Train net output #0: loss = 0.154442 (* 1 = 0.154442 loss)
I0422 05:52:17.275262  6613 sgd_solver.cpp:106] Iteration 29100, lr = 0.0001
I0422 05:53:54.734539  6613 solver.cpp:228] Iteration 29200, loss = 0.232494
I0422 05:53:54.734683  6613 solver.cpp:244]     Train net output #0: loss = 0.232494 (* 1 = 0.232494 loss)
I0422 05:53:54.734690  6613 sgd_solver.cpp:106] Iteration 29200, lr = 0.0001
I0422 05:55:30.122786  6613 solver.cpp:228] Iteration 29300, loss = 0.167845
I0422 05:55:30.122927  6613 solver.cpp:244]     Train net output #0: loss = 0.167845 (* 1 = 0.167845 loss)
I0422 05:55:30.122936  6613 sgd_solver.cpp:106] Iteration 29300, lr = 0.0001
I0422 05:57:07.496531  6613 solver.cpp:228] Iteration 29400, loss = 0.13635
I0422 05:57:07.496685  6613 solver.cpp:244]     Train net output #0: loss = 0.13635 (* 1 = 0.13635 loss)
I0422 05:57:07.496692  6613 sgd_solver.cpp:106] Iteration 29400, lr = 0.0001
I0422 05:58:44.794519  6613 solver.cpp:228] Iteration 29500, loss = 0.132226
I0422 05:58:44.794663  6613 solver.cpp:244]     Train net output #0: loss = 0.132226 (* 1 = 0.132226 loss)
I0422 05:58:44.794672  6613 sgd_solver.cpp:106] Iteration 29500, lr = 0.0001
I0422 06:00:20.156358  6613 solver.cpp:228] Iteration 29600, loss = 0.105621
I0422 06:00:20.156502  6613 solver.cpp:244]     Train net output #0: loss = 0.105621 (* 1 = 0.105621 loss)
I0422 06:00:20.156509  6613 sgd_solver.cpp:106] Iteration 29600, lr = 0.0001
I0422 06:01:57.531080  6613 solver.cpp:228] Iteration 29700, loss = 0.103543
I0422 06:01:57.531221  6613 solver.cpp:244]     Train net output #0: loss = 0.103543 (* 1 = 0.103543 loss)
I0422 06:01:57.531229  6613 sgd_solver.cpp:106] Iteration 29700, lr = 0.0001
I0422 06:03:35.147490  6613 solver.cpp:228] Iteration 29800, loss = 0.119758
I0422 06:03:35.147630  6613 solver.cpp:244]     Train net output #0: loss = 0.119758 (* 1 = 0.119758 loss)
I0422 06:03:35.147637  6613 sgd_solver.cpp:106] Iteration 29800, lr = 0.0001
I0422 06:05:12.638617  6613 solver.cpp:228] Iteration 29900, loss = 0.11354
I0422 06:05:12.638766  6613 solver.cpp:244]     Train net output #0: loss = 0.11354 (* 1 = 0.11354 loss)
I0422 06:05:12.638774  6613 sgd_solver.cpp:106] Iteration 29900, lr = 0.0001
I0422 06:06:48.626793  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_30000.caffemodel
I0422 06:06:56.708726  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_30000.solverstate
I0422 06:06:56.904520  6613 solver.cpp:337] Iteration 30000, Testing net (#0)
I0422 06:06:56.904546  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 06:06:56.904549  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 06:06:56.904553  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 06:06:56.904570  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 06:06:56.904588  6613 net.cpp:693] Ignoring source layer visualize
I0422 06:06:56.904590  6613 net.cpp:693] Ignoring source layer fake
I0422 06:10:17.405514  6613 solver.cpp:404]     Test net output #0: loss = 0.128184 (* 1 = 0.128184 loss)
I0422 06:10:18.030810  6613 solver.cpp:228] Iteration 30000, loss = 0.0909356
I0422 06:10:18.030850  6613 solver.cpp:244]     Train net output #0: loss = 0.0909356 (* 1 = 0.0909356 loss)
I0422 06:10:18.030855  6613 sgd_solver.cpp:106] Iteration 30000, lr = 0.0001
I0422 06:11:55.139422  6613 solver.cpp:228] Iteration 30100, loss = 0.139902
I0422 06:11:55.139577  6613 solver.cpp:244]     Train net output #0: loss = 0.139902 (* 1 = 0.139902 loss)
I0422 06:11:55.139585  6613 sgd_solver.cpp:106] Iteration 30100, lr = 0.0001
I0422 06:13:32.888799  6613 solver.cpp:228] Iteration 30200, loss = 0.107519
I0422 06:13:32.888948  6613 solver.cpp:244]     Train net output #0: loss = 0.107519 (* 1 = 0.107519 loss)
I0422 06:13:32.888955  6613 sgd_solver.cpp:106] Iteration 30200, lr = 0.0001
I0422 06:15:08.250955  6613 solver.cpp:228] Iteration 30300, loss = 0.110712
I0422 06:15:08.251096  6613 solver.cpp:244]     Train net output #0: loss = 0.110712 (* 1 = 0.110712 loss)
I0422 06:15:08.251104  6613 sgd_solver.cpp:106] Iteration 30300, lr = 0.0001
I0422 06:16:45.902307  6613 solver.cpp:228] Iteration 30400, loss = 0.151734
I0422 06:16:45.902456  6613 solver.cpp:244]     Train net output #0: loss = 0.151734 (* 1 = 0.151734 loss)
I0422 06:16:45.902464  6613 sgd_solver.cpp:106] Iteration 30400, lr = 0.0001
I0422 06:18:23.907130  6613 solver.cpp:228] Iteration 30500, loss = 0.164418
I0422 06:18:23.907275  6613 solver.cpp:244]     Train net output #0: loss = 0.164418 (* 1 = 0.164418 loss)
I0422 06:18:23.907282  6613 sgd_solver.cpp:106] Iteration 30500, lr = 0.0001
I0422 06:20:01.185534  6613 solver.cpp:228] Iteration 30600, loss = 0.191129
I0422 06:20:01.185693  6613 solver.cpp:244]     Train net output #0: loss = 0.191129 (* 1 = 0.191129 loss)
I0422 06:20:01.185699  6613 sgd_solver.cpp:106] Iteration 30600, lr = 0.0001
I0422 06:21:36.582473  6613 solver.cpp:228] Iteration 30700, loss = 0.149472
I0422 06:21:36.582641  6613 solver.cpp:244]     Train net output #0: loss = 0.149472 (* 1 = 0.149472 loss)
I0422 06:21:36.582649  6613 sgd_solver.cpp:106] Iteration 30700, lr = 0.0001
I0422 06:23:13.985033  6613 solver.cpp:228] Iteration 30800, loss = 0.170468
I0422 06:23:13.985173  6613 solver.cpp:244]     Train net output #0: loss = 0.170468 (* 1 = 0.170468 loss)
I0422 06:23:13.985182  6613 sgd_solver.cpp:106] Iteration 30800, lr = 0.0001
I0422 06:24:51.465719  6613 solver.cpp:228] Iteration 30900, loss = 0.0845119
I0422 06:24:51.465865  6613 solver.cpp:244]     Train net output #0: loss = 0.0845119 (* 1 = 0.0845119 loss)
I0422 06:24:51.465873  6613 sgd_solver.cpp:106] Iteration 30900, lr = 0.0001
I0422 06:26:27.999888  6613 solver.cpp:337] Iteration 31000, Testing net (#0)
I0422 06:26:28.000043  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 06:26:28.000048  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 06:26:28.000053  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 06:26:28.000072  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 06:26:28.000074  6613 net.cpp:693] Ignoring source layer visualize
I0422 06:26:28.000077  6613 net.cpp:693] Ignoring source layer fake
I0422 06:29:48.812038  6613 solver.cpp:404]     Test net output #0: loss = 0.127495 (* 1 = 0.127495 loss)
I0422 06:29:49.442046  6613 solver.cpp:228] Iteration 31000, loss = 0.0855032
I0422 06:29:49.442082  6613 solver.cpp:244]     Train net output #0: loss = 0.0855032 (* 1 = 0.0855032 loss)
I0422 06:29:49.442088  6613 sgd_solver.cpp:106] Iteration 31000, lr = 0.0001
I0422 06:31:24.806287  6613 solver.cpp:228] Iteration 31100, loss = 0.0735258
I0422 06:31:24.806457  6613 solver.cpp:244]     Train net output #0: loss = 0.0735258 (* 1 = 0.0735258 loss)
I0422 06:31:24.806465  6613 sgd_solver.cpp:106] Iteration 31100, lr = 0.0001
I0422 06:33:02.319830  6613 solver.cpp:228] Iteration 31200, loss = 0.123975
I0422 06:33:02.319978  6613 solver.cpp:244]     Train net output #0: loss = 0.123975 (* 1 = 0.123975 loss)
I0422 06:33:02.319985  6613 sgd_solver.cpp:106] Iteration 31200, lr = 0.0001
I0422 06:34:38.984482  6613 solver.cpp:228] Iteration 31300, loss = 0.129773
I0422 06:34:38.984623  6613 solver.cpp:244]     Train net output #0: loss = 0.129773 (* 1 = 0.129773 loss)
I0422 06:34:38.984632  6613 sgd_solver.cpp:106] Iteration 31300, lr = 0.0001
I0422 06:36:18.098461  6613 solver.cpp:228] Iteration 31400, loss = 0.175791
I0422 06:36:18.098603  6613 solver.cpp:244]     Train net output #0: loss = 0.175791 (* 1 = 0.175791 loss)
I0422 06:36:18.098608  6613 sgd_solver.cpp:106] Iteration 31400, lr = 0.0001
I0422 06:37:55.838369  6613 solver.cpp:228] Iteration 31500, loss = 0.0531196
I0422 06:37:55.838517  6613 solver.cpp:244]     Train net output #0: loss = 0.0531196 (* 1 = 0.0531196 loss)
I0422 06:37:55.838524  6613 sgd_solver.cpp:106] Iteration 31500, lr = 0.0001
I0422 06:39:32.976945  6613 solver.cpp:228] Iteration 31600, loss = 0.160593
I0422 06:39:32.977095  6613 solver.cpp:244]     Train net output #0: loss = 0.160593 (* 1 = 0.160593 loss)
I0422 06:39:32.977103  6613 sgd_solver.cpp:106] Iteration 31600, lr = 0.0001
I0422 06:41:10.204680  6613 solver.cpp:228] Iteration 31700, loss = 0.153522
I0422 06:41:10.204819  6613 solver.cpp:244]     Train net output #0: loss = 0.153522 (* 1 = 0.153522 loss)
I0422 06:41:10.204826  6613 sgd_solver.cpp:106] Iteration 31700, lr = 0.0001
I0422 06:42:45.608877  6613 solver.cpp:228] Iteration 31800, loss = 0.125891
I0422 06:42:45.609005  6613 solver.cpp:244]     Train net output #0: loss = 0.125891 (* 1 = 0.125891 loss)
I0422 06:42:45.609011  6613 sgd_solver.cpp:106] Iteration 31800, lr = 0.0001
I0422 06:44:22.866230  6613 solver.cpp:228] Iteration 31900, loss = 0.170572
I0422 06:44:22.866374  6613 solver.cpp:244]     Train net output #0: loss = 0.170572 (* 1 = 0.170572 loss)
I0422 06:44:22.866380  6613 sgd_solver.cpp:106] Iteration 31900, lr = 0.0001
I0422 06:45:59.133582  6613 solver.cpp:337] Iteration 32000, Testing net (#0)
I0422 06:45:59.133715  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 06:45:59.133719  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 06:45:59.133724  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 06:45:59.133740  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 06:45:59.133744  6613 net.cpp:693] Ignoring source layer visualize
I0422 06:45:59.133745  6613 net.cpp:693] Ignoring source layer fake
I0422 06:49:19.520565  6613 solver.cpp:404]     Test net output #0: loss = 0.147643 (* 1 = 0.147643 loss)
I0422 06:49:20.148895  6613 solver.cpp:228] Iteration 32000, loss = 0.189059
I0422 06:49:20.148917  6613 solver.cpp:244]     Train net output #0: loss = 0.189059 (* 1 = 0.189059 loss)
I0422 06:49:20.148939  6613 sgd_solver.cpp:106] Iteration 32000, lr = 0.0001
I0422 06:50:55.589371  6613 solver.cpp:228] Iteration 32100, loss = 0.14737
I0422 06:50:55.589530  6613 solver.cpp:244]     Train net output #0: loss = 0.14737 (* 1 = 0.14737 loss)
I0422 06:50:55.589539  6613 sgd_solver.cpp:106] Iteration 32100, lr = 0.0001
I0422 06:52:32.707480  6613 solver.cpp:228] Iteration 32200, loss = 0.0691474
I0422 06:52:32.707633  6613 solver.cpp:244]     Train net output #0: loss = 0.0691474 (* 1 = 0.0691474 loss)
I0422 06:52:32.707640  6613 sgd_solver.cpp:106] Iteration 32200, lr = 0.0001
I0422 06:54:09.896793  6613 solver.cpp:228] Iteration 32300, loss = 0.161243
I0422 06:54:09.896981  6613 solver.cpp:244]     Train net output #0: loss = 0.161243 (* 1 = 0.161243 loss)
I0422 06:54:09.896988  6613 sgd_solver.cpp:106] Iteration 32300, lr = 0.0001
I0422 06:55:46.914042  6613 solver.cpp:228] Iteration 32400, loss = 0.148731
I0422 06:55:46.914230  6613 solver.cpp:244]     Train net output #0: loss = 0.148731 (* 1 = 0.148731 loss)
I0422 06:55:46.914237  6613 sgd_solver.cpp:106] Iteration 32400, lr = 0.0001
I0422 06:57:23.506662  6613 solver.cpp:228] Iteration 32500, loss = 0.12887
I0422 06:57:23.506808  6613 solver.cpp:244]     Train net output #0: loss = 0.12887 (* 1 = 0.12887 loss)
I0422 06:57:23.506816  6613 sgd_solver.cpp:106] Iteration 32500, lr = 0.0001
I0422 06:59:00.179057  6613 solver.cpp:228] Iteration 32600, loss = 0.128006
I0422 06:59:00.180060  6613 solver.cpp:244]     Train net output #0: loss = 0.128006 (* 1 = 0.128006 loss)
I0422 06:59:00.180066  6613 sgd_solver.cpp:106] Iteration 32600, lr = 0.0001
I0422 07:00:37.114553  6613 solver.cpp:228] Iteration 32700, loss = 0.0988033
I0422 07:00:37.114693  6613 solver.cpp:244]     Train net output #0: loss = 0.0988033 (* 1 = 0.0988033 loss)
I0422 07:00:37.114701  6613 sgd_solver.cpp:106] Iteration 32700, lr = 0.0001
I0422 07:02:12.486289  6613 solver.cpp:228] Iteration 32800, loss = 0.131588
I0422 07:02:12.486423  6613 solver.cpp:244]     Train net output #0: loss = 0.131588 (* 1 = 0.131588 loss)
I0422 07:02:12.486430  6613 sgd_solver.cpp:106] Iteration 32800, lr = 0.0001
I0422 07:03:49.576453  6613 solver.cpp:228] Iteration 32900, loss = 0.081337
I0422 07:03:49.576601  6613 solver.cpp:244]     Train net output #0: loss = 0.081337 (* 1 = 0.081337 loss)
I0422 07:03:49.576608  6613 sgd_solver.cpp:106] Iteration 32900, lr = 0.0001
I0422 07:05:25.852807  6613 solver.cpp:337] Iteration 33000, Testing net (#0)
I0422 07:05:25.852941  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 07:05:25.852944  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 07:05:25.852949  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 07:05:25.852967  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 07:05:25.852968  6613 net.cpp:693] Ignoring source layer visualize
I0422 07:05:25.852970  6613 net.cpp:693] Ignoring source layer fake
I0422 07:08:46.081903  6613 solver.cpp:404]     Test net output #0: loss = 0.177854 (* 1 = 0.177854 loss)
I0422 07:08:46.711746  6613 solver.cpp:228] Iteration 33000, loss = 0.141864
I0422 07:08:46.711786  6613 solver.cpp:244]     Train net output #0: loss = 0.141864 (* 1 = 0.141864 loss)
I0422 07:08:46.711792  6613 sgd_solver.cpp:106] Iteration 33000, lr = 0.0001
I0422 07:10:24.025773  6613 solver.cpp:228] Iteration 33100, loss = 0.13623
I0422 07:10:24.025918  6613 solver.cpp:244]     Train net output #0: loss = 0.13623 (* 1 = 0.13623 loss)
I0422 07:10:24.025925  6613 sgd_solver.cpp:106] Iteration 33100, lr = 0.0001
I0422 07:11:59.378693  6613 solver.cpp:228] Iteration 33200, loss = 0.114694
I0422 07:11:59.378859  6613 solver.cpp:244]     Train net output #0: loss = 0.114694 (* 1 = 0.114694 loss)
I0422 07:11:59.378867  6613 sgd_solver.cpp:106] Iteration 33200, lr = 0.0001
I0422 07:13:36.543956  6613 solver.cpp:228] Iteration 33300, loss = 0.19613
I0422 07:13:36.544100  6613 solver.cpp:244]     Train net output #0: loss = 0.19613 (* 1 = 0.19613 loss)
I0422 07:13:36.544108  6613 sgd_solver.cpp:106] Iteration 33300, lr = 0.0001
I0422 07:15:13.685695  6613 solver.cpp:228] Iteration 33400, loss = 0.0834869
I0422 07:15:13.685844  6613 solver.cpp:244]     Train net output #0: loss = 0.0834869 (* 1 = 0.0834869 loss)
I0422 07:15:13.685850  6613 sgd_solver.cpp:106] Iteration 33400, lr = 0.0001
I0422 07:16:50.764425  6613 solver.cpp:228] Iteration 33500, loss = 0.0710725
I0422 07:16:50.764585  6613 solver.cpp:244]     Train net output #0: loss = 0.0710725 (* 1 = 0.0710725 loss)
I0422 07:16:50.764591  6613 sgd_solver.cpp:106] Iteration 33500, lr = 0.0001
I0422 07:18:26.071274  6613 solver.cpp:228] Iteration 33600, loss = 0.115981
I0422 07:18:26.071413  6613 solver.cpp:244]     Train net output #0: loss = 0.115981 (* 1 = 0.115981 loss)
I0422 07:18:26.071419  6613 sgd_solver.cpp:106] Iteration 33600, lr = 0.0001
I0422 07:20:03.049052  6613 solver.cpp:228] Iteration 33700, loss = 0.0630341
I0422 07:20:03.049229  6613 solver.cpp:244]     Train net output #0: loss = 0.0630341 (* 1 = 0.0630341 loss)
I0422 07:20:03.049237  6613 sgd_solver.cpp:106] Iteration 33700, lr = 0.0001
I0422 07:21:39.652750  6613 solver.cpp:228] Iteration 33800, loss = 0.111464
I0422 07:21:39.652904  6613 solver.cpp:244]     Train net output #0: loss = 0.111464 (* 1 = 0.111464 loss)
I0422 07:21:39.652909  6613 sgd_solver.cpp:106] Iteration 33800, lr = 0.0001
I0422 07:23:16.347841  6613 solver.cpp:228] Iteration 33900, loss = 0.137715
I0422 07:23:16.347986  6613 solver.cpp:244]     Train net output #0: loss = 0.137715 (* 1 = 0.137715 loss)
I0422 07:23:16.347992  6613 sgd_solver.cpp:106] Iteration 33900, lr = 0.0001
I0422 07:24:52.438083  6613 solver.cpp:337] Iteration 34000, Testing net (#0)
I0422 07:24:52.438220  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 07:24:52.438225  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 07:24:52.438228  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 07:24:52.438246  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 07:24:52.438251  6613 net.cpp:693] Ignoring source layer visualize
I0422 07:24:52.438252  6613 net.cpp:693] Ignoring source layer fake
I0422 07:28:12.478031  6613 solver.cpp:404]     Test net output #0: loss = 0.13229 (* 1 = 0.13229 loss)
I0422 07:28:13.105386  6613 solver.cpp:228] Iteration 34000, loss = 0.13457
I0422 07:28:13.105427  6613 solver.cpp:244]     Train net output #0: loss = 0.13457 (* 1 = 0.13457 loss)
I0422 07:28:13.105433  6613 sgd_solver.cpp:106] Iteration 34000, lr = 0.0001
I0422 07:29:51.093770  6613 solver.cpp:228] Iteration 34100, loss = 0.139943
I0422 07:29:51.093924  6613 solver.cpp:244]     Train net output #0: loss = 0.139943 (* 1 = 0.139943 loss)
I0422 07:29:51.093932  6613 sgd_solver.cpp:106] Iteration 34100, lr = 0.0001
I0422 07:31:28.648088  6613 solver.cpp:228] Iteration 34200, loss = 0.129519
I0422 07:31:28.648241  6613 solver.cpp:244]     Train net output #0: loss = 0.129519 (* 1 = 0.129519 loss)
I0422 07:31:28.648248  6613 sgd_solver.cpp:106] Iteration 34200, lr = 0.0001
I0422 07:33:04.019981  6613 solver.cpp:228] Iteration 34300, loss = 0.138803
I0422 07:33:04.020153  6613 solver.cpp:244]     Train net output #0: loss = 0.138803 (* 1 = 0.138803 loss)
I0422 07:33:04.020161  6613 sgd_solver.cpp:106] Iteration 34300, lr = 0.0001
I0422 07:34:42.074628  6613 solver.cpp:228] Iteration 34400, loss = 0.170483
I0422 07:34:42.074764  6613 solver.cpp:244]     Train net output #0: loss = 0.170483 (* 1 = 0.170483 loss)
I0422 07:34:42.074770  6613 sgd_solver.cpp:106] Iteration 34400, lr = 0.0001
I0422 07:36:19.411798  6613 solver.cpp:228] Iteration 34500, loss = 0.249317
I0422 07:36:19.411942  6613 solver.cpp:244]     Train net output #0: loss = 0.249317 (* 1 = 0.249317 loss)
I0422 07:36:19.411950  6613 sgd_solver.cpp:106] Iteration 34500, lr = 0.0001
I0422 07:37:54.769163  6613 solver.cpp:228] Iteration 34600, loss = 0.0926418
I0422 07:37:54.769309  6613 solver.cpp:244]     Train net output #0: loss = 0.0926418 (* 1 = 0.0926418 loss)
I0422 07:37:54.769316  6613 sgd_solver.cpp:106] Iteration 34600, lr = 0.0001
I0422 07:39:32.152079  6613 solver.cpp:228] Iteration 34700, loss = 0.0868673
I0422 07:39:32.152214  6613 solver.cpp:244]     Train net output #0: loss = 0.0868673 (* 1 = 0.0868673 loss)
I0422 07:39:32.152220  6613 sgd_solver.cpp:106] Iteration 34700, lr = 0.0001
I0422 07:41:09.403416  6613 solver.cpp:228] Iteration 34800, loss = 0.172581
I0422 07:41:09.403564  6613 solver.cpp:244]     Train net output #0: loss = 0.172581 (* 1 = 0.172581 loss)
I0422 07:41:09.403571  6613 sgd_solver.cpp:106] Iteration 34800, lr = 0.0001
I0422 07:42:46.474396  6613 solver.cpp:228] Iteration 34900, loss = 0.125596
I0422 07:42:46.474544  6613 solver.cpp:244]     Train net output #0: loss = 0.125596 (* 1 = 0.125596 loss)
I0422 07:42:46.474550  6613 sgd_solver.cpp:106] Iteration 34900, lr = 0.0001
I0422 07:44:22.153164  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_35000.caffemodel
I0422 07:44:29.729403  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_35000.solverstate
I0422 07:44:29.930431  6613 solver.cpp:337] Iteration 35000, Testing net (#0)
I0422 07:44:29.930474  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 07:44:29.930476  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 07:44:29.930480  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 07:44:29.930495  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 07:44:29.930497  6613 net.cpp:693] Ignoring source layer visualize
I0422 07:44:29.930500  6613 net.cpp:693] Ignoring source layer fake
I0422 07:47:50.726490  6613 solver.cpp:404]     Test net output #0: loss = 0.124139 (* 1 = 0.124139 loss)
I0422 07:47:51.357856  6613 solver.cpp:228] Iteration 35000, loss = 0.149546
I0422 07:47:51.357882  6613 solver.cpp:244]     Train net output #0: loss = 0.149546 (* 1 = 0.149546 loss)
I0422 07:47:51.357895  6613 sgd_solver.cpp:106] Iteration 35000, lr = 0.0001
I0422 07:49:28.187907  6613 solver.cpp:228] Iteration 35100, loss = 0.127056
I0422 07:49:28.188057  6613 solver.cpp:244]     Train net output #0: loss = 0.127056 (* 1 = 0.127056 loss)
I0422 07:49:28.188066  6613 sgd_solver.cpp:106] Iteration 35100, lr = 0.0001
I0422 07:51:05.403399  6613 solver.cpp:228] Iteration 35200, loss = 0.0977
I0422 07:51:05.403553  6613 solver.cpp:244]     Train net output #0: loss = 0.0977 (* 1 = 0.0977 loss)
I0422 07:51:05.403560  6613 sgd_solver.cpp:106] Iteration 35200, lr = 0.0001
I0422 07:52:40.768069  6613 solver.cpp:228] Iteration 35300, loss = 0.108026
I0422 07:52:40.768977  6613 solver.cpp:244]     Train net output #0: loss = 0.108026 (* 1 = 0.108026 loss)
I0422 07:52:40.768985  6613 sgd_solver.cpp:106] Iteration 35300, lr = 0.0001
I0422 07:54:18.186748  6613 solver.cpp:228] Iteration 35400, loss = 0.0928017
I0422 07:54:18.186897  6613 solver.cpp:244]     Train net output #0: loss = 0.0928017 (* 1 = 0.0928017 loss)
I0422 07:54:18.186904  6613 sgd_solver.cpp:106] Iteration 35400, lr = 0.0001
I0422 07:55:55.500937  6613 solver.cpp:228] Iteration 35500, loss = 0.0955384
I0422 07:55:55.501075  6613 solver.cpp:244]     Train net output #0: loss = 0.0955384 (* 1 = 0.0955384 loss)
I0422 07:55:55.501082  6613 sgd_solver.cpp:106] Iteration 35500, lr = 0.0001
I0422 07:57:32.728415  6613 solver.cpp:228] Iteration 35600, loss = 0.0891816
I0422 07:57:32.729329  6613 solver.cpp:244]     Train net output #0: loss = 0.0891816 (* 1 = 0.0891816 loss)
I0422 07:57:32.729336  6613 sgd_solver.cpp:106] Iteration 35600, lr = 0.0001
I0422 07:59:08.082957  6613 solver.cpp:228] Iteration 35700, loss = 0.117304
I0422 07:59:08.083093  6613 solver.cpp:244]     Train net output #0: loss = 0.117304 (* 1 = 0.117304 loss)
I0422 07:59:08.083099  6613 sgd_solver.cpp:106] Iteration 35700, lr = 0.0001
I0422 08:00:45.335852  6613 solver.cpp:228] Iteration 35800, loss = 0.177022
I0422 08:00:45.335994  6613 solver.cpp:244]     Train net output #0: loss = 0.177022 (* 1 = 0.177022 loss)
I0422 08:00:45.336001  6613 sgd_solver.cpp:106] Iteration 35800, lr = 0.0001
I0422 08:02:22.506916  6613 solver.cpp:228] Iteration 35900, loss = 0.095584
I0422 08:02:22.507866  6613 solver.cpp:244]     Train net output #0: loss = 0.095584 (* 1 = 0.095584 loss)
I0422 08:02:22.507874  6613 sgd_solver.cpp:106] Iteration 35900, lr = 0.0001
I0422 08:03:58.695267  6613 solver.cpp:337] Iteration 36000, Testing net (#0)
I0422 08:03:58.695416  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 08:03:58.695420  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 08:03:58.695425  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 08:03:58.695439  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 08:03:58.695442  6613 net.cpp:693] Ignoring source layer visualize
I0422 08:03:58.695444  6613 net.cpp:693] Ignoring source layer fake
I0422 08:07:19.193533  6613 solver.cpp:404]     Test net output #0: loss = 0.126318 (* 1 = 0.126318 loss)
I0422 08:07:19.818783  6613 solver.cpp:228] Iteration 36000, loss = 0.107233
I0422 08:07:19.818822  6613 solver.cpp:244]     Train net output #0: loss = 0.107233 (* 1 = 0.107233 loss)
I0422 08:07:19.818827  6613 sgd_solver.cpp:106] Iteration 36000, lr = 0.0001
I0422 08:08:55.174304  6613 solver.cpp:228] Iteration 36100, loss = 0.114333
I0422 08:08:55.174443  6613 solver.cpp:244]     Train net output #0: loss = 0.114333 (* 1 = 0.114333 loss)
I0422 08:08:55.174449  6613 sgd_solver.cpp:106] Iteration 36100, lr = 0.0001
I0422 08:10:32.151862  6613 solver.cpp:228] Iteration 36200, loss = 0.0702661
I0422 08:10:32.152011  6613 solver.cpp:244]     Train net output #0: loss = 0.0702661 (* 1 = 0.0702661 loss)
I0422 08:10:32.152017  6613 sgd_solver.cpp:106] Iteration 36200, lr = 0.0001
I0422 08:12:08.759222  6613 solver.cpp:228] Iteration 36300, loss = 0.124342
I0422 08:12:08.759377  6613 solver.cpp:244]     Train net output #0: loss = 0.124342 (* 1 = 0.124342 loss)
I0422 08:12:08.759384  6613 sgd_solver.cpp:106] Iteration 36300, lr = 0.0001
I0422 08:13:45.498621  6613 solver.cpp:228] Iteration 36400, loss = 0.0924745
I0422 08:13:45.498769  6613 solver.cpp:244]     Train net output #0: loss = 0.0924745 (* 1 = 0.0924745 loss)
I0422 08:13:45.498775  6613 sgd_solver.cpp:106] Iteration 36400, lr = 0.0001
I0422 08:15:22.426738  6613 solver.cpp:228] Iteration 36500, loss = 0.124504
I0422 08:15:22.426890  6613 solver.cpp:244]     Train net output #0: loss = 0.124504 (* 1 = 0.124504 loss)
I0422 08:15:22.426898  6613 sgd_solver.cpp:106] Iteration 36500, lr = 0.0001
I0422 08:16:59.846410  6613 solver.cpp:228] Iteration 36600, loss = 0.160294
I0422 08:16:59.846559  6613 solver.cpp:244]     Train net output #0: loss = 0.160294 (* 1 = 0.160294 loss)
I0422 08:16:59.846565  6613 sgd_solver.cpp:106] Iteration 36600, lr = 0.0001
I0422 08:18:37.078433  6613 solver.cpp:228] Iteration 36700, loss = 0.160875
I0422 08:18:37.078563  6613 solver.cpp:244]     Train net output #0: loss = 0.160875 (* 1 = 0.160875 loss)
I0422 08:18:37.078572  6613 sgd_solver.cpp:106] Iteration 36700, lr = 0.0001
I0422 08:20:12.470479  6613 solver.cpp:228] Iteration 36800, loss = 0.164964
I0422 08:20:12.470613  6613 solver.cpp:244]     Train net output #0: loss = 0.164964 (* 1 = 0.164964 loss)
I0422 08:20:12.470619  6613 sgd_solver.cpp:106] Iteration 36800, lr = 0.0001
I0422 08:21:49.698427  6613 solver.cpp:228] Iteration 36900, loss = 0.115343
I0422 08:21:49.698563  6613 solver.cpp:244]     Train net output #0: loss = 0.115343 (* 1 = 0.115343 loss)
I0422 08:21:49.698570  6613 sgd_solver.cpp:106] Iteration 36900, lr = 0.0001
I0422 08:23:26.004154  6613 solver.cpp:337] Iteration 37000, Testing net (#0)
I0422 08:23:26.004307  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 08:23:26.004312  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 08:23:26.004315  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 08:23:26.004330  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 08:23:26.004333  6613 net.cpp:693] Ignoring source layer visualize
I0422 08:23:26.004335  6613 net.cpp:693] Ignoring source layer fake
I0422 08:26:46.367682  6613 solver.cpp:404]     Test net output #0: loss = 0.145894 (* 1 = 0.145894 loss)
I0422 08:26:46.994927  6613 solver.cpp:228] Iteration 37000, loss = 0.224847
I0422 08:26:46.994953  6613 solver.cpp:244]     Train net output #0: loss = 0.224847 (* 1 = 0.224847 loss)
I0422 08:26:46.994976  6613 sgd_solver.cpp:106] Iteration 37000, lr = 0.0001
I0422 08:28:22.425182  6613 solver.cpp:228] Iteration 37100, loss = 0.120238
I0422 08:28:22.425317  6613 solver.cpp:244]     Train net output #0: loss = 0.120238 (* 1 = 0.120238 loss)
I0422 08:28:22.425323  6613 sgd_solver.cpp:106] Iteration 37100, lr = 0.0001
I0422 08:29:59.964875  6613 solver.cpp:228] Iteration 37200, loss = 0.106467
I0422 08:29:59.965037  6613 solver.cpp:244]     Train net output #0: loss = 0.106467 (* 1 = 0.106467 loss)
I0422 08:29:59.965046  6613 sgd_solver.cpp:106] Iteration 37200, lr = 0.0001
I0422 08:31:37.849666  6613 solver.cpp:228] Iteration 37300, loss = 0.115561
I0422 08:31:37.849846  6613 solver.cpp:244]     Train net output #0: loss = 0.115561 (* 1 = 0.115561 loss)
I0422 08:31:37.849854  6613 sgd_solver.cpp:106] Iteration 37300, lr = 0.0001
I0422 08:33:15.214174  6613 solver.cpp:228] Iteration 37400, loss = 0.304535
I0422 08:33:15.214352  6613 solver.cpp:244]     Train net output #0: loss = 0.304535 (* 1 = 0.304535 loss)
I0422 08:33:15.214362  6613 sgd_solver.cpp:106] Iteration 37400, lr = 0.0001
I0422 08:34:51.933205  6613 solver.cpp:228] Iteration 37500, loss = 0.125001
I0422 08:34:51.933372  6613 solver.cpp:244]     Train net output #0: loss = 0.125001 (* 1 = 0.125001 loss)
I0422 08:34:51.933380  6613 sgd_solver.cpp:106] Iteration 37500, lr = 0.0001
I0422 08:36:28.647286  6613 solver.cpp:228] Iteration 37600, loss = 0.122251
I0422 08:36:28.647435  6613 solver.cpp:244]     Train net output #0: loss = 0.122251 (* 1 = 0.122251 loss)
I0422 08:36:28.647441  6613 sgd_solver.cpp:106] Iteration 37600, lr = 0.0001
I0422 08:38:05.583544  6613 solver.cpp:228] Iteration 37700, loss = 0.0735998
I0422 08:38:05.583694  6613 solver.cpp:244]     Train net output #0: loss = 0.0735998 (* 1 = 0.0735998 loss)
I0422 08:38:05.583701  6613 sgd_solver.cpp:106] Iteration 37700, lr = 0.0001
I0422 08:39:40.956899  6613 solver.cpp:228] Iteration 37800, loss = 0.140078
I0422 08:39:40.957031  6613 solver.cpp:244]     Train net output #0: loss = 0.140078 (* 1 = 0.140078 loss)
I0422 08:39:40.957036  6613 sgd_solver.cpp:106] Iteration 37800, lr = 0.0001
I0422 08:41:18.096449  6613 solver.cpp:228] Iteration 37900, loss = 0.141761
I0422 08:41:18.096580  6613 solver.cpp:244]     Train net output #0: loss = 0.141761 (* 1 = 0.141761 loss)
I0422 08:41:18.096587  6613 sgd_solver.cpp:106] Iteration 37900, lr = 0.0001
I0422 08:42:54.647194  6613 solver.cpp:337] Iteration 38000, Testing net (#0)
I0422 08:42:54.647322  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 08:42:54.647326  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 08:42:54.647331  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 08:42:54.647346  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 08:42:54.647348  6613 net.cpp:693] Ignoring source layer visualize
I0422 08:42:54.647351  6613 net.cpp:693] Ignoring source layer fake
I0422 08:46:15.187077  6613 solver.cpp:404]     Test net output #0: loss = 0.181769 (* 1 = 0.181769 loss)
I0422 08:46:15.821352  6613 solver.cpp:228] Iteration 38000, loss = 0.139909
I0422 08:46:15.821393  6613 solver.cpp:244]     Train net output #0: loss = 0.139909 (* 1 = 0.139909 loss)
I0422 08:46:15.821399  6613 sgd_solver.cpp:106] Iteration 38000, lr = 0.0001
I0422 08:47:53.123194  6613 solver.cpp:228] Iteration 38100, loss = 0.138061
I0422 08:47:53.123332  6613 solver.cpp:244]     Train net output #0: loss = 0.138061 (* 1 = 0.138061 loss)
I0422 08:47:53.123339  6613 sgd_solver.cpp:106] Iteration 38100, lr = 0.0001
I0422 08:49:28.513532  6613 solver.cpp:228] Iteration 38200, loss = 0.129453
I0422 08:49:28.513700  6613 solver.cpp:244]     Train net output #0: loss = 0.129453 (* 1 = 0.129453 loss)
I0422 08:49:28.513707  6613 sgd_solver.cpp:106] Iteration 38200, lr = 0.0001
I0422 08:51:05.971766  6613 solver.cpp:228] Iteration 38300, loss = 0.11883
I0422 08:51:05.971907  6613 solver.cpp:244]     Train net output #0: loss = 0.11883 (* 1 = 0.11883 loss)
I0422 08:51:05.971915  6613 sgd_solver.cpp:106] Iteration 38300, lr = 0.0001
I0422 08:52:43.559463  6613 solver.cpp:228] Iteration 38400, loss = 0.112106
I0422 08:52:43.559607  6613 solver.cpp:244]     Train net output #0: loss = 0.112106 (* 1 = 0.112106 loss)
I0422 08:52:43.559613  6613 sgd_solver.cpp:106] Iteration 38400, lr = 0.0001
I0422 08:54:20.844439  6613 solver.cpp:228] Iteration 38500, loss = 0.112544
I0422 08:54:20.844600  6613 solver.cpp:244]     Train net output #0: loss = 0.112544 (* 1 = 0.112544 loss)
I0422 08:54:20.844607  6613 sgd_solver.cpp:106] Iteration 38500, lr = 0.0001
I0422 08:55:56.175513  6613 solver.cpp:228] Iteration 38600, loss = 0.0945332
I0422 08:55:56.175681  6613 solver.cpp:244]     Train net output #0: loss = 0.0945332 (* 1 = 0.0945332 loss)
I0422 08:55:56.175689  6613 sgd_solver.cpp:106] Iteration 38600, lr = 0.0001
I0422 08:57:33.164003  6613 solver.cpp:228] Iteration 38700, loss = 0.0732868
I0422 08:57:33.164145  6613 solver.cpp:244]     Train net output #0: loss = 0.0732868 (* 1 = 0.0732868 loss)
I0422 08:57:33.164153  6613 sgd_solver.cpp:106] Iteration 38700, lr = 0.0001
I0422 08:59:09.799619  6613 solver.cpp:228] Iteration 38800, loss = 0.101431
I0422 08:59:09.799767  6613 solver.cpp:244]     Train net output #0: loss = 0.101431 (* 1 = 0.101431 loss)
I0422 08:59:09.799774  6613 sgd_solver.cpp:106] Iteration 38800, lr = 0.0001
I0422 09:00:46.481384  6613 solver.cpp:228] Iteration 38900, loss = 0.109058
I0422 09:00:46.481550  6613 solver.cpp:244]     Train net output #0: loss = 0.109058 (* 1 = 0.109058 loss)
I0422 09:00:46.481557  6613 sgd_solver.cpp:106] Iteration 38900, lr = 0.0001
I0422 09:02:22.668347  6613 solver.cpp:337] Iteration 39000, Testing net (#0)
I0422 09:02:22.668498  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 09:02:22.668503  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 09:02:22.668506  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 09:02:22.668522  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 09:02:22.668525  6613 net.cpp:693] Ignoring source layer visualize
I0422 09:02:22.668527  6613 net.cpp:693] Ignoring source layer fake
I0422 09:05:43.344619  6613 solver.cpp:404]     Test net output #0: loss = 0.129517 (* 1 = 0.129517 loss)
I0422 09:05:43.970419  6613 solver.cpp:228] Iteration 39000, loss = 0.104967
I0422 09:05:43.970440  6613 solver.cpp:244]     Train net output #0: loss = 0.104967 (* 1 = 0.104967 loss)
I0422 09:05:43.970461  6613 sgd_solver.cpp:106] Iteration 39000, lr = 0.0001
I0422 09:07:21.426688  6613 solver.cpp:228] Iteration 39100, loss = 0.13557
I0422 09:07:21.426853  6613 solver.cpp:244]     Train net output #0: loss = 0.13557 (* 1 = 0.13557 loss)
I0422 09:07:21.426862  6613 sgd_solver.cpp:106] Iteration 39100, lr = 0.0001
I0422 09:08:58.684239  6613 solver.cpp:228] Iteration 39200, loss = 0.12804
I0422 09:08:58.684391  6613 solver.cpp:244]     Train net output #0: loss = 0.12804 (* 1 = 0.12804 loss)
I0422 09:08:58.684397  6613 sgd_solver.cpp:106] Iteration 39200, lr = 0.0001
I0422 09:10:34.066440  6613 solver.cpp:228] Iteration 39300, loss = 0.113521
I0422 09:10:34.066584  6613 solver.cpp:244]     Train net output #0: loss = 0.113521 (* 1 = 0.113521 loss)
I0422 09:10:34.066591  6613 sgd_solver.cpp:106] Iteration 39300, lr = 0.0001
I0422 09:12:11.562703  6613 solver.cpp:228] Iteration 39400, loss = 0.0914824
I0422 09:12:11.564232  6613 solver.cpp:244]     Train net output #0: loss = 0.0914824 (* 1 = 0.0914824 loss)
I0422 09:12:11.564241  6613 sgd_solver.cpp:106] Iteration 39400, lr = 0.0001
I0422 09:13:48.972579  6613 solver.cpp:228] Iteration 39500, loss = 0.155405
I0422 09:13:48.972728  6613 solver.cpp:244]     Train net output #0: loss = 0.155405 (* 1 = 0.155405 loss)
I0422 09:13:48.972736  6613 sgd_solver.cpp:106] Iteration 39500, lr = 0.0001
I0422 09:15:24.324868  6613 solver.cpp:228] Iteration 39600, loss = 0.199144
I0422 09:15:24.325003  6613 solver.cpp:244]     Train net output #0: loss = 0.199144 (* 1 = 0.199144 loss)
I0422 09:15:24.325011  6613 sgd_solver.cpp:106] Iteration 39600, lr = 0.0001
I0422 09:17:01.501503  6613 solver.cpp:228] Iteration 39700, loss = 0.0810054
I0422 09:17:01.501641  6613 solver.cpp:244]     Train net output #0: loss = 0.0810054 (* 1 = 0.0810054 loss)
I0422 09:17:01.501648  6613 sgd_solver.cpp:106] Iteration 39700, lr = 0.0001
I0422 09:18:38.671928  6613 solver.cpp:228] Iteration 39800, loss = 0.100026
I0422 09:18:38.672077  6613 solver.cpp:244]     Train net output #0: loss = 0.100026 (* 1 = 0.100026 loss)
I0422 09:18:38.672085  6613 sgd_solver.cpp:106] Iteration 39800, lr = 0.0001
I0422 09:20:15.686444  6613 solver.cpp:228] Iteration 39900, loss = 0.39262
I0422 09:20:15.686606  6613 solver.cpp:244]     Train net output #0: loss = 0.39262 (* 1 = 0.39262 loss)
I0422 09:20:15.686615  6613 sgd_solver.cpp:106] Iteration 39900, lr = 0.0001
I0422 09:21:51.323393  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_40000.caffemodel
I0422 09:22:19.407204  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_40000.solverstate
I0422 09:22:19.602141  6613 solver.cpp:337] Iteration 40000, Testing net (#0)
I0422 09:22:19.602185  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 09:22:19.602188  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 09:22:19.602193  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 09:22:19.602207  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 09:22:19.602210  6613 net.cpp:693] Ignoring source layer visualize
I0422 09:22:19.602211  6613 net.cpp:693] Ignoring source layer fake
I0422 09:25:39.723603  6613 solver.cpp:404]     Test net output #0: loss = 0.12043 (* 1 = 0.12043 loss)
I0422 09:25:40.354866  6613 solver.cpp:228] Iteration 40000, loss = 0.121563
I0422 09:25:40.354885  6613 solver.cpp:244]     Train net output #0: loss = 0.121563 (* 1 = 0.121563 loss)
I0422 09:25:40.354907  6613 sgd_solver.cpp:106] Iteration 40000, lr = 1e-05
I0422 09:27:17.101922  6613 solver.cpp:228] Iteration 40100, loss = 0.114832
I0422 09:27:17.102074  6613 solver.cpp:244]     Train net output #0: loss = 0.114832 (* 1 = 0.114832 loss)
I0422 09:27:17.102082  6613 sgd_solver.cpp:106] Iteration 40100, lr = 1e-05
I0422 09:28:54.031431  6613 solver.cpp:228] Iteration 40200, loss = 0.103325
I0422 09:28:54.031575  6613 solver.cpp:244]     Train net output #0: loss = 0.103325 (* 1 = 0.103325 loss)
I0422 09:28:54.031582  6613 sgd_solver.cpp:106] Iteration 40200, lr = 1e-05
I0422 09:30:29.387372  6613 solver.cpp:228] Iteration 40300, loss = 0.126237
I0422 09:30:29.387513  6613 solver.cpp:244]     Train net output #0: loss = 0.126237 (* 1 = 0.126237 loss)
I0422 09:30:29.387519  6613 sgd_solver.cpp:106] Iteration 40300, lr = 1e-05
I0422 09:32:06.542956  6613 solver.cpp:228] Iteration 40400, loss = 0.127907
I0422 09:32:06.543159  6613 solver.cpp:244]     Train net output #0: loss = 0.127907 (* 1 = 0.127907 loss)
I0422 09:32:06.543176  6613 sgd_solver.cpp:106] Iteration 40400, lr = 1e-05
I0422 09:33:45.034387  6613 solver.cpp:228] Iteration 40500, loss = 0.133706
I0422 09:33:45.034549  6613 solver.cpp:244]     Train net output #0: loss = 0.133706 (* 1 = 0.133706 loss)
I0422 09:33:45.034557  6613 sgd_solver.cpp:106] Iteration 40500, lr = 1e-05
I0422 09:35:22.364473  6613 solver.cpp:228] Iteration 40600, loss = 0.136034
I0422 09:35:22.364637  6613 solver.cpp:244]     Train net output #0: loss = 0.136034 (* 1 = 0.136034 loss)
I0422 09:35:22.364645  6613 sgd_solver.cpp:106] Iteration 40600, lr = 1e-05
I0422 09:36:57.768410  6613 solver.cpp:228] Iteration 40700, loss = 0.0894472
I0422 09:36:57.768563  6613 solver.cpp:244]     Train net output #0: loss = 0.0894472 (* 1 = 0.0894472 loss)
I0422 09:36:57.768570  6613 sgd_solver.cpp:106] Iteration 40700, lr = 1e-05
I0422 09:38:35.029717  6613 solver.cpp:228] Iteration 40800, loss = 0.121638
I0422 09:38:35.029861  6613 solver.cpp:244]     Train net output #0: loss = 0.121638 (* 1 = 0.121638 loss)
I0422 09:38:35.029867  6613 sgd_solver.cpp:106] Iteration 40800, lr = 1e-05
I0422 09:40:12.279355  6613 solver.cpp:228] Iteration 40900, loss = 0.131956
I0422 09:40:12.279496  6613 solver.cpp:244]     Train net output #0: loss = 0.131956 (* 1 = 0.131956 loss)
I0422 09:40:12.279505  6613 sgd_solver.cpp:106] Iteration 40900, lr = 1e-05
I0422 09:41:48.543434  6613 solver.cpp:337] Iteration 41000, Testing net (#0)
I0422 09:41:48.543586  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 09:41:48.543589  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 09:41:48.543594  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 09:41:48.543611  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 09:41:48.543612  6613 net.cpp:693] Ignoring source layer visualize
I0422 09:41:48.543614  6613 net.cpp:693] Ignoring source layer fake
I0422 09:45:09.020509  6613 solver.cpp:404]     Test net output #0: loss = 0.11809 (* 1 = 0.11809 loss)
I0422 09:45:09.646643  6613 solver.cpp:228] Iteration 41000, loss = 0.118498
I0422 09:45:09.646663  6613 solver.cpp:244]     Train net output #0: loss = 0.118498 (* 1 = 0.118498 loss)
I0422 09:45:09.646685  6613 sgd_solver.cpp:106] Iteration 41000, lr = 1e-05
I0422 09:46:45.278414  6613 solver.cpp:228] Iteration 41100, loss = 0.081299
I0422 09:46:45.278576  6613 solver.cpp:244]     Train net output #0: loss = 0.081299 (* 1 = 0.081299 loss)
I0422 09:46:45.278584  6613 sgd_solver.cpp:106] Iteration 41100, lr = 1e-05
I0422 09:48:23.409178  6613 solver.cpp:228] Iteration 41200, loss = 0.0796374
I0422 09:48:23.409332  6613 solver.cpp:244]     Train net output #0: loss = 0.0796374 (* 1 = 0.0796374 loss)
I0422 09:48:23.409338  6613 sgd_solver.cpp:106] Iteration 41200, lr = 1e-05
I0422 09:50:00.813494  6613 solver.cpp:228] Iteration 41300, loss = 0.125605
I0422 09:50:00.813642  6613 solver.cpp:244]     Train net output #0: loss = 0.125605 (* 1 = 0.125605 loss)
I0422 09:50:00.813649  6613 sgd_solver.cpp:106] Iteration 41300, lr = 1e-05
I0422 09:51:37.944344  6613 solver.cpp:228] Iteration 41400, loss = 0.183813
I0422 09:51:37.944476  6613 solver.cpp:244]     Train net output #0: loss = 0.183813 (* 1 = 0.183813 loss)
I0422 09:51:37.944483  6613 sgd_solver.cpp:106] Iteration 41400, lr = 1e-05
I0422 09:53:15.896363  6613 solver.cpp:228] Iteration 41500, loss = 0.0822512
I0422 09:53:15.896518  6613 solver.cpp:244]     Train net output #0: loss = 0.0822512 (* 1 = 0.0822512 loss)
I0422 09:53:15.896528  6613 sgd_solver.cpp:106] Iteration 41500, lr = 1e-05
I0422 09:54:53.534546  6613 solver.cpp:228] Iteration 41600, loss = 0.139433
I0422 09:54:53.534687  6613 solver.cpp:244]     Train net output #0: loss = 0.139433 (* 1 = 0.139433 loss)
I0422 09:54:53.534694  6613 sgd_solver.cpp:106] Iteration 41600, lr = 1e-05
I0422 09:56:31.929070  6613 solver.cpp:228] Iteration 41700, loss = 0.133317
I0422 09:56:31.929203  6613 solver.cpp:244]     Train net output #0: loss = 0.133317 (* 1 = 0.133317 loss)
I0422 09:56:31.929211  6613 sgd_solver.cpp:106] Iteration 41700, lr = 1e-05
I0422 09:58:07.319030  6613 solver.cpp:228] Iteration 41800, loss = 0.115564
I0422 09:58:07.319159  6613 solver.cpp:244]     Train net output #0: loss = 0.115564 (* 1 = 0.115564 loss)
I0422 09:58:07.319165  6613 sgd_solver.cpp:106] Iteration 41800, lr = 1e-05
I0422 09:59:45.414584  6613 solver.cpp:228] Iteration 41900, loss = 0.131761
I0422 09:59:45.414724  6613 solver.cpp:244]     Train net output #0: loss = 0.131761 (* 1 = 0.131761 loss)
I0422 09:59:45.414731  6613 sgd_solver.cpp:106] Iteration 41900, lr = 1e-05
I0422 10:01:21.675477  6613 solver.cpp:337] Iteration 42000, Testing net (#0)
I0422 10:01:21.675609  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 10:01:21.675613  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 10:01:21.675617  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 10:01:21.675631  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 10:01:21.675637  6613 net.cpp:693] Ignoring source layer visualize
I0422 10:01:21.675638  6613 net.cpp:693] Ignoring source layer fake
I0422 10:04:42.436372  6613 solver.cpp:404]     Test net output #0: loss = 0.153069 (* 1 = 0.153069 loss)
I0422 10:04:43.068897  6613 solver.cpp:228] Iteration 42000, loss = 0.135783
I0422 10:04:43.068941  6613 solver.cpp:244]     Train net output #0: loss = 0.135783 (* 1 = 0.135783 loss)
I0422 10:04:43.068948  6613 sgd_solver.cpp:106] Iteration 42000, lr = 1e-05
I0422 10:06:18.711565  6613 solver.cpp:228] Iteration 42100, loss = 0.191363
I0422 10:06:18.711701  6613 solver.cpp:244]     Train net output #0: loss = 0.191363 (* 1 = 0.191363 loss)
I0422 10:06:18.711720  6613 sgd_solver.cpp:106] Iteration 42100, lr = 1e-05
I0422 10:07:56.324949  6613 solver.cpp:228] Iteration 42200, loss = 0.0998004
I0422 10:07:56.325117  6613 solver.cpp:244]     Train net output #0: loss = 0.0998004 (* 1 = 0.0998004 loss)
I0422 10:07:56.325125  6613 sgd_solver.cpp:106] Iteration 42200, lr = 1e-05
I0422 10:09:33.449987  6613 solver.cpp:228] Iteration 42300, loss = 0.0988098
I0422 10:09:33.450141  6613 solver.cpp:244]     Train net output #0: loss = 0.0988098 (* 1 = 0.0988098 loss)
I0422 10:09:33.450148  6613 sgd_solver.cpp:106] Iteration 42300, lr = 1e-05
I0422 10:11:10.426980  6613 solver.cpp:228] Iteration 42400, loss = 0.337801
I0422 10:11:10.427116  6613 solver.cpp:244]     Train net output #0: loss = 0.337801 (* 1 = 0.337801 loss)
I0422 10:11:10.427124  6613 sgd_solver.cpp:106] Iteration 42400, lr = 1e-05
I0422 10:12:47.043680  6613 solver.cpp:228] Iteration 42500, loss = 0.100909
I0422 10:12:47.043967  6613 solver.cpp:244]     Train net output #0: loss = 0.100909 (* 1 = 0.100909 loss)
I0422 10:12:47.043974  6613 sgd_solver.cpp:106] Iteration 42500, lr = 1e-05
I0422 10:14:23.749390  6613 solver.cpp:228] Iteration 42600, loss = 0.170968
I0422 10:14:23.749547  6613 solver.cpp:244]     Train net output #0: loss = 0.170968 (* 1 = 0.170968 loss)
I0422 10:14:23.749553  6613 sgd_solver.cpp:106] Iteration 42600, lr = 1e-05
I0422 10:16:00.680404  6613 solver.cpp:228] Iteration 42700, loss = 0.0797136
I0422 10:16:00.680547  6613 solver.cpp:244]     Train net output #0: loss = 0.0797136 (* 1 = 0.0797136 loss)
I0422 10:16:00.680554  6613 sgd_solver.cpp:106] Iteration 42700, lr = 1e-05
I0422 10:17:36.055112  6613 solver.cpp:228] Iteration 42800, loss = 0.0968366
I0422 10:17:36.055248  6613 solver.cpp:244]     Train net output #0: loss = 0.0968366 (* 1 = 0.0968366 loss)
I0422 10:17:36.055255  6613 sgd_solver.cpp:106] Iteration 42800, lr = 1e-05
I0422 10:19:17.166919  6613 solver.cpp:228] Iteration 42900, loss = 0.146195
I0422 10:19:17.167057  6613 solver.cpp:244]     Train net output #0: loss = 0.146195 (* 1 = 0.146195 loss)
I0422 10:19:17.167065  6613 sgd_solver.cpp:106] Iteration 42900, lr = 1e-05
I0422 10:20:53.439307  6613 solver.cpp:337] Iteration 43000, Testing net (#0)
I0422 10:20:53.439440  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 10:20:53.439445  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 10:20:53.439448  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 10:20:53.439462  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 10:20:53.439465  6613 net.cpp:693] Ignoring source layer visualize
I0422 10:20:53.439467  6613 net.cpp:693] Ignoring source layer fake
I0422 10:24:14.307965  6613 solver.cpp:404]     Test net output #0: loss = 0.119233 (* 1 = 0.119233 loss)
I0422 10:24:14.936866  6613 solver.cpp:228] Iteration 43000, loss = 0.101885
I0422 10:24:14.936908  6613 solver.cpp:244]     Train net output #0: loss = 0.101885 (* 1 = 0.101885 loss)
I0422 10:24:14.936913  6613 sgd_solver.cpp:106] Iteration 43000, lr = 1e-05
I0422 10:25:52.411186  6613 solver.cpp:228] Iteration 43100, loss = 0.0853951
I0422 10:25:52.411419  6613 solver.cpp:244]     Train net output #0: loss = 0.0853951 (* 1 = 0.0853951 loss)
I0422 10:25:52.411427  6613 sgd_solver.cpp:106] Iteration 43100, lr = 1e-05
I0422 10:27:27.753893  6613 solver.cpp:228] Iteration 43200, loss = 0.105922
I0422 10:27:27.754324  6613 solver.cpp:244]     Train net output #0: loss = 0.105922 (* 1 = 0.105922 loss)
I0422 10:27:27.754330  6613 sgd_solver.cpp:106] Iteration 43200, lr = 1e-05
I0422 10:29:04.958963  6613 solver.cpp:228] Iteration 43300, loss = 0.16379
I0422 10:29:04.960306  6613 solver.cpp:244]     Train net output #0: loss = 0.16379 (* 1 = 0.16379 loss)
I0422 10:29:04.960314  6613 sgd_solver.cpp:106] Iteration 43300, lr = 1e-05
I0422 10:30:42.464684  6613 solver.cpp:228] Iteration 43400, loss = 0.0806447
I0422 10:30:42.464833  6613 solver.cpp:244]     Train net output #0: loss = 0.0806447 (* 1 = 0.0806447 loss)
I0422 10:30:42.464839  6613 sgd_solver.cpp:106] Iteration 43400, lr = 1e-05
I0422 10:32:19.572005  6613 solver.cpp:228] Iteration 43500, loss = 0.0857195
I0422 10:32:19.572190  6613 solver.cpp:244]     Train net output #0: loss = 0.0857195 (* 1 = 0.0857195 loss)
I0422 10:32:19.572197  6613 sgd_solver.cpp:106] Iteration 43500, lr = 1e-05
I0422 10:33:54.907013  6613 solver.cpp:228] Iteration 43600, loss = 0.115487
I0422 10:33:54.907172  6613 solver.cpp:244]     Train net output #0: loss = 0.115487 (* 1 = 0.115487 loss)
I0422 10:33:54.907181  6613 sgd_solver.cpp:106] Iteration 43600, lr = 1e-05
I0422 10:35:31.874146  6613 solver.cpp:228] Iteration 43700, loss = 0.0792016
I0422 10:35:31.874280  6613 solver.cpp:244]     Train net output #0: loss = 0.0792016 (* 1 = 0.0792016 loss)
I0422 10:35:31.874287  6613 sgd_solver.cpp:106] Iteration 43700, lr = 1e-05
I0422 10:37:08.476038  6613 solver.cpp:228] Iteration 43800, loss = 0.117518
I0422 10:37:08.477948  6613 solver.cpp:244]     Train net output #0: loss = 0.117518 (* 1 = 0.117518 loss)
I0422 10:37:08.477954  6613 sgd_solver.cpp:106] Iteration 43800, lr = 1e-05
I0422 10:38:45.202294  6613 solver.cpp:228] Iteration 43900, loss = 0.102851
I0422 10:38:45.202428  6613 solver.cpp:244]     Train net output #0: loss = 0.102851 (* 1 = 0.102851 loss)
I0422 10:38:45.202435  6613 sgd_solver.cpp:106] Iteration 43900, lr = 1e-05
I0422 10:40:21.173373  6613 solver.cpp:337] Iteration 44000, Testing net (#0)
I0422 10:40:21.173506  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 10:40:21.173509  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 10:40:21.173513  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 10:40:21.173528  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 10:40:21.173532  6613 net.cpp:693] Ignoring source layer visualize
I0422 10:40:21.173533  6613 net.cpp:693] Ignoring source layer fake
I0422 10:43:42.156697  6613 solver.cpp:404]     Test net output #0: loss = 0.124777 (* 1 = 0.124777 loss)
I0422 10:43:42.786931  6613 solver.cpp:228] Iteration 44000, loss = 0.10861
I0422 10:43:42.786968  6613 solver.cpp:244]     Train net output #0: loss = 0.10861 (* 1 = 0.10861 loss)
I0422 10:43:42.786974  6613 sgd_solver.cpp:106] Iteration 44000, lr = 1e-05
I0422 10:45:20.191824  6613 solver.cpp:228] Iteration 44100, loss = 0.16772
I0422 10:45:20.191968  6613 solver.cpp:244]     Train net output #0: loss = 0.16772 (* 1 = 0.16772 loss)
I0422 10:45:20.191975  6613 sgd_solver.cpp:106] Iteration 44100, lr = 1e-05
I0422 10:46:57.757419  6613 solver.cpp:228] Iteration 44200, loss = 0.186142
I0422 10:46:57.757589  6613 solver.cpp:244]     Train net output #0: loss = 0.186142 (* 1 = 0.186142 loss)
I0422 10:46:57.757597  6613 sgd_solver.cpp:106] Iteration 44200, lr = 1e-05
I0422 10:48:33.111838  6613 solver.cpp:228] Iteration 44300, loss = 0.153465
I0422 10:48:33.111980  6613 solver.cpp:244]     Train net output #0: loss = 0.153465 (* 1 = 0.153465 loss)
I0422 10:48:33.111987  6613 sgd_solver.cpp:106] Iteration 44300, lr = 1e-05
I0422 10:50:10.324738  6613 solver.cpp:228] Iteration 44400, loss = 0.135395
I0422 10:50:10.324884  6613 solver.cpp:244]     Train net output #0: loss = 0.135395 (* 1 = 0.135395 loss)
I0422 10:50:10.324892  6613 sgd_solver.cpp:106] Iteration 44400, lr = 1e-05
I0422 10:51:47.910246  6613 solver.cpp:228] Iteration 44500, loss = 0.124629
I0422 10:51:47.910400  6613 solver.cpp:244]     Train net output #0: loss = 0.124629 (* 1 = 0.124629 loss)
I0422 10:51:47.910408  6613 sgd_solver.cpp:106] Iteration 44500, lr = 1e-05
I0422 10:53:23.291070  6613 solver.cpp:228] Iteration 44600, loss = 0.171917
I0422 10:53:23.292385  6613 solver.cpp:244]     Train net output #0: loss = 0.171917 (* 1 = 0.171917 loss)
I0422 10:53:23.292393  6613 sgd_solver.cpp:106] Iteration 44600, lr = 1e-05
I0422 10:55:01.032977  6613 solver.cpp:228] Iteration 44700, loss = 0.122409
I0422 10:55:01.033118  6613 solver.cpp:244]     Train net output #0: loss = 0.122409 (* 1 = 0.122409 loss)
I0422 10:55:01.033125  6613 sgd_solver.cpp:106] Iteration 44700, lr = 1e-05
I0422 10:56:38.271006  6613 solver.cpp:228] Iteration 44800, loss = 0.100437
I0422 10:56:38.271142  6613 solver.cpp:244]     Train net output #0: loss = 0.100437 (* 1 = 0.100437 loss)
I0422 10:56:38.271150  6613 sgd_solver.cpp:106] Iteration 44800, lr = 1e-05
I0422 10:58:15.378916  6613 solver.cpp:228] Iteration 44900, loss = 0.0943375
I0422 10:58:15.379101  6613 solver.cpp:244]     Train net output #0: loss = 0.0943375 (* 1 = 0.0943375 loss)
I0422 10:58:15.379109  6613 sgd_solver.cpp:106] Iteration 44900, lr = 1e-05
I0422 10:59:51.091087  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_45000.caffemodel
I0422 11:00:02.205272  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_45000.solverstate
I0422 11:00:02.402259  6613 solver.cpp:337] Iteration 45000, Testing net (#0)
I0422 11:00:02.402305  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 11:00:02.402308  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 11:00:02.402312  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 11:00:02.402328  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 11:00:02.402330  6613 net.cpp:693] Ignoring source layer visualize
I0422 11:00:02.402333  6613 net.cpp:693] Ignoring source layer fake
I0422 11:03:23.595859  6613 solver.cpp:404]     Test net output #0: loss = 0.115756 (* 1 = 0.115756 loss)
I0422 11:03:24.227440  6613 solver.cpp:228] Iteration 45000, loss = 0.103902
I0422 11:03:24.227481  6613 solver.cpp:244]     Train net output #0: loss = 0.103902 (* 1 = 0.103902 loss)
I0422 11:03:24.227488  6613 sgd_solver.cpp:106] Iteration 45000, lr = 1e-05
I0422 11:05:01.305021  6613 solver.cpp:228] Iteration 45100, loss = 0.167033
I0422 11:05:01.305169  6613 solver.cpp:244]     Train net output #0: loss = 0.167033 (* 1 = 0.167033 loss)
I0422 11:05:01.305178  6613 sgd_solver.cpp:106] Iteration 45100, lr = 1e-05
I0422 11:06:38.728881  6613 solver.cpp:228] Iteration 45200, loss = 0.103224
I0422 11:06:38.729038  6613 solver.cpp:244]     Train net output #0: loss = 0.103224 (* 1 = 0.103224 loss)
I0422 11:06:38.729046  6613 sgd_solver.cpp:106] Iteration 45200, lr = 1e-05
I0422 11:08:14.088647  6613 solver.cpp:228] Iteration 45300, loss = 0.120268
I0422 11:08:14.088783  6613 solver.cpp:244]     Train net output #0: loss = 0.120268 (* 1 = 0.120268 loss)
I0422 11:08:14.088789  6613 sgd_solver.cpp:106] Iteration 45300, lr = 1e-05
I0422 11:09:51.792162  6613 solver.cpp:228] Iteration 45400, loss = 0.164964
I0422 11:09:51.792312  6613 solver.cpp:244]     Train net output #0: loss = 0.164964 (* 1 = 0.164964 loss)
I0422 11:09:51.792321  6613 sgd_solver.cpp:106] Iteration 45400, lr = 1e-05
I0422 11:11:29.447116  6613 solver.cpp:228] Iteration 45500, loss = 0.11736
I0422 11:11:29.447264  6613 solver.cpp:244]     Train net output #0: loss = 0.11736 (* 1 = 0.11736 loss)
I0422 11:11:29.447273  6613 sgd_solver.cpp:106] Iteration 45500, lr = 1e-05
I0422 11:13:07.309175  6613 solver.cpp:228] Iteration 45600, loss = 0.144678
I0422 11:13:07.309334  6613 solver.cpp:244]     Train net output #0: loss = 0.144678 (* 1 = 0.144678 loss)
I0422 11:13:07.309342  6613 sgd_solver.cpp:106] Iteration 45600, lr = 1e-05
I0422 11:14:42.697973  6613 solver.cpp:228] Iteration 45700, loss = 0.120929
I0422 11:14:42.698107  6613 solver.cpp:244]     Train net output #0: loss = 0.120929 (* 1 = 0.120929 loss)
I0422 11:14:42.698114  6613 sgd_solver.cpp:106] Iteration 45700, lr = 1e-05
I0422 11:16:20.467912  6613 solver.cpp:228] Iteration 45800, loss = 0.165071
I0422 11:16:20.468049  6613 solver.cpp:244]     Train net output #0: loss = 0.165071 (* 1 = 0.165071 loss)
I0422 11:16:20.468055  6613 sgd_solver.cpp:106] Iteration 45800, lr = 1e-05
I0422 11:17:57.792464  6613 solver.cpp:228] Iteration 45900, loss = 0.0905066
I0422 11:17:57.792594  6613 solver.cpp:244]     Train net output #0: loss = 0.0905066 (* 1 = 0.0905066 loss)
I0422 11:17:57.792603  6613 sgd_solver.cpp:106] Iteration 45900, lr = 1e-05
I0422 11:19:41.681555  6613 solver.cpp:337] Iteration 46000, Testing net (#0)
I0422 11:19:41.681727  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 11:19:41.681732  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 11:19:41.681740  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 11:19:41.681761  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 11:19:41.681764  6613 net.cpp:693] Ignoring source layer visualize
I0422 11:19:41.681767  6613 net.cpp:693] Ignoring source layer fake
I0422 11:23:02.316908  6613 solver.cpp:404]     Test net output #0: loss = 0.116363 (* 1 = 0.116363 loss)
I0422 11:23:02.947937  6613 solver.cpp:228] Iteration 46000, loss = 0.102095
I0422 11:23:02.947978  6613 solver.cpp:244]     Train net output #0: loss = 0.102095 (* 1 = 0.102095 loss)
I0422 11:23:02.947983  6613 sgd_solver.cpp:106] Iteration 46000, lr = 1e-05
I0422 11:24:38.557060  6613 solver.cpp:228] Iteration 46100, loss = 0.107672
I0422 11:24:38.558425  6613 solver.cpp:244]     Train net output #0: loss = 0.107672 (* 1 = 0.107672 loss)
I0422 11:24:38.558432  6613 sgd_solver.cpp:106] Iteration 46100, lr = 1e-05
I0422 11:26:25.084683  6613 solver.cpp:228] Iteration 46200, loss = 0.0750007
I0422 11:26:25.084820  6613 solver.cpp:244]     Train net output #0: loss = 0.0750007 (* 1 = 0.0750007 loss)
I0422 11:26:25.084827  6613 sgd_solver.cpp:106] Iteration 46200, lr = 1e-05
I0422 11:28:07.365051  6613 solver.cpp:228] Iteration 46300, loss = 0.119493
I0422 11:28:07.365207  6613 solver.cpp:244]     Train net output #0: loss = 0.119493 (* 1 = 0.119493 loss)
I0422 11:28:07.365216  6613 sgd_solver.cpp:106] Iteration 46300, lr = 1e-05
I0422 11:29:50.314867  6613 solver.cpp:228] Iteration 46400, loss = 0.143736
I0422 11:29:50.315017  6613 solver.cpp:244]     Train net output #0: loss = 0.143736 (* 1 = 0.143736 loss)
I0422 11:29:50.315026  6613 sgd_solver.cpp:106] Iteration 46400, lr = 1e-05
I0422 11:31:34.713708  6613 solver.cpp:228] Iteration 46500, loss = 0.124472
I0422 11:31:34.713860  6613 solver.cpp:244]     Train net output #0: loss = 0.124472 (* 1 = 0.124472 loss)
I0422 11:31:34.713867  6613 sgd_solver.cpp:106] Iteration 46500, lr = 1e-05
I0422 11:33:11.993269  6613 solver.cpp:228] Iteration 46600, loss = 0.123825
I0422 11:33:11.993412  6613 solver.cpp:244]     Train net output #0: loss = 0.123825 (* 1 = 0.123825 loss)
I0422 11:33:11.993419  6613 sgd_solver.cpp:106] Iteration 46600, lr = 1e-05
I0422 11:34:49.336021  6613 solver.cpp:228] Iteration 46700, loss = 0.162118
I0422 11:34:49.336163  6613 solver.cpp:244]     Train net output #0: loss = 0.162118 (* 1 = 0.162118 loss)
I0422 11:34:49.336171  6613 sgd_solver.cpp:106] Iteration 46700, lr = 1e-05
I0422 11:36:24.750823  6613 solver.cpp:228] Iteration 46800, loss = 0.107493
I0422 11:36:24.750950  6613 solver.cpp:244]     Train net output #0: loss = 0.107493 (* 1 = 0.107493 loss)
I0422 11:36:24.750957  6613 sgd_solver.cpp:106] Iteration 46800, lr = 1e-05
I0422 11:38:02.063843  6613 solver.cpp:228] Iteration 46900, loss = 0.085816
I0422 11:38:02.063982  6613 solver.cpp:244]     Train net output #0: loss = 0.085816 (* 1 = 0.085816 loss)
I0422 11:38:02.063987  6613 sgd_solver.cpp:106] Iteration 46900, lr = 1e-05
I0422 11:39:38.446902  6613 solver.cpp:337] Iteration 47000, Testing net (#0)
I0422 11:39:38.447028  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 11:39:38.447032  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 11:39:38.447036  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 11:39:38.447052  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 11:39:38.447054  6613 net.cpp:693] Ignoring source layer visualize
I0422 11:39:38.447057  6613 net.cpp:693] Ignoring source layer fake
I0422 11:42:59.039158  6613 solver.cpp:404]     Test net output #0: loss = 0.150443 (* 1 = 0.150443 loss)
I0422 11:42:59.670929  6613 solver.cpp:228] Iteration 47000, loss = 0.187436
I0422 11:42:59.670969  6613 solver.cpp:244]     Train net output #0: loss = 0.187436 (* 1 = 0.187436 loss)
I0422 11:42:59.670974  6613 sgd_solver.cpp:106] Iteration 47000, lr = 1e-05
I0422 11:44:35.288519  6613 solver.cpp:228] Iteration 47100, loss = 0.121544
I0422 11:44:35.289638  6613 solver.cpp:244]     Train net output #0: loss = 0.121544 (* 1 = 0.121544 loss)
I0422 11:44:35.289646  6613 sgd_solver.cpp:106] Iteration 47100, lr = 1e-05
I0422 11:46:12.516986  6613 solver.cpp:228] Iteration 47200, loss = 0.128519
I0422 11:46:12.517129  6613 solver.cpp:244]     Train net output #0: loss = 0.128519 (* 1 = 0.128519 loss)
I0422 11:46:12.517138  6613 sgd_solver.cpp:106] Iteration 47200, lr = 1e-05
I0422 11:47:49.750761  6613 solver.cpp:228] Iteration 47300, loss = 0.100242
I0422 11:47:49.750900  6613 solver.cpp:244]     Train net output #0: loss = 0.100242 (* 1 = 0.100242 loss)
I0422 11:47:49.750908  6613 sgd_solver.cpp:106] Iteration 47300, lr = 1e-05
I0422 11:49:26.806077  6613 solver.cpp:228] Iteration 47400, loss = 0.118949
I0422 11:49:26.806223  6613 solver.cpp:244]     Train net output #0: loss = 0.118949 (* 1 = 0.118949 loss)
I0422 11:49:26.806231  6613 sgd_solver.cpp:106] Iteration 47400, lr = 1e-05
I0422 11:51:03.436601  6613 solver.cpp:228] Iteration 47500, loss = 0.116323
I0422 11:51:03.436744  6613 solver.cpp:244]     Train net output #0: loss = 0.116323 (* 1 = 0.116323 loss)
I0422 11:51:03.436753  6613 sgd_solver.cpp:106] Iteration 47500, lr = 1e-05
I0422 11:52:40.196576  6613 solver.cpp:228] Iteration 47600, loss = 0.106333
I0422 11:52:40.196732  6613 solver.cpp:244]     Train net output #0: loss = 0.106333 (* 1 = 0.106333 loss)
I0422 11:52:40.196740  6613 sgd_solver.cpp:106] Iteration 47600, lr = 1e-05
I0422 11:54:17.168325  6613 solver.cpp:228] Iteration 47700, loss = 0.111097
I0422 11:54:17.168467  6613 solver.cpp:244]     Train net output #0: loss = 0.111097 (* 1 = 0.111097 loss)
I0422 11:54:17.168474  6613 sgd_solver.cpp:106] Iteration 47700, lr = 1e-05
I0422 11:55:52.544347  6613 solver.cpp:228] Iteration 47800, loss = 0.107915
I0422 11:55:52.544476  6613 solver.cpp:244]     Train net output #0: loss = 0.107915 (* 1 = 0.107915 loss)
I0422 11:55:52.544482  6613 sgd_solver.cpp:106] Iteration 47800, lr = 1e-05
I0422 11:57:29.745627  6613 solver.cpp:228] Iteration 47900, loss = 0.106482
I0422 11:57:29.745769  6613 solver.cpp:244]     Train net output #0: loss = 0.106482 (* 1 = 0.106482 loss)
I0422 11:57:29.745776  6613 sgd_solver.cpp:106] Iteration 47900, lr = 1e-05
I0422 11:59:06.799628  6613 solver.cpp:337] Iteration 48000, Testing net (#0)
I0422 11:59:06.799767  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 11:59:06.799772  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 11:59:06.799777  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 11:59:06.799792  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 11:59:06.799793  6613 net.cpp:693] Ignoring source layer visualize
I0422 11:59:06.799796  6613 net.cpp:693] Ignoring source layer fake
I0422 12:02:27.480762  6613 solver.cpp:404]     Test net output #0: loss = 0.119658 (* 1 = 0.119658 loss)
I0422 12:02:28.107802  6613 solver.cpp:228] Iteration 48000, loss = 0.137137
I0422 12:02:28.107841  6613 solver.cpp:244]     Train net output #0: loss = 0.137137 (* 1 = 0.137137 loss)
I0422 12:02:28.107848  6613 sgd_solver.cpp:106] Iteration 48000, lr = 1e-05
I0422 12:04:05.821759  6613 solver.cpp:228] Iteration 48100, loss = 0.161366
I0422 12:04:05.821897  6613 solver.cpp:244]     Train net output #0: loss = 0.161366 (* 1 = 0.161366 loss)
I0422 12:04:05.821904  6613 sgd_solver.cpp:106] Iteration 48100, lr = 1e-05
I0422 12:05:41.446660  6613 solver.cpp:228] Iteration 48200, loss = 0.131089
I0422 12:05:41.446795  6613 solver.cpp:244]     Train net output #0: loss = 0.131089 (* 1 = 0.131089 loss)
I0422 12:05:41.446801  6613 sgd_solver.cpp:106] Iteration 48200, lr = 1e-05
I0422 12:07:19.501763  6613 solver.cpp:228] Iteration 48300, loss = 0.0994642
I0422 12:07:19.501911  6613 solver.cpp:244]     Train net output #0: loss = 0.0994642 (* 1 = 0.0994642 loss)
I0422 12:07:19.501919  6613 sgd_solver.cpp:106] Iteration 48300, lr = 1e-05
I0422 12:08:57.588842  6613 solver.cpp:228] Iteration 48400, loss = 0.121923
I0422 12:08:57.588986  6613 solver.cpp:244]     Train net output #0: loss = 0.121923 (* 1 = 0.121923 loss)
I0422 12:08:57.588994  6613 sgd_solver.cpp:106] Iteration 48400, lr = 1e-05
I0422 12:10:35.369180  6613 solver.cpp:228] Iteration 48500, loss = 0.0981009
I0422 12:10:35.369362  6613 solver.cpp:244]     Train net output #0: loss = 0.0981009 (* 1 = 0.0981009 loss)
I0422 12:10:35.369370  6613 sgd_solver.cpp:106] Iteration 48500, lr = 1e-05
I0422 12:12:10.695211  6613 solver.cpp:228] Iteration 48600, loss = 0.0925181
I0422 12:12:10.695355  6613 solver.cpp:244]     Train net output #0: loss = 0.0925181 (* 1 = 0.0925181 loss)
I0422 12:12:10.695363  6613 sgd_solver.cpp:106] Iteration 48600, lr = 1e-05
I0422 12:13:47.690506  6613 solver.cpp:228] Iteration 48700, loss = 0.0882349
I0422 12:13:47.690640  6613 solver.cpp:244]     Train net output #0: loss = 0.0882349 (* 1 = 0.0882349 loss)
I0422 12:13:47.690649  6613 sgd_solver.cpp:106] Iteration 48700, lr = 1e-05
I0422 12:15:24.309512  6613 solver.cpp:228] Iteration 48800, loss = 0.108765
I0422 12:15:24.309633  6613 solver.cpp:244]     Train net output #0: loss = 0.108765 (* 1 = 0.108765 loss)
I0422 12:15:24.309640  6613 sgd_solver.cpp:106] Iteration 48800, lr = 1e-05
I0422 12:17:00.989663  6613 solver.cpp:228] Iteration 48900, loss = 0.119585
I0422 12:17:00.989790  6613 solver.cpp:244]     Train net output #0: loss = 0.119585 (* 1 = 0.119585 loss)
I0422 12:17:00.989812  6613 sgd_solver.cpp:106] Iteration 48900, lr = 1e-05
I0422 12:18:36.944733  6613 solver.cpp:337] Iteration 49000, Testing net (#0)
I0422 12:18:36.944885  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 12:18:36.944890  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 12:18:36.944893  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 12:18:36.944908  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 12:18:36.944911  6613 net.cpp:693] Ignoring source layer visualize
I0422 12:18:36.944913  6613 net.cpp:693] Ignoring source layer fake
I0422 12:21:57.862373  6613 solver.cpp:404]     Test net output #0: loss = 0.123539 (* 1 = 0.123539 loss)
I0422 12:21:58.489141  6613 solver.cpp:228] Iteration 49000, loss = 0.0985414
I0422 12:21:58.489161  6613 solver.cpp:244]     Train net output #0: loss = 0.0985414 (* 1 = 0.0985414 loss)
I0422 12:21:58.489182  6613 sgd_solver.cpp:106] Iteration 49000, lr = 1e-05
I0422 12:23:35.904232  6613 solver.cpp:228] Iteration 49100, loss = 0.211243
I0422 12:23:35.904383  6613 solver.cpp:244]     Train net output #0: loss = 0.211243 (* 1 = 0.211243 loss)
I0422 12:23:35.904392  6613 sgd_solver.cpp:106] Iteration 49100, lr = 1e-05
I0422 12:25:13.399580  6613 solver.cpp:228] Iteration 49200, loss = 0.0879692
I0422 12:25:13.399720  6613 solver.cpp:244]     Train net output #0: loss = 0.0879692 (* 1 = 0.0879692 loss)
I0422 12:25:13.399727  6613 sgd_solver.cpp:106] Iteration 49200, lr = 1e-05
I0422 12:26:48.772068  6613 solver.cpp:228] Iteration 49300, loss = 0.093903
I0422 12:26:48.772207  6613 solver.cpp:244]     Train net output #0: loss = 0.093903 (* 1 = 0.093903 loss)
I0422 12:26:48.772213  6613 sgd_solver.cpp:106] Iteration 49300, lr = 1e-05
I0422 12:28:26.000658  6613 solver.cpp:228] Iteration 49400, loss = 0.12868
I0422 12:28:26.000779  6613 solver.cpp:244]     Train net output #0: loss = 0.12868 (* 1 = 0.12868 loss)
I0422 12:28:26.000787  6613 sgd_solver.cpp:106] Iteration 49400, lr = 1e-05
I0422 12:30:03.288889  6613 solver.cpp:228] Iteration 49500, loss = 0.134204
I0422 12:30:03.289021  6613 solver.cpp:244]     Train net output #0: loss = 0.134204 (* 1 = 0.134204 loss)
I0422 12:30:03.289029  6613 sgd_solver.cpp:106] Iteration 49500, lr = 1e-05
I0422 12:31:38.648833  6613 solver.cpp:228] Iteration 49600, loss = 0.108739
I0422 12:31:38.648990  6613 solver.cpp:244]     Train net output #0: loss = 0.108739 (* 1 = 0.108739 loss)
I0422 12:31:38.648999  6613 sgd_solver.cpp:106] Iteration 49600, lr = 1e-05
I0422 12:33:15.847982  6613 solver.cpp:228] Iteration 49700, loss = 0.0803816
I0422 12:33:15.848130  6613 solver.cpp:244]     Train net output #0: loss = 0.0803816 (* 1 = 0.0803816 loss)
I0422 12:33:15.848137  6613 sgd_solver.cpp:106] Iteration 49700, lr = 1e-05
I0422 12:34:53.093605  6613 solver.cpp:228] Iteration 49800, loss = 0.0939729
I0422 12:34:53.093781  6613 solver.cpp:244]     Train net output #0: loss = 0.0939729 (* 1 = 0.0939729 loss)
I0422 12:34:53.093788  6613 sgd_solver.cpp:106] Iteration 49800, lr = 1e-05
I0422 12:36:30.676398  6613 solver.cpp:228] Iteration 49900, loss = 0.101137
I0422 12:36:30.676547  6613 solver.cpp:244]     Train net output #0: loss = 0.101137 (* 1 = 0.101137 loss)
I0422 12:36:30.676554  6613 sgd_solver.cpp:106] Iteration 49900, lr = 1e-05
I0422 12:38:06.576032  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_50000.caffemodel
I0422 12:38:14.213313  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_50000.solverstate
I0422 12:38:14.411866  6613 solver.cpp:337] Iteration 50000, Testing net (#0)
I0422 12:38:14.411907  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 12:38:14.411909  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 12:38:14.411913  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 12:38:14.411927  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 12:38:14.411931  6613 net.cpp:693] Ignoring source layer visualize
I0422 12:38:14.411932  6613 net.cpp:693] Ignoring source layer fake
I0422 12:41:34.842887  6613 solver.cpp:404]     Test net output #0: loss = 0.115224 (* 1 = 0.115224 loss)
I0422 12:41:35.473196  6613 solver.cpp:228] Iteration 50000, loss = 0.105092
I0422 12:41:35.473217  6613 solver.cpp:244]     Train net output #0: loss = 0.105092 (* 1 = 0.105092 loss)
I0422 12:41:35.473237  6613 sgd_solver.cpp:106] Iteration 50000, lr = 1e-05
I0422 12:43:12.807343  6613 solver.cpp:228] Iteration 50100, loss = 0.1758
I0422 12:43:12.807495  6613 solver.cpp:244]     Train net output #0: loss = 0.1758 (* 1 = 0.1758 loss)
I0422 12:43:12.807503  6613 sgd_solver.cpp:106] Iteration 50100, lr = 1e-05
I0422 12:44:50.379894  6613 solver.cpp:228] Iteration 50200, loss = 0.0418392
I0422 12:44:50.380035  6613 solver.cpp:244]     Train net output #0: loss = 0.0418392 (* 1 = 0.0418392 loss)
I0422 12:44:50.380043  6613 sgd_solver.cpp:106] Iteration 50200, lr = 1e-05
I0422 12:46:25.744670  6613 solver.cpp:228] Iteration 50300, loss = 0.147718
I0422 12:46:25.744802  6613 solver.cpp:244]     Train net output #0: loss = 0.147718 (* 1 = 0.147718 loss)
I0422 12:46:25.744808  6613 sgd_solver.cpp:106] Iteration 50300, lr = 1e-05
I0422 12:48:03.416090  6613 solver.cpp:228] Iteration 50400, loss = 0.127239
I0422 12:48:03.416235  6613 solver.cpp:244]     Train net output #0: loss = 0.127239 (* 1 = 0.127239 loss)
I0422 12:48:03.416242  6613 sgd_solver.cpp:106] Iteration 50400, lr = 1e-05
I0422 12:49:41.283447  6613 solver.cpp:228] Iteration 50500, loss = 0.0873466
I0422 12:49:41.284457  6613 solver.cpp:244]     Train net output #0: loss = 0.0873466 (* 1 = 0.0873466 loss)
I0422 12:49:41.284471  6613 sgd_solver.cpp:106] Iteration 50500, lr = 1e-05
I0422 12:51:18.623371  6613 solver.cpp:228] Iteration 50600, loss = 0.0908729
I0422 12:51:18.623515  6613 solver.cpp:244]     Train net output #0: loss = 0.0908729 (* 1 = 0.0908729 loss)
I0422 12:51:18.623522  6613 sgd_solver.cpp:106] Iteration 50600, lr = 1e-05
I0422 12:52:53.998812  6613 solver.cpp:228] Iteration 50700, loss = 0.0991224
I0422 12:52:53.998967  6613 solver.cpp:244]     Train net output #0: loss = 0.0991224 (* 1 = 0.0991224 loss)
I0422 12:52:53.998975  6613 sgd_solver.cpp:106] Iteration 50700, lr = 1e-05
I0422 12:54:31.472589  6613 solver.cpp:228] Iteration 50800, loss = 0.0775553
I0422 12:54:31.472738  6613 solver.cpp:244]     Train net output #0: loss = 0.0775553 (* 1 = 0.0775553 loss)
I0422 12:54:31.472745  6613 sgd_solver.cpp:106] Iteration 50800, lr = 1e-05
I0422 12:56:08.675340  6613 solver.cpp:228] Iteration 50900, loss = 0.0799868
I0422 12:56:08.675503  6613 solver.cpp:244]     Train net output #0: loss = 0.0799868 (* 1 = 0.0799868 loss)
I0422 12:56:08.675511  6613 sgd_solver.cpp:106] Iteration 50900, lr = 1e-05
I0422 12:57:44.941421  6613 solver.cpp:337] Iteration 51000, Testing net (#0)
I0422 12:57:44.941601  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 12:57:44.941606  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 12:57:44.941611  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 12:57:44.941625  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 12:57:44.941627  6613 net.cpp:693] Ignoring source layer visualize
I0422 12:57:44.941629  6613 net.cpp:693] Ignoring source layer fake
I0422 13:01:05.992810  6613 solver.cpp:404]     Test net output #0: loss = 0.116182 (* 1 = 0.116182 loss)
I0422 13:01:06.616632  6613 solver.cpp:228] Iteration 51000, loss = 0.101973
I0422 13:01:06.616667  6613 solver.cpp:244]     Train net output #0: loss = 0.101973 (* 1 = 0.101973 loss)
I0422 13:01:06.616673  6613 sgd_solver.cpp:106] Iteration 51000, lr = 1e-05
I0422 13:02:42.208431  6613 solver.cpp:228] Iteration 51100, loss = 0.113381
I0422 13:02:42.208577  6613 solver.cpp:244]     Train net output #0: loss = 0.113381 (* 1 = 0.113381 loss)
I0422 13:02:42.208585  6613 sgd_solver.cpp:106] Iteration 51100, lr = 1e-05
I0422 13:04:19.707007  6613 solver.cpp:228] Iteration 51200, loss = 0.0763857
I0422 13:04:19.707147  6613 solver.cpp:244]     Train net output #0: loss = 0.0763857 (* 1 = 0.0763857 loss)
I0422 13:04:19.707154  6613 sgd_solver.cpp:106] Iteration 51200, lr = 1e-05
I0422 13:05:56.687600  6613 solver.cpp:228] Iteration 51300, loss = 0.0830457
I0422 13:05:56.687747  6613 solver.cpp:244]     Train net output #0: loss = 0.0830457 (* 1 = 0.0830457 loss)
I0422 13:05:56.687757  6613 sgd_solver.cpp:106] Iteration 51300, lr = 1e-05
I0422 13:07:33.495748  6613 solver.cpp:228] Iteration 51400, loss = 0.12305
I0422 13:07:33.495903  6613 solver.cpp:244]     Train net output #0: loss = 0.12305 (* 1 = 0.12305 loss)
I0422 13:07:33.495910  6613 sgd_solver.cpp:106] Iteration 51400, lr = 1e-05
I0422 13:09:10.483026  6613 solver.cpp:228] Iteration 51500, loss = 0.0852214
I0422 13:09:10.483177  6613 solver.cpp:244]     Train net output #0: loss = 0.0852214 (* 1 = 0.0852214 loss)
I0422 13:09:10.483186  6613 sgd_solver.cpp:106] Iteration 51500, lr = 1e-05
I0422 13:10:47.819368  6613 solver.cpp:228] Iteration 51600, loss = 0.174073
I0422 13:10:47.819530  6613 solver.cpp:244]     Train net output #0: loss = 0.174073 (* 1 = 0.174073 loss)
I0422 13:10:47.819537  6613 sgd_solver.cpp:106] Iteration 51600, lr = 1e-05
I0422 13:12:29.139036  6613 solver.cpp:228] Iteration 51700, loss = 0.134604
I0422 13:12:29.139185  6613 solver.cpp:244]     Train net output #0: loss = 0.134604 (* 1 = 0.134604 loss)
I0422 13:12:29.139194  6613 sgd_solver.cpp:106] Iteration 51700, lr = 1e-05
I0422 13:14:04.508863  6613 solver.cpp:228] Iteration 51800, loss = 0.132258
I0422 13:14:04.509008  6613 solver.cpp:244]     Train net output #0: loss = 0.132258 (* 1 = 0.132258 loss)
I0422 13:14:04.509016  6613 sgd_solver.cpp:106] Iteration 51800, lr = 1e-05
I0422 13:15:57.433470  6613 solver.cpp:228] Iteration 51900, loss = 0.190725
I0422 13:15:57.433610  6613 solver.cpp:244]     Train net output #0: loss = 0.190725 (* 1 = 0.190725 loss)
I0422 13:15:57.433617  6613 sgd_solver.cpp:106] Iteration 51900, lr = 1e-05
I0422 13:17:35.099438  6613 solver.cpp:337] Iteration 52000, Testing net (#0)
I0422 13:17:35.099581  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 13:17:35.099586  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 13:17:35.099589  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 13:17:35.099604  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 13:17:35.099607  6613 net.cpp:693] Ignoring source layer visualize
I0422 13:17:35.099609  6613 net.cpp:693] Ignoring source layer fake
I0422 13:20:56.190352  6613 solver.cpp:404]     Test net output #0: loss = 0.149386 (* 1 = 0.149386 loss)
I0422 13:20:56.820755  6613 solver.cpp:228] Iteration 52000, loss = 0.0986208
I0422 13:20:56.820775  6613 solver.cpp:244]     Train net output #0: loss = 0.0986208 (* 1 = 0.0986208 loss)
I0422 13:20:56.820796  6613 sgd_solver.cpp:106] Iteration 52000, lr = 1e-05
I0422 13:22:32.440186  6613 solver.cpp:228] Iteration 52100, loss = 0.121569
I0422 13:22:32.440359  6613 solver.cpp:244]     Train net output #0: loss = 0.121569 (* 1 = 0.121569 loss)
I0422 13:22:32.440368  6613 sgd_solver.cpp:106] Iteration 52100, lr = 1e-05
I0422 13:24:09.722581  6613 solver.cpp:228] Iteration 52200, loss = 0.0955914
I0422 13:24:09.722736  6613 solver.cpp:244]     Train net output #0: loss = 0.0955914 (* 1 = 0.0955914 loss)
I0422 13:24:09.722744  6613 sgd_solver.cpp:106] Iteration 52200, lr = 1e-05
I0422 13:25:47.040525  6613 solver.cpp:228] Iteration 52300, loss = 0.0857752
I0422 13:25:47.040685  6613 solver.cpp:244]     Train net output #0: loss = 0.0857752 (* 1 = 0.0857752 loss)
I0422 13:25:47.040693  6613 sgd_solver.cpp:106] Iteration 52300, lr = 1e-05
I0422 13:27:24.155656  6613 solver.cpp:228] Iteration 52400, loss = 0.181522
I0422 13:27:24.157199  6613 solver.cpp:244]     Train net output #0: loss = 0.181522 (* 1 = 0.181522 loss)
I0422 13:27:24.157222  6613 sgd_solver.cpp:106] Iteration 52400, lr = 1e-05
I0422 13:29:00.828940  6613 solver.cpp:228] Iteration 52500, loss = 0.0822086
I0422 13:29:00.829553  6613 solver.cpp:244]     Train net output #0: loss = 0.0822086 (* 1 = 0.0822086 loss)
I0422 13:29:00.829576  6613 sgd_solver.cpp:106] Iteration 52500, lr = 1e-05
I0422 13:30:37.612069  6613 solver.cpp:228] Iteration 52600, loss = 0.159096
I0422 13:30:37.612234  6613 solver.cpp:244]     Train net output #0: loss = 0.159096 (* 1 = 0.159096 loss)
I0422 13:30:37.612242  6613 sgd_solver.cpp:106] Iteration 52600, lr = 1e-05
I0422 13:32:14.991899  6613 solver.cpp:228] Iteration 52700, loss = 0.157555
I0422 13:32:14.992053  6613 solver.cpp:244]     Train net output #0: loss = 0.157555 (* 1 = 0.157555 loss)
I0422 13:32:14.992061  6613 sgd_solver.cpp:106] Iteration 52700, lr = 1e-05
I0422 13:33:50.357009  6613 solver.cpp:228] Iteration 52800, loss = 0.156312
I0422 13:33:50.357156  6613 solver.cpp:244]     Train net output #0: loss = 0.156312 (* 1 = 0.156312 loss)
I0422 13:33:50.357163  6613 sgd_solver.cpp:106] Iteration 52800, lr = 1e-05
I0422 13:35:27.682761  6613 solver.cpp:228] Iteration 52900, loss = 0.175589
I0422 13:35:27.682916  6613 solver.cpp:244]     Train net output #0: loss = 0.175589 (* 1 = 0.175589 loss)
I0422 13:35:27.682924  6613 sgd_solver.cpp:106] Iteration 52900, lr = 1e-05
I0422 13:37:04.754257  6613 solver.cpp:337] Iteration 53000, Testing net (#0)
I0422 13:37:04.754405  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 13:37:04.754410  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 13:37:04.754415  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 13:37:04.754428  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 13:37:04.754431  6613 net.cpp:693] Ignoring source layer visualize
I0422 13:37:04.754433  6613 net.cpp:693] Ignoring source layer fake
I0422 13:40:25.458267  6613 solver.cpp:404]     Test net output #0: loss = 0.119595 (* 1 = 0.119595 loss)
I0422 13:40:26.085515  6613 solver.cpp:228] Iteration 53000, loss = 0.101165
I0422 13:40:26.085561  6613 solver.cpp:244]     Train net output #0: loss = 0.101165 (* 1 = 0.101165 loss)
I0422 13:40:26.085567  6613 sgd_solver.cpp:106] Iteration 53000, lr = 1e-05
I0422 13:42:03.564165  6613 solver.cpp:228] Iteration 53100, loss = 0.124975
I0422 13:42:03.564317  6613 solver.cpp:244]     Train net output #0: loss = 0.124975 (* 1 = 0.124975 loss)
I0422 13:42:03.564326  6613 sgd_solver.cpp:106] Iteration 53100, lr = 1e-05
I0422 13:43:39.157742  6613 solver.cpp:228] Iteration 53200, loss = 0.153515
I0422 13:43:39.157896  6613 solver.cpp:244]     Train net output #0: loss = 0.153515 (* 1 = 0.153515 loss)
I0422 13:43:39.157903  6613 sgd_solver.cpp:106] Iteration 53200, lr = 1e-05
I0422 13:45:16.418108  6613 solver.cpp:228] Iteration 53300, loss = 0.0868752
I0422 13:45:16.418254  6613 solver.cpp:244]     Train net output #0: loss = 0.0868752 (* 1 = 0.0868752 loss)
I0422 13:45:16.418262  6613 sgd_solver.cpp:106] Iteration 53300, lr = 1e-05
I0422 13:46:53.541749  6613 solver.cpp:228] Iteration 53400, loss = 0.0766374
I0422 13:46:53.541929  6613 solver.cpp:244]     Train net output #0: loss = 0.0766374 (* 1 = 0.0766374 loss)
I0422 13:46:53.541935  6613 sgd_solver.cpp:106] Iteration 53400, lr = 1e-05
I0422 13:48:30.668782  6613 solver.cpp:228] Iteration 53500, loss = 0.0954176
I0422 13:48:30.668931  6613 solver.cpp:244]     Train net output #0: loss = 0.0954176 (* 1 = 0.0954176 loss)
I0422 13:48:30.668937  6613 sgd_solver.cpp:106] Iteration 53500, lr = 1e-05
I0422 13:50:05.998143  6613 solver.cpp:228] Iteration 53600, loss = 0.130717
I0422 13:50:05.998270  6613 solver.cpp:244]     Train net output #0: loss = 0.130717 (* 1 = 0.130717 loss)
I0422 13:50:05.998277  6613 sgd_solver.cpp:106] Iteration 53600, lr = 1e-05
I0422 13:51:42.971144  6613 solver.cpp:228] Iteration 53700, loss = 0.0735525
I0422 13:51:42.971294  6613 solver.cpp:244]     Train net output #0: loss = 0.0735525 (* 1 = 0.0735525 loss)
I0422 13:51:42.971302  6613 sgd_solver.cpp:106] Iteration 53700, lr = 1e-05
I0422 13:53:19.582839  6613 solver.cpp:228] Iteration 53800, loss = 0.131007
I0422 13:53:19.582984  6613 solver.cpp:244]     Train net output #0: loss = 0.131007 (* 1 = 0.131007 loss)
I0422 13:53:19.582991  6613 sgd_solver.cpp:106] Iteration 53800, lr = 1e-05
I0422 13:54:56.273725  6613 solver.cpp:228] Iteration 53900, loss = 0.114675
I0422 13:54:56.273876  6613 solver.cpp:244]     Train net output #0: loss = 0.114675 (* 1 = 0.114675 loss)
I0422 13:54:56.273882  6613 sgd_solver.cpp:106] Iteration 53900, lr = 1e-05
I0422 13:56:32.202481  6613 solver.cpp:337] Iteration 54000, Testing net (#0)
I0422 13:56:32.202618  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 13:56:32.202622  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 13:56:32.202626  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 13:56:32.202641  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 13:56:32.202644  6613 net.cpp:693] Ignoring source layer visualize
I0422 13:56:32.202646  6613 net.cpp:693] Ignoring source layer fake
I0422 13:59:52.978067  6613 solver.cpp:404]     Test net output #0: loss = 0.123639 (* 1 = 0.123639 loss)
I0422 13:59:53.604535  6613 solver.cpp:228] Iteration 54000, loss = 0.146095
I0422 13:59:53.604578  6613 solver.cpp:244]     Train net output #0: loss = 0.146095 (* 1 = 0.146095 loss)
I0422 13:59:53.604583  6613 sgd_solver.cpp:106] Iteration 54000, lr = 1e-05
I0422 14:01:30.965943  6613 solver.cpp:228] Iteration 54100, loss = 0.142326
I0422 14:01:30.966097  6613 solver.cpp:244]     Train net output #0: loss = 0.142326 (* 1 = 0.142326 loss)
I0422 14:01:30.966105  6613 sgd_solver.cpp:106] Iteration 54100, lr = 1e-05
I0422 14:03:08.405673  6613 solver.cpp:228] Iteration 54200, loss = 0.150195
I0422 14:03:08.405817  6613 solver.cpp:244]     Train net output #0: loss = 0.150195 (* 1 = 0.150195 loss)
I0422 14:03:08.405825  6613 sgd_solver.cpp:106] Iteration 54200, lr = 1e-05
I0422 14:04:43.785266  6613 solver.cpp:228] Iteration 54300, loss = 0.116159
I0422 14:04:43.785424  6613 solver.cpp:244]     Train net output #0: loss = 0.116159 (* 1 = 0.116159 loss)
I0422 14:04:43.785431  6613 sgd_solver.cpp:106] Iteration 54300, lr = 1e-05
I0422 14:06:21.040848  6613 solver.cpp:228] Iteration 54400, loss = 0.14054
I0422 14:06:21.040992  6613 solver.cpp:244]     Train net output #0: loss = 0.14054 (* 1 = 0.14054 loss)
I0422 14:06:21.040999  6613 sgd_solver.cpp:106] Iteration 54400, lr = 1e-05
I0422 14:07:58.289122  6613 solver.cpp:228] Iteration 54500, loss = 0.109421
I0422 14:07:58.289273  6613 solver.cpp:244]     Train net output #0: loss = 0.109421 (* 1 = 0.109421 loss)
I0422 14:07:58.289280  6613 sgd_solver.cpp:106] Iteration 54500, lr = 1e-05
I0422 14:09:33.686666  6613 solver.cpp:228] Iteration 54600, loss = 0.151714
I0422 14:09:33.686822  6613 solver.cpp:244]     Train net output #0: loss = 0.151714 (* 1 = 0.151714 loss)
I0422 14:09:33.686830  6613 sgd_solver.cpp:106] Iteration 54600, lr = 1e-05
I0422 14:11:10.845614  6613 solver.cpp:228] Iteration 54700, loss = 0.106384
I0422 14:11:10.845784  6613 solver.cpp:244]     Train net output #0: loss = 0.106384 (* 1 = 0.106384 loss)
I0422 14:11:10.845793  6613 sgd_solver.cpp:106] Iteration 54700, lr = 1e-05
I0422 14:12:48.042361  6613 solver.cpp:228] Iteration 54800, loss = 0.111309
I0422 14:12:48.043882  6613 solver.cpp:244]     Train net output #0: loss = 0.111309 (* 1 = 0.111309 loss)
I0422 14:12:48.043890  6613 sgd_solver.cpp:106] Iteration 54800, lr = 1e-05
I0422 14:14:25.509373  6613 solver.cpp:228] Iteration 54900, loss = 0.151641
I0422 14:14:25.509539  6613 solver.cpp:244]     Train net output #0: loss = 0.151641 (* 1 = 0.151641 loss)
I0422 14:14:25.509547  6613 sgd_solver.cpp:106] Iteration 54900, lr = 1e-05
I0422 14:16:01.842034  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_55000.caffemodel
I0422 14:16:10.816750  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_55000.solverstate
I0422 14:16:11.020495  6613 solver.cpp:337] Iteration 55000, Testing net (#0)
I0422 14:16:11.020539  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 14:16:11.020541  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 14:16:11.020545  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 14:16:11.020560  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 14:16:11.020562  6613 net.cpp:693] Ignoring source layer visualize
I0422 14:16:11.020565  6613 net.cpp:693] Ignoring source layer fake
I0422 14:19:31.390275  6613 solver.cpp:404]     Test net output #0: loss = 0.114608 (* 1 = 0.114608 loss)
I0422 14:19:32.022111  6613 solver.cpp:228] Iteration 55000, loss = 0.0952512
I0422 14:19:32.022150  6613 solver.cpp:244]     Train net output #0: loss = 0.0952512 (* 1 = 0.0952512 loss)
I0422 14:19:32.022156  6613 sgd_solver.cpp:106] Iteration 55000, lr = 1e-05
I0422 14:21:10.881638  6613 solver.cpp:228] Iteration 55100, loss = 0.156277
I0422 14:21:10.881814  6613 solver.cpp:244]     Train net output #0: loss = 0.156277 (* 1 = 0.156277 loss)
I0422 14:21:10.881821  6613 sgd_solver.cpp:106] Iteration 55100, lr = 1e-05
I0422 14:22:48.998754  6613 solver.cpp:228] Iteration 55200, loss = 0.177882
I0422 14:22:48.998914  6613 solver.cpp:244]     Train net output #0: loss = 0.177882 (* 1 = 0.177882 loss)
I0422 14:22:48.998921  6613 sgd_solver.cpp:106] Iteration 55200, lr = 1e-05
I0422 14:24:24.378620  6613 solver.cpp:228] Iteration 55300, loss = 0.0913791
I0422 14:24:24.378772  6613 solver.cpp:244]     Train net output #0: loss = 0.0913791 (* 1 = 0.0913791 loss)
I0422 14:24:24.378778  6613 sgd_solver.cpp:106] Iteration 55300, lr = 1e-05
I0422 14:26:01.600584  6613 solver.cpp:228] Iteration 55400, loss = 0.143352
I0422 14:26:01.600739  6613 solver.cpp:244]     Train net output #0: loss = 0.143352 (* 1 = 0.143352 loss)
I0422 14:26:01.600746  6613 sgd_solver.cpp:106] Iteration 55400, lr = 1e-05
I0422 14:27:38.961490  6613 solver.cpp:228] Iteration 55500, loss = 0.148586
I0422 14:27:38.961627  6613 solver.cpp:244]     Train net output #0: loss = 0.148586 (* 1 = 0.148586 loss)
I0422 14:27:38.961634  6613 sgd_solver.cpp:106] Iteration 55500, lr = 1e-05
I0422 14:29:16.290612  6613 solver.cpp:228] Iteration 55600, loss = 0.180132
I0422 14:29:16.290765  6613 solver.cpp:244]     Train net output #0: loss = 0.180132 (* 1 = 0.180132 loss)
I0422 14:29:16.290772  6613 sgd_solver.cpp:106] Iteration 55600, lr = 1e-05
I0422 14:30:51.677037  6613 solver.cpp:228] Iteration 55700, loss = 0.142102
I0422 14:30:51.677196  6613 solver.cpp:244]     Train net output #0: loss = 0.142102 (* 1 = 0.142102 loss)
I0422 14:30:51.677202  6613 sgd_solver.cpp:106] Iteration 55700, lr = 1e-05
I0422 14:32:28.921546  6613 solver.cpp:228] Iteration 55800, loss = 0.100734
I0422 14:32:28.921679  6613 solver.cpp:244]     Train net output #0: loss = 0.100734 (* 1 = 0.100734 loss)
I0422 14:32:28.921685  6613 sgd_solver.cpp:106] Iteration 55800, lr = 1e-05
I0422 14:34:06.064260  6613 solver.cpp:228] Iteration 55900, loss = 0.0926868
I0422 14:34:06.064409  6613 solver.cpp:244]     Train net output #0: loss = 0.0926868 (* 1 = 0.0926868 loss)
I0422 14:34:06.064416  6613 sgd_solver.cpp:106] Iteration 55900, lr = 1e-05
I0422 14:35:42.273346  6613 solver.cpp:337] Iteration 56000, Testing net (#0)
I0422 14:35:42.273494  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 14:35:42.273499  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 14:35:42.273504  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 14:35:42.273519  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 14:35:42.273520  6613 net.cpp:693] Ignoring source layer visualize
I0422 14:35:42.273522  6613 net.cpp:693] Ignoring source layer fake
I0422 14:39:03.320531  6613 solver.cpp:404]     Test net output #0: loss = 0.115847 (* 1 = 0.115847 loss)
I0422 14:39:03.950764  6613 solver.cpp:228] Iteration 56000, loss = 0.103759
I0422 14:39:03.950788  6613 solver.cpp:244]     Train net output #0: loss = 0.103759 (* 1 = 0.103759 loss)
I0422 14:39:03.950810  6613 sgd_solver.cpp:106] Iteration 56000, lr = 1e-05
I0422 14:40:39.560809  6613 solver.cpp:228] Iteration 56100, loss = 0.108649
I0422 14:40:39.560956  6613 solver.cpp:244]     Train net output #0: loss = 0.108649 (* 1 = 0.108649 loss)
I0422 14:40:39.560961  6613 sgd_solver.cpp:106] Iteration 56100, lr = 1e-05
I0422 14:42:17.566390  6613 solver.cpp:228] Iteration 56200, loss = 0.0887837
I0422 14:42:17.566530  6613 solver.cpp:244]     Train net output #0: loss = 0.0887837 (* 1 = 0.0887837 loss)
I0422 14:42:17.566537  6613 sgd_solver.cpp:106] Iteration 56200, lr = 1e-05
I0422 14:43:54.448916  6613 solver.cpp:228] Iteration 56300, loss = 0.131002
I0422 14:43:54.449057  6613 solver.cpp:244]     Train net output #0: loss = 0.131002 (* 1 = 0.131002 loss)
I0422 14:43:54.449065  6613 sgd_solver.cpp:106] Iteration 56300, lr = 1e-05
I0422 14:45:31.455209  6613 solver.cpp:228] Iteration 56400, loss = 0.0953578
I0422 14:45:31.455343  6613 solver.cpp:244]     Train net output #0: loss = 0.0953578 (* 1 = 0.0953578 loss)
I0422 14:45:31.455349  6613 sgd_solver.cpp:106] Iteration 56400, lr = 1e-05
I0422 14:47:08.968873  6613 solver.cpp:228] Iteration 56500, loss = 0.139736
I0422 14:47:08.969023  6613 solver.cpp:244]     Train net output #0: loss = 0.139736 (* 1 = 0.139736 loss)
I0422 14:47:08.969030  6613 sgd_solver.cpp:106] Iteration 56500, lr = 1e-05
I0422 14:48:47.090456  6613 solver.cpp:228] Iteration 56600, loss = 0.128707
I0422 14:48:47.090606  6613 solver.cpp:244]     Train net output #0: loss = 0.128707 (* 1 = 0.128707 loss)
I0422 14:48:47.090613  6613 sgd_solver.cpp:106] Iteration 56600, lr = 1e-05
I0422 14:50:25.547786  6613 solver.cpp:228] Iteration 56700, loss = 0.129188
I0422 14:50:25.547933  6613 solver.cpp:244]     Train net output #0: loss = 0.129188 (* 1 = 0.129188 loss)
I0422 14:50:25.547942  6613 sgd_solver.cpp:106] Iteration 56700, lr = 1e-05
I0422 14:52:00.932579  6613 solver.cpp:228] Iteration 56800, loss = 0.0956515
I0422 14:52:00.932716  6613 solver.cpp:244]     Train net output #0: loss = 0.0956515 (* 1 = 0.0956515 loss)
I0422 14:52:00.932723  6613 sgd_solver.cpp:106] Iteration 56800, lr = 1e-05
I0422 14:53:38.958353  6613 solver.cpp:228] Iteration 56900, loss = 0.115785
I0422 14:53:38.958523  6613 solver.cpp:244]     Train net output #0: loss = 0.115785 (* 1 = 0.115785 loss)
I0422 14:53:38.958531  6613 sgd_solver.cpp:106] Iteration 56900, lr = 1e-05
I0422 14:55:15.327579  6613 solver.cpp:337] Iteration 57000, Testing net (#0)
I0422 14:55:15.327710  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 14:55:15.327714  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 14:55:15.327718  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 14:55:15.327733  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 14:55:15.327736  6613 net.cpp:693] Ignoring source layer visualize
I0422 14:55:15.327739  6613 net.cpp:693] Ignoring source layer fake
I0422 14:58:36.637898  6613 solver.cpp:404]     Test net output #0: loss = 0.149057 (* 1 = 0.149057 loss)
I0422 14:58:37.271947  6613 solver.cpp:228] Iteration 57000, loss = 0.113453
I0422 14:58:37.271975  6613 solver.cpp:244]     Train net output #0: loss = 0.113453 (* 1 = 0.113453 loss)
I0422 14:58:37.271981  6613 sgd_solver.cpp:106] Iteration 57000, lr = 1e-05
I0422 15:00:12.891113  6613 solver.cpp:228] Iteration 57100, loss = 0.107023
I0422 15:00:12.891260  6613 solver.cpp:244]     Train net output #0: loss = 0.107023 (* 1 = 0.107023 loss)
I0422 15:00:12.891268  6613 sgd_solver.cpp:106] Iteration 57100, lr = 1e-05
I0422 15:01:50.675479  6613 solver.cpp:228] Iteration 57200, loss = 0.0685589
I0422 15:01:50.675626  6613 solver.cpp:244]     Train net output #0: loss = 0.0685589 (* 1 = 0.0685589 loss)
I0422 15:01:50.675633  6613 sgd_solver.cpp:106] Iteration 57200, lr = 1e-05
I0422 15:03:28.726604  6613 solver.cpp:228] Iteration 57300, loss = 0.142011
I0422 15:03:28.726745  6613 solver.cpp:244]     Train net output #0: loss = 0.142011 (* 1 = 0.142011 loss)
I0422 15:03:28.726753  6613 sgd_solver.cpp:106] Iteration 57300, lr = 1e-05
I0422 15:05:06.335405  6613 solver.cpp:228] Iteration 57400, loss = 0.0633499
I0422 15:05:06.335935  6613 solver.cpp:244]     Train net output #0: loss = 0.0633499 (* 1 = 0.0633499 loss)
I0422 15:05:06.335943  6613 sgd_solver.cpp:106] Iteration 57400, lr = 1e-05
I0422 15:06:43.411214  6613 solver.cpp:228] Iteration 57500, loss = 0.11232
I0422 15:06:43.411360  6613 solver.cpp:244]     Train net output #0: loss = 0.11232 (* 1 = 0.11232 loss)
I0422 15:06:43.411367  6613 sgd_solver.cpp:106] Iteration 57500, lr = 1e-05
I0422 15:08:20.354351  6613 solver.cpp:228] Iteration 57600, loss = 0.167092
I0422 15:08:20.354501  6613 solver.cpp:244]     Train net output #0: loss = 0.167092 (* 1 = 0.167092 loss)
I0422 15:08:20.354508  6613 sgd_solver.cpp:106] Iteration 57600, lr = 1e-05
I0422 15:09:57.815912  6613 solver.cpp:228] Iteration 57700, loss = 0.0521386
I0422 15:09:57.816085  6613 solver.cpp:244]     Train net output #0: loss = 0.0521386 (* 1 = 0.0521386 loss)
I0422 15:09:57.816093  6613 sgd_solver.cpp:106] Iteration 57700, lr = 1e-05
I0422 15:11:33.416182  6613 solver.cpp:228] Iteration 57800, loss = 0.100514
I0422 15:11:33.416576  6613 solver.cpp:244]     Train net output #0: loss = 0.100514 (* 1 = 0.100514 loss)
I0422 15:11:33.416582  6613 sgd_solver.cpp:106] Iteration 57800, lr = 1e-05
I0422 15:13:10.846822  6613 solver.cpp:228] Iteration 57900, loss = 0.0856187
I0422 15:13:10.846984  6613 solver.cpp:244]     Train net output #0: loss = 0.0856187 (* 1 = 0.0856187 loss)
I0422 15:13:10.846993  6613 sgd_solver.cpp:106] Iteration 57900, lr = 1e-05
I0422 15:14:47.568014  6613 solver.cpp:337] Iteration 58000, Testing net (#0)
I0422 15:14:47.568140  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 15:14:47.568143  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 15:14:47.568147  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 15:14:47.568166  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 15:14:47.568169  6613 net.cpp:693] Ignoring source layer visualize
I0422 15:14:47.568171  6613 net.cpp:693] Ignoring source layer fake
I0422 15:18:08.405591  6613 solver.cpp:404]     Test net output #0: loss = 0.119501 (* 1 = 0.119501 loss)
I0422 15:18:09.036257  6613 solver.cpp:228] Iteration 58000, loss = 0.110712
I0422 15:18:09.036274  6613 solver.cpp:244]     Train net output #0: loss = 0.110712 (* 1 = 0.110712 loss)
I0422 15:18:09.036296  6613 sgd_solver.cpp:106] Iteration 58000, lr = 1e-05
I0422 15:19:49.753118  6613 solver.cpp:228] Iteration 58100, loss = 0.121804
I0422 15:19:49.753291  6613 solver.cpp:244]     Train net output #0: loss = 0.121804 (* 1 = 0.121804 loss)
I0422 15:19:49.753298  6613 sgd_solver.cpp:106] Iteration 58100, lr = 1e-05
I0422 15:21:25.105800  6613 solver.cpp:228] Iteration 58200, loss = 0.0916183
I0422 15:21:25.105957  6613 solver.cpp:244]     Train net output #0: loss = 0.0916183 (* 1 = 0.0916183 loss)
I0422 15:21:25.105963  6613 sgd_solver.cpp:106] Iteration 58200, lr = 1e-05
I0422 15:23:02.555186  6613 solver.cpp:228] Iteration 58300, loss = 0.0932405
I0422 15:23:02.555347  6613 solver.cpp:244]     Train net output #0: loss = 0.0932405 (* 1 = 0.0932405 loss)
I0422 15:23:02.555356  6613 sgd_solver.cpp:106] Iteration 58300, lr = 1e-05
I0422 15:24:39.768172  6613 solver.cpp:228] Iteration 58400, loss = 0.0944471
I0422 15:24:39.768328  6613 solver.cpp:244]     Train net output #0: loss = 0.0944471 (* 1 = 0.0944471 loss)
I0422 15:24:39.768334  6613 sgd_solver.cpp:106] Iteration 58400, lr = 1e-05
I0422 15:26:16.988067  6613 solver.cpp:228] Iteration 58500, loss = 0.0910104
I0422 15:26:16.988225  6613 solver.cpp:244]     Train net output #0: loss = 0.0910104 (* 1 = 0.0910104 loss)
I0422 15:26:16.988232  6613 sgd_solver.cpp:106] Iteration 58500, lr = 1e-05
I0422 15:27:52.331586  6613 solver.cpp:228] Iteration 58600, loss = 0.0703795
I0422 15:27:52.331727  6613 solver.cpp:244]     Train net output #0: loss = 0.0703795 (* 1 = 0.0703795 loss)
I0422 15:27:52.331734  6613 sgd_solver.cpp:106] Iteration 58600, lr = 1e-05
I0422 15:29:29.326563  6613 solver.cpp:228] Iteration 58700, loss = 0.078057
I0422 15:29:29.326700  6613 solver.cpp:244]     Train net output #0: loss = 0.078057 (* 1 = 0.078057 loss)
I0422 15:29:29.326709  6613 sgd_solver.cpp:106] Iteration 58700, lr = 1e-05
I0422 15:31:06.015705  6613 solver.cpp:228] Iteration 58800, loss = 0.107872
I0422 15:31:06.015887  6613 solver.cpp:244]     Train net output #0: loss = 0.107872 (* 1 = 0.107872 loss)
I0422 15:31:06.015895  6613 sgd_solver.cpp:106] Iteration 58800, lr = 1e-05
I0422 15:32:42.723124  6613 solver.cpp:228] Iteration 58900, loss = 0.156064
I0422 15:32:42.723256  6613 solver.cpp:244]     Train net output #0: loss = 0.156064 (* 1 = 0.156064 loss)
I0422 15:32:42.723263  6613 sgd_solver.cpp:106] Iteration 58900, lr = 1e-05
I0422 15:34:18.746162  6613 solver.cpp:337] Iteration 59000, Testing net (#0)
I0422 15:34:18.746279  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 15:34:18.746284  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 15:34:18.746287  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 15:34:18.746302  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 15:34:18.746305  6613 net.cpp:693] Ignoring source layer visualize
I0422 15:34:18.746307  6613 net.cpp:693] Ignoring source layer fake
I0422 15:37:39.713320  6613 solver.cpp:404]     Test net output #0: loss = 0.123939 (* 1 = 0.123939 loss)
I0422 15:37:40.342411  6613 solver.cpp:228] Iteration 59000, loss = 0.100738
I0422 15:37:40.342430  6613 solver.cpp:244]     Train net output #0: loss = 0.100738 (* 1 = 0.100738 loss)
I0422 15:37:40.342453  6613 sgd_solver.cpp:106] Iteration 59000, lr = 1e-05
I0422 15:39:17.812541  6613 solver.cpp:228] Iteration 59100, loss = 0.155574
I0422 15:39:17.812700  6613 solver.cpp:244]     Train net output #0: loss = 0.155574 (* 1 = 0.155574 loss)
I0422 15:39:17.812708  6613 sgd_solver.cpp:106] Iteration 59100, lr = 1e-05
I0422 15:40:59.211356  6613 solver.cpp:228] Iteration 59200, loss = 0.122133
I0422 15:40:59.211520  6613 solver.cpp:244]     Train net output #0: loss = 0.122133 (* 1 = 0.122133 loss)
I0422 15:40:59.211527  6613 sgd_solver.cpp:106] Iteration 59200, lr = 1e-05
I0422 15:42:34.573668  6613 solver.cpp:228] Iteration 59300, loss = 0.132512
I0422 15:42:34.573812  6613 solver.cpp:244]     Train net output #0: loss = 0.132512 (* 1 = 0.132512 loss)
I0422 15:42:34.573819  6613 sgd_solver.cpp:106] Iteration 59300, lr = 1e-05
I0422 15:44:12.111493  6613 solver.cpp:228] Iteration 59400, loss = 0.154368
I0422 15:44:12.111630  6613 solver.cpp:244]     Train net output #0: loss = 0.154368 (* 1 = 0.154368 loss)
I0422 15:44:12.111637  6613 sgd_solver.cpp:106] Iteration 59400, lr = 1e-05
I0422 15:45:49.678470  6613 solver.cpp:228] Iteration 59500, loss = 0.0927355
I0422 15:45:49.678620  6613 solver.cpp:244]     Train net output #0: loss = 0.0927355 (* 1 = 0.0927355 loss)
I0422 15:45:49.678628  6613 sgd_solver.cpp:106] Iteration 59500, lr = 1e-05
I0422 15:47:26.891857  6613 solver.cpp:228] Iteration 59600, loss = 0.0976766
I0422 15:47:26.892041  6613 solver.cpp:244]     Train net output #0: loss = 0.0976766 (* 1 = 0.0976766 loss)
I0422 15:47:26.892050  6613 sgd_solver.cpp:106] Iteration 59600, lr = 1e-05
I0422 15:49:02.277617  6613 solver.cpp:228] Iteration 59700, loss = 0.0757699
I0422 15:49:02.277760  6613 solver.cpp:244]     Train net output #0: loss = 0.0757699 (* 1 = 0.0757699 loss)
I0422 15:49:02.277767  6613 sgd_solver.cpp:106] Iteration 59700, lr = 1e-05
I0422 15:50:39.425014  6613 solver.cpp:228] Iteration 59800, loss = 0.163772
I0422 15:50:39.425163  6613 solver.cpp:244]     Train net output #0: loss = 0.163772 (* 1 = 0.163772 loss)
I0422 15:50:39.425169  6613 sgd_solver.cpp:106] Iteration 59800, lr = 1e-05
I0422 15:52:16.454246  6613 solver.cpp:228] Iteration 59900, loss = 0.0664093
I0422 15:52:16.454422  6613 solver.cpp:244]     Train net output #0: loss = 0.0664093 (* 1 = 0.0664093 loss)
I0422 15:52:16.454432  6613 sgd_solver.cpp:106] Iteration 59900, lr = 1e-05
I0422 15:53:52.111918  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_60000.caffemodel
I0422 15:54:19.466071  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_60000.solverstate
I0422 15:54:19.652815  6613 solver.cpp:337] Iteration 60000, Testing net (#0)
I0422 15:54:19.652858  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 15:54:19.652861  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 15:54:19.652864  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 15:54:19.652878  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 15:54:19.652881  6613 net.cpp:693] Ignoring source layer visualize
I0422 15:54:19.652884  6613 net.cpp:693] Ignoring source layer fake
I0422 15:57:40.121798  6613 solver.cpp:404]     Test net output #0: loss = 0.114498 (* 1 = 0.114498 loss)
I0422 15:57:40.750169  6613 solver.cpp:228] Iteration 60000, loss = 0.08518
I0422 15:57:40.750188  6613 solver.cpp:244]     Train net output #0: loss = 0.08518 (* 1 = 0.08518 loss)
I0422 15:57:40.750211  6613 sgd_solver.cpp:106] Iteration 60000, lr = 1e-06
I0422 15:59:17.715481  6613 solver.cpp:228] Iteration 60100, loss = 0.140472
I0422 15:59:17.715627  6613 solver.cpp:244]     Train net output #0: loss = 0.140472 (* 1 = 0.140472 loss)
I0422 15:59:17.715634  6613 sgd_solver.cpp:106] Iteration 60100, lr = 1e-06
I0422 16:00:54.887564  6613 solver.cpp:228] Iteration 60200, loss = 0.0979485
I0422 16:00:54.887696  6613 solver.cpp:244]     Train net output #0: loss = 0.0979485 (* 1 = 0.0979485 loss)
I0422 16:00:54.887702  6613 sgd_solver.cpp:106] Iteration 60200, lr = 1e-06
I0422 16:02:30.473412  6613 solver.cpp:228] Iteration 60300, loss = 0.100345
I0422 16:02:30.473564  6613 solver.cpp:244]     Train net output #0: loss = 0.100345 (* 1 = 0.100345 loss)
I0422 16:02:30.473572  6613 sgd_solver.cpp:106] Iteration 60300, lr = 1e-06
I0422 16:04:07.829675  6613 solver.cpp:228] Iteration 60400, loss = 0.143942
I0422 16:04:07.829787  6613 solver.cpp:244]     Train net output #0: loss = 0.143942 (* 1 = 0.143942 loss)
I0422 16:04:07.829794  6613 sgd_solver.cpp:106] Iteration 60400, lr = 1e-06
I0422 16:05:45.296829  6613 solver.cpp:228] Iteration 60500, loss = 0.0936787
I0422 16:05:45.296959  6613 solver.cpp:244]     Train net output #0: loss = 0.0936787 (* 1 = 0.0936787 loss)
I0422 16:05:45.296967  6613 sgd_solver.cpp:106] Iteration 60500, lr = 1e-06
I0422 16:07:22.819504  6613 solver.cpp:228] Iteration 60600, loss = 0.127327
I0422 16:07:22.819630  6613 solver.cpp:244]     Train net output #0: loss = 0.127327 (* 1 = 0.127327 loss)
I0422 16:07:22.819638  6613 sgd_solver.cpp:106] Iteration 60600, lr = 1e-06
I0422 16:08:58.446625  6613 solver.cpp:228] Iteration 60700, loss = 0.146493
I0422 16:08:58.446753  6613 solver.cpp:244]     Train net output #0: loss = 0.146493 (* 1 = 0.146493 loss)
I0422 16:08:58.446761  6613 sgd_solver.cpp:106] Iteration 60700, lr = 1e-06
I0422 16:10:35.896886  6613 solver.cpp:228] Iteration 60800, loss = 0.0986889
I0422 16:10:35.897047  6613 solver.cpp:244]     Train net output #0: loss = 0.0986889 (* 1 = 0.0986889 loss)
I0422 16:10:35.897053  6613 sgd_solver.cpp:106] Iteration 60800, lr = 1e-06
I0422 16:12:13.295707  6613 solver.cpp:228] Iteration 60900, loss = 0.0823654
I0422 16:12:13.295846  6613 solver.cpp:244]     Train net output #0: loss = 0.0823654 (* 1 = 0.0823654 loss)
I0422 16:12:13.295855  6613 sgd_solver.cpp:106] Iteration 60900, lr = 1e-06
I0422 16:13:49.766826  6613 solver.cpp:337] Iteration 61000, Testing net (#0)
I0422 16:13:49.766968  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 16:13:49.766973  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 16:13:49.766978  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 16:13:49.766993  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 16:13:49.766995  6613 net.cpp:693] Ignoring source layer visualize
I0422 16:13:49.766997  6613 net.cpp:693] Ignoring source layer fake
I0422 16:17:10.843762  6613 solver.cpp:404]     Test net output #0: loss = 0.125399 (* 1 = 0.125399 loss)
I0422 16:17:11.474447  6613 solver.cpp:228] Iteration 61000, loss = 0.0633163
I0422 16:17:11.474468  6613 solver.cpp:244]     Train net output #0: loss = 0.0633163 (* 1 = 0.0633163 loss)
I0422 16:17:11.474490  6613 sgd_solver.cpp:106] Iteration 61000, lr = 1e-06
I0422 16:18:47.087837  6613 solver.cpp:228] Iteration 61100, loss = 0.0788665
I0422 16:18:47.088685  6613 solver.cpp:244]     Train net output #0: loss = 0.0788665 (* 1 = 0.0788665 loss)
I0422 16:18:47.088693  6613 sgd_solver.cpp:106] Iteration 61100, lr = 1e-06
I0422 16:20:38.079646  6613 solver.cpp:228] Iteration 61200, loss = 0.106562
I0422 16:20:38.081270  6613 solver.cpp:244]     Train net output #0: loss = 0.106562 (* 1 = 0.106562 loss)
I0422 16:20:38.081279  6613 sgd_solver.cpp:106] Iteration 61200, lr = 1e-06
I0422 16:22:14.807361  6613 solver.cpp:228] Iteration 61300, loss = 0.119744
I0422 16:22:14.807545  6613 solver.cpp:244]     Train net output #0: loss = 0.119744 (* 1 = 0.119744 loss)
I0422 16:22:14.807555  6613 sgd_solver.cpp:106] Iteration 61300, lr = 1e-06
I0422 16:23:51.619040  6613 solver.cpp:228] Iteration 61400, loss = 0.191381
I0422 16:23:51.620319  6613 solver.cpp:244]     Train net output #0: loss = 0.191381 (* 1 = 0.191381 loss)
I0422 16:23:51.620327  6613 sgd_solver.cpp:106] Iteration 61400, lr = 1e-06
I0422 16:25:28.692369  6613 solver.cpp:228] Iteration 61500, loss = 0.0859597
I0422 16:25:28.692509  6613 solver.cpp:244]     Train net output #0: loss = 0.0859597 (* 1 = 0.0859597 loss)
I0422 16:25:28.692517  6613 sgd_solver.cpp:106] Iteration 61500, lr = 1e-06
I0422 16:27:05.944552  6613 solver.cpp:228] Iteration 61600, loss = 0.126378
I0422 16:27:05.944681  6613 solver.cpp:244]     Train net output #0: loss = 0.126378 (* 1 = 0.126378 loss)
I0422 16:27:05.944689  6613 sgd_solver.cpp:106] Iteration 61600, lr = 1e-06
I0422 16:28:43.334223  6613 solver.cpp:228] Iteration 61700, loss = 0.12436
I0422 16:28:43.334362  6613 solver.cpp:244]     Train net output #0: loss = 0.12436 (* 1 = 0.12436 loss)
I0422 16:28:43.334369  6613 sgd_solver.cpp:106] Iteration 61700, lr = 1e-06
I0422 16:30:18.769306  6613 solver.cpp:228] Iteration 61800, loss = 0.126709
I0422 16:30:18.769491  6613 solver.cpp:244]     Train net output #0: loss = 0.126709 (* 1 = 0.126709 loss)
I0422 16:30:18.769500  6613 sgd_solver.cpp:106] Iteration 61800, lr = 1e-06
I0422 16:31:56.096602  6613 solver.cpp:228] Iteration 61900, loss = 0.138737
I0422 16:31:56.096748  6613 solver.cpp:244]     Train net output #0: loss = 0.138737 (* 1 = 0.138737 loss)
I0422 16:31:56.096755  6613 sgd_solver.cpp:106] Iteration 61900, lr = 1e-06
I0422 16:33:32.675163  6613 solver.cpp:337] Iteration 62000, Testing net (#0)
I0422 16:33:32.675308  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 16:33:32.675312  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 16:33:32.675317  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 16:33:32.675333  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 16:33:32.675335  6613 net.cpp:693] Ignoring source layer visualize
I0422 16:33:32.675338  6613 net.cpp:693] Ignoring source layer fake
I0422 16:36:53.872684  6613 solver.cpp:404]     Test net output #0: loss = 0.124078 (* 1 = 0.124078 loss)
I0422 16:36:54.501696  6613 solver.cpp:228] Iteration 62000, loss = 0.102768
I0422 16:36:54.501718  6613 solver.cpp:244]     Train net output #0: loss = 0.102768 (* 1 = 0.102768 loss)
I0422 16:36:54.501739  6613 sgd_solver.cpp:106] Iteration 62000, lr = 1e-06
I0422 16:38:32.268941  6613 solver.cpp:228] Iteration 62100, loss = 0.113116
I0422 16:38:32.269104  6613 solver.cpp:244]     Train net output #0: loss = 0.113116 (* 1 = 0.113116 loss)
I0422 16:38:32.269114  6613 sgd_solver.cpp:106] Iteration 62100, lr = 1e-06
I0422 16:40:07.852552  6613 solver.cpp:228] Iteration 62200, loss = 0.104208
I0422 16:40:07.852694  6613 solver.cpp:244]     Train net output #0: loss = 0.104208 (* 1 = 0.104208 loss)
I0422 16:40:07.852702  6613 sgd_solver.cpp:106] Iteration 62200, lr = 1e-06
I0422 16:41:45.306675  6613 solver.cpp:228] Iteration 62300, loss = 0.103179
I0422 16:41:45.306825  6613 solver.cpp:244]     Train net output #0: loss = 0.103179 (* 1 = 0.103179 loss)
I0422 16:41:45.306833  6613 sgd_solver.cpp:106] Iteration 62300, lr = 1e-06
I0422 16:43:23.044869  6613 solver.cpp:228] Iteration 62400, loss = 0.0750513
I0422 16:43:23.045030  6613 solver.cpp:244]     Train net output #0: loss = 0.0750513 (* 1 = 0.0750513 loss)
I0422 16:43:23.045037  6613 sgd_solver.cpp:106] Iteration 62400, lr = 1e-06
I0422 16:45:00.240667  6613 solver.cpp:228] Iteration 62500, loss = 0.100183
I0422 16:45:00.242138  6613 solver.cpp:244]     Train net output #0: loss = 0.100183 (* 1 = 0.100183 loss)
I0422 16:45:00.242147  6613 sgd_solver.cpp:106] Iteration 62500, lr = 1e-06
I0422 16:46:37.169800  6613 solver.cpp:228] Iteration 62600, loss = 0.0937823
I0422 16:46:37.169940  6613 solver.cpp:244]     Train net output #0: loss = 0.0937823 (* 1 = 0.0937823 loss)
I0422 16:46:37.169947  6613 sgd_solver.cpp:106] Iteration 62600, lr = 1e-06
I0422 16:48:14.327549  6613 solver.cpp:228] Iteration 62700, loss = 0.0775035
I0422 16:48:14.327702  6613 solver.cpp:244]     Train net output #0: loss = 0.0775035 (* 1 = 0.0775035 loss)
I0422 16:48:14.327708  6613 sgd_solver.cpp:106] Iteration 62700, lr = 1e-06
I0422 16:49:49.930085  6613 solver.cpp:228] Iteration 62800, loss = 0.122762
I0422 16:49:49.930233  6613 solver.cpp:244]     Train net output #0: loss = 0.122762 (* 1 = 0.122762 loss)
I0422 16:49:49.930238  6613 sgd_solver.cpp:106] Iteration 62800, lr = 1e-06
I0422 16:51:27.682353  6613 solver.cpp:228] Iteration 62900, loss = 0.177022
I0422 16:51:27.682509  6613 solver.cpp:244]     Train net output #0: loss = 0.177022 (* 1 = 0.177022 loss)
I0422 16:51:27.682518  6613 sgd_solver.cpp:106] Iteration 62900, lr = 1e-06
I0422 16:53:05.232873  6613 solver.cpp:337] Iteration 63000, Testing net (#0)
I0422 16:53:05.233009  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 16:53:05.233014  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 16:53:05.233018  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 16:53:05.233033  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 16:53:05.233036  6613 net.cpp:693] Ignoring source layer visualize
I0422 16:53:05.233038  6613 net.cpp:693] Ignoring source layer fake
I0422 16:56:25.979457  6613 solver.cpp:404]     Test net output #0: loss = 0.117694 (* 1 = 0.117694 loss)
I0422 16:56:26.610960  6613 solver.cpp:228] Iteration 63000, loss = 0.102114
I0422 16:56:26.610996  6613 solver.cpp:244]     Train net output #0: loss = 0.102114 (* 1 = 0.102114 loss)
I0422 16:56:26.611001  6613 sgd_solver.cpp:106] Iteration 63000, lr = 1e-06
I0422 16:58:05.736255  6613 solver.cpp:228] Iteration 63100, loss = 0.15426
I0422 16:58:05.736423  6613 solver.cpp:244]     Train net output #0: loss = 0.15426 (* 1 = 0.15426 loss)
I0422 16:58:05.736430  6613 sgd_solver.cpp:106] Iteration 63100, lr = 1e-06
I0422 16:59:41.330432  6613 solver.cpp:228] Iteration 63200, loss = 0.184879
I0422 16:59:41.330595  6613 solver.cpp:244]     Train net output #0: loss = 0.184879 (* 1 = 0.184879 loss)
I0422 16:59:41.330602  6613 sgd_solver.cpp:106] Iteration 63200, lr = 1e-06
I0422 17:01:19.633189  6613 solver.cpp:228] Iteration 63300, loss = 0.106459
I0422 17:01:19.633364  6613 solver.cpp:244]     Train net output #0: loss = 0.106459 (* 1 = 0.106459 loss)
I0422 17:01:19.633373  6613 sgd_solver.cpp:106] Iteration 63300, lr = 1e-06
I0422 17:02:57.623544  6613 solver.cpp:228] Iteration 63400, loss = 0.0919779
I0422 17:02:57.623693  6613 solver.cpp:244]     Train net output #0: loss = 0.0919779 (* 1 = 0.0919779 loss)
I0422 17:02:57.623702  6613 sgd_solver.cpp:106] Iteration 63400, lr = 1e-06
I0422 17:04:35.600064  6613 solver.cpp:228] Iteration 63500, loss = 0.0882207
I0422 17:04:35.600215  6613 solver.cpp:244]     Train net output #0: loss = 0.0882207 (* 1 = 0.0882207 loss)
I0422 17:04:35.600224  6613 sgd_solver.cpp:106] Iteration 63500, lr = 1e-06
I0422 17:06:10.926069  6613 solver.cpp:228] Iteration 63600, loss = 0.09498
I0422 17:06:10.926247  6613 solver.cpp:244]     Train net output #0: loss = 0.09498 (* 1 = 0.09498 loss)
I0422 17:06:10.926255  6613 sgd_solver.cpp:106] Iteration 63600, lr = 1e-06
I0422 17:07:48.791666  6613 solver.cpp:228] Iteration 63700, loss = 0.125379
I0422 17:07:48.791811  6613 solver.cpp:244]     Train net output #0: loss = 0.125379 (* 1 = 0.125379 loss)
I0422 17:07:48.791818  6613 sgd_solver.cpp:106] Iteration 63700, lr = 1e-06
I0422 17:09:26.196189  6613 solver.cpp:228] Iteration 63800, loss = 0.108669
I0422 17:09:26.196945  6613 solver.cpp:244]     Train net output #0: loss = 0.108669 (* 1 = 0.108669 loss)
I0422 17:09:26.196954  6613 sgd_solver.cpp:106] Iteration 63800, lr = 1e-06
I0422 17:11:05.266963  6613 solver.cpp:228] Iteration 63900, loss = 0.149552
I0422 17:11:05.267122  6613 solver.cpp:244]     Train net output #0: loss = 0.149552 (* 1 = 0.149552 loss)
I0422 17:11:05.267129  6613 sgd_solver.cpp:106] Iteration 63900, lr = 1e-06
I0422 17:12:43.088241  6613 solver.cpp:337] Iteration 64000, Testing net (#0)
I0422 17:12:43.088392  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 17:12:43.088397  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 17:12:43.088400  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 17:12:43.088415  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 17:12:43.088418  6613 net.cpp:693] Ignoring source layer visualize
I0422 17:12:43.088420  6613 net.cpp:693] Ignoring source layer fake
I0422 17:16:04.525614  6613 solver.cpp:404]     Test net output #0: loss = 0.119741 (* 1 = 0.119741 loss)
I0422 17:16:05.152706  6613 solver.cpp:228] Iteration 64000, loss = 0.122791
I0422 17:16:05.152729  6613 solver.cpp:244]     Train net output #0: loss = 0.122791 (* 1 = 0.122791 loss)
I0422 17:16:05.152750  6613 sgd_solver.cpp:106] Iteration 64000, lr = 1e-06
I0422 17:17:43.279012  6613 solver.cpp:228] Iteration 64100, loss = 0.0883268
I0422 17:17:43.279507  6613 solver.cpp:244]     Train net output #0: loss = 0.0883268 (* 1 = 0.0883268 loss)
I0422 17:17:43.279517  6613 sgd_solver.cpp:106] Iteration 64100, lr = 1e-06
I0422 17:19:24.531402  6613 solver.cpp:228] Iteration 64200, loss = 0.0885145
I0422 17:19:24.531549  6613 solver.cpp:244]     Train net output #0: loss = 0.0885145 (* 1 = 0.0885145 loss)
I0422 17:19:24.531556  6613 sgd_solver.cpp:106] Iteration 64200, lr = 1e-06
I0422 17:20:59.860672  6613 solver.cpp:228] Iteration 64300, loss = 0.0993852
I0422 17:20:59.860836  6613 solver.cpp:244]     Train net output #0: loss = 0.0993852 (* 1 = 0.0993852 loss)
I0422 17:20:59.860844  6613 sgd_solver.cpp:106] Iteration 64300, lr = 1e-06
I0422 17:22:38.141111  6613 solver.cpp:228] Iteration 64400, loss = 0.0992533
I0422 17:22:38.141252  6613 solver.cpp:244]     Train net output #0: loss = 0.0992533 (* 1 = 0.0992533 loss)
I0422 17:22:38.141260  6613 sgd_solver.cpp:106] Iteration 64400, lr = 1e-06
I0422 17:24:16.028807  6613 solver.cpp:228] Iteration 64500, loss = 0.115476
I0422 17:24:16.028970  6613 solver.cpp:244]     Train net output #0: loss = 0.115476 (* 1 = 0.115476 loss)
I0422 17:24:16.028978  6613 sgd_solver.cpp:106] Iteration 64500, lr = 1e-06
I0422 17:25:53.333602  6613 solver.cpp:228] Iteration 64600, loss = 0.118052
I0422 17:25:53.333757  6613 solver.cpp:244]     Train net output #0: loss = 0.118052 (* 1 = 0.118052 loss)
I0422 17:25:53.333765  6613 sgd_solver.cpp:106] Iteration 64600, lr = 1e-06
I0422 17:27:28.655915  6613 solver.cpp:228] Iteration 64700, loss = 0.0998254
I0422 17:27:28.656056  6613 solver.cpp:244]     Train net output #0: loss = 0.0998254 (* 1 = 0.0998254 loss)
I0422 17:27:28.656064  6613 sgd_solver.cpp:106] Iteration 64700, lr = 1e-06
I0422 17:29:05.897622  6613 solver.cpp:228] Iteration 64800, loss = 0.0924756
I0422 17:29:05.897768  6613 solver.cpp:244]     Train net output #0: loss = 0.0924756 (* 1 = 0.0924756 loss)
I0422 17:29:05.897774  6613 sgd_solver.cpp:106] Iteration 64800, lr = 1e-06
I0422 17:30:42.954092  6613 solver.cpp:228] Iteration 64900, loss = 0.0933783
I0422 17:30:42.954236  6613 solver.cpp:244]     Train net output #0: loss = 0.0933783 (* 1 = 0.0933783 loss)
I0422 17:30:42.954243  6613 sgd_solver.cpp:106] Iteration 64900, lr = 1e-06
I0422 17:32:18.674541  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_65000.caffemodel
I0422 17:32:42.535209  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_65000.solverstate
I0422 17:32:42.742811  6613 solver.cpp:337] Iteration 65000, Testing net (#0)
I0422 17:32:42.742837  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 17:32:42.742840  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 17:32:42.742843  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 17:32:42.742857  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 17:32:42.742861  6613 net.cpp:693] Ignoring source layer visualize
I0422 17:32:42.742862  6613 net.cpp:693] Ignoring source layer fake
I0422 17:36:03.047467  6613 solver.cpp:404]     Test net output #0: loss = 0.1207 (* 1 = 0.1207 loss)
I0422 17:36:03.678704  6613 solver.cpp:228] Iteration 65000, loss = 0.112729
I0422 17:36:03.678745  6613 solver.cpp:244]     Train net output #0: loss = 0.112729 (* 1 = 0.112729 loss)
I0422 17:36:03.678751  6613 sgd_solver.cpp:106] Iteration 65000, lr = 1e-06
I0422 17:37:40.668324  6613 solver.cpp:228] Iteration 65100, loss = 0.122771
I0422 17:37:40.668459  6613 solver.cpp:244]     Train net output #0: loss = 0.122771 (* 1 = 0.122771 loss)
I0422 17:37:40.668467  6613 sgd_solver.cpp:106] Iteration 65100, lr = 1e-06
I0422 17:39:17.891770  6613 solver.cpp:228] Iteration 65200, loss = 0.09622
I0422 17:39:17.891919  6613 solver.cpp:244]     Train net output #0: loss = 0.09622 (* 1 = 0.09622 loss)
I0422 17:39:17.891927  6613 sgd_solver.cpp:106] Iteration 65200, lr = 1e-06
I0422 17:40:53.501492  6613 solver.cpp:228] Iteration 65300, loss = 0.106466
I0422 17:40:53.501629  6613 solver.cpp:244]     Train net output #0: loss = 0.106466 (* 1 = 0.106466 loss)
I0422 17:40:53.501637  6613 sgd_solver.cpp:106] Iteration 65300, lr = 1e-06
I0422 17:42:31.447821  6613 solver.cpp:228] Iteration 65400, loss = 0.140883
I0422 17:42:31.447968  6613 solver.cpp:244]     Train net output #0: loss = 0.140883 (* 1 = 0.140883 loss)
I0422 17:42:31.447975  6613 sgd_solver.cpp:106] Iteration 65400, lr = 1e-06
I0422 17:44:09.214566  6613 solver.cpp:228] Iteration 65500, loss = 0.107536
I0422 17:44:09.214705  6613 solver.cpp:244]     Train net output #0: loss = 0.107536 (* 1 = 0.107536 loss)
I0422 17:44:09.214715  6613 sgd_solver.cpp:106] Iteration 65500, lr = 1e-06
I0422 17:45:47.006054  6613 solver.cpp:228] Iteration 65600, loss = 0.123188
I0422 17:45:47.006202  6613 solver.cpp:244]     Train net output #0: loss = 0.123188 (* 1 = 0.123188 loss)
I0422 17:45:47.006211  6613 sgd_solver.cpp:106] Iteration 65600, lr = 1e-06
I0422 17:47:22.610287  6613 solver.cpp:228] Iteration 65700, loss = 0.121162
I0422 17:47:22.610458  6613 solver.cpp:244]     Train net output #0: loss = 0.121162 (* 1 = 0.121162 loss)
I0422 17:47:22.610466  6613 sgd_solver.cpp:106] Iteration 65700, lr = 1e-06
I0422 17:49:00.213809  6613 solver.cpp:228] Iteration 65800, loss = 0.104025
I0422 17:49:00.213946  6613 solver.cpp:244]     Train net output #0: loss = 0.104025 (* 1 = 0.104025 loss)
I0422 17:49:00.213953  6613 sgd_solver.cpp:106] Iteration 65800, lr = 1e-06
I0422 17:50:37.917646  6613 solver.cpp:228] Iteration 65900, loss = 0.11662
I0422 17:50:37.917856  6613 solver.cpp:244]     Train net output #0: loss = 0.11662 (* 1 = 0.11662 loss)
I0422 17:50:37.917875  6613 sgd_solver.cpp:106] Iteration 65900, lr = 1e-06
I0422 17:52:14.473598  6613 solver.cpp:337] Iteration 66000, Testing net (#0)
I0422 17:52:14.473752  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 17:52:14.473757  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 17:52:14.473762  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 17:52:14.473778  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 17:52:14.473779  6613 net.cpp:693] Ignoring source layer visualize
I0422 17:52:14.473781  6613 net.cpp:693] Ignoring source layer fake
I0422 17:55:36.076287  6613 solver.cpp:404]     Test net output #0: loss = 0.12584 (* 1 = 0.12584 loss)
I0422 17:55:36.703387  6613 solver.cpp:228] Iteration 66000, loss = 0.0805173
I0422 17:55:36.703424  6613 solver.cpp:244]     Train net output #0: loss = 0.0805173 (* 1 = 0.0805173 loss)
I0422 17:55:36.703431  6613 sgd_solver.cpp:106] Iteration 66000, lr = 1e-06
I0422 17:57:12.333886  6613 solver.cpp:228] Iteration 66100, loss = 0.09683
I0422 17:57:12.334033  6613 solver.cpp:244]     Train net output #0: loss = 0.09683 (* 1 = 0.09683 loss)
I0422 17:57:12.334039  6613 sgd_solver.cpp:106] Iteration 66100, lr = 1e-06
I0422 17:58:49.673524  6613 solver.cpp:228] Iteration 66200, loss = 0.0984176
I0422 17:58:49.673691  6613 solver.cpp:244]     Train net output #0: loss = 0.0984176 (* 1 = 0.0984176 loss)
I0422 17:58:49.673697  6613 sgd_solver.cpp:106] Iteration 66200, lr = 1e-06
I0422 18:00:26.594409  6613 solver.cpp:228] Iteration 66300, loss = 0.0866271
I0422 18:00:26.596542  6613 solver.cpp:244]     Train net output #0: loss = 0.0866271 (* 1 = 0.0866271 loss)
I0422 18:00:26.596549  6613 sgd_solver.cpp:106] Iteration 66300, lr = 1e-06
I0422 18:02:03.609046  6613 solver.cpp:228] Iteration 66400, loss = 0.169461
I0422 18:02:03.609192  6613 solver.cpp:244]     Train net output #0: loss = 0.169461 (* 1 = 0.169461 loss)
I0422 18:02:03.609200  6613 sgd_solver.cpp:106] Iteration 66400, lr = 1e-06
I0422 18:03:41.201303  6613 solver.cpp:228] Iteration 66500, loss = 0.126532
I0422 18:03:41.201457  6613 solver.cpp:244]     Train net output #0: loss = 0.126532 (* 1 = 0.126532 loss)
I0422 18:03:41.201464  6613 sgd_solver.cpp:106] Iteration 66500, lr = 1e-06
I0422 18:05:18.668225  6613 solver.cpp:228] Iteration 66600, loss = 0.1805
I0422 18:05:18.668375  6613 solver.cpp:244]     Train net output #0: loss = 0.1805 (* 1 = 0.1805 loss)
I0422 18:05:18.668382  6613 sgd_solver.cpp:106] Iteration 66600, lr = 1e-06
I0422 18:06:56.256454  6613 solver.cpp:228] Iteration 66700, loss = 0.135011
I0422 18:06:56.256605  6613 solver.cpp:244]     Train net output #0: loss = 0.135011 (* 1 = 0.135011 loss)
I0422 18:06:56.256613  6613 sgd_solver.cpp:106] Iteration 66700, lr = 1e-06
I0422 18:08:31.882361  6613 solver.cpp:228] Iteration 66800, loss = 0.146537
I0422 18:08:31.883944  6613 solver.cpp:244]     Train net output #0: loss = 0.146537 (* 1 = 0.146537 loss)
I0422 18:08:31.883950  6613 sgd_solver.cpp:106] Iteration 66800, lr = 1e-06
I0422 18:10:09.489676  6613 solver.cpp:228] Iteration 66900, loss = 0.15518
I0422 18:10:09.489811  6613 solver.cpp:244]     Train net output #0: loss = 0.15518 (* 1 = 0.15518 loss)
I0422 18:10:09.489820  6613 sgd_solver.cpp:106] Iteration 66900, lr = 1e-06
I0422 18:11:46.123348  6613 solver.cpp:337] Iteration 67000, Testing net (#0)
I0422 18:11:46.123535  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 18:11:46.123540  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 18:11:46.123544  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 18:11:46.123559  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 18:11:46.123563  6613 net.cpp:693] Ignoring source layer visualize
I0422 18:11:46.123564  6613 net.cpp:693] Ignoring source layer fake
I0422 18:15:07.660187  6613 solver.cpp:404]     Test net output #0: loss = 0.123635 (* 1 = 0.123635 loss)
I0422 18:15:08.291870  6613 solver.cpp:228] Iteration 67000, loss = 0.124071
I0422 18:15:08.291913  6613 solver.cpp:244]     Train net output #0: loss = 0.124071 (* 1 = 0.124071 loss)
I0422 18:15:08.291919  6613 sgd_solver.cpp:106] Iteration 67000, lr = 1e-06
I0422 18:16:45.843308  6613 solver.cpp:228] Iteration 67100, loss = 0.114134
I0422 18:16:45.843991  6613 solver.cpp:244]     Train net output #0: loss = 0.114134 (* 1 = 0.114134 loss)
I0422 18:16:45.844002  6613 sgd_solver.cpp:106] Iteration 67100, lr = 1e-06
I0422 18:18:21.405938  6613 solver.cpp:228] Iteration 67200, loss = 0.106174
I0422 18:18:21.406095  6613 solver.cpp:244]     Train net output #0: loss = 0.106174 (* 1 = 0.106174 loss)
I0422 18:18:21.406102  6613 sgd_solver.cpp:106] Iteration 67200, lr = 1e-06
I0422 18:19:58.942926  6613 solver.cpp:228] Iteration 67300, loss = 0.120683
I0422 18:19:58.944010  6613 solver.cpp:244]     Train net output #0: loss = 0.120683 (* 1 = 0.120683 loss)
I0422 18:19:58.944018  6613 sgd_solver.cpp:106] Iteration 67300, lr = 1e-06
I0422 18:21:42.700129  6613 solver.cpp:228] Iteration 67400, loss = 0.0997094
I0422 18:21:42.700285  6613 solver.cpp:244]     Train net output #0: loss = 0.0997094 (* 1 = 0.0997094 loss)
I0422 18:21:42.700294  6613 sgd_solver.cpp:106] Iteration 67400, lr = 1e-06
I0422 18:23:20.228307  6613 solver.cpp:228] Iteration 67500, loss = 0.139463
I0422 18:23:20.228462  6613 solver.cpp:244]     Train net output #0: loss = 0.139463 (* 1 = 0.139463 loss)
I0422 18:23:20.228471  6613 sgd_solver.cpp:106] Iteration 67500, lr = 1e-06
I0422 18:24:57.957751  6613 solver.cpp:228] Iteration 67600, loss = 0.226915
I0422 18:24:57.957891  6613 solver.cpp:244]     Train net output #0: loss = 0.226915 (* 1 = 0.226915 loss)
I0422 18:24:57.957900  6613 sgd_solver.cpp:106] Iteration 67600, lr = 1e-06
I0422 18:26:34.926554  6613 solver.cpp:228] Iteration 67700, loss = 0.125737
I0422 18:26:34.926692  6613 solver.cpp:244]     Train net output #0: loss = 0.125737 (* 1 = 0.125737 loss)
I0422 18:26:34.926699  6613 sgd_solver.cpp:106] Iteration 67700, lr = 1e-06
I0422 18:28:10.299432  6613 solver.cpp:228] Iteration 67800, loss = 0.121052
I0422 18:28:10.299569  6613 solver.cpp:244]     Train net output #0: loss = 0.121052 (* 1 = 0.121052 loss)
I0422 18:28:10.299576  6613 sgd_solver.cpp:106] Iteration 67800, lr = 1e-06
I0422 18:29:47.512573  6613 solver.cpp:228] Iteration 67900, loss = 0.119259
I0422 18:29:47.513303  6613 solver.cpp:244]     Train net output #0: loss = 0.119259 (* 1 = 0.119259 loss)
I0422 18:29:47.513325  6613 sgd_solver.cpp:106] Iteration 67900, lr = 1e-06
I0422 18:31:24.532657  6613 solver.cpp:337] Iteration 68000, Testing net (#0)
I0422 18:31:24.532796  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 18:31:24.532801  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 18:31:24.532806  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 18:31:24.532822  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 18:31:24.532824  6613 net.cpp:693] Ignoring source layer visualize
I0422 18:31:24.532826  6613 net.cpp:693] Ignoring source layer fake
I0422 18:34:46.237468  6613 solver.cpp:404]     Test net output #0: loss = 0.117574 (* 1 = 0.117574 loss)
I0422 18:34:46.870529  6613 solver.cpp:228] Iteration 68000, loss = 0.111777
I0422 18:34:46.870558  6613 solver.cpp:244]     Train net output #0: loss = 0.111777 (* 1 = 0.111777 loss)
I0422 18:34:46.870564  6613 sgd_solver.cpp:106] Iteration 68000, lr = 1e-06
I0422 18:36:24.751353  6613 solver.cpp:228] Iteration 68100, loss = 0.165636
I0422 18:36:24.751518  6613 solver.cpp:244]     Train net output #0: loss = 0.165636 (* 1 = 0.165636 loss)
I0422 18:36:24.751525  6613 sgd_solver.cpp:106] Iteration 68100, lr = 1e-06
I0422 18:38:00.378412  6613 solver.cpp:228] Iteration 68200, loss = 0.126958
I0422 18:38:00.378549  6613 solver.cpp:244]     Train net output #0: loss = 0.126958 (* 1 = 0.126958 loss)
I0422 18:38:00.378556  6613 sgd_solver.cpp:106] Iteration 68200, lr = 1e-06
I0422 18:39:38.562948  6613 solver.cpp:228] Iteration 68300, loss = 0.109325
I0422 18:39:38.563074  6613 solver.cpp:244]     Train net output #0: loss = 0.109325 (* 1 = 0.109325 loss)
I0422 18:39:38.563083  6613 sgd_solver.cpp:106] Iteration 68300, lr = 1e-06
I0422 18:41:16.212064  6613 solver.cpp:228] Iteration 68400, loss = 0.102092
I0422 18:41:16.212200  6613 solver.cpp:244]     Train net output #0: loss = 0.102092 (* 1 = 0.102092 loss)
I0422 18:41:16.212208  6613 sgd_solver.cpp:106] Iteration 68400, lr = 1e-06
I0422 18:42:53.848064  6613 solver.cpp:228] Iteration 68500, loss = 0.0835325
I0422 18:42:53.848211  6613 solver.cpp:244]     Train net output #0: loss = 0.0835325 (* 1 = 0.0835325 loss)
I0422 18:42:53.848217  6613 sgd_solver.cpp:106] Iteration 68500, lr = 1e-06
I0422 18:44:29.382699  6613 solver.cpp:228] Iteration 68600, loss = 0.0875469
I0422 18:44:29.382853  6613 solver.cpp:244]     Train net output #0: loss = 0.0875469 (* 1 = 0.0875469 loss)
I0422 18:44:29.382861  6613 sgd_solver.cpp:106] Iteration 68600, lr = 1e-06
I0422 18:46:06.688267  6613 solver.cpp:228] Iteration 68700, loss = 0.123224
I0422 18:46:06.688421  6613 solver.cpp:244]     Train net output #0: loss = 0.123224 (* 1 = 0.123224 loss)
I0422 18:46:06.688428  6613 sgd_solver.cpp:106] Iteration 68700, lr = 1e-06
I0422 18:47:43.632504  6613 solver.cpp:228] Iteration 68800, loss = 0.106469
I0422 18:47:43.632659  6613 solver.cpp:244]     Train net output #0: loss = 0.106469 (* 1 = 0.106469 loss)
I0422 18:47:43.632668  6613 sgd_solver.cpp:106] Iteration 68800, lr = 1e-06
I0422 18:49:20.647824  6613 solver.cpp:228] Iteration 68900, loss = 0.225822
I0422 18:49:20.647974  6613 solver.cpp:244]     Train net output #0: loss = 0.225822 (* 1 = 0.225822 loss)
I0422 18:49:20.647982  6613 sgd_solver.cpp:106] Iteration 68900, lr = 1e-06
I0422 18:50:56.979928  6613 solver.cpp:337] Iteration 69000, Testing net (#0)
I0422 18:50:56.980074  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 18:50:56.980079  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 18:50:56.980083  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 18:50:56.980098  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 18:50:56.980101  6613 net.cpp:693] Ignoring source layer visualize
I0422 18:50:56.980103  6613 net.cpp:693] Ignoring source layer fake
I0422 18:54:18.501539  6613 solver.cpp:404]     Test net output #0: loss = 0.120058 (* 1 = 0.120058 loss)
I0422 18:54:19.129003  6613 solver.cpp:228] Iteration 69000, loss = 0.0949442
I0422 18:54:19.129042  6613 solver.cpp:244]     Train net output #0: loss = 0.0949442 (* 1 = 0.0949442 loss)
I0422 18:54:19.129048  6613 sgd_solver.cpp:106] Iteration 69000, lr = 1e-06
I0422 18:55:56.661892  6613 solver.cpp:228] Iteration 69100, loss = 0.210491
I0422 18:55:56.662037  6613 solver.cpp:244]     Train net output #0: loss = 0.210491 (* 1 = 0.210491 loss)
I0422 18:55:56.662045  6613 sgd_solver.cpp:106] Iteration 69100, lr = 1e-06
I0422 18:57:34.260450  6613 solver.cpp:228] Iteration 69200, loss = 0.199928
I0422 18:57:34.260599  6613 solver.cpp:244]     Train net output #0: loss = 0.199928 (* 1 = 0.199928 loss)
I0422 18:57:34.260607  6613 sgd_solver.cpp:106] Iteration 69200, lr = 1e-06
I0422 18:59:09.895557  6613 solver.cpp:228] Iteration 69300, loss = 0.149018
I0422 18:59:09.895704  6613 solver.cpp:244]     Train net output #0: loss = 0.149018 (* 1 = 0.149018 loss)
I0422 18:59:09.895711  6613 sgd_solver.cpp:106] Iteration 69300, lr = 1e-06
I0422 19:00:47.548019  6613 solver.cpp:228] Iteration 69400, loss = 0.138483
I0422 19:00:47.548192  6613 solver.cpp:244]     Train net output #0: loss = 0.138483 (* 1 = 0.138483 loss)
I0422 19:00:47.548200  6613 sgd_solver.cpp:106] Iteration 69400, lr = 1e-06
I0422 19:02:25.153017  6613 solver.cpp:228] Iteration 69500, loss = 0.114163
I0422 19:02:25.153167  6613 solver.cpp:244]     Train net output #0: loss = 0.114163 (* 1 = 0.114163 loss)
I0422 19:02:25.153175  6613 sgd_solver.cpp:106] Iteration 69500, lr = 1e-06
I0422 19:04:02.731221  6613 solver.cpp:228] Iteration 69600, loss = 0.137633
I0422 19:04:02.731374  6613 solver.cpp:244]     Train net output #0: loss = 0.137633 (* 1 = 0.137633 loss)
I0422 19:04:02.731381  6613 sgd_solver.cpp:106] Iteration 69600, lr = 1e-06
I0422 19:05:38.308079  6613 solver.cpp:228] Iteration 69700, loss = 0.153379
I0422 19:05:38.308235  6613 solver.cpp:244]     Train net output #0: loss = 0.153379 (* 1 = 0.153379 loss)
I0422 19:05:38.308243  6613 sgd_solver.cpp:106] Iteration 69700, lr = 1e-06
I0422 19:07:15.808182  6613 solver.cpp:228] Iteration 69800, loss = 0.110318
I0422 19:07:15.808334  6613 solver.cpp:244]     Train net output #0: loss = 0.110318 (* 1 = 0.110318 loss)
I0422 19:07:15.808341  6613 sgd_solver.cpp:106] Iteration 69800, lr = 1e-06
I0422 19:08:53.172049  6613 solver.cpp:228] Iteration 69900, loss = 0.0900615
I0422 19:08:53.172194  6613 solver.cpp:244]     Train net output #0: loss = 0.0900615 (* 1 = 0.0900615 loss)
I0422 19:08:53.172201  6613 sgd_solver.cpp:106] Iteration 69900, lr = 1e-06
I0422 19:10:29.170689  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_70000.caffemodel
I0422 19:10:39.952410  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_70000.solverstate
I0422 19:10:40.156002  6613 solver.cpp:337] Iteration 70000, Testing net (#0)
I0422 19:10:40.156044  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 19:10:40.156047  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 19:10:40.156050  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 19:10:40.156064  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 19:10:40.156067  6613 net.cpp:693] Ignoring source layer visualize
I0422 19:10:40.156069  6613 net.cpp:693] Ignoring source layer fake
I0422 19:14:00.638427  6613 solver.cpp:404]     Test net output #0: loss = 0.120666 (* 1 = 0.120666 loss)
I0422 19:14:01.265972  6613 solver.cpp:228] Iteration 70000, loss = 0.116978
I0422 19:14:01.265992  6613 solver.cpp:244]     Train net output #0: loss = 0.116978 (* 1 = 0.116978 loss)
I0422 19:14:01.266013  6613 sgd_solver.cpp:106] Iteration 70000, lr = 1e-06
I0422 19:15:38.233335  6613 solver.cpp:228] Iteration 70100, loss = 0.0945454
I0422 19:15:38.233506  6613 solver.cpp:244]     Train net output #0: loss = 0.0945454 (* 1 = 0.0945454 loss)
I0422 19:15:38.233515  6613 sgd_solver.cpp:106] Iteration 70100, lr = 1e-06
I0422 19:17:15.407080  6613 solver.cpp:228] Iteration 70200, loss = 0.0861809
I0422 19:17:15.407249  6613 solver.cpp:244]     Train net output #0: loss = 0.0861809 (* 1 = 0.0861809 loss)
I0422 19:17:15.407256  6613 sgd_solver.cpp:106] Iteration 70200, lr = 1e-06
I0422 19:18:51.031476  6613 solver.cpp:228] Iteration 70300, loss = 0.124831
I0422 19:18:51.031615  6613 solver.cpp:244]     Train net output #0: loss = 0.124831 (* 1 = 0.124831 loss)
I0422 19:18:51.031621  6613 sgd_solver.cpp:106] Iteration 70300, lr = 1e-06
I0422 19:20:28.402894  6613 solver.cpp:228] Iteration 70400, loss = 0.161971
I0422 19:20:28.404770  6613 solver.cpp:244]     Train net output #0: loss = 0.161971 (* 1 = 0.161971 loss)
I0422 19:20:28.404778  6613 sgd_solver.cpp:106] Iteration 70400, lr = 1e-06
I0422 19:22:11.577306  6613 solver.cpp:228] Iteration 70500, loss = 0.168133
I0422 19:22:11.577474  6613 solver.cpp:244]     Train net output #0: loss = 0.168133 (* 1 = 0.168133 loss)
I0422 19:22:11.577481  6613 sgd_solver.cpp:106] Iteration 70500, lr = 1e-06
I0422 19:23:48.830832  6613 solver.cpp:228] Iteration 70600, loss = 0.174508
I0422 19:23:48.830989  6613 solver.cpp:244]     Train net output #0: loss = 0.174508 (* 1 = 0.174508 loss)
I0422 19:23:48.830996  6613 sgd_solver.cpp:106] Iteration 70600, lr = 1e-06
I0422 19:25:24.178390  6613 solver.cpp:228] Iteration 70700, loss = 0.160871
I0422 19:25:24.178515  6613 solver.cpp:244]     Train net output #0: loss = 0.160871 (* 1 = 0.160871 loss)
I0422 19:25:24.178522  6613 sgd_solver.cpp:106] Iteration 70700, lr = 1e-06
I0422 19:27:01.372292  6613 solver.cpp:228] Iteration 70800, loss = 0.103921
I0422 19:27:01.372433  6613 solver.cpp:244]     Train net output #0: loss = 0.103921 (* 1 = 0.103921 loss)
I0422 19:27:01.372440  6613 sgd_solver.cpp:106] Iteration 70800, lr = 1e-06
I0422 19:28:38.557936  6613 solver.cpp:228] Iteration 70900, loss = 0.0978899
I0422 19:28:38.558073  6613 solver.cpp:244]     Train net output #0: loss = 0.0978899 (* 1 = 0.0978899 loss)
I0422 19:28:38.558081  6613 sgd_solver.cpp:106] Iteration 70900, lr = 1e-06
I0422 19:30:15.451098  6613 solver.cpp:337] Iteration 71000, Testing net (#0)
I0422 19:30:15.451236  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 19:30:15.451239  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 19:30:15.451244  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 19:30:15.451259  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 19:30:15.451261  6613 net.cpp:693] Ignoring source layer visualize
I0422 19:30:15.451263  6613 net.cpp:693] Ignoring source layer fake
I0422 19:33:36.656785  6613 solver.cpp:404]     Test net output #0: loss = 0.125601 (* 1 = 0.125601 loss)
I0422 19:33:37.286489  6613 solver.cpp:228] Iteration 71000, loss = 0.087913
I0422 19:33:37.286510  6613 solver.cpp:244]     Train net output #0: loss = 0.087913 (* 1 = 0.087913 loss)
I0422 19:33:37.286533  6613 sgd_solver.cpp:106] Iteration 71000, lr = 1e-06
I0422 19:35:12.892894  6613 solver.cpp:228] Iteration 71100, loss = 0.0606613
I0422 19:35:12.893028  6613 solver.cpp:244]     Train net output #0: loss = 0.0606613 (* 1 = 0.0606613 loss)
I0422 19:35:12.893034  6613 sgd_solver.cpp:106] Iteration 71100, lr = 1e-06
I0422 19:36:50.320670  6613 solver.cpp:228] Iteration 71200, loss = 0.165098
I0422 19:36:50.320787  6613 solver.cpp:244]     Train net output #0: loss = 0.165098 (* 1 = 0.165098 loss)
I0422 19:36:50.320796  6613 sgd_solver.cpp:106] Iteration 71200, lr = 1e-06
I0422 19:38:27.280918  6613 solver.cpp:228] Iteration 71300, loss = 0.128948
I0422 19:38:27.281069  6613 solver.cpp:244]     Train net output #0: loss = 0.128948 (* 1 = 0.128948 loss)
I0422 19:38:27.281077  6613 sgd_solver.cpp:106] Iteration 71300, lr = 1e-06
I0422 19:40:04.296363  6613 solver.cpp:228] Iteration 71400, loss = 0.219192
I0422 19:40:04.296507  6613 solver.cpp:244]     Train net output #0: loss = 0.219192 (* 1 = 0.219192 loss)
I0422 19:40:04.296514  6613 sgd_solver.cpp:106] Iteration 71400, lr = 1e-06
I0422 19:41:42.333083  6613 solver.cpp:228] Iteration 71500, loss = 0.0816234
I0422 19:41:42.333228  6613 solver.cpp:244]     Train net output #0: loss = 0.0816234 (* 1 = 0.0816234 loss)
I0422 19:41:42.333235  6613 sgd_solver.cpp:106] Iteration 71500, lr = 1e-06
I0422 19:43:20.142338  6613 solver.cpp:228] Iteration 71600, loss = 0.138403
I0422 19:43:20.142470  6613 solver.cpp:244]     Train net output #0: loss = 0.138403 (* 1 = 0.138403 loss)
I0422 19:43:20.142477  6613 sgd_solver.cpp:106] Iteration 71600, lr = 1e-06
I0422 19:44:58.661574  6613 solver.cpp:228] Iteration 71700, loss = 0.136628
I0422 19:44:58.661720  6613 solver.cpp:244]     Train net output #0: loss = 0.136628 (* 1 = 0.136628 loss)
I0422 19:44:58.661727  6613 sgd_solver.cpp:106] Iteration 71700, lr = 1e-06
I0422 19:46:34.282186  6613 solver.cpp:228] Iteration 71800, loss = 0.105113
I0422 19:46:34.282325  6613 solver.cpp:244]     Train net output #0: loss = 0.105113 (* 1 = 0.105113 loss)
I0422 19:46:34.282331  6613 sgd_solver.cpp:106] Iteration 71800, lr = 1e-06
I0422 19:48:13.013187  6613 solver.cpp:228] Iteration 71900, loss = 0.100594
I0422 19:48:13.013331  6613 solver.cpp:244]     Train net output #0: loss = 0.100594 (* 1 = 0.100594 loss)
I0422 19:48:13.013339  6613 sgd_solver.cpp:106] Iteration 71900, lr = 1e-06
I0422 19:49:50.343266  6613 solver.cpp:337] Iteration 72000, Testing net (#0)
I0422 19:49:50.343435  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 19:49:50.343439  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 19:49:50.343443  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 19:49:50.343458  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 19:49:50.343461  6613 net.cpp:693] Ignoring source layer visualize
I0422 19:49:50.343463  6613 net.cpp:693] Ignoring source layer fake
I0422 19:53:10.987208  6613 solver.cpp:404]     Test net output #0: loss = 0.123699 (* 1 = 0.123699 loss)
I0422 19:53:11.611050  6613 solver.cpp:228] Iteration 72000, loss = 0.0919342
I0422 19:53:11.611090  6613 solver.cpp:244]     Train net output #0: loss = 0.0919342 (* 1 = 0.0919342 loss)
I0422 19:53:11.611096  6613 sgd_solver.cpp:106] Iteration 72000, lr = 1e-06
I0422 19:54:50.735713  6613 solver.cpp:228] Iteration 72100, loss = 0.138523
I0422 19:54:50.735853  6613 solver.cpp:244]     Train net output #0: loss = 0.138523 (* 1 = 0.138523 loss)
I0422 19:54:50.735862  6613 sgd_solver.cpp:106] Iteration 72100, lr = 1e-06
I0422 19:56:26.290027  6613 solver.cpp:228] Iteration 72200, loss = 0.114908
I0422 19:56:26.290176  6613 solver.cpp:244]     Train net output #0: loss = 0.114908 (* 1 = 0.114908 loss)
I0422 19:56:26.290184  6613 sgd_solver.cpp:106] Iteration 72200, lr = 1e-06
I0422 19:58:04.746215  6613 solver.cpp:228] Iteration 72300, loss = 0.097035
I0422 19:58:04.746371  6613 solver.cpp:244]     Train net output #0: loss = 0.097035 (* 1 = 0.097035 loss)
I0422 19:58:04.746379  6613 sgd_solver.cpp:106] Iteration 72300, lr = 1e-06
I0422 19:59:42.300050  6613 solver.cpp:228] Iteration 72400, loss = 0.106586
I0422 19:59:42.300200  6613 solver.cpp:244]     Train net output #0: loss = 0.106586 (* 1 = 0.106586 loss)
I0422 19:59:42.300209  6613 sgd_solver.cpp:106] Iteration 72400, lr = 1e-06
I0422 20:01:19.129670  6613 solver.cpp:228] Iteration 72500, loss = 0.109926
I0422 20:01:19.129815  6613 solver.cpp:244]     Train net output #0: loss = 0.109926 (* 1 = 0.109926 loss)
I0422 20:01:19.129823  6613 sgd_solver.cpp:106] Iteration 72500, lr = 1e-06
I0422 20:02:56.061588  6613 solver.cpp:228] Iteration 72600, loss = 0.141806
I0422 20:02:56.061731  6613 solver.cpp:244]     Train net output #0: loss = 0.141806 (* 1 = 0.141806 loss)
I0422 20:02:56.061739  6613 sgd_solver.cpp:106] Iteration 72600, lr = 1e-06
I0422 20:04:33.214401  6613 solver.cpp:228] Iteration 72700, loss = 0.0992024
I0422 20:04:33.214539  6613 solver.cpp:244]     Train net output #0: loss = 0.0992024 (* 1 = 0.0992024 loss)
I0422 20:04:33.214546  6613 sgd_solver.cpp:106] Iteration 72700, lr = 1e-06
I0422 20:06:08.802989  6613 solver.cpp:228] Iteration 72800, loss = 0.108511
I0422 20:06:08.803139  6613 solver.cpp:244]     Train net output #0: loss = 0.108511 (* 1 = 0.108511 loss)
I0422 20:06:08.803145  6613 sgd_solver.cpp:106] Iteration 72800, lr = 1e-06
I0422 20:07:48.525431  6613 solver.cpp:228] Iteration 72900, loss = 0.104227
I0422 20:07:48.525571  6613 solver.cpp:244]     Train net output #0: loss = 0.104227 (* 1 = 0.104227 loss)
I0422 20:07:48.525579  6613 sgd_solver.cpp:106] Iteration 72900, lr = 1e-06
I0422 20:09:27.184118  6613 solver.cpp:337] Iteration 73000, Testing net (#0)
I0422 20:09:27.184279  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 20:09:27.184283  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 20:09:27.184288  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 20:09:27.184303  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 20:09:27.184305  6613 net.cpp:693] Ignoring source layer visualize
I0422 20:09:27.184307  6613 net.cpp:693] Ignoring source layer fake
I0422 20:12:48.590996  6613 solver.cpp:404]     Test net output #0: loss = 0.117916 (* 1 = 0.117916 loss)
I0422 20:12:49.219071  6613 solver.cpp:228] Iteration 73000, loss = 0.149913
I0422 20:12:49.219090  6613 solver.cpp:244]     Train net output #0: loss = 0.149913 (* 1 = 0.149913 loss)
I0422 20:12:49.219112  6613 sgd_solver.cpp:106] Iteration 73000, lr = 1e-06
I0422 20:14:30.274189  6613 solver.cpp:228] Iteration 73100, loss = 0.116087
I0422 20:14:30.274343  6613 solver.cpp:244]     Train net output #0: loss = 0.116087 (* 1 = 0.116087 loss)
I0422 20:14:30.274350  6613 sgd_solver.cpp:106] Iteration 73100, lr = 1e-06
I0422 20:16:05.623653  6613 solver.cpp:228] Iteration 73200, loss = 0.097185
I0422 20:16:05.623797  6613 solver.cpp:244]     Train net output #0: loss = 0.097185 (* 1 = 0.097185 loss)
I0422 20:16:05.623805  6613 sgd_solver.cpp:106] Iteration 73200, lr = 1e-06
I0422 20:17:45.532783  6613 solver.cpp:228] Iteration 73300, loss = 0.101088
I0422 20:17:45.532925  6613 solver.cpp:244]     Train net output #0: loss = 0.101088 (* 1 = 0.101088 loss)
I0422 20:17:45.532933  6613 sgd_solver.cpp:106] Iteration 73300, lr = 1e-06
I0422 20:19:25.098855  6613 solver.cpp:228] Iteration 73400, loss = 0.0923156
I0422 20:19:25.098995  6613 solver.cpp:244]     Train net output #0: loss = 0.0923156 (* 1 = 0.0923156 loss)
I0422 20:19:25.099002  6613 sgd_solver.cpp:106] Iteration 73400, lr = 1e-06
I0422 20:21:04.544669  6613 solver.cpp:228] Iteration 73500, loss = 0.0788933
I0422 20:21:04.544806  6613 solver.cpp:244]     Train net output #0: loss = 0.0788933 (* 1 = 0.0788933 loss)
I0422 20:21:04.544813  6613 sgd_solver.cpp:106] Iteration 73500, lr = 1e-06
I0422 20:22:39.850402  6613 solver.cpp:228] Iteration 73600, loss = 0.0831965
I0422 20:22:39.850551  6613 solver.cpp:244]     Train net output #0: loss = 0.0831965 (* 1 = 0.0831965 loss)
I0422 20:22:39.850559  6613 sgd_solver.cpp:106] Iteration 73600, lr = 1e-06
I0422 20:24:22.554813  6613 solver.cpp:228] Iteration 73700, loss = 0.311222
I0422 20:24:22.554960  6613 solver.cpp:244]     Train net output #0: loss = 0.311222 (* 1 = 0.311222 loss)
I0422 20:24:22.554968  6613 sgd_solver.cpp:106] Iteration 73700, lr = 1e-06
I0422 20:26:01.072060  6613 solver.cpp:228] Iteration 73800, loss = 0.1166
I0422 20:26:01.072207  6613 solver.cpp:244]     Train net output #0: loss = 0.1166 (* 1 = 0.1166 loss)
I0422 20:26:01.072216  6613 sgd_solver.cpp:106] Iteration 73800, lr = 1e-06
I0422 20:27:38.505075  6613 solver.cpp:228] Iteration 73900, loss = 0.166818
I0422 20:27:38.505215  6613 solver.cpp:244]     Train net output #0: loss = 0.166818 (* 1 = 0.166818 loss)
I0422 20:27:38.505223  6613 sgd_solver.cpp:106] Iteration 73900, lr = 1e-06
I0422 20:29:17.176800  6613 solver.cpp:337] Iteration 74000, Testing net (#0)
I0422 20:29:17.176949  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 20:29:17.176954  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 20:29:17.176957  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 20:29:17.176973  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 20:29:17.176976  6613 net.cpp:693] Ignoring source layer visualize
I0422 20:29:17.176978  6613 net.cpp:693] Ignoring source layer fake
I0422 20:32:38.332918  6613 solver.cpp:404]     Test net output #0: loss = 0.120138 (* 1 = 0.120138 loss)
I0422 20:32:38.960523  6613 solver.cpp:228] Iteration 74000, loss = 0.0831542
I0422 20:32:38.960566  6613 solver.cpp:244]     Train net output #0: loss = 0.0831542 (* 1 = 0.0831542 loss)
I0422 20:32:38.960572  6613 sgd_solver.cpp:106] Iteration 74000, lr = 1e-06
I0422 20:34:17.034126  6613 solver.cpp:228] Iteration 74100, loss = 0.140327
I0422 20:34:17.034281  6613 solver.cpp:244]     Train net output #0: loss = 0.140327 (* 1 = 0.140327 loss)
I0422 20:34:17.034288  6613 sgd_solver.cpp:106] Iteration 74100, lr = 1e-06
I0422 20:35:54.531847  6613 solver.cpp:228] Iteration 74200, loss = 0.0972524
I0422 20:35:54.532003  6613 solver.cpp:244]     Train net output #0: loss = 0.0972524 (* 1 = 0.0972524 loss)
I0422 20:35:54.532011  6613 sgd_solver.cpp:106] Iteration 74200, lr = 1e-06
I0422 20:37:30.163784  6613 solver.cpp:228] Iteration 74300, loss = 0.0965608
I0422 20:37:30.163949  6613 solver.cpp:244]     Train net output #0: loss = 0.0965608 (* 1 = 0.0965608 loss)
I0422 20:37:30.163955  6613 sgd_solver.cpp:106] Iteration 74300, lr = 1e-06
I0422 20:39:08.068356  6613 solver.cpp:228] Iteration 74400, loss = 0.145854
I0422 20:39:08.068516  6613 solver.cpp:244]     Train net output #0: loss = 0.145854 (* 1 = 0.145854 loss)
I0422 20:39:08.068523  6613 sgd_solver.cpp:106] Iteration 74400, lr = 1e-06
I0422 20:40:45.726117  6613 solver.cpp:228] Iteration 74500, loss = 0.0914972
I0422 20:40:45.726253  6613 solver.cpp:244]     Train net output #0: loss = 0.0914972 (* 1 = 0.0914972 loss)
I0422 20:40:45.726261  6613 sgd_solver.cpp:106] Iteration 74500, lr = 1e-06
I0422 20:42:23.418611  6613 solver.cpp:228] Iteration 74600, loss = 0.12262
I0422 20:42:23.418742  6613 solver.cpp:244]     Train net output #0: loss = 0.12262 (* 1 = 0.12262 loss)
I0422 20:42:23.418750  6613 sgd_solver.cpp:106] Iteration 74600, lr = 1e-06
I0422 20:43:58.982553  6613 solver.cpp:228] Iteration 74700, loss = 0.0926321
I0422 20:43:58.982693  6613 solver.cpp:244]     Train net output #0: loss = 0.0926321 (* 1 = 0.0926321 loss)
I0422 20:43:58.982700  6613 sgd_solver.cpp:106] Iteration 74700, lr = 1e-06
I0422 20:45:36.547317  6613 solver.cpp:228] Iteration 74800, loss = 0.0861136
I0422 20:45:36.547472  6613 solver.cpp:244]     Train net output #0: loss = 0.0861136 (* 1 = 0.0861136 loss)
I0422 20:45:36.547478  6613 sgd_solver.cpp:106] Iteration 74800, lr = 1e-06
I0422 20:47:13.850659  6613 solver.cpp:228] Iteration 74900, loss = 0.0967223
I0422 20:47:13.850816  6613 solver.cpp:244]     Train net output #0: loss = 0.0967223 (* 1 = 0.0967223 loss)
I0422 20:47:13.850824  6613 sgd_solver.cpp:106] Iteration 74900, lr = 1e-06
I0422 20:48:49.790091  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_75000.caffemodel
I0422 20:48:54.505694  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_75000.solverstate
I0422 20:48:54.699038  6613 solver.cpp:337] Iteration 75000, Testing net (#0)
I0422 20:48:54.699080  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 20:48:54.699084  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 20:48:54.699086  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 20:48:54.699101  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 20:48:54.699103  6613 net.cpp:693] Ignoring source layer visualize
I0422 20:48:54.699105  6613 net.cpp:693] Ignoring source layer fake
I0422 20:52:15.977814  6613 solver.cpp:404]     Test net output #0: loss = 0.120574 (* 1 = 0.120574 loss)
I0422 20:52:16.600975  6613 solver.cpp:228] Iteration 75000, loss = 0.0937591
I0422 20:52:16.600997  6613 solver.cpp:244]     Train net output #0: loss = 0.0937591 (* 1 = 0.0937591 loss)
I0422 20:52:16.601019  6613 sgd_solver.cpp:106] Iteration 75000, lr = 1e-06
I0422 20:53:53.658375  6613 solver.cpp:228] Iteration 75100, loss = 0.120016
I0422 20:53:53.658519  6613 solver.cpp:244]     Train net output #0: loss = 0.120016 (* 1 = 0.120016 loss)
I0422 20:53:53.658526  6613 sgd_solver.cpp:106] Iteration 75100, lr = 1e-06
I0422 20:55:31.051724  6613 solver.cpp:228] Iteration 75200, loss = 0.120058
I0422 20:55:31.051875  6613 solver.cpp:244]     Train net output #0: loss = 0.120058 (* 1 = 0.120058 loss)
I0422 20:55:31.051882  6613 sgd_solver.cpp:106] Iteration 75200, lr = 1e-06
I0422 20:57:08.500633  6613 solver.cpp:228] Iteration 75300, loss = 0.0948198
I0422 20:57:08.500788  6613 solver.cpp:244]     Train net output #0: loss = 0.0948198 (* 1 = 0.0948198 loss)
I0422 20:57:08.500797  6613 sgd_solver.cpp:106] Iteration 75300, lr = 1e-06
I0422 20:58:44.088377  6613 solver.cpp:228] Iteration 75400, loss = 0.0813367
I0422 20:58:44.088546  6613 solver.cpp:244]     Train net output #0: loss = 0.0813367 (* 1 = 0.0813367 loss)
I0422 20:58:44.088552  6613 sgd_solver.cpp:106] Iteration 75400, lr = 1e-06
I0422 21:00:22.104249  6613 solver.cpp:228] Iteration 75500, loss = 0.0742751
I0422 21:00:22.104411  6613 solver.cpp:244]     Train net output #0: loss = 0.0742751 (* 1 = 0.0742751 loss)
I0422 21:00:22.104420  6613 sgd_solver.cpp:106] Iteration 75500, lr = 1e-06
I0422 21:02:00.081758  6613 solver.cpp:228] Iteration 75600, loss = 0.0844999
I0422 21:02:00.081954  6613 solver.cpp:244]     Train net output #0: loss = 0.0844999 (* 1 = 0.0844999 loss)
I0422 21:02:00.081961  6613 sgd_solver.cpp:106] Iteration 75600, lr = 1e-06
I0422 21:03:35.709180  6613 solver.cpp:228] Iteration 75700, loss = 0.0994899
I0422 21:03:35.709321  6613 solver.cpp:244]     Train net output #0: loss = 0.0994899 (* 1 = 0.0994899 loss)
I0422 21:03:35.709329  6613 sgd_solver.cpp:106] Iteration 75700, lr = 1e-06
I0422 21:05:13.464715  6613 solver.cpp:228] Iteration 75800, loss = 0.0871835
I0422 21:05:13.464855  6613 solver.cpp:244]     Train net output #0: loss = 0.0871835 (* 1 = 0.0871835 loss)
I0422 21:05:13.464862  6613 sgd_solver.cpp:106] Iteration 75800, lr = 1e-06
I0422 21:06:51.350311  6613 solver.cpp:228] Iteration 75900, loss = 0.0851873
I0422 21:06:51.350471  6613 solver.cpp:244]     Train net output #0: loss = 0.0851873 (* 1 = 0.0851873 loss)
I0422 21:06:51.350479  6613 sgd_solver.cpp:106] Iteration 75900, lr = 1e-06
I0422 21:08:28.068759  6613 solver.cpp:337] Iteration 76000, Testing net (#0)
I0422 21:08:28.068892  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 21:08:28.068895  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 21:08:28.068900  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 21:08:28.068915  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 21:08:28.068917  6613 net.cpp:693] Ignoring source layer visualize
I0422 21:08:28.068919  6613 net.cpp:693] Ignoring source layer fake
I0422 21:11:49.146498  6613 solver.cpp:404]     Test net output #0: loss = 0.125384 (* 1 = 0.125384 loss)
I0422 21:11:49.773272  6613 solver.cpp:228] Iteration 76000, loss = 0.0780063
I0422 21:11:49.773313  6613 solver.cpp:244]     Train net output #0: loss = 0.0780063 (* 1 = 0.0780063 loss)
I0422 21:11:49.773319  6613 sgd_solver.cpp:106] Iteration 76000, lr = 1e-06
I0422 21:13:25.387670  6613 solver.cpp:228] Iteration 76100, loss = 0.116047
I0422 21:13:25.387806  6613 solver.cpp:244]     Train net output #0: loss = 0.116047 (* 1 = 0.116047 loss)
I0422 21:13:25.387814  6613 sgd_solver.cpp:106] Iteration 76100, lr = 1e-06
I0422 21:15:03.560402  6613 solver.cpp:228] Iteration 76200, loss = 0.369015
I0422 21:15:03.560545  6613 solver.cpp:244]     Train net output #0: loss = 0.369015 (* 1 = 0.369015 loss)
I0422 21:15:03.560554  6613 sgd_solver.cpp:106] Iteration 76200, lr = 1e-06
I0422 21:16:40.443156  6613 solver.cpp:228] Iteration 76300, loss = 0.104537
I0422 21:16:40.443300  6613 solver.cpp:244]     Train net output #0: loss = 0.104537 (* 1 = 0.104537 loss)
I0422 21:16:40.443308  6613 sgd_solver.cpp:106] Iteration 76300, lr = 1e-06
I0422 21:18:17.635571  6613 solver.cpp:228] Iteration 76400, loss = 0.0855935
I0422 21:18:17.635720  6613 solver.cpp:244]     Train net output #0: loss = 0.0855935 (* 1 = 0.0855935 loss)
I0422 21:18:17.635727  6613 sgd_solver.cpp:106] Iteration 76400, lr = 1e-06
I0422 21:19:54.988976  6613 solver.cpp:228] Iteration 76500, loss = 0.0955802
I0422 21:19:54.989679  6613 solver.cpp:244]     Train net output #0: loss = 0.0955802 (* 1 = 0.0955802 loss)
I0422 21:19:54.989688  6613 sgd_solver.cpp:106] Iteration 76500, lr = 1e-06
I0422 21:21:32.333884  6613 solver.cpp:228] Iteration 76600, loss = 0.159737
I0422 21:21:32.334038  6613 solver.cpp:244]     Train net output #0: loss = 0.159737 (* 1 = 0.159737 loss)
I0422 21:21:32.334048  6613 sgd_solver.cpp:106] Iteration 76600, lr = 1e-06
I0422 21:23:09.779224  6613 solver.cpp:228] Iteration 76700, loss = 0.115528
I0422 21:23:09.779368  6613 solver.cpp:244]     Train net output #0: loss = 0.115528 (* 1 = 0.115528 loss)
I0422 21:23:09.779376  6613 sgd_solver.cpp:106] Iteration 76700, lr = 1e-06
I0422 21:24:45.377496  6613 solver.cpp:228] Iteration 76800, loss = 0.133751
I0422 21:24:45.377652  6613 solver.cpp:244]     Train net output #0: loss = 0.133751 (* 1 = 0.133751 loss)
I0422 21:24:45.377660  6613 sgd_solver.cpp:106] Iteration 76800, lr = 1e-06
I0422 21:26:22.869057  6613 solver.cpp:228] Iteration 76900, loss = 0.179748
I0422 21:26:22.869212  6613 solver.cpp:244]     Train net output #0: loss = 0.179748 (* 1 = 0.179748 loss)
I0422 21:26:22.869220  6613 sgd_solver.cpp:106] Iteration 76900, lr = 1e-06
I0422 21:27:59.360831  6613 solver.cpp:337] Iteration 77000, Testing net (#0)
I0422 21:27:59.360966  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 21:27:59.360970  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 21:27:59.360973  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 21:27:59.360990  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 21:27:59.360992  6613 net.cpp:693] Ignoring source layer visualize
I0422 21:27:59.360994  6613 net.cpp:693] Ignoring source layer fake
I0422 21:31:20.193532  6613 solver.cpp:404]     Test net output #0: loss = 0.123941 (* 1 = 0.123941 loss)
I0422 21:31:20.816912  6613 solver.cpp:228] Iteration 77000, loss = 0.0952044
I0422 21:31:20.816933  6613 solver.cpp:244]     Train net output #0: loss = 0.0952044 (* 1 = 0.0952044 loss)
I0422 21:31:20.816939  6613 sgd_solver.cpp:106] Iteration 77000, lr = 1e-06
I0422 21:32:58.239648  6613 solver.cpp:228] Iteration 77100, loss = 0.11104
I0422 21:32:58.240522  6613 solver.cpp:244]     Train net output #0: loss = 0.11104 (* 1 = 0.11104 loss)
I0422 21:32:58.240532  6613 sgd_solver.cpp:106] Iteration 77100, lr = 1e-06
I0422 21:34:33.833623  6613 solver.cpp:228] Iteration 77200, loss = 0.123676
I0422 21:34:33.833765  6613 solver.cpp:244]     Train net output #0: loss = 0.123676 (* 1 = 0.123676 loss)
I0422 21:34:33.833771  6613 sgd_solver.cpp:106] Iteration 77200, lr = 1e-06
I0422 21:36:11.235066  6613 solver.cpp:228] Iteration 77300, loss = 0.100299
I0422 21:36:11.235218  6613 solver.cpp:244]     Train net output #0: loss = 0.100299 (* 1 = 0.100299 loss)
I0422 21:36:11.235224  6613 sgd_solver.cpp:106] Iteration 77300, lr = 1e-06
I0422 21:37:48.796207  6613 solver.cpp:228] Iteration 77400, loss = 0.0911762
I0422 21:37:48.796367  6613 solver.cpp:244]     Train net output #0: loss = 0.0911762 (* 1 = 0.0911762 loss)
I0422 21:37:48.796375  6613 sgd_solver.cpp:106] Iteration 77400, lr = 1e-06
I0422 21:39:25.632375  6613 solver.cpp:228] Iteration 77500, loss = 0.113834
I0422 21:39:25.632520  6613 solver.cpp:244]     Train net output #0: loss = 0.113834 (* 1 = 0.113834 loss)
I0422 21:39:25.632527  6613 sgd_solver.cpp:106] Iteration 77500, lr = 1e-06
I0422 21:41:02.577004  6613 solver.cpp:228] Iteration 77600, loss = 0.104672
I0422 21:41:02.577147  6613 solver.cpp:244]     Train net output #0: loss = 0.104672 (* 1 = 0.104672 loss)
I0422 21:41:02.577153  6613 sgd_solver.cpp:106] Iteration 77600, lr = 1e-06
I0422 21:42:39.698920  6613 solver.cpp:228] Iteration 77700, loss = 0.0787222
I0422 21:42:39.699054  6613 solver.cpp:244]     Train net output #0: loss = 0.0787222 (* 1 = 0.0787222 loss)
I0422 21:42:39.699060  6613 sgd_solver.cpp:106] Iteration 77700, lr = 1e-06
I0422 21:44:17.081284  6613 solver.cpp:228] Iteration 77800, loss = 0.0914634
I0422 21:44:17.081429  6613 solver.cpp:244]     Train net output #0: loss = 0.0914634 (* 1 = 0.0914634 loss)
I0422 21:44:17.081442  6613 sgd_solver.cpp:106] Iteration 77800, lr = 1e-06
I0422 21:45:52.671557  6613 solver.cpp:228] Iteration 77900, loss = 0.147306
I0422 21:45:52.671700  6613 solver.cpp:244]     Train net output #0: loss = 0.147306 (* 1 = 0.147306 loss)
I0422 21:45:52.671708  6613 sgd_solver.cpp:106] Iteration 77900, lr = 1e-06
I0422 21:47:29.183010  6613 solver.cpp:337] Iteration 78000, Testing net (#0)
I0422 21:47:29.183145  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 21:47:29.183149  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 21:47:29.183154  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 21:47:29.183169  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 21:47:29.183171  6613 net.cpp:693] Ignoring source layer visualize
I0422 21:47:29.183173  6613 net.cpp:693] Ignoring source layer fake
I0422 21:50:50.056624  6613 solver.cpp:404]     Test net output #0: loss = 0.118072 (* 1 = 0.118072 loss)
I0422 21:50:50.686898  6613 solver.cpp:228] Iteration 78000, loss = 0.120163
I0422 21:50:50.686921  6613 solver.cpp:244]     Train net output #0: loss = 0.120163 (* 1 = 0.120163 loss)
I0422 21:50:50.686944  6613 sgd_solver.cpp:106] Iteration 78000, lr = 1e-06
I0422 21:52:28.143512  6613 solver.cpp:228] Iteration 78100, loss = 0.126768
I0422 21:52:28.143666  6613 solver.cpp:244]     Train net output #0: loss = 0.126768 (* 1 = 0.126768 loss)
I0422 21:52:28.143676  6613 sgd_solver.cpp:106] Iteration 78100, lr = 1e-06
I0422 21:54:03.749737  6613 solver.cpp:228] Iteration 78200, loss = 0.180332
I0422 21:54:03.749908  6613 solver.cpp:244]     Train net output #0: loss = 0.180332 (* 1 = 0.180332 loss)
I0422 21:54:03.749915  6613 sgd_solver.cpp:106] Iteration 78200, lr = 1e-06
I0422 21:55:41.194855  6613 solver.cpp:228] Iteration 78300, loss = 0.0794489
I0422 21:55:41.195005  6613 solver.cpp:244]     Train net output #0: loss = 0.0794489 (* 1 = 0.0794489 loss)
I0422 21:55:41.195014  6613 sgd_solver.cpp:106] Iteration 78300, lr = 1e-06
I0422 21:57:18.832132  6613 solver.cpp:228] Iteration 78400, loss = 0.103107
I0422 21:57:18.832283  6613 solver.cpp:244]     Train net output #0: loss = 0.103107 (* 1 = 0.103107 loss)
I0422 21:57:18.832291  6613 sgd_solver.cpp:106] Iteration 78400, lr = 1e-06
I0422 21:58:56.182485  6613 solver.cpp:228] Iteration 78500, loss = 0.0940879
I0422 21:58:56.182632  6613 solver.cpp:244]     Train net output #0: loss = 0.0940879 (* 1 = 0.0940879 loss)
I0422 21:58:56.182641  6613 sgd_solver.cpp:106] Iteration 78500, lr = 1e-06
I0422 22:00:31.757402  6613 solver.cpp:228] Iteration 78600, loss = 0.105185
I0422 22:00:31.757544  6613 solver.cpp:244]     Train net output #0: loss = 0.105185 (* 1 = 0.105185 loss)
I0422 22:00:31.757551  6613 sgd_solver.cpp:106] Iteration 78600, lr = 1e-06
I0422 22:02:08.993948  6613 solver.cpp:228] Iteration 78700, loss = 0.441894
I0422 22:02:08.994096  6613 solver.cpp:244]     Train net output #0: loss = 0.441894 (* 1 = 0.441894 loss)
I0422 22:02:08.994102  6613 sgd_solver.cpp:106] Iteration 78700, lr = 1e-06
I0422 22:03:45.862684  6613 solver.cpp:228] Iteration 78800, loss = 0.0952956
I0422 22:03:45.862839  6613 solver.cpp:244]     Train net output #0: loss = 0.0952956 (* 1 = 0.0952956 loss)
I0422 22:03:45.862846  6613 sgd_solver.cpp:106] Iteration 78800, lr = 1e-06
I0422 22:05:22.764292  6613 solver.cpp:228] Iteration 78900, loss = 0.110799
I0422 22:05:22.764444  6613 solver.cpp:244]     Train net output #0: loss = 0.110799 (* 1 = 0.110799 loss)
I0422 22:05:22.764451  6613 sgd_solver.cpp:106] Iteration 78900, lr = 1e-06
I0422 22:06:58.976224  6613 solver.cpp:337] Iteration 79000, Testing net (#0)
I0422 22:06:58.976352  6613 net.cpp:693] Ignoring source layer dropout_d3c
I0422 22:06:58.976356  6613 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 22:06:58.976361  6613 net.cpp:693] Ignoring source layer dropout_d4c
I0422 22:06:58.976377  6613 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 22:06:58.976379  6613 net.cpp:693] Ignoring source layer visualize
I0422 22:06:58.976382  6613 net.cpp:693] Ignoring source layer fake
I0422 22:10:20.189808  6613 solver.cpp:404]     Test net output #0: loss = 0.120194 (* 1 = 0.120194 loss)
I0422 22:10:20.818604  6613 solver.cpp:228] Iteration 79000, loss = 0.125889
I0422 22:10:20.818642  6613 solver.cpp:244]     Train net output #0: loss = 0.125889 (* 1 = 0.125889 loss)
I0422 22:10:20.818650  6613 sgd_solver.cpp:106] Iteration 79000, lr = 1e-06
I0422 22:11:58.194795  6613 solver.cpp:228] Iteration 79100, loss = 0.123474
I0422 22:11:58.194974  6613 solver.cpp:244]     Train net output #0: loss = 0.123474 (* 1 = 0.123474 loss)
I0422 22:11:58.194984  6613 sgd_solver.cpp:106] Iteration 79100, lr = 1e-06
I0422 22:13:36.135630  6613 solver.cpp:228] Iteration 79200, loss = 0.107771
I0422 22:13:36.135808  6613 solver.cpp:244]     Train net output #0: loss = 0.107771 (* 1 = 0.107771 loss)
I0422 22:13:36.135817  6613 sgd_solver.cpp:106] Iteration 79200, lr = 1e-06
I0422 22:15:11.736346  6613 solver.cpp:228] Iteration 79300, loss = 0.104817
I0422 22:15:11.736491  6613 solver.cpp:244]     Train net output #0: loss = 0.104817 (* 1 = 0.104817 loss)
I0422 22:15:11.736500  6613 sgd_solver.cpp:106] Iteration 79300, lr = 1e-06
I0422 22:16:49.885864  6613 solver.cpp:228] Iteration 79400, loss = 0.149417
I0422 22:16:49.886011  6613 solver.cpp:244]     Train net output #0: loss = 0.149417 (* 1 = 0.149417 loss)
I0422 22:16:49.886018  6613 sgd_solver.cpp:106] Iteration 79400, lr = 1e-06
I0422 22:18:27.756793  6613 solver.cpp:228] Iteration 79500, loss = 0.104504
I0422 22:18:27.756952  6613 solver.cpp:244]     Train net output #0: loss = 0.104504 (* 1 = 0.104504 loss)
I0422 22:18:27.756960  6613 sgd_solver.cpp:106] Iteration 79500, lr = 1e-06
I0422 22:20:05.461488  6613 solver.cpp:228] Iteration 79600, loss = 0.112972
I0422 22:20:05.461627  6613 solver.cpp:244]     Train net output #0: loss = 0.112972 (* 1 = 0.112972 loss)
I0422 22:20:05.461634  6613 sgd_solver.cpp:106] Iteration 79600, lr = 1e-06
I0422 22:21:41.065217  6613 solver.cpp:228] Iteration 79700, loss = 0.125949
I0422 22:21:41.065356  6613 solver.cpp:244]     Train net output #0: loss = 0.125949 (* 1 = 0.125949 loss)
I0422 22:21:41.065361  6613 sgd_solver.cpp:106] Iteration 79700, lr = 1e-06
I0422 22:23:18.464392  6613 solver.cpp:228] Iteration 79800, loss = 0.103172
I0422 22:23:18.464537  6613 solver.cpp:244]     Train net output #0: loss = 0.103172 (* 1 = 0.103172 loss)
I0422 22:23:18.464545  6613 sgd_solver.cpp:106] Iteration 79800, lr = 1e-06
I0422 22:24:55.745872  6613 solver.cpp:228] Iteration 79900, loss = 0.105816
I0422 22:24:55.746013  6613 solver.cpp:244]     Train net output #0: loss = 0.105816 (* 1 = 0.105816 loss)
I0422 22:24:55.746022  6613 sgd_solver.cpp:106] Iteration 79900, lr = 1e-06
I0422 22:26:31.639667  6613 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_80000.caffemodel
I0422 22:26:45.021450  6613 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_weighted_3/unet_weighted_3_iter_80000.solverstate
