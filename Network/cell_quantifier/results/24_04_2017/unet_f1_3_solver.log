I0422 22:26:47.875512 16565 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3456
test_interval: 1000
base_lr: 0.0001
display: 100
max_iter: 300000
lr_policy: "step"
gamma: 0.3
momentum: 0.99
stepsize: 20000
snapshot: 5000
snapshot_prefix: "./snapshots/unet_f1_3/unet_f1_3"
solver_mode: GPU
net: "./unet_f1_3/unet_f1_3.prototxt"
regularization_type: "L2"
test_initialization: true
iter_size: 1
I0422 22:26:47.901798 16565 solver.cpp:91] Creating training net from net file: ./unet_f1_3/unet_f1_3.prototxt
I0422 22:26:47.902479 16565 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer loaddata
I0422 22:26:47.902878 16565 net.cpp:58] Initializing net from parameters: 
name: "unet_f1_3"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "caffeHDF5_3.txt"
    batch_size: 5
  }
}
layer {
  name: "conv_d0a-b"
  type: "Convolution"
  bottom: "data"
  top: "d0b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0b"
  type: "ReLU"
  bottom: "d0b"
  top: "d0b"
}
layer {
  name: "conv_d0b-c"
  type: "Convolution"
  bottom: "d0b"
  top: "d0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0c"
  type: "ReLU"
  bottom: "d0c"
  top: "d0c"
}
layer {
  name: "pool_d0c-1a"
  type: "Pooling"
  bottom: "d0c"
  top: "d1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d1a-b"
  type: "Convolution"
  bottom: "d1a"
  top: "d1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1b"
  type: "ReLU"
  bottom: "d1b"
  top: "d1b"
}
layer {
  name: "conv_d1b-c"
  type: "Convolution"
  bottom: "d1b"
  top: "d1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1c"
  type: "ReLU"
  bottom: "d1c"
  top: "d1c"
}
layer {
  name: "pool_d1c-2a"
  type: "Pooling"
  bottom: "d1c"
  top: "d2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d2a-b"
  type: "Convolution"
  bottom: "d2a"
  top: "d2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2b"
  type: "ReLU"
  bottom: "d2b"
  top: "d2b"
}
layer {
  name: "conv_d2b-c"
  type: "Convolution"
  bottom: "d2b"
  top: "d2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2c"
  type: "ReLU"
  bottom: "d2c"
  top: "d2c"
}
layer {
  name: "pool_d2c-3a"
  type: "Pooling"
  bottom: "d2c"
  top: "d3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d3a-b"
  type: "Convolution"
  bottom: "d3a"
  top: "d3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3b"
  type: "ReLU"
  bottom: "d3b"
  top: "d3b"
}
layer {
  name: "conv_d3b-c"
  type: "Convolution"
  bottom: "d3b"
  top: "d3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3c"
  type: "ReLU"
  bottom: "d3c"
  top: "d3c"
}
layer {
  name: "dropout_d3c"
  type: "Dropout"
  bottom: "d3c"
  top: "d3c"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool_d3c-4a"
  type: "Pooling"
  bottom: "d3c"
  top: "d4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d4a-b"
  type: "Convolution"
  bottom: "d4a"
  top: "d4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4b"
  type: "ReLU"
  bottom: "d4b"
  top: "d4b"
}
layer {
  name: "conv_d4b-c"
  type: "Convolution"
  bottom: "d4b"
  top: "d4c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4c"
  type: "ReLU"
  bottom: "d4c"
  top: "d4c"
}
layer {
  name: "dropout_d4c"
  type: "Dropout"
  bottom: "d4c"
  top: "d4c"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upconv_d4c_u3a"
  type: "Deconvolution"
  bottom: "d4c"
  top: "u3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u3a"
  type: "ReLU"
  bottom: "u3a"
  top: "u3a"
}
layer {
  name: "crop_d3c-d3cc"
  type: "Crop"
  bottom: "d3c"
  bottom: "u3a"
  top: "d3cc"
  crop_param {
    axis: 2
    offset: 4
  }
}
layer {
  name: "concat_d3cc_u3a-b"
  type: "Concat"
  bottom: "u3a"
  bottom: "d3cc"
  top: "u3b"
}
layer {
  name: "conv_u3b-c"
  type: "Convolution"
  bottom: "u3b"
  top: "u3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3c"
  type: "ReLU"
  bottom: "u3c"
  top: "u3c"
}
layer {
  name: "conv_u3c-d"
  type: "Convolution"
  bottom: "u3c"
  top: "u3d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3d"
  type: "ReLU"
  bottom: "u3d"
  top: "u3d"
}
layer {
  name: "upconv_u3d_u2a"
  type: "Deconvolution"
  bottom: "u3d"
  top: "u2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u2a"
  type: "ReLU"
  bottom: "u2a"
  top: "u2a"
}
layer {
  name: "crop_d2c-d2cc"
  type: "Crop"
  bottom: "d2c"
  bottom: "u2a"
  top: "d2cc"
  crop_param {
    axis: 2
    offset: 16
  }
}
layer {
  name: "concat_d2cc_u2a-b"
  type: "Concat"
  bottom: "u2a"
  bottom: "d2cc"
  top: "u2b"
}
layer {
  name: "conv_u2b-c"
  type: "Convolution"
  bottom: "u2b"
  top: "u2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2c"
  type: "ReLU"
  bottom: "u2c"
  top: "u2c"
}
layer {
  name: "conv_u2c-d"
  type: "Convolution"
  bottom: "u2c"
  top: "u2d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2d"
  type: "ReLU"
  bottom: "u2d"
  top: "u2d"
}
layer {
  name: "upconv_u2d_u1a"
  type: "Deconvolution"
  bottom: "u2d"
  top: "u1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u1a"
  type: "ReLU"
  bottom: "u1a"
  top: "u1a"
}
layer {
  name: "crop_d1c-d1cc"
  type: "Crop"
  bottom: "d1c"
  bottom: "u1a"
  top: "d1cc"
  crop_param {
    axis: 2
    offset: 40
  }
}
layer {
  name: "concat_d1cc_u1a-b"
  type: "Concat"
  bottom: "u1a"
  bottom: "d1cc"
  top: "u1b"
}
layer {
  name: "conv_u1b-c"
  type: "Convolution"
  bottom: "u1b"
  top: "u1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1c"
  type: "ReLU"
  bottom: "u1c"
  top: "u1c"
}
layer {
  name: "conv_u1c-d"
  type: "Convolution"
  bottom: "u1c"
  top: "u1d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1d"
  type: "ReLU"
  bottom: "u1d"
  top: "u1d"
}
layer {
  name: "upconv_u1d_u0a"
  type: "Deconvolution"
  bottom: "u1d"
  top: "u0a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u0a"
  type: "ReLU"
  bottom: "u0a"
  top: "u0a"
}
layer {
  name: "crop_d0c-d0cc"
  type: "Crop"
  bottom: "d0c"
  bottom: "u0a"
  top: "d0cc"
  crop_param {
    axis: 2
    offset: 88
  }
}
layer {
  name: "concat_d0cc_u0a-b"
  type: "Concat"
  bottom: "u0a"
  bottom: "d0cc"
  top: "u0b"
}
layer {
  name: "conv_u0b-c"
  type: "Convolution"
  bottom: "u0b"
  top: "u0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0c"
  type: "ReLU"
  bottom: "u0c"
  top: "u0c"
}
layer {
  name: "conv_u0c-d"
  type: "Convolution"
  bottom: "u0c"
  top: "u0d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0d"
  type: "ReLU"
  bottom: "u0d"
  top: "u0d"
}
layer {
  name: "conv_u0d-score"
  type: "Convolution"
  bottom: "u0d"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "score"
  top: "softmax_out"
}
layer {
  name: "reshapelab"
  type: "Reshape"
  bottom: "label"
  top: "label_flat"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "reshaperes"
  type: "Reshape"
  bottom: "softmax_out"
  top: "softmax_out_flat"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "loss"
  type: "Python"
  bottom: "softmax_out_flat"
  bottom: "label_flat"
  top: "loss"
  loss_weight: 1
  python_param {
    module: "multiclass_f1_loss"
    layer: "F1Loss"
  }
}
layer {
  name: "visualize"
  type: "Softmax"
  bottom: "score"
  top: "visualize_out"
  include {
    phase: TRAIN
  }
}
layer {
  name: "fake"
  type: "Silence"
  bottom: "visualize_out"
  include {
    phase: TRAIN
  }
}
I0422 22:26:47.903211 16565 layer_factory.hpp:77] Creating layer loaddata
I0422 22:26:47.903223 16565 net.cpp:100] Creating Layer loaddata
I0422 22:26:47.903236 16565 net.cpp:408] loaddata -> data
I0422 22:26:47.903246 16565 net.cpp:408] loaddata -> label
I0422 22:26:47.903257 16565 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: caffeHDF5_3.txt
I0422 22:26:47.909637 16565 hdf5_data_layer.cpp:93] Number of HDF5 files: 20
I0422 22:26:47.910606 16565 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0422 22:26:48.857957 16565 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0422 22:26:48.968624 16565 net.cpp:150] Setting up loaddata
I0422 22:26:48.968667 16565 net.cpp:157] Top shape: 5 3 428 428 (2747760)
I0422 22:26:48.968670 16565 net.cpp:157] Top shape: 5 244 244 (297680)
I0422 22:26:48.968672 16565 net.cpp:165] Memory required for data: 12181760
I0422 22:26:48.968678 16565 layer_factory.hpp:77] Creating layer conv_d0a-b
I0422 22:26:48.968695 16565 net.cpp:100] Creating Layer conv_d0a-b
I0422 22:26:48.968698 16565 net.cpp:434] conv_d0a-b <- data
I0422 22:26:48.968704 16565 net.cpp:408] conv_d0a-b -> d0b
I0422 22:26:48.972879 16565 net.cpp:150] Setting up conv_d0a-b
I0422 22:26:48.972894 16565 net.cpp:157] Top shape: 5 64 426 426 (58072320)
I0422 22:26:48.972913 16565 net.cpp:165] Memory required for data: 244471040
I0422 22:26:48.972921 16565 layer_factory.hpp:77] Creating layer relu_d0b
I0422 22:26:48.972929 16565 net.cpp:100] Creating Layer relu_d0b
I0422 22:26:48.972932 16565 net.cpp:434] relu_d0b <- d0b
I0422 22:26:48.972936 16565 net.cpp:395] relu_d0b -> d0b (in-place)
I0422 22:26:49.351893 16565 net.cpp:150] Setting up relu_d0b
I0422 22:26:49.351925 16565 net.cpp:157] Top shape: 5 64 426 426 (58072320)
I0422 22:26:49.351932 16565 net.cpp:165] Memory required for data: 476760320
I0422 22:26:49.351938 16565 layer_factory.hpp:77] Creating layer conv_d0b-c
I0422 22:26:49.351958 16565 net.cpp:100] Creating Layer conv_d0b-c
I0422 22:26:49.351964 16565 net.cpp:434] conv_d0b-c <- d0b
I0422 22:26:49.351976 16565 net.cpp:408] conv_d0b-c -> d0c
I0422 22:26:49.363385 16565 net.cpp:150] Setting up conv_d0b-c
I0422 22:26:49.363409 16565 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0422 22:26:49.363414 16565 net.cpp:165] Memory required for data: 706873600
I0422 22:26:49.363430 16565 layer_factory.hpp:77] Creating layer relu_d0c
I0422 22:26:49.363441 16565 net.cpp:100] Creating Layer relu_d0c
I0422 22:26:49.363446 16565 net.cpp:434] relu_d0c <- d0c
I0422 22:26:49.363453 16565 net.cpp:395] relu_d0c -> d0c (in-place)
I0422 22:26:49.370035 16565 net.cpp:150] Setting up relu_d0c
I0422 22:26:49.370059 16565 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0422 22:26:49.370062 16565 net.cpp:165] Memory required for data: 936986880
I0422 22:26:49.370067 16565 layer_factory.hpp:77] Creating layer d0c_relu_d0c_0_split
I0422 22:26:49.370079 16565 net.cpp:100] Creating Layer d0c_relu_d0c_0_split
I0422 22:26:49.370082 16565 net.cpp:434] d0c_relu_d0c_0_split <- d0c
I0422 22:26:49.370095 16565 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_0
I0422 22:26:49.370107 16565 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_1
I0422 22:26:49.370172 16565 net.cpp:150] Setting up d0c_relu_d0c_0_split
I0422 22:26:49.370182 16565 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0422 22:26:49.370187 16565 net.cpp:157] Top shape: 5 64 424 424 (57528320)
I0422 22:26:49.370192 16565 net.cpp:165] Memory required for data: 1397213440
I0422 22:26:49.370196 16565 layer_factory.hpp:77] Creating layer pool_d0c-1a
I0422 22:26:49.370208 16565 net.cpp:100] Creating Layer pool_d0c-1a
I0422 22:26:49.370211 16565 net.cpp:434] pool_d0c-1a <- d0c_relu_d0c_0_split_0
I0422 22:26:49.370220 16565 net.cpp:408] pool_d0c-1a -> d1a
I0422 22:26:49.370270 16565 net.cpp:150] Setting up pool_d0c-1a
I0422 22:26:49.370280 16565 net.cpp:157] Top shape: 5 64 212 212 (14382080)
I0422 22:26:49.370283 16565 net.cpp:165] Memory required for data: 1454741760
I0422 22:26:49.370287 16565 layer_factory.hpp:77] Creating layer conv_d1a-b
I0422 22:26:49.370301 16565 net.cpp:100] Creating Layer conv_d1a-b
I0422 22:26:49.370306 16565 net.cpp:434] conv_d1a-b <- d1a
I0422 22:26:49.370314 16565 net.cpp:408] conv_d1a-b -> d1b
I0422 22:26:49.371412 16565 net.cpp:150] Setting up conv_d1a-b
I0422 22:26:49.371424 16565 net.cpp:157] Top shape: 5 128 210 210 (28224000)
I0422 22:26:49.371428 16565 net.cpp:165] Memory required for data: 1567637760
I0422 22:26:49.371443 16565 layer_factory.hpp:77] Creating layer relu_d1b
I0422 22:26:49.371453 16565 net.cpp:100] Creating Layer relu_d1b
I0422 22:26:49.371457 16565 net.cpp:434] relu_d1b <- d1b
I0422 22:26:49.371464 16565 net.cpp:395] relu_d1b -> d1b (in-place)
I0422 22:26:49.371743 16565 net.cpp:150] Setting up relu_d1b
I0422 22:26:49.371757 16565 net.cpp:157] Top shape: 5 128 210 210 (28224000)
I0422 22:26:49.371762 16565 net.cpp:165] Memory required for data: 1680533760
I0422 22:26:49.371767 16565 layer_factory.hpp:77] Creating layer conv_d1b-c
I0422 22:26:49.371778 16565 net.cpp:100] Creating Layer conv_d1b-c
I0422 22:26:49.371786 16565 net.cpp:434] conv_d1b-c <- d1b
I0422 22:26:49.371795 16565 net.cpp:408] conv_d1b-c -> d1c
I0422 22:26:49.374778 16565 net.cpp:150] Setting up conv_d1b-c
I0422 22:26:49.374799 16565 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0422 22:26:49.374804 16565 net.cpp:165] Memory required for data: 1791289600
I0422 22:26:49.374814 16565 layer_factory.hpp:77] Creating layer relu_d1c
I0422 22:26:49.374825 16565 net.cpp:100] Creating Layer relu_d1c
I0422 22:26:49.374828 16565 net.cpp:434] relu_d1c <- d1c
I0422 22:26:49.374835 16565 net.cpp:395] relu_d1c -> d1c (in-place)
I0422 22:26:49.375120 16565 net.cpp:150] Setting up relu_d1c
I0422 22:26:49.375133 16565 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0422 22:26:49.375138 16565 net.cpp:165] Memory required for data: 1902045440
I0422 22:26:49.375143 16565 layer_factory.hpp:77] Creating layer d1c_relu_d1c_0_split
I0422 22:26:49.375152 16565 net.cpp:100] Creating Layer d1c_relu_d1c_0_split
I0422 22:26:49.375156 16565 net.cpp:434] d1c_relu_d1c_0_split <- d1c
I0422 22:26:49.375164 16565 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_0
I0422 22:26:49.375174 16565 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_1
I0422 22:26:49.375237 16565 net.cpp:150] Setting up d1c_relu_d1c_0_split
I0422 22:26:49.375247 16565 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0422 22:26:49.375252 16565 net.cpp:157] Top shape: 5 128 208 208 (27688960)
I0422 22:26:49.375255 16565 net.cpp:165] Memory required for data: 2123557120
I0422 22:26:49.375260 16565 layer_factory.hpp:77] Creating layer pool_d1c-2a
I0422 22:26:49.375268 16565 net.cpp:100] Creating Layer pool_d1c-2a
I0422 22:26:49.375272 16565 net.cpp:434] pool_d1c-2a <- d1c_relu_d1c_0_split_0
I0422 22:26:49.375280 16565 net.cpp:408] pool_d1c-2a -> d2a
I0422 22:26:49.375330 16565 net.cpp:150] Setting up pool_d1c-2a
I0422 22:26:49.375339 16565 net.cpp:157] Top shape: 5 128 104 104 (6922240)
I0422 22:26:49.375342 16565 net.cpp:165] Memory required for data: 2151246080
I0422 22:26:49.375346 16565 layer_factory.hpp:77] Creating layer conv_d2a-b
I0422 22:26:49.375362 16565 net.cpp:100] Creating Layer conv_d2a-b
I0422 22:26:49.375368 16565 net.cpp:434] conv_d2a-b <- d2a
I0422 22:26:49.375376 16565 net.cpp:408] conv_d2a-b -> d2b
I0422 22:26:49.379608 16565 net.cpp:150] Setting up conv_d2a-b
I0422 22:26:49.379629 16565 net.cpp:157] Top shape: 5 256 102 102 (13317120)
I0422 22:26:49.379633 16565 net.cpp:165] Memory required for data: 2204514560
I0422 22:26:49.379647 16565 layer_factory.hpp:77] Creating layer relu_d2b
I0422 22:26:49.379655 16565 net.cpp:100] Creating Layer relu_d2b
I0422 22:26:49.379662 16565 net.cpp:434] relu_d2b <- d2b
I0422 22:26:49.379673 16565 net.cpp:395] relu_d2b -> d2b (in-place)
I0422 22:26:49.379966 16565 net.cpp:150] Setting up relu_d2b
I0422 22:26:49.379981 16565 net.cpp:157] Top shape: 5 256 102 102 (13317120)
I0422 22:26:49.379986 16565 net.cpp:165] Memory required for data: 2257783040
I0422 22:26:49.379989 16565 layer_factory.hpp:77] Creating layer conv_d2b-c
I0422 22:26:49.380002 16565 net.cpp:100] Creating Layer conv_d2b-c
I0422 22:26:49.380007 16565 net.cpp:434] conv_d2b-c <- d2b
I0422 22:26:49.380028 16565 net.cpp:408] conv_d2b-c -> d2c
I0422 22:26:49.387024 16565 net.cpp:150] Setting up conv_d2b-c
I0422 22:26:49.387046 16565 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0422 22:26:49.387050 16565 net.cpp:165] Memory required for data: 2308983040
I0422 22:26:49.387060 16565 layer_factory.hpp:77] Creating layer relu_d2c
I0422 22:26:49.387073 16565 net.cpp:100] Creating Layer relu_d2c
I0422 22:26:49.387079 16565 net.cpp:434] relu_d2c <- d2c
I0422 22:26:49.387085 16565 net.cpp:395] relu_d2c -> d2c (in-place)
I0422 22:26:49.388221 16565 net.cpp:150] Setting up relu_d2c
I0422 22:26:49.388238 16565 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0422 22:26:49.388242 16565 net.cpp:165] Memory required for data: 2360183040
I0422 22:26:49.388247 16565 layer_factory.hpp:77] Creating layer d2c_relu_d2c_0_split
I0422 22:26:49.388259 16565 net.cpp:100] Creating Layer d2c_relu_d2c_0_split
I0422 22:26:49.388264 16565 net.cpp:434] d2c_relu_d2c_0_split <- d2c
I0422 22:26:49.388272 16565 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_0
I0422 22:26:49.388281 16565 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_1
I0422 22:26:49.388341 16565 net.cpp:150] Setting up d2c_relu_d2c_0_split
I0422 22:26:49.388351 16565 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0422 22:26:49.388356 16565 net.cpp:157] Top shape: 5 256 100 100 (12800000)
I0422 22:26:49.388360 16565 net.cpp:165] Memory required for data: 2462583040
I0422 22:26:49.388365 16565 layer_factory.hpp:77] Creating layer pool_d2c-3a
I0422 22:26:49.388372 16565 net.cpp:100] Creating Layer pool_d2c-3a
I0422 22:26:49.388376 16565 net.cpp:434] pool_d2c-3a <- d2c_relu_d2c_0_split_0
I0422 22:26:49.388384 16565 net.cpp:408] pool_d2c-3a -> d3a
I0422 22:26:49.388439 16565 net.cpp:150] Setting up pool_d2c-3a
I0422 22:26:49.388448 16565 net.cpp:157] Top shape: 5 256 50 50 (3200000)
I0422 22:26:49.388451 16565 net.cpp:165] Memory required for data: 2475383040
I0422 22:26:49.388455 16565 layer_factory.hpp:77] Creating layer conv_d3a-b
I0422 22:26:49.388468 16565 net.cpp:100] Creating Layer conv_d3a-b
I0422 22:26:49.388473 16565 net.cpp:434] conv_d3a-b <- d3a
I0422 22:26:49.388481 16565 net.cpp:408] conv_d3a-b -> d3b
I0422 22:26:49.401967 16565 net.cpp:150] Setting up conv_d3a-b
I0422 22:26:49.401986 16565 net.cpp:157] Top shape: 5 512 48 48 (5898240)
I0422 22:26:49.401989 16565 net.cpp:165] Memory required for data: 2498976000
I0422 22:26:49.401998 16565 layer_factory.hpp:77] Creating layer relu_d3b
I0422 22:26:49.402005 16565 net.cpp:100] Creating Layer relu_d3b
I0422 22:26:49.402010 16565 net.cpp:434] relu_d3b <- d3b
I0422 22:26:49.402016 16565 net.cpp:395] relu_d3b -> d3b (in-place)
I0422 22:26:49.402284 16565 net.cpp:150] Setting up relu_d3b
I0422 22:26:49.402297 16565 net.cpp:157] Top shape: 5 512 48 48 (5898240)
I0422 22:26:49.402300 16565 net.cpp:165] Memory required for data: 2522568960
I0422 22:26:49.402304 16565 layer_factory.hpp:77] Creating layer conv_d3b-c
I0422 22:26:49.402317 16565 net.cpp:100] Creating Layer conv_d3b-c
I0422 22:26:49.402320 16565 net.cpp:434] conv_d3b-c <- d3b
I0422 22:26:49.402328 16565 net.cpp:408] conv_d3b-c -> d3c
I0422 22:26:49.424672 16565 net.cpp:150] Setting up conv_d3b-c
I0422 22:26:49.424688 16565 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0422 22:26:49.424692 16565 net.cpp:165] Memory required for data: 2544236800
I0422 22:26:49.424700 16565 layer_factory.hpp:77] Creating layer relu_d3c
I0422 22:26:49.424707 16565 net.cpp:100] Creating Layer relu_d3c
I0422 22:26:49.424711 16565 net.cpp:434] relu_d3c <- d3c
I0422 22:26:49.424720 16565 net.cpp:395] relu_d3c -> d3c (in-place)
I0422 22:26:49.424973 16565 net.cpp:150] Setting up relu_d3c
I0422 22:26:49.424985 16565 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0422 22:26:49.424988 16565 net.cpp:165] Memory required for data: 2565904640
I0422 22:26:49.424993 16565 layer_factory.hpp:77] Creating layer dropout_d3c
I0422 22:26:49.425001 16565 net.cpp:100] Creating Layer dropout_d3c
I0422 22:26:49.425004 16565 net.cpp:434] dropout_d3c <- d3c
I0422 22:26:49.425012 16565 net.cpp:395] dropout_d3c -> d3c (in-place)
I0422 22:26:49.425068 16565 net.cpp:150] Setting up dropout_d3c
I0422 22:26:49.425079 16565 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0422 22:26:49.425082 16565 net.cpp:165] Memory required for data: 2587572480
I0422 22:26:49.425086 16565 layer_factory.hpp:77] Creating layer d3c_dropout_d3c_0_split
I0422 22:26:49.425092 16565 net.cpp:100] Creating Layer d3c_dropout_d3c_0_split
I0422 22:26:49.425096 16565 net.cpp:434] d3c_dropout_d3c_0_split <- d3c
I0422 22:26:49.425104 16565 net.cpp:408] d3c_dropout_d3c_0_split -> d3c_dropout_d3c_0_split_0
I0422 22:26:49.425112 16565 net.cpp:408] d3c_dropout_d3c_0_split -> d3c_dropout_d3c_0_split_1
I0422 22:26:49.425156 16565 net.cpp:150] Setting up d3c_dropout_d3c_0_split
I0422 22:26:49.425165 16565 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0422 22:26:49.425170 16565 net.cpp:157] Top shape: 5 512 46 46 (5416960)
I0422 22:26:49.425173 16565 net.cpp:165] Memory required for data: 2630908160
I0422 22:26:49.425176 16565 layer_factory.hpp:77] Creating layer pool_d3c-4a
I0422 22:26:49.425185 16565 net.cpp:100] Creating Layer pool_d3c-4a
I0422 22:26:49.425189 16565 net.cpp:434] pool_d3c-4a <- d3c_dropout_d3c_0_split_0
I0422 22:26:49.425196 16565 net.cpp:408] pool_d3c-4a -> d4a
I0422 22:26:49.425238 16565 net.cpp:150] Setting up pool_d3c-4a
I0422 22:26:49.425247 16565 net.cpp:157] Top shape: 5 512 23 23 (1354240)
I0422 22:26:49.425251 16565 net.cpp:165] Memory required for data: 2636325120
I0422 22:26:49.425253 16565 layer_factory.hpp:77] Creating layer conv_d4a-b
I0422 22:26:49.425266 16565 net.cpp:100] Creating Layer conv_d4a-b
I0422 22:26:49.425271 16565 net.cpp:434] conv_d4a-b <- d4a
I0422 22:26:49.425278 16565 net.cpp:408] conv_d4a-b -> d4b
I0422 22:26:49.466424 16565 net.cpp:150] Setting up conv_d4a-b
I0422 22:26:49.466441 16565 net.cpp:157] Top shape: 5 1024 21 21 (2257920)
I0422 22:26:49.466446 16565 net.cpp:165] Memory required for data: 2645356800
I0422 22:26:49.466459 16565 layer_factory.hpp:77] Creating layer relu_d4b
I0422 22:26:49.466470 16565 net.cpp:100] Creating Layer relu_d4b
I0422 22:26:49.466475 16565 net.cpp:434] relu_d4b <- d4b
I0422 22:26:49.466480 16565 net.cpp:395] relu_d4b -> d4b (in-place)
I0422 22:26:49.467460 16565 net.cpp:150] Setting up relu_d4b
I0422 22:26:49.467475 16565 net.cpp:157] Top shape: 5 1024 21 21 (2257920)
I0422 22:26:49.467478 16565 net.cpp:165] Memory required for data: 2654388480
I0422 22:26:49.467483 16565 layer_factory.hpp:77] Creating layer conv_d4b-c
I0422 22:26:49.467494 16565 net.cpp:100] Creating Layer conv_d4b-c
I0422 22:26:49.467497 16565 net.cpp:434] conv_d4b-c <- d4b
I0422 22:26:49.467507 16565 net.cpp:408] conv_d4b-c -> d4c
I0422 22:26:49.545971 16565 net.cpp:150] Setting up conv_d4b-c
I0422 22:26:49.545996 16565 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0422 22:26:49.546000 16565 net.cpp:165] Memory required for data: 2661781760
I0422 22:26:49.546011 16565 layer_factory.hpp:77] Creating layer relu_d4c
I0422 22:26:49.546022 16565 net.cpp:100] Creating Layer relu_d4c
I0422 22:26:49.546030 16565 net.cpp:434] relu_d4c <- d4c
I0422 22:26:49.546036 16565 net.cpp:395] relu_d4c -> d4c (in-place)
I0422 22:26:49.546315 16565 net.cpp:150] Setting up relu_d4c
I0422 22:26:49.546329 16565 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0422 22:26:49.546331 16565 net.cpp:165] Memory required for data: 2669175040
I0422 22:26:49.546335 16565 layer_factory.hpp:77] Creating layer dropout_d4c
I0422 22:26:49.546344 16565 net.cpp:100] Creating Layer dropout_d4c
I0422 22:26:49.546347 16565 net.cpp:434] dropout_d4c <- d4c
I0422 22:26:49.546352 16565 net.cpp:395] dropout_d4c -> d4c (in-place)
I0422 22:26:49.546388 16565 net.cpp:150] Setting up dropout_d4c
I0422 22:26:49.546396 16565 net.cpp:157] Top shape: 5 1024 19 19 (1848320)
I0422 22:26:49.546401 16565 net.cpp:165] Memory required for data: 2676568320
I0422 22:26:49.546403 16565 layer_factory.hpp:77] Creating layer upconv_d4c_u3a
I0422 22:26:49.546412 16565 net.cpp:100] Creating Layer upconv_d4c_u3a
I0422 22:26:49.546416 16565 net.cpp:434] upconv_d4c_u3a <- d4c
I0422 22:26:49.546439 16565 net.cpp:408] upconv_d4c_u3a -> u3a
I0422 22:26:49.564337 16565 net.cpp:150] Setting up upconv_d4c_u3a
I0422 22:26:49.564352 16565 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0422 22:26:49.564357 16565 net.cpp:165] Memory required for data: 2691354880
I0422 22:26:49.564370 16565 layer_factory.hpp:77] Creating layer relu_u3a
I0422 22:26:49.564385 16565 net.cpp:100] Creating Layer relu_u3a
I0422 22:26:49.564389 16565 net.cpp:434] relu_u3a <- u3a
I0422 22:26:49.564395 16565 net.cpp:395] relu_u3a -> u3a (in-place)
I0422 22:26:49.564630 16565 net.cpp:150] Setting up relu_u3a
I0422 22:26:49.564642 16565 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0422 22:26:49.564646 16565 net.cpp:165] Memory required for data: 2706141440
I0422 22:26:49.564649 16565 layer_factory.hpp:77] Creating layer u3a_relu_u3a_0_split
I0422 22:26:49.564656 16565 net.cpp:100] Creating Layer u3a_relu_u3a_0_split
I0422 22:26:49.564659 16565 net.cpp:434] u3a_relu_u3a_0_split <- u3a
I0422 22:26:49.564666 16565 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_0
I0422 22:26:49.564673 16565 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_1
I0422 22:26:49.564723 16565 net.cpp:150] Setting up u3a_relu_u3a_0_split
I0422 22:26:49.564730 16565 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0422 22:26:49.564734 16565 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0422 22:26:49.564738 16565 net.cpp:165] Memory required for data: 2735714560
I0422 22:26:49.564741 16565 layer_factory.hpp:77] Creating layer crop_d3c-d3cc
I0422 22:26:49.564750 16565 net.cpp:100] Creating Layer crop_d3c-d3cc
I0422 22:26:49.564754 16565 net.cpp:434] crop_d3c-d3cc <- d3c_dropout_d3c_0_split_1
I0422 22:26:49.564759 16565 net.cpp:434] crop_d3c-d3cc <- u3a_relu_u3a_0_split_0
I0422 22:26:49.564764 16565 net.cpp:408] crop_d3c-d3cc -> d3cc
I0422 22:26:49.564790 16565 net.cpp:150] Setting up crop_d3c-d3cc
I0422 22:26:49.564797 16565 net.cpp:157] Top shape: 5 512 38 38 (3696640)
I0422 22:26:49.564800 16565 net.cpp:165] Memory required for data: 2750501120
I0422 22:26:49.564805 16565 layer_factory.hpp:77] Creating layer concat_d3cc_u3a-b
I0422 22:26:49.564810 16565 net.cpp:100] Creating Layer concat_d3cc_u3a-b
I0422 22:26:49.564813 16565 net.cpp:434] concat_d3cc_u3a-b <- u3a_relu_u3a_0_split_1
I0422 22:26:49.564817 16565 net.cpp:434] concat_d3cc_u3a-b <- d3cc
I0422 22:26:49.564826 16565 net.cpp:408] concat_d3cc_u3a-b -> u3b
I0422 22:26:49.564851 16565 net.cpp:150] Setting up concat_d3cc_u3a-b
I0422 22:26:49.564857 16565 net.cpp:157] Top shape: 5 1024 38 38 (7393280)
I0422 22:26:49.564860 16565 net.cpp:165] Memory required for data: 2780074240
I0422 22:26:49.564864 16565 layer_factory.hpp:77] Creating layer conv_u3b-c
I0422 22:26:49.564874 16565 net.cpp:100] Creating Layer conv_u3b-c
I0422 22:26:49.564878 16565 net.cpp:434] conv_u3b-c <- u3b
I0422 22:26:49.564883 16565 net.cpp:408] conv_u3b-c -> u3c
I0422 22:26:49.604084 16565 net.cpp:150] Setting up conv_u3b-c
I0422 22:26:49.604101 16565 net.cpp:157] Top shape: 5 512 36 36 (3317760)
I0422 22:26:49.604105 16565 net.cpp:165] Memory required for data: 2793345280
I0422 22:26:49.604112 16565 layer_factory.hpp:77] Creating layer relu_u3c
I0422 22:26:49.604121 16565 net.cpp:100] Creating Layer relu_u3c
I0422 22:26:49.604125 16565 net.cpp:434] relu_u3c <- u3c
I0422 22:26:49.604130 16565 net.cpp:395] relu_u3c -> u3c (in-place)
I0422 22:26:49.604365 16565 net.cpp:150] Setting up relu_u3c
I0422 22:26:49.604377 16565 net.cpp:157] Top shape: 5 512 36 36 (3317760)
I0422 22:26:49.604380 16565 net.cpp:165] Memory required for data: 2806616320
I0422 22:26:49.604383 16565 layer_factory.hpp:77] Creating layer conv_u3c-d
I0422 22:26:49.604394 16565 net.cpp:100] Creating Layer conv_u3c-d
I0422 22:26:49.604399 16565 net.cpp:434] conv_u3c-d <- u3c
I0422 22:26:49.604405 16565 net.cpp:408] conv_u3c-d -> u3d
I0422 22:26:49.624367 16565 net.cpp:150] Setting up conv_u3c-d
I0422 22:26:49.624382 16565 net.cpp:157] Top shape: 5 512 34 34 (2959360)
I0422 22:26:49.624387 16565 net.cpp:165] Memory required for data: 2818453760
I0422 22:26:49.624397 16565 layer_factory.hpp:77] Creating layer relu_u3d
I0422 22:26:49.624418 16565 net.cpp:100] Creating Layer relu_u3d
I0422 22:26:49.624421 16565 net.cpp:434] relu_u3d <- u3d
I0422 22:26:49.624429 16565 net.cpp:395] relu_u3d -> u3d (in-place)
I0422 22:26:49.627099 16565 net.cpp:150] Setting up relu_u3d
I0422 22:26:49.627117 16565 net.cpp:157] Top shape: 5 512 34 34 (2959360)
I0422 22:26:49.627121 16565 net.cpp:165] Memory required for data: 2830291200
I0422 22:26:49.627132 16565 layer_factory.hpp:77] Creating layer upconv_u3d_u2a
I0422 22:26:49.627143 16565 net.cpp:100] Creating Layer upconv_u3d_u2a
I0422 22:26:49.627146 16565 net.cpp:434] upconv_u3d_u2a <- u3d
I0422 22:26:49.627156 16565 net.cpp:408] upconv_u3d_u2a -> u2a
I0422 22:26:49.632138 16565 net.cpp:150] Setting up upconv_u3d_u2a
I0422 22:26:49.632154 16565 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0422 22:26:49.632158 16565 net.cpp:165] Memory required for data: 2853966080
I0422 22:26:49.632174 16565 layer_factory.hpp:77] Creating layer relu_u2a
I0422 22:26:49.632184 16565 net.cpp:100] Creating Layer relu_u2a
I0422 22:26:49.632187 16565 net.cpp:434] relu_u2a <- u2a
I0422 22:26:49.632194 16565 net.cpp:395] relu_u2a -> u2a (in-place)
I0422 22:26:49.632416 16565 net.cpp:150] Setting up relu_u2a
I0422 22:26:49.632427 16565 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0422 22:26:49.632431 16565 net.cpp:165] Memory required for data: 2877640960
I0422 22:26:49.632433 16565 layer_factory.hpp:77] Creating layer u2a_relu_u2a_0_split
I0422 22:26:49.632441 16565 net.cpp:100] Creating Layer u2a_relu_u2a_0_split
I0422 22:26:49.632446 16565 net.cpp:434] u2a_relu_u2a_0_split <- u2a
I0422 22:26:49.632453 16565 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_0
I0422 22:26:49.632467 16565 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_1
I0422 22:26:49.632519 16565 net.cpp:150] Setting up u2a_relu_u2a_0_split
I0422 22:26:49.632529 16565 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0422 22:26:49.632532 16565 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0422 22:26:49.632535 16565 net.cpp:165] Memory required for data: 2924990720
I0422 22:26:49.632539 16565 layer_factory.hpp:77] Creating layer crop_d2c-d2cc
I0422 22:26:49.632547 16565 net.cpp:100] Creating Layer crop_d2c-d2cc
I0422 22:26:49.632551 16565 net.cpp:434] crop_d2c-d2cc <- d2c_relu_d2c_0_split_1
I0422 22:26:49.632555 16565 net.cpp:434] crop_d2c-d2cc <- u2a_relu_u2a_0_split_0
I0422 22:26:49.632561 16565 net.cpp:408] crop_d2c-d2cc -> d2cc
I0422 22:26:49.632589 16565 net.cpp:150] Setting up crop_d2c-d2cc
I0422 22:26:49.632596 16565 net.cpp:157] Top shape: 5 256 68 68 (5918720)
I0422 22:26:49.632599 16565 net.cpp:165] Memory required for data: 2948665600
I0422 22:26:49.632602 16565 layer_factory.hpp:77] Creating layer concat_d2cc_u2a-b
I0422 22:26:49.632608 16565 net.cpp:100] Creating Layer concat_d2cc_u2a-b
I0422 22:26:49.632611 16565 net.cpp:434] concat_d2cc_u2a-b <- u2a_relu_u2a_0_split_1
I0422 22:26:49.632616 16565 net.cpp:434] concat_d2cc_u2a-b <- d2cc
I0422 22:26:49.632622 16565 net.cpp:408] concat_d2cc_u2a-b -> u2b
I0422 22:26:49.632648 16565 net.cpp:150] Setting up concat_d2cc_u2a-b
I0422 22:26:49.632655 16565 net.cpp:157] Top shape: 5 512 68 68 (11837440)
I0422 22:26:49.632658 16565 net.cpp:165] Memory required for data: 2996015360
I0422 22:26:49.632661 16565 layer_factory.hpp:77] Creating layer conv_u2b-c
I0422 22:26:49.632673 16565 net.cpp:100] Creating Layer conv_u2b-c
I0422 22:26:49.632678 16565 net.cpp:434] conv_u2b-c <- u2b
I0422 22:26:49.632683 16565 net.cpp:408] conv_u2b-c -> u2c
I0422 22:26:49.642901 16565 net.cpp:150] Setting up conv_u2b-c
I0422 22:26:49.642918 16565 net.cpp:157] Top shape: 5 256 66 66 (5575680)
I0422 22:26:49.642921 16565 net.cpp:165] Memory required for data: 3018318080
I0422 22:26:49.642935 16565 layer_factory.hpp:77] Creating layer relu_u2c
I0422 22:26:49.642942 16565 net.cpp:100] Creating Layer relu_u2c
I0422 22:26:49.642947 16565 net.cpp:434] relu_u2c <- u2c
I0422 22:26:49.642952 16565 net.cpp:395] relu_u2c -> u2c (in-place)
I0422 22:26:49.643182 16565 net.cpp:150] Setting up relu_u2c
I0422 22:26:49.643208 16565 net.cpp:157] Top shape: 5 256 66 66 (5575680)
I0422 22:26:49.643213 16565 net.cpp:165] Memory required for data: 3040620800
I0422 22:26:49.643215 16565 layer_factory.hpp:77] Creating layer conv_u2c-d
I0422 22:26:49.643225 16565 net.cpp:100] Creating Layer conv_u2c-d
I0422 22:26:49.643229 16565 net.cpp:434] conv_u2c-d <- u2c
I0422 22:26:49.643236 16565 net.cpp:408] conv_u2c-d -> u2d
I0422 22:26:49.648675 16565 net.cpp:150] Setting up conv_u2c-d
I0422 22:26:49.648691 16565 net.cpp:157] Top shape: 5 256 64 64 (5242880)
I0422 22:26:49.648694 16565 net.cpp:165] Memory required for data: 3061592320
I0422 22:26:49.648702 16565 layer_factory.hpp:77] Creating layer relu_u2d
I0422 22:26:49.648710 16565 net.cpp:100] Creating Layer relu_u2d
I0422 22:26:49.648712 16565 net.cpp:434] relu_u2d <- u2d
I0422 22:26:49.648720 16565 net.cpp:395] relu_u2d -> u2d (in-place)
I0422 22:26:49.648955 16565 net.cpp:150] Setting up relu_u2d
I0422 22:26:49.648967 16565 net.cpp:157] Top shape: 5 256 64 64 (5242880)
I0422 22:26:49.648969 16565 net.cpp:165] Memory required for data: 3082563840
I0422 22:26:49.648972 16565 layer_factory.hpp:77] Creating layer upconv_u2d_u1a
I0422 22:26:49.648983 16565 net.cpp:100] Creating Layer upconv_u2d_u1a
I0422 22:26:49.648986 16565 net.cpp:434] upconv_u2d_u1a <- u2d
I0422 22:26:49.648993 16565 net.cpp:408] upconv_u2d_u1a -> u1a
I0422 22:26:49.651221 16565 net.cpp:150] Setting up upconv_u2d_u1a
I0422 22:26:49.651237 16565 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0422 22:26:49.651240 16565 net.cpp:165] Memory required for data: 3124506880
I0422 22:26:49.651262 16565 layer_factory.hpp:77] Creating layer relu_u1a
I0422 22:26:49.651270 16565 net.cpp:100] Creating Layer relu_u1a
I0422 22:26:49.651275 16565 net.cpp:434] relu_u1a <- u1a
I0422 22:26:49.651280 16565 net.cpp:395] relu_u1a -> u1a (in-place)
I0422 22:26:49.657116 16565 net.cpp:150] Setting up relu_u1a
I0422 22:26:49.657135 16565 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0422 22:26:49.657140 16565 net.cpp:165] Memory required for data: 3166449920
I0422 22:26:49.657143 16565 layer_factory.hpp:77] Creating layer u1a_relu_u1a_0_split
I0422 22:26:49.657150 16565 net.cpp:100] Creating Layer u1a_relu_u1a_0_split
I0422 22:26:49.657155 16565 net.cpp:434] u1a_relu_u1a_0_split <- u1a
I0422 22:26:49.657165 16565 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_0
I0422 22:26:49.657173 16565 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_1
I0422 22:26:49.657227 16565 net.cpp:150] Setting up u1a_relu_u1a_0_split
I0422 22:26:49.657232 16565 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0422 22:26:49.657238 16565 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0422 22:26:49.657240 16565 net.cpp:165] Memory required for data: 3250336000
I0422 22:26:49.657243 16565 layer_factory.hpp:77] Creating layer crop_d1c-d1cc
I0422 22:26:49.657250 16565 net.cpp:100] Creating Layer crop_d1c-d1cc
I0422 22:26:49.657256 16565 net.cpp:434] crop_d1c-d1cc <- d1c_relu_d1c_0_split_1
I0422 22:26:49.657261 16565 net.cpp:434] crop_d1c-d1cc <- u1a_relu_u1a_0_split_0
I0422 22:26:49.657266 16565 net.cpp:408] crop_d1c-d1cc -> d1cc
I0422 22:26:49.657294 16565 net.cpp:150] Setting up crop_d1c-d1cc
I0422 22:26:49.657301 16565 net.cpp:157] Top shape: 5 128 128 128 (10485760)
I0422 22:26:49.657305 16565 net.cpp:165] Memory required for data: 3292279040
I0422 22:26:49.657307 16565 layer_factory.hpp:77] Creating layer concat_d1cc_u1a-b
I0422 22:26:49.657313 16565 net.cpp:100] Creating Layer concat_d1cc_u1a-b
I0422 22:26:49.657317 16565 net.cpp:434] concat_d1cc_u1a-b <- u1a_relu_u1a_0_split_1
I0422 22:26:49.657321 16565 net.cpp:434] concat_d1cc_u1a-b <- d1cc
I0422 22:26:49.657328 16565 net.cpp:408] concat_d1cc_u1a-b -> u1b
I0422 22:26:49.657351 16565 net.cpp:150] Setting up concat_d1cc_u1a-b
I0422 22:26:49.657357 16565 net.cpp:157] Top shape: 5 256 128 128 (20971520)
I0422 22:26:49.657361 16565 net.cpp:165] Memory required for data: 3376165120
I0422 22:26:49.657363 16565 layer_factory.hpp:77] Creating layer conv_u1b-c
I0422 22:26:49.657394 16565 net.cpp:100] Creating Layer conv_u1b-c
I0422 22:26:49.657399 16565 net.cpp:434] conv_u1b-c <- u1b
I0422 22:26:49.657407 16565 net.cpp:408] conv_u1b-c -> u1c
I0422 22:26:49.659806 16565 net.cpp:150] Setting up conv_u1b-c
I0422 22:26:49.659817 16565 net.cpp:157] Top shape: 5 128 126 126 (10160640)
I0422 22:26:49.659821 16565 net.cpp:165] Memory required for data: 3416807680
I0422 22:26:49.659837 16565 layer_factory.hpp:77] Creating layer relu_u1c
I0422 22:26:49.659844 16565 net.cpp:100] Creating Layer relu_u1c
I0422 22:26:49.659848 16565 net.cpp:434] relu_u1c <- u1c
I0422 22:26:49.659854 16565 net.cpp:395] relu_u1c -> u1c (in-place)
I0422 22:26:49.660068 16565 net.cpp:150] Setting up relu_u1c
I0422 22:26:49.660079 16565 net.cpp:157] Top shape: 5 128 126 126 (10160640)
I0422 22:26:49.660081 16565 net.cpp:165] Memory required for data: 3457450240
I0422 22:26:49.660085 16565 layer_factory.hpp:77] Creating layer conv_u1c-d
I0422 22:26:49.660096 16565 net.cpp:100] Creating Layer conv_u1c-d
I0422 22:26:49.660099 16565 net.cpp:434] conv_u1c-d <- u1c
I0422 22:26:49.660106 16565 net.cpp:408] conv_u1c-d -> u1d
I0422 22:26:49.665782 16565 net.cpp:150] Setting up conv_u1c-d
I0422 22:26:49.665801 16565 net.cpp:157] Top shape: 5 128 124 124 (9840640)
I0422 22:26:49.665804 16565 net.cpp:165] Memory required for data: 3496812800
I0422 22:26:49.665817 16565 layer_factory.hpp:77] Creating layer relu_u1d
I0422 22:26:49.665824 16565 net.cpp:100] Creating Layer relu_u1d
I0422 22:26:49.665827 16565 net.cpp:434] relu_u1d <- u1d
I0422 22:26:49.665835 16565 net.cpp:395] relu_u1d -> u1d (in-place)
I0422 22:26:49.666060 16565 net.cpp:150] Setting up relu_u1d
I0422 22:26:49.666072 16565 net.cpp:157] Top shape: 5 128 124 124 (9840640)
I0422 22:26:49.666076 16565 net.cpp:165] Memory required for data: 3536175360
I0422 22:26:49.666079 16565 layer_factory.hpp:77] Creating layer upconv_u1d_u0a
I0422 22:26:49.666088 16565 net.cpp:100] Creating Layer upconv_u1d_u0a
I0422 22:26:49.666095 16565 net.cpp:434] upconv_u1d_u0a <- u1d
I0422 22:26:49.666101 16565 net.cpp:408] upconv_u1d_u0a -> u0a
I0422 22:26:49.666913 16565 net.cpp:150] Setting up upconv_u1d_u0a
I0422 22:26:49.666923 16565 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0422 22:26:49.666927 16565 net.cpp:165] Memory required for data: 3693625600
I0422 22:26:49.666942 16565 layer_factory.hpp:77] Creating layer relu_u0a
I0422 22:26:49.666947 16565 net.cpp:100] Creating Layer relu_u0a
I0422 22:26:49.666951 16565 net.cpp:434] relu_u0a <- u0a
I0422 22:26:49.666960 16565 net.cpp:395] relu_u0a -> u0a (in-place)
I0422 22:26:49.667176 16565 net.cpp:150] Setting up relu_u0a
I0422 22:26:49.667186 16565 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0422 22:26:49.667189 16565 net.cpp:165] Memory required for data: 3851075840
I0422 22:26:49.667193 16565 layer_factory.hpp:77] Creating layer u0a_relu_u0a_0_split
I0422 22:26:49.667199 16565 net.cpp:100] Creating Layer u0a_relu_u0a_0_split
I0422 22:26:49.667202 16565 net.cpp:434] u0a_relu_u0a_0_split <- u0a
I0422 22:26:49.667209 16565 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_0
I0422 22:26:49.667218 16565 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_1
I0422 22:26:49.667266 16565 net.cpp:150] Setting up u0a_relu_u0a_0_split
I0422 22:26:49.667274 16565 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0422 22:26:49.667279 16565 net.cpp:157] Top shape: 5 128 248 248 (39362560)
I0422 22:26:49.667282 16565 net.cpp:165] Memory required for data: 4165976320
I0422 22:26:49.667285 16565 layer_factory.hpp:77] Creating layer crop_d0c-d0cc
I0422 22:26:49.667291 16565 net.cpp:100] Creating Layer crop_d0c-d0cc
I0422 22:26:49.667295 16565 net.cpp:434] crop_d0c-d0cc <- d0c_relu_d0c_0_split_1
I0422 22:26:49.667300 16565 net.cpp:434] crop_d0c-d0cc <- u0a_relu_u0a_0_split_0
I0422 22:26:49.667307 16565 net.cpp:408] crop_d0c-d0cc -> d0cc
I0422 22:26:49.667332 16565 net.cpp:150] Setting up crop_d0c-d0cc
I0422 22:26:49.667337 16565 net.cpp:157] Top shape: 5 64 248 248 (19681280)
I0422 22:26:49.667341 16565 net.cpp:165] Memory required for data: 4244701440
I0422 22:26:49.667361 16565 layer_factory.hpp:77] Creating layer concat_d0cc_u0a-b
I0422 22:26:49.667369 16565 net.cpp:100] Creating Layer concat_d0cc_u0a-b
I0422 22:26:49.667373 16565 net.cpp:434] concat_d0cc_u0a-b <- u0a_relu_u0a_0_split_1
I0422 22:26:49.667379 16565 net.cpp:434] concat_d0cc_u0a-b <- d0cc
I0422 22:26:49.667385 16565 net.cpp:408] concat_d0cc_u0a-b -> u0b
I0422 22:26:49.667412 16565 net.cpp:150] Setting up concat_d0cc_u0a-b
I0422 22:26:49.667419 16565 net.cpp:157] Top shape: 5 192 248 248 (59043840)
I0422 22:26:49.667423 16565 net.cpp:165] Memory required for data: 4480876800
I0422 22:26:49.667426 16565 layer_factory.hpp:77] Creating layer conv_u0b-c
I0422 22:26:49.667436 16565 net.cpp:100] Creating Layer conv_u0b-c
I0422 22:26:49.667440 16565 net.cpp:434] conv_u0b-c <- u0b
I0422 22:26:49.667448 16565 net.cpp:408] conv_u0b-c -> u0c
I0422 22:26:49.668552 16565 net.cpp:150] Setting up conv_u0b-c
I0422 22:26:49.668562 16565 net.cpp:157] Top shape: 5 64 246 246 (19365120)
I0422 22:26:49.668565 16565 net.cpp:165] Memory required for data: 4558337280
I0422 22:26:49.668572 16565 layer_factory.hpp:77] Creating layer relu_u0c
I0422 22:26:49.668589 16565 net.cpp:100] Creating Layer relu_u0c
I0422 22:26:49.668596 16565 net.cpp:434] relu_u0c <- u0c
I0422 22:26:49.668601 16565 net.cpp:395] relu_u0c -> u0c (in-place)
I0422 22:26:49.669600 16565 net.cpp:150] Setting up relu_u0c
I0422 22:26:49.669615 16565 net.cpp:157] Top shape: 5 64 246 246 (19365120)
I0422 22:26:49.669620 16565 net.cpp:165] Memory required for data: 4635797760
I0422 22:26:49.669625 16565 layer_factory.hpp:77] Creating layer conv_u0c-d
I0422 22:26:49.669636 16565 net.cpp:100] Creating Layer conv_u0c-d
I0422 22:26:49.669643 16565 net.cpp:434] conv_u0c-d <- u0c
I0422 22:26:49.669651 16565 net.cpp:408] conv_u0c-d -> u0d
I0422 22:26:49.670279 16565 net.cpp:150] Setting up conv_u0c-d
I0422 22:26:49.670289 16565 net.cpp:157] Top shape: 5 64 244 244 (19051520)
I0422 22:26:49.670291 16565 net.cpp:165] Memory required for data: 4712003840
I0422 22:26:49.670305 16565 layer_factory.hpp:77] Creating layer relu_u0d
I0422 22:26:49.670311 16565 net.cpp:100] Creating Layer relu_u0d
I0422 22:26:49.670315 16565 net.cpp:434] relu_u0d <- u0d
I0422 22:26:49.670320 16565 net.cpp:395] relu_u0d -> u0d (in-place)
I0422 22:26:49.670541 16565 net.cpp:150] Setting up relu_u0d
I0422 22:26:49.670550 16565 net.cpp:157] Top shape: 5 64 244 244 (19051520)
I0422 22:26:49.670554 16565 net.cpp:165] Memory required for data: 4788209920
I0422 22:26:49.670557 16565 layer_factory.hpp:77] Creating layer conv_u0d-score
I0422 22:26:49.670567 16565 net.cpp:100] Creating Layer conv_u0d-score
I0422 22:26:49.670570 16565 net.cpp:434] conv_u0d-score <- u0d
I0422 22:26:49.670578 16565 net.cpp:408] conv_u0d-score -> score
I0422 22:26:49.670928 16565 net.cpp:150] Setting up conv_u0d-score
I0422 22:26:49.670936 16565 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0422 22:26:49.670939 16565 net.cpp:165] Memory required for data: 4791782080
I0422 22:26:49.670954 16565 layer_factory.hpp:77] Creating layer score_conv_u0d-score_0_split
I0422 22:26:49.670963 16565 net.cpp:100] Creating Layer score_conv_u0d-score_0_split
I0422 22:26:49.670965 16565 net.cpp:434] score_conv_u0d-score_0_split <- score
I0422 22:26:49.670972 16565 net.cpp:408] score_conv_u0d-score_0_split -> score_conv_u0d-score_0_split_0
I0422 22:26:49.670980 16565 net.cpp:408] score_conv_u0d-score_0_split -> score_conv_u0d-score_0_split_1
I0422 22:26:49.671025 16565 net.cpp:150] Setting up score_conv_u0d-score_0_split
I0422 22:26:49.671031 16565 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0422 22:26:49.671036 16565 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0422 22:26:49.671039 16565 net.cpp:165] Memory required for data: 4798926400
I0422 22:26:49.671041 16565 layer_factory.hpp:77] Creating layer softmax
I0422 22:26:49.671047 16565 net.cpp:100] Creating Layer softmax
I0422 22:26:49.671051 16565 net.cpp:434] softmax <- score_conv_u0d-score_0_split_0
I0422 22:26:49.671056 16565 net.cpp:408] softmax -> softmax_out
I0422 22:26:49.671347 16565 net.cpp:150] Setting up softmax
I0422 22:26:49.671357 16565 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0422 22:26:49.671360 16565 net.cpp:165] Memory required for data: 4802498560
I0422 22:26:49.671365 16565 layer_factory.hpp:77] Creating layer reshapelab
I0422 22:26:49.671377 16565 net.cpp:100] Creating Layer reshapelab
I0422 22:26:49.671381 16565 net.cpp:434] reshapelab <- label
I0422 22:26:49.671386 16565 net.cpp:408] reshapelab -> label_flat
I0422 22:26:49.671418 16565 net.cpp:150] Setting up reshapelab
I0422 22:26:49.671425 16565 net.cpp:157] Top shape: 5 59536 (297680)
I0422 22:26:49.671428 16565 net.cpp:165] Memory required for data: 4803689280
I0422 22:26:49.671432 16565 layer_factory.hpp:77] Creating layer reshaperes
I0422 22:26:49.671437 16565 net.cpp:100] Creating Layer reshaperes
I0422 22:26:49.671440 16565 net.cpp:434] reshaperes <- softmax_out
I0422 22:26:49.671447 16565 net.cpp:408] reshaperes -> softmax_out_flat
I0422 22:26:49.671475 16565 net.cpp:150] Setting up reshaperes
I0422 22:26:49.671483 16565 net.cpp:157] Top shape: 5 3 59536 (893040)
I0422 22:26:49.671486 16565 net.cpp:165] Memory required for data: 4807261440
I0422 22:26:49.671489 16565 layer_factory.hpp:77] Creating layer loss
I0422 22:26:49.687530 16565 net.cpp:100] Creating Layer loss
I0422 22:26:49.687547 16565 net.cpp:434] loss <- softmax_out_flat
I0422 22:26:49.687564 16565 net.cpp:434] loss <- label_flat
I0422 22:26:49.687572 16565 net.cpp:408] loss -> loss
I0422 22:26:49.698870 16565 net.cpp:150] Setting up loss
I0422 22:26:49.698889 16565 net.cpp:157] Top shape: 3 (3)
I0422 22:26:49.698892 16565 net.cpp:160]     with loss weight 1
I0422 22:26:49.698911 16565 net.cpp:165] Memory required for data: 4807261452
I0422 22:26:49.698915 16565 layer_factory.hpp:77] Creating layer visualize
I0422 22:26:49.698925 16565 net.cpp:100] Creating Layer visualize
I0422 22:26:49.698928 16565 net.cpp:434] visualize <- score_conv_u0d-score_0_split_1
I0422 22:26:49.698935 16565 net.cpp:408] visualize -> visualize_out
I0422 22:26:49.700057 16565 net.cpp:150] Setting up visualize
I0422 22:26:49.700073 16565 net.cpp:157] Top shape: 5 3 244 244 (893040)
I0422 22:26:49.700076 16565 net.cpp:165] Memory required for data: 4810833612
I0422 22:26:49.700080 16565 layer_factory.hpp:77] Creating layer fake
I0422 22:26:49.700091 16565 net.cpp:100] Creating Layer fake
I0422 22:26:49.700096 16565 net.cpp:434] fake <- visualize_out
I0422 22:26:49.700103 16565 net.cpp:150] Setting up fake
I0422 22:26:49.700106 16565 net.cpp:165] Memory required for data: 4810833612
I0422 22:26:49.700109 16565 net.cpp:228] fake does not need backward computation.
I0422 22:26:49.700114 16565 net.cpp:228] visualize does not need backward computation.
I0422 22:26:49.700117 16565 net.cpp:226] loss needs backward computation.
I0422 22:26:49.700121 16565 net.cpp:226] reshaperes needs backward computation.
I0422 22:26:49.700125 16565 net.cpp:228] reshapelab does not need backward computation.
I0422 22:26:49.700129 16565 net.cpp:226] softmax needs backward computation.
I0422 22:26:49.700132 16565 net.cpp:226] score_conv_u0d-score_0_split needs backward computation.
I0422 22:26:49.700136 16565 net.cpp:226] conv_u0d-score needs backward computation.
I0422 22:26:49.700139 16565 net.cpp:226] relu_u0d needs backward computation.
I0422 22:26:49.700143 16565 net.cpp:226] conv_u0c-d needs backward computation.
I0422 22:26:49.700146 16565 net.cpp:226] relu_u0c needs backward computation.
I0422 22:26:49.700150 16565 net.cpp:226] conv_u0b-c needs backward computation.
I0422 22:26:49.700152 16565 net.cpp:226] concat_d0cc_u0a-b needs backward computation.
I0422 22:26:49.700157 16565 net.cpp:226] crop_d0c-d0cc needs backward computation.
I0422 22:26:49.700162 16565 net.cpp:226] u0a_relu_u0a_0_split needs backward computation.
I0422 22:26:49.700165 16565 net.cpp:226] relu_u0a needs backward computation.
I0422 22:26:49.700168 16565 net.cpp:226] upconv_u1d_u0a needs backward computation.
I0422 22:26:49.700172 16565 net.cpp:226] relu_u1d needs backward computation.
I0422 22:26:49.700176 16565 net.cpp:226] conv_u1c-d needs backward computation.
I0422 22:26:49.700194 16565 net.cpp:226] relu_u1c needs backward computation.
I0422 22:26:49.700198 16565 net.cpp:226] conv_u1b-c needs backward computation.
I0422 22:26:49.700202 16565 net.cpp:226] concat_d1cc_u1a-b needs backward computation.
I0422 22:26:49.700206 16565 net.cpp:226] crop_d1c-d1cc needs backward computation.
I0422 22:26:49.700211 16565 net.cpp:226] u1a_relu_u1a_0_split needs backward computation.
I0422 22:26:49.700213 16565 net.cpp:226] relu_u1a needs backward computation.
I0422 22:26:49.700217 16565 net.cpp:226] upconv_u2d_u1a needs backward computation.
I0422 22:26:49.700220 16565 net.cpp:226] relu_u2d needs backward computation.
I0422 22:26:49.700223 16565 net.cpp:226] conv_u2c-d needs backward computation.
I0422 22:26:49.700227 16565 net.cpp:226] relu_u2c needs backward computation.
I0422 22:26:49.700230 16565 net.cpp:226] conv_u2b-c needs backward computation.
I0422 22:26:49.700233 16565 net.cpp:226] concat_d2cc_u2a-b needs backward computation.
I0422 22:26:49.700237 16565 net.cpp:226] crop_d2c-d2cc needs backward computation.
I0422 22:26:49.700242 16565 net.cpp:226] u2a_relu_u2a_0_split needs backward computation.
I0422 22:26:49.700245 16565 net.cpp:226] relu_u2a needs backward computation.
I0422 22:26:49.700248 16565 net.cpp:226] upconv_u3d_u2a needs backward computation.
I0422 22:26:49.700251 16565 net.cpp:226] relu_u3d needs backward computation.
I0422 22:26:49.700254 16565 net.cpp:226] conv_u3c-d needs backward computation.
I0422 22:26:49.700258 16565 net.cpp:226] relu_u3c needs backward computation.
I0422 22:26:49.700263 16565 net.cpp:226] conv_u3b-c needs backward computation.
I0422 22:26:49.700265 16565 net.cpp:226] concat_d3cc_u3a-b needs backward computation.
I0422 22:26:49.700269 16565 net.cpp:226] crop_d3c-d3cc needs backward computation.
I0422 22:26:49.700273 16565 net.cpp:226] u3a_relu_u3a_0_split needs backward computation.
I0422 22:26:49.700278 16565 net.cpp:226] relu_u3a needs backward computation.
I0422 22:26:49.700280 16565 net.cpp:226] upconv_d4c_u3a needs backward computation.
I0422 22:26:49.700284 16565 net.cpp:226] dropout_d4c needs backward computation.
I0422 22:26:49.700289 16565 net.cpp:226] relu_d4c needs backward computation.
I0422 22:26:49.700291 16565 net.cpp:226] conv_d4b-c needs backward computation.
I0422 22:26:49.700294 16565 net.cpp:226] relu_d4b needs backward computation.
I0422 22:26:49.700297 16565 net.cpp:226] conv_d4a-b needs backward computation.
I0422 22:26:49.700301 16565 net.cpp:226] pool_d3c-4a needs backward computation.
I0422 22:26:49.700305 16565 net.cpp:226] d3c_dropout_d3c_0_split needs backward computation.
I0422 22:26:49.700309 16565 net.cpp:226] dropout_d3c needs backward computation.
I0422 22:26:49.700312 16565 net.cpp:226] relu_d3c needs backward computation.
I0422 22:26:49.700316 16565 net.cpp:226] conv_d3b-c needs backward computation.
I0422 22:26:49.700320 16565 net.cpp:226] relu_d3b needs backward computation.
I0422 22:26:49.700322 16565 net.cpp:226] conv_d3a-b needs backward computation.
I0422 22:26:49.700325 16565 net.cpp:226] pool_d2c-3a needs backward computation.
I0422 22:26:49.700330 16565 net.cpp:226] d2c_relu_d2c_0_split needs backward computation.
I0422 22:26:49.700333 16565 net.cpp:226] relu_d2c needs backward computation.
I0422 22:26:49.700336 16565 net.cpp:226] conv_d2b-c needs backward computation.
I0422 22:26:49.700340 16565 net.cpp:226] relu_d2b needs backward computation.
I0422 22:26:49.700345 16565 net.cpp:226] conv_d2a-b needs backward computation.
I0422 22:26:49.700347 16565 net.cpp:226] pool_d1c-2a needs backward computation.
I0422 22:26:49.700350 16565 net.cpp:226] d1c_relu_d1c_0_split needs backward computation.
I0422 22:26:49.700354 16565 net.cpp:226] relu_d1c needs backward computation.
I0422 22:26:49.700358 16565 net.cpp:226] conv_d1b-c needs backward computation.
I0422 22:26:49.700363 16565 net.cpp:226] relu_d1b needs backward computation.
I0422 22:26:49.700366 16565 net.cpp:226] conv_d1a-b needs backward computation.
I0422 22:26:49.700376 16565 net.cpp:226] pool_d0c-1a needs backward computation.
I0422 22:26:49.700387 16565 net.cpp:226] d0c_relu_d0c_0_split needs backward computation.
I0422 22:26:49.700392 16565 net.cpp:226] relu_d0c needs backward computation.
I0422 22:26:49.700394 16565 net.cpp:226] conv_d0b-c needs backward computation.
I0422 22:26:49.700397 16565 net.cpp:226] relu_d0b needs backward computation.
I0422 22:26:49.700402 16565 net.cpp:226] conv_d0a-b needs backward computation.
I0422 22:26:49.700407 16565 net.cpp:228] loaddata does not need backward computation.
I0422 22:26:49.700413 16565 net.cpp:270] This network produces output loss
I0422 22:26:49.700469 16565 net.cpp:283] Network initialization done.
I0422 22:26:49.701174 16565 solver.cpp:181] Creating test net (#0) specified by net file: ./unet_f1_3/unet_f1_3.prototxt
I0422 22:26:49.701262 16565 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer loaddata
I0422 22:26:49.701282 16565 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer dropout_d3c
I0422 22:26:49.701289 16565 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer dropout_d4c
I0422 22:26:49.701311 16565 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer visualize
I0422 22:26:49.701318 16565 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer fake
I0422 22:26:49.701704 16565 net.cpp:58] Initializing net from parameters: 
name: "unet_f1_3"
force_backward: true
state {
  phase: TEST
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "caffeHDF5_validation_3.txt"
    batch_size: 1
  }
}
layer {
  name: "conv_d0a-b"
  type: "Convolution"
  bottom: "data"
  top: "d0b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0b"
  type: "ReLU"
  bottom: "d0b"
  top: "d0b"
}
layer {
  name: "conv_d0b-c"
  type: "Convolution"
  bottom: "d0b"
  top: "d0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d0c"
  type: "ReLU"
  bottom: "d0c"
  top: "d0c"
}
layer {
  name: "pool_d0c-1a"
  type: "Pooling"
  bottom: "d0c"
  top: "d1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d1a-b"
  type: "Convolution"
  bottom: "d1a"
  top: "d1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1b"
  type: "ReLU"
  bottom: "d1b"
  top: "d1b"
}
layer {
  name: "conv_d1b-c"
  type: "Convolution"
  bottom: "d1b"
  top: "d1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d1c"
  type: "ReLU"
  bottom: "d1c"
  top: "d1c"
}
layer {
  name: "pool_d1c-2a"
  type: "Pooling"
  bottom: "d1c"
  top: "d2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d2a-b"
  type: "Convolution"
  bottom: "d2a"
  top: "d2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2b"
  type: "ReLU"
  bottom: "d2b"
  top: "d2b"
}
layer {
  name: "conv_d2b-c"
  type: "Convolution"
  bottom: "d2b"
  top: "d2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d2c"
  type: "ReLU"
  bottom: "d2c"
  top: "d2c"
}
layer {
  name: "pool_d2c-3a"
  type: "Pooling"
  bottom: "d2c"
  top: "d3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d3a-b"
  type: "Convolution"
  bottom: "d3a"
  top: "d3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3b"
  type: "ReLU"
  bottom: "d3b"
  top: "d3b"
}
layer {
  name: "conv_d3b-c"
  type: "Convolution"
  bottom: "d3b"
  top: "d3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d3c"
  type: "ReLU"
  bottom: "d3c"
  top: "d3c"
}
layer {
  name: "pool_d3c-4a"
  type: "Pooling"
  bottom: "d3c"
  top: "d4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv_d4a-b"
  type: "Convolution"
  bottom: "d4a"
  top: "d4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4b"
  type: "ReLU"
  bottom: "d4b"
  top: "d4b"
}
layer {
  name: "conv_d4b-c"
  type: "Convolution"
  bottom: "d4b"
  top: "d4c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_d4c"
  type: "ReLU"
  bottom: "d4c"
  top: "d4c"
}
layer {
  name: "upconv_d4c_u3a"
  type: "Deconvolution"
  bottom: "d4c"
  top: "u3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u3a"
  type: "ReLU"
  bottom: "u3a"
  top: "u3a"
}
layer {
  name: "crop_d3c-d3cc"
  type: "Crop"
  bottom: "d3c"
  bottom: "u3a"
  top: "d3cc"
  crop_param {
    axis: 2
    offset: 4
  }
}
layer {
  name: "concat_d3cc_u3a-b"
  type: "Concat"
  bottom: "u3a"
  bottom: "d3cc"
  top: "u3b"
}
layer {
  name: "conv_u3b-c"
  type: "Convolution"
  bottom: "u3b"
  top: "u3c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3c"
  type: "ReLU"
  bottom: "u3c"
  top: "u3c"
}
layer {
  name: "conv_u3c-d"
  type: "Convolution"
  bottom: "u3c"
  top: "u3d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u3d"
  type: "ReLU"
  bottom: "u3d"
  top: "u3d"
}
layer {
  name: "upconv_u3d_u2a"
  type: "Deconvolution"
  bottom: "u3d"
  top: "u2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u2a"
  type: "ReLU"
  bottom: "u2a"
  top: "u2a"
}
layer {
  name: "crop_d2c-d2cc"
  type: "Crop"
  bottom: "d2c"
  bottom: "u2a"
  top: "d2cc"
  crop_param {
    axis: 2
    offset: 16
  }
}
layer {
  name: "concat_d2cc_u2a-b"
  type: "Concat"
  bottom: "u2a"
  bottom: "d2cc"
  top: "u2b"
}
layer {
  name: "conv_u2b-c"
  type: "Convolution"
  bottom: "u2b"
  top: "u2c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2c"
  type: "ReLU"
  bottom: "u2c"
  top: "u2c"
}
layer {
  name: "conv_u2c-d"
  type: "Convolution"
  bottom: "u2c"
  top: "u2d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u2d"
  type: "ReLU"
  bottom: "u2d"
  top: "u2d"
}
layer {
  name: "upconv_u2d_u1a"
  type: "Deconvolution"
  bottom: "u2d"
  top: "u1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u1a"
  type: "ReLU"
  bottom: "u1a"
  top: "u1a"
}
layer {
  name: "crop_d1c-d1cc"
  type: "Crop"
  bottom: "d1c"
  bottom: "u1a"
  top: "d1cc"
  crop_param {
    axis: 2
    offset: 40
  }
}
layer {
  name: "concat_d1cc_u1a-b"
  type: "Concat"
  bottom: "u1a"
  bottom: "d1cc"
  top: "u1b"
}
layer {
  name: "conv_u1b-c"
  type: "Convolution"
  bottom: "u1b"
  top: "u1c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1c"
  type: "ReLU"
  bottom: "u1c"
  top: "u1c"
}
layer {
  name: "conv_u1c-d"
  type: "Convolution"
  bottom: "u1c"
  top: "u1d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u1d"
  type: "ReLU"
  bottom: "u1d"
  top: "u1d"
}
layer {
  name: "upconv_u1d_u0a"
  type: "Deconvolution"
  bottom: "u1d"
  top: "u0a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_u0a"
  type: "ReLU"
  bottom: "u0a"
  top: "u0a"
}
layer {
  name: "crop_d0c-d0cc"
  type: "Crop"
  bottom: "d0c"
  bottom: "u0a"
  top: "d0cc"
  crop_param {
    axis: 2
    offset: 88
  }
}
layer {
  name: "concat_d0cc_u0a-b"
  type: "Concat"
  bottom: "u0a"
  bottom: "d0cc"
  top: "u0b"
}
layer {
  name: "conv_u0b-c"
  type: "Convolution"
  bottom: "u0b"
  top: "u0c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0c"
  type: "ReLU"
  bottom: "u0c"
  top: "u0c"
}
layer {
  name: "conv_u0c-d"
  type: "Convolution"
  bottom: "u0c"
  top: "u0d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "relu_u0d"
  type: "ReLU"
  bottom: "u0d"
  top: "u0d"
}
layer {
  name: "conv_u0d-score"
  type: "Convolution"
  bottom: "u0d"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "score"
  top: "softmax_out"
}
layer {
  name: "reshapelab"
  type: "Reshape"
  bottom: "label"
  top: "label_flat"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "reshaperes"
  type: "Reshape"
  bottom: "softmax_out"
  top: "softmax_out_flat"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "loss"
  type: "Python"
  bottom: "softmax_out_flat"
  bottom: "label_flat"
  top: "loss"
  loss_weight: 1
  python_param {
    module: "multiclass_f1_loss"
    layer: "F1Loss"
  }
}
I0422 22:26:49.701987 16565 layer_factory.hpp:77] Creating layer loaddata
I0422 22:26:49.701998 16565 net.cpp:100] Creating Layer loaddata
I0422 22:26:49.702003 16565 net.cpp:408] loaddata -> data
I0422 22:26:49.702011 16565 net.cpp:408] loaddata -> label
I0422 22:26:49.702018 16565 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: caffeHDF5_validation_3.txt
I0422 22:26:49.702247 16565 hdf5_data_layer.cpp:93] Number of HDF5 files: 10
I0422 22:26:50.003304 16565 net.cpp:150] Setting up loaddata
I0422 22:26:50.003342 16565 net.cpp:157] Top shape: 1 3 428 428 (549552)
I0422 22:26:50.003348 16565 net.cpp:157] Top shape: 1 244 244 (59536)
I0422 22:26:50.003352 16565 net.cpp:165] Memory required for data: 2436352
I0422 22:26:50.003360 16565 layer_factory.hpp:77] Creating layer conv_d0a-b
I0422 22:26:50.003379 16565 net.cpp:100] Creating Layer conv_d0a-b
I0422 22:26:50.003383 16565 net.cpp:434] conv_d0a-b <- data
I0422 22:26:50.003391 16565 net.cpp:408] conv_d0a-b -> d0b
I0422 22:26:50.003994 16565 net.cpp:150] Setting up conv_d0a-b
I0422 22:26:50.004005 16565 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0422 22:26:50.004009 16565 net.cpp:165] Memory required for data: 48894208
I0422 22:26:50.004029 16565 layer_factory.hpp:77] Creating layer relu_d0b
I0422 22:26:50.004047 16565 net.cpp:100] Creating Layer relu_d0b
I0422 22:26:50.004051 16565 net.cpp:434] relu_d0b <- d0b
I0422 22:26:50.004056 16565 net.cpp:395] relu_d0b -> d0b (in-place)
I0422 22:26:50.004345 16565 net.cpp:150] Setting up relu_d0b
I0422 22:26:50.004356 16565 net.cpp:157] Top shape: 1 64 426 426 (11614464)
I0422 22:26:50.004359 16565 net.cpp:165] Memory required for data: 95352064
I0422 22:26:50.004364 16565 layer_factory.hpp:77] Creating layer conv_d0b-c
I0422 22:26:50.004371 16565 net.cpp:100] Creating Layer conv_d0b-c
I0422 22:26:50.004375 16565 net.cpp:434] conv_d0b-c <- d0b
I0422 22:26:50.004381 16565 net.cpp:408] conv_d0b-c -> d0c
I0422 22:26:50.005132 16565 net.cpp:150] Setting up conv_d0b-c
I0422 22:26:50.005142 16565 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0422 22:26:50.005146 16565 net.cpp:165] Memory required for data: 141374720
I0422 22:26:50.005164 16565 layer_factory.hpp:77] Creating layer relu_d0c
I0422 22:26:50.005172 16565 net.cpp:100] Creating Layer relu_d0c
I0422 22:26:50.005175 16565 net.cpp:434] relu_d0c <- d0c
I0422 22:26:50.005180 16565 net.cpp:395] relu_d0c -> d0c (in-place)
I0422 22:26:50.005424 16565 net.cpp:150] Setting up relu_d0c
I0422 22:26:50.005441 16565 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0422 22:26:50.005446 16565 net.cpp:165] Memory required for data: 187397376
I0422 22:26:50.005460 16565 layer_factory.hpp:77] Creating layer d0c_relu_d0c_0_split
I0422 22:26:50.005466 16565 net.cpp:100] Creating Layer d0c_relu_d0c_0_split
I0422 22:26:50.005470 16565 net.cpp:434] d0c_relu_d0c_0_split <- d0c
I0422 22:26:50.005476 16565 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_0
I0422 22:26:50.005484 16565 net.cpp:408] d0c_relu_d0c_0_split -> d0c_relu_d0c_0_split_1
I0422 22:26:50.005534 16565 net.cpp:150] Setting up d0c_relu_d0c_0_split
I0422 22:26:50.005542 16565 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0422 22:26:50.005548 16565 net.cpp:157] Top shape: 1 64 424 424 (11505664)
I0422 22:26:50.005550 16565 net.cpp:165] Memory required for data: 279442688
I0422 22:26:50.005553 16565 layer_factory.hpp:77] Creating layer pool_d0c-1a
I0422 22:26:50.005560 16565 net.cpp:100] Creating Layer pool_d0c-1a
I0422 22:26:50.005564 16565 net.cpp:434] pool_d0c-1a <- d0c_relu_d0c_0_split_0
I0422 22:26:50.005587 16565 net.cpp:408] pool_d0c-1a -> d1a
I0422 22:26:50.005633 16565 net.cpp:150] Setting up pool_d0c-1a
I0422 22:26:50.005641 16565 net.cpp:157] Top shape: 1 64 212 212 (2876416)
I0422 22:26:50.005645 16565 net.cpp:165] Memory required for data: 290948352
I0422 22:26:50.005648 16565 layer_factory.hpp:77] Creating layer conv_d1a-b
I0422 22:26:50.005657 16565 net.cpp:100] Creating Layer conv_d1a-b
I0422 22:26:50.005661 16565 net.cpp:434] conv_d1a-b <- d1a
I0422 22:26:50.005667 16565 net.cpp:408] conv_d1a-b -> d1b
I0422 22:26:50.007540 16565 net.cpp:150] Setting up conv_d1a-b
I0422 22:26:50.007556 16565 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0422 22:26:50.007560 16565 net.cpp:165] Memory required for data: 313527552
I0422 22:26:50.007571 16565 layer_factory.hpp:77] Creating layer relu_d1b
I0422 22:26:50.007580 16565 net.cpp:100] Creating Layer relu_d1b
I0422 22:26:50.007582 16565 net.cpp:434] relu_d1b <- d1b
I0422 22:26:50.007588 16565 net.cpp:395] relu_d1b -> d1b (in-place)
I0422 22:26:50.007822 16565 net.cpp:150] Setting up relu_d1b
I0422 22:26:50.007833 16565 net.cpp:157] Top shape: 1 128 210 210 (5644800)
I0422 22:26:50.007835 16565 net.cpp:165] Memory required for data: 336106752
I0422 22:26:50.007839 16565 layer_factory.hpp:77] Creating layer conv_d1b-c
I0422 22:26:50.007848 16565 net.cpp:100] Creating Layer conv_d1b-c
I0422 22:26:50.007851 16565 net.cpp:434] conv_d1b-c <- d1b
I0422 22:26:50.007858 16565 net.cpp:408] conv_d1b-c -> d1c
I0422 22:26:50.010201 16565 net.cpp:150] Setting up conv_d1b-c
I0422 22:26:50.010218 16565 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0422 22:26:50.010232 16565 net.cpp:165] Memory required for data: 358257920
I0422 22:26:50.010239 16565 layer_factory.hpp:77] Creating layer relu_d1c
I0422 22:26:50.010246 16565 net.cpp:100] Creating Layer relu_d1c
I0422 22:26:50.010251 16565 net.cpp:434] relu_d1c <- d1c
I0422 22:26:50.010257 16565 net.cpp:395] relu_d1c -> d1c (in-place)
I0422 22:26:50.011283 16565 net.cpp:150] Setting up relu_d1c
I0422 22:26:50.011298 16565 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0422 22:26:50.011302 16565 net.cpp:165] Memory required for data: 380409088
I0422 22:26:50.011314 16565 layer_factory.hpp:77] Creating layer d1c_relu_d1c_0_split
I0422 22:26:50.011320 16565 net.cpp:100] Creating Layer d1c_relu_d1c_0_split
I0422 22:26:50.011324 16565 net.cpp:434] d1c_relu_d1c_0_split <- d1c
I0422 22:26:50.011332 16565 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_0
I0422 22:26:50.011340 16565 net.cpp:408] d1c_relu_d1c_0_split -> d1c_relu_d1c_0_split_1
I0422 22:26:50.011392 16565 net.cpp:150] Setting up d1c_relu_d1c_0_split
I0422 22:26:50.011404 16565 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0422 22:26:50.011409 16565 net.cpp:157] Top shape: 1 128 208 208 (5537792)
I0422 22:26:50.011412 16565 net.cpp:165] Memory required for data: 424711424
I0422 22:26:50.011415 16565 layer_factory.hpp:77] Creating layer pool_d1c-2a
I0422 22:26:50.011421 16565 net.cpp:100] Creating Layer pool_d1c-2a
I0422 22:26:50.011425 16565 net.cpp:434] pool_d1c-2a <- d1c_relu_d1c_0_split_0
I0422 22:26:50.011431 16565 net.cpp:408] pool_d1c-2a -> d2a
I0422 22:26:50.011472 16565 net.cpp:150] Setting up pool_d1c-2a
I0422 22:26:50.011481 16565 net.cpp:157] Top shape: 1 128 104 104 (1384448)
I0422 22:26:50.011483 16565 net.cpp:165] Memory required for data: 430249216
I0422 22:26:50.011487 16565 layer_factory.hpp:77] Creating layer conv_d2a-b
I0422 22:26:50.011497 16565 net.cpp:100] Creating Layer conv_d2a-b
I0422 22:26:50.011499 16565 net.cpp:434] conv_d2a-b <- d2a
I0422 22:26:50.011507 16565 net.cpp:408] conv_d2a-b -> d2b
I0422 22:26:50.013876 16565 net.cpp:150] Setting up conv_d2a-b
I0422 22:26:50.013887 16565 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0422 22:26:50.013890 16565 net.cpp:165] Memory required for data: 440902912
I0422 22:26:50.013911 16565 layer_factory.hpp:77] Creating layer relu_d2b
I0422 22:26:50.013917 16565 net.cpp:100] Creating Layer relu_d2b
I0422 22:26:50.013921 16565 net.cpp:434] relu_d2b <- d2b
I0422 22:26:50.013941 16565 net.cpp:395] relu_d2b -> d2b (in-place)
I0422 22:26:50.014154 16565 net.cpp:150] Setting up relu_d2b
I0422 22:26:50.014165 16565 net.cpp:157] Top shape: 1 256 102 102 (2663424)
I0422 22:26:50.014168 16565 net.cpp:165] Memory required for data: 451556608
I0422 22:26:50.014173 16565 layer_factory.hpp:77] Creating layer conv_d2b-c
I0422 22:26:50.014181 16565 net.cpp:100] Creating Layer conv_d2b-c
I0422 22:26:50.014185 16565 net.cpp:434] conv_d2b-c <- d2b
I0422 22:26:50.014191 16565 net.cpp:408] conv_d2b-c -> d2c
I0422 22:26:50.019656 16565 net.cpp:150] Setting up conv_d2b-c
I0422 22:26:50.019673 16565 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0422 22:26:50.019677 16565 net.cpp:165] Memory required for data: 461796608
I0422 22:26:50.019691 16565 layer_factory.hpp:77] Creating layer relu_d2c
I0422 22:26:50.019701 16565 net.cpp:100] Creating Layer relu_d2c
I0422 22:26:50.019706 16565 net.cpp:434] relu_d2c <- d2c
I0422 22:26:50.019711 16565 net.cpp:395] relu_d2c -> d2c (in-place)
I0422 22:26:50.019951 16565 net.cpp:150] Setting up relu_d2c
I0422 22:26:50.019963 16565 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0422 22:26:50.019966 16565 net.cpp:165] Memory required for data: 472036608
I0422 22:26:50.019969 16565 layer_factory.hpp:77] Creating layer d2c_relu_d2c_0_split
I0422 22:26:50.019974 16565 net.cpp:100] Creating Layer d2c_relu_d2c_0_split
I0422 22:26:50.019979 16565 net.cpp:434] d2c_relu_d2c_0_split <- d2c
I0422 22:26:50.019984 16565 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_0
I0422 22:26:50.019992 16565 net.cpp:408] d2c_relu_d2c_0_split -> d2c_relu_d2c_0_split_1
I0422 22:26:50.020040 16565 net.cpp:150] Setting up d2c_relu_d2c_0_split
I0422 22:26:50.020048 16565 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0422 22:26:50.020053 16565 net.cpp:157] Top shape: 1 256 100 100 (2560000)
I0422 22:26:50.020056 16565 net.cpp:165] Memory required for data: 492516608
I0422 22:26:50.020059 16565 layer_factory.hpp:77] Creating layer pool_d2c-3a
I0422 22:26:50.020066 16565 net.cpp:100] Creating Layer pool_d2c-3a
I0422 22:26:50.020078 16565 net.cpp:434] pool_d2c-3a <- d2c_relu_d2c_0_split_0
I0422 22:26:50.020084 16565 net.cpp:408] pool_d2c-3a -> d3a
I0422 22:26:50.020129 16565 net.cpp:150] Setting up pool_d2c-3a
I0422 22:26:50.020138 16565 net.cpp:157] Top shape: 1 256 50 50 (640000)
I0422 22:26:50.020141 16565 net.cpp:165] Memory required for data: 495076608
I0422 22:26:50.020144 16565 layer_factory.hpp:77] Creating layer conv_d3a-b
I0422 22:26:50.020153 16565 net.cpp:100] Creating Layer conv_d3a-b
I0422 22:26:50.020155 16565 net.cpp:434] conv_d3a-b <- d3a
I0422 22:26:50.020162 16565 net.cpp:408] conv_d3a-b -> d3b
I0422 22:26:50.030437 16565 net.cpp:150] Setting up conv_d3a-b
I0422 22:26:50.030452 16565 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0422 22:26:50.030455 16565 net.cpp:165] Memory required for data: 499795200
I0422 22:26:50.030472 16565 layer_factory.hpp:77] Creating layer relu_d3b
I0422 22:26:50.030479 16565 net.cpp:100] Creating Layer relu_d3b
I0422 22:26:50.030483 16565 net.cpp:434] relu_d3b <- d3b
I0422 22:26:50.030489 16565 net.cpp:395] relu_d3b -> d3b (in-place)
I0422 22:26:50.030714 16565 net.cpp:150] Setting up relu_d3b
I0422 22:26:50.030725 16565 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0422 22:26:50.030728 16565 net.cpp:165] Memory required for data: 504513792
I0422 22:26:50.030731 16565 layer_factory.hpp:77] Creating layer conv_d3b-c
I0422 22:26:50.030741 16565 net.cpp:100] Creating Layer conv_d3b-c
I0422 22:26:50.030745 16565 net.cpp:434] conv_d3b-c <- d3b
I0422 22:26:50.030751 16565 net.cpp:408] conv_d3b-c -> d3c
I0422 22:26:50.050492 16565 net.cpp:150] Setting up conv_d3b-c
I0422 22:26:50.050509 16565 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0422 22:26:50.050513 16565 net.cpp:165] Memory required for data: 508847360
I0422 22:26:50.050528 16565 layer_factory.hpp:77] Creating layer relu_d3c
I0422 22:26:50.050534 16565 net.cpp:100] Creating Layer relu_d3c
I0422 22:26:50.050539 16565 net.cpp:434] relu_d3c <- d3c
I0422 22:26:50.050557 16565 net.cpp:395] relu_d3c -> d3c (in-place)
I0422 22:26:50.051592 16565 net.cpp:150] Setting up relu_d3c
I0422 22:26:50.051609 16565 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0422 22:26:50.051612 16565 net.cpp:165] Memory required for data: 513180928
I0422 22:26:50.051625 16565 layer_factory.hpp:77] Creating layer d3c_relu_d3c_0_split
I0422 22:26:50.051631 16565 net.cpp:100] Creating Layer d3c_relu_d3c_0_split
I0422 22:26:50.051635 16565 net.cpp:434] d3c_relu_d3c_0_split <- d3c
I0422 22:26:50.051643 16565 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_0
I0422 22:26:50.051651 16565 net.cpp:408] d3c_relu_d3c_0_split -> d3c_relu_d3c_0_split_1
I0422 22:26:50.051714 16565 net.cpp:150] Setting up d3c_relu_d3c_0_split
I0422 22:26:50.051723 16565 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0422 22:26:50.051728 16565 net.cpp:157] Top shape: 1 512 46 46 (1083392)
I0422 22:26:50.051731 16565 net.cpp:165] Memory required for data: 521848064
I0422 22:26:50.051734 16565 layer_factory.hpp:77] Creating layer pool_d3c-4a
I0422 22:26:50.051740 16565 net.cpp:100] Creating Layer pool_d3c-4a
I0422 22:26:50.051745 16565 net.cpp:434] pool_d3c-4a <- d3c_relu_d3c_0_split_0
I0422 22:26:50.051750 16565 net.cpp:408] pool_d3c-4a -> d4a
I0422 22:26:50.051792 16565 net.cpp:150] Setting up pool_d3c-4a
I0422 22:26:50.051800 16565 net.cpp:157] Top shape: 1 512 23 23 (270848)
I0422 22:26:50.051805 16565 net.cpp:165] Memory required for data: 522931456
I0422 22:26:50.051806 16565 layer_factory.hpp:77] Creating layer conv_d4a-b
I0422 22:26:50.051816 16565 net.cpp:100] Creating Layer conv_d4a-b
I0422 22:26:50.051820 16565 net.cpp:434] conv_d4a-b <- d4a
I0422 22:26:50.051827 16565 net.cpp:408] conv_d4a-b -> d4b
I0422 22:26:50.090747 16565 net.cpp:150] Setting up conv_d4a-b
I0422 22:26:50.090764 16565 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0422 22:26:50.090778 16565 net.cpp:165] Memory required for data: 524737792
I0422 22:26:50.090791 16565 layer_factory.hpp:77] Creating layer relu_d4b
I0422 22:26:50.090798 16565 net.cpp:100] Creating Layer relu_d4b
I0422 22:26:50.090802 16565 net.cpp:434] relu_d4b <- d4b
I0422 22:26:50.090808 16565 net.cpp:395] relu_d4b -> d4b (in-place)
I0422 22:26:50.091037 16565 net.cpp:150] Setting up relu_d4b
I0422 22:26:50.091047 16565 net.cpp:157] Top shape: 1 1024 21 21 (451584)
I0422 22:26:50.091050 16565 net.cpp:165] Memory required for data: 526544128
I0422 22:26:50.091053 16565 layer_factory.hpp:77] Creating layer conv_d4b-c
I0422 22:26:50.091064 16565 net.cpp:100] Creating Layer conv_d4b-c
I0422 22:26:50.091068 16565 net.cpp:434] conv_d4b-c <- d4b
I0422 22:26:50.091074 16565 net.cpp:408] conv_d4b-c -> d4c
I0422 22:26:50.168447 16565 net.cpp:150] Setting up conv_d4b-c
I0422 22:26:50.168473 16565 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0422 22:26:50.168485 16565 net.cpp:165] Memory required for data: 528022784
I0422 22:26:50.168494 16565 layer_factory.hpp:77] Creating layer relu_d4c
I0422 22:26:50.168503 16565 net.cpp:100] Creating Layer relu_d4c
I0422 22:26:50.168509 16565 net.cpp:434] relu_d4c <- d4c
I0422 22:26:50.168516 16565 net.cpp:395] relu_d4c -> d4c (in-place)
I0422 22:26:50.168792 16565 net.cpp:150] Setting up relu_d4c
I0422 22:26:50.168802 16565 net.cpp:157] Top shape: 1 1024 19 19 (369664)
I0422 22:26:50.168807 16565 net.cpp:165] Memory required for data: 529501440
I0422 22:26:50.168809 16565 layer_factory.hpp:77] Creating layer upconv_d4c_u3a
I0422 22:26:50.168818 16565 net.cpp:100] Creating Layer upconv_d4c_u3a
I0422 22:26:50.168823 16565 net.cpp:434] upconv_d4c_u3a <- d4c
I0422 22:26:50.168830 16565 net.cpp:408] upconv_d4c_u3a -> u3a
I0422 22:26:50.186728 16565 net.cpp:150] Setting up upconv_d4c_u3a
I0422 22:26:50.186743 16565 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0422 22:26:50.186746 16565 net.cpp:165] Memory required for data: 532458752
I0422 22:26:50.186754 16565 layer_factory.hpp:77] Creating layer relu_u3a
I0422 22:26:50.186761 16565 net.cpp:100] Creating Layer relu_u3a
I0422 22:26:50.186764 16565 net.cpp:434] relu_u3a <- u3a
I0422 22:26:50.186770 16565 net.cpp:395] relu_u3a -> u3a (in-place)
I0422 22:26:50.187038 16565 net.cpp:150] Setting up relu_u3a
I0422 22:26:50.187049 16565 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0422 22:26:50.187052 16565 net.cpp:165] Memory required for data: 535416064
I0422 22:26:50.187055 16565 layer_factory.hpp:77] Creating layer u3a_relu_u3a_0_split
I0422 22:26:50.187063 16565 net.cpp:100] Creating Layer u3a_relu_u3a_0_split
I0422 22:26:50.187067 16565 net.cpp:434] u3a_relu_u3a_0_split <- u3a
I0422 22:26:50.187072 16565 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_0
I0422 22:26:50.187079 16565 net.cpp:408] u3a_relu_u3a_0_split -> u3a_relu_u3a_0_split_1
I0422 22:26:50.187129 16565 net.cpp:150] Setting up u3a_relu_u3a_0_split
I0422 22:26:50.187136 16565 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0422 22:26:50.187140 16565 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0422 22:26:50.187144 16565 net.cpp:165] Memory required for data: 541330688
I0422 22:26:50.187146 16565 layer_factory.hpp:77] Creating layer crop_d3c-d3cc
I0422 22:26:50.187160 16565 net.cpp:100] Creating Layer crop_d3c-d3cc
I0422 22:26:50.187163 16565 net.cpp:434] crop_d3c-d3cc <- d3c_relu_d3c_0_split_1
I0422 22:26:50.187167 16565 net.cpp:434] crop_d3c-d3cc <- u3a_relu_u3a_0_split_0
I0422 22:26:50.187175 16565 net.cpp:408] crop_d3c-d3cc -> d3cc
I0422 22:26:50.187201 16565 net.cpp:150] Setting up crop_d3c-d3cc
I0422 22:26:50.187207 16565 net.cpp:157] Top shape: 1 512 38 38 (739328)
I0422 22:26:50.187211 16565 net.cpp:165] Memory required for data: 544288000
I0422 22:26:50.187214 16565 layer_factory.hpp:77] Creating layer concat_d3cc_u3a-b
I0422 22:26:50.187219 16565 net.cpp:100] Creating Layer concat_d3cc_u3a-b
I0422 22:26:50.187222 16565 net.cpp:434] concat_d3cc_u3a-b <- u3a_relu_u3a_0_split_1
I0422 22:26:50.187227 16565 net.cpp:434] concat_d3cc_u3a-b <- d3cc
I0422 22:26:50.187233 16565 net.cpp:408] concat_d3cc_u3a-b -> u3b
I0422 22:26:50.187258 16565 net.cpp:150] Setting up concat_d3cc_u3a-b
I0422 22:26:50.187265 16565 net.cpp:157] Top shape: 1 1024 38 38 (1478656)
I0422 22:26:50.187268 16565 net.cpp:165] Memory required for data: 550202624
I0422 22:26:50.187273 16565 layer_factory.hpp:77] Creating layer conv_u3b-c
I0422 22:26:50.187281 16565 net.cpp:100] Creating Layer conv_u3b-c
I0422 22:26:50.187284 16565 net.cpp:434] conv_u3b-c <- u3b
I0422 22:26:50.187290 16565 net.cpp:408] conv_u3b-c -> u3c
I0422 22:26:50.223232 16565 net.cpp:150] Setting up conv_u3b-c
I0422 22:26:50.223248 16565 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0422 22:26:50.223251 16565 net.cpp:165] Memory required for data: 552856832
I0422 22:26:50.223261 16565 layer_factory.hpp:77] Creating layer relu_u3c
I0422 22:26:50.223268 16565 net.cpp:100] Creating Layer relu_u3c
I0422 22:26:50.223273 16565 net.cpp:434] relu_u3c <- u3c
I0422 22:26:50.223278 16565 net.cpp:395] relu_u3c -> u3c (in-place)
I0422 22:26:50.224182 16565 net.cpp:150] Setting up relu_u3c
I0422 22:26:50.224197 16565 net.cpp:157] Top shape: 1 512 36 36 (663552)
I0422 22:26:50.224200 16565 net.cpp:165] Memory required for data: 555511040
I0422 22:26:50.224203 16565 layer_factory.hpp:77] Creating layer conv_u3c-d
I0422 22:26:50.224220 16565 net.cpp:100] Creating Layer conv_u3c-d
I0422 22:26:50.224223 16565 net.cpp:434] conv_u3c-d <- u3c
I0422 22:26:50.224230 16565 net.cpp:408] conv_u3c-d -> u3d
I0422 22:26:50.241017 16565 net.cpp:150] Setting up conv_u3c-d
I0422 22:26:50.241031 16565 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0422 22:26:50.241035 16565 net.cpp:165] Memory required for data: 557878528
I0422 22:26:50.241041 16565 layer_factory.hpp:77] Creating layer relu_u3d
I0422 22:26:50.241046 16565 net.cpp:100] Creating Layer relu_u3d
I0422 22:26:50.241050 16565 net.cpp:434] relu_u3d <- u3d
I0422 22:26:50.241055 16565 net.cpp:395] relu_u3d -> u3d (in-place)
I0422 22:26:50.241247 16565 net.cpp:150] Setting up relu_u3d
I0422 22:26:50.241257 16565 net.cpp:157] Top shape: 1 512 34 34 (591872)
I0422 22:26:50.241259 16565 net.cpp:165] Memory required for data: 560246016
I0422 22:26:50.241263 16565 layer_factory.hpp:77] Creating layer upconv_u3d_u2a
I0422 22:26:50.241283 16565 net.cpp:100] Creating Layer upconv_u3d_u2a
I0422 22:26:50.241288 16565 net.cpp:434] upconv_u3d_u2a <- u3d
I0422 22:26:50.241294 16565 net.cpp:408] upconv_u3d_u2a -> u2a
I0422 22:26:50.245347 16565 net.cpp:150] Setting up upconv_u3d_u2a
I0422 22:26:50.245362 16565 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0422 22:26:50.245363 16565 net.cpp:165] Memory required for data: 564980992
I0422 22:26:50.245369 16565 layer_factory.hpp:77] Creating layer relu_u2a
I0422 22:26:50.245375 16565 net.cpp:100] Creating Layer relu_u2a
I0422 22:26:50.245378 16565 net.cpp:434] relu_u2a <- u2a
I0422 22:26:50.245383 16565 net.cpp:395] relu_u2a -> u2a (in-place)
I0422 22:26:50.245580 16565 net.cpp:150] Setting up relu_u2a
I0422 22:26:50.245591 16565 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0422 22:26:50.245594 16565 net.cpp:165] Memory required for data: 569715968
I0422 22:26:50.245597 16565 layer_factory.hpp:77] Creating layer u2a_relu_u2a_0_split
I0422 22:26:50.245602 16565 net.cpp:100] Creating Layer u2a_relu_u2a_0_split
I0422 22:26:50.245606 16565 net.cpp:434] u2a_relu_u2a_0_split <- u2a
I0422 22:26:50.245612 16565 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_0
I0422 22:26:50.245625 16565 net.cpp:408] u2a_relu_u2a_0_split -> u2a_relu_u2a_0_split_1
I0422 22:26:50.245667 16565 net.cpp:150] Setting up u2a_relu_u2a_0_split
I0422 22:26:50.245676 16565 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0422 22:26:50.245679 16565 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0422 22:26:50.245682 16565 net.cpp:165] Memory required for data: 579185920
I0422 22:26:50.245683 16565 layer_factory.hpp:77] Creating layer crop_d2c-d2cc
I0422 22:26:50.245690 16565 net.cpp:100] Creating Layer crop_d2c-d2cc
I0422 22:26:50.245693 16565 net.cpp:434] crop_d2c-d2cc <- d2c_relu_d2c_0_split_1
I0422 22:26:50.245697 16565 net.cpp:434] crop_d2c-d2cc <- u2a_relu_u2a_0_split_0
I0422 22:26:50.245702 16565 net.cpp:408] crop_d2c-d2cc -> d2cc
I0422 22:26:50.245726 16565 net.cpp:150] Setting up crop_d2c-d2cc
I0422 22:26:50.245733 16565 net.cpp:157] Top shape: 1 256 68 68 (1183744)
I0422 22:26:50.245735 16565 net.cpp:165] Memory required for data: 583920896
I0422 22:26:50.245738 16565 layer_factory.hpp:77] Creating layer concat_d2cc_u2a-b
I0422 22:26:50.245743 16565 net.cpp:100] Creating Layer concat_d2cc_u2a-b
I0422 22:26:50.245745 16565 net.cpp:434] concat_d2cc_u2a-b <- u2a_relu_u2a_0_split_1
I0422 22:26:50.245749 16565 net.cpp:434] concat_d2cc_u2a-b <- d2cc
I0422 22:26:50.245754 16565 net.cpp:408] concat_d2cc_u2a-b -> u2b
I0422 22:26:50.245775 16565 net.cpp:150] Setting up concat_d2cc_u2a-b
I0422 22:26:50.245782 16565 net.cpp:157] Top shape: 1 512 68 68 (2367488)
I0422 22:26:50.245784 16565 net.cpp:165] Memory required for data: 593390848
I0422 22:26:50.245787 16565 layer_factory.hpp:77] Creating layer conv_u2b-c
I0422 22:26:50.245796 16565 net.cpp:100] Creating Layer conv_u2b-c
I0422 22:26:50.245798 16565 net.cpp:434] conv_u2b-c <- u2b
I0422 22:26:50.245803 16565 net.cpp:408] conv_u2b-c -> u2c
I0422 22:26:50.254169 16565 net.cpp:150] Setting up conv_u2b-c
I0422 22:26:50.254184 16565 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0422 22:26:50.254186 16565 net.cpp:165] Memory required for data: 597851392
I0422 22:26:50.254194 16565 layer_factory.hpp:77] Creating layer relu_u2c
I0422 22:26:50.254199 16565 net.cpp:100] Creating Layer relu_u2c
I0422 22:26:50.254202 16565 net.cpp:434] relu_u2c <- u2c
I0422 22:26:50.254206 16565 net.cpp:395] relu_u2c -> u2c (in-place)
I0422 22:26:50.255059 16565 net.cpp:150] Setting up relu_u2c
I0422 22:26:50.255072 16565 net.cpp:157] Top shape: 1 256 66 66 (1115136)
I0422 22:26:50.255076 16565 net.cpp:165] Memory required for data: 602311936
I0422 22:26:50.255079 16565 layer_factory.hpp:77] Creating layer conv_u2c-d
I0422 22:26:50.255087 16565 net.cpp:100] Creating Layer conv_u2c-d
I0422 22:26:50.255090 16565 net.cpp:434] conv_u2c-d <- u2c
I0422 22:26:50.255097 16565 net.cpp:408] conv_u2c-d -> u2d
I0422 22:26:50.259582 16565 net.cpp:150] Setting up conv_u2c-d
I0422 22:26:50.259610 16565 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0422 22:26:50.259613 16565 net.cpp:165] Memory required for data: 606506240
I0422 22:26:50.259620 16565 layer_factory.hpp:77] Creating layer relu_u2d
I0422 22:26:50.259626 16565 net.cpp:100] Creating Layer relu_u2d
I0422 22:26:50.259629 16565 net.cpp:434] relu_u2d <- u2d
I0422 22:26:50.259634 16565 net.cpp:395] relu_u2d -> u2d (in-place)
I0422 22:26:50.259819 16565 net.cpp:150] Setting up relu_u2d
I0422 22:26:50.259827 16565 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0422 22:26:50.259830 16565 net.cpp:165] Memory required for data: 610700544
I0422 22:26:50.259834 16565 layer_factory.hpp:77] Creating layer upconv_u2d_u1a
I0422 22:26:50.259840 16565 net.cpp:100] Creating Layer upconv_u2d_u1a
I0422 22:26:50.259843 16565 net.cpp:434] upconv_u2d_u1a <- u2d
I0422 22:26:50.259848 16565 net.cpp:408] upconv_u2d_u1a -> u1a
I0422 22:26:50.264178 16565 net.cpp:150] Setting up upconv_u2d_u1a
I0422 22:26:50.264195 16565 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0422 22:26:50.264199 16565 net.cpp:165] Memory required for data: 619089152
I0422 22:26:50.264214 16565 layer_factory.hpp:77] Creating layer relu_u1a
I0422 22:26:50.264220 16565 net.cpp:100] Creating Layer relu_u1a
I0422 22:26:50.264223 16565 net.cpp:434] relu_u1a <- u1a
I0422 22:26:50.264228 16565 net.cpp:395] relu_u1a -> u1a (in-place)
I0422 22:26:50.264413 16565 net.cpp:150] Setting up relu_u1a
I0422 22:26:50.264423 16565 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0422 22:26:50.264426 16565 net.cpp:165] Memory required for data: 627477760
I0422 22:26:50.264430 16565 layer_factory.hpp:77] Creating layer u1a_relu_u1a_0_split
I0422 22:26:50.264434 16565 net.cpp:100] Creating Layer u1a_relu_u1a_0_split
I0422 22:26:50.264437 16565 net.cpp:434] u1a_relu_u1a_0_split <- u1a
I0422 22:26:50.264442 16565 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_0
I0422 22:26:50.264449 16565 net.cpp:408] u1a_relu_u1a_0_split -> u1a_relu_u1a_0_split_1
I0422 22:26:50.264490 16565 net.cpp:150] Setting up u1a_relu_u1a_0_split
I0422 22:26:50.264497 16565 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0422 22:26:50.264502 16565 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0422 22:26:50.264503 16565 net.cpp:165] Memory required for data: 644254976
I0422 22:26:50.264506 16565 layer_factory.hpp:77] Creating layer crop_d1c-d1cc
I0422 22:26:50.264513 16565 net.cpp:100] Creating Layer crop_d1c-d1cc
I0422 22:26:50.264515 16565 net.cpp:434] crop_d1c-d1cc <- d1c_relu_d1c_0_split_1
I0422 22:26:50.264519 16565 net.cpp:434] crop_d1c-d1cc <- u1a_relu_u1a_0_split_0
I0422 22:26:50.264524 16565 net.cpp:408] crop_d1c-d1cc -> d1cc
I0422 22:26:50.264546 16565 net.cpp:150] Setting up crop_d1c-d1cc
I0422 22:26:50.264554 16565 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0422 22:26:50.264556 16565 net.cpp:165] Memory required for data: 652643584
I0422 22:26:50.264559 16565 layer_factory.hpp:77] Creating layer concat_d1cc_u1a-b
I0422 22:26:50.264562 16565 net.cpp:100] Creating Layer concat_d1cc_u1a-b
I0422 22:26:50.264566 16565 net.cpp:434] concat_d1cc_u1a-b <- u1a_relu_u1a_0_split_1
I0422 22:26:50.264569 16565 net.cpp:434] concat_d1cc_u1a-b <- d1cc
I0422 22:26:50.264574 16565 net.cpp:408] concat_d1cc_u1a-b -> u1b
I0422 22:26:50.264595 16565 net.cpp:150] Setting up concat_d1cc_u1a-b
I0422 22:26:50.264600 16565 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0422 22:26:50.264602 16565 net.cpp:165] Memory required for data: 669420800
I0422 22:26:50.264605 16565 layer_factory.hpp:77] Creating layer conv_u1b-c
I0422 22:26:50.264612 16565 net.cpp:100] Creating Layer conv_u1b-c
I0422 22:26:50.264616 16565 net.cpp:434] conv_u1b-c <- u1b
I0422 22:26:50.264621 16565 net.cpp:408] conv_u1b-c -> u1c
I0422 22:26:50.266470 16565 net.cpp:150] Setting up conv_u1b-c
I0422 22:26:50.266479 16565 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0422 22:26:50.266482 16565 net.cpp:165] Memory required for data: 677549312
I0422 22:26:50.266489 16565 layer_factory.hpp:77] Creating layer relu_u1c
I0422 22:26:50.266494 16565 net.cpp:100] Creating Layer relu_u1c
I0422 22:26:50.266507 16565 net.cpp:434] relu_u1c <- u1c
I0422 22:26:50.266513 16565 net.cpp:395] relu_u1c -> u1c (in-place)
I0422 22:26:50.266693 16565 net.cpp:150] Setting up relu_u1c
I0422 22:26:50.266702 16565 net.cpp:157] Top shape: 1 128 126 126 (2032128)
I0422 22:26:50.266705 16565 net.cpp:165] Memory required for data: 685677824
I0422 22:26:50.266707 16565 layer_factory.hpp:77] Creating layer conv_u1c-d
I0422 22:26:50.266716 16565 net.cpp:100] Creating Layer conv_u1c-d
I0422 22:26:50.266717 16565 net.cpp:434] conv_u1c-d <- u1c
I0422 22:26:50.266723 16565 net.cpp:408] conv_u1c-d -> u1d
I0422 22:26:50.268615 16565 net.cpp:150] Setting up conv_u1c-d
I0422 22:26:50.268628 16565 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0422 22:26:50.268630 16565 net.cpp:165] Memory required for data: 693550336
I0422 22:26:50.268636 16565 layer_factory.hpp:77] Creating layer relu_u1d
I0422 22:26:50.268642 16565 net.cpp:100] Creating Layer relu_u1d
I0422 22:26:50.268646 16565 net.cpp:434] relu_u1d <- u1d
I0422 22:26:50.268649 16565 net.cpp:395] relu_u1d -> u1d (in-place)
I0422 22:26:50.269505 16565 net.cpp:150] Setting up relu_u1d
I0422 22:26:50.269520 16565 net.cpp:157] Top shape: 1 128 124 124 (1968128)
I0422 22:26:50.269537 16565 net.cpp:165] Memory required for data: 701422848
I0422 22:26:50.269541 16565 layer_factory.hpp:77] Creating layer upconv_u1d_u0a
I0422 22:26:50.269548 16565 net.cpp:100] Creating Layer upconv_u1d_u0a
I0422 22:26:50.269552 16565 net.cpp:434] upconv_u1d_u0a <- u1d
I0422 22:26:50.269558 16565 net.cpp:408] upconv_u1d_u0a -> u0a
I0422 22:26:50.270241 16565 net.cpp:150] Setting up upconv_u1d_u0a
I0422 22:26:50.270248 16565 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0422 22:26:50.270252 16565 net.cpp:165] Memory required for data: 732912896
I0422 22:26:50.270273 16565 layer_factory.hpp:77] Creating layer relu_u0a
I0422 22:26:50.270277 16565 net.cpp:100] Creating Layer relu_u0a
I0422 22:26:50.270280 16565 net.cpp:434] relu_u0a <- u0a
I0422 22:26:50.270285 16565 net.cpp:395] relu_u0a -> u0a (in-place)
I0422 22:26:50.270455 16565 net.cpp:150] Setting up relu_u0a
I0422 22:26:50.270464 16565 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0422 22:26:50.270467 16565 net.cpp:165] Memory required for data: 764402944
I0422 22:26:50.270470 16565 layer_factory.hpp:77] Creating layer u0a_relu_u0a_0_split
I0422 22:26:50.270476 16565 net.cpp:100] Creating Layer u0a_relu_u0a_0_split
I0422 22:26:50.270478 16565 net.cpp:434] u0a_relu_u0a_0_split <- u0a
I0422 22:26:50.270483 16565 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_0
I0422 22:26:50.270490 16565 net.cpp:408] u0a_relu_u0a_0_split -> u0a_relu_u0a_0_split_1
I0422 22:26:50.270532 16565 net.cpp:150] Setting up u0a_relu_u0a_0_split
I0422 22:26:50.270539 16565 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0422 22:26:50.270543 16565 net.cpp:157] Top shape: 1 128 248 248 (7872512)
I0422 22:26:50.270546 16565 net.cpp:165] Memory required for data: 827383040
I0422 22:26:50.270548 16565 layer_factory.hpp:77] Creating layer crop_d0c-d0cc
I0422 22:26:50.270555 16565 net.cpp:100] Creating Layer crop_d0c-d0cc
I0422 22:26:50.270556 16565 net.cpp:434] crop_d0c-d0cc <- d0c_relu_d0c_0_split_1
I0422 22:26:50.270561 16565 net.cpp:434] crop_d0c-d0cc <- u0a_relu_u0a_0_split_0
I0422 22:26:50.270566 16565 net.cpp:408] crop_d0c-d0cc -> d0cc
I0422 22:26:50.270591 16565 net.cpp:150] Setting up crop_d0c-d0cc
I0422 22:26:50.270596 16565 net.cpp:157] Top shape: 1 64 248 248 (3936256)
I0422 22:26:50.270599 16565 net.cpp:165] Memory required for data: 843128064
I0422 22:26:50.270602 16565 layer_factory.hpp:77] Creating layer concat_d0cc_u0a-b
I0422 22:26:50.270606 16565 net.cpp:100] Creating Layer concat_d0cc_u0a-b
I0422 22:26:50.270609 16565 net.cpp:434] concat_d0cc_u0a-b <- u0a_relu_u0a_0_split_1
I0422 22:26:50.270613 16565 net.cpp:434] concat_d0cc_u0a-b <- d0cc
I0422 22:26:50.270617 16565 net.cpp:408] concat_d0cc_u0a-b -> u0b
I0422 22:26:50.270639 16565 net.cpp:150] Setting up concat_d0cc_u0a-b
I0422 22:26:50.270643 16565 net.cpp:157] Top shape: 1 192 248 248 (11808768)
I0422 22:26:50.270658 16565 net.cpp:165] Memory required for data: 890363136
I0422 22:26:50.270661 16565 layer_factory.hpp:77] Creating layer conv_u0b-c
I0422 22:26:50.270669 16565 net.cpp:100] Creating Layer conv_u0b-c
I0422 22:26:50.270673 16565 net.cpp:434] conv_u0b-c <- u0b
I0422 22:26:50.270678 16565 net.cpp:408] conv_u0b-c -> u0c
I0422 22:26:50.271592 16565 net.cpp:150] Setting up conv_u0b-c
I0422 22:26:50.271600 16565 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0422 22:26:50.271602 16565 net.cpp:165] Memory required for data: 905855232
I0422 22:26:50.271623 16565 layer_factory.hpp:77] Creating layer relu_u0c
I0422 22:26:50.271628 16565 net.cpp:100] Creating Layer relu_u0c
I0422 22:26:50.271631 16565 net.cpp:434] relu_u0c <- u0c
I0422 22:26:50.271636 16565 net.cpp:395] relu_u0c -> u0c (in-place)
I0422 22:26:50.271811 16565 net.cpp:150] Setting up relu_u0c
I0422 22:26:50.271821 16565 net.cpp:157] Top shape: 1 64 246 246 (3873024)
I0422 22:26:50.271822 16565 net.cpp:165] Memory required for data: 921347328
I0422 22:26:50.271826 16565 layer_factory.hpp:77] Creating layer conv_u0c-d
I0422 22:26:50.271833 16565 net.cpp:100] Creating Layer conv_u0c-d
I0422 22:26:50.271836 16565 net.cpp:434] conv_u0c-d <- u0c
I0422 22:26:50.271842 16565 net.cpp:408] conv_u0c-d -> u0d
I0422 22:26:50.272356 16565 net.cpp:150] Setting up conv_u0c-d
I0422 22:26:50.272366 16565 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0422 22:26:50.272367 16565 net.cpp:165] Memory required for data: 936588544
I0422 22:26:50.272388 16565 layer_factory.hpp:77] Creating layer relu_u0d
I0422 22:26:50.272400 16565 net.cpp:100] Creating Layer relu_u0d
I0422 22:26:50.272403 16565 net.cpp:434] relu_u0d <- u0d
I0422 22:26:50.272408 16565 net.cpp:395] relu_u0d -> u0d (in-place)
I0422 22:26:50.272578 16565 net.cpp:150] Setting up relu_u0d
I0422 22:26:50.272586 16565 net.cpp:157] Top shape: 1 64 244 244 (3810304)
I0422 22:26:50.272590 16565 net.cpp:165] Memory required for data: 951829760
I0422 22:26:50.272593 16565 layer_factory.hpp:77] Creating layer conv_u0d-score
I0422 22:26:50.272600 16565 net.cpp:100] Creating Layer conv_u0d-score
I0422 22:26:50.272603 16565 net.cpp:434] conv_u0d-score <- u0d
I0422 22:26:50.272608 16565 net.cpp:408] conv_u0d-score -> score
I0422 22:26:50.272917 16565 net.cpp:150] Setting up conv_u0d-score
I0422 22:26:50.272924 16565 net.cpp:157] Top shape: 1 3 244 244 (178608)
I0422 22:26:50.272927 16565 net.cpp:165] Memory required for data: 952544192
I0422 22:26:50.272948 16565 layer_factory.hpp:77] Creating layer softmax
I0422 22:26:50.272953 16565 net.cpp:100] Creating Layer softmax
I0422 22:26:50.272955 16565 net.cpp:434] softmax <- score
I0422 22:26:50.272959 16565 net.cpp:408] softmax -> softmax_out
I0422 22:26:50.273865 16565 net.cpp:150] Setting up softmax
I0422 22:26:50.273879 16565 net.cpp:157] Top shape: 1 3 244 244 (178608)
I0422 22:26:50.273881 16565 net.cpp:165] Memory required for data: 953258624
I0422 22:26:50.273883 16565 layer_factory.hpp:77] Creating layer reshapelab
I0422 22:26:50.273893 16565 net.cpp:100] Creating Layer reshapelab
I0422 22:26:50.273895 16565 net.cpp:434] reshapelab <- label
I0422 22:26:50.273901 16565 net.cpp:408] reshapelab -> label_flat
I0422 22:26:50.273929 16565 net.cpp:150] Setting up reshapelab
I0422 22:26:50.273934 16565 net.cpp:157] Top shape: 1 59536 (59536)
I0422 22:26:50.273937 16565 net.cpp:165] Memory required for data: 953496768
I0422 22:26:50.273939 16565 layer_factory.hpp:77] Creating layer reshaperes
I0422 22:26:50.273943 16565 net.cpp:100] Creating Layer reshaperes
I0422 22:26:50.273947 16565 net.cpp:434] reshaperes <- softmax_out
I0422 22:26:50.273952 16565 net.cpp:408] reshaperes -> softmax_out_flat
I0422 22:26:50.273973 16565 net.cpp:150] Setting up reshaperes
I0422 22:26:50.273978 16565 net.cpp:157] Top shape: 1 3 59536 (178608)
I0422 22:26:50.273982 16565 net.cpp:165] Memory required for data: 954211200
I0422 22:26:50.273983 16565 layer_factory.hpp:77] Creating layer loss
I0422 22:26:50.274024 16565 net.cpp:100] Creating Layer loss
I0422 22:26:50.274029 16565 net.cpp:434] loss <- softmax_out_flat
I0422 22:26:50.274049 16565 net.cpp:434] loss <- label_flat
I0422 22:26:50.274055 16565 net.cpp:408] loss -> loss
I0422 22:26:50.275192 16565 net.cpp:150] Setting up loss
I0422 22:26:50.275202 16565 net.cpp:157] Top shape: 3 (3)
I0422 22:26:50.275205 16565 net.cpp:160]     with loss weight 1
I0422 22:26:50.275221 16565 net.cpp:165] Memory required for data: 954211212
I0422 22:26:50.275224 16565 net.cpp:226] loss needs backward computation.
I0422 22:26:50.275228 16565 net.cpp:226] reshaperes needs backward computation.
I0422 22:26:50.275233 16565 net.cpp:228] reshapelab does not need backward computation.
I0422 22:26:50.275235 16565 net.cpp:226] softmax needs backward computation.
I0422 22:26:50.275238 16565 net.cpp:226] conv_u0d-score needs backward computation.
I0422 22:26:50.275240 16565 net.cpp:226] relu_u0d needs backward computation.
I0422 22:26:50.275243 16565 net.cpp:226] conv_u0c-d needs backward computation.
I0422 22:26:50.275246 16565 net.cpp:226] relu_u0c needs backward computation.
I0422 22:26:50.275249 16565 net.cpp:226] conv_u0b-c needs backward computation.
I0422 22:26:50.275250 16565 net.cpp:226] concat_d0cc_u0a-b needs backward computation.
I0422 22:26:50.275254 16565 net.cpp:226] crop_d0c-d0cc needs backward computation.
I0422 22:26:50.275257 16565 net.cpp:226] u0a_relu_u0a_0_split needs backward computation.
I0422 22:26:50.275260 16565 net.cpp:226] relu_u0a needs backward computation.
I0422 22:26:50.275262 16565 net.cpp:226] upconv_u1d_u0a needs backward computation.
I0422 22:26:50.275265 16565 net.cpp:226] relu_u1d needs backward computation.
I0422 22:26:50.275269 16565 net.cpp:226] conv_u1c-d needs backward computation.
I0422 22:26:50.275270 16565 net.cpp:226] relu_u1c needs backward computation.
I0422 22:26:50.275274 16565 net.cpp:226] conv_u1b-c needs backward computation.
I0422 22:26:50.275276 16565 net.cpp:226] concat_d1cc_u1a-b needs backward computation.
I0422 22:26:50.275279 16565 net.cpp:226] crop_d1c-d1cc needs backward computation.
I0422 22:26:50.275282 16565 net.cpp:226] u1a_relu_u1a_0_split needs backward computation.
I0422 22:26:50.275285 16565 net.cpp:226] relu_u1a needs backward computation.
I0422 22:26:50.275287 16565 net.cpp:226] upconv_u2d_u1a needs backward computation.
I0422 22:26:50.275290 16565 net.cpp:226] relu_u2d needs backward computation.
I0422 22:26:50.275292 16565 net.cpp:226] conv_u2c-d needs backward computation.
I0422 22:26:50.275295 16565 net.cpp:226] relu_u2c needs backward computation.
I0422 22:26:50.275297 16565 net.cpp:226] conv_u2b-c needs backward computation.
I0422 22:26:50.275300 16565 net.cpp:226] concat_d2cc_u2a-b needs backward computation.
I0422 22:26:50.275303 16565 net.cpp:226] crop_d2c-d2cc needs backward computation.
I0422 22:26:50.275306 16565 net.cpp:226] u2a_relu_u2a_0_split needs backward computation.
I0422 22:26:50.275310 16565 net.cpp:226] relu_u2a needs backward computation.
I0422 22:26:50.275311 16565 net.cpp:226] upconv_u3d_u2a needs backward computation.
I0422 22:26:50.275315 16565 net.cpp:226] relu_u3d needs backward computation.
I0422 22:26:50.275316 16565 net.cpp:226] conv_u3c-d needs backward computation.
I0422 22:26:50.275319 16565 net.cpp:226] relu_u3c needs backward computation.
I0422 22:26:50.275321 16565 net.cpp:226] conv_u3b-c needs backward computation.
I0422 22:26:50.275324 16565 net.cpp:226] concat_d3cc_u3a-b needs backward computation.
I0422 22:26:50.275327 16565 net.cpp:226] crop_d3c-d3cc needs backward computation.
I0422 22:26:50.275331 16565 net.cpp:226] u3a_relu_u3a_0_split needs backward computation.
I0422 22:26:50.275333 16565 net.cpp:226] relu_u3a needs backward computation.
I0422 22:26:50.275336 16565 net.cpp:226] upconv_d4c_u3a needs backward computation.
I0422 22:26:50.275338 16565 net.cpp:226] relu_d4c needs backward computation.
I0422 22:26:50.275342 16565 net.cpp:226] conv_d4b-c needs backward computation.
I0422 22:26:50.275344 16565 net.cpp:226] relu_d4b needs backward computation.
I0422 22:26:50.275347 16565 net.cpp:226] conv_d4a-b needs backward computation.
I0422 22:26:50.275351 16565 net.cpp:226] pool_d3c-4a needs backward computation.
I0422 22:26:50.275363 16565 net.cpp:226] d3c_relu_d3c_0_split needs backward computation.
I0422 22:26:50.275367 16565 net.cpp:226] relu_d3c needs backward computation.
I0422 22:26:50.275369 16565 net.cpp:226] conv_d3b-c needs backward computation.
I0422 22:26:50.275372 16565 net.cpp:226] relu_d3b needs backward computation.
I0422 22:26:50.275374 16565 net.cpp:226] conv_d3a-b needs backward computation.
I0422 22:26:50.275377 16565 net.cpp:226] pool_d2c-3a needs backward computation.
I0422 22:26:50.275380 16565 net.cpp:226] d2c_relu_d2c_0_split needs backward computation.
I0422 22:26:50.275383 16565 net.cpp:226] relu_d2c needs backward computation.
I0422 22:26:50.275387 16565 net.cpp:226] conv_d2b-c needs backward computation.
I0422 22:26:50.275389 16565 net.cpp:226] relu_d2b needs backward computation.
I0422 22:26:50.275391 16565 net.cpp:226] conv_d2a-b needs backward computation.
I0422 22:26:50.275394 16565 net.cpp:226] pool_d1c-2a needs backward computation.
I0422 22:26:50.275398 16565 net.cpp:226] d1c_relu_d1c_0_split needs backward computation.
I0422 22:26:50.275400 16565 net.cpp:226] relu_d1c needs backward computation.
I0422 22:26:50.275403 16565 net.cpp:226] conv_d1b-c needs backward computation.
I0422 22:26:50.275405 16565 net.cpp:226] relu_d1b needs backward computation.
I0422 22:26:50.275408 16565 net.cpp:226] conv_d1a-b needs backward computation.
I0422 22:26:50.275411 16565 net.cpp:226] pool_d0c-1a needs backward computation.
I0422 22:26:50.275413 16565 net.cpp:226] d0c_relu_d0c_0_split needs backward computation.
I0422 22:26:50.275416 16565 net.cpp:226] relu_d0c needs backward computation.
I0422 22:26:50.275419 16565 net.cpp:226] conv_d0b-c needs backward computation.
I0422 22:26:50.275423 16565 net.cpp:226] relu_d0b needs backward computation.
I0422 22:26:50.275424 16565 net.cpp:226] conv_d0a-b needs backward computation.
I0422 22:26:50.275427 16565 net.cpp:228] loaddata does not need backward computation.
I0422 22:26:50.275434 16565 net.cpp:270] This network produces output loss
I0422 22:26:50.275482 16565 net.cpp:283] Network initialization done.
I0422 22:26:50.275667 16565 solver.cpp:60] Solver scaffolding done.
I0422 22:26:50.289211 16565 solver.cpp:337] Iteration 0, Testing net (#0)
I0422 22:26:50.292132 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0422 22:26:50.292142 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 22:26:50.299149 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0422 22:26:50.309319 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 22:26:50.309334 16565 net.cpp:693] Ignoring source layer visualize
I0422 22:26:50.309335 16565 net.cpp:693] Ignoring source layer fake
I0422 22:30:23.440575 16565 solver.cpp:404]     Test net output #0: loss = 0.928527 (* 1 = 0.928527 loss)
I0422 22:30:23.440625 16565 solver.cpp:404]     Test net output #1: loss = 0.229316 (* 1 = 0.229316 loss)
I0422 22:30:23.440647 16565 solver.cpp:404]     Test net output #2: loss = 0.207536 (* 1 = 0.207536 loss)
I0422 22:30:24.133891 16565 solver.cpp:228] Iteration 0, loss = 1.35711
I0422 22:30:24.133934 16565 solver.cpp:244]     Train net output #0: loss = 0.891066 (* 1 = 0.891066 loss)
I0422 22:30:24.133956 16565 solver.cpp:244]     Train net output #1: loss = 0.18335 (* 1 = 0.18335 loss)
I0422 22:30:24.133961 16565 solver.cpp:244]     Train net output #2: loss = 0.282689 (* 1 = 0.282689 loss)
I0422 22:30:24.133965 16565 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0422 22:32:03.572790 16565 solver.cpp:228] Iteration 100, loss = 1.58276
I0422 22:32:03.572965 16565 solver.cpp:244]     Train net output #0: loss = 0.932567 (* 1 = 0.932567 loss)
I0422 22:32:03.572974 16565 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0422 22:32:03.572979 16565 solver.cpp:244]     Train net output #2: loss = 0.650196 (* 1 = 0.650196 loss)
I0422 22:32:03.572984 16565 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0422 22:33:41.804445 16565 solver.cpp:228] Iteration 200, loss = 1.65336
I0422 22:33:41.804600 16565 solver.cpp:244]     Train net output #0: loss = 0.938072 (* 1 = 0.938072 loss)
I0422 22:33:41.804607 16565 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0422 22:33:41.804612 16565 solver.cpp:244]     Train net output #2: loss = 0.715284 (* 1 = 0.715284 loss)
I0422 22:33:41.804616 16565 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0422 22:35:21.855242 16565 solver.cpp:228] Iteration 300, loss = 2.08066
I0422 22:35:21.855391 16565 solver.cpp:244]     Train net output #0: loss = 0.962062 (* 1 = 0.962062 loss)
I0422 22:35:21.855399 16565 solver.cpp:244]     Train net output #1: loss = 0.403157 (* 1 = 0.403157 loss)
I0422 22:35:21.855404 16565 solver.cpp:244]     Train net output #2: loss = 0.715438 (* 1 = 0.715438 loss)
I0422 22:35:21.855410 16565 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0422 22:37:02.200204 16565 solver.cpp:228] Iteration 400, loss = 2.00888
I0422 22:37:02.200352 16565 solver.cpp:244]     Train net output #0: loss = 0.799946 (* 1 = 0.799946 loss)
I0422 22:37:02.200361 16565 solver.cpp:244]     Train net output #1: loss = 0.488375 (* 1 = 0.488375 loss)
I0422 22:37:02.200366 16565 solver.cpp:244]     Train net output #2: loss = 0.720561 (* 1 = 0.720561 loss)
I0422 22:37:02.200371 16565 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0422 22:38:42.614426 16565 solver.cpp:228] Iteration 500, loss = 2.23826
I0422 22:38:42.614583 16565 solver.cpp:244]     Train net output #0: loss = 0.946819 (* 1 = 0.946819 loss)
I0422 22:38:42.614593 16565 solver.cpp:244]     Train net output #1: loss = 0.500195 (* 1 = 0.500195 loss)
I0422 22:38:42.614598 16565 solver.cpp:244]     Train net output #2: loss = 0.791243 (* 1 = 0.791243 loss)
I0422 22:38:42.614601 16565 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0422 22:40:22.652827 16565 solver.cpp:228] Iteration 600, loss = 2.54853
I0422 22:40:22.652992 16565 solver.cpp:244]     Train net output #0: loss = 0.955677 (* 1 = 0.955677 loss)
I0422 22:40:22.653000 16565 solver.cpp:244]     Train net output #1: loss = 0.725871 (* 1 = 0.725871 loss)
I0422 22:40:22.653005 16565 solver.cpp:244]     Train net output #2: loss = 0.866982 (* 1 = 0.866982 loss)
I0422 22:40:22.653010 16565 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0422 22:42:00.893846 16565 solver.cpp:228] Iteration 700, loss = 2.48771
I0422 22:42:00.894003 16565 solver.cpp:244]     Train net output #0: loss = 0.9499 (* 1 = 0.9499 loss)
I0422 22:42:00.894011 16565 solver.cpp:244]     Train net output #1: loss = 0.704847 (* 1 = 0.704847 loss)
I0422 22:42:00.894016 16565 solver.cpp:244]     Train net output #2: loss = 0.832957 (* 1 = 0.832957 loss)
I0422 22:42:00.894021 16565 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0422 22:43:40.939137 16565 solver.cpp:228] Iteration 800, loss = 2.30621
I0422 22:43:40.939296 16565 solver.cpp:244]     Train net output #0: loss = 0.962361 (* 1 = 0.962361 loss)
I0422 22:43:40.939303 16565 solver.cpp:244]     Train net output #1: loss = 0.52552 (* 1 = 0.52552 loss)
I0422 22:43:40.939309 16565 solver.cpp:244]     Train net output #2: loss = 0.818327 (* 1 = 0.818327 loss)
I0422 22:43:40.939314 16565 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0422 22:45:21.243309 16565 solver.cpp:228] Iteration 900, loss = 2.13337
I0422 22:45:21.243474 16565 solver.cpp:244]     Train net output #0: loss = 0.975184 (* 1 = 0.975184 loss)
I0422 22:45:21.243482 16565 solver.cpp:244]     Train net output #1: loss = 0.514699 (* 1 = 0.514699 loss)
I0422 22:45:21.243487 16565 solver.cpp:244]     Train net output #2: loss = 0.643492 (* 1 = 0.643492 loss)
I0422 22:45:21.243492 16565 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0422 22:47:00.262738 16565 solver.cpp:337] Iteration 1000, Testing net (#0)
I0422 22:47:00.262925 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0422 22:47:00.262930 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 22:47:00.262936 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0422 22:47:00.262956 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 22:47:00.262960 16565 net.cpp:693] Ignoring source layer visualize
I0422 22:47:00.262962 16565 net.cpp:693] Ignoring source layer fake
I0422 22:50:34.634223 16565 solver.cpp:404]     Test net output #0: loss = 0.941353 (* 1 = 0.941353 loss)
I0422 22:50:34.634376 16565 solver.cpp:404]     Test net output #1: loss = 0.528957 (* 1 = 0.528957 loss)
I0422 22:50:34.634383 16565 solver.cpp:404]     Test net output #2: loss = 0.668864 (* 1 = 0.668864 loss)
I0422 22:50:35.290711 16565 solver.cpp:228] Iteration 1000, loss = 2.25398
I0422 22:50:35.290751 16565 solver.cpp:244]     Train net output #0: loss = 0.957975 (* 1 = 0.957975 loss)
I0422 22:50:35.290757 16565 solver.cpp:244]     Train net output #1: loss = 0.592872 (* 1 = 0.592872 loss)
I0422 22:50:35.290761 16565 solver.cpp:244]     Train net output #2: loss = 0.703137 (* 1 = 0.703137 loss)
I0422 22:50:35.290766 16565 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0422 22:52:13.502698 16565 solver.cpp:228] Iteration 1100, loss = 2.21739
I0422 22:52:13.502843 16565 solver.cpp:244]     Train net output #0: loss = 0.968245 (* 1 = 0.968245 loss)
I0422 22:52:13.502852 16565 solver.cpp:244]     Train net output #1: loss = 0.554879 (* 1 = 0.554879 loss)
I0422 22:52:13.502856 16565 solver.cpp:244]     Train net output #2: loss = 0.694265 (* 1 = 0.694265 loss)
I0422 22:52:13.502862 16565 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0422 22:53:53.205904 16565 solver.cpp:228] Iteration 1200, loss = 2.36354
I0422 22:53:53.207618 16565 solver.cpp:244]     Train net output #0: loss = 0.96154 (* 1 = 0.96154 loss)
I0422 22:53:53.207625 16565 solver.cpp:244]     Train net output #1: loss = 0.511332 (* 1 = 0.511332 loss)
I0422 22:53:53.207630 16565 solver.cpp:244]     Train net output #2: loss = 0.890663 (* 1 = 0.890663 loss)
I0422 22:53:53.207636 16565 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0422 22:55:32.572407 16565 solver.cpp:228] Iteration 1300, loss = 1.85038
I0422 22:55:32.572564 16565 solver.cpp:244]     Train net output #0: loss = 0.95805 (* 1 = 0.95805 loss)
I0422 22:55:32.572571 16565 solver.cpp:244]     Train net output #1: loss = 0.16362 (* 1 = 0.16362 loss)
I0422 22:55:32.572576 16565 solver.cpp:244]     Train net output #2: loss = 0.728711 (* 1 = 0.728711 loss)
I0422 22:55:32.572583 16565 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0422 22:57:12.083322 16565 solver.cpp:228] Iteration 1400, loss = 2.27295
I0422 22:57:12.083472 16565 solver.cpp:244]     Train net output #0: loss = 0.965863 (* 1 = 0.965863 loss)
I0422 22:57:12.083480 16565 solver.cpp:244]     Train net output #1: loss = 0.632504 (* 1 = 0.632504 loss)
I0422 22:57:12.083487 16565 solver.cpp:244]     Train net output #2: loss = 0.674587 (* 1 = 0.674587 loss)
I0422 22:57:12.083492 16565 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0422 22:58:52.365875 16565 solver.cpp:228] Iteration 1500, loss = 2.0698
I0422 22:58:52.366041 16565 solver.cpp:244]     Train net output #0: loss = 0.953009 (* 1 = 0.953009 loss)
I0422 22:58:52.366050 16565 solver.cpp:244]     Train net output #1: loss = 0.483517 (* 1 = 0.483517 loss)
I0422 22:58:52.366055 16565 solver.cpp:244]     Train net output #2: loss = 0.633273 (* 1 = 0.633273 loss)
I0422 22:58:52.366061 16565 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0422 23:00:32.191850 16565 solver.cpp:228] Iteration 1600, loss = 2.11142
I0422 23:00:32.192026 16565 solver.cpp:244]     Train net output #0: loss = 0.760965 (* 1 = 0.760965 loss)
I0422 23:00:32.192034 16565 solver.cpp:244]     Train net output #1: loss = 0.55101 (* 1 = 0.55101 loss)
I0422 23:00:32.192039 16565 solver.cpp:244]     Train net output #2: loss = 0.799442 (* 1 = 0.799442 loss)
I0422 23:00:32.192045 16565 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0422 23:02:10.439585 16565 solver.cpp:228] Iteration 1700, loss = 2.28423
I0422 23:02:10.439766 16565 solver.cpp:244]     Train net output #0: loss = 0.832073 (* 1 = 0.832073 loss)
I0422 23:02:10.439774 16565 solver.cpp:244]     Train net output #1: loss = 0.606632 (* 1 = 0.606632 loss)
I0422 23:02:10.439779 16565 solver.cpp:244]     Train net output #2: loss = 0.845521 (* 1 = 0.845521 loss)
I0422 23:02:10.439785 16565 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0422 23:03:50.379014 16565 solver.cpp:228] Iteration 1800, loss = 2.39347
I0422 23:03:50.379181 16565 solver.cpp:244]     Train net output #0: loss = 0.959344 (* 1 = 0.959344 loss)
I0422 23:03:50.379189 16565 solver.cpp:244]     Train net output #1: loss = 0.655342 (* 1 = 0.655342 loss)
I0422 23:03:50.379194 16565 solver.cpp:244]     Train net output #2: loss = 0.778783 (* 1 = 0.778783 loss)
I0422 23:03:50.379200 16565 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0422 23:05:30.311161 16565 solver.cpp:228] Iteration 1900, loss = 2.38644
I0422 23:05:30.311307 16565 solver.cpp:244]     Train net output #0: loss = 0.916129 (* 1 = 0.916129 loss)
I0422 23:05:30.311316 16565 solver.cpp:244]     Train net output #1: loss = 0.586945 (* 1 = 0.586945 loss)
I0422 23:05:30.311321 16565 solver.cpp:244]     Train net output #2: loss = 0.883365 (* 1 = 0.883365 loss)
I0422 23:05:30.311326 16565 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0422 23:07:09.213609 16565 solver.cpp:337] Iteration 2000, Testing net (#0)
I0422 23:07:09.213783 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0422 23:07:09.213788 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 23:07:09.213793 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0422 23:07:09.213810 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 23:07:09.213814 16565 net.cpp:693] Ignoring source layer visualize
I0422 23:07:09.213816 16565 net.cpp:693] Ignoring source layer fake
I0422 23:10:43.269457 16565 solver.cpp:404]     Test net output #0: loss = 0.939022 (* 1 = 0.939022 loss)
I0422 23:10:43.270325 16565 solver.cpp:404]     Test net output #1: loss = 0.561609 (* 1 = 0.561609 loss)
I0422 23:10:43.270334 16565 solver.cpp:404]     Test net output #2: loss = 0.732947 (* 1 = 0.732947 loss)
I0422 23:10:43.926926 16565 solver.cpp:228] Iteration 2000, loss = 2.34818
I0422 23:10:43.926969 16565 solver.cpp:244]     Train net output #0: loss = 0.967025 (* 1 = 0.967025 loss)
I0422 23:10:43.926973 16565 solver.cpp:244]     Train net output #1: loss = 0.591008 (* 1 = 0.591008 loss)
I0422 23:10:43.926978 16565 solver.cpp:244]     Train net output #2: loss = 0.790151 (* 1 = 0.790151 loss)
I0422 23:10:43.926983 16565 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0422 23:12:22.231838 16565 solver.cpp:228] Iteration 2100, loss = 2.31423
I0422 23:12:22.231986 16565 solver.cpp:244]     Train net output #0: loss = 0.97285 (* 1 = 0.97285 loss)
I0422 23:12:22.231994 16565 solver.cpp:244]     Train net output #1: loss = 0.558703 (* 1 = 0.558703 loss)
I0422 23:12:22.231999 16565 solver.cpp:244]     Train net output #2: loss = 0.782678 (* 1 = 0.782678 loss)
I0422 23:12:22.232004 16565 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0422 23:14:02.065006 16565 solver.cpp:228] Iteration 2200, loss = 2.44231
I0422 23:14:02.065160 16565 solver.cpp:244]     Train net output #0: loss = 0.96392 (* 1 = 0.96392 loss)
I0422 23:14:02.065167 16565 solver.cpp:244]     Train net output #1: loss = 0.656937 (* 1 = 0.656937 loss)
I0422 23:14:02.065173 16565 solver.cpp:244]     Train net output #2: loss = 0.821458 (* 1 = 0.821458 loss)
I0422 23:14:02.065178 16565 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0422 23:15:41.947924 16565 solver.cpp:228] Iteration 2300, loss = 1.99874
I0422 23:15:41.948091 16565 solver.cpp:244]     Train net output #0: loss = 0.96159 (* 1 = 0.96159 loss)
I0422 23:15:41.948099 16565 solver.cpp:244]     Train net output #1: loss = 0.374935 (* 1 = 0.374935 loss)
I0422 23:15:41.948104 16565 solver.cpp:244]     Train net output #2: loss = 0.66221 (* 1 = 0.66221 loss)
I0422 23:15:41.948110 16565 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0422 23:17:24.658468 16565 solver.cpp:228] Iteration 2400, loss = 1.98615
I0422 23:17:24.658663 16565 solver.cpp:244]     Train net output #0: loss = 0.977407 (* 1 = 0.977407 loss)
I0422 23:17:24.658670 16565 solver.cpp:244]     Train net output #1: loss = 0.393702 (* 1 = 0.393702 loss)
I0422 23:17:24.658676 16565 solver.cpp:244]     Train net output #2: loss = 0.615043 (* 1 = 0.615043 loss)
I0422 23:17:24.658681 16565 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0422 23:19:03.789295 16565 solver.cpp:228] Iteration 2500, loss = 1.90577
I0422 23:19:03.789497 16565 solver.cpp:244]     Train net output #0: loss = 0.923942 (* 1 = 0.923942 loss)
I0422 23:19:03.789506 16565 solver.cpp:244]     Train net output #1: loss = 0.323142 (* 1 = 0.323142 loss)
I0422 23:19:03.789510 16565 solver.cpp:244]     Train net output #2: loss = 0.658686 (* 1 = 0.658686 loss)
I0422 23:19:03.789516 16565 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0422 23:20:43.031872 16565 solver.cpp:228] Iteration 2600, loss = 1.94624
I0422 23:20:43.033917 16565 solver.cpp:244]     Train net output #0: loss = 0.959263 (* 1 = 0.959263 loss)
I0422 23:20:43.033941 16565 solver.cpp:244]     Train net output #1: loss = 0.316441 (* 1 = 0.316441 loss)
I0422 23:20:43.033947 16565 solver.cpp:244]     Train net output #2: loss = 0.670532 (* 1 = 0.670532 loss)
I0422 23:20:43.033952 16565 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0422 23:22:20.979940 16565 solver.cpp:228] Iteration 2700, loss = 2.13236
I0422 23:22:20.980096 16565 solver.cpp:244]     Train net output #0: loss = 0.96739 (* 1 = 0.96739 loss)
I0422 23:22:20.980103 16565 solver.cpp:244]     Train net output #1: loss = 0.551024 (* 1 = 0.551024 loss)
I0422 23:22:20.980109 16565 solver.cpp:244]     Train net output #2: loss = 0.613946 (* 1 = 0.613946 loss)
I0422 23:22:20.980115 16565 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0422 23:24:00.626909 16565 solver.cpp:228] Iteration 2800, loss = 2.37864
I0422 23:24:00.627064 16565 solver.cpp:244]     Train net output #0: loss = 0.948329 (* 1 = 0.948329 loss)
I0422 23:24:00.627073 16565 solver.cpp:244]     Train net output #1: loss = 0.690497 (* 1 = 0.690497 loss)
I0422 23:24:00.627079 16565 solver.cpp:244]     Train net output #2: loss = 0.739814 (* 1 = 0.739814 loss)
I0422 23:24:00.627084 16565 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0422 23:25:40.259960 16565 solver.cpp:228] Iteration 2900, loss = 2.14414
I0422 23:25:40.260125 16565 solver.cpp:244]     Train net output #0: loss = 0.706444 (* 1 = 0.706444 loss)
I0422 23:25:40.260133 16565 solver.cpp:244]     Train net output #1: loss = 0.624104 (* 1 = 0.624104 loss)
I0422 23:25:40.260138 16565 solver.cpp:244]     Train net output #2: loss = 0.813589 (* 1 = 0.813589 loss)
I0422 23:25:40.260143 16565 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0422 23:27:19.001894 16565 solver.cpp:337] Iteration 3000, Testing net (#0)
I0422 23:27:19.002049 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0422 23:27:19.002053 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 23:27:19.002058 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0422 23:27:19.002075 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 23:27:19.002080 16565 net.cpp:693] Ignoring source layer visualize
I0422 23:27:19.002082 16565 net.cpp:693] Ignoring source layer fake
I0422 23:30:53.359341 16565 solver.cpp:404]     Test net output #0: loss = 0.944561 (* 1 = 0.944561 loss)
I0422 23:30:53.359508 16565 solver.cpp:404]     Test net output #1: loss = 0.556703 (* 1 = 0.556703 loss)
I0422 23:30:53.359516 16565 solver.cpp:404]     Test net output #2: loss = 0.747758 (* 1 = 0.747758 loss)
I0422 23:30:54.011139 16565 solver.cpp:228] Iteration 3000, loss = 2.50809
I0422 23:30:54.011181 16565 solver.cpp:244]     Train net output #0: loss = 0.972314 (* 1 = 0.972314 loss)
I0422 23:30:54.011188 16565 solver.cpp:244]     Train net output #1: loss = 0.700879 (* 1 = 0.700879 loss)
I0422 23:30:54.011193 16565 solver.cpp:244]     Train net output #2: loss = 0.834895 (* 1 = 0.834895 loss)
I0422 23:30:54.011196 16565 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0422 23:32:34.160035 16565 solver.cpp:228] Iteration 3100, loss = 2.55367
I0422 23:32:34.160228 16565 solver.cpp:244]     Train net output #0: loss = 0.967836 (* 1 = 0.967836 loss)
I0422 23:32:34.160236 16565 solver.cpp:244]     Train net output #1: loss = 0.762247 (* 1 = 0.762247 loss)
I0422 23:32:34.160241 16565 solver.cpp:244]     Train net output #2: loss = 0.823586 (* 1 = 0.823586 loss)
I0422 23:32:34.160246 16565 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0422 23:34:12.360648 16565 solver.cpp:228] Iteration 3200, loss = 2.37939
I0422 23:34:12.360791 16565 solver.cpp:244]     Train net output #0: loss = 0.937824 (* 1 = 0.937824 loss)
I0422 23:34:12.360798 16565 solver.cpp:244]     Train net output #1: loss = 0.661421 (* 1 = 0.661421 loss)
I0422 23:34:12.360803 16565 solver.cpp:244]     Train net output #2: loss = 0.780148 (* 1 = 0.780148 loss)
I0422 23:34:12.360808 16565 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0422 23:35:52.248667 16565 solver.cpp:228] Iteration 3300, loss = 2.56568
I0422 23:35:52.248826 16565 solver.cpp:244]     Train net output #0: loss = 0.96534 (* 1 = 0.96534 loss)
I0422 23:35:52.248833 16565 solver.cpp:244]     Train net output #1: loss = 0.708792 (* 1 = 0.708792 loss)
I0422 23:35:52.248838 16565 solver.cpp:244]     Train net output #2: loss = 0.89155 (* 1 = 0.89155 loss)
I0422 23:35:52.248844 16565 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0422 23:37:32.311655 16565 solver.cpp:228] Iteration 3400, loss = 2.30337
I0422 23:37:32.311813 16565 solver.cpp:244]     Train net output #0: loss = 0.979052 (* 1 = 0.979052 loss)
I0422 23:37:32.311820 16565 solver.cpp:244]     Train net output #1: loss = 0.619781 (* 1 = 0.619781 loss)
I0422 23:37:32.311826 16565 solver.cpp:244]     Train net output #2: loss = 0.704536 (* 1 = 0.704536 loss)
I0422 23:37:32.311831 16565 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0422 23:39:12.162747 16565 solver.cpp:228] Iteration 3500, loss = 2.60082
I0422 23:39:12.162914 16565 solver.cpp:244]     Train net output #0: loss = 0.964328 (* 1 = 0.964328 loss)
I0422 23:39:12.162924 16565 solver.cpp:244]     Train net output #1: loss = 0.722928 (* 1 = 0.722928 loss)
I0422 23:39:12.162928 16565 solver.cpp:244]     Train net output #2: loss = 0.913569 (* 1 = 0.913569 loss)
I0422 23:39:12.162935 16565 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0422 23:40:50.388326 16565 solver.cpp:228] Iteration 3600, loss = 2.44463
I0422 23:40:50.388473 16565 solver.cpp:244]     Train net output #0: loss = 0.979549 (* 1 = 0.979549 loss)
I0422 23:40:50.388480 16565 solver.cpp:244]     Train net output #1: loss = 0.677502 (* 1 = 0.677502 loss)
I0422 23:40:50.388485 16565 solver.cpp:244]     Train net output #2: loss = 0.787575 (* 1 = 0.787575 loss)
I0422 23:40:50.388490 16565 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0422 23:42:30.620012 16565 solver.cpp:228] Iteration 3700, loss = 2.11947
I0422 23:42:30.620159 16565 solver.cpp:244]     Train net output #0: loss = 0.971901 (* 1 = 0.971901 loss)
I0422 23:42:30.620167 16565 solver.cpp:244]     Train net output #1: loss = 0.430778 (* 1 = 0.430778 loss)
I0422 23:42:30.620172 16565 solver.cpp:244]     Train net output #2: loss = 0.716787 (* 1 = 0.716787 loss)
I0422 23:42:30.620177 16565 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0422 23:44:10.180122 16565 solver.cpp:228] Iteration 3800, loss = 2.06234
I0422 23:44:10.180266 16565 solver.cpp:244]     Train net output #0: loss = 0.952517 (* 1 = 0.952517 loss)
I0422 23:44:10.180274 16565 solver.cpp:244]     Train net output #1: loss = 0.296607 (* 1 = 0.296607 loss)
I0422 23:44:10.180279 16565 solver.cpp:244]     Train net output #2: loss = 0.813217 (* 1 = 0.813217 loss)
I0422 23:44:10.180284 16565 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0422 23:45:49.544677 16565 solver.cpp:228] Iteration 3900, loss = 2.50499
I0422 23:45:49.544878 16565 solver.cpp:244]     Train net output #0: loss = 0.971571 (* 1 = 0.971571 loss)
I0422 23:45:49.544888 16565 solver.cpp:244]     Train net output #1: loss = 0.675213 (* 1 = 0.675213 loss)
I0422 23:45:49.544893 16565 solver.cpp:244]     Train net output #2: loss = 0.858203 (* 1 = 0.858203 loss)
I0422 23:45:49.544898 16565 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0422 23:47:28.124701 16565 solver.cpp:337] Iteration 4000, Testing net (#0)
I0422 23:47:28.124828 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0422 23:47:28.124833 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0422 23:47:28.124837 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0422 23:47:28.124856 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0422 23:47:28.124861 16565 net.cpp:693] Ignoring source layer visualize
I0422 23:47:28.124862 16565 net.cpp:693] Ignoring source layer fake
I0422 23:51:01.919126 16565 solver.cpp:404]     Test net output #0: loss = 0.847922 (* 1 = 0.847922 loss)
I0422 23:51:01.919263 16565 solver.cpp:404]     Test net output #1: loss = 0.489602 (* 1 = 0.489602 loss)
I0422 23:51:01.919271 16565 solver.cpp:404]     Test net output #2: loss = 0.775727 (* 1 = 0.775727 loss)
I0422 23:51:02.571971 16565 solver.cpp:228] Iteration 4000, loss = 2.20961
I0422 23:51:02.572013 16565 solver.cpp:244]     Train net output #0: loss = 0.946949 (* 1 = 0.946949 loss)
I0422 23:51:02.572019 16565 solver.cpp:244]     Train net output #1: loss = 0.566507 (* 1 = 0.566507 loss)
I0422 23:51:02.572024 16565 solver.cpp:244]     Train net output #2: loss = 0.696152 (* 1 = 0.696152 loss)
I0422 23:51:02.572028 16565 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0422 23:52:42.807073 16565 solver.cpp:228] Iteration 4100, loss = 1.96191
I0422 23:52:42.807232 16565 solver.cpp:244]     Train net output #0: loss = 0.630333 (* 1 = 0.630333 loss)
I0422 23:52:42.807240 16565 solver.cpp:244]     Train net output #1: loss = 0.528353 (* 1 = 0.528353 loss)
I0422 23:52:42.807245 16565 solver.cpp:244]     Train net output #2: loss = 0.803224 (* 1 = 0.803224 loss)
I0422 23:52:42.807250 16565 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0422 23:54:20.987848 16565 solver.cpp:228] Iteration 4200, loss = 2.23613
I0422 23:54:20.989373 16565 solver.cpp:244]     Train net output #0: loss = 0.750501 (* 1 = 0.750501 loss)
I0422 23:54:20.989382 16565 solver.cpp:244]     Train net output #1: loss = 0.621415 (* 1 = 0.621415 loss)
I0422 23:54:20.989387 16565 solver.cpp:244]     Train net output #2: loss = 0.864216 (* 1 = 0.864216 loss)
I0422 23:54:20.989390 16565 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0422 23:56:00.858973 16565 solver.cpp:228] Iteration 4300, loss = 2.42676
I0422 23:56:00.859122 16565 solver.cpp:244]     Train net output #0: loss = 0.942003 (* 1 = 0.942003 loss)
I0422 23:56:00.859129 16565 solver.cpp:244]     Train net output #1: loss = 0.645713 (* 1 = 0.645713 loss)
I0422 23:56:00.859134 16565 solver.cpp:244]     Train net output #2: loss = 0.839045 (* 1 = 0.839045 loss)
I0422 23:56:00.859140 16565 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0422 23:57:40.737463 16565 solver.cpp:228] Iteration 4400, loss = 2.42408
I0422 23:57:40.737628 16565 solver.cpp:244]     Train net output #0: loss = 0.922448 (* 1 = 0.922448 loss)
I0422 23:57:40.737637 16565 solver.cpp:244]     Train net output #1: loss = 0.643299 (* 1 = 0.643299 loss)
I0422 23:57:40.737643 16565 solver.cpp:244]     Train net output #2: loss = 0.858335 (* 1 = 0.858335 loss)
I0422 23:57:40.737646 16565 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0422 23:59:20.623117 16565 solver.cpp:228] Iteration 4500, loss = 2.59071
I0422 23:59:20.623286 16565 solver.cpp:244]     Train net output #0: loss = 0.980584 (* 1 = 0.980584 loss)
I0422 23:59:20.623294 16565 solver.cpp:244]     Train net output #1: loss = 0.732969 (* 1 = 0.732969 loss)
I0422 23:59:20.623299 16565 solver.cpp:244]     Train net output #2: loss = 0.877159 (* 1 = 0.877159 loss)
I0422 23:59:20.623306 16565 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0423 00:00:58.811038 16565 solver.cpp:228] Iteration 4600, loss = 2.58437
I0423 00:00:58.811218 16565 solver.cpp:244]     Train net output #0: loss = 0.972027 (* 1 = 0.972027 loss)
I0423 00:00:58.811225 16565 solver.cpp:244]     Train net output #1: loss = 0.702902 (* 1 = 0.702902 loss)
I0423 00:00:58.811230 16565 solver.cpp:244]     Train net output #2: loss = 0.909442 (* 1 = 0.909442 loss)
I0423 00:00:58.811236 16565 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0423 00:02:38.629493 16565 solver.cpp:228] Iteration 4700, loss = 2.51277
I0423 00:02:38.629647 16565 solver.cpp:244]     Train net output #0: loss = 0.97057 (* 1 = 0.97057 loss)
I0423 00:02:38.629660 16565 solver.cpp:244]     Train net output #1: loss = 0.678695 (* 1 = 0.678695 loss)
I0423 00:02:38.629667 16565 solver.cpp:244]     Train net output #2: loss = 0.863501 (* 1 = 0.863501 loss)
I0423 00:02:38.629674 16565 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0423 00:04:18.470654 16565 solver.cpp:228] Iteration 4800, loss = 1.83791
I0423 00:04:18.470794 16565 solver.cpp:244]     Train net output #0: loss = 0.985078 (* 1 = 0.985078 loss)
I0423 00:04:18.470803 16565 solver.cpp:244]     Train net output #1: loss = 0.279424 (* 1 = 0.279424 loss)
I0423 00:04:18.470808 16565 solver.cpp:244]     Train net output #2: loss = 0.573406 (* 1 = 0.573406 loss)
I0423 00:04:18.470813 16565 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0423 00:05:58.166339 16565 solver.cpp:228] Iteration 4900, loss = 2.25437
I0423 00:05:58.166491 16565 solver.cpp:244]     Train net output #0: loss = 0.975079 (* 1 = 0.975079 loss)
I0423 00:05:58.166499 16565 solver.cpp:244]     Train net output #1: loss = 0.545845 (* 1 = 0.545845 loss)
I0423 00:05:58.166504 16565 solver.cpp:244]     Train net output #2: loss = 0.733447 (* 1 = 0.733447 loss)
I0423 00:05:58.166509 16565 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0423 00:07:36.552062 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_5000.caffemodel
I0423 00:07:42.179736 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_5000.solverstate
I0423 00:07:42.368577 16565 solver.cpp:337] Iteration 5000, Testing net (#0)
I0423 00:07:42.368621 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 00:07:42.368624 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 00:07:42.368628 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 00:07:42.368647 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 00:07:42.368650 16565 net.cpp:693] Ignoring source layer visualize
I0423 00:07:42.368652 16565 net.cpp:693] Ignoring source layer fake
I0423 00:11:16.126446 16565 solver.cpp:404]     Test net output #0: loss = 0.946912 (* 1 = 0.946912 loss)
I0423 00:11:16.126610 16565 solver.cpp:404]     Test net output #1: loss = 0.552912 (* 1 = 0.552912 loss)
I0423 00:11:16.126616 16565 solver.cpp:404]     Test net output #2: loss = 0.781918 (* 1 = 0.781918 loss)
I0423 00:11:16.784570 16565 solver.cpp:228] Iteration 5000, loss = 2.15448
I0423 00:11:16.784613 16565 solver.cpp:244]     Train net output #0: loss = 0.972852 (* 1 = 0.972852 loss)
I0423 00:11:16.784618 16565 solver.cpp:244]     Train net output #1: loss = 0.376527 (* 1 = 0.376527 loss)
I0423 00:11:16.784622 16565 solver.cpp:244]     Train net output #2: loss = 0.805097 (* 1 = 0.805097 loss)
I0423 00:11:16.784627 16565 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0423 00:12:56.275691 16565 solver.cpp:228] Iteration 5100, loss = 2.39692
I0423 00:12:56.275863 16565 solver.cpp:244]     Train net output #0: loss = 0.924556 (* 1 = 0.924556 loss)
I0423 00:12:56.275871 16565 solver.cpp:244]     Train net output #1: loss = 0.542829 (* 1 = 0.542829 loss)
I0423 00:12:56.275876 16565 solver.cpp:244]     Train net output #2: loss = 0.929537 (* 1 = 0.929537 loss)
I0423 00:12:56.275882 16565 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0423 00:14:34.485550 16565 solver.cpp:228] Iteration 5200, loss = 2.54055
I0423 00:14:34.486387 16565 solver.cpp:244]     Train net output #0: loss = 0.960694 (* 1 = 0.960694 loss)
I0423 00:14:34.486397 16565 solver.cpp:244]     Train net output #1: loss = 0.638551 (* 1 = 0.638551 loss)
I0423 00:14:34.486403 16565 solver.cpp:244]     Train net output #2: loss = 0.9413 (* 1 = 0.9413 loss)
I0423 00:14:34.486407 16565 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0423 00:16:14.161821 16565 solver.cpp:228] Iteration 5300, loss = 2.12284
I0423 00:16:14.161967 16565 solver.cpp:244]     Train net output #0: loss = 0.940062 (* 1 = 0.940062 loss)
I0423 00:16:14.161975 16565 solver.cpp:244]     Train net output #1: loss = 0.61746 (* 1 = 0.61746 loss)
I0423 00:16:14.161980 16565 solver.cpp:244]     Train net output #2: loss = 0.565313 (* 1 = 0.565313 loss)
I0423 00:16:14.161985 16565 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0423 00:17:54.061916 16565 solver.cpp:228] Iteration 5400, loss = 1.77695
I0423 00:17:54.062072 16565 solver.cpp:244]     Train net output #0: loss = 0.903523 (* 1 = 0.903523 loss)
I0423 00:17:54.062080 16565 solver.cpp:244]     Train net output #1: loss = 0.343812 (* 1 = 0.343812 loss)
I0423 00:17:54.062085 16565 solver.cpp:244]     Train net output #2: loss = 0.529618 (* 1 = 0.529618 loss)
I0423 00:17:54.062090 16565 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0423 00:19:34.281420 16565 solver.cpp:228] Iteration 5500, loss = 2.44957
I0423 00:19:34.281585 16565 solver.cpp:244]     Train net output #0: loss = 0.948449 (* 1 = 0.948449 loss)
I0423 00:19:34.281594 16565 solver.cpp:244]     Train net output #1: loss = 0.623134 (* 1 = 0.623134 loss)
I0423 00:19:34.281597 16565 solver.cpp:244]     Train net output #2: loss = 0.877988 (* 1 = 0.877988 loss)
I0423 00:19:34.281605 16565 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0423 00:21:14.346439 16565 solver.cpp:228] Iteration 5600, loss = 2.49602
I0423 00:21:14.346598 16565 solver.cpp:244]     Train net output #0: loss = 0.945139 (* 1 = 0.945139 loss)
I0423 00:21:14.346606 16565 solver.cpp:244]     Train net output #1: loss = 0.628404 (* 1 = 0.628404 loss)
I0423 00:21:14.346612 16565 solver.cpp:244]     Train net output #2: loss = 0.92248 (* 1 = 0.92248 loss)
I0423 00:21:14.346617 16565 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0423 00:22:52.528594 16565 solver.cpp:228] Iteration 5700, loss = 2.36877
I0423 00:22:52.528751 16565 solver.cpp:244]     Train net output #0: loss = 0.911701 (* 1 = 0.911701 loss)
I0423 00:22:52.528760 16565 solver.cpp:244]     Train net output #1: loss = 0.631911 (* 1 = 0.631911 loss)
I0423 00:22:52.528765 16565 solver.cpp:244]     Train net output #2: loss = 0.825153 (* 1 = 0.825153 loss)
I0423 00:22:52.528770 16565 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0423 00:24:32.440232 16565 solver.cpp:228] Iteration 5800, loss = 2.26962
I0423 00:24:32.440289 16565 solver.cpp:244]     Train net output #0: loss = 0.973294 (* 1 = 0.973294 loss)
I0423 00:24:32.440295 16565 solver.cpp:244]     Train net output #1: loss = 0.622283 (* 1 = 0.622283 loss)
I0423 00:24:32.440299 16565 solver.cpp:244]     Train net output #2: loss = 0.674042 (* 1 = 0.674042 loss)
I0423 00:24:32.440304 16565 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0423 00:26:12.445629 16565 solver.cpp:228] Iteration 5900, loss = 2.66827
I0423 00:26:12.446765 16565 solver.cpp:244]     Train net output #0: loss = 0.983438 (* 1 = 0.983438 loss)
I0423 00:26:12.446774 16565 solver.cpp:244]     Train net output #1: loss = 0.783369 (* 1 = 0.783369 loss)
I0423 00:26:12.446779 16565 solver.cpp:244]     Train net output #2: loss = 0.901465 (* 1 = 0.901465 loss)
I0423 00:26:12.446785 16565 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0423 00:27:51.436108 16565 solver.cpp:337] Iteration 6000, Testing net (#0)
I0423 00:27:51.436697 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 00:27:51.436702 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 00:27:51.436707 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 00:27:51.436723 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 00:27:51.436727 16565 net.cpp:693] Ignoring source layer visualize
I0423 00:27:51.436728 16565 net.cpp:693] Ignoring source layer fake
I0423 00:31:27.488129 16565 solver.cpp:404]     Test net output #0: loss = 0.941163 (* 1 = 0.941163 loss)
I0423 00:31:27.488291 16565 solver.cpp:404]     Test net output #1: loss = 0.563187 (* 1 = 0.563187 loss)
I0423 00:31:27.488299 16565 solver.cpp:404]     Test net output #2: loss = 0.789917 (* 1 = 0.789917 loss)
I0423 00:31:28.146610 16565 solver.cpp:228] Iteration 6000, loss = 2.36629
I0423 00:31:28.146654 16565 solver.cpp:244]     Train net output #0: loss = 0.97602 (* 1 = 0.97602 loss)
I0423 00:31:28.146675 16565 solver.cpp:244]     Train net output #1: loss = 0.570227 (* 1 = 0.570227 loss)
I0423 00:31:28.146680 16565 solver.cpp:244]     Train net output #2: loss = 0.820045 (* 1 = 0.820045 loss)
I0423 00:31:28.146685 16565 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0423 00:33:06.397009 16565 solver.cpp:228] Iteration 6100, loss = 2.30832
I0423 00:33:06.397181 16565 solver.cpp:244]     Train net output #0: loss = 0.979024 (* 1 = 0.979024 loss)
I0423 00:33:06.397188 16565 solver.cpp:244]     Train net output #1: loss = 0.513742 (* 1 = 0.513742 loss)
I0423 00:33:06.397193 16565 solver.cpp:244]     Train net output #2: loss = 0.815558 (* 1 = 0.815558 loss)
I0423 00:33:06.397200 16565 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0423 00:34:46.321338 16565 solver.cpp:228] Iteration 6200, loss = 2.32197
I0423 00:34:46.321681 16565 solver.cpp:244]     Train net output #0: loss = 0.960149 (* 1 = 0.960149 loss)
I0423 00:34:46.321689 16565 solver.cpp:244]     Train net output #1: loss = 0.484707 (* 1 = 0.484707 loss)
I0423 00:34:46.321696 16565 solver.cpp:244]     Train net output #2: loss = 0.877118 (* 1 = 0.877118 loss)
I0423 00:34:46.321701 16565 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0423 00:36:25.726938 16565 solver.cpp:228] Iteration 6300, loss = 2.25062
I0423 00:36:25.727111 16565 solver.cpp:244]     Train net output #0: loss = 0.942063 (* 1 = 0.942063 loss)
I0423 00:36:25.727120 16565 solver.cpp:244]     Train net output #1: loss = 0.498792 (* 1 = 0.498792 loss)
I0423 00:36:25.727125 16565 solver.cpp:244]     Train net output #2: loss = 0.80977 (* 1 = 0.80977 loss)
I0423 00:36:25.727131 16565 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0423 00:38:05.124501 16565 solver.cpp:228] Iteration 6400, loss = 2.40496
I0423 00:38:05.124671 16565 solver.cpp:244]     Train net output #0: loss = 0.936315 (* 1 = 0.936315 loss)
I0423 00:38:05.124680 16565 solver.cpp:244]     Train net output #1: loss = 0.719321 (* 1 = 0.719321 loss)
I0423 00:38:05.124685 16565 solver.cpp:244]     Train net output #2: loss = 0.749326 (* 1 = 0.749326 loss)
I0423 00:38:05.124688 16565 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0423 00:39:44.813195 16565 solver.cpp:228] Iteration 6500, loss = 2.32357
I0423 00:39:44.813349 16565 solver.cpp:244]     Train net output #0: loss = 0.923004 (* 1 = 0.923004 loss)
I0423 00:39:44.813357 16565 solver.cpp:244]     Train net output #1: loss = 0.636304 (* 1 = 0.636304 loss)
I0423 00:39:44.813361 16565 solver.cpp:244]     Train net output #2: loss = 0.764262 (* 1 = 0.764262 loss)
I0423 00:39:44.813367 16565 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0423 00:41:24.718910 16565 solver.cpp:228] Iteration 6600, loss = 1.99556
I0423 00:41:24.719048 16565 solver.cpp:244]     Train net output #0: loss = 0.588246 (* 1 = 0.588246 loss)
I0423 00:41:24.719055 16565 solver.cpp:244]     Train net output #1: loss = 0.648754 (* 1 = 0.648754 loss)
I0423 00:41:24.719060 16565 solver.cpp:244]     Train net output #2: loss = 0.758558 (* 1 = 0.758558 loss)
I0423 00:41:24.719065 16565 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0423 00:43:02.978030 16565 solver.cpp:228] Iteration 6700, loss = 2.27681
I0423 00:43:02.978178 16565 solver.cpp:244]     Train net output #0: loss = 0.744479 (* 1 = 0.744479 loss)
I0423 00:43:02.978185 16565 solver.cpp:244]     Train net output #1: loss = 0.634526 (* 1 = 0.634526 loss)
I0423 00:43:02.978190 16565 solver.cpp:244]     Train net output #2: loss = 0.897807 (* 1 = 0.897807 loss)
I0423 00:43:02.978195 16565 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0423 00:44:43.060907 16565 solver.cpp:228] Iteration 6800, loss = 2.56907
I0423 00:44:43.061074 16565 solver.cpp:244]     Train net output #0: loss = 0.948746 (* 1 = 0.948746 loss)
I0423 00:44:43.061082 16565 solver.cpp:244]     Train net output #1: loss = 0.797103 (* 1 = 0.797103 loss)
I0423 00:44:43.061087 16565 solver.cpp:244]     Train net output #2: loss = 0.823218 (* 1 = 0.823218 loss)
I0423 00:44:43.061092 16565 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0423 00:46:23.036937 16565 solver.cpp:228] Iteration 6900, loss = 2.54246
I0423 00:46:23.037112 16565 solver.cpp:244]     Train net output #0: loss = 0.962021 (* 1 = 0.962021 loss)
I0423 00:46:23.037120 16565 solver.cpp:244]     Train net output #1: loss = 0.793839 (* 1 = 0.793839 loss)
I0423 00:46:23.037127 16565 solver.cpp:244]     Train net output #2: loss = 0.786595 (* 1 = 0.786595 loss)
I0423 00:46:23.037132 16565 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0423 00:48:01.977486 16565 solver.cpp:337] Iteration 7000, Testing net (#0)
I0423 00:48:01.977659 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 00:48:01.977663 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 00:48:01.977669 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 00:48:01.977685 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 00:48:01.977689 16565 net.cpp:693] Ignoring source layer visualize
I0423 00:48:01.977691 16565 net.cpp:693] Ignoring source layer fake
I0423 00:51:36.119302 16565 solver.cpp:404]     Test net output #0: loss = 0.942892 (* 1 = 0.942892 loss)
I0423 00:51:36.119444 16565 solver.cpp:404]     Test net output #1: loss = 0.583662 (* 1 = 0.583662 loss)
I0423 00:51:36.119451 16565 solver.cpp:404]     Test net output #2: loss = 0.806446 (* 1 = 0.806446 loss)
I0423 00:51:36.766973 16565 solver.cpp:228] Iteration 7000, loss = 2.18248
I0423 00:51:36.767019 16565 solver.cpp:244]     Train net output #0: loss = 0.971999 (* 1 = 0.971999 loss)
I0423 00:51:36.767025 16565 solver.cpp:244]     Train net output #1: loss = 0.587247 (* 1 = 0.587247 loss)
I0423 00:51:36.767030 16565 solver.cpp:244]     Train net output #2: loss = 0.623233 (* 1 = 0.623233 loss)
I0423 00:51:36.767035 16565 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0423 00:53:15.017946 16565 solver.cpp:228] Iteration 7100, loss = 2.4997
I0423 00:53:15.019058 16565 solver.cpp:244]     Train net output #0: loss = 0.953501 (* 1 = 0.953501 loss)
I0423 00:53:15.019080 16565 solver.cpp:244]     Train net output #1: loss = 0.636668 (* 1 = 0.636668 loss)
I0423 00:53:15.019085 16565 solver.cpp:244]     Train net output #2: loss = 0.909534 (* 1 = 0.909534 loss)
I0423 00:53:15.019090 16565 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0423 00:54:55.197304 16565 solver.cpp:228] Iteration 7200, loss = 2.33792
I0423 00:54:55.197455 16565 solver.cpp:244]     Train net output #0: loss = 0.970897 (* 1 = 0.970897 loss)
I0423 00:54:55.197463 16565 solver.cpp:244]     Train net output #1: loss = 0.621131 (* 1 = 0.621131 loss)
I0423 00:54:55.197469 16565 solver.cpp:244]     Train net output #2: loss = 0.745894 (* 1 = 0.745894 loss)
I0423 00:54:55.197475 16565 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0423 00:56:35.234362 16565 solver.cpp:228] Iteration 7300, loss = 2.22281
I0423 00:56:35.234514 16565 solver.cpp:244]     Train net output #0: loss = 0.983716 (* 1 = 0.983716 loss)
I0423 00:56:35.234524 16565 solver.cpp:244]     Train net output #1: loss = 0.542966 (* 1 = 0.542966 loss)
I0423 00:56:35.234529 16565 solver.cpp:244]     Train net output #2: loss = 0.696123 (* 1 = 0.696123 loss)
I0423 00:56:35.234532 16565 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0423 00:58:15.250479 16565 solver.cpp:228] Iteration 7400, loss = 2.12077
I0423 00:58:15.250643 16565 solver.cpp:244]     Train net output #0: loss = 0.980348 (* 1 = 0.980348 loss)
I0423 00:58:15.250650 16565 solver.cpp:244]     Train net output #1: loss = 0.501563 (* 1 = 0.501563 loss)
I0423 00:58:15.250655 16565 solver.cpp:244]     Train net output #2: loss = 0.638858 (* 1 = 0.638858 loss)
I0423 00:58:15.250660 16565 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0423 00:59:54.577606 16565 solver.cpp:228] Iteration 7500, loss = 2.3027
I0423 00:59:54.577793 16565 solver.cpp:244]     Train net output #0: loss = 0.963805 (* 1 = 0.963805 loss)
I0423 00:59:54.577801 16565 solver.cpp:244]     Train net output #1: loss = 0.460313 (* 1 = 0.460313 loss)
I0423 00:59:54.577807 16565 solver.cpp:244]     Train net output #2: loss = 0.878579 (* 1 = 0.878579 loss)
I0423 00:59:54.577812 16565 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0423 01:01:34.233321 16565 solver.cpp:228] Iteration 7600, loss = 2.21009
I0423 01:01:34.235440 16565 solver.cpp:244]     Train net output #0: loss = 0.932874 (* 1 = 0.932874 loss)
I0423 01:01:34.235447 16565 solver.cpp:244]     Train net output #1: loss = 0.552786 (* 1 = 0.552786 loss)
I0423 01:01:34.235452 16565 solver.cpp:244]     Train net output #2: loss = 0.724428 (* 1 = 0.724428 loss)
I0423 01:01:34.235457 16565 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0423 01:03:12.382954 16565 solver.cpp:228] Iteration 7700, loss = 2.30831
I0423 01:03:12.383126 16565 solver.cpp:244]     Train net output #0: loss = 0.938987 (* 1 = 0.938987 loss)
I0423 01:03:12.383136 16565 solver.cpp:244]     Train net output #1: loss = 0.615423 (* 1 = 0.615423 loss)
I0423 01:03:12.383141 16565 solver.cpp:244]     Train net output #2: loss = 0.753902 (* 1 = 0.753902 loss)
I0423 01:03:12.383146 16565 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0423 01:04:51.942672 16565 solver.cpp:228] Iteration 7800, loss = 2.22553
I0423 01:04:51.942832 16565 solver.cpp:244]     Train net output #0: loss = 0.94238 (* 1 = 0.94238 loss)
I0423 01:04:51.942840 16565 solver.cpp:244]     Train net output #1: loss = 0.522493 (* 1 = 0.522493 loss)
I0423 01:04:51.942845 16565 solver.cpp:244]     Train net output #2: loss = 0.760654 (* 1 = 0.760654 loss)
I0423 01:04:51.942852 16565 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0423 01:06:31.740404 16565 solver.cpp:228] Iteration 7900, loss = 1.43721
I0423 01:06:31.740545 16565 solver.cpp:244]     Train net output #0: loss = 0.968684 (* 1 = 0.968684 loss)
I0423 01:06:31.740553 16565 solver.cpp:244]     Train net output #1: loss = 0.156896 (* 1 = 0.156896 loss)
I0423 01:06:31.740558 16565 solver.cpp:244]     Train net output #2: loss = 0.311632 (* 1 = 0.311632 loss)
I0423 01:06:31.740563 16565 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0423 01:08:10.699864 16565 solver.cpp:337] Iteration 8000, Testing net (#0)
I0423 01:08:10.700024 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 01:08:10.700029 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 01:08:10.700034 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 01:08:10.700052 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 01:08:10.700055 16565 net.cpp:693] Ignoring source layer visualize
I0423 01:08:10.700057 16565 net.cpp:693] Ignoring source layer fake
I0423 01:11:44.493166 16565 solver.cpp:404]     Test net output #0: loss = 0.936403 (* 1 = 0.936403 loss)
I0423 01:11:44.493290 16565 solver.cpp:404]     Test net output #1: loss = 0.576824 (* 1 = 0.576824 loss)
I0423 01:11:44.493297 16565 solver.cpp:404]     Test net output #2: loss = 0.805277 (* 1 = 0.805277 loss)
I0423 01:11:45.144009 16565 solver.cpp:228] Iteration 8000, loss = 2.47775
I0423 01:11:45.144039 16565 solver.cpp:244]     Train net output #0: loss = 0.941283 (* 1 = 0.941283 loss)
I0423 01:11:45.144062 16565 solver.cpp:244]     Train net output #1: loss = 0.669971 (* 1 = 0.669971 loss)
I0423 01:11:45.144065 16565 solver.cpp:244]     Train net output #2: loss = 0.866495 (* 1 = 0.866495 loss)
I0423 01:11:45.144069 16565 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0423 01:13:25.000520 16565 solver.cpp:228] Iteration 8100, loss = 2.61941
I0423 01:13:25.000671 16565 solver.cpp:244]     Train net output #0: loss = 0.955442 (* 1 = 0.955442 loss)
I0423 01:13:25.000679 16565 solver.cpp:244]     Train net output #1: loss = 0.720957 (* 1 = 0.720957 loss)
I0423 01:13:25.000684 16565 solver.cpp:244]     Train net output #2: loss = 0.943006 (* 1 = 0.943006 loss)
I0423 01:13:25.000690 16565 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0423 01:15:03.199089 16565 solver.cpp:228] Iteration 8200, loss = 2.55509
I0423 01:15:03.199301 16565 solver.cpp:244]     Train net output #0: loss = 0.93794 (* 1 = 0.93794 loss)
I0423 01:15:03.199312 16565 solver.cpp:244]     Train net output #1: loss = 0.753682 (* 1 = 0.753682 loss)
I0423 01:15:03.199321 16565 solver.cpp:244]     Train net output #2: loss = 0.863464 (* 1 = 0.863464 loss)
I0423 01:15:03.199328 16565 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0423 01:16:43.091428 16565 solver.cpp:228] Iteration 8300, loss = 2.4707
I0423 01:16:43.091572 16565 solver.cpp:244]     Train net output #0: loss = 0.977281 (* 1 = 0.977281 loss)
I0423 01:16:43.091581 16565 solver.cpp:244]     Train net output #1: loss = 0.625071 (* 1 = 0.625071 loss)
I0423 01:16:43.091588 16565 solver.cpp:244]     Train net output #2: loss = 0.868349 (* 1 = 0.868349 loss)
I0423 01:16:43.091593 16565 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0423 01:18:22.907977 16565 solver.cpp:228] Iteration 8400, loss = 2.33263
I0423 01:18:22.908156 16565 solver.cpp:244]     Train net output #0: loss = 0.98373 (* 1 = 0.98373 loss)
I0423 01:18:22.908164 16565 solver.cpp:244]     Train net output #1: loss = 0.639548 (* 1 = 0.639548 loss)
I0423 01:18:22.908170 16565 solver.cpp:244]     Train net output #2: loss = 0.709351 (* 1 = 0.709351 loss)
I0423 01:18:22.908175 16565 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0423 01:20:02.719069 16565 solver.cpp:228] Iteration 8500, loss = 2.1483
I0423 01:20:02.719249 16565 solver.cpp:244]     Train net output #0: loss = 0.984829 (* 1 = 0.984829 loss)
I0423 01:20:02.719257 16565 solver.cpp:244]     Train net output #1: loss = 0.506708 (* 1 = 0.506708 loss)
I0423 01:20:02.719262 16565 solver.cpp:244]     Train net output #2: loss = 0.656763 (* 1 = 0.656763 loss)
I0423 01:20:02.719269 16565 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0423 01:21:40.895967 16565 solver.cpp:228] Iteration 8600, loss = 2.25923
I0423 01:21:40.896128 16565 solver.cpp:244]     Train net output #0: loss = 0.973992 (* 1 = 0.973992 loss)
I0423 01:21:40.896136 16565 solver.cpp:244]     Train net output #1: loss = 0.559403 (* 1 = 0.559403 loss)
I0423 01:21:40.896142 16565 solver.cpp:244]     Train net output #2: loss = 0.725838 (* 1 = 0.725838 loss)
I0423 01:21:40.896147 16565 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0423 01:23:20.575158 16565 solver.cpp:228] Iteration 8700, loss = 2.26501
I0423 01:23:20.575320 16565 solver.cpp:244]     Train net output #0: loss = 0.955786 (* 1 = 0.955786 loss)
I0423 01:23:20.575328 16565 solver.cpp:244]     Train net output #1: loss = 0.559653 (* 1 = 0.559653 loss)
I0423 01:23:20.575333 16565 solver.cpp:244]     Train net output #2: loss = 0.749569 (* 1 = 0.749569 loss)
I0423 01:23:20.575338 16565 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0423 01:24:59.885748 16565 solver.cpp:228] Iteration 8800, loss = 2.26698
I0423 01:24:59.885917 16565 solver.cpp:244]     Train net output #0: loss = 0.939864 (* 1 = 0.939864 loss)
I0423 01:24:59.885926 16565 solver.cpp:244]     Train net output #1: loss = 0.45992 (* 1 = 0.45992 loss)
I0423 01:24:59.885931 16565 solver.cpp:244]     Train net output #2: loss = 0.867194 (* 1 = 0.867194 loss)
I0423 01:24:59.885936 16565 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0423 01:26:39.222441 16565 solver.cpp:228] Iteration 8900, loss = 2.39534
I0423 01:26:39.222602 16565 solver.cpp:244]     Train net output #0: loss = 0.940495 (* 1 = 0.940495 loss)
I0423 01:26:39.222610 16565 solver.cpp:244]     Train net output #1: loss = 0.689935 (* 1 = 0.689935 loss)
I0423 01:26:39.222615 16565 solver.cpp:244]     Train net output #2: loss = 0.764909 (* 1 = 0.764909 loss)
I0423 01:26:39.222621 16565 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0423 01:28:17.840911 16565 solver.cpp:337] Iteration 9000, Testing net (#0)
I0423 01:28:17.841078 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 01:28:17.841084 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 01:28:17.841089 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 01:28:17.841105 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 01:28:17.841109 16565 net.cpp:693] Ignoring source layer visualize
I0423 01:28:17.841111 16565 net.cpp:693] Ignoring source layer fake
I0423 01:31:51.605509 16565 solver.cpp:404]     Test net output #0: loss = 0.887462 (* 1 = 0.887462 loss)
I0423 01:31:51.605662 16565 solver.cpp:404]     Test net output #1: loss = 0.541041 (* 1 = 0.541041 loss)
I0423 01:31:51.605669 16565 solver.cpp:404]     Test net output #2: loss = 0.790395 (* 1 = 0.790395 loss)
I0423 01:31:52.260694 16565 solver.cpp:228] Iteration 9000, loss = 2.23502
I0423 01:31:52.260735 16565 solver.cpp:244]     Train net output #0: loss = 0.944086 (* 1 = 0.944086 loss)
I0423 01:31:52.260740 16565 solver.cpp:244]     Train net output #1: loss = 0.709608 (* 1 = 0.709608 loss)
I0423 01:31:52.260745 16565 solver.cpp:244]     Train net output #2: loss = 0.581324 (* 1 = 0.581324 loss)
I0423 01:31:52.260748 16565 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0423 01:33:32.137065 16565 solver.cpp:228] Iteration 9100, loss = 2.41017
I0423 01:33:32.137210 16565 solver.cpp:244]     Train net output #0: loss = 0.887392 (* 1 = 0.887392 loss)
I0423 01:33:32.137218 16565 solver.cpp:244]     Train net output #1: loss = 0.660298 (* 1 = 0.660298 loss)
I0423 01:33:32.137223 16565 solver.cpp:244]     Train net output #2: loss = 0.862476 (* 1 = 0.862476 loss)
I0423 01:33:32.137229 16565 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0423 01:35:12.048527 16565 solver.cpp:228] Iteration 9200, loss = 2.44204
I0423 01:35:12.048673 16565 solver.cpp:244]     Train net output #0: loss = 0.866125 (* 1 = 0.866125 loss)
I0423 01:35:12.048681 16565 solver.cpp:244]     Train net output #1: loss = 0.661028 (* 1 = 0.661028 loss)
I0423 01:35:12.048687 16565 solver.cpp:244]     Train net output #2: loss = 0.91489 (* 1 = 0.91489 loss)
I0423 01:35:12.048692 16565 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0423 01:36:50.227753 16565 solver.cpp:228] Iteration 9300, loss = 2.30919
I0423 01:36:50.227893 16565 solver.cpp:244]     Train net output #0: loss = 0.945754 (* 1 = 0.945754 loss)
I0423 01:36:50.227902 16565 solver.cpp:244]     Train net output #1: loss = 0.667998 (* 1 = 0.667998 loss)
I0423 01:36:50.227906 16565 solver.cpp:244]     Train net output #2: loss = 0.695433 (* 1 = 0.695433 loss)
I0423 01:36:50.227911 16565 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0423 01:38:30.166251 16565 solver.cpp:228] Iteration 9400, loss = 2.41784
I0423 01:38:30.166407 16565 solver.cpp:244]     Train net output #0: loss = 0.957489 (* 1 = 0.957489 loss)
I0423 01:38:30.166415 16565 solver.cpp:244]     Train net output #1: loss = 0.62701 (* 1 = 0.62701 loss)
I0423 01:38:30.166420 16565 solver.cpp:244]     Train net output #2: loss = 0.833338 (* 1 = 0.833338 loss)
I0423 01:38:30.166425 16565 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0423 01:40:10.042316 16565 solver.cpp:228] Iteration 9500, loss = 2.19276
I0423 01:40:10.042470 16565 solver.cpp:244]     Train net output #0: loss = 0.962838 (* 1 = 0.962838 loss)
I0423 01:40:10.042479 16565 solver.cpp:244]     Train net output #1: loss = 0.544423 (* 1 = 0.544423 loss)
I0423 01:40:10.042484 16565 solver.cpp:244]     Train net output #2: loss = 0.685504 (* 1 = 0.685504 loss)
I0423 01:40:10.042490 16565 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0423 01:41:48.240805 16565 solver.cpp:228] Iteration 9600, loss = 2.59862
I0423 01:41:48.240947 16565 solver.cpp:244]     Train net output #0: loss = 0.967847 (* 1 = 0.967847 loss)
I0423 01:41:48.240955 16565 solver.cpp:244]     Train net output #1: loss = 0.704077 (* 1 = 0.704077 loss)
I0423 01:41:48.240962 16565 solver.cpp:244]     Train net output #2: loss = 0.926696 (* 1 = 0.926696 loss)
I0423 01:41:48.240967 16565 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0423 01:43:28.037556 16565 solver.cpp:228] Iteration 9700, loss = 2.44353
I0423 01:43:28.037725 16565 solver.cpp:244]     Train net output #0: loss = 0.954355 (* 1 = 0.954355 loss)
I0423 01:43:28.037734 16565 solver.cpp:244]     Train net output #1: loss = 0.620961 (* 1 = 0.620961 loss)
I0423 01:43:28.037739 16565 solver.cpp:244]     Train net output #2: loss = 0.868215 (* 1 = 0.868215 loss)
I0423 01:43:28.037744 16565 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0423 01:45:07.825373 16565 solver.cpp:228] Iteration 9800, loss = 2.56144
I0423 01:45:07.825924 16565 solver.cpp:244]     Train net output #0: loss = 0.976935 (* 1 = 0.976935 loss)
I0423 01:45:07.825933 16565 solver.cpp:244]     Train net output #1: loss = 0.665366 (* 1 = 0.665366 loss)
I0423 01:45:07.825938 16565 solver.cpp:244]     Train net output #2: loss = 0.91914 (* 1 = 0.91914 loss)
I0423 01:45:07.825943 16565 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0423 01:46:47.500007 16565 solver.cpp:228] Iteration 9900, loss = 2.33137
I0423 01:46:47.500159 16565 solver.cpp:244]     Train net output #0: loss = 0.981849 (* 1 = 0.981849 loss)
I0423 01:46:47.500166 16565 solver.cpp:244]     Train net output #1: loss = 0.49192 (* 1 = 0.49192 loss)
I0423 01:46:47.500171 16565 solver.cpp:244]     Train net output #2: loss = 0.857598 (* 1 = 0.857598 loss)
I0423 01:46:47.500178 16565 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0423 01:48:25.839395 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_10000.caffemodel
I0423 01:48:33.633982 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_10000.solverstate
I0423 01:48:33.819607 16565 solver.cpp:337] Iteration 10000, Testing net (#0)
I0423 01:48:33.819650 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 01:48:33.819653 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 01:48:33.819656 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 01:48:33.819672 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 01:48:33.819679 16565 net.cpp:693] Ignoring source layer visualize
I0423 01:48:33.819680 16565 net.cpp:693] Ignoring source layer fake
I0423 01:52:07.278373 16565 solver.cpp:404]     Test net output #0: loss = 0.947806 (* 1 = 0.947806 loss)
I0423 01:52:07.278508 16565 solver.cpp:404]     Test net output #1: loss = 0.574859 (* 1 = 0.574859 loss)
I0423 01:52:07.278517 16565 solver.cpp:404]     Test net output #2: loss = 0.782321 (* 1 = 0.782321 loss)
I0423 01:52:07.927875 16565 solver.cpp:228] Iteration 10000, loss = 2.10079
I0423 01:52:07.927916 16565 solver.cpp:244]     Train net output #0: loss = 0.935843 (* 1 = 0.935843 loss)
I0423 01:52:07.927922 16565 solver.cpp:244]     Train net output #1: loss = 0.322225 (* 1 = 0.322225 loss)
I0423 01:52:07.927927 16565 solver.cpp:244]     Train net output #2: loss = 0.842724 (* 1 = 0.842724 loss)
I0423 01:52:07.927930 16565 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0423 01:53:47.292593 16565 solver.cpp:228] Iteration 10100, loss = 2.38614
I0423 01:53:47.292731 16565 solver.cpp:244]     Train net output #0: loss = 0.931466 (* 1 = 0.931466 loss)
I0423 01:53:47.292739 16565 solver.cpp:244]     Train net output #1: loss = 0.564286 (* 1 = 0.564286 loss)
I0423 01:53:47.292744 16565 solver.cpp:244]     Train net output #2: loss = 0.890386 (* 1 = 0.890386 loss)
I0423 01:53:47.292750 16565 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0423 01:55:25.449477 16565 solver.cpp:228] Iteration 10200, loss = 2.18932
I0423 01:55:25.449626 16565 solver.cpp:244]     Train net output #0: loss = 0.978325 (* 1 = 0.978325 loss)
I0423 01:55:25.449633 16565 solver.cpp:244]     Train net output #1: loss = 0.481887 (* 1 = 0.481887 loss)
I0423 01:55:25.449638 16565 solver.cpp:244]     Train net output #2: loss = 0.729112 (* 1 = 0.729112 loss)
I0423 01:55:25.449645 16565 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0423 01:57:05.032879 16565 solver.cpp:228] Iteration 10300, loss = 2.48569
I0423 01:57:05.033027 16565 solver.cpp:244]     Train net output #0: loss = 0.962006 (* 1 = 0.962006 loss)
I0423 01:57:05.033035 16565 solver.cpp:244]     Train net output #1: loss = 0.763311 (* 1 = 0.763311 loss)
I0423 01:57:05.033041 16565 solver.cpp:244]     Train net output #2: loss = 0.760378 (* 1 = 0.760378 loss)
I0423 01:57:05.033046 16565 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0423 01:58:44.793931 16565 solver.cpp:228] Iteration 10400, loss = 1.71979
I0423 01:58:44.794061 16565 solver.cpp:244]     Train net output #0: loss = 0.962839 (* 1 = 0.962839 loss)
I0423 01:58:44.794070 16565 solver.cpp:244]     Train net output #1: loss = 0.154878 (* 1 = 0.154878 loss)
I0423 01:58:44.794075 16565 solver.cpp:244]     Train net output #2: loss = 0.60207 (* 1 = 0.60207 loss)
I0423 01:58:44.794080 16565 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0423 02:00:24.656644 16565 solver.cpp:228] Iteration 10500, loss = 2.58861
I0423 02:00:24.656813 16565 solver.cpp:244]     Train net output #0: loss = 0.961438 (* 1 = 0.961438 loss)
I0423 02:00:24.656822 16565 solver.cpp:244]     Train net output #1: loss = 0.788797 (* 1 = 0.788797 loss)
I0423 02:00:24.656826 16565 solver.cpp:244]     Train net output #2: loss = 0.838378 (* 1 = 0.838378 loss)
I0423 02:00:24.656831 16565 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0423 02:02:04.524260 16565 solver.cpp:228] Iteration 10600, loss = 2.41862
I0423 02:02:04.524420 16565 solver.cpp:244]     Train net output #0: loss = 0.957293 (* 1 = 0.957293 loss)
I0423 02:02:04.524427 16565 solver.cpp:244]     Train net output #1: loss = 0.730772 (* 1 = 0.730772 loss)
I0423 02:02:04.524432 16565 solver.cpp:244]     Train net output #2: loss = 0.730551 (* 1 = 0.730551 loss)
I0423 02:02:04.524437 16565 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0423 02:03:42.699427 16565 solver.cpp:228] Iteration 10700, loss = 2.60766
I0423 02:03:42.699589 16565 solver.cpp:244]     Train net output #0: loss = 0.958371 (* 1 = 0.958371 loss)
I0423 02:03:42.699596 16565 solver.cpp:244]     Train net output #1: loss = 0.781467 (* 1 = 0.781467 loss)
I0423 02:03:42.699600 16565 solver.cpp:244]     Train net output #2: loss = 0.867823 (* 1 = 0.867823 loss)
I0423 02:03:42.699606 16565 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0423 02:05:22.555943 16565 solver.cpp:228] Iteration 10800, loss = 2.4369
I0423 02:05:22.556082 16565 solver.cpp:244]     Train net output #0: loss = 0.980788 (* 1 = 0.980788 loss)
I0423 02:05:22.556088 16565 solver.cpp:244]     Train net output #1: loss = 0.704387 (* 1 = 0.704387 loss)
I0423 02:05:22.556094 16565 solver.cpp:244]     Train net output #2: loss = 0.751726 (* 1 = 0.751726 loss)
I0423 02:05:22.556099 16565 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0423 02:07:02.332566 16565 solver.cpp:228] Iteration 10900, loss = 2.3619
I0423 02:07:02.332722 16565 solver.cpp:244]     Train net output #0: loss = 0.973709 (* 1 = 0.973709 loss)
I0423 02:07:02.332731 16565 solver.cpp:244]     Train net output #1: loss = 0.647283 (* 1 = 0.647283 loss)
I0423 02:07:02.332736 16565 solver.cpp:244]     Train net output #2: loss = 0.740909 (* 1 = 0.740909 loss)
I0423 02:07:02.332741 16565 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0423 02:08:41.112663 16565 solver.cpp:337] Iteration 11000, Testing net (#0)
I0423 02:08:41.112789 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 02:08:41.112794 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 02:08:41.112798 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 02:08:41.112817 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 02:08:41.112820 16565 net.cpp:693] Ignoring source layer visualize
I0423 02:08:41.112823 16565 net.cpp:693] Ignoring source layer fake
I0423 02:12:15.152123 16565 solver.cpp:404]     Test net output #0: loss = 0.94212 (* 1 = 0.94212 loss)
I0423 02:12:15.152266 16565 solver.cpp:404]     Test net output #1: loss = 0.583256 (* 1 = 0.583256 loss)
I0423 02:12:15.152273 16565 solver.cpp:404]     Test net output #2: loss = 0.806991 (* 1 = 0.806991 loss)
I0423 02:12:15.801211 16565 solver.cpp:228] Iteration 11000, loss = 2.42483
I0423 02:12:15.801254 16565 solver.cpp:244]     Train net output #0: loss = 0.974683 (* 1 = 0.974683 loss)
I0423 02:12:15.801259 16565 solver.cpp:244]     Train net output #1: loss = 0.683777 (* 1 = 0.683777 loss)
I0423 02:12:15.801264 16565 solver.cpp:244]     Train net output #2: loss = 0.766376 (* 1 = 0.766376 loss)
I0423 02:12:15.801268 16565 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0423 02:13:54.322489 16565 solver.cpp:228] Iteration 11100, loss = 2.61123
I0423 02:13:54.322667 16565 solver.cpp:244]     Train net output #0: loss = 0.969334 (* 1 = 0.969334 loss)
I0423 02:13:54.322676 16565 solver.cpp:244]     Train net output #1: loss = 0.694411 (* 1 = 0.694411 loss)
I0423 02:13:54.322681 16565 solver.cpp:244]     Train net output #2: loss = 0.94748 (* 1 = 0.94748 loss)
I0423 02:13:54.322686 16565 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0423 02:15:34.320755 16565 solver.cpp:228] Iteration 11200, loss = 2.4038
I0423 02:15:34.320925 16565 solver.cpp:244]     Train net output #0: loss = 0.973308 (* 1 = 0.973308 loss)
I0423 02:15:34.320933 16565 solver.cpp:244]     Train net output #1: loss = 0.595018 (* 1 = 0.595018 loss)
I0423 02:15:34.320938 16565 solver.cpp:244]     Train net output #2: loss = 0.835472 (* 1 = 0.835472 loss)
I0423 02:15:34.320943 16565 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0423 02:17:13.574975 16565 solver.cpp:228] Iteration 11300, loss = 2.22417
I0423 02:17:13.575132 16565 solver.cpp:244]     Train net output #0: loss = 0.950176 (* 1 = 0.950176 loss)
I0423 02:17:13.575140 16565 solver.cpp:244]     Train net output #1: loss = 0.385704 (* 1 = 0.385704 loss)
I0423 02:17:13.575145 16565 solver.cpp:244]     Train net output #2: loss = 0.888293 (* 1 = 0.888293 loss)
I0423 02:17:13.575150 16565 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0423 02:18:53.161545 16565 solver.cpp:228] Iteration 11400, loss = 1.97952
I0423 02:18:53.161698 16565 solver.cpp:244]     Train net output #0: loss = 0.958012 (* 1 = 0.958012 loss)
I0423 02:18:53.161706 16565 solver.cpp:244]     Train net output #1: loss = 0.443134 (* 1 = 0.443134 loss)
I0423 02:18:53.161712 16565 solver.cpp:244]     Train net output #2: loss = 0.578374 (* 1 = 0.578374 loss)
I0423 02:18:53.161717 16565 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0423 02:20:33.012231 16565 solver.cpp:228] Iteration 11500, loss = 2.23429
I0423 02:20:33.012387 16565 solver.cpp:244]     Train net output #0: loss = 0.955574 (* 1 = 0.955574 loss)
I0423 02:20:33.012395 16565 solver.cpp:244]     Train net output #1: loss = 0.727679 (* 1 = 0.727679 loss)
I0423 02:20:33.012400 16565 solver.cpp:244]     Train net output #2: loss = 0.551035 (* 1 = 0.551035 loss)
I0423 02:20:33.012404 16565 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0423 02:22:13.551944 16565 solver.cpp:228] Iteration 11600, loss = 2.01326
I0423 02:22:13.552104 16565 solver.cpp:244]     Train net output #0: loss = 0.947606 (* 1 = 0.947606 loss)
I0423 02:22:13.552112 16565 solver.cpp:244]     Train net output #1: loss = 0.373361 (* 1 = 0.373361 loss)
I0423 02:22:13.552117 16565 solver.cpp:244]     Train net output #2: loss = 0.692292 (* 1 = 0.692292 loss)
I0423 02:22:13.552122 16565 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0423 02:23:54.533385 16565 solver.cpp:228] Iteration 11700, loss = 2.40511
I0423 02:23:54.533556 16565 solver.cpp:244]     Train net output #0: loss = 0.930091 (* 1 = 0.930091 loss)
I0423 02:23:54.533563 16565 solver.cpp:244]     Train net output #1: loss = 0.627135 (* 1 = 0.627135 loss)
I0423 02:23:54.533568 16565 solver.cpp:244]     Train net output #2: loss = 0.847883 (* 1 = 0.847883 loss)
I0423 02:23:54.533574 16565 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0423 02:25:32.736629 16565 solver.cpp:228] Iteration 11800, loss = 2.44909
I0423 02:25:32.736790 16565 solver.cpp:244]     Train net output #0: loss = 0.957025 (* 1 = 0.957025 loss)
I0423 02:25:32.736799 16565 solver.cpp:244]     Train net output #1: loss = 0.631881 (* 1 = 0.631881 loss)
I0423 02:25:32.736804 16565 solver.cpp:244]     Train net output #2: loss = 0.860187 (* 1 = 0.860187 loss)
I0423 02:25:32.736809 16565 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0423 02:27:12.622094 16565 solver.cpp:228] Iteration 11900, loss = 2.49017
I0423 02:27:12.622298 16565 solver.cpp:244]     Train net output #0: loss = 0.95582 (* 1 = 0.95582 loss)
I0423 02:27:12.622306 16565 solver.cpp:244]     Train net output #1: loss = 0.669029 (* 1 = 0.669029 loss)
I0423 02:27:12.622311 16565 solver.cpp:244]     Train net output #2: loss = 0.865323 (* 1 = 0.865323 loss)
I0423 02:27:12.622315 16565 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0423 02:28:51.512761 16565 solver.cpp:337] Iteration 12000, Testing net (#0)
I0423 02:28:51.512922 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 02:28:51.512926 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 02:28:51.512930 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 02:28:51.512946 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 02:28:51.512950 16565 net.cpp:693] Ignoring source layer visualize
I0423 02:28:51.512953 16565 net.cpp:693] Ignoring source layer fake
I0423 02:32:25.222643 16565 solver.cpp:404]     Test net output #0: loss = 0.946419 (* 1 = 0.946419 loss)
I0423 02:32:25.222798 16565 solver.cpp:404]     Test net output #1: loss = 0.603853 (* 1 = 0.603853 loss)
I0423 02:32:25.222805 16565 solver.cpp:404]     Test net output #2: loss = 0.819771 (* 1 = 0.819771 loss)
I0423 02:32:25.878883 16565 solver.cpp:228] Iteration 12000, loss = 2.41559
I0423 02:32:25.878923 16565 solver.cpp:244]     Train net output #0: loss = 0.972079 (* 1 = 0.972079 loss)
I0423 02:32:25.878928 16565 solver.cpp:244]     Train net output #1: loss = 0.763377 (* 1 = 0.763377 loss)
I0423 02:32:25.878933 16565 solver.cpp:244]     Train net output #2: loss = 0.680138 (* 1 = 0.680138 loss)
I0423 02:32:25.878937 16565 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0423 02:34:04.073294 16565 solver.cpp:228] Iteration 12100, loss = 2.63614
I0423 02:34:04.073449 16565 solver.cpp:244]     Train net output #0: loss = 0.983763 (* 1 = 0.983763 loss)
I0423 02:34:04.073458 16565 solver.cpp:244]     Train net output #1: loss = 0.747304 (* 1 = 0.747304 loss)
I0423 02:34:04.073463 16565 solver.cpp:244]     Train net output #2: loss = 0.905073 (* 1 = 0.905073 loss)
I0423 02:34:04.073469 16565 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0423 02:35:43.985914 16565 solver.cpp:228] Iteration 12200, loss = 2.47244
I0423 02:35:43.986079 16565 solver.cpp:244]     Train net output #0: loss = 0.965554 (* 1 = 0.965554 loss)
I0423 02:35:43.986088 16565 solver.cpp:244]     Train net output #1: loss = 0.635438 (* 1 = 0.635438 loss)
I0423 02:35:43.986093 16565 solver.cpp:244]     Train net output #2: loss = 0.871445 (* 1 = 0.871445 loss)
I0423 02:35:43.986098 16565 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0423 02:37:23.876622 16565 solver.cpp:228] Iteration 12300, loss = 2.31084
I0423 02:37:23.876780 16565 solver.cpp:244]     Train net output #0: loss = 0.975931 (* 1 = 0.975931 loss)
I0423 02:37:23.876787 16565 solver.cpp:244]     Train net output #1: loss = 0.55517 (* 1 = 0.55517 loss)
I0423 02:37:23.876792 16565 solver.cpp:244]     Train net output #2: loss = 0.779741 (* 1 = 0.779741 loss)
I0423 02:37:23.876798 16565 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0423 02:39:03.941272 16565 solver.cpp:228] Iteration 12400, loss = 2.42108
I0423 02:39:03.941426 16565 solver.cpp:244]     Train net output #0: loss = 0.968113 (* 1 = 0.968113 loss)
I0423 02:39:03.941432 16565 solver.cpp:244]     Train net output #1: loss = 0.537493 (* 1 = 0.537493 loss)
I0423 02:39:03.941448 16565 solver.cpp:244]     Train net output #2: loss = 0.91547 (* 1 = 0.91547 loss)
I0423 02:39:03.941453 16565 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0423 02:40:43.375834 16565 solver.cpp:228] Iteration 12500, loss = 2.05897
I0423 02:40:43.375999 16565 solver.cpp:244]     Train net output #0: loss = 0.936072 (* 1 = 0.936072 loss)
I0423 02:40:43.376008 16565 solver.cpp:244]     Train net output #1: loss = 0.260361 (* 1 = 0.260361 loss)
I0423 02:40:43.376013 16565 solver.cpp:244]     Train net output #2: loss = 0.862537 (* 1 = 0.862537 loss)
I0423 02:40:43.376019 16565 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0423 02:42:22.681524 16565 solver.cpp:228] Iteration 12600, loss = 1.93786
I0423 02:42:22.682039 16565 solver.cpp:244]     Train net output #0: loss = 0.927022 (* 1 = 0.927022 loss)
I0423 02:42:22.682046 16565 solver.cpp:244]     Train net output #1: loss = 0.43681 (* 1 = 0.43681 loss)
I0423 02:42:22.682051 16565 solver.cpp:244]     Train net output #2: loss = 0.574024 (* 1 = 0.574024 loss)
I0423 02:42:22.682056 16565 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0423 02:44:00.905504 16565 solver.cpp:228] Iteration 12700, loss = 2.46082
I0423 02:44:00.905648 16565 solver.cpp:244]     Train net output #0: loss = 0.94305 (* 1 = 0.94305 loss)
I0423 02:44:00.905658 16565 solver.cpp:244]     Train net output #1: loss = 0.561821 (* 1 = 0.561821 loss)
I0423 02:44:00.905663 16565 solver.cpp:244]     Train net output #2: loss = 0.955944 (* 1 = 0.955944 loss)
I0423 02:44:00.905668 16565 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0423 02:45:40.858553 16565 solver.cpp:228] Iteration 12800, loss = 2.24016
I0423 02:45:40.858722 16565 solver.cpp:244]     Train net output #0: loss = 0.976557 (* 1 = 0.976557 loss)
I0423 02:45:40.858731 16565 solver.cpp:244]     Train net output #1: loss = 0.690963 (* 1 = 0.690963 loss)
I0423 02:45:40.858737 16565 solver.cpp:244]     Train net output #2: loss = 0.572638 (* 1 = 0.572638 loss)
I0423 02:45:40.858741 16565 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0423 02:47:20.798295 16565 solver.cpp:228] Iteration 12900, loss = 1.62159
I0423 02:47:20.798444 16565 solver.cpp:244]     Train net output #0: loss = 0.960463 (* 1 = 0.960463 loss)
I0423 02:47:20.798452 16565 solver.cpp:244]     Train net output #1: loss = 0.102507 (* 1 = 0.102507 loss)
I0423 02:47:20.798457 16565 solver.cpp:244]     Train net output #2: loss = 0.558623 (* 1 = 0.558623 loss)
I0423 02:47:20.798461 16565 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0423 02:48:59.813014 16565 solver.cpp:337] Iteration 13000, Testing net (#0)
I0423 02:48:59.813161 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 02:48:59.813165 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 02:48:59.813170 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 02:48:59.813186 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 02:48:59.813190 16565 net.cpp:693] Ignoring source layer visualize
I0423 02:48:59.813192 16565 net.cpp:693] Ignoring source layer fake
I0423 02:52:34.375849 16565 solver.cpp:404]     Test net output #0: loss = 0.946007 (* 1 = 0.946007 loss)
I0423 02:52:34.375988 16565 solver.cpp:404]     Test net output #1: loss = 0.567521 (* 1 = 0.567521 loss)
I0423 02:52:34.375996 16565 solver.cpp:404]     Test net output #2: loss = 0.772428 (* 1 = 0.772428 loss)
I0423 02:52:35.026808 16565 solver.cpp:228] Iteration 13000, loss = 2.35148
I0423 02:52:35.026851 16565 solver.cpp:244]     Train net output #0: loss = 0.958317 (* 1 = 0.958317 loss)
I0423 02:52:35.026857 16565 solver.cpp:244]     Train net output #1: loss = 0.629019 (* 1 = 0.629019 loss)
I0423 02:52:35.026861 16565 solver.cpp:244]     Train net output #2: loss = 0.764142 (* 1 = 0.764142 loss)
I0423 02:52:35.026865 16565 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0423 02:54:15.305176 16565 solver.cpp:228] Iteration 13100, loss = 2.38088
I0423 02:54:15.305340 16565 solver.cpp:244]     Train net output #0: loss = 0.951847 (* 1 = 0.951847 loss)
I0423 02:54:15.305347 16565 solver.cpp:244]     Train net output #1: loss = 0.551136 (* 1 = 0.551136 loss)
I0423 02:54:15.305352 16565 solver.cpp:244]     Train net output #2: loss = 0.877894 (* 1 = 0.877894 loss)
I0423 02:54:15.305357 16565 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0423 02:55:53.531970 16565 solver.cpp:228] Iteration 13200, loss = 2.46736
I0423 02:55:53.532130 16565 solver.cpp:244]     Train net output #0: loss = 0.934785 (* 1 = 0.934785 loss)
I0423 02:55:53.532137 16565 solver.cpp:244]     Train net output #1: loss = 0.646743 (* 1 = 0.646743 loss)
I0423 02:55:53.532142 16565 solver.cpp:244]     Train net output #2: loss = 0.885835 (* 1 = 0.885835 loss)
I0423 02:55:53.532148 16565 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0423 02:57:33.522330 16565 solver.cpp:228] Iteration 13300, loss = 2.24853
I0423 02:57:33.522547 16565 solver.cpp:244]     Train net output #0: loss = 0.972248 (* 1 = 0.972248 loss)
I0423 02:57:33.522555 16565 solver.cpp:244]     Train net output #1: loss = 0.60063 (* 1 = 0.60063 loss)
I0423 02:57:33.522560 16565 solver.cpp:244]     Train net output #2: loss = 0.675656 (* 1 = 0.675656 loss)
I0423 02:57:33.522567 16565 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0423 02:59:13.452993 16565 solver.cpp:228] Iteration 13400, loss = 2.44904
I0423 02:59:13.453168 16565 solver.cpp:244]     Train net output #0: loss = 0.980523 (* 1 = 0.980523 loss)
I0423 02:59:13.453176 16565 solver.cpp:244]     Train net output #1: loss = 0.758244 (* 1 = 0.758244 loss)
I0423 02:59:13.453181 16565 solver.cpp:244]     Train net output #2: loss = 0.710274 (* 1 = 0.710274 loss)
I0423 02:59:13.453186 16565 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0423 03:00:53.542461 16565 solver.cpp:228] Iteration 13500, loss = 2.49855
I0423 03:00:53.542613 16565 solver.cpp:244]     Train net output #0: loss = 0.970922 (* 1 = 0.970922 loss)
I0423 03:00:53.542623 16565 solver.cpp:244]     Train net output #1: loss = 0.616632 (* 1 = 0.616632 loss)
I0423 03:00:53.542628 16565 solver.cpp:244]     Train net output #2: loss = 0.910995 (* 1 = 0.910995 loss)
I0423 03:00:53.542634 16565 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0423 03:02:31.752436 16565 solver.cpp:228] Iteration 13600, loss = 2.50171
I0423 03:02:31.752590 16565 solver.cpp:244]     Train net output #0: loss = 0.970687 (* 1 = 0.970687 loss)
I0423 03:02:31.752599 16565 solver.cpp:244]     Train net output #1: loss = 0.635548 (* 1 = 0.635548 loss)
I0423 03:02:31.752604 16565 solver.cpp:244]     Train net output #2: loss = 0.89548 (* 1 = 0.89548 loss)
I0423 03:02:31.752609 16565 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0423 03:04:11.509035 16565 solver.cpp:228] Iteration 13700, loss = 2.41384
I0423 03:04:11.509193 16565 solver.cpp:244]     Train net output #0: loss = 0.951288 (* 1 = 0.951288 loss)
I0423 03:04:11.509201 16565 solver.cpp:244]     Train net output #1: loss = 0.612447 (* 1 = 0.612447 loss)
I0423 03:04:11.509205 16565 solver.cpp:244]     Train net output #2: loss = 0.850105 (* 1 = 0.850105 loss)
I0423 03:04:11.509212 16565 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0423 03:05:50.789288 16565 solver.cpp:228] Iteration 13800, loss = 2.22755
I0423 03:05:50.789487 16565 solver.cpp:244]     Train net output #0: loss = 0.95845 (* 1 = 0.95845 loss)
I0423 03:05:50.789496 16565 solver.cpp:244]     Train net output #1: loss = 0.368576 (* 1 = 0.368576 loss)
I0423 03:05:50.789502 16565 solver.cpp:244]     Train net output #2: loss = 0.900519 (* 1 = 0.900519 loss)
I0423 03:05:50.789507 16565 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0423 03:07:30.116055 16565 solver.cpp:228] Iteration 13900, loss = 2.24036
I0423 03:07:30.116225 16565 solver.cpp:244]     Train net output #0: loss = 0.961996 (* 1 = 0.961996 loss)
I0423 03:07:30.116235 16565 solver.cpp:244]     Train net output #1: loss = 0.618958 (* 1 = 0.618958 loss)
I0423 03:07:30.116238 16565 solver.cpp:244]     Train net output #2: loss = 0.659411 (* 1 = 0.659411 loss)
I0423 03:07:30.116243 16565 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0423 03:09:08.796165 16565 solver.cpp:337] Iteration 14000, Testing net (#0)
I0423 03:09:08.796306 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 03:09:08.796310 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 03:09:08.796315 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 03:09:08.796329 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 03:09:08.796334 16565 net.cpp:693] Ignoring source layer visualize
I0423 03:09:08.796336 16565 net.cpp:693] Ignoring source layer fake
I0423 03:12:42.544800 16565 solver.cpp:404]     Test net output #0: loss = 0.888451 (* 1 = 0.888451 loss)
I0423 03:12:42.544965 16565 solver.cpp:404]     Test net output #1: loss = 0.546264 (* 1 = 0.546264 loss)
I0423 03:12:42.544972 16565 solver.cpp:404]     Test net output #2: loss = 0.805622 (* 1 = 0.805622 loss)
I0423 03:12:43.196610 16565 solver.cpp:228] Iteration 14000, loss = 2.38443
I0423 03:12:43.196655 16565 solver.cpp:244]     Train net output #0: loss = 0.957321 (* 1 = 0.957321 loss)
I0423 03:12:43.196661 16565 solver.cpp:244]     Train net output #1: loss = 0.674873 (* 1 = 0.674873 loss)
I0423 03:12:43.196666 16565 solver.cpp:244]     Train net output #2: loss = 0.752235 (* 1 = 0.752235 loss)
I0423 03:12:43.196671 16565 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0423 03:14:23.006176 16565 solver.cpp:228] Iteration 14100, loss = 1.68867
I0423 03:14:23.006319 16565 solver.cpp:244]     Train net output #0: loss = 0.953172 (* 1 = 0.953172 loss)
I0423 03:14:23.006328 16565 solver.cpp:244]     Train net output #1: loss = 0.212945 (* 1 = 0.212945 loss)
I0423 03:14:23.006333 16565 solver.cpp:244]     Train net output #2: loss = 0.522556 (* 1 = 0.522556 loss)
I0423 03:14:23.006338 16565 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0423 03:16:02.894428 16565 solver.cpp:228] Iteration 14200, loss = 2.40862
I0423 03:16:02.894575 16565 solver.cpp:244]     Train net output #0: loss = 0.941344 (* 1 = 0.941344 loss)
I0423 03:16:02.894583 16565 solver.cpp:244]     Train net output #1: loss = 0.592048 (* 1 = 0.592048 loss)
I0423 03:16:02.894588 16565 solver.cpp:244]     Train net output #2: loss = 0.875223 (* 1 = 0.875223 loss)
I0423 03:16:02.894604 16565 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0423 03:17:41.096531 16565 solver.cpp:228] Iteration 14300, loss = 2.52551
I0423 03:17:41.096738 16565 solver.cpp:244]     Train net output #0: loss = 0.941657 (* 1 = 0.941657 loss)
I0423 03:17:41.096753 16565 solver.cpp:244]     Train net output #1: loss = 0.697359 (* 1 = 0.697359 loss)
I0423 03:17:41.096761 16565 solver.cpp:244]     Train net output #2: loss = 0.886499 (* 1 = 0.886499 loss)
I0423 03:17:41.096776 16565 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0423 03:19:20.940896 16565 solver.cpp:228] Iteration 14400, loss = 2.63539
I0423 03:19:20.941045 16565 solver.cpp:244]     Train net output #0: loss = 0.962054 (* 1 = 0.962054 loss)
I0423 03:19:20.941053 16565 solver.cpp:244]     Train net output #1: loss = 0.787128 (* 1 = 0.787128 loss)
I0423 03:19:20.941058 16565 solver.cpp:244]     Train net output #2: loss = 0.886203 (* 1 = 0.886203 loss)
I0423 03:19:20.941063 16565 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0423 03:21:00.787789 16565 solver.cpp:228] Iteration 14500, loss = 2.10713
I0423 03:21:00.787937 16565 solver.cpp:244]     Train net output #0: loss = 0.972617 (* 1 = 0.972617 loss)
I0423 03:21:00.787946 16565 solver.cpp:244]     Train net output #1: loss = 0.653645 (* 1 = 0.653645 loss)
I0423 03:21:00.787951 16565 solver.cpp:244]     Train net output #2: loss = 0.480871 (* 1 = 0.480871 loss)
I0423 03:21:00.787956 16565 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0423 03:22:38.992733 16565 solver.cpp:228] Iteration 14600, loss = 2.47603
I0423 03:22:38.992888 16565 solver.cpp:244]     Train net output #0: loss = 0.98464 (* 1 = 0.98464 loss)
I0423 03:22:38.992897 16565 solver.cpp:244]     Train net output #1: loss = 0.67557 (* 1 = 0.67557 loss)
I0423 03:22:38.992902 16565 solver.cpp:244]     Train net output #2: loss = 0.815822 (* 1 = 0.815822 loss)
I0423 03:22:38.992907 16565 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0423 03:24:18.794258 16565 solver.cpp:228] Iteration 14700, loss = 2.41242
I0423 03:24:18.794420 16565 solver.cpp:244]     Train net output #0: loss = 0.984031 (* 1 = 0.984031 loss)
I0423 03:24:18.794428 16565 solver.cpp:244]     Train net output #1: loss = 0.670702 (* 1 = 0.670702 loss)
I0423 03:24:18.794433 16565 solver.cpp:244]     Train net output #2: loss = 0.75769 (* 1 = 0.75769 loss)
I0423 03:24:18.794440 16565 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0423 03:25:58.590479 16565 solver.cpp:228] Iteration 14800, loss = 2.49338
I0423 03:25:58.590665 16565 solver.cpp:244]     Train net output #0: loss = 0.981339 (* 1 = 0.981339 loss)
I0423 03:25:58.590674 16565 solver.cpp:244]     Train net output #1: loss = 0.697592 (* 1 = 0.697592 loss)
I0423 03:25:58.590679 16565 solver.cpp:244]     Train net output #2: loss = 0.814448 (* 1 = 0.814448 loss)
I0423 03:25:58.590684 16565 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0423 03:27:38.314275 16565 solver.cpp:228] Iteration 14900, loss = 2.32233
I0423 03:27:38.314445 16565 solver.cpp:244]     Train net output #0: loss = 0.980748 (* 1 = 0.980748 loss)
I0423 03:27:38.314453 16565 solver.cpp:244]     Train net output #1: loss = 0.535442 (* 1 = 0.535442 loss)
I0423 03:27:38.314458 16565 solver.cpp:244]     Train net output #2: loss = 0.806142 (* 1 = 0.806142 loss)
I0423 03:27:38.314465 16565 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0423 03:29:16.597872 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_15000.caffemodel
I0423 03:29:30.962771 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_15000.solverstate
I0423 03:29:31.151281 16565 solver.cpp:337] Iteration 15000, Testing net (#0)
I0423 03:29:31.151322 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 03:29:31.151324 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 03:29:31.151329 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 03:29:31.151343 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 03:29:31.151346 16565 net.cpp:693] Ignoring source layer visualize
I0423 03:29:31.151347 16565 net.cpp:693] Ignoring source layer fake
I0423 03:33:04.413843 16565 solver.cpp:404]     Test net output #0: loss = 0.947061 (* 1 = 0.947061 loss)
I0423 03:33:04.413985 16565 solver.cpp:404]     Test net output #1: loss = 0.594881 (* 1 = 0.594881 loss)
I0423 03:33:04.413992 16565 solver.cpp:404]     Test net output #2: loss = 0.780622 (* 1 = 0.780622 loss)
I0423 03:33:05.068234 16565 solver.cpp:228] Iteration 15000, loss = 2.21026
I0423 03:33:05.068260 16565 solver.cpp:244]     Train net output #0: loss = 0.923582 (* 1 = 0.923582 loss)
I0423 03:33:05.068281 16565 solver.cpp:244]     Train net output #1: loss = 0.396611 (* 1 = 0.396611 loss)
I0423 03:33:05.068285 16565 solver.cpp:244]     Train net output #2: loss = 0.890065 (* 1 = 0.890065 loss)
I0423 03:33:05.068289 16565 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0423 03:34:44.470062 16565 solver.cpp:228] Iteration 15100, loss = 2.30738
I0423 03:34:44.470224 16565 solver.cpp:244]     Train net output #0: loss = 0.968029 (* 1 = 0.968029 loss)
I0423 03:34:44.470232 16565 solver.cpp:244]     Train net output #1: loss = 0.603359 (* 1 = 0.603359 loss)
I0423 03:34:44.470237 16565 solver.cpp:244]     Train net output #2: loss = 0.735996 (* 1 = 0.735996 loss)
I0423 03:34:44.470242 16565 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0423 03:36:22.588358 16565 solver.cpp:228] Iteration 15200, loss = 2.36416
I0423 03:36:22.588515 16565 solver.cpp:244]     Train net output #0: loss = 0.966039 (* 1 = 0.966039 loss)
I0423 03:36:22.588521 16565 solver.cpp:244]     Train net output #1: loss = 0.654617 (* 1 = 0.654617 loss)
I0423 03:36:22.588527 16565 solver.cpp:244]     Train net output #2: loss = 0.743508 (* 1 = 0.743508 loss)
I0423 03:36:22.588532 16565 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0423 03:38:02.191932 16565 solver.cpp:228] Iteration 15300, loss = 2.29252
I0423 03:38:02.192077 16565 solver.cpp:244]     Train net output #0: loss = 0.97558 (* 1 = 0.97558 loss)
I0423 03:38:02.192086 16565 solver.cpp:244]     Train net output #1: loss = 0.558345 (* 1 = 0.558345 loss)
I0423 03:38:02.192091 16565 solver.cpp:244]     Train net output #2: loss = 0.758599 (* 1 = 0.758599 loss)
I0423 03:38:02.192096 16565 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0423 03:39:41.958957 16565 solver.cpp:228] Iteration 15400, loss = 1.19505
I0423 03:39:41.959157 16565 solver.cpp:244]     Train net output #0: loss = 0.975863 (* 1 = 0.975863 loss)
I0423 03:39:41.959166 16565 solver.cpp:244]     Train net output #1: loss = 0.0319521 (* 1 = 0.0319521 loss)
I0423 03:39:41.959170 16565 solver.cpp:244]     Train net output #2: loss = 0.187237 (* 1 = 0.187237 loss)
I0423 03:39:41.959177 16565 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0423 03:41:21.873095 16565 solver.cpp:228] Iteration 15500, loss = 2.32438
I0423 03:41:21.873256 16565 solver.cpp:244]     Train net output #0: loss = 0.939703 (* 1 = 0.939703 loss)
I0423 03:41:21.873263 16565 solver.cpp:244]     Train net output #1: loss = 0.575157 (* 1 = 0.575157 loss)
I0423 03:41:21.873268 16565 solver.cpp:244]     Train net output #2: loss = 0.809519 (* 1 = 0.809519 loss)
I0423 03:41:21.873273 16565 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0423 03:43:01.772083 16565 solver.cpp:228] Iteration 15600, loss = 2.37104
I0423 03:43:01.772248 16565 solver.cpp:244]     Train net output #0: loss = 0.962282 (* 1 = 0.962282 loss)
I0423 03:43:01.772255 16565 solver.cpp:244]     Train net output #1: loss = 0.519639 (* 1 = 0.519639 loss)
I0423 03:43:01.772261 16565 solver.cpp:244]     Train net output #2: loss = 0.889117 (* 1 = 0.889117 loss)
I0423 03:43:01.772265 16565 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0423 03:44:39.978941 16565 solver.cpp:228] Iteration 15700, loss = 2.51776
I0423 03:44:39.979105 16565 solver.cpp:244]     Train net output #0: loss = 0.929513 (* 1 = 0.929513 loss)
I0423 03:44:39.979123 16565 solver.cpp:244]     Train net output #1: loss = 0.688938 (* 1 = 0.688938 loss)
I0423 03:44:39.979128 16565 solver.cpp:244]     Train net output #2: loss = 0.899304 (* 1 = 0.899304 loss)
I0423 03:44:39.979133 16565 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0423 03:46:19.805470 16565 solver.cpp:228] Iteration 15800, loss = 2.33439
I0423 03:46:19.805629 16565 solver.cpp:244]     Train net output #0: loss = 0.96794 (* 1 = 0.96794 loss)
I0423 03:46:19.805636 16565 solver.cpp:244]     Train net output #1: loss = 0.616711 (* 1 = 0.616711 loss)
I0423 03:46:19.805641 16565 solver.cpp:244]     Train net output #2: loss = 0.749738 (* 1 = 0.749738 loss)
I0423 03:46:19.805645 16565 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0423 03:48:00.250593 16565 solver.cpp:228] Iteration 15900, loss = 2.52041
I0423 03:48:00.251096 16565 solver.cpp:244]     Train net output #0: loss = 0.992352 (* 1 = 0.992352 loss)
I0423 03:48:00.251104 16565 solver.cpp:244]     Train net output #1: loss = 0.799546 (* 1 = 0.799546 loss)
I0423 03:48:00.251109 16565 solver.cpp:244]     Train net output #2: loss = 0.728508 (* 1 = 0.728508 loss)
I0423 03:48:00.251114 16565 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0423 03:49:39.036490 16565 solver.cpp:337] Iteration 16000, Testing net (#0)
I0423 03:49:39.036669 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 03:49:39.036674 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 03:49:39.036679 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 03:49:39.036695 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 03:49:39.036700 16565 net.cpp:693] Ignoring source layer visualize
I0423 03:49:39.036701 16565 net.cpp:693] Ignoring source layer fake
I0423 03:53:13.277897 16565 solver.cpp:404]     Test net output #0: loss = 0.944688 (* 1 = 0.944688 loss)
I0423 03:53:13.278034 16565 solver.cpp:404]     Test net output #1: loss = 0.606827 (* 1 = 0.606827 loss)
I0423 03:53:13.278053 16565 solver.cpp:404]     Test net output #2: loss = 0.812451 (* 1 = 0.812451 loss)
I0423 03:53:13.933648 16565 solver.cpp:228] Iteration 16000, loss = 2.43551
I0423 03:53:13.933689 16565 solver.cpp:244]     Train net output #0: loss = 0.972984 (* 1 = 0.972984 loss)
I0423 03:53:13.933696 16565 solver.cpp:244]     Train net output #1: loss = 0.543985 (* 1 = 0.543985 loss)
I0423 03:53:13.933699 16565 solver.cpp:244]     Train net output #2: loss = 0.918545 (* 1 = 0.918545 loss)
I0423 03:53:13.933703 16565 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0423 03:54:52.124589 16565 solver.cpp:228] Iteration 16100, loss = 2.26773
I0423 03:54:52.126201 16565 solver.cpp:244]     Train net output #0: loss = 0.975655 (* 1 = 0.975655 loss)
I0423 03:54:52.126209 16565 solver.cpp:244]     Train net output #1: loss = 0.54473 (* 1 = 0.54473 loss)
I0423 03:54:52.126212 16565 solver.cpp:244]     Train net output #2: loss = 0.747349 (* 1 = 0.747349 loss)
I0423 03:54:52.126219 16565 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0423 03:56:32.025048 16565 solver.cpp:228] Iteration 16200, loss = 2.36401
I0423 03:56:32.025198 16565 solver.cpp:244]     Train net output #0: loss = 0.914535 (* 1 = 0.914535 loss)
I0423 03:56:32.025207 16565 solver.cpp:244]     Train net output #1: loss = 0.598019 (* 1 = 0.598019 loss)
I0423 03:56:32.025213 16565 solver.cpp:244]     Train net output #2: loss = 0.851457 (* 1 = 0.851457 loss)
I0423 03:56:32.025218 16565 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0423 03:58:11.330757 16565 solver.cpp:228] Iteration 16300, loss = 2.24188
I0423 03:58:11.330915 16565 solver.cpp:244]     Train net output #0: loss = 0.955984 (* 1 = 0.955984 loss)
I0423 03:58:11.330924 16565 solver.cpp:244]     Train net output #1: loss = 0.378979 (* 1 = 0.378979 loss)
I0423 03:58:11.330929 16565 solver.cpp:244]     Train net output #2: loss = 0.906914 (* 1 = 0.906914 loss)
I0423 03:58:11.330934 16565 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0423 03:59:50.665374 16565 solver.cpp:228] Iteration 16400, loss = 2.66518
I0423 03:59:50.665519 16565 solver.cpp:244]     Train net output #0: loss = 0.939403 (* 1 = 0.939403 loss)
I0423 03:59:50.665526 16565 solver.cpp:244]     Train net output #1: loss = 0.760334 (* 1 = 0.760334 loss)
I0423 03:59:50.665531 16565 solver.cpp:244]     Train net output #2: loss = 0.96544 (* 1 = 0.96544 loss)
I0423 03:59:50.665536 16565 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0423 04:01:30.372709 16565 solver.cpp:228] Iteration 16500, loss = 2.15758
I0423 04:01:30.372853 16565 solver.cpp:244]     Train net output #0: loss = 0.951646 (* 1 = 0.951646 loss)
I0423 04:01:30.372861 16565 solver.cpp:244]     Train net output #1: loss = 0.63168 (* 1 = 0.63168 loss)
I0423 04:01:30.372866 16565 solver.cpp:244]     Train net output #2: loss = 0.574257 (* 1 = 0.574257 loss)
I0423 04:01:30.372872 16565 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0423 04:03:10.144060 16565 solver.cpp:228] Iteration 16600, loss = 1.64477
I0423 04:03:10.144234 16565 solver.cpp:244]     Train net output #0: loss = 0.970797 (* 1 = 0.970797 loss)
I0423 04:03:10.144243 16565 solver.cpp:244]     Train net output #1: loss = 0.136525 (* 1 = 0.136525 loss)
I0423 04:03:10.144248 16565 solver.cpp:244]     Train net output #2: loss = 0.537452 (* 1 = 0.537452 loss)
I0423 04:03:10.144253 16565 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0423 04:04:50.439002 16565 solver.cpp:228] Iteration 16700, loss = 2.41097
I0423 04:04:50.439165 16565 solver.cpp:244]     Train net output #0: loss = 0.959343 (* 1 = 0.959343 loss)
I0423 04:04:50.439173 16565 solver.cpp:244]     Train net output #1: loss = 0.661207 (* 1 = 0.661207 loss)
I0423 04:04:50.439178 16565 solver.cpp:244]     Train net output #2: loss = 0.790424 (* 1 = 0.790424 loss)
I0423 04:04:50.439184 16565 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0423 04:06:28.635538 16565 solver.cpp:228] Iteration 16800, loss = 2.58137
I0423 04:06:28.635701 16565 solver.cpp:244]     Train net output #0: loss = 0.941274 (* 1 = 0.941274 loss)
I0423 04:06:28.635710 16565 solver.cpp:244]     Train net output #1: loss = 0.717609 (* 1 = 0.717609 loss)
I0423 04:06:28.635715 16565 solver.cpp:244]     Train net output #2: loss = 0.922483 (* 1 = 0.922483 loss)
I0423 04:06:28.635720 16565 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0423 04:08:08.802572 16565 solver.cpp:228] Iteration 16900, loss = 2.59199
I0423 04:08:08.802713 16565 solver.cpp:244]     Train net output #0: loss = 0.949513 (* 1 = 0.949513 loss)
I0423 04:08:08.802721 16565 solver.cpp:244]     Train net output #1: loss = 0.770526 (* 1 = 0.770526 loss)
I0423 04:08:08.802726 16565 solver.cpp:244]     Train net output #2: loss = 0.871948 (* 1 = 0.871948 loss)
I0423 04:08:08.802731 16565 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0423 04:09:47.682703 16565 solver.cpp:337] Iteration 17000, Testing net (#0)
I0423 04:09:47.682869 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 04:09:47.682874 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 04:09:47.682879 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 04:09:47.682895 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 04:09:47.682898 16565 net.cpp:693] Ignoring source layer visualize
I0423 04:09:47.682900 16565 net.cpp:693] Ignoring source layer fake
I0423 04:13:21.487427 16565 solver.cpp:404]     Test net output #0: loss = 0.952001 (* 1 = 0.952001 loss)
I0423 04:13:21.487576 16565 solver.cpp:404]     Test net output #1: loss = 0.636434 (* 1 = 0.636434 loss)
I0423 04:13:21.487583 16565 solver.cpp:404]     Test net output #2: loss = 0.810234 (* 1 = 0.810234 loss)
I0423 04:13:22.141383 16565 solver.cpp:228] Iteration 17000, loss = 2.23444
I0423 04:13:22.141428 16565 solver.cpp:244]     Train net output #0: loss = 0.972815 (* 1 = 0.972815 loss)
I0423 04:13:22.141453 16565 solver.cpp:244]     Train net output #1: loss = 0.589788 (* 1 = 0.589788 loss)
I0423 04:13:22.141458 16565 solver.cpp:244]     Train net output #2: loss = 0.671833 (* 1 = 0.671833 loss)
I0423 04:13:22.141463 16565 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0423 04:15:00.405841 16565 solver.cpp:228] Iteration 17100, loss = 2.42139
I0423 04:15:00.407958 16565 solver.cpp:244]     Train net output #0: loss = 0.977574 (* 1 = 0.977574 loss)
I0423 04:15:00.407966 16565 solver.cpp:244]     Train net output #1: loss = 0.617411 (* 1 = 0.617411 loss)
I0423 04:15:00.407974 16565 solver.cpp:244]     Train net output #2: loss = 0.826404 (* 1 = 0.826404 loss)
I0423 04:15:00.407981 16565 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0423 04:16:40.332406 16565 solver.cpp:228] Iteration 17200, loss = 2.50928
I0423 04:16:40.332567 16565 solver.cpp:244]     Train net output #0: loss = 0.983986 (* 1 = 0.983986 loss)
I0423 04:16:40.332576 16565 solver.cpp:244]     Train net output #1: loss = 0.766982 (* 1 = 0.766982 loss)
I0423 04:16:40.332581 16565 solver.cpp:244]     Train net output #2: loss = 0.758311 (* 1 = 0.758311 loss)
I0423 04:16:40.332587 16565 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0423 04:18:20.553040 16565 solver.cpp:228] Iteration 17300, loss = 2.40254
I0423 04:18:20.553198 16565 solver.cpp:244]     Train net output #0: loss = 0.98103 (* 1 = 0.98103 loss)
I0423 04:18:20.553207 16565 solver.cpp:244]     Train net output #1: loss = 0.627536 (* 1 = 0.627536 loss)
I0423 04:18:20.553212 16565 solver.cpp:244]     Train net output #2: loss = 0.793976 (* 1 = 0.793976 loss)
I0423 04:18:20.553218 16565 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0423 04:20:00.734724 16565 solver.cpp:228] Iteration 17400, loss = 2.48511
I0423 04:20:00.734880 16565 solver.cpp:244]     Train net output #0: loss = 0.982291 (* 1 = 0.982291 loss)
I0423 04:20:00.734889 16565 solver.cpp:244]     Train net output #1: loss = 0.627021 (* 1 = 0.627021 loss)
I0423 04:20:00.734894 16565 solver.cpp:244]     Train net output #2: loss = 0.875801 (* 1 = 0.875801 loss)
I0423 04:20:00.734899 16565 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0423 04:21:40.147899 16565 solver.cpp:228] Iteration 17500, loss = 2.28547
I0423 04:21:40.152514 16565 solver.cpp:244]     Train net output #0: loss = 0.947006 (* 1 = 0.947006 loss)
I0423 04:21:40.152523 16565 solver.cpp:244]     Train net output #1: loss = 0.43819 (* 1 = 0.43819 loss)
I0423 04:21:40.152528 16565 solver.cpp:244]     Train net output #2: loss = 0.900274 (* 1 = 0.900274 loss)
I0423 04:21:40.152532 16565 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0423 04:23:19.575201 16565 solver.cpp:228] Iteration 17600, loss = 2.69111
I0423 04:23:19.575366 16565 solver.cpp:244]     Train net output #0: loss = 0.957652 (* 1 = 0.957652 loss)
I0423 04:23:19.575374 16565 solver.cpp:244]     Train net output #1: loss = 0.771798 (* 1 = 0.771798 loss)
I0423 04:23:19.575381 16565 solver.cpp:244]     Train net output #2: loss = 0.961665 (* 1 = 0.961665 loss)
I0423 04:23:19.575386 16565 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0423 04:24:59.219911 16565 solver.cpp:228] Iteration 17700, loss = 2.48566
I0423 04:24:59.220095 16565 solver.cpp:244]     Train net output #0: loss = 0.965744 (* 1 = 0.965744 loss)
I0423 04:24:59.220104 16565 solver.cpp:244]     Train net output #1: loss = 0.755075 (* 1 = 0.755075 loss)
I0423 04:24:59.220109 16565 solver.cpp:244]     Train net output #2: loss = 0.764839 (* 1 = 0.764839 loss)
I0423 04:24:59.220115 16565 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0423 04:26:37.429325 16565 solver.cpp:228] Iteration 17800, loss = 2.39385
I0423 04:26:37.429677 16565 solver.cpp:244]     Train net output #0: loss = 0.953999 (* 1 = 0.953999 loss)
I0423 04:26:37.429683 16565 solver.cpp:244]     Train net output #1: loss = 0.679338 (* 1 = 0.679338 loss)
I0423 04:26:37.429688 16565 solver.cpp:244]     Train net output #2: loss = 0.760515 (* 1 = 0.760515 loss)
I0423 04:26:37.429693 16565 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0423 04:28:17.332962 16565 solver.cpp:228] Iteration 17900, loss = 1.59077
I0423 04:28:17.333119 16565 solver.cpp:244]     Train net output #0: loss = 0.966862 (* 1 = 0.966862 loss)
I0423 04:28:17.333128 16565 solver.cpp:244]     Train net output #1: loss = 0.0875457 (* 1 = 0.0875457 loss)
I0423 04:28:17.333132 16565 solver.cpp:244]     Train net output #2: loss = 0.536364 (* 1 = 0.536364 loss)
I0423 04:28:17.333138 16565 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0423 04:29:56.800659 16565 solver.cpp:337] Iteration 18000, Testing net (#0)
I0423 04:29:56.800812 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 04:29:56.800817 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 04:29:56.800822 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 04:29:56.800838 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 04:29:56.800842 16565 net.cpp:693] Ignoring source layer visualize
I0423 04:29:56.800843 16565 net.cpp:693] Ignoring source layer fake
I0423 04:33:31.507206 16565 solver.cpp:404]     Test net output #0: loss = 0.944105 (* 1 = 0.944105 loss)
I0423 04:33:31.507360 16565 solver.cpp:404]     Test net output #1: loss = 0.567764 (* 1 = 0.567764 loss)
I0423 04:33:31.507366 16565 solver.cpp:404]     Test net output #2: loss = 0.765126 (* 1 = 0.765126 loss)
I0423 04:33:32.158996 16565 solver.cpp:228] Iteration 18000, loss = 2.33083
I0423 04:33:32.159044 16565 solver.cpp:244]     Train net output #0: loss = 0.950934 (* 1 = 0.950934 loss)
I0423 04:33:32.159050 16565 solver.cpp:244]     Train net output #1: loss = 0.698896 (* 1 = 0.698896 loss)
I0423 04:33:32.159054 16565 solver.cpp:244]     Train net output #2: loss = 0.681 (* 1 = 0.681 loss)
I0423 04:33:32.159060 16565 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0423 04:35:12.554687 16565 solver.cpp:228] Iteration 18100, loss = 2.61152
I0423 04:35:12.554842 16565 solver.cpp:244]     Train net output #0: loss = 0.966598 (* 1 = 0.966598 loss)
I0423 04:35:12.554849 16565 solver.cpp:244]     Train net output #1: loss = 0.727473 (* 1 = 0.727473 loss)
I0423 04:35:12.554855 16565 solver.cpp:244]     Train net output #2: loss = 0.917454 (* 1 = 0.917454 loss)
I0423 04:35:12.554860 16565 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0423 04:36:50.795971 16565 solver.cpp:228] Iteration 18200, loss = 2.61242
I0423 04:36:50.796121 16565 solver.cpp:244]     Train net output #0: loss = 0.953122 (* 1 = 0.953122 loss)
I0423 04:36:50.796129 16565 solver.cpp:244]     Train net output #1: loss = 0.782992 (* 1 = 0.782992 loss)
I0423 04:36:50.796135 16565 solver.cpp:244]     Train net output #2: loss = 0.876309 (* 1 = 0.876309 loss)
I0423 04:36:50.796140 16565 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0423 04:38:30.827697 16565 solver.cpp:228] Iteration 18300, loss = 2.65824
I0423 04:38:30.827879 16565 solver.cpp:244]     Train net output #0: loss = 0.978395 (* 1 = 0.978395 loss)
I0423 04:38:30.827889 16565 solver.cpp:244]     Train net output #1: loss = 0.802156 (* 1 = 0.802156 loss)
I0423 04:38:30.827894 16565 solver.cpp:244]     Train net output #2: loss = 0.877686 (* 1 = 0.877686 loss)
I0423 04:38:30.827899 16565 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0423 04:40:10.758659 16565 solver.cpp:228] Iteration 18400, loss = 2.54613
I0423 04:40:10.758831 16565 solver.cpp:244]     Train net output #0: loss = 0.985954 (* 1 = 0.985954 loss)
I0423 04:40:10.758838 16565 solver.cpp:244]     Train net output #1: loss = 0.810007 (* 1 = 0.810007 loss)
I0423 04:40:10.758843 16565 solver.cpp:244]     Train net output #2: loss = 0.750172 (* 1 = 0.750172 loss)
I0423 04:40:10.758848 16565 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0423 04:41:50.664402 16565 solver.cpp:228] Iteration 18500, loss = 2.64509
I0423 04:41:50.664577 16565 solver.cpp:244]     Train net output #0: loss = 0.98151 (* 1 = 0.98151 loss)
I0423 04:41:50.664584 16565 solver.cpp:244]     Train net output #1: loss = 0.720918 (* 1 = 0.720918 loss)
I0423 04:41:50.664589 16565 solver.cpp:244]     Train net output #2: loss = 0.942659 (* 1 = 0.942659 loss)
I0423 04:41:50.664595 16565 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0423 04:43:28.840091 16565 solver.cpp:228] Iteration 18600, loss = 2.42137
I0423 04:43:28.840258 16565 solver.cpp:244]     Train net output #0: loss = 0.983952 (* 1 = 0.983952 loss)
I0423 04:43:28.840265 16565 solver.cpp:244]     Train net output #1: loss = 0.704974 (* 1 = 0.704974 loss)
I0423 04:43:28.840271 16565 solver.cpp:244]     Train net output #2: loss = 0.732443 (* 1 = 0.732443 loss)
I0423 04:43:28.840276 16565 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0423 04:45:09.547646 16565 solver.cpp:228] Iteration 18700, loss = 2.17314
I0423 04:45:09.550532 16565 solver.cpp:244]     Train net output #0: loss = 0.973698 (* 1 = 0.973698 loss)
I0423 04:45:09.550541 16565 solver.cpp:244]     Train net output #1: loss = 0.709813 (* 1 = 0.709813 loss)
I0423 04:45:09.550545 16565 solver.cpp:244]     Train net output #2: loss = 0.489627 (* 1 = 0.489627 loss)
I0423 04:45:09.550550 16565 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0423 04:46:48.815306 16565 solver.cpp:228] Iteration 18800, loss = 2.45835
I0423 04:46:48.815466 16565 solver.cpp:244]     Train net output #0: loss = 0.943655 (* 1 = 0.943655 loss)
I0423 04:46:48.815474 16565 solver.cpp:244]     Train net output #1: loss = 0.619285 (* 1 = 0.619285 loss)
I0423 04:46:48.815479 16565 solver.cpp:244]     Train net output #2: loss = 0.895406 (* 1 = 0.895406 loss)
I0423 04:46:48.815484 16565 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0423 04:48:28.068599 16565 solver.cpp:228] Iteration 18900, loss = 2.71476
I0423 04:48:28.068755 16565 solver.cpp:244]     Train net output #0: loss = 0.939159 (* 1 = 0.939159 loss)
I0423 04:48:28.068763 16565 solver.cpp:244]     Train net output #1: loss = 0.823825 (* 1 = 0.823825 loss)
I0423 04:48:28.068768 16565 solver.cpp:244]     Train net output #2: loss = 0.951772 (* 1 = 0.951772 loss)
I0423 04:48:28.068774 16565 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0423 04:50:06.606437 16565 solver.cpp:337] Iteration 19000, Testing net (#0)
I0423 04:50:06.606580 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 04:50:06.606585 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 04:50:06.606590 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 04:50:06.606604 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 04:50:06.606608 16565 net.cpp:693] Ignoring source layer visualize
I0423 04:50:06.606611 16565 net.cpp:693] Ignoring source layer fake
I0423 04:53:40.825929 16565 solver.cpp:404]     Test net output #0: loss = 0.940889 (* 1 = 0.940889 loss)
I0423 04:53:40.826102 16565 solver.cpp:404]     Test net output #1: loss = 0.632417 (* 1 = 0.632417 loss)
I0423 04:53:40.826109 16565 solver.cpp:404]     Test net output #2: loss = 0.801871 (* 1 = 0.801871 loss)
I0423 04:53:41.481573 16565 solver.cpp:228] Iteration 19000, loss = 2.68589
I0423 04:53:41.481617 16565 solver.cpp:244]     Train net output #0: loss = 0.967047 (* 1 = 0.967047 loss)
I0423 04:53:41.481623 16565 solver.cpp:244]     Train net output #1: loss = 0.765275 (* 1 = 0.765275 loss)
I0423 04:53:41.481627 16565 solver.cpp:244]     Train net output #2: loss = 0.95357 (* 1 = 0.95357 loss)
I0423 04:53:41.481632 16565 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0423 04:55:21.427644 16565 solver.cpp:228] Iteration 19100, loss = 1.56726
I0423 04:55:21.427845 16565 solver.cpp:244]     Train net output #0: loss = 0.969864 (* 1 = 0.969864 loss)
I0423 04:55:21.427852 16565 solver.cpp:244]     Train net output #1: loss = 0.217532 (* 1 = 0.217532 loss)
I0423 04:55:21.427857 16565 solver.cpp:244]     Train net output #2: loss = 0.379866 (* 1 = 0.379866 loss)
I0423 04:55:21.427863 16565 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0423 04:57:01.647016 16565 solver.cpp:228] Iteration 19200, loss = 2.27904
I0423 04:57:01.647162 16565 solver.cpp:244]     Train net output #0: loss = 0.938752 (* 1 = 0.938752 loss)
I0423 04:57:01.647171 16565 solver.cpp:244]     Train net output #1: loss = 0.521577 (* 1 = 0.521577 loss)
I0423 04:57:01.647176 16565 solver.cpp:244]     Train net output #2: loss = 0.81871 (* 1 = 0.81871 loss)
I0423 04:57:01.647181 16565 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0423 04:58:39.849581 16565 solver.cpp:228] Iteration 19300, loss = 2.52693
I0423 04:58:39.849750 16565 solver.cpp:244]     Train net output #0: loss = 0.933312 (* 1 = 0.933312 loss)
I0423 04:58:39.849758 16565 solver.cpp:244]     Train net output #1: loss = 0.710008 (* 1 = 0.710008 loss)
I0423 04:58:39.849762 16565 solver.cpp:244]     Train net output #2: loss = 0.883606 (* 1 = 0.883606 loss)
I0423 04:58:39.849767 16565 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0423 05:00:20.327258 16565 solver.cpp:228] Iteration 19400, loss = 2.64997
I0423 05:00:20.327428 16565 solver.cpp:244]     Train net output #0: loss = 0.964414 (* 1 = 0.964414 loss)
I0423 05:00:20.327436 16565 solver.cpp:244]     Train net output #1: loss = 0.769929 (* 1 = 0.769929 loss)
I0423 05:00:20.327441 16565 solver.cpp:244]     Train net output #2: loss = 0.915631 (* 1 = 0.915631 loss)
I0423 05:00:20.327446 16565 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0423 05:02:00.797988 16565 solver.cpp:228] Iteration 19500, loss = 2.56811
I0423 05:02:00.798149 16565 solver.cpp:244]     Train net output #0: loss = 0.975759 (* 1 = 0.975759 loss)
I0423 05:02:00.798157 16565 solver.cpp:244]     Train net output #1: loss = 0.696648 (* 1 = 0.696648 loss)
I0423 05:02:00.798162 16565 solver.cpp:244]     Train net output #2: loss = 0.895704 (* 1 = 0.895704 loss)
I0423 05:02:00.798168 16565 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0423 05:03:39.021085 16565 solver.cpp:228] Iteration 19600, loss = 2.5598
I0423 05:03:39.021232 16565 solver.cpp:244]     Train net output #0: loss = 0.97813 (* 1 = 0.97813 loss)
I0423 05:03:39.021240 16565 solver.cpp:244]     Train net output #1: loss = 0.775628 (* 1 = 0.775628 loss)
I0423 05:03:39.021246 16565 solver.cpp:244]     Train net output #2: loss = 0.806045 (* 1 = 0.806045 loss)
I0423 05:03:39.021250 16565 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0423 05:05:18.805174 16565 solver.cpp:228] Iteration 19700, loss = 2.60886
I0423 05:05:18.805305 16565 solver.cpp:244]     Train net output #0: loss = 0.990129 (* 1 = 0.990129 loss)
I0423 05:05:18.805313 16565 solver.cpp:244]     Train net output #1: loss = 0.844818 (* 1 = 0.844818 loss)
I0423 05:05:18.805318 16565 solver.cpp:244]     Train net output #2: loss = 0.773914 (* 1 = 0.773914 loss)
I0423 05:05:18.805323 16565 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0423 05:06:58.568994 16565 solver.cpp:228] Iteration 19800, loss = 2.3138
I0423 05:06:58.570660 16565 solver.cpp:244]     Train net output #0: loss = 0.982204 (* 1 = 0.982204 loss)
I0423 05:06:58.570667 16565 solver.cpp:244]     Train net output #1: loss = 0.486384 (* 1 = 0.486384 loss)
I0423 05:06:58.570672 16565 solver.cpp:244]     Train net output #2: loss = 0.84521 (* 1 = 0.84521 loss)
I0423 05:06:58.570677 16565 sgd_solver.cpp:106] Iteration 19800, lr = 0.0001
I0423 05:08:38.365272 16565 solver.cpp:228] Iteration 19900, loss = 2.55526
I0423 05:08:38.365504 16565 solver.cpp:244]     Train net output #0: loss = 0.978956 (* 1 = 0.978956 loss)
I0423 05:08:38.365512 16565 solver.cpp:244]     Train net output #1: loss = 0.648015 (* 1 = 0.648015 loss)
I0423 05:08:38.365517 16565 solver.cpp:244]     Train net output #2: loss = 0.928287 (* 1 = 0.928287 loss)
I0423 05:08:38.365523 16565 sgd_solver.cpp:106] Iteration 19900, lr = 0.0001
I0423 05:10:16.711725 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_20000.caffemodel
I0423 05:10:28.065593 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_20000.solverstate
I0423 05:10:28.252635 16565 solver.cpp:337] Iteration 20000, Testing net (#0)
I0423 05:10:28.252679 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 05:10:28.252682 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 05:10:28.252686 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 05:10:28.252701 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 05:10:28.252704 16565 net.cpp:693] Ignoring source layer visualize
I0423 05:10:28.252707 16565 net.cpp:693] Ignoring source layer fake
I0423 05:14:01.389647 16565 solver.cpp:404]     Test net output #0: loss = 0.954602 (* 1 = 0.954602 loss)
I0423 05:14:01.389789 16565 solver.cpp:404]     Test net output #1: loss = 0.632507 (* 1 = 0.632507 loss)
I0423 05:14:01.389797 16565 solver.cpp:404]     Test net output #2: loss = 0.783728 (* 1 = 0.783728 loss)
I0423 05:14:02.041918 16565 solver.cpp:228] Iteration 20000, loss = 2.35634
I0423 05:14:02.041959 16565 solver.cpp:244]     Train net output #0: loss = 0.9517 (* 1 = 0.9517 loss)
I0423 05:14:02.041963 16565 solver.cpp:244]     Train net output #1: loss = 0.522823 (* 1 = 0.522823 loss)
I0423 05:14:02.041968 16565 solver.cpp:244]     Train net output #2: loss = 0.881816 (* 1 = 0.881816 loss)
I0423 05:14:02.041972 16565 sgd_solver.cpp:106] Iteration 20000, lr = 3e-05
I0423 05:15:41.689713 16565 solver.cpp:228] Iteration 20100, loss = 2.32154
I0423 05:15:41.689877 16565 solver.cpp:244]     Train net output #0: loss = 0.957064 (* 1 = 0.957064 loss)
I0423 05:15:41.689884 16565 solver.cpp:244]     Train net output #1: loss = 0.666948 (* 1 = 0.666948 loss)
I0423 05:15:41.689889 16565 solver.cpp:244]     Train net output #2: loss = 0.697524 (* 1 = 0.697524 loss)
I0423 05:15:41.689894 16565 sgd_solver.cpp:106] Iteration 20100, lr = 3e-05
I0423 05:17:21.375761 16565 solver.cpp:228] Iteration 20200, loss = 2.24694
I0423 05:17:21.375907 16565 solver.cpp:244]     Train net output #0: loss = 0.974709 (* 1 = 0.974709 loss)
I0423 05:17:21.375916 16565 solver.cpp:244]     Train net output #1: loss = 0.744471 (* 1 = 0.744471 loss)
I0423 05:17:21.375919 16565 solver.cpp:244]     Train net output #2: loss = 0.527756 (* 1 = 0.527756 loss)
I0423 05:17:21.375926 16565 sgd_solver.cpp:106] Iteration 20200, lr = 3e-05
I0423 05:18:59.467430 16565 solver.cpp:228] Iteration 20300, loss = 2.48584
I0423 05:18:59.467574 16565 solver.cpp:244]     Train net output #0: loss = 0.937764 (* 1 = 0.937764 loss)
I0423 05:18:59.467582 16565 solver.cpp:244]     Train net output #1: loss = 0.768569 (* 1 = 0.768569 loss)
I0423 05:18:59.467597 16565 solver.cpp:244]     Train net output #2: loss = 0.779511 (* 1 = 0.779511 loss)
I0423 05:18:59.467602 16565 sgd_solver.cpp:106] Iteration 20300, lr = 3e-05
I0423 05:20:39.223034 16565 solver.cpp:228] Iteration 20400, loss = 1.81373
I0423 05:20:39.223181 16565 solver.cpp:244]     Train net output #0: loss = 0.962084 (* 1 = 0.962084 loss)
I0423 05:20:39.223189 16565 solver.cpp:244]     Train net output #1: loss = 0.271035 (* 1 = 0.271035 loss)
I0423 05:20:39.223196 16565 solver.cpp:244]     Train net output #2: loss = 0.58061 (* 1 = 0.58061 loss)
I0423 05:20:39.223201 16565 sgd_solver.cpp:106] Iteration 20400, lr = 3e-05
I0423 05:22:19.167316 16565 solver.cpp:228] Iteration 20500, loss = 2.36104
I0423 05:22:19.167479 16565 solver.cpp:244]     Train net output #0: loss = 0.945436 (* 1 = 0.945436 loss)
I0423 05:22:19.167487 16565 solver.cpp:244]     Train net output #1: loss = 0.722835 (* 1 = 0.722835 loss)
I0423 05:22:19.167492 16565 solver.cpp:244]     Train net output #2: loss = 0.692772 (* 1 = 0.692772 loss)
I0423 05:22:19.167497 16565 sgd_solver.cpp:106] Iteration 20500, lr = 3e-05
I0423 05:23:59.042842 16565 solver.cpp:228] Iteration 20600, loss = 2.69361
I0423 05:23:59.042987 16565 solver.cpp:244]     Train net output #0: loss = 0.966826 (* 1 = 0.966826 loss)
I0423 05:23:59.042995 16565 solver.cpp:244]     Train net output #1: loss = 0.795892 (* 1 = 0.795892 loss)
I0423 05:23:59.043000 16565 solver.cpp:244]     Train net output #2: loss = 0.930889 (* 1 = 0.930889 loss)
I0423 05:23:59.043005 16565 sgd_solver.cpp:106] Iteration 20600, lr = 3e-05
I0423 05:25:37.168540 16565 solver.cpp:228] Iteration 20700, loss = 2.6444
I0423 05:25:37.168684 16565 solver.cpp:244]     Train net output #0: loss = 0.964812 (* 1 = 0.964812 loss)
I0423 05:25:37.168691 16565 solver.cpp:244]     Train net output #1: loss = 0.760489 (* 1 = 0.760489 loss)
I0423 05:25:37.168696 16565 solver.cpp:244]     Train net output #2: loss = 0.919095 (* 1 = 0.919095 loss)
I0423 05:25:37.168702 16565 sgd_solver.cpp:106] Iteration 20700, lr = 3e-05
I0423 05:27:16.986053 16565 solver.cpp:228] Iteration 20800, loss = 2.62276
I0423 05:27:16.987434 16565 solver.cpp:244]     Train net output #0: loss = 0.987021 (* 1 = 0.987021 loss)
I0423 05:27:16.987457 16565 solver.cpp:244]     Train net output #1: loss = 0.840445 (* 1 = 0.840445 loss)
I0423 05:27:16.987463 16565 solver.cpp:244]     Train net output #2: loss = 0.79529 (* 1 = 0.79529 loss)
I0423 05:27:16.987468 16565 sgd_solver.cpp:106] Iteration 20800, lr = 3e-05
I0423 05:28:56.767848 16565 solver.cpp:228] Iteration 20900, loss = 2.60015
I0423 05:28:56.767998 16565 solver.cpp:244]     Train net output #0: loss = 0.985211 (* 1 = 0.985211 loss)
I0423 05:28:56.768007 16565 solver.cpp:244]     Train net output #1: loss = 0.852952 (* 1 = 0.852952 loss)
I0423 05:28:56.768013 16565 solver.cpp:244]     Train net output #2: loss = 0.761982 (* 1 = 0.761982 loss)
I0423 05:28:56.768016 16565 sgd_solver.cpp:106] Iteration 20900, lr = 3e-05
I0423 05:30:35.530838 16565 solver.cpp:337] Iteration 21000, Testing net (#0)
I0423 05:30:35.531038 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 05:30:35.531044 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 05:30:35.531047 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 05:30:35.531062 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 05:30:35.531066 16565 net.cpp:693] Ignoring source layer visualize
I0423 05:30:35.531069 16565 net.cpp:693] Ignoring source layer fake
I0423 05:34:09.218307 16565 solver.cpp:404]     Test net output #0: loss = 0.956609 (* 1 = 0.956609 loss)
I0423 05:34:09.218441 16565 solver.cpp:404]     Test net output #1: loss = 0.68544 (* 1 = 0.68544 loss)
I0423 05:34:09.218449 16565 solver.cpp:404]     Test net output #2: loss = 0.814994 (* 1 = 0.814994 loss)
I0423 05:34:09.873345 16565 solver.cpp:228] Iteration 21000, loss = 2.25666
I0423 05:34:09.873371 16565 solver.cpp:244]     Train net output #0: loss = 0.990588 (* 1 = 0.990588 loss)
I0423 05:34:09.873392 16565 solver.cpp:244]     Train net output #1: loss = 0.554451 (* 1 = 0.554451 loss)
I0423 05:34:09.873397 16565 solver.cpp:244]     Train net output #2: loss = 0.711619 (* 1 = 0.711619 loss)
I0423 05:34:09.873402 16565 sgd_solver.cpp:106] Iteration 21000, lr = 3e-05
I0423 05:35:48.024051 16565 solver.cpp:228] Iteration 21100, loss = 2.33257
I0423 05:35:48.024188 16565 solver.cpp:244]     Train net output #0: loss = 0.98065 (* 1 = 0.98065 loss)
I0423 05:35:48.024195 16565 solver.cpp:244]     Train net output #1: loss = 0.548372 (* 1 = 0.548372 loss)
I0423 05:35:48.024200 16565 solver.cpp:244]     Train net output #2: loss = 0.803543 (* 1 = 0.803543 loss)
I0423 05:35:48.024205 16565 sgd_solver.cpp:106] Iteration 21100, lr = 3e-05
I0423 05:37:28.031102 16565 solver.cpp:228] Iteration 21200, loss = 2.33265
I0423 05:37:28.031256 16565 solver.cpp:244]     Train net output #0: loss = 0.990455 (* 1 = 0.990455 loss)
I0423 05:37:28.031265 16565 solver.cpp:244]     Train net output #1: loss = 0.791134 (* 1 = 0.791134 loss)
I0423 05:37:28.031270 16565 solver.cpp:244]     Train net output #2: loss = 0.55106 (* 1 = 0.55106 loss)
I0423 05:37:28.031275 16565 sgd_solver.cpp:106] Iteration 21200, lr = 3e-05
I0423 05:39:07.611533 16565 solver.cpp:228] Iteration 21300, loss = 2.219
I0423 05:39:07.611757 16565 solver.cpp:244]     Train net output #0: loss = 0.965103 (* 1 = 0.965103 loss)
I0423 05:39:07.611780 16565 solver.cpp:244]     Train net output #1: loss = 0.505646 (* 1 = 0.505646 loss)
I0423 05:39:07.611793 16565 solver.cpp:244]     Train net output #2: loss = 0.748254 (* 1 = 0.748254 loss)
I0423 05:39:07.611807 16565 sgd_solver.cpp:106] Iteration 21300, lr = 3e-05
I0423 05:40:46.881706 16565 solver.cpp:228] Iteration 21400, loss = 2.65482
I0423 05:40:46.881875 16565 solver.cpp:244]     Train net output #0: loss = 0.961973 (* 1 = 0.961973 loss)
I0423 05:40:46.881882 16565 solver.cpp:244]     Train net output #1: loss = 0.772152 (* 1 = 0.772152 loss)
I0423 05:40:46.881887 16565 solver.cpp:244]     Train net output #2: loss = 0.920694 (* 1 = 0.920694 loss)
I0423 05:40:46.881893 16565 sgd_solver.cpp:106] Iteration 21400, lr = 3e-05
I0423 05:42:26.350113 16565 solver.cpp:228] Iteration 21500, loss = 2.13971
I0423 05:42:26.350270 16565 solver.cpp:244]     Train net output #0: loss = 0.970225 (* 1 = 0.970225 loss)
I0423 05:42:26.350280 16565 solver.cpp:244]     Train net output #1: loss = 0.58843 (* 1 = 0.58843 loss)
I0423 05:42:26.350284 16565 solver.cpp:244]     Train net output #2: loss = 0.581058 (* 1 = 0.581058 loss)
I0423 05:42:26.350289 16565 sgd_solver.cpp:106] Iteration 21500, lr = 3e-05
I0423 05:44:06.396306 16565 solver.cpp:228] Iteration 21600, loss = 1.99773
I0423 05:44:06.396461 16565 solver.cpp:244]     Train net output #0: loss = 0.958446 (* 1 = 0.958446 loss)
I0423 05:44:06.396469 16565 solver.cpp:244]     Train net output #1: loss = 0.310716 (* 1 = 0.310716 loss)
I0423 05:44:06.396473 16565 solver.cpp:244]     Train net output #2: loss = 0.72857 (* 1 = 0.72857 loss)
I0423 05:44:06.396479 16565 sgd_solver.cpp:106] Iteration 21600, lr = 3e-05
I0423 05:45:46.339974 16565 solver.cpp:228] Iteration 21700, loss = 2.51857
I0423 05:45:46.340147 16565 solver.cpp:244]     Train net output #0: loss = 0.954798 (* 1 = 0.954798 loss)
I0423 05:45:46.340153 16565 solver.cpp:244]     Train net output #1: loss = 0.693347 (* 1 = 0.693347 loss)
I0423 05:45:46.340158 16565 solver.cpp:244]     Train net output #2: loss = 0.870421 (* 1 = 0.870421 loss)
I0423 05:45:46.340163 16565 sgd_solver.cpp:106] Iteration 21700, lr = 3e-05
I0423 05:47:24.484586 16565 solver.cpp:228] Iteration 21800, loss = 2.55606
I0423 05:47:24.484733 16565 solver.cpp:244]     Train net output #0: loss = 0.943008 (* 1 = 0.943008 loss)
I0423 05:47:24.484740 16565 solver.cpp:244]     Train net output #1: loss = 0.7511 (* 1 = 0.7511 loss)
I0423 05:47:24.484746 16565 solver.cpp:244]     Train net output #2: loss = 0.861949 (* 1 = 0.861949 loss)
I0423 05:47:24.484752 16565 sgd_solver.cpp:106] Iteration 21800, lr = 3e-05
I0423 05:49:04.605777 16565 solver.cpp:228] Iteration 21900, loss = 2.46657
I0423 05:49:04.605926 16565 solver.cpp:244]     Train net output #0: loss = 0.965777 (* 1 = 0.965777 loss)
I0423 05:49:04.605933 16565 solver.cpp:244]     Train net output #1: loss = 0.765825 (* 1 = 0.765825 loss)
I0423 05:49:04.605938 16565 solver.cpp:244]     Train net output #2: loss = 0.734973 (* 1 = 0.734973 loss)
I0423 05:49:04.605944 16565 sgd_solver.cpp:106] Iteration 21900, lr = 3e-05
I0423 05:50:43.470362 16565 solver.cpp:337] Iteration 22000, Testing net (#0)
I0423 05:50:43.470510 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 05:50:43.470515 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 05:50:43.470517 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 05:50:43.470532 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 05:50:43.470536 16565 net.cpp:693] Ignoring source layer visualize
I0423 05:50:43.470538 16565 net.cpp:693] Ignoring source layer fake
I0423 05:54:17.359486 16565 solver.cpp:404]     Test net output #0: loss = 0.966966 (* 1 = 0.966966 loss)
I0423 05:54:17.359665 16565 solver.cpp:404]     Test net output #1: loss = 0.69441 (* 1 = 0.69441 loss)
I0423 05:54:17.359674 16565 solver.cpp:404]     Test net output #2: loss = 0.81375 (* 1 = 0.81375 loss)
I0423 05:54:18.014298 16565 solver.cpp:228] Iteration 22000, loss = 2.66956
I0423 05:54:18.014340 16565 solver.cpp:244]     Train net output #0: loss = 0.982431 (* 1 = 0.982431 loss)
I0423 05:54:18.014346 16565 solver.cpp:244]     Train net output #1: loss = 0.808761 (* 1 = 0.808761 loss)
I0423 05:54:18.014350 16565 solver.cpp:244]     Train net output #2: loss = 0.878365 (* 1 = 0.878365 loss)
I0423 05:54:18.014355 16565 sgd_solver.cpp:106] Iteration 22000, lr = 3e-05
I0423 05:55:56.218816 16565 solver.cpp:228] Iteration 22100, loss = 2.5132
I0423 05:55:56.218969 16565 solver.cpp:244]     Train net output #0: loss = 0.986209 (* 1 = 0.986209 loss)
I0423 05:55:56.218977 16565 solver.cpp:244]     Train net output #1: loss = 0.857574 (* 1 = 0.857574 loss)
I0423 05:55:56.218982 16565 solver.cpp:244]     Train net output #2: loss = 0.669419 (* 1 = 0.669419 loss)
I0423 05:55:56.218987 16565 sgd_solver.cpp:106] Iteration 22100, lr = 3e-05
I0423 05:57:35.985360 16565 solver.cpp:228] Iteration 22200, loss = 2.78951
I0423 05:57:35.985508 16565 solver.cpp:244]     Train net output #0: loss = 0.986946 (* 1 = 0.986946 loss)
I0423 05:57:35.985515 16565 solver.cpp:244]     Train net output #1: loss = 0.844449 (* 1 = 0.844449 loss)
I0423 05:57:35.985520 16565 solver.cpp:244]     Train net output #2: loss = 0.958112 (* 1 = 0.958112 loss)
I0423 05:57:35.985524 16565 sgd_solver.cpp:106] Iteration 22200, lr = 3e-05
I0423 05:59:15.769783 16565 solver.cpp:228] Iteration 22300, loss = 2.49975
I0423 05:59:15.769965 16565 solver.cpp:244]     Train net output #0: loss = 0.976746 (* 1 = 0.976746 loss)
I0423 05:59:15.769973 16565 solver.cpp:244]     Train net output #1: loss = 0.754433 (* 1 = 0.754433 loss)
I0423 05:59:15.769979 16565 solver.cpp:244]     Train net output #2: loss = 0.768573 (* 1 = 0.768573 loss)
I0423 05:59:15.769984 16565 sgd_solver.cpp:106] Iteration 22300, lr = 3e-05
I0423 06:00:55.410409 16565 solver.cpp:228] Iteration 22400, loss = 2.35276
I0423 06:00:55.410576 16565 solver.cpp:244]     Train net output #0: loss = 0.974146 (* 1 = 0.974146 loss)
I0423 06:00:55.410584 16565 solver.cpp:244]     Train net output #1: loss = 0.476759 (* 1 = 0.476759 loss)
I0423 06:00:55.410590 16565 solver.cpp:244]     Train net output #2: loss = 0.901854 (* 1 = 0.901854 loss)
I0423 06:00:55.410595 16565 sgd_solver.cpp:106] Iteration 22400, lr = 3e-05
I0423 06:02:34.673583 16565 solver.cpp:228] Iteration 22500, loss = 2.41927
I0423 06:02:34.673743 16565 solver.cpp:244]     Train net output #0: loss = 0.958418 (* 1 = 0.958418 loss)
I0423 06:02:34.673751 16565 solver.cpp:244]     Train net output #1: loss = 0.561498 (* 1 = 0.561498 loss)
I0423 06:02:34.673756 16565 solver.cpp:244]     Train net output #2: loss = 0.899354 (* 1 = 0.899354 loss)
I0423 06:02:34.673761 16565 sgd_solver.cpp:106] Iteration 22500, lr = 3e-05
I0423 06:04:13.947525 16565 solver.cpp:228] Iteration 22600, loss = 2.64024
I0423 06:04:13.947677 16565 solver.cpp:244]     Train net output #0: loss = 0.950961 (* 1 = 0.950961 loss)
I0423 06:04:13.947685 16565 solver.cpp:244]     Train net output #1: loss = 0.781233 (* 1 = 0.781233 loss)
I0423 06:04:13.947690 16565 solver.cpp:244]     Train net output #2: loss = 0.908049 (* 1 = 0.908049 loss)
I0423 06:04:13.947695 16565 sgd_solver.cpp:106] Iteration 22600, lr = 3e-05
I0423 06:05:53.412139 16565 solver.cpp:228] Iteration 22700, loss = 2.31364
I0423 06:05:53.412320 16565 solver.cpp:244]     Train net output #0: loss = 0.965633 (* 1 = 0.965633 loss)
I0423 06:05:53.412328 16565 solver.cpp:244]     Train net output #1: loss = 0.638874 (* 1 = 0.638874 loss)
I0423 06:05:53.412333 16565 solver.cpp:244]     Train net output #2: loss = 0.709137 (* 1 = 0.709137 loss)
I0423 06:05:53.412339 16565 sgd_solver.cpp:106] Iteration 22700, lr = 3e-05
I0423 06:07:31.506577 16565 solver.cpp:228] Iteration 22800, loss = 2.40011
I0423 06:07:31.506739 16565 solver.cpp:244]     Train net output #0: loss = 0.973071 (* 1 = 0.973071 loss)
I0423 06:07:31.506747 16565 solver.cpp:244]     Train net output #1: loss = 0.660023 (* 1 = 0.660023 loss)
I0423 06:07:31.506752 16565 solver.cpp:244]     Train net output #2: loss = 0.767019 (* 1 = 0.767019 loss)
I0423 06:07:31.506758 16565 sgd_solver.cpp:106] Iteration 22800, lr = 3e-05
I0423 06:09:11.223690 16565 solver.cpp:228] Iteration 22900, loss = 1.73338
I0423 06:09:11.223866 16565 solver.cpp:244]     Train net output #0: loss = 0.976085 (* 1 = 0.976085 loss)
I0423 06:09:11.223875 16565 solver.cpp:244]     Train net output #1: loss = 0.220411 (* 1 = 0.220411 loss)
I0423 06:09:11.223881 16565 solver.cpp:244]     Train net output #2: loss = 0.53688 (* 1 = 0.53688 loss)
I0423 06:09:11.223886 16565 sgd_solver.cpp:106] Iteration 22900, lr = 3e-05
I0423 06:10:50.115399 16565 solver.cpp:337] Iteration 23000, Testing net (#0)
I0423 06:10:50.115546 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 06:10:50.115550 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 06:10:50.115555 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 06:10:50.115571 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 06:10:50.115574 16565 net.cpp:693] Ignoring source layer visualize
I0423 06:10:50.115576 16565 net.cpp:693] Ignoring source layer fake
I0423 06:14:23.533821 16565 solver.cpp:404]     Test net output #0: loss = 0.964853 (* 1 = 0.964853 loss)
I0423 06:14:23.534979 16565 solver.cpp:404]     Test net output #1: loss = 0.663409 (* 1 = 0.663409 loss)
I0423 06:14:23.534988 16565 solver.cpp:404]     Test net output #2: loss = 0.786451 (* 1 = 0.786451 loss)
I0423 06:14:24.187734 16565 solver.cpp:228] Iteration 23000, loss = 2.52091
I0423 06:14:24.187762 16565 solver.cpp:244]     Train net output #0: loss = 0.944786 (* 1 = 0.944786 loss)
I0423 06:14:24.187767 16565 solver.cpp:244]     Train net output #1: loss = 0.747193 (* 1 = 0.747193 loss)
I0423 06:14:24.187772 16565 solver.cpp:244]     Train net output #2: loss = 0.828932 (* 1 = 0.828932 loss)
I0423 06:14:24.187777 16565 sgd_solver.cpp:106] Iteration 23000, lr = 3e-05
I0423 06:16:04.713027 16565 solver.cpp:228] Iteration 23100, loss = 2.70969
I0423 06:16:04.713156 16565 solver.cpp:244]     Train net output #0: loss = 0.984271 (* 1 = 0.984271 loss)
I0423 06:16:04.713165 16565 solver.cpp:244]     Train net output #1: loss = 0.801864 (* 1 = 0.801864 loss)
I0423 06:16:04.713168 16565 solver.cpp:244]     Train net output #2: loss = 0.923553 (* 1 = 0.923553 loss)
I0423 06:16:04.713174 16565 sgd_solver.cpp:106] Iteration 23100, lr = 3e-05
I0423 06:17:42.867259 16565 solver.cpp:228] Iteration 23200, loss = 2.57534
I0423 06:17:42.867427 16565 solver.cpp:244]     Train net output #0: loss = 0.963461 (* 1 = 0.963461 loss)
I0423 06:17:42.867434 16565 solver.cpp:244]     Train net output #1: loss = 0.691539 (* 1 = 0.691539 loss)
I0423 06:17:42.867439 16565 solver.cpp:244]     Train net output #2: loss = 0.920338 (* 1 = 0.920338 loss)
I0423 06:17:42.867444 16565 sgd_solver.cpp:106] Iteration 23200, lr = 3e-05
I0423 06:19:22.738592 16565 solver.cpp:228] Iteration 23300, loss = 2.548
I0423 06:19:22.738746 16565 solver.cpp:244]     Train net output #0: loss = 0.98191 (* 1 = 0.98191 loss)
I0423 06:19:22.738754 16565 solver.cpp:244]     Train net output #1: loss = 0.728056 (* 1 = 0.728056 loss)
I0423 06:19:22.738759 16565 solver.cpp:244]     Train net output #2: loss = 0.838037 (* 1 = 0.838037 loss)
I0423 06:19:22.738765 16565 sgd_solver.cpp:106] Iteration 23300, lr = 3e-05
I0423 06:21:02.595052 16565 solver.cpp:228] Iteration 23400, loss = 2.58207
I0423 06:21:02.595234 16565 solver.cpp:244]     Train net output #0: loss = 0.98912 (* 1 = 0.98912 loss)
I0423 06:21:02.595242 16565 solver.cpp:244]     Train net output #1: loss = 0.8225 (* 1 = 0.8225 loss)
I0423 06:21:02.595248 16565 solver.cpp:244]     Train net output #2: loss = 0.770444 (* 1 = 0.770444 loss)
I0423 06:21:02.595254 16565 sgd_solver.cpp:106] Iteration 23400, lr = 3e-05
I0423 06:22:42.490490 16565 solver.cpp:228] Iteration 23500, loss = 1.89587
I0423 06:22:42.490666 16565 solver.cpp:244]     Train net output #0: loss = 0.986771 (* 1 = 0.986771 loss)
I0423 06:22:42.490675 16565 solver.cpp:244]     Train net output #1: loss = 0.443007 (* 1 = 0.443007 loss)
I0423 06:22:42.490680 16565 solver.cpp:244]     Train net output #2: loss = 0.466093 (* 1 = 0.466093 loss)
I0423 06:22:42.490685 16565 sgd_solver.cpp:106] Iteration 23500, lr = 3e-05
I0423 06:24:20.690991 16565 solver.cpp:228] Iteration 23600, loss = 2.32692
I0423 06:24:20.691146 16565 solver.cpp:244]     Train net output #0: loss = 0.980937 (* 1 = 0.980937 loss)
I0423 06:24:20.691154 16565 solver.cpp:244]     Train net output #1: loss = 0.691835 (* 1 = 0.691835 loss)
I0423 06:24:20.691159 16565 solver.cpp:244]     Train net output #2: loss = 0.654147 (* 1 = 0.654147 loss)
I0423 06:24:20.691164 16565 sgd_solver.cpp:106] Iteration 23600, lr = 3e-05
I0423 06:26:00.417285 16565 solver.cpp:228] Iteration 23700, loss = 2.68541
I0423 06:26:00.417460 16565 solver.cpp:244]     Train net output #0: loss = 0.980204 (* 1 = 0.980204 loss)
I0423 06:26:00.417469 16565 solver.cpp:244]     Train net output #1: loss = 0.77667 (* 1 = 0.77667 loss)
I0423 06:26:00.417474 16565 solver.cpp:244]     Train net output #2: loss = 0.928539 (* 1 = 0.928539 loss)
I0423 06:26:00.417479 16565 sgd_solver.cpp:106] Iteration 23700, lr = 3e-05
I0423 06:27:39.780545 16565 solver.cpp:228] Iteration 23800, loss = 2.59519
I0423 06:27:39.780714 16565 solver.cpp:244]     Train net output #0: loss = 0.974081 (* 1 = 0.974081 loss)
I0423 06:27:39.780721 16565 solver.cpp:244]     Train net output #1: loss = 0.702253 (* 1 = 0.702253 loss)
I0423 06:27:39.780727 16565 solver.cpp:244]     Train net output #2: loss = 0.918851 (* 1 = 0.918851 loss)
I0423 06:27:39.780732 16565 sgd_solver.cpp:106] Iteration 23800, lr = 3e-05
I0423 06:29:19.141721 16565 solver.cpp:228] Iteration 23900, loss = 2.46507
I0423 06:29:19.141932 16565 solver.cpp:244]     Train net output #0: loss = 0.957496 (* 1 = 0.957496 loss)
I0423 06:29:19.141940 16565 solver.cpp:244]     Train net output #1: loss = 0.754129 (* 1 = 0.754129 loss)
I0423 06:29:19.141945 16565 solver.cpp:244]     Train net output #2: loss = 0.753443 (* 1 = 0.753443 loss)
I0423 06:29:19.141952 16565 sgd_solver.cpp:106] Iteration 23900, lr = 3e-05
I0423 06:30:57.677115 16565 solver.cpp:337] Iteration 24000, Testing net (#0)
I0423 06:30:57.677274 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 06:30:57.677278 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 06:30:57.677283 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 06:30:57.677297 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 06:30:57.677301 16565 net.cpp:693] Ignoring source layer visualize
I0423 06:30:57.677304 16565 net.cpp:693] Ignoring source layer fake
I0423 06:34:31.718387 16565 solver.cpp:404]     Test net output #0: loss = 0.962269 (* 1 = 0.962269 loss)
I0423 06:34:31.718559 16565 solver.cpp:404]     Test net output #1: loss = 0.686134 (* 1 = 0.686134 loss)
I0423 06:34:31.718565 16565 solver.cpp:404]     Test net output #2: loss = 0.80952 (* 1 = 0.80952 loss)
I0423 06:34:32.375900 16565 solver.cpp:228] Iteration 24000, loss = 1.89484
I0423 06:34:32.375939 16565 solver.cpp:244]     Train net output #0: loss = 0.969956 (* 1 = 0.969956 loss)
I0423 06:34:32.375946 16565 solver.cpp:244]     Train net output #1: loss = 0.536565 (* 1 = 0.536565 loss)
I0423 06:34:32.375949 16565 solver.cpp:244]     Train net output #2: loss = 0.388322 (* 1 = 0.388322 loss)
I0423 06:34:32.375954 16565 sgd_solver.cpp:106] Iteration 24000, lr = 3e-05
I0423 06:36:12.156322 16565 solver.cpp:228] Iteration 24100, loss = 1.92515
I0423 06:36:12.156507 16565 solver.cpp:244]     Train net output #0: loss = 0.96156 (* 1 = 0.96156 loss)
I0423 06:36:12.156517 16565 solver.cpp:244]     Train net output #1: loss = 0.224989 (* 1 = 0.224989 loss)
I0423 06:36:12.156522 16565 solver.cpp:244]     Train net output #2: loss = 0.738599 (* 1 = 0.738599 loss)
I0423 06:36:12.156527 16565 sgd_solver.cpp:106] Iteration 24100, lr = 3e-05
I0423 06:37:52.316846 16565 solver.cpp:228] Iteration 24200, loss = 2.70036
I0423 06:37:52.317021 16565 solver.cpp:244]     Train net output #0: loss = 0.976713 (* 1 = 0.976713 loss)
I0423 06:37:52.317029 16565 solver.cpp:244]     Train net output #1: loss = 0.876789 (* 1 = 0.876789 loss)
I0423 06:37:52.317034 16565 solver.cpp:244]     Train net output #2: loss = 0.846855 (* 1 = 0.846855 loss)
I0423 06:37:52.317039 16565 sgd_solver.cpp:106] Iteration 24200, lr = 3e-05
I0423 06:39:30.507206 16565 solver.cpp:228] Iteration 24300, loss = 2.68735
I0423 06:39:30.507369 16565 solver.cpp:244]     Train net output #0: loss = 0.973432 (* 1 = 0.973432 loss)
I0423 06:39:30.507377 16565 solver.cpp:244]     Train net output #1: loss = 0.863673 (* 1 = 0.863673 loss)
I0423 06:39:30.507382 16565 solver.cpp:244]     Train net output #2: loss = 0.850248 (* 1 = 0.850248 loss)
I0423 06:39:30.507388 16565 sgd_solver.cpp:106] Iteration 24300, lr = 3e-05
I0423 06:41:11.023633 16565 solver.cpp:228] Iteration 24400, loss = 2.58503
I0423 06:41:11.023797 16565 solver.cpp:244]     Train net output #0: loss = 0.9848 (* 1 = 0.9848 loss)
I0423 06:41:11.023805 16565 solver.cpp:244]     Train net output #1: loss = 0.887433 (* 1 = 0.887433 loss)
I0423 06:41:11.023811 16565 solver.cpp:244]     Train net output #2: loss = 0.712798 (* 1 = 0.712798 loss)
I0423 06:41:11.023816 16565 sgd_solver.cpp:106] Iteration 24400, lr = 3e-05
I0423 06:42:51.442998 16565 solver.cpp:228] Iteration 24500, loss = 2.7141
I0423 06:42:51.443169 16565 solver.cpp:244]     Train net output #0: loss = 0.987204 (* 1 = 0.987204 loss)
I0423 06:42:51.443177 16565 solver.cpp:244]     Train net output #1: loss = 0.828726 (* 1 = 0.828726 loss)
I0423 06:42:51.443183 16565 solver.cpp:244]     Train net output #2: loss = 0.898173 (* 1 = 0.898173 loss)
I0423 06:42:51.443187 16565 sgd_solver.cpp:106] Iteration 24500, lr = 3e-05
I0423 06:44:29.673563 16565 solver.cpp:228] Iteration 24600, loss = 2.41092
I0423 06:44:29.673714 16565 solver.cpp:244]     Train net output #0: loss = 0.983195 (* 1 = 0.983195 loss)
I0423 06:44:29.673722 16565 solver.cpp:244]     Train net output #1: loss = 0.744327 (* 1 = 0.744327 loss)
I0423 06:44:29.673727 16565 solver.cpp:244]     Train net output #2: loss = 0.683402 (* 1 = 0.683402 loss)
I0423 06:44:29.673732 16565 sgd_solver.cpp:106] Iteration 24600, lr = 3e-05
I0423 06:46:09.609282 16565 solver.cpp:228] Iteration 24700, loss = 2.77769
I0423 06:46:09.609447 16565 solver.cpp:244]     Train net output #0: loss = 0.985698 (* 1 = 0.985698 loss)
I0423 06:46:09.609455 16565 solver.cpp:244]     Train net output #1: loss = 0.841465 (* 1 = 0.841465 loss)
I0423 06:46:09.609460 16565 solver.cpp:244]     Train net output #2: loss = 0.950524 (* 1 = 0.950524 loss)
I0423 06:46:09.609467 16565 sgd_solver.cpp:106] Iteration 24700, lr = 3e-05
I0423 06:47:49.597491 16565 solver.cpp:228] Iteration 24800, loss = 2.72068
I0423 06:47:49.597645 16565 solver.cpp:244]     Train net output #0: loss = 0.978939 (* 1 = 0.978939 loss)
I0423 06:47:49.597652 16565 solver.cpp:244]     Train net output #1: loss = 0.796012 (* 1 = 0.796012 loss)
I0423 06:47:49.597658 16565 solver.cpp:244]     Train net output #2: loss = 0.945728 (* 1 = 0.945728 loss)
I0423 06:47:49.597663 16565 sgd_solver.cpp:106] Iteration 24800, lr = 3e-05
I0423 06:49:29.391017 16565 solver.cpp:228] Iteration 24900, loss = 2.44652
I0423 06:49:29.391202 16565 solver.cpp:244]     Train net output #0: loss = 0.963001 (* 1 = 0.963001 loss)
I0423 06:49:29.391211 16565 solver.cpp:244]     Train net output #1: loss = 0.576906 (* 1 = 0.576906 loss)
I0423 06:49:29.391216 16565 solver.cpp:244]     Train net output #2: loss = 0.906612 (* 1 = 0.906612 loss)
I0423 06:49:29.391222 16565 sgd_solver.cpp:106] Iteration 24900, lr = 3e-05
I0423 06:51:07.794803 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_25000.caffemodel
I0423 06:51:30.037056 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_25000.solverstate
I0423 06:51:30.227881 16565 solver.cpp:337] Iteration 25000, Testing net (#0)
I0423 06:51:30.227924 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 06:51:30.227927 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 06:51:30.227931 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 06:51:30.227946 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 06:51:30.227949 16565 net.cpp:693] Ignoring source layer visualize
I0423 06:51:30.227962 16565 net.cpp:693] Ignoring source layer fake
I0423 06:55:03.464040 16565 solver.cpp:404]     Test net output #0: loss = 0.967144 (* 1 = 0.967144 loss)
I0423 06:55:03.464231 16565 solver.cpp:404]     Test net output #1: loss = 0.695549 (* 1 = 0.695549 loss)
I0423 06:55:03.464238 16565 solver.cpp:404]     Test net output #2: loss = 0.810713 (* 1 = 0.810713 loss)
I0423 06:55:04.120352 16565 solver.cpp:228] Iteration 25000, loss = 2.6065
I0423 06:55:04.120394 16565 solver.cpp:244]     Train net output #0: loss = 0.958964 (* 1 = 0.958964 loss)
I0423 06:55:04.120400 16565 solver.cpp:244]     Train net output #1: loss = 0.693477 (* 1 = 0.693477 loss)
I0423 06:55:04.120404 16565 solver.cpp:244]     Train net output #2: loss = 0.954063 (* 1 = 0.954063 loss)
I0423 06:55:04.120409 16565 sgd_solver.cpp:106] Iteration 25000, lr = 3e-05
I0423 06:56:43.566787 16565 solver.cpp:228] Iteration 25100, loss = 2.65004
I0423 06:56:43.568492 16565 solver.cpp:244]     Train net output #0: loss = 0.941561 (* 1 = 0.941561 loss)
I0423 06:56:43.568500 16565 solver.cpp:244]     Train net output #1: loss = 0.798724 (* 1 = 0.798724 loss)
I0423 06:56:43.568506 16565 solver.cpp:244]     Train net output #2: loss = 0.909751 (* 1 = 0.909751 loss)
I0423 06:56:43.568511 16565 sgd_solver.cpp:106] Iteration 25100, lr = 3e-05
I0423 06:58:23.194874 16565 solver.cpp:228] Iteration 25200, loss = 2.43158
I0423 06:58:23.195047 16565 solver.cpp:244]     Train net output #0: loss = 0.959061 (* 1 = 0.959061 loss)
I0423 06:58:23.195056 16565 solver.cpp:244]     Train net output #1: loss = 0.692244 (* 1 = 0.692244 loss)
I0423 06:58:23.195061 16565 solver.cpp:244]     Train net output #2: loss = 0.780279 (* 1 = 0.780279 loss)
I0423 06:58:23.195067 16565 sgd_solver.cpp:106] Iteration 25200, lr = 3e-05
I0423 07:00:01.369102 16565 solver.cpp:228] Iteration 25300, loss = 2.32269
I0423 07:00:01.369252 16565 solver.cpp:244]     Train net output #0: loss = 0.965248 (* 1 = 0.965248 loss)
I0423 07:00:01.369261 16565 solver.cpp:244]     Train net output #1: loss = 0.77775 (* 1 = 0.77775 loss)
I0423 07:00:01.369266 16565 solver.cpp:244]     Train net output #2: loss = 0.579697 (* 1 = 0.579697 loss)
I0423 07:00:01.369271 16565 sgd_solver.cpp:106] Iteration 25300, lr = 3e-05
I0423 07:01:41.407301 16565 solver.cpp:228] Iteration 25400, loss = 1.92587
I0423 07:01:41.407469 16565 solver.cpp:244]     Train net output #0: loss = 0.975146 (* 1 = 0.975146 loss)
I0423 07:01:41.407476 16565 solver.cpp:244]     Train net output #1: loss = 0.400493 (* 1 = 0.400493 loss)
I0423 07:01:41.407481 16565 solver.cpp:244]     Train net output #2: loss = 0.550234 (* 1 = 0.550234 loss)
I0423 07:01:41.407487 16565 sgd_solver.cpp:106] Iteration 25400, lr = 3e-05
I0423 07:03:21.664902 16565 solver.cpp:228] Iteration 25500, loss = 2.66373
I0423 07:03:21.665055 16565 solver.cpp:244]     Train net output #0: loss = 0.954909 (* 1 = 0.954909 loss)
I0423 07:03:21.665063 16565 solver.cpp:244]     Train net output #1: loss = 0.843316 (* 1 = 0.843316 loss)
I0423 07:03:21.665068 16565 solver.cpp:244]     Train net output #2: loss = 0.865508 (* 1 = 0.865508 loss)
I0423 07:03:21.665073 16565 sgd_solver.cpp:106] Iteration 25500, lr = 3e-05
I0423 07:05:01.520735 16565 solver.cpp:228] Iteration 25600, loss = 2.72769
I0423 07:05:01.520920 16565 solver.cpp:244]     Train net output #0: loss = 0.989099 (* 1 = 0.989099 loss)
I0423 07:05:01.520927 16565 solver.cpp:244]     Train net output #1: loss = 0.838097 (* 1 = 0.838097 loss)
I0423 07:05:01.520932 16565 solver.cpp:244]     Train net output #2: loss = 0.900497 (* 1 = 0.900497 loss)
I0423 07:05:01.520937 16565 sgd_solver.cpp:106] Iteration 25600, lr = 3e-05
I0423 07:06:39.673996 16565 solver.cpp:228] Iteration 25700, loss = 2.51069
I0423 07:06:39.674151 16565 solver.cpp:244]     Train net output #0: loss = 0.979271 (* 1 = 0.979271 loss)
I0423 07:06:39.674160 16565 solver.cpp:244]     Train net output #1: loss = 0.796819 (* 1 = 0.796819 loss)
I0423 07:06:39.674165 16565 solver.cpp:244]     Train net output #2: loss = 0.734606 (* 1 = 0.734606 loss)
I0423 07:06:39.674170 16565 sgd_solver.cpp:106] Iteration 25700, lr = 3e-05
I0423 07:08:19.463891 16565 solver.cpp:228] Iteration 25800, loss = 2.6152
I0423 07:08:19.464063 16565 solver.cpp:244]     Train net output #0: loss = 0.976607 (* 1 = 0.976607 loss)
I0423 07:08:19.464071 16565 solver.cpp:244]     Train net output #1: loss = 0.713081 (* 1 = 0.713081 loss)
I0423 07:08:19.464076 16565 solver.cpp:244]     Train net output #2: loss = 0.925508 (* 1 = 0.925508 loss)
I0423 07:08:19.464081 16565 sgd_solver.cpp:106] Iteration 25800, lr = 3e-05
I0423 07:09:59.620227 16565 solver.cpp:228] Iteration 25900, loss = 2.75712
I0423 07:09:59.620385 16565 solver.cpp:244]     Train net output #0: loss = 0.985572 (* 1 = 0.985572 loss)
I0423 07:09:59.620393 16565 solver.cpp:244]     Train net output #1: loss = 0.80735 (* 1 = 0.80735 loss)
I0423 07:09:59.620398 16565 solver.cpp:244]     Train net output #2: loss = 0.964195 (* 1 = 0.964195 loss)
I0423 07:09:59.620404 16565 sgd_solver.cpp:106] Iteration 25900, lr = 3e-05
I0423 07:11:38.445541 16565 solver.cpp:337] Iteration 26000, Testing net (#0)
I0423 07:11:38.445713 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 07:11:38.445719 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 07:11:38.445724 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 07:11:38.445739 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 07:11:38.445744 16565 net.cpp:693] Ignoring source layer visualize
I0423 07:11:38.445745 16565 net.cpp:693] Ignoring source layer fake
I0423 07:15:12.419459 16565 solver.cpp:404]     Test net output #0: loss = 0.972258 (* 1 = 0.972258 loss)
I0423 07:15:12.419620 16565 solver.cpp:404]     Test net output #1: loss = 0.730222 (* 1 = 0.730222 loss)
I0423 07:15:12.419627 16565 solver.cpp:404]     Test net output #2: loss = 0.809757 (* 1 = 0.809757 loss)
I0423 07:15:13.073066 16565 solver.cpp:228] Iteration 26000, loss = 2.43141
I0423 07:15:13.073112 16565 solver.cpp:244]     Train net output #0: loss = 0.985396 (* 1 = 0.985396 loss)
I0423 07:15:13.073117 16565 solver.cpp:244]     Train net output #1: loss = 0.704448 (* 1 = 0.704448 loss)
I0423 07:15:13.073120 16565 solver.cpp:244]     Train net output #2: loss = 0.741564 (* 1 = 0.741564 loss)
I0423 07:15:13.073125 16565 sgd_solver.cpp:106] Iteration 26000, lr = 3e-05
I0423 07:16:51.295033 16565 solver.cpp:228] Iteration 26100, loss = 2.57008
I0423 07:16:51.295202 16565 solver.cpp:244]     Train net output #0: loss = 0.98491 (* 1 = 0.98491 loss)
I0423 07:16:51.295208 16565 solver.cpp:244]     Train net output #1: loss = 0.815562 (* 1 = 0.815562 loss)
I0423 07:16:51.295213 16565 solver.cpp:244]     Train net output #2: loss = 0.769604 (* 1 = 0.769604 loss)
I0423 07:16:51.295219 16565 sgd_solver.cpp:106] Iteration 26100, lr = 3e-05
I0423 07:18:31.076807 16565 solver.cpp:228] Iteration 26200, loss = 2.62596
I0423 07:18:31.076953 16565 solver.cpp:244]     Train net output #0: loss = 0.982191 (* 1 = 0.982191 loss)
I0423 07:18:31.076961 16565 solver.cpp:244]     Train net output #1: loss = 0.706899 (* 1 = 0.706899 loss)
I0423 07:18:31.076967 16565 solver.cpp:244]     Train net output #2: loss = 0.936871 (* 1 = 0.936871 loss)
I0423 07:18:31.076973 16565 sgd_solver.cpp:106] Iteration 26200, lr = 3e-05
I0423 07:20:10.308272 16565 solver.cpp:228] Iteration 26300, loss = 2.72632
I0423 07:20:10.308450 16565 solver.cpp:244]     Train net output #0: loss = 0.970705 (* 1 = 0.970705 loss)
I0423 07:20:10.308459 16565 solver.cpp:244]     Train net output #1: loss = 0.824704 (* 1 = 0.824704 loss)
I0423 07:20:10.308465 16565 solver.cpp:244]     Train net output #2: loss = 0.930914 (* 1 = 0.930914 loss)
I0423 07:20:10.308468 16565 sgd_solver.cpp:106] Iteration 26300, lr = 3e-05
I0423 07:21:49.763581 16565 solver.cpp:228] Iteration 26400, loss = 2.47079
I0423 07:21:49.763764 16565 solver.cpp:244]     Train net output #0: loss = 0.966689 (* 1 = 0.966689 loss)
I0423 07:21:49.763772 16565 solver.cpp:244]     Train net output #1: loss = 0.745206 (* 1 = 0.745206 loss)
I0423 07:21:49.763779 16565 solver.cpp:244]     Train net output #2: loss = 0.758896 (* 1 = 0.758896 loss)
I0423 07:21:49.763784 16565 sgd_solver.cpp:106] Iteration 26400, lr = 3e-05
I0423 07:23:29.245862 16565 solver.cpp:228] Iteration 26500, loss = 2.378
I0423 07:23:29.246023 16565 solver.cpp:244]     Train net output #0: loss = 0.966673 (* 1 = 0.966673 loss)
I0423 07:23:29.246031 16565 solver.cpp:244]     Train net output #1: loss = 0.652336 (* 1 = 0.652336 loss)
I0423 07:23:29.246037 16565 solver.cpp:244]     Train net output #2: loss = 0.758992 (* 1 = 0.758992 loss)
I0423 07:23:29.246042 16565 sgd_solver.cpp:106] Iteration 26500, lr = 3e-05
I0423 07:25:09.100992 16565 solver.cpp:228] Iteration 26600, loss = 1.57418
I0423 07:25:09.101133 16565 solver.cpp:244]     Train net output #0: loss = 0.970478 (* 1 = 0.970478 loss)
I0423 07:25:09.101141 16565 solver.cpp:244]     Train net output #1: loss = 0.224615 (* 1 = 0.224615 loss)
I0423 07:25:09.101147 16565 solver.cpp:244]     Train net output #2: loss = 0.379085 (* 1 = 0.379085 loss)
I0423 07:25:09.101152 16565 sgd_solver.cpp:106] Iteration 26600, lr = 3e-05
I0423 07:26:49.031038 16565 solver.cpp:228] Iteration 26700, loss = 2.53588
I0423 07:26:49.031191 16565 solver.cpp:244]     Train net output #0: loss = 0.975205 (* 1 = 0.975205 loss)
I0423 07:26:49.031200 16565 solver.cpp:244]     Train net output #1: loss = 0.796403 (* 1 = 0.796403 loss)
I0423 07:26:49.031205 16565 solver.cpp:244]     Train net output #2: loss = 0.764277 (* 1 = 0.764277 loss)
I0423 07:26:49.031211 16565 sgd_solver.cpp:106] Iteration 26700, lr = 3e-05
I0423 07:28:27.252795 16565 solver.cpp:228] Iteration 26800, loss = 2.61276
I0423 07:28:27.252979 16565 solver.cpp:244]     Train net output #0: loss = 0.973954 (* 1 = 0.973954 loss)
I0423 07:28:27.252988 16565 solver.cpp:244]     Train net output #1: loss = 0.791728 (* 1 = 0.791728 loss)
I0423 07:28:27.252993 16565 solver.cpp:244]     Train net output #2: loss = 0.847076 (* 1 = 0.847076 loss)
I0423 07:28:27.252997 16565 sgd_solver.cpp:106] Iteration 26800, lr = 3e-05
I0423 07:30:07.264417 16565 solver.cpp:228] Iteration 26900, loss = 2.58123
I0423 07:30:07.264582 16565 solver.cpp:244]     Train net output #0: loss = 0.977585 (* 1 = 0.977585 loss)
I0423 07:30:07.264590 16565 solver.cpp:244]     Train net output #1: loss = 0.700867 (* 1 = 0.700867 loss)
I0423 07:30:07.264595 16565 solver.cpp:244]     Train net output #2: loss = 0.902781 (* 1 = 0.902781 loss)
I0423 07:30:07.264601 16565 sgd_solver.cpp:106] Iteration 26900, lr = 3e-05
I0423 07:31:46.251781 16565 solver.cpp:337] Iteration 27000, Testing net (#0)
I0423 07:31:46.251925 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 07:31:46.251930 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 07:31:46.251935 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 07:31:46.251950 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 07:31:46.251953 16565 net.cpp:693] Ignoring source layer visualize
I0423 07:31:46.251955 16565 net.cpp:693] Ignoring source layer fake
I0423 07:35:22.502796 16565 solver.cpp:404]     Test net output #0: loss = 0.972842 (* 1 = 0.972842 loss)
I0423 07:35:22.502996 16565 solver.cpp:404]     Test net output #1: loss = 0.714457 (* 1 = 0.714457 loss)
I0423 07:35:22.503005 16565 solver.cpp:404]     Test net output #2: loss = 0.807373 (* 1 = 0.807373 loss)
I0423 07:35:23.161388 16565 solver.cpp:228] Iteration 27000, loss = 2.66065
I0423 07:35:23.161430 16565 solver.cpp:244]     Train net output #0: loss = 0.979807 (* 1 = 0.979807 loss)
I0423 07:35:23.161439 16565 solver.cpp:244]     Train net output #1: loss = 0.757186 (* 1 = 0.757186 loss)
I0423 07:35:23.161459 16565 solver.cpp:244]     Train net output #2: loss = 0.92366 (* 1 = 0.92366 loss)
I0423 07:35:23.161464 16565 sgd_solver.cpp:106] Iteration 27000, lr = 3e-05
I0423 07:37:01.385043 16565 solver.cpp:228] Iteration 27100, loss = 2.71835
I0423 07:37:01.385203 16565 solver.cpp:244]     Train net output #0: loss = 0.988043 (* 1 = 0.988043 loss)
I0423 07:37:01.385211 16565 solver.cpp:244]     Train net output #1: loss = 0.816759 (* 1 = 0.816759 loss)
I0423 07:37:01.385216 16565 solver.cpp:244]     Train net output #2: loss = 0.913552 (* 1 = 0.913552 loss)
I0423 07:37:01.385222 16565 sgd_solver.cpp:106] Iteration 27100, lr = 3e-05
I0423 07:38:41.313881 16565 solver.cpp:228] Iteration 27200, loss = 2.55844
I0423 07:38:41.314028 16565 solver.cpp:244]     Train net output #0: loss = 0.989453 (* 1 = 0.989453 loss)
I0423 07:38:41.314036 16565 solver.cpp:244]     Train net output #1: loss = 0.839242 (* 1 = 0.839242 loss)
I0423 07:38:41.314043 16565 solver.cpp:244]     Train net output #2: loss = 0.729747 (* 1 = 0.729747 loss)
I0423 07:38:41.314047 16565 sgd_solver.cpp:106] Iteration 27200, lr = 3e-05
I0423 07:40:21.234853 16565 solver.cpp:228] Iteration 27300, loss = 2.41127
I0423 07:40:21.235009 16565 solver.cpp:244]     Train net output #0: loss = 0.974071 (* 1 = 0.974071 loss)
I0423 07:40:21.235018 16565 solver.cpp:244]     Train net output #1: loss = 0.679022 (* 1 = 0.679022 loss)
I0423 07:40:21.235023 16565 solver.cpp:244]     Train net output #2: loss = 0.758179 (* 1 = 0.758179 loss)
I0423 07:40:21.235028 16565 sgd_solver.cpp:106] Iteration 27300, lr = 3e-05
I0423 07:42:01.040515 16565 solver.cpp:228] Iteration 27400, loss = 2.37278
I0423 07:42:01.040673 16565 solver.cpp:244]     Train net output #0: loss = 0.982438 (* 1 = 0.982438 loss)
I0423 07:42:01.040681 16565 solver.cpp:244]     Train net output #1: loss = 0.650412 (* 1 = 0.650412 loss)
I0423 07:42:01.040686 16565 solver.cpp:244]     Train net output #2: loss = 0.739927 (* 1 = 0.739927 loss)
I0423 07:42:01.040691 16565 sgd_solver.cpp:106] Iteration 27400, lr = 3e-05
I0423 07:43:40.437302 16565 solver.cpp:228] Iteration 27500, loss = 2.38925
I0423 07:43:40.437482 16565 solver.cpp:244]     Train net output #0: loss = 0.981172 (* 1 = 0.981172 loss)
I0423 07:43:40.437490 16565 solver.cpp:244]     Train net output #1: loss = 0.580137 (* 1 = 0.580137 loss)
I0423 07:43:40.437495 16565 solver.cpp:244]     Train net output #2: loss = 0.827937 (* 1 = 0.827937 loss)
I0423 07:43:40.437502 16565 sgd_solver.cpp:106] Iteration 27500, lr = 3e-05
I0423 07:45:20.077482 16565 solver.cpp:228] Iteration 27600, loss = 2.52469
I0423 07:45:20.077667 16565 solver.cpp:244]     Train net output #0: loss = 0.961758 (* 1 = 0.961758 loss)
I0423 07:45:20.077677 16565 solver.cpp:244]     Train net output #1: loss = 0.694423 (* 1 = 0.694423 loss)
I0423 07:45:20.077682 16565 solver.cpp:244]     Train net output #2: loss = 0.868512 (* 1 = 0.868512 loss)
I0423 07:45:20.077687 16565 sgd_solver.cpp:106] Iteration 27600, lr = 3e-05
I0423 07:46:59.985219 16565 solver.cpp:228] Iteration 27700, loss = 2.44983
I0423 07:46:59.985396 16565 solver.cpp:244]     Train net output #0: loss = 0.987924 (* 1 = 0.987924 loss)
I0423 07:46:59.985405 16565 solver.cpp:244]     Train net output #1: loss = 0.885135 (* 1 = 0.885135 loss)
I0423 07:46:59.985410 16565 solver.cpp:244]     Train net output #2: loss = 0.576775 (* 1 = 0.576775 loss)
I0423 07:46:59.985415 16565 sgd_solver.cpp:106] Iteration 27700, lr = 3e-05
I0423 07:48:38.124106 16565 solver.cpp:228] Iteration 27800, loss = 2.40656
I0423 07:48:38.124294 16565 solver.cpp:244]     Train net output #0: loss = 0.955092 (* 1 = 0.955092 loss)
I0423 07:48:38.124301 16565 solver.cpp:244]     Train net output #1: loss = 0.689088 (* 1 = 0.689088 loss)
I0423 07:48:38.124306 16565 solver.cpp:244]     Train net output #2: loss = 0.76238 (* 1 = 0.76238 loss)
I0423 07:48:38.124311 16565 sgd_solver.cpp:106] Iteration 27800, lr = 3e-05
I0423 07:50:17.793583 16565 solver.cpp:228] Iteration 27900, loss = 2.44548
I0423 07:50:17.793723 16565 solver.cpp:244]     Train net output #0: loss = 0.941889 (* 1 = 0.941889 loss)
I0423 07:50:17.793730 16565 solver.cpp:244]     Train net output #1: loss = 0.745858 (* 1 = 0.745858 loss)
I0423 07:50:17.793735 16565 solver.cpp:244]     Train net output #2: loss = 0.757737 (* 1 = 0.757737 loss)
I0423 07:50:17.793741 16565 sgd_solver.cpp:106] Iteration 27900, lr = 3e-05
I0423 07:51:57.173598 16565 solver.cpp:337] Iteration 28000, Testing net (#0)
I0423 07:51:57.173730 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 07:51:57.173734 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 07:51:57.173739 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 07:51:57.173755 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 07:51:57.173759 16565 net.cpp:693] Ignoring source layer visualize
I0423 07:51:57.173761 16565 net.cpp:693] Ignoring source layer fake
I0423 07:55:31.407256 16565 solver.cpp:404]     Test net output #0: loss = 0.969877 (* 1 = 0.969877 loss)
I0423 07:55:31.409010 16565 solver.cpp:404]     Test net output #1: loss = 0.706021 (* 1 = 0.706021 loss)
I0423 07:55:31.409019 16565 solver.cpp:404]     Test net output #2: loss = 0.80448 (* 1 = 0.80448 loss)
I0423 07:55:32.062897 16565 solver.cpp:228] Iteration 28000, loss = 2.73612
I0423 07:55:32.062924 16565 solver.cpp:244]     Train net output #0: loss = 0.973879 (* 1 = 0.973879 loss)
I0423 07:55:32.062930 16565 solver.cpp:244]     Train net output #1: loss = 0.869323 (* 1 = 0.869323 loss)
I0423 07:55:32.062934 16565 solver.cpp:244]     Train net output #2: loss = 0.892917 (* 1 = 0.892917 loss)
I0423 07:55:32.062938 16565 sgd_solver.cpp:106] Iteration 28000, lr = 3e-05
I0423 07:57:12.439604 16565 solver.cpp:228] Iteration 28100, loss = 2.60061
I0423 07:57:12.439749 16565 solver.cpp:244]     Train net output #0: loss = 0.977722 (* 1 = 0.977722 loss)
I0423 07:57:12.439757 16565 solver.cpp:244]     Train net output #1: loss = 0.818713 (* 1 = 0.818713 loss)
I0423 07:57:12.439762 16565 solver.cpp:244]     Train net output #2: loss = 0.804173 (* 1 = 0.804173 loss)
I0423 07:57:12.439769 16565 sgd_solver.cpp:106] Iteration 28100, lr = 3e-05
I0423 07:58:50.638345 16565 solver.cpp:228] Iteration 28200, loss = 2.58456
I0423 07:58:50.638506 16565 solver.cpp:244]     Train net output #0: loss = 0.97606 (* 1 = 0.97606 loss)
I0423 07:58:50.638514 16565 solver.cpp:244]     Train net output #1: loss = 0.696251 (* 1 = 0.696251 loss)
I0423 07:58:50.638520 16565 solver.cpp:244]     Train net output #2: loss = 0.912254 (* 1 = 0.912254 loss)
I0423 07:58:50.638525 16565 sgd_solver.cpp:106] Iteration 28200, lr = 3e-05
I0423 08:00:31.187433 16565 solver.cpp:228] Iteration 28300, loss = 2.7276
I0423 08:00:31.187572 16565 solver.cpp:244]     Train net output #0: loss = 0.983204 (* 1 = 0.983204 loss)
I0423 08:00:31.187582 16565 solver.cpp:244]     Train net output #1: loss = 0.802066 (* 1 = 0.802066 loss)
I0423 08:00:31.187587 16565 solver.cpp:244]     Train net output #2: loss = 0.942334 (* 1 = 0.942334 loss)
I0423 08:00:31.187592 16565 sgd_solver.cpp:106] Iteration 28300, lr = 3e-05
I0423 08:02:11.446974 16565 solver.cpp:228] Iteration 28400, loss = 2.60537
I0423 08:02:11.447135 16565 solver.cpp:244]     Train net output #0: loss = 0.986644 (* 1 = 0.986644 loss)
I0423 08:02:11.447144 16565 solver.cpp:244]     Train net output #1: loss = 0.857816 (* 1 = 0.857816 loss)
I0423 08:02:11.447149 16565 solver.cpp:244]     Train net output #2: loss = 0.76091 (* 1 = 0.76091 loss)
I0423 08:02:11.447154 16565 sgd_solver.cpp:106] Iteration 28400, lr = 3e-05
I0423 08:03:51.374617 16565 solver.cpp:228] Iteration 28500, loss = 2.42277
I0423 08:03:51.374810 16565 solver.cpp:244]     Train net output #0: loss = 0.983604 (* 1 = 0.983604 loss)
I0423 08:03:51.374819 16565 solver.cpp:244]     Train net output #1: loss = 0.688629 (* 1 = 0.688629 loss)
I0423 08:03:51.374825 16565 solver.cpp:244]     Train net output #2: loss = 0.750538 (* 1 = 0.750538 loss)
I0423 08:03:51.374830 16565 sgd_solver.cpp:106] Iteration 28500, lr = 3e-05
I0423 08:05:29.503499 16565 solver.cpp:228] Iteration 28600, loss = 2.13932
I0423 08:05:29.503644 16565 solver.cpp:244]     Train net output #0: loss = 0.984388 (* 1 = 0.984388 loss)
I0423 08:05:29.503653 16565 solver.cpp:244]     Train net output #1: loss = 0.577824 (* 1 = 0.577824 loss)
I0423 08:05:29.503659 16565 solver.cpp:244]     Train net output #2: loss = 0.577112 (* 1 = 0.577112 loss)
I0423 08:05:29.503664 16565 sgd_solver.cpp:106] Iteration 28600, lr = 3e-05
I0423 08:07:09.158561 16565 solver.cpp:228] Iteration 28700, loss = 2.36999
I0423 08:07:09.158707 16565 solver.cpp:244]     Train net output #0: loss = 0.974488 (* 1 = 0.974488 loss)
I0423 08:07:09.158715 16565 solver.cpp:244]     Train net output #1: loss = 0.669396 (* 1 = 0.669396 loss)
I0423 08:07:09.158720 16565 solver.cpp:244]     Train net output #2: loss = 0.726109 (* 1 = 0.726109 loss)
I0423 08:07:09.158725 16565 sgd_solver.cpp:106] Iteration 28700, lr = 3e-05
I0423 08:08:48.431934 16565 solver.cpp:228] Iteration 28800, loss = 2.72489
I0423 08:08:48.432082 16565 solver.cpp:244]     Train net output #0: loss = 0.977857 (* 1 = 0.977857 loss)
I0423 08:08:48.432090 16565 solver.cpp:244]     Train net output #1: loss = 0.824349 (* 1 = 0.824349 loss)
I0423 08:08:48.432096 16565 solver.cpp:244]     Train net output #2: loss = 0.922688 (* 1 = 0.922688 loss)
I0423 08:08:48.432099 16565 sgd_solver.cpp:106] Iteration 28800, lr = 3e-05
I0423 08:10:27.732343 16565 solver.cpp:228] Iteration 28900, loss = 2.67328
I0423 08:10:27.732491 16565 solver.cpp:244]     Train net output #0: loss = 0.964296 (* 1 = 0.964296 loss)
I0423 08:10:27.732498 16565 solver.cpp:244]     Train net output #1: loss = 0.75184 (* 1 = 0.75184 loss)
I0423 08:10:27.732503 16565 solver.cpp:244]     Train net output #2: loss = 0.95714 (* 1 = 0.95714 loss)
I0423 08:10:27.732509 16565 sgd_solver.cpp:106] Iteration 28900, lr = 3e-05
I0423 08:12:06.289063 16565 solver.cpp:337] Iteration 29000, Testing net (#0)
I0423 08:12:06.289170 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 08:12:06.289173 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 08:12:06.289177 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 08:12:06.289191 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 08:12:06.289194 16565 net.cpp:693] Ignoring source layer visualize
I0423 08:12:06.289196 16565 net.cpp:693] Ignoring source layer fake
I0423 08:15:39.800303 16565 solver.cpp:404]     Test net output #0: loss = 0.972216 (* 1 = 0.972216 loss)
I0423 08:15:39.800439 16565 solver.cpp:404]     Test net output #1: loss = 0.730019 (* 1 = 0.730019 loss)
I0423 08:15:39.800446 16565 solver.cpp:404]     Test net output #2: loss = 0.813127 (* 1 = 0.813127 loss)
I0423 08:15:40.454308 16565 solver.cpp:228] Iteration 29000, loss = 2.28002
I0423 08:15:40.454334 16565 solver.cpp:244]     Train net output #0: loss = 0.973669 (* 1 = 0.973669 loss)
I0423 08:15:40.454355 16565 solver.cpp:244]     Train net output #1: loss = 0.725852 (* 1 = 0.725852 loss)
I0423 08:15:40.454358 16565 solver.cpp:244]     Train net output #2: loss = 0.580499 (* 1 = 0.580499 loss)
I0423 08:15:40.454362 16565 sgd_solver.cpp:106] Iteration 29000, lr = 3e-05
I0423 08:17:20.196842 16565 solver.cpp:228] Iteration 29100, loss = 1.78873
I0423 08:17:20.197000 16565 solver.cpp:244]     Train net output #0: loss = 0.972451 (* 1 = 0.972451 loss)
I0423 08:17:20.197008 16565 solver.cpp:244]     Train net output #1: loss = 0.270151 (* 1 = 0.270151 loss)
I0423 08:17:20.197013 16565 solver.cpp:244]     Train net output #2: loss = 0.546131 (* 1 = 0.546131 loss)
I0423 08:17:20.197018 16565 sgd_solver.cpp:106] Iteration 29100, lr = 3e-05
I0423 08:19:00.683567 16565 solver.cpp:228] Iteration 29200, loss = 2.57833
I0423 08:19:00.683769 16565 solver.cpp:244]     Train net output #0: loss = 0.970518 (* 1 = 0.970518 loss)
I0423 08:19:00.683778 16565 solver.cpp:244]     Train net output #1: loss = 0.791783 (* 1 = 0.791783 loss)
I0423 08:19:00.683784 16565 solver.cpp:244]     Train net output #2: loss = 0.816027 (* 1 = 0.816027 loss)
I0423 08:19:00.683789 16565 sgd_solver.cpp:106] Iteration 29200, lr = 3e-05
I0423 08:20:38.904093 16565 solver.cpp:228] Iteration 29300, loss = 2.60971
I0423 08:20:38.904251 16565 solver.cpp:244]     Train net output #0: loss = 0.955955 (* 1 = 0.955955 loss)
I0423 08:20:38.904260 16565 solver.cpp:244]     Train net output #1: loss = 0.767662 (* 1 = 0.767662 loss)
I0423 08:20:38.904265 16565 solver.cpp:244]     Train net output #2: loss = 0.886089 (* 1 = 0.886089 loss)
I0423 08:20:38.904270 16565 sgd_solver.cpp:106] Iteration 29300, lr = 3e-05
I0423 08:22:19.833288 16565 solver.cpp:228] Iteration 29400, loss = 2.68405
I0423 08:22:19.833457 16565 solver.cpp:244]     Train net output #0: loss = 0.980873 (* 1 = 0.980873 loss)
I0423 08:22:19.833465 16565 solver.cpp:244]     Train net output #1: loss = 0.779077 (* 1 = 0.779077 loss)
I0423 08:22:19.833470 16565 solver.cpp:244]     Train net output #2: loss = 0.924097 (* 1 = 0.924097 loss)
I0423 08:22:19.833475 16565 sgd_solver.cpp:106] Iteration 29400, lr = 3e-05
I0423 08:24:00.110158 16565 solver.cpp:228] Iteration 29500, loss = 2.73055
I0423 08:24:00.110311 16565 solver.cpp:244]     Train net output #0: loss = 0.977915 (* 1 = 0.977915 loss)
I0423 08:24:00.110318 16565 solver.cpp:244]     Train net output #1: loss = 0.824356 (* 1 = 0.824356 loss)
I0423 08:24:00.110323 16565 solver.cpp:244]     Train net output #2: loss = 0.928276 (* 1 = 0.928276 loss)
I0423 08:24:00.110330 16565 sgd_solver.cpp:106] Iteration 29500, lr = 3e-05
I0423 08:25:38.282604 16565 solver.cpp:228] Iteration 29600, loss = 2.70603
I0423 08:25:38.282757 16565 solver.cpp:244]     Train net output #0: loss = 0.990249 (* 1 = 0.990249 loss)
I0423 08:25:38.282765 16565 solver.cpp:244]     Train net output #1: loss = 0.84676 (* 1 = 0.84676 loss)
I0423 08:25:38.282771 16565 solver.cpp:244]     Train net output #2: loss = 0.869019 (* 1 = 0.869019 loss)
I0423 08:25:38.282776 16565 sgd_solver.cpp:106] Iteration 29600, lr = 3e-05
I0423 08:27:18.295531 16565 solver.cpp:228] Iteration 29700, loss = 2.49199
I0423 08:27:18.296542 16565 solver.cpp:244]     Train net output #0: loss = 0.988984 (* 1 = 0.988984 loss)
I0423 08:27:18.296550 16565 solver.cpp:244]     Train net output #1: loss = 0.765882 (* 1 = 0.765882 loss)
I0423 08:27:18.296556 16565 solver.cpp:244]     Train net output #2: loss = 0.737127 (* 1 = 0.737127 loss)
I0423 08:27:18.296561 16565 sgd_solver.cpp:106] Iteration 29700, lr = 3e-05
I0423 08:28:58.068434 16565 solver.cpp:228] Iteration 29800, loss = 2.43256
I0423 08:28:58.068593 16565 solver.cpp:244]     Train net output #0: loss = 0.98134 (* 1 = 0.98134 loss)
I0423 08:28:58.068601 16565 solver.cpp:244]     Train net output #1: loss = 0.704404 (* 1 = 0.704404 loss)
I0423 08:28:58.068606 16565 solver.cpp:244]     Train net output #2: loss = 0.746817 (* 1 = 0.746817 loss)
I0423 08:28:58.068611 16565 sgd_solver.cpp:106] Iteration 29800, lr = 3e-05
I0423 08:30:38.222242 16565 solver.cpp:228] Iteration 29900, loss = 2.20277
I0423 08:30:38.223840 16565 solver.cpp:244]     Train net output #0: loss = 0.98282 (* 1 = 0.98282 loss)
I0423 08:30:38.223848 16565 solver.cpp:244]     Train net output #1: loss = 0.479998 (* 1 = 0.479998 loss)
I0423 08:30:38.223853 16565 solver.cpp:244]     Train net output #2: loss = 0.739952 (* 1 = 0.739952 loss)
I0423 08:30:38.223858 16565 sgd_solver.cpp:106] Iteration 29900, lr = 3e-05
I0423 08:32:16.757272 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_30000.caffemodel
I0423 08:32:28.666645 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_30000.solverstate
I0423 08:32:28.858804 16565 solver.cpp:337] Iteration 30000, Testing net (#0)
I0423 08:32:28.858850 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 08:32:28.858851 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 08:32:28.858855 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 08:32:28.858871 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 08:32:28.858875 16565 net.cpp:693] Ignoring source layer visualize
I0423 08:32:28.858876 16565 net.cpp:693] Ignoring source layer fake
I0423 08:36:03.384785 16565 solver.cpp:404]     Test net output #0: loss = 0.971331 (* 1 = 0.971331 loss)
I0423 08:36:03.384963 16565 solver.cpp:404]     Test net output #1: loss = 0.725844 (* 1 = 0.725844 loss)
I0423 08:36:03.384970 16565 solver.cpp:404]     Test net output #2: loss = 0.806459 (* 1 = 0.806459 loss)
I0423 08:36:04.035744 16565 solver.cpp:228] Iteration 30000, loss = 2.43337
I0423 08:36:04.035794 16565 solver.cpp:244]     Train net output #0: loss = 0.980828 (* 1 = 0.980828 loss)
I0423 08:36:04.035799 16565 solver.cpp:244]     Train net output #1: loss = 0.647818 (* 1 = 0.647818 loss)
I0423 08:36:04.035804 16565 solver.cpp:244]     Train net output #2: loss = 0.804726 (* 1 = 0.804726 loss)
I0423 08:36:04.035809 16565 sgd_solver.cpp:106] Iteration 30000, lr = 3e-05
I0423 08:37:43.387398 16565 solver.cpp:228] Iteration 30100, loss = 2.42865
I0423 08:37:43.387552 16565 solver.cpp:244]     Train net output #0: loss = 0.973392 (* 1 = 0.973392 loss)
I0423 08:37:43.387562 16565 solver.cpp:244]     Train net output #1: loss = 0.695973 (* 1 = 0.695973 loss)
I0423 08:37:43.387567 16565 solver.cpp:244]     Train net output #2: loss = 0.759284 (* 1 = 0.759284 loss)
I0423 08:37:43.387570 16565 sgd_solver.cpp:106] Iteration 30100, lr = 3e-05
I0423 08:39:22.922832 16565 solver.cpp:228] Iteration 30200, loss = 2.78378
I0423 08:39:22.922978 16565 solver.cpp:244]     Train net output #0: loss = 0.972036 (* 1 = 0.972036 loss)
I0423 08:39:22.922986 16565 solver.cpp:244]     Train net output #1: loss = 0.859972 (* 1 = 0.859972 loss)
I0423 08:39:22.922991 16565 solver.cpp:244]     Train net output #2: loss = 0.951776 (* 1 = 0.951776 loss)
I0423 08:39:22.922996 16565 sgd_solver.cpp:106] Iteration 30200, lr = 3e-05
I0423 08:41:01.082556 16565 solver.cpp:228] Iteration 30300, loss = 2.42577
I0423 08:41:01.082700 16565 solver.cpp:244]     Train net output #0: loss = 0.980566 (* 1 = 0.980566 loss)
I0423 08:41:01.082706 16565 solver.cpp:244]     Train net output #1: loss = 0.688978 (* 1 = 0.688978 loss)
I0423 08:41:01.082711 16565 solver.cpp:244]     Train net output #2: loss = 0.756228 (* 1 = 0.756228 loss)
I0423 08:41:01.082717 16565 sgd_solver.cpp:106] Iteration 30300, lr = 3e-05
I0423 08:42:40.773680 16565 solver.cpp:228] Iteration 30400, loss = 2.59014
I0423 08:42:40.773823 16565 solver.cpp:244]     Train net output #0: loss = 0.938744 (* 1 = 0.938744 loss)
I0423 08:42:40.773830 16565 solver.cpp:244]     Train net output #1: loss = 0.781474 (* 1 = 0.781474 loss)
I0423 08:42:40.773836 16565 solver.cpp:244]     Train net output #2: loss = 0.86992 (* 1 = 0.86992 loss)
I0423 08:42:40.773840 16565 sgd_solver.cpp:106] Iteration 30400, lr = 3e-05
I0423 08:44:20.875762 16565 solver.cpp:228] Iteration 30500, loss = 2.64312
I0423 08:44:20.875922 16565 solver.cpp:244]     Train net output #0: loss = 0.95462 (* 1 = 0.95462 loss)
I0423 08:44:20.875931 16565 solver.cpp:244]     Train net output #1: loss = 0.789871 (* 1 = 0.789871 loss)
I0423 08:44:20.875936 16565 solver.cpp:244]     Train net output #2: loss = 0.898631 (* 1 = 0.898631 loss)
I0423 08:44:20.875941 16565 sgd_solver.cpp:106] Iteration 30500, lr = 3e-05
I0423 08:46:00.784685 16565 solver.cpp:228] Iteration 30600, loss = 2.62131
I0423 08:46:00.784857 16565 solver.cpp:244]     Train net output #0: loss = 0.960965 (* 1 = 0.960965 loss)
I0423 08:46:00.784865 16565 solver.cpp:244]     Train net output #1: loss = 0.778572 (* 1 = 0.778572 loss)
I0423 08:46:00.784870 16565 solver.cpp:244]     Train net output #2: loss = 0.88177 (* 1 = 0.88177 loss)
I0423 08:46:00.784875 16565 sgd_solver.cpp:106] Iteration 30600, lr = 3e-05
I0423 08:47:38.989301 16565 solver.cpp:228] Iteration 30700, loss = 2.54216
I0423 08:47:38.989490 16565 solver.cpp:244]     Train net output #0: loss = 0.978557 (* 1 = 0.978557 loss)
I0423 08:47:38.989497 16565 solver.cpp:244]     Train net output #1: loss = 0.653566 (* 1 = 0.653566 loss)
I0423 08:47:38.989502 16565 solver.cpp:244]     Train net output #2: loss = 0.910038 (* 1 = 0.910038 loss)
I0423 08:47:38.989508 16565 sgd_solver.cpp:106] Iteration 30700, lr = 3e-05
I0423 08:49:18.817701 16565 solver.cpp:228] Iteration 30800, loss = 2.68214
I0423 08:49:18.817852 16565 solver.cpp:244]     Train net output #0: loss = 0.977278 (* 1 = 0.977278 loss)
I0423 08:49:18.817859 16565 solver.cpp:244]     Train net output #1: loss = 0.780192 (* 1 = 0.780192 loss)
I0423 08:49:18.817865 16565 solver.cpp:244]     Train net output #2: loss = 0.924668 (* 1 = 0.924668 loss)
I0423 08:49:18.817869 16565 sgd_solver.cpp:106] Iteration 30800, lr = 3e-05
I0423 08:50:58.776279 16565 solver.cpp:228] Iteration 30900, loss = 2.54369
I0423 08:50:58.776427 16565 solver.cpp:244]     Train net output #0: loss = 0.989136 (* 1 = 0.989136 loss)
I0423 08:50:58.776435 16565 solver.cpp:244]     Train net output #1: loss = 0.828726 (* 1 = 0.828726 loss)
I0423 08:50:58.776440 16565 solver.cpp:244]     Train net output #2: loss = 0.725827 (* 1 = 0.725827 loss)
I0423 08:50:58.776445 16565 sgd_solver.cpp:106] Iteration 30900, lr = 3e-05
I0423 08:52:37.589730 16565 solver.cpp:337] Iteration 31000, Testing net (#0)
I0423 08:52:37.589879 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 08:52:37.589882 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 08:52:37.589886 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 08:52:37.589902 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 08:52:37.589907 16565 net.cpp:693] Ignoring source layer visualize
I0423 08:52:37.589910 16565 net.cpp:693] Ignoring source layer fake
I0423 08:56:11.785917 16565 solver.cpp:404]     Test net output #0: loss = 0.97003 (* 1 = 0.97003 loss)
I0423 08:56:11.786059 16565 solver.cpp:404]     Test net output #1: loss = 0.732627 (* 1 = 0.732627 loss)
I0423 08:56:11.786067 16565 solver.cpp:404]     Test net output #2: loss = 0.814438 (* 1 = 0.814438 loss)
I0423 08:56:12.446516 16565 solver.cpp:228] Iteration 31000, loss = 2.28948
I0423 08:56:12.446558 16565 solver.cpp:244]     Train net output #0: loss = 0.986073 (* 1 = 0.986073 loss)
I0423 08:56:12.446563 16565 solver.cpp:244]     Train net output #1: loss = 0.729772 (* 1 = 0.729772 loss)
I0423 08:56:12.446568 16565 solver.cpp:244]     Train net output #2: loss = 0.573636 (* 1 = 0.573636 loss)
I0423 08:56:12.446571 16565 sgd_solver.cpp:106] Iteration 31000, lr = 3e-05
I0423 08:57:50.646260 16565 solver.cpp:228] Iteration 31100, loss = 1.74987
I0423 08:57:50.646447 16565 solver.cpp:244]     Train net output #0: loss = 0.988717 (* 1 = 0.988717 loss)
I0423 08:57:50.646456 16565 solver.cpp:244]     Train net output #1: loss = 0.571649 (* 1 = 0.571649 loss)
I0423 08:57:50.646461 16565 solver.cpp:244]     Train net output #2: loss = 0.1895 (* 1 = 0.1895 loss)
I0423 08:57:50.646466 16565 sgd_solver.cpp:106] Iteration 31100, lr = 3e-05
I0423 08:59:30.463629 16565 solver.cpp:228] Iteration 31200, loss = 2.64003
I0423 08:59:30.463781 16565 solver.cpp:244]     Train net output #0: loss = 0.984437 (* 1 = 0.984437 loss)
I0423 08:59:30.463788 16565 solver.cpp:244]     Train net output #1: loss = 0.782172 (* 1 = 0.782172 loss)
I0423 08:59:30.463794 16565 solver.cpp:244]     Train net output #2: loss = 0.87342 (* 1 = 0.87342 loss)
I0423 08:59:30.463798 16565 sgd_solver.cpp:106] Iteration 31200, lr = 3e-05
I0423 09:01:09.757642 16565 solver.cpp:228] Iteration 31300, loss = 2.57126
I0423 09:01:09.757814 16565 solver.cpp:244]     Train net output #0: loss = 0.98145 (* 1 = 0.98145 loss)
I0423 09:01:09.757822 16565 solver.cpp:244]     Train net output #1: loss = 0.847128 (* 1 = 0.847128 loss)
I0423 09:01:09.757827 16565 solver.cpp:244]     Train net output #2: loss = 0.742681 (* 1 = 0.742681 loss)
I0423 09:01:09.757833 16565 sgd_solver.cpp:106] Iteration 31300, lr = 3e-05
I0423 09:02:49.065659 16565 solver.cpp:228] Iteration 31400, loss = 2.41741
I0423 09:02:49.065845 16565 solver.cpp:244]     Train net output #0: loss = 0.974437 (* 1 = 0.974437 loss)
I0423 09:02:49.065852 16565 solver.cpp:244]     Train net output #1: loss = 0.725005 (* 1 = 0.725005 loss)
I0423 09:02:49.065858 16565 solver.cpp:244]     Train net output #2: loss = 0.717965 (* 1 = 0.717965 loss)
I0423 09:02:49.065863 16565 sgd_solver.cpp:106] Iteration 31400, lr = 3e-05
I0423 09:04:28.965188 16565 solver.cpp:228] Iteration 31500, loss = 1.97927
I0423 09:04:28.965338 16565 solver.cpp:244]     Train net output #0: loss = 0.990811 (* 1 = 0.990811 loss)
I0423 09:04:28.965348 16565 solver.cpp:244]     Train net output #1: loss = 0.610269 (* 1 = 0.610269 loss)
I0423 09:04:28.965353 16565 solver.cpp:244]     Train net output #2: loss = 0.378193 (* 1 = 0.378193 loss)
I0423 09:04:28.965358 16565 sgd_solver.cpp:106] Iteration 31500, lr = 3e-05
I0423 09:06:10.216764 16565 solver.cpp:228] Iteration 31600, loss = 2.34111
I0423 09:06:10.216925 16565 solver.cpp:244]     Train net output #0: loss = 0.959657 (* 1 = 0.959657 loss)
I0423 09:06:10.216933 16565 solver.cpp:244]     Train net output #1: loss = 0.458425 (* 1 = 0.458425 loss)
I0423 09:06:10.216938 16565 solver.cpp:244]     Train net output #2: loss = 0.923026 (* 1 = 0.923026 loss)
I0423 09:06:10.216943 16565 sgd_solver.cpp:106] Iteration 31600, lr = 3e-05
I0423 09:07:50.777686 16565 solver.cpp:228] Iteration 31700, loss = 2.71446
I0423 09:07:50.777829 16565 solver.cpp:244]     Train net output #0: loss = 0.973851 (* 1 = 0.973851 loss)
I0423 09:07:50.777837 16565 solver.cpp:244]     Train net output #1: loss = 0.868075 (* 1 = 0.868075 loss)
I0423 09:07:50.777842 16565 solver.cpp:244]     Train net output #2: loss = 0.872537 (* 1 = 0.872537 loss)
I0423 09:07:50.777848 16565 sgd_solver.cpp:106] Iteration 31700, lr = 3e-05
I0423 09:09:28.922757 16565 solver.cpp:228] Iteration 31800, loss = 2.76134
I0423 09:09:28.922904 16565 solver.cpp:244]     Train net output #0: loss = 0.970723 (* 1 = 0.970723 loss)
I0423 09:09:28.922910 16565 solver.cpp:244]     Train net output #1: loss = 0.863291 (* 1 = 0.863291 loss)
I0423 09:09:28.922916 16565 solver.cpp:244]     Train net output #2: loss = 0.92733 (* 1 = 0.92733 loss)
I0423 09:09:28.922921 16565 sgd_solver.cpp:106] Iteration 31800, lr = 3e-05
I0423 09:11:09.543856 16565 solver.cpp:228] Iteration 31900, loss = 2.5568
I0423 09:11:09.543994 16565 solver.cpp:244]     Train net output #0: loss = 0.979583 (* 1 = 0.979583 loss)
I0423 09:11:09.544003 16565 solver.cpp:244]     Train net output #1: loss = 0.848086 (* 1 = 0.848086 loss)
I0423 09:11:09.544008 16565 solver.cpp:244]     Train net output #2: loss = 0.729129 (* 1 = 0.729129 loss)
I0423 09:11:09.544013 16565 sgd_solver.cpp:106] Iteration 31900, lr = 3e-05
I0423 09:12:48.773460 16565 solver.cpp:337] Iteration 32000, Testing net (#0)
I0423 09:12:48.774189 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 09:12:48.774195 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 09:12:48.774199 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 09:12:48.774215 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 09:12:48.774219 16565 net.cpp:693] Ignoring source layer visualize
I0423 09:12:48.774220 16565 net.cpp:693] Ignoring source layer fake
I0423 09:16:22.505131 16565 solver.cpp:404]     Test net output #0: loss = 0.971933 (* 1 = 0.971933 loss)
I0423 09:16:22.505285 16565 solver.cpp:404]     Test net output #1: loss = 0.721372 (* 1 = 0.721372 loss)
I0423 09:16:22.505292 16565 solver.cpp:404]     Test net output #2: loss = 0.809378 (* 1 = 0.809378 loss)
I0423 09:16:23.160377 16565 solver.cpp:228] Iteration 32000, loss = 2.74081
I0423 09:16:23.160419 16565 solver.cpp:244]     Train net output #0: loss = 0.975527 (* 1 = 0.975527 loss)
I0423 09:16:23.160425 16565 solver.cpp:244]     Train net output #1: loss = 0.842748 (* 1 = 0.842748 loss)
I0423 09:16:23.160430 16565 solver.cpp:244]     Train net output #2: loss = 0.922536 (* 1 = 0.922536 loss)
I0423 09:16:23.160434 16565 sgd_solver.cpp:106] Iteration 32000, lr = 3e-05
I0423 09:18:01.357157 16565 solver.cpp:228] Iteration 32100, loss = 2.60553
I0423 09:18:01.357326 16565 solver.cpp:244]     Train net output #0: loss = 0.976567 (* 1 = 0.976567 loss)
I0423 09:18:01.357334 16565 solver.cpp:244]     Train net output #1: loss = 0.728519 (* 1 = 0.728519 loss)
I0423 09:18:01.357339 16565 solver.cpp:244]     Train net output #2: loss = 0.900443 (* 1 = 0.900443 loss)
I0423 09:18:01.357344 16565 sgd_solver.cpp:106] Iteration 32100, lr = 3e-05
I0423 09:19:41.419015 16565 solver.cpp:228] Iteration 32200, loss = 2.57919
I0423 09:19:41.419163 16565 solver.cpp:244]     Train net output #0: loss = 0.989929 (* 1 = 0.989929 loss)
I0423 09:19:41.419172 16565 solver.cpp:244]     Train net output #1: loss = 0.814757 (* 1 = 0.814757 loss)
I0423 09:19:41.419175 16565 solver.cpp:244]     Train net output #2: loss = 0.774504 (* 1 = 0.774504 loss)
I0423 09:19:41.419181 16565 sgd_solver.cpp:106] Iteration 32200, lr = 3e-05
I0423 09:21:21.330739 16565 solver.cpp:228] Iteration 32300, loss = 2.47099
I0423 09:21:21.330888 16565 solver.cpp:244]     Train net output #0: loss = 0.983103 (* 1 = 0.983103 loss)
I0423 09:21:21.330896 16565 solver.cpp:244]     Train net output #1: loss = 0.750552 (* 1 = 0.750552 loss)
I0423 09:21:21.330901 16565 solver.cpp:244]     Train net output #2: loss = 0.737339 (* 1 = 0.737339 loss)
I0423 09:21:21.330907 16565 sgd_solver.cpp:106] Iteration 32300, lr = 3e-05
I0423 09:23:01.081693 16565 solver.cpp:228] Iteration 32400, loss = 2.35286
I0423 09:23:01.081847 16565 solver.cpp:244]     Train net output #0: loss = 0.972543 (* 1 = 0.972543 loss)
I0423 09:23:01.081856 16565 solver.cpp:244]     Train net output #1: loss = 0.524623 (* 1 = 0.524623 loss)
I0423 09:23:01.081861 16565 solver.cpp:244]     Train net output #2: loss = 0.855696 (* 1 = 0.855696 loss)
I0423 09:23:01.081866 16565 sgd_solver.cpp:106] Iteration 32400, lr = 3e-05
I0423 09:24:40.458925 16565 solver.cpp:228] Iteration 32500, loss = 2.70933
I0423 09:24:40.459095 16565 solver.cpp:244]     Train net output #0: loss = 0.982842 (* 1 = 0.982842 loss)
I0423 09:24:40.459105 16565 solver.cpp:244]     Train net output #1: loss = 0.799181 (* 1 = 0.799181 loss)
I0423 09:24:40.459110 16565 solver.cpp:244]     Train net output #2: loss = 0.927309 (* 1 = 0.927309 loss)
I0423 09:24:40.459115 16565 sgd_solver.cpp:106] Iteration 32500, lr = 3e-05
I0423 09:26:19.911842 16565 solver.cpp:228] Iteration 32600, loss = 2.56637
I0423 09:26:19.911994 16565 solver.cpp:244]     Train net output #0: loss = 0.968584 (* 1 = 0.968584 loss)
I0423 09:26:19.912003 16565 solver.cpp:244]     Train net output #1: loss = 0.860745 (* 1 = 0.860745 loss)
I0423 09:26:19.912008 16565 solver.cpp:244]     Train net output #2: loss = 0.737042 (* 1 = 0.737042 loss)
I0423 09:26:19.912012 16565 sgd_solver.cpp:106] Iteration 32600, lr = 3e-05
I0423 09:28:00.052438 16565 solver.cpp:228] Iteration 32700, loss = 2.5614
I0423 09:28:00.052590 16565 solver.cpp:244]     Train net output #0: loss = 0.980237 (* 1 = 0.980237 loss)
I0423 09:28:00.052598 16565 solver.cpp:244]     Train net output #1: loss = 0.818709 (* 1 = 0.818709 loss)
I0423 09:28:00.052603 16565 solver.cpp:244]     Train net output #2: loss = 0.762458 (* 1 = 0.762458 loss)
I0423 09:28:00.052609 16565 sgd_solver.cpp:106] Iteration 32700, lr = 3e-05
I0423 09:29:38.176205 16565 solver.cpp:228] Iteration 32800, loss = 2.46642
I0423 09:29:38.176362 16565 solver.cpp:244]     Train net output #0: loss = 0.948671 (* 1 = 0.948671 loss)
I0423 09:29:38.176369 16565 solver.cpp:244]     Train net output #1: loss = 0.755917 (* 1 = 0.755917 loss)
I0423 09:29:38.176374 16565 solver.cpp:244]     Train net output #2: loss = 0.761836 (* 1 = 0.761836 loss)
I0423 09:29:38.176379 16565 sgd_solver.cpp:106] Iteration 32800, lr = 3e-05
I0423 09:31:17.878475 16565 solver.cpp:228] Iteration 32900, loss = 2.39364
I0423 09:31:17.878643 16565 solver.cpp:244]     Train net output #0: loss = 0.966497 (* 1 = 0.966497 loss)
I0423 09:31:17.878653 16565 solver.cpp:244]     Train net output #1: loss = 0.848282 (* 1 = 0.848282 loss)
I0423 09:31:17.878656 16565 solver.cpp:244]     Train net output #2: loss = 0.578863 (* 1 = 0.578863 loss)
I0423 09:31:17.878664 16565 sgd_solver.cpp:106] Iteration 32900, lr = 3e-05
I0423 09:32:56.671525 16565 solver.cpp:337] Iteration 33000, Testing net (#0)
I0423 09:32:56.671666 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 09:32:56.671670 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 09:32:56.671674 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 09:32:56.671689 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 09:32:56.671694 16565 net.cpp:693] Ignoring source layer visualize
I0423 09:32:56.671695 16565 net.cpp:693] Ignoring source layer fake
I0423 09:36:30.302038 16565 solver.cpp:404]     Test net output #0: loss = 0.971331 (* 1 = 0.971331 loss)
I0423 09:36:30.302179 16565 solver.cpp:404]     Test net output #1: loss = 0.705759 (* 1 = 0.705759 loss)
I0423 09:36:30.302187 16565 solver.cpp:404]     Test net output #2: loss = 0.786368 (* 1 = 0.786368 loss)
I0423 09:36:30.967860 16565 solver.cpp:228] Iteration 33000, loss = 2.72038
I0423 09:36:30.967902 16565 solver.cpp:244]     Train net output #0: loss = 0.953322 (* 1 = 0.953322 loss)
I0423 09:36:30.967907 16565 solver.cpp:244]     Train net output #1: loss = 0.829356 (* 1 = 0.829356 loss)
I0423 09:36:30.967912 16565 solver.cpp:244]     Train net output #2: loss = 0.937704 (* 1 = 0.937704 loss)
I0423 09:36:30.967916 16565 sgd_solver.cpp:106] Iteration 33000, lr = 3e-05
I0423 09:38:11.061331 16565 solver.cpp:228] Iteration 33100, loss = 2.73302
I0423 09:38:11.061496 16565 solver.cpp:244]     Train net output #0: loss = 0.965992 (* 1 = 0.965992 loss)
I0423 09:38:11.061506 16565 solver.cpp:244]     Train net output #1: loss = 0.865156 (* 1 = 0.865156 loss)
I0423 09:38:11.061511 16565 solver.cpp:244]     Train net output #2: loss = 0.901873 (* 1 = 0.901873 loss)
I0423 09:38:11.061516 16565 sgd_solver.cpp:106] Iteration 33100, lr = 3e-05
I0423 09:39:49.228217 16565 solver.cpp:228] Iteration 33200, loss = 2.59031
I0423 09:39:49.228377 16565 solver.cpp:244]     Train net output #0: loss = 0.988904 (* 1 = 0.988904 loss)
I0423 09:39:49.228384 16565 solver.cpp:244]     Train net output #1: loss = 0.867911 (* 1 = 0.867911 loss)
I0423 09:39:49.228389 16565 solver.cpp:244]     Train net output #2: loss = 0.7335 (* 1 = 0.7335 loss)
I0423 09:39:49.228394 16565 sgd_solver.cpp:106] Iteration 33200, lr = 3e-05
I0423 09:41:29.099452 16565 solver.cpp:228] Iteration 33300, loss = 2.58853
I0423 09:41:29.099617 16565 solver.cpp:244]     Train net output #0: loss = 0.973442 (* 1 = 0.973442 loss)
I0423 09:41:29.099625 16565 solver.cpp:244]     Train net output #1: loss = 0.715613 (* 1 = 0.715613 loss)
I0423 09:41:29.099630 16565 solver.cpp:244]     Train net output #2: loss = 0.899474 (* 1 = 0.899474 loss)
I0423 09:41:29.099637 16565 sgd_solver.cpp:106] Iteration 33300, lr = 3e-05
I0423 09:43:08.863972 16565 solver.cpp:228] Iteration 33400, loss = 2.4523
I0423 09:43:08.864130 16565 solver.cpp:244]     Train net output #0: loss = 0.988462 (* 1 = 0.988462 loss)
I0423 09:43:08.864137 16565 solver.cpp:244]     Train net output #1: loss = 0.689376 (* 1 = 0.689376 loss)
I0423 09:43:08.864143 16565 solver.cpp:244]     Train net output #2: loss = 0.774463 (* 1 = 0.774463 loss)
I0423 09:43:08.864150 16565 sgd_solver.cpp:106] Iteration 33400, lr = 3e-05
I0423 09:44:48.662513 16565 solver.cpp:228] Iteration 33500, loss = 2.35041
I0423 09:44:48.662674 16565 solver.cpp:244]     Train net output #0: loss = 0.992615 (* 1 = 0.992615 loss)
I0423 09:44:48.662683 16565 solver.cpp:244]     Train net output #1: loss = 0.787101 (* 1 = 0.787101 loss)
I0423 09:44:48.662688 16565 solver.cpp:244]     Train net output #2: loss = 0.570695 (* 1 = 0.570695 loss)
I0423 09:44:48.662693 16565 sgd_solver.cpp:106] Iteration 33500, lr = 3e-05
I0423 09:46:26.841378 16565 solver.cpp:228] Iteration 33600, loss = 2.2499
I0423 09:46:26.842301 16565 solver.cpp:244]     Train net output #0: loss = 0.988653 (* 1 = 0.988653 loss)
I0423 09:46:26.842309 16565 solver.cpp:244]     Train net output #1: loss = 0.71666 (* 1 = 0.71666 loss)
I0423 09:46:26.842314 16565 solver.cpp:244]     Train net output #2: loss = 0.544589 (* 1 = 0.544589 loss)
I0423 09:46:26.842319 16565 sgd_solver.cpp:106] Iteration 33600, lr = 3e-05
I0423 09:48:06.494149 16565 solver.cpp:228] Iteration 33700, loss = 2.57087
I0423 09:48:06.494307 16565 solver.cpp:244]     Train net output #0: loss = 0.993838 (* 1 = 0.993838 loss)
I0423 09:48:06.494315 16565 solver.cpp:244]     Train net output #1: loss = 0.781128 (* 1 = 0.781128 loss)
I0423 09:48:06.494320 16565 solver.cpp:244]     Train net output #2: loss = 0.795906 (* 1 = 0.795906 loss)
I0423 09:48:06.494326 16565 sgd_solver.cpp:106] Iteration 33700, lr = 3e-05
I0423 09:49:45.722787 16565 solver.cpp:228] Iteration 33800, loss = 2.57865
I0423 09:49:45.722959 16565 solver.cpp:244]     Train net output #0: loss = 0.982607 (* 1 = 0.982607 loss)
I0423 09:49:45.722965 16565 solver.cpp:244]     Train net output #1: loss = 0.83357 (* 1 = 0.83357 loss)
I0423 09:49:45.722971 16565 solver.cpp:244]     Train net output #2: loss = 0.762469 (* 1 = 0.762469 loss)
I0423 09:49:45.722976 16565 sgd_solver.cpp:106] Iteration 33800, lr = 3e-05
I0423 09:51:25.032889 16565 solver.cpp:228] Iteration 33900, loss = 2.59684
I0423 09:51:25.033037 16565 solver.cpp:244]     Train net output #0: loss = 0.964626 (* 1 = 0.964626 loss)
I0423 09:51:25.033046 16565 solver.cpp:244]     Train net output #1: loss = 0.711619 (* 1 = 0.711619 loss)
I0423 09:51:25.033051 16565 solver.cpp:244]     Train net output #2: loss = 0.920598 (* 1 = 0.920598 loss)
I0423 09:51:25.033056 16565 sgd_solver.cpp:106] Iteration 33900, lr = 3e-05
I0423 09:53:03.599961 16565 solver.cpp:337] Iteration 34000, Testing net (#0)
I0423 09:53:03.600111 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 09:53:03.600114 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 09:53:03.600118 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 09:53:03.600132 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 09:53:03.600136 16565 net.cpp:693] Ignoring source layer visualize
I0423 09:53:03.600138 16565 net.cpp:693] Ignoring source layer fake
I0423 09:56:37.128324 16565 solver.cpp:404]     Test net output #0: loss = 0.973313 (* 1 = 0.973313 loss)
I0423 09:56:37.128469 16565 solver.cpp:404]     Test net output #1: loss = 0.738167 (* 1 = 0.738167 loss)
I0423 09:56:37.128478 16565 solver.cpp:404]     Test net output #2: loss = 0.81484 (* 1 = 0.81484 loss)
I0423 09:56:37.783977 16565 solver.cpp:228] Iteration 34000, loss = 2.38318
I0423 09:56:37.784020 16565 solver.cpp:244]     Train net output #0: loss = 0.971742 (* 1 = 0.971742 loss)
I0423 09:56:37.784026 16565 solver.cpp:244]     Train net output #1: loss = 0.658163 (* 1 = 0.658163 loss)
I0423 09:56:37.784030 16565 solver.cpp:244]     Train net output #2: loss = 0.753277 (* 1 = 0.753277 loss)
I0423 09:56:37.784035 16565 sgd_solver.cpp:106] Iteration 34000, lr = 3e-05
I0423 09:58:17.775409 16565 solver.cpp:228] Iteration 34100, loss = 2.61858
I0423 09:58:17.775554 16565 solver.cpp:244]     Train net output #0: loss = 0.947951 (* 1 = 0.947951 loss)
I0423 09:58:17.775563 16565 solver.cpp:244]     Train net output #1: loss = 0.797794 (* 1 = 0.797794 loss)
I0423 09:58:17.775568 16565 solver.cpp:244]     Train net output #2: loss = 0.87283 (* 1 = 0.87283 loss)
I0423 09:58:17.775573 16565 sgd_solver.cpp:106] Iteration 34100, lr = 3e-05
I0423 09:59:58.126610 16565 solver.cpp:228] Iteration 34200, loss = 2.73601
I0423 09:59:58.126782 16565 solver.cpp:244]     Train net output #0: loss = 0.967488 (* 1 = 0.967488 loss)
I0423 09:59:58.126791 16565 solver.cpp:244]     Train net output #1: loss = 0.848234 (* 1 = 0.848234 loss)
I0423 09:59:58.126796 16565 solver.cpp:244]     Train net output #2: loss = 0.920288 (* 1 = 0.920288 loss)
I0423 09:59:58.126801 16565 sgd_solver.cpp:106] Iteration 34200, lr = 3e-05
I0423 10:01:36.239142 16565 solver.cpp:228] Iteration 34300, loss = 2.67909
I0423 10:01:36.239315 16565 solver.cpp:244]     Train net output #0: loss = 0.970177 (* 1 = 0.970177 loss)
I0423 10:01:36.239323 16565 solver.cpp:244]     Train net output #1: loss = 0.80984 (* 1 = 0.80984 loss)
I0423 10:01:36.239328 16565 solver.cpp:244]     Train net output #2: loss = 0.899073 (* 1 = 0.899073 loss)
I0423 10:01:36.239336 16565 sgd_solver.cpp:106] Iteration 34300, lr = 3e-05
I0423 10:03:16.574347 16565 solver.cpp:228] Iteration 34400, loss = 2.60538
I0423 10:03:16.574496 16565 solver.cpp:244]     Train net output #0: loss = 0.976639 (* 1 = 0.976639 loss)
I0423 10:03:16.574502 16565 solver.cpp:244]     Train net output #1: loss = 0.732503 (* 1 = 0.732503 loss)
I0423 10:03:16.574508 16565 solver.cpp:244]     Train net output #2: loss = 0.896234 (* 1 = 0.896234 loss)
I0423 10:03:16.574513 16565 sgd_solver.cpp:106] Iteration 34400, lr = 3e-05
I0423 10:04:56.557296 16565 solver.cpp:228] Iteration 34500, loss = 2.54876
I0423 10:04:56.557448 16565 solver.cpp:244]     Train net output #0: loss = 0.970527 (* 1 = 0.970527 loss)
I0423 10:04:56.557457 16565 solver.cpp:244]     Train net output #1: loss = 0.727791 (* 1 = 0.727791 loss)
I0423 10:04:56.557462 16565 solver.cpp:244]     Train net output #2: loss = 0.850444 (* 1 = 0.850444 loss)
I0423 10:04:56.557468 16565 sgd_solver.cpp:106] Iteration 34500, lr = 3e-05
I0423 10:06:34.754835 16565 solver.cpp:228] Iteration 34600, loss = 2.75048
I0423 10:06:34.755048 16565 solver.cpp:244]     Train net output #0: loss = 0.987425 (* 1 = 0.987425 loss)
I0423 10:06:34.755056 16565 solver.cpp:244]     Train net output #1: loss = 0.816819 (* 1 = 0.816819 loss)
I0423 10:06:34.755061 16565 solver.cpp:244]     Train net output #2: loss = 0.946232 (* 1 = 0.946232 loss)
I0423 10:06:34.755066 16565 sgd_solver.cpp:106] Iteration 34600, lr = 3e-05
I0423 10:08:16.318362 16565 solver.cpp:228] Iteration 34700, loss = 2.74775
I0423 10:08:16.318529 16565 solver.cpp:244]     Train net output #0: loss = 0.987568 (* 1 = 0.987568 loss)
I0423 10:08:16.318537 16565 solver.cpp:244]     Train net output #1: loss = 0.848507 (* 1 = 0.848507 loss)
I0423 10:08:16.318542 16565 solver.cpp:244]     Train net output #2: loss = 0.911676 (* 1 = 0.911676 loss)
I0423 10:08:16.318549 16565 sgd_solver.cpp:106] Iteration 34700, lr = 3e-05
I0423 10:10:01.524422 16565 solver.cpp:228] Iteration 34800, loss = 2.10988
I0423 10:10:01.524581 16565 solver.cpp:244]     Train net output #0: loss = 0.972108 (* 1 = 0.972108 loss)
I0423 10:10:01.524588 16565 solver.cpp:244]     Train net output #1: loss = 0.538976 (* 1 = 0.538976 loss)
I0423 10:10:01.524595 16565 solver.cpp:244]     Train net output #2: loss = 0.598791 (* 1 = 0.598791 loss)
I0423 10:10:01.524600 16565 sgd_solver.cpp:106] Iteration 34800, lr = 3e-05
I0423 10:11:41.673122 16565 solver.cpp:228] Iteration 34900, loss = 2.52991
I0423 10:11:41.673276 16565 solver.cpp:244]     Train net output #0: loss = 0.982731 (* 1 = 0.982731 loss)
I0423 10:11:41.673285 16565 solver.cpp:244]     Train net output #1: loss = 0.687142 (* 1 = 0.687142 loss)
I0423 10:11:41.673290 16565 solver.cpp:244]     Train net output #2: loss = 0.860035 (* 1 = 0.860035 loss)
I0423 10:11:41.673295 16565 sgd_solver.cpp:106] Iteration 34900, lr = 3e-05
I0423 10:13:19.780138 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_35000.caffemodel
I0423 10:13:35.959525 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_35000.solverstate
I0423 10:13:36.160127 16565 solver.cpp:337] Iteration 35000, Testing net (#0)
I0423 10:13:36.160154 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 10:13:36.160157 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 10:13:36.160161 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 10:13:36.160176 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 10:13:36.160178 16565 net.cpp:693] Ignoring source layer visualize
I0423 10:13:36.160181 16565 net.cpp:693] Ignoring source layer fake
I0423 10:17:09.598177 16565 solver.cpp:404]     Test net output #0: loss = 0.97274 (* 1 = 0.97274 loss)
I0423 10:17:09.598332 16565 solver.cpp:404]     Test net output #1: loss = 0.736289 (* 1 = 0.736289 loss)
I0423 10:17:09.598340 16565 solver.cpp:404]     Test net output #2: loss = 0.807855 (* 1 = 0.807855 loss)
I0423 10:17:10.254842 16565 solver.cpp:228] Iteration 35000, loss = 2.60016
I0423 10:17:10.254891 16565 solver.cpp:244]     Train net output #0: loss = 0.968212 (* 1 = 0.968212 loss)
I0423 10:17:10.254896 16565 solver.cpp:244]     Train net output #1: loss = 0.863257 (* 1 = 0.863257 loss)
I0423 10:17:10.254900 16565 solver.cpp:244]     Train net output #2: loss = 0.768687 (* 1 = 0.768687 loss)
I0423 10:17:10.254907 16565 sgd_solver.cpp:106] Iteration 35000, lr = 3e-05
I0423 10:18:49.650372 16565 solver.cpp:228] Iteration 35100, loss = 2.63638
I0423 10:18:49.650523 16565 solver.cpp:244]     Train net output #0: loss = 0.964879 (* 1 = 0.964879 loss)
I0423 10:18:49.650530 16565 solver.cpp:244]     Train net output #1: loss = 0.736054 (* 1 = 0.736054 loss)
I0423 10:18:49.650535 16565 solver.cpp:244]     Train net output #2: loss = 0.935445 (* 1 = 0.935445 loss)
I0423 10:18:49.650540 16565 sgd_solver.cpp:106] Iteration 35100, lr = 3e-05
I0423 10:20:29.143550 16565 solver.cpp:228] Iteration 35200, loss = 2.76205
I0423 10:20:29.143743 16565 solver.cpp:244]     Train net output #0: loss = 0.974555 (* 1 = 0.974555 loss)
I0423 10:20:29.143750 16565 solver.cpp:244]     Train net output #1: loss = 0.827849 (* 1 = 0.827849 loss)
I0423 10:20:29.143756 16565 solver.cpp:244]     Train net output #2: loss = 0.959649 (* 1 = 0.959649 loss)
I0423 10:20:29.143762 16565 sgd_solver.cpp:106] Iteration 35200, lr = 3e-05
I0423 10:22:07.233944 16565 solver.cpp:228] Iteration 35300, loss = 2.47075
I0423 10:22:07.234093 16565 solver.cpp:244]     Train net output #0: loss = 0.972073 (* 1 = 0.972073 loss)
I0423 10:22:07.234102 16565 solver.cpp:244]     Train net output #1: loss = 0.734827 (* 1 = 0.734827 loss)
I0423 10:22:07.234107 16565 solver.cpp:244]     Train net output #2: loss = 0.763849 (* 1 = 0.763849 loss)
I0423 10:22:07.234112 16565 sgd_solver.cpp:106] Iteration 35300, lr = 3e-05
I0423 10:23:47.702033 16565 solver.cpp:228] Iteration 35400, loss = 2.42528
I0423 10:23:47.702190 16565 solver.cpp:244]     Train net output #0: loss = 0.973912 (* 1 = 0.973912 loss)
I0423 10:23:47.702198 16565 solver.cpp:244]     Train net output #1: loss = 0.840354 (* 1 = 0.840354 loss)
I0423 10:23:47.702203 16565 solver.cpp:244]     Train net output #2: loss = 0.611015 (* 1 = 0.611015 loss)
I0423 10:23:47.702208 16565 sgd_solver.cpp:106] Iteration 35400, lr = 3e-05
I0423 10:25:28.476763 16565 solver.cpp:228] Iteration 35500, loss = 2.77251
I0423 10:25:28.476938 16565 solver.cpp:244]     Train net output #0: loss = 0.967988 (* 1 = 0.967988 loss)
I0423 10:25:28.476944 16565 solver.cpp:244]     Train net output #1: loss = 0.864711 (* 1 = 0.864711 loss)
I0423 10:25:28.476949 16565 solver.cpp:244]     Train net output #2: loss = 0.939811 (* 1 = 0.939811 loss)
I0423 10:25:28.476955 16565 sgd_solver.cpp:106] Iteration 35500, lr = 3e-05
I0423 10:27:08.285238 16565 solver.cpp:228] Iteration 35600, loss = 2.80663
I0423 10:27:08.285411 16565 solver.cpp:244]     Train net output #0: loss = 0.979336 (* 1 = 0.979336 loss)
I0423 10:27:08.285419 16565 solver.cpp:244]     Train net output #1: loss = 0.90662 (* 1 = 0.90662 loss)
I0423 10:27:08.285425 16565 solver.cpp:244]     Train net output #2: loss = 0.920672 (* 1 = 0.920672 loss)
I0423 10:27:08.285432 16565 sgd_solver.cpp:106] Iteration 35600, lr = 3e-05
I0423 10:28:46.426610 16565 solver.cpp:228] Iteration 35700, loss = 2.42019
I0423 10:28:46.426767 16565 solver.cpp:244]     Train net output #0: loss = 0.985549 (* 1 = 0.985549 loss)
I0423 10:28:46.426775 16565 solver.cpp:244]     Train net output #1: loss = 0.754355 (* 1 = 0.754355 loss)
I0423 10:28:46.426780 16565 solver.cpp:244]     Train net output #2: loss = 0.680285 (* 1 = 0.680285 loss)
I0423 10:28:46.426784 16565 sgd_solver.cpp:106] Iteration 35700, lr = 3e-05
I0423 10:30:26.236667 16565 solver.cpp:228] Iteration 35800, loss = 2.62308
I0423 10:30:26.236874 16565 solver.cpp:244]     Train net output #0: loss = 0.982479 (* 1 = 0.982479 loss)
I0423 10:30:26.236882 16565 solver.cpp:244]     Train net output #1: loss = 0.744416 (* 1 = 0.744416 loss)
I0423 10:30:26.236887 16565 solver.cpp:244]     Train net output #2: loss = 0.896187 (* 1 = 0.896187 loss)
I0423 10:30:26.236892 16565 sgd_solver.cpp:106] Iteration 35800, lr = 3e-05
I0423 10:32:06.007429 16565 solver.cpp:228] Iteration 35900, loss = 2.57349
I0423 10:32:06.007572 16565 solver.cpp:244]     Train net output #0: loss = 0.984895 (* 1 = 0.984895 loss)
I0423 10:32:06.007580 16565 solver.cpp:244]     Train net output #1: loss = 0.820854 (* 1 = 0.820854 loss)
I0423 10:32:06.007585 16565 solver.cpp:244]     Train net output #2: loss = 0.767746 (* 1 = 0.767746 loss)
I0423 10:32:06.007591 16565 sgd_solver.cpp:106] Iteration 35900, lr = 3e-05
I0423 10:33:44.855984 16565 solver.cpp:337] Iteration 36000, Testing net (#0)
I0423 10:33:44.856122 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 10:33:44.856127 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 10:33:44.856132 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 10:33:44.856147 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 10:33:44.856149 16565 net.cpp:693] Ignoring source layer visualize
I0423 10:33:44.856153 16565 net.cpp:693] Ignoring source layer fake
I0423 10:37:18.516907 16565 solver.cpp:404]     Test net output #0: loss = 0.969193 (* 1 = 0.969193 loss)
I0423 10:37:18.517086 16565 solver.cpp:404]     Test net output #1: loss = 0.739618 (* 1 = 0.739618 loss)
I0423 10:37:18.517091 16565 solver.cpp:404]     Test net output #2: loss = 0.817062 (* 1 = 0.817062 loss)
I0423 10:37:19.171210 16565 solver.cpp:228] Iteration 36000, loss = 2.44393
I0423 10:37:19.171234 16565 solver.cpp:244]     Train net output #0: loss = 0.98713 (* 1 = 0.98713 loss)
I0423 10:37:19.171257 16565 solver.cpp:244]     Train net output #1: loss = 0.718082 (* 1 = 0.718082 loss)
I0423 10:37:19.171260 16565 solver.cpp:244]     Train net output #2: loss = 0.738716 (* 1 = 0.738716 loss)
I0423 10:37:19.171263 16565 sgd_solver.cpp:106] Iteration 36000, lr = 3e-05
I0423 10:38:57.430340 16565 solver.cpp:228] Iteration 36100, loss = 2.64855
I0423 10:38:57.432041 16565 solver.cpp:244]     Train net output #0: loss = 0.984583 (* 1 = 0.984583 loss)
I0423 10:38:57.432049 16565 solver.cpp:244]     Train net output #1: loss = 0.73258 (* 1 = 0.73258 loss)
I0423 10:38:57.432054 16565 solver.cpp:244]     Train net output #2: loss = 0.931383 (* 1 = 0.931383 loss)
I0423 10:38:57.432060 16565 sgd_solver.cpp:106] Iteration 36100, lr = 3e-05
I0423 10:40:37.431977 16565 solver.cpp:228] Iteration 36200, loss = 2.36618
I0423 10:40:37.432140 16565 solver.cpp:244]     Train net output #0: loss = 0.991128 (* 1 = 0.991128 loss)
I0423 10:40:37.432148 16565 solver.cpp:244]     Train net output #1: loss = 0.64527 (* 1 = 0.64527 loss)
I0423 10:40:37.432153 16565 solver.cpp:244]     Train net output #2: loss = 0.729779 (* 1 = 0.729779 loss)
I0423 10:40:37.432158 16565 sgd_solver.cpp:106] Iteration 36200, lr = 3e-05
I0423 10:42:16.670830 16565 solver.cpp:228] Iteration 36300, loss = 2.75915
I0423 10:42:16.671006 16565 solver.cpp:244]     Train net output #0: loss = 0.979194 (* 1 = 0.979194 loss)
I0423 10:42:16.671015 16565 solver.cpp:244]     Train net output #1: loss = 0.826681 (* 1 = 0.826681 loss)
I0423 10:42:16.671020 16565 solver.cpp:244]     Train net output #2: loss = 0.95327 (* 1 = 0.95327 loss)
I0423 10:42:16.671025 16565 sgd_solver.cpp:106] Iteration 36300, lr = 3e-05
I0423 10:43:55.959404 16565 solver.cpp:228] Iteration 36400, loss = 2.38856
I0423 10:43:55.959549 16565 solver.cpp:244]     Train net output #0: loss = 0.959792 (* 1 = 0.959792 loss)
I0423 10:43:55.959558 16565 solver.cpp:244]     Train net output #1: loss = 0.80046 (* 1 = 0.80046 loss)
I0423 10:43:55.959563 16565 solver.cpp:244]     Train net output #2: loss = 0.62831 (* 1 = 0.62831 loss)
I0423 10:43:55.959566 16565 sgd_solver.cpp:106] Iteration 36400, lr = 3e-05
I0423 10:45:36.248620 16565 solver.cpp:228] Iteration 36500, loss = 2.32892
I0423 10:45:36.248801 16565 solver.cpp:244]     Train net output #0: loss = 0.978328 (* 1 = 0.978328 loss)
I0423 10:45:36.248809 16565 solver.cpp:244]     Train net output #1: loss = 0.780224 (* 1 = 0.780224 loss)
I0423 10:45:36.248814 16565 solver.cpp:244]     Train net output #2: loss = 0.570366 (* 1 = 0.570366 loss)
I0423 10:45:36.248819 16565 sgd_solver.cpp:106] Iteration 36500, lr = 3e-05
I0423 10:47:15.974171 16565 solver.cpp:228] Iteration 36600, loss = 2.65192
I0423 10:47:15.974364 16565 solver.cpp:244]     Train net output #0: loss = 0.953846 (* 1 = 0.953846 loss)
I0423 10:47:15.974371 16565 solver.cpp:244]     Train net output #1: loss = 0.808364 (* 1 = 0.808364 loss)
I0423 10:47:15.974377 16565 solver.cpp:244]     Train net output #2: loss = 0.889711 (* 1 = 0.889711 loss)
I0423 10:47:15.974382 16565 sgd_solver.cpp:106] Iteration 36600, lr = 3e-05
I0423 10:48:56.030635 16565 solver.cpp:228] Iteration 36700, loss = 2.70098
I0423 10:48:56.030810 16565 solver.cpp:244]     Train net output #0: loss = 0.959639 (* 1 = 0.959639 loss)
I0423 10:48:56.030819 16565 solver.cpp:244]     Train net output #1: loss = 0.816866 (* 1 = 0.816866 loss)
I0423 10:48:56.030824 16565 solver.cpp:244]     Train net output #2: loss = 0.924471 (* 1 = 0.924471 loss)
I0423 10:48:56.030829 16565 sgd_solver.cpp:106] Iteration 36700, lr = 3e-05
I0423 10:50:34.208534 16565 solver.cpp:228] Iteration 36800, loss = 2.5971
I0423 10:50:34.208700 16565 solver.cpp:244]     Train net output #0: loss = 0.965631 (* 1 = 0.965631 loss)
I0423 10:50:34.208709 16565 solver.cpp:244]     Train net output #1: loss = 0.786914 (* 1 = 0.786914 loss)
I0423 10:50:34.208714 16565 solver.cpp:244]     Train net output #2: loss = 0.844557 (* 1 = 0.844557 loss)
I0423 10:50:34.208720 16565 sgd_solver.cpp:106] Iteration 36800, lr = 3e-05
I0423 10:52:16.739621 16565 solver.cpp:228] Iteration 36900, loss = 2.54531
I0423 10:52:16.740949 16565 solver.cpp:244]     Train net output #0: loss = 0.985871 (* 1 = 0.985871 loss)
I0423 10:52:16.740957 16565 solver.cpp:244]     Train net output #1: loss = 0.676378 (* 1 = 0.676378 loss)
I0423 10:52:16.740962 16565 solver.cpp:244]     Train net output #2: loss = 0.883062 (* 1 = 0.883062 loss)
I0423 10:52:16.740967 16565 sgd_solver.cpp:106] Iteration 36900, lr = 3e-05
I0423 10:53:57.138232 16565 solver.cpp:337] Iteration 37000, Testing net (#0)
I0423 10:53:57.138473 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 10:53:57.138485 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 10:53:57.138490 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 10:53:57.138504 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 10:53:57.138509 16565 net.cpp:693] Ignoring source layer visualize
I0423 10:53:57.138510 16565 net.cpp:693] Ignoring source layer fake
I0423 10:57:31.591769 16565 solver.cpp:404]     Test net output #0: loss = 0.974233 (* 1 = 0.974233 loss)
I0423 10:57:31.591924 16565 solver.cpp:404]     Test net output #1: loss = 0.730321 (* 1 = 0.730321 loss)
I0423 10:57:31.591933 16565 solver.cpp:404]     Test net output #2: loss = 0.801724 (* 1 = 0.801724 loss)
I0423 10:57:32.244959 16565 solver.cpp:228] Iteration 37000, loss = 2.51404
I0423 10:57:32.245003 16565 solver.cpp:244]     Train net output #0: loss = 0.98216 (* 1 = 0.98216 loss)
I0423 10:57:32.245009 16565 solver.cpp:244]     Train net output #1: loss = 0.722104 (* 1 = 0.722104 loss)
I0423 10:57:32.245013 16565 solver.cpp:244]     Train net output #2: loss = 0.80978 (* 1 = 0.80978 loss)
I0423 10:57:32.245018 16565 sgd_solver.cpp:106] Iteration 37000, lr = 3e-05
I0423 10:59:10.458456 16565 solver.cpp:228] Iteration 37100, loss = 2.72033
I0423 10:59:10.458633 16565 solver.cpp:244]     Train net output #0: loss = 0.989434 (* 1 = 0.989434 loss)
I0423 10:59:10.458642 16565 solver.cpp:244]     Train net output #1: loss = 0.818581 (* 1 = 0.818581 loss)
I0423 10:59:10.458647 16565 solver.cpp:244]     Train net output #2: loss = 0.912317 (* 1 = 0.912317 loss)
I0423 10:59:10.458652 16565 sgd_solver.cpp:106] Iteration 37100, lr = 3e-05
I0423 11:00:51.376492 16565 solver.cpp:228] Iteration 37200, loss = 2.5507
I0423 11:00:51.378305 16565 solver.cpp:244]     Train net output #0: loss = 0.985539 (* 1 = 0.985539 loss)
I0423 11:00:51.378314 16565 solver.cpp:244]     Train net output #1: loss = 0.666082 (* 1 = 0.666082 loss)
I0423 11:00:51.378320 16565 solver.cpp:244]     Train net output #2: loss = 0.899083 (* 1 = 0.899083 loss)
I0423 11:00:51.378324 16565 sgd_solver.cpp:106] Iteration 37200, lr = 3e-05
I0423 11:02:31.463851 16565 solver.cpp:228] Iteration 37300, loss = 2.2353
I0423 11:02:31.464038 16565 solver.cpp:244]     Train net output #0: loss = 0.978691 (* 1 = 0.978691 loss)
I0423 11:02:31.464046 16565 solver.cpp:244]     Train net output #1: loss = 0.639036 (* 1 = 0.639036 loss)
I0423 11:02:31.464051 16565 solver.cpp:244]     Train net output #2: loss = 0.617572 (* 1 = 0.617572 loss)
I0423 11:02:31.464057 16565 sgd_solver.cpp:106] Iteration 37300, lr = 3e-05
I0423 11:04:15.479322 16565 solver.cpp:228] Iteration 37400, loss = 2.13234
I0423 11:04:15.479504 16565 solver.cpp:244]     Train net output #0: loss = 0.982216 (* 1 = 0.982216 loss)
I0423 11:04:15.479518 16565 solver.cpp:244]     Train net output #1: loss = 0.607702 (* 1 = 0.607702 loss)
I0423 11:04:15.479523 16565 solver.cpp:244]     Train net output #2: loss = 0.542424 (* 1 = 0.542424 loss)
I0423 11:04:15.479528 16565 sgd_solver.cpp:106] Iteration 37400, lr = 3e-05
I0423 11:05:54.792680 16565 solver.cpp:228] Iteration 37500, loss = 2.59588
I0423 11:05:54.792840 16565 solver.cpp:244]     Train net output #0: loss = 0.975711 (* 1 = 0.975711 loss)
I0423 11:05:54.792846 16565 solver.cpp:244]     Train net output #1: loss = 0.853533 (* 1 = 0.853533 loss)
I0423 11:05:54.792851 16565 solver.cpp:244]     Train net output #2: loss = 0.766638 (* 1 = 0.766638 loss)
I0423 11:05:54.792858 16565 sgd_solver.cpp:106] Iteration 37500, lr = 3e-05
I0423 11:07:33.955587 16565 solver.cpp:228] Iteration 37600, loss = 2.33984
I0423 11:07:33.955759 16565 solver.cpp:244]     Train net output #0: loss = 0.962644 (* 1 = 0.962644 loss)
I0423 11:07:33.955766 16565 solver.cpp:244]     Train net output #1: loss = 0.61266 (* 1 = 0.61266 loss)
I0423 11:07:33.955772 16565 solver.cpp:244]     Train net output #2: loss = 0.764533 (* 1 = 0.764533 loss)
I0423 11:07:33.955777 16565 sgd_solver.cpp:106] Iteration 37600, lr = 3e-05
I0423 11:09:13.403245 16565 solver.cpp:228] Iteration 37700, loss = 2.35165
I0423 11:09:13.403419 16565 solver.cpp:244]     Train net output #0: loss = 0.984543 (* 1 = 0.984543 loss)
I0423 11:09:13.403429 16565 solver.cpp:244]     Train net output #1: loss = 0.787864 (* 1 = 0.787864 loss)
I0423 11:09:13.403434 16565 solver.cpp:244]     Train net output #2: loss = 0.57924 (* 1 = 0.57924 loss)
I0423 11:09:13.403439 16565 sgd_solver.cpp:106] Iteration 37700, lr = 3e-05
I0423 11:10:51.570469 16565 solver.cpp:228] Iteration 37800, loss = 2.51487
I0423 11:10:51.570616 16565 solver.cpp:244]     Train net output #0: loss = 0.978364 (* 1 = 0.978364 loss)
I0423 11:10:51.570624 16565 solver.cpp:244]     Train net output #1: loss = 0.772827 (* 1 = 0.772827 loss)
I0423 11:10:51.570629 16565 solver.cpp:244]     Train net output #2: loss = 0.763682 (* 1 = 0.763682 loss)
I0423 11:10:51.570634 16565 sgd_solver.cpp:106] Iteration 37800, lr = 3e-05
I0423 11:12:31.357157 16565 solver.cpp:228] Iteration 37900, loss = 2.67138
I0423 11:12:31.357347 16565 solver.cpp:244]     Train net output #0: loss = 0.96503 (* 1 = 0.96503 loss)
I0423 11:12:31.357354 16565 solver.cpp:244]     Train net output #1: loss = 0.83095 (* 1 = 0.83095 loss)
I0423 11:12:31.357359 16565 solver.cpp:244]     Train net output #2: loss = 0.875395 (* 1 = 0.875395 loss)
I0423 11:12:31.357365 16565 sgd_solver.cpp:106] Iteration 37900, lr = 3e-05
I0423 11:14:10.338310 16565 solver.cpp:337] Iteration 38000, Testing net (#0)
I0423 11:14:10.338511 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 11:14:10.338516 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 11:14:10.338521 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 11:14:10.338536 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 11:14:10.338539 16565 net.cpp:693] Ignoring source layer visualize
I0423 11:14:10.338541 16565 net.cpp:693] Ignoring source layer fake
I0423 11:17:44.362669 16565 solver.cpp:404]     Test net output #0: loss = 0.971437 (* 1 = 0.971437 loss)
I0423 11:17:44.362808 16565 solver.cpp:404]     Test net output #1: loss = 0.723266 (* 1 = 0.723266 loss)
I0423 11:17:44.362817 16565 solver.cpp:404]     Test net output #2: loss = 0.802376 (* 1 = 0.802376 loss)
I0423 11:17:45.017428 16565 solver.cpp:228] Iteration 38000, loss = 2.7052
I0423 11:17:45.017474 16565 solver.cpp:244]     Train net output #0: loss = 0.962392 (* 1 = 0.962392 loss)
I0423 11:17:45.017480 16565 solver.cpp:244]     Train net output #1: loss = 0.817768 (* 1 = 0.817768 loss)
I0423 11:17:45.017484 16565 solver.cpp:244]     Train net output #2: loss = 0.925044 (* 1 = 0.925044 loss)
I0423 11:17:45.017488 16565 sgd_solver.cpp:106] Iteration 38000, lr = 3e-05
I0423 11:19:24.890008 16565 solver.cpp:228] Iteration 38100, loss = 2.68727
I0423 11:19:24.890161 16565 solver.cpp:244]     Train net output #0: loss = 0.963546 (* 1 = 0.963546 loss)
I0423 11:19:24.890169 16565 solver.cpp:244]     Train net output #1: loss = 0.819327 (* 1 = 0.819327 loss)
I0423 11:19:24.890174 16565 solver.cpp:244]     Train net output #2: loss = 0.904401 (* 1 = 0.904401 loss)
I0423 11:19:24.890182 16565 sgd_solver.cpp:106] Iteration 38100, lr = 3e-05
I0423 11:21:03.095338 16565 solver.cpp:228] Iteration 38200, loss = 2.50914
I0423 11:21:03.095485 16565 solver.cpp:244]     Train net output #0: loss = 0.975088 (* 1 = 0.975088 loss)
I0423 11:21:03.095494 16565 solver.cpp:244]     Train net output #1: loss = 0.644139 (* 1 = 0.644139 loss)
I0423 11:21:03.095499 16565 solver.cpp:244]     Train net output #2: loss = 0.889911 (* 1 = 0.889911 loss)
I0423 11:21:03.095504 16565 sgd_solver.cpp:106] Iteration 38200, lr = 3e-05
I0423 11:22:43.001981 16565 solver.cpp:228] Iteration 38300, loss = 2.72294
I0423 11:22:43.002135 16565 solver.cpp:244]     Train net output #0: loss = 0.986517 (* 1 = 0.986517 loss)
I0423 11:22:43.002153 16565 solver.cpp:244]     Train net output #1: loss = 0.812657 (* 1 = 0.812657 loss)
I0423 11:22:43.002158 16565 solver.cpp:244]     Train net output #2: loss = 0.923761 (* 1 = 0.923761 loss)
I0423 11:22:43.002164 16565 sgd_solver.cpp:106] Iteration 38300, lr = 3e-05
I0423 11:24:22.771442 16565 solver.cpp:228] Iteration 38400, loss = 2.70045
I0423 11:24:22.771613 16565 solver.cpp:244]     Train net output #0: loss = 0.985004 (* 1 = 0.985004 loss)
I0423 11:24:22.771621 16565 solver.cpp:244]     Train net output #1: loss = 0.819548 (* 1 = 0.819548 loss)
I0423 11:24:22.771626 16565 solver.cpp:244]     Train net output #2: loss = 0.8959 (* 1 = 0.8959 loss)
I0423 11:24:22.771631 16565 sgd_solver.cpp:106] Iteration 38400, lr = 3e-05
I0423 11:26:02.724750 16565 solver.cpp:228] Iteration 38500, loss = 2.22423
I0423 11:26:02.724905 16565 solver.cpp:244]     Train net output #0: loss = 0.982474 (* 1 = 0.982474 loss)
I0423 11:26:02.724918 16565 solver.cpp:244]     Train net output #1: loss = 0.66896 (* 1 = 0.66896 loss)
I0423 11:26:02.724925 16565 solver.cpp:244]     Train net output #2: loss = 0.572798 (* 1 = 0.572798 loss)
I0423 11:26:02.724930 16565 sgd_solver.cpp:106] Iteration 38500, lr = 3e-05
I0423 11:27:40.843551 16565 solver.cpp:228] Iteration 38600, loss = 2.15333
I0423 11:27:40.843732 16565 solver.cpp:244]     Train net output #0: loss = 0.987244 (* 1 = 0.987244 loss)
I0423 11:27:40.843739 16565 solver.cpp:244]     Train net output #1: loss = 0.592277 (* 1 = 0.592277 loss)
I0423 11:27:40.843745 16565 solver.cpp:244]     Train net output #2: loss = 0.573805 (* 1 = 0.573805 loss)
I0423 11:27:40.843750 16565 sgd_solver.cpp:106] Iteration 38600, lr = 3e-05
I0423 11:29:20.516510 16565 solver.cpp:228] Iteration 38700, loss = 2.29482
I0423 11:29:20.516682 16565 solver.cpp:244]     Train net output #0: loss = 0.990857 (* 1 = 0.990857 loss)
I0423 11:29:20.516693 16565 solver.cpp:244]     Train net output #1: loss = 0.617264 (* 1 = 0.617264 loss)
I0423 11:29:20.516698 16565 solver.cpp:244]     Train net output #2: loss = 0.686698 (* 1 = 0.686698 loss)
I0423 11:29:20.516705 16565 sgd_solver.cpp:106] Iteration 38700, lr = 3e-05
I0423 11:30:59.776566 16565 solver.cpp:228] Iteration 38800, loss = 2.56143
I0423 11:30:59.776723 16565 solver.cpp:244]     Train net output #0: loss = 0.980932 (* 1 = 0.980932 loss)
I0423 11:30:59.776731 16565 solver.cpp:244]     Train net output #1: loss = 0.81517 (* 1 = 0.81517 loss)
I0423 11:30:59.776736 16565 solver.cpp:244]     Train net output #2: loss = 0.76533 (* 1 = 0.76533 loss)
I0423 11:30:59.776741 16565 sgd_solver.cpp:106] Iteration 38800, lr = 3e-05
I0423 11:32:39.092397 16565 solver.cpp:228] Iteration 38900, loss = 2.30007
I0423 11:32:39.092566 16565 solver.cpp:244]     Train net output #0: loss = 0.981679 (* 1 = 0.981679 loss)
I0423 11:32:39.092573 16565 solver.cpp:244]     Train net output #1: loss = 0.722453 (* 1 = 0.722453 loss)
I0423 11:32:39.092577 16565 solver.cpp:244]     Train net output #2: loss = 0.595943 (* 1 = 0.595943 loss)
I0423 11:32:39.092583 16565 sgd_solver.cpp:106] Iteration 38900, lr = 3e-05
I0423 11:34:17.694828 16565 solver.cpp:337] Iteration 39000, Testing net (#0)
I0423 11:34:17.696410 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 11:34:17.696416 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 11:34:17.696420 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 11:34:17.696439 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 11:34:17.696441 16565 net.cpp:693] Ignoring source layer visualize
I0423 11:34:17.696442 16565 net.cpp:693] Ignoring source layer fake
I0423 11:37:51.548847 16565 solver.cpp:404]     Test net output #0: loss = 0.97485 (* 1 = 0.97485 loss)
I0423 11:37:51.548979 16565 solver.cpp:404]     Test net output #1: loss = 0.747311 (* 1 = 0.747311 loss)
I0423 11:37:51.548985 16565 solver.cpp:404]     Test net output #2: loss = 0.813759 (* 1 = 0.813759 loss)
I0423 11:37:52.203872 16565 solver.cpp:228] Iteration 39000, loss = 2.61685
I0423 11:37:52.203899 16565 solver.cpp:244]     Train net output #0: loss = 0.987039 (* 1 = 0.987039 loss)
I0423 11:37:52.203904 16565 solver.cpp:244]     Train net output #1: loss = 0.875204 (* 1 = 0.875204 loss)
I0423 11:37:52.203908 16565 solver.cpp:244]     Train net output #2: loss = 0.754602 (* 1 = 0.754602 loss)
I0423 11:37:52.203913 16565 sgd_solver.cpp:106] Iteration 39000, lr = 3e-05
I0423 11:39:31.974560 16565 solver.cpp:228] Iteration 39100, loss = 2.53857
I0423 11:39:31.974712 16565 solver.cpp:244]     Train net output #0: loss = 0.96894 (* 1 = 0.96894 loss)
I0423 11:39:31.974720 16565 solver.cpp:244]     Train net output #1: loss = 0.86377 (* 1 = 0.86377 loss)
I0423 11:39:31.974725 16565 solver.cpp:244]     Train net output #2: loss = 0.705864 (* 1 = 0.705864 loss)
I0423 11:39:31.974730 16565 sgd_solver.cpp:106] Iteration 39100, lr = 3e-05
I0423 11:41:11.775498 16565 solver.cpp:228] Iteration 39200, loss = 2.79178
I0423 11:41:11.777709 16565 solver.cpp:244]     Train net output #0: loss = 0.96722 (* 1 = 0.96722 loss)
I0423 11:41:11.777716 16565 solver.cpp:244]     Train net output #1: loss = 0.892315 (* 1 = 0.892315 loss)
I0423 11:41:11.777721 16565 solver.cpp:244]     Train net output #2: loss = 0.932242 (* 1 = 0.932242 loss)
I0423 11:41:11.777726 16565 sgd_solver.cpp:106] Iteration 39200, lr = 3e-05
I0423 11:42:49.881564 16565 solver.cpp:228] Iteration 39300, loss = 2.71375
I0423 11:42:49.881714 16565 solver.cpp:244]     Train net output #0: loss = 0.981091 (* 1 = 0.981091 loss)
I0423 11:42:49.881723 16565 solver.cpp:244]     Train net output #1: loss = 0.872811 (* 1 = 0.872811 loss)
I0423 11:42:49.881727 16565 solver.cpp:244]     Train net output #2: loss = 0.859847 (* 1 = 0.859847 loss)
I0423 11:42:49.881732 16565 sgd_solver.cpp:106] Iteration 39300, lr = 3e-05
I0423 11:44:30.012397 16565 solver.cpp:228] Iteration 39400, loss = 2.70466
I0423 11:44:30.012557 16565 solver.cpp:244]     Train net output #0: loss = 0.987872 (* 1 = 0.987872 loss)
I0423 11:44:30.012567 16565 solver.cpp:244]     Train net output #1: loss = 0.827401 (* 1 = 0.827401 loss)
I0423 11:44:30.012572 16565 solver.cpp:244]     Train net output #2: loss = 0.889383 (* 1 = 0.889383 loss)
I0423 11:44:30.012576 16565 sgd_solver.cpp:106] Iteration 39400, lr = 3e-05
I0423 11:46:10.075662 16565 solver.cpp:228] Iteration 39500, loss = 2.72162
I0423 11:46:10.075809 16565 solver.cpp:244]     Train net output #0: loss = 0.982806 (* 1 = 0.982806 loss)
I0423 11:46:10.075816 16565 solver.cpp:244]     Train net output #1: loss = 0.824505 (* 1 = 0.824505 loss)
I0423 11:46:10.075821 16565 solver.cpp:244]     Train net output #2: loss = 0.914311 (* 1 = 0.914311 loss)
I0423 11:46:10.075827 16565 sgd_solver.cpp:106] Iteration 39500, lr = 3e-05
I0423 11:47:48.220360 16565 solver.cpp:228] Iteration 39600, loss = 2.66255
I0423 11:47:48.220511 16565 solver.cpp:244]     Train net output #0: loss = 0.976802 (* 1 = 0.976802 loss)
I0423 11:47:48.220520 16565 solver.cpp:244]     Train net output #1: loss = 0.784706 (* 1 = 0.784706 loss)
I0423 11:47:48.220525 16565 solver.cpp:244]     Train net output #2: loss = 0.901041 (* 1 = 0.901041 loss)
I0423 11:47:48.220530 16565 sgd_solver.cpp:106] Iteration 39600, lr = 3e-05
I0423 11:49:28.014978 16565 solver.cpp:228] Iteration 39700, loss = 2.41159
I0423 11:49:28.015141 16565 solver.cpp:244]     Train net output #0: loss = 0.989142 (* 1 = 0.989142 loss)
I0423 11:49:28.015149 16565 solver.cpp:244]     Train net output #1: loss = 0.658611 (* 1 = 0.658611 loss)
I0423 11:49:28.015154 16565 solver.cpp:244]     Train net output #2: loss = 0.763839 (* 1 = 0.763839 loss)
I0423 11:49:28.015159 16565 sgd_solver.cpp:106] Iteration 39700, lr = 3e-05
I0423 11:51:07.769932 16565 solver.cpp:228] Iteration 39800, loss = 2.53963
I0423 11:51:07.770087 16565 solver.cpp:244]     Train net output #0: loss = 0.986101 (* 1 = 0.986101 loss)
I0423 11:51:07.770094 16565 solver.cpp:244]     Train net output #1: loss = 0.788431 (* 1 = 0.788431 loss)
I0423 11:51:07.770099 16565 solver.cpp:244]     Train net output #2: loss = 0.765102 (* 1 = 0.765102 loss)
I0423 11:51:07.770104 16565 sgd_solver.cpp:106] Iteration 39800, lr = 3e-05
I0423 11:52:47.390878 16565 solver.cpp:228] Iteration 39900, loss = 2.15997
I0423 11:52:47.391036 16565 solver.cpp:244]     Train net output #0: loss = 0.941582 (* 1 = 0.941582 loss)
I0423 11:52:47.391044 16565 solver.cpp:244]     Train net output #1: loss = 0.52041 (* 1 = 0.52041 loss)
I0423 11:52:47.391049 16565 solver.cpp:244]     Train net output #2: loss = 0.697979 (* 1 = 0.697979 loss)
I0423 11:52:47.391055 16565 sgd_solver.cpp:106] Iteration 39900, lr = 3e-05
I0423 11:54:25.678380 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_40000.caffemodel
I0423 11:54:45.661478 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_40000.solverstate
I0423 11:54:45.856355 16565 solver.cpp:337] Iteration 40000, Testing net (#0)
I0423 11:54:45.856398 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 11:54:45.856400 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 11:54:45.856405 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 11:54:45.856417 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 11:54:45.856421 16565 net.cpp:693] Ignoring source layer visualize
I0423 11:54:45.856422 16565 net.cpp:693] Ignoring source layer fake
I0423 11:58:19.182332 16565 solver.cpp:404]     Test net output #0: loss = 0.973661 (* 1 = 0.973661 loss)
I0423 11:58:19.182478 16565 solver.cpp:404]     Test net output #1: loss = 0.746394 (* 1 = 0.746394 loss)
I0423 11:58:19.182487 16565 solver.cpp:404]     Test net output #2: loss = 0.809911 (* 1 = 0.809911 loss)
I0423 11:58:19.840126 16565 solver.cpp:228] Iteration 40000, loss = 2.78916
I0423 11:58:19.840167 16565 solver.cpp:244]     Train net output #0: loss = 0.966979 (* 1 = 0.966979 loss)
I0423 11:58:19.840173 16565 solver.cpp:244]     Train net output #1: loss = 0.859327 (* 1 = 0.859327 loss)
I0423 11:58:19.840178 16565 solver.cpp:244]     Train net output #2: loss = 0.96285 (* 1 = 0.96285 loss)
I0423 11:58:19.840181 16565 sgd_solver.cpp:106] Iteration 40000, lr = 9e-06
I0423 11:59:59.189998 16565 solver.cpp:228] Iteration 40100, loss = 2.67236
I0423 11:59:59.190181 16565 solver.cpp:244]     Train net output #0: loss = 0.957776 (* 1 = 0.957776 loss)
I0423 11:59:59.190191 16565 solver.cpp:244]     Train net output #1: loss = 0.776367 (* 1 = 0.776367 loss)
I0423 11:59:59.190196 16565 solver.cpp:244]     Train net output #2: loss = 0.938221 (* 1 = 0.938221 loss)
I0423 11:59:59.190201 16565 sgd_solver.cpp:106] Iteration 40100, lr = 9e-06
I0423 12:01:39.808473 16565 solver.cpp:228] Iteration 40200, loss = 2.59154
I0423 12:01:39.808662 16565 solver.cpp:244]     Train net output #0: loss = 0.983126 (* 1 = 0.983126 loss)
I0423 12:01:39.808670 16565 solver.cpp:244]     Train net output #1: loss = 0.843838 (* 1 = 0.843838 loss)
I0423 12:01:39.808676 16565 solver.cpp:244]     Train net output #2: loss = 0.764576 (* 1 = 0.764576 loss)
I0423 12:01:39.808679 16565 sgd_solver.cpp:106] Iteration 40200, lr = 9e-06
I0423 12:03:17.986215 16565 solver.cpp:228] Iteration 40300, loss = 2.79571
I0423 12:03:17.986389 16565 solver.cpp:244]     Train net output #0: loss = 0.976824 (* 1 = 0.976824 loss)
I0423 12:03:17.986397 16565 solver.cpp:244]     Train net output #1: loss = 0.859956 (* 1 = 0.859956 loss)
I0423 12:03:17.986402 16565 solver.cpp:244]     Train net output #2: loss = 0.958926 (* 1 = 0.958926 loss)
I0423 12:03:17.986408 16565 sgd_solver.cpp:106] Iteration 40300, lr = 9e-06
I0423 12:04:57.768607 16565 solver.cpp:228] Iteration 40400, loss = 2.64106
I0423 12:04:57.769897 16565 solver.cpp:244]     Train net output #0: loss = 0.959055 (* 1 = 0.959055 loss)
I0423 12:04:57.769906 16565 solver.cpp:244]     Train net output #1: loss = 0.815929 (* 1 = 0.815929 loss)
I0423 12:04:57.769912 16565 solver.cpp:244]     Train net output #2: loss = 0.866072 (* 1 = 0.866072 loss)
I0423 12:04:57.769915 16565 sgd_solver.cpp:106] Iteration 40400, lr = 9e-06
I0423 12:06:38.514529 16565 solver.cpp:228] Iteration 40500, loss = 2.73564
I0423 12:06:38.514693 16565 solver.cpp:244]     Train net output #0: loss = 0.971807 (* 1 = 0.971807 loss)
I0423 12:06:38.514703 16565 solver.cpp:244]     Train net output #1: loss = 0.849506 (* 1 = 0.849506 loss)
I0423 12:06:38.514708 16565 solver.cpp:244]     Train net output #2: loss = 0.914331 (* 1 = 0.914331 loss)
I0423 12:06:38.514713 16565 sgd_solver.cpp:106] Iteration 40500, lr = 9e-06
I0423 12:08:19.938860 16565 solver.cpp:228] Iteration 40600, loss = 2.71435
I0423 12:08:19.940027 16565 solver.cpp:244]     Train net output #0: loss = 0.96378 (* 1 = 0.96378 loss)
I0423 12:08:19.940034 16565 solver.cpp:244]     Train net output #1: loss = 0.823377 (* 1 = 0.823377 loss)
I0423 12:08:19.940038 16565 solver.cpp:244]     Train net output #2: loss = 0.927189 (* 1 = 0.927189 loss)
I0423 12:08:19.940044 16565 sgd_solver.cpp:106] Iteration 40600, lr = 9e-06
I0423 12:09:58.047719 16565 solver.cpp:228] Iteration 40700, loss = 2.72843
I0423 12:09:58.047863 16565 solver.cpp:244]     Train net output #0: loss = 0.989708 (* 1 = 0.989708 loss)
I0423 12:09:58.047871 16565 solver.cpp:244]     Train net output #1: loss = 0.823748 (* 1 = 0.823748 loss)
I0423 12:09:58.047876 16565 solver.cpp:244]     Train net output #2: loss = 0.914972 (* 1 = 0.914972 loss)
I0423 12:09:58.047883 16565 sgd_solver.cpp:106] Iteration 40700, lr = 9e-06
I0423 12:11:38.132221 16565 solver.cpp:228] Iteration 40800, loss = 2.62139
I0423 12:11:38.132364 16565 solver.cpp:244]     Train net output #0: loss = 0.985571 (* 1 = 0.985571 loss)
I0423 12:11:38.132370 16565 solver.cpp:244]     Train net output #1: loss = 0.785732 (* 1 = 0.785732 loss)
I0423 12:11:38.132376 16565 solver.cpp:244]     Train net output #2: loss = 0.850088 (* 1 = 0.850088 loss)
I0423 12:11:38.132381 16565 sgd_solver.cpp:106] Iteration 40800, lr = 9e-06
I0423 12:13:18.132737 16565 solver.cpp:228] Iteration 40900, loss = 2.61738
I0423 12:13:18.132907 16565 solver.cpp:244]     Train net output #0: loss = 0.982812 (* 1 = 0.982812 loss)
I0423 12:13:18.132917 16565 solver.cpp:244]     Train net output #1: loss = 0.731431 (* 1 = 0.731431 loss)
I0423 12:13:18.132922 16565 solver.cpp:244]     Train net output #2: loss = 0.903137 (* 1 = 0.903137 loss)
I0423 12:13:18.132926 16565 sgd_solver.cpp:106] Iteration 40900, lr = 9e-06
I0423 12:14:57.553753 16565 solver.cpp:337] Iteration 41000, Testing net (#0)
I0423 12:14:57.553908 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 12:14:57.553912 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 12:14:57.553916 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 12:14:57.553931 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 12:14:57.553936 16565 net.cpp:693] Ignoring source layer visualize
I0423 12:14:57.553938 16565 net.cpp:693] Ignoring source layer fake
I0423 12:18:31.924222 16565 solver.cpp:404]     Test net output #0: loss = 0.963348 (* 1 = 0.963348 loss)
I0423 12:18:31.924357 16565 solver.cpp:404]     Test net output #1: loss = 0.732674 (* 1 = 0.732674 loss)
I0423 12:18:31.924365 16565 solver.cpp:404]     Test net output #2: loss = 0.825396 (* 1 = 0.825396 loss)
I0423 12:18:32.573122 16565 solver.cpp:228] Iteration 41000, loss = 2.41968
I0423 12:18:32.573171 16565 solver.cpp:244]     Train net output #0: loss = 0.986462 (* 1 = 0.986462 loss)
I0423 12:18:32.573176 16565 solver.cpp:244]     Train net output #1: loss = 0.667925 (* 1 = 0.667925 loss)
I0423 12:18:32.573181 16565 solver.cpp:244]     Train net output #2: loss = 0.765293 (* 1 = 0.765293 loss)
I0423 12:18:32.573186 16565 sgd_solver.cpp:106] Iteration 41000, lr = 9e-06
I0423 12:20:10.729360 16565 solver.cpp:228] Iteration 41100, loss = 2.10995
I0423 12:20:10.729511 16565 solver.cpp:244]     Train net output #0: loss = 0.991019 (* 1 = 0.991019 loss)
I0423 12:20:10.729519 16565 solver.cpp:244]     Train net output #1: loss = 0.556917 (* 1 = 0.556917 loss)
I0423 12:20:10.729524 16565 solver.cpp:244]     Train net output #2: loss = 0.562013 (* 1 = 0.562013 loss)
I0423 12:20:10.729529 16565 sgd_solver.cpp:106] Iteration 41100, lr = 9e-06
I0423 12:21:50.537838 16565 solver.cpp:228] Iteration 41200, loss = 2.78723
I0423 12:21:50.538019 16565 solver.cpp:244]     Train net output #0: loss = 0.991754 (* 1 = 0.991754 loss)
I0423 12:21:50.538028 16565 solver.cpp:244]     Train net output #1: loss = 0.848629 (* 1 = 0.848629 loss)
I0423 12:21:50.538033 16565 solver.cpp:244]     Train net output #2: loss = 0.946849 (* 1 = 0.946849 loss)
I0423 12:21:50.538038 16565 sgd_solver.cpp:106] Iteration 41200, lr = 9e-06
I0423 12:23:29.858019 16565 solver.cpp:228] Iteration 41300, loss = 2.7525
I0423 12:23:29.858188 16565 solver.cpp:244]     Train net output #0: loss = 0.976467 (* 1 = 0.976467 loss)
I0423 12:23:29.858196 16565 solver.cpp:244]     Train net output #1: loss = 0.819104 (* 1 = 0.819104 loss)
I0423 12:23:29.858201 16565 solver.cpp:244]     Train net output #2: loss = 0.956928 (* 1 = 0.956928 loss)
I0423 12:23:29.858206 16565 sgd_solver.cpp:106] Iteration 41300, lr = 9e-06
I0423 12:25:09.148542 16565 solver.cpp:228] Iteration 41400, loss = 2.38984
I0423 12:25:09.148710 16565 solver.cpp:244]     Train net output #0: loss = 0.96474 (* 1 = 0.96474 loss)
I0423 12:25:09.148718 16565 solver.cpp:244]     Train net output #1: loss = 0.67696 (* 1 = 0.67696 loss)
I0423 12:25:09.148725 16565 solver.cpp:244]     Train net output #2: loss = 0.748139 (* 1 = 0.748139 loss)
I0423 12:25:09.148730 16565 sgd_solver.cpp:106] Iteration 41400, lr = 9e-06
I0423 12:26:48.758252 16565 solver.cpp:228] Iteration 41500, loss = 2.40242
I0423 12:26:48.758404 16565 solver.cpp:244]     Train net output #0: loss = 0.990787 (* 1 = 0.990787 loss)
I0423 12:26:48.758412 16565 solver.cpp:244]     Train net output #1: loss = 0.828494 (* 1 = 0.828494 loss)
I0423 12:26:48.758417 16565 solver.cpp:244]     Train net output #2: loss = 0.583142 (* 1 = 0.583142 loss)
I0423 12:26:48.758421 16565 sgd_solver.cpp:106] Iteration 41500, lr = 9e-06
I0423 12:28:29.480232 16565 solver.cpp:228] Iteration 41600, loss = 2.5696
I0423 12:28:29.480430 16565 solver.cpp:244]     Train net output #0: loss = 0.960386 (* 1 = 0.960386 loss)
I0423 12:28:29.480439 16565 solver.cpp:244]     Train net output #1: loss = 0.81744 (* 1 = 0.81744 loss)
I0423 12:28:29.480444 16565 solver.cpp:244]     Train net output #2: loss = 0.79177 (* 1 = 0.79177 loss)
I0423 12:28:29.480450 16565 sgd_solver.cpp:106] Iteration 41600, lr = 9e-06
I0423 12:30:09.648361 16565 solver.cpp:228] Iteration 41700, loss = 2.76206
I0423 12:30:09.648548 16565 solver.cpp:244]     Train net output #0: loss = 0.98061 (* 1 = 0.98061 loss)
I0423 12:30:09.648557 16565 solver.cpp:244]     Train net output #1: loss = 0.900236 (* 1 = 0.900236 loss)
I0423 12:30:09.648562 16565 solver.cpp:244]     Train net output #2: loss = 0.881215 (* 1 = 0.881215 loss)
I0423 12:30:09.648568 16565 sgd_solver.cpp:106] Iteration 41700, lr = 9e-06
I0423 12:31:47.849594 16565 solver.cpp:228] Iteration 41800, loss = 2.77535
I0423 12:31:47.849748 16565 solver.cpp:244]     Train net output #0: loss = 0.98097 (* 1 = 0.98097 loss)
I0423 12:31:47.849756 16565 solver.cpp:244]     Train net output #1: loss = 0.869642 (* 1 = 0.869642 loss)
I0423 12:31:47.849762 16565 solver.cpp:244]     Train net output #2: loss = 0.924738 (* 1 = 0.924738 loss)
I0423 12:31:47.849767 16565 sgd_solver.cpp:106] Iteration 41800, lr = 9e-06
I0423 12:33:28.050609 16565 solver.cpp:228] Iteration 41900, loss = 2.75753
I0423 12:33:28.050792 16565 solver.cpp:244]     Train net output #0: loss = 0.97853 (* 1 = 0.97853 loss)
I0423 12:33:28.050802 16565 solver.cpp:244]     Train net output #1: loss = 0.851567 (* 1 = 0.851567 loss)
I0423 12:33:28.050807 16565 solver.cpp:244]     Train net output #2: loss = 0.927436 (* 1 = 0.927436 loss)
I0423 12:33:28.050812 16565 sgd_solver.cpp:106] Iteration 41900, lr = 9e-06
I0423 12:35:06.878442 16565 solver.cpp:337] Iteration 42000, Testing net (#0)
I0423 12:35:06.878587 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 12:35:06.878590 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 12:35:06.878594 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 12:35:06.878608 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 12:35:06.878612 16565 net.cpp:693] Ignoring source layer visualize
I0423 12:35:06.878615 16565 net.cpp:693] Ignoring source layer fake
I0423 12:38:40.835955 16565 solver.cpp:404]     Test net output #0: loss = 0.976731 (* 1 = 0.976731 loss)
I0423 12:38:40.836165 16565 solver.cpp:404]     Test net output #1: loss = 0.746726 (* 1 = 0.746726 loss)
I0423 12:38:40.836174 16565 solver.cpp:404]     Test net output #2: loss = 0.805362 (* 1 = 0.805362 loss)
I0423 12:38:41.485141 16565 solver.cpp:228] Iteration 42000, loss = 2.65067
I0423 12:38:41.485182 16565 solver.cpp:244]     Train net output #0: loss = 0.982428 (* 1 = 0.982428 loss)
I0423 12:38:41.485188 16565 solver.cpp:244]     Train net output #1: loss = 0.798108 (* 1 = 0.798108 loss)
I0423 12:38:41.485193 16565 solver.cpp:244]     Train net output #2: loss = 0.870131 (* 1 = 0.870131 loss)
I0423 12:38:41.485196 16565 sgd_solver.cpp:106] Iteration 42000, lr = 9e-06
I0423 12:40:19.687386 16565 solver.cpp:228] Iteration 42100, loss = 2.58006
I0423 12:40:19.687522 16565 solver.cpp:244]     Train net output #0: loss = 0.970191 (* 1 = 0.970191 loss)
I0423 12:40:19.687530 16565 solver.cpp:244]     Train net output #1: loss = 0.736778 (* 1 = 0.736778 loss)
I0423 12:40:19.687536 16565 solver.cpp:244]     Train net output #2: loss = 0.873094 (* 1 = 0.873094 loss)
I0423 12:40:19.687541 16565 sgd_solver.cpp:106] Iteration 42100, lr = 9e-06
I0423 12:41:59.526718 16565 solver.cpp:228] Iteration 42200, loss = 2.7437
I0423 12:41:59.526865 16565 solver.cpp:244]     Train net output #0: loss = 0.98521 (* 1 = 0.98521 loss)
I0423 12:41:59.526873 16565 solver.cpp:244]     Train net output #1: loss = 0.853586 (* 1 = 0.853586 loss)
I0423 12:41:59.526878 16565 solver.cpp:244]     Train net output #2: loss = 0.904902 (* 1 = 0.904902 loss)
I0423 12:41:59.526885 16565 sgd_solver.cpp:106] Iteration 42200, lr = 9e-06
I0423 12:43:39.410429 16565 solver.cpp:228] Iteration 42300, loss = 2.55788
I0423 12:43:39.410636 16565 solver.cpp:244]     Train net output #0: loss = 0.984527 (* 1 = 0.984527 loss)
I0423 12:43:39.410645 16565 solver.cpp:244]     Train net output #1: loss = 0.810451 (* 1 = 0.810451 loss)
I0423 12:43:39.410650 16565 solver.cpp:244]     Train net output #2: loss = 0.762899 (* 1 = 0.762899 loss)
I0423 12:43:39.410656 16565 sgd_solver.cpp:106] Iteration 42300, lr = 9e-06
I0423 12:45:19.081928 16565 solver.cpp:228] Iteration 42400, loss = 2.32272
I0423 12:45:19.082075 16565 solver.cpp:244]     Train net output #0: loss = 0.959069 (* 1 = 0.959069 loss)
I0423 12:45:19.082083 16565 solver.cpp:244]     Train net output #1: loss = 0.633754 (* 1 = 0.633754 loss)
I0423 12:45:19.082089 16565 solver.cpp:244]     Train net output #2: loss = 0.729902 (* 1 = 0.729902 loss)
I0423 12:45:19.082093 16565 sgd_solver.cpp:106] Iteration 42400, lr = 9e-06
I0423 12:46:58.376191 16565 solver.cpp:228] Iteration 42500, loss = 2.7633
I0423 12:46:58.376345 16565 solver.cpp:244]     Train net output #0: loss = 0.973939 (* 1 = 0.973939 loss)
I0423 12:46:58.376354 16565 solver.cpp:244]     Train net output #1: loss = 0.825997 (* 1 = 0.825997 loss)
I0423 12:46:58.376359 16565 solver.cpp:244]     Train net output #2: loss = 0.96336 (* 1 = 0.96336 loss)
I0423 12:46:58.376365 16565 sgd_solver.cpp:106] Iteration 42500, lr = 9e-06
I0423 12:48:37.696571 16565 solver.cpp:228] Iteration 42600, loss = 2.66098
I0423 12:48:37.698431 16565 solver.cpp:244]     Train net output #0: loss = 0.967447 (* 1 = 0.967447 loss)
I0423 12:48:37.698438 16565 solver.cpp:244]     Train net output #1: loss = 0.754563 (* 1 = 0.754563 loss)
I0423 12:48:37.698442 16565 solver.cpp:244]     Train net output #2: loss = 0.938974 (* 1 = 0.938974 loss)
I0423 12:48:37.698449 16565 sgd_solver.cpp:106] Iteration 42600, lr = 9e-06
I0423 12:50:17.210441 16565 solver.cpp:228] Iteration 42700, loss = 2.53682
I0423 12:50:17.210595 16565 solver.cpp:244]     Train net output #0: loss = 0.982199 (* 1 = 0.982199 loss)
I0423 12:50:17.210603 16565 solver.cpp:244]     Train net output #1: loss = 0.788574 (* 1 = 0.788574 loss)
I0423 12:50:17.210608 16565 solver.cpp:244]     Train net output #2: loss = 0.766051 (* 1 = 0.766051 loss)
I0423 12:50:17.210613 16565 sgd_solver.cpp:106] Iteration 42700, lr = 9e-06
I0423 12:51:55.328927 16565 solver.cpp:228] Iteration 42800, loss = 2.3068
I0423 12:51:55.329088 16565 solver.cpp:244]     Train net output #0: loss = 0.981053 (* 1 = 0.981053 loss)
I0423 12:51:55.329097 16565 solver.cpp:244]     Train net output #1: loss = 0.748152 (* 1 = 0.748152 loss)
I0423 12:51:55.329102 16565 solver.cpp:244]     Train net output #2: loss = 0.577596 (* 1 = 0.577596 loss)
I0423 12:51:55.329107 16565 sgd_solver.cpp:106] Iteration 42800, lr = 9e-06
I0423 12:53:35.693701 16565 solver.cpp:228] Iteration 42900, loss = 2.66187
I0423 12:53:35.693892 16565 solver.cpp:244]     Train net output #0: loss = 0.967967 (* 1 = 0.967967 loss)
I0423 12:53:35.693902 16565 solver.cpp:244]     Train net output #1: loss = 0.852493 (* 1 = 0.852493 loss)
I0423 12:53:35.693907 16565 solver.cpp:244]     Train net output #2: loss = 0.841414 (* 1 = 0.841414 loss)
I0423 12:53:35.693910 16565 sgd_solver.cpp:106] Iteration 42900, lr = 9e-06
I0423 12:55:15.458045 16565 solver.cpp:337] Iteration 43000, Testing net (#0)
I0423 12:55:15.458200 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 12:55:15.458204 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 12:55:15.458209 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 12:55:15.458232 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 12:55:15.458236 16565 net.cpp:693] Ignoring source layer visualize
I0423 12:55:15.458240 16565 net.cpp:693] Ignoring source layer fake
I0423 12:58:49.165477 16565 solver.cpp:404]     Test net output #0: loss = 0.975337 (* 1 = 0.975337 loss)
I0423 12:58:49.165662 16565 solver.cpp:404]     Test net output #1: loss = 0.749423 (* 1 = 0.749423 loss)
I0423 12:58:49.165668 16565 solver.cpp:404]     Test net output #2: loss = 0.813996 (* 1 = 0.813996 loss)
I0423 12:58:49.815982 16565 solver.cpp:228] Iteration 43000, loss = 2.79657
I0423 12:58:49.816007 16565 solver.cpp:244]     Train net output #0: loss = 0.98648 (* 1 = 0.98648 loss)
I0423 12:58:49.816014 16565 solver.cpp:244]     Train net output #1: loss = 0.899161 (* 1 = 0.899161 loss)
I0423 12:58:49.816033 16565 solver.cpp:244]     Train net output #2: loss = 0.91093 (* 1 = 0.91093 loss)
I0423 12:58:49.816037 16565 sgd_solver.cpp:106] Iteration 43000, lr = 9e-06
I0423 13:00:30.417521 16565 solver.cpp:228] Iteration 43100, loss = 2.83593
I0423 13:00:30.417676 16565 solver.cpp:244]     Train net output #0: loss = 0.987676 (* 1 = 0.987676 loss)
I0423 13:00:30.417685 16565 solver.cpp:244]     Train net output #1: loss = 0.905349 (* 1 = 0.905349 loss)
I0423 13:00:30.417690 16565 solver.cpp:244]     Train net output #2: loss = 0.942904 (* 1 = 0.942904 loss)
I0423 13:00:30.417695 16565 sgd_solver.cpp:106] Iteration 43100, lr = 9e-06
I0423 13:02:08.563048 16565 solver.cpp:228] Iteration 43200, loss = 2.81693
I0423 13:02:08.563213 16565 solver.cpp:244]     Train net output #0: loss = 0.984821 (* 1 = 0.984821 loss)
I0423 13:02:08.563220 16565 solver.cpp:244]     Train net output #1: loss = 0.902182 (* 1 = 0.902182 loss)
I0423 13:02:08.563225 16565 solver.cpp:244]     Train net output #2: loss = 0.929924 (* 1 = 0.929924 loss)
I0423 13:02:08.563230 16565 sgd_solver.cpp:106] Iteration 43200, lr = 9e-06
I0423 13:03:49.719148 16565 solver.cpp:228] Iteration 43300, loss = 2.57734
I0423 13:03:49.719317 16565 solver.cpp:244]     Train net output #0: loss = 0.976974 (* 1 = 0.976974 loss)
I0423 13:03:49.719326 16565 solver.cpp:244]     Train net output #1: loss = 0.765112 (* 1 = 0.765112 loss)
I0423 13:03:49.719331 16565 solver.cpp:244]     Train net output #2: loss = 0.835253 (* 1 = 0.835253 loss)
I0423 13:03:49.719337 16565 sgd_solver.cpp:106] Iteration 43300, lr = 9e-06
I0423 13:05:30.284814 16565 solver.cpp:228] Iteration 43400, loss = 2.74632
I0423 13:05:30.284965 16565 solver.cpp:244]     Train net output #0: loss = 0.98912 (* 1 = 0.98912 loss)
I0423 13:05:30.284972 16565 solver.cpp:244]     Train net output #1: loss = 0.80477 (* 1 = 0.80477 loss)
I0423 13:05:30.284978 16565 solver.cpp:244]     Train net output #2: loss = 0.952434 (* 1 = 0.952434 loss)
I0423 13:05:30.284983 16565 sgd_solver.cpp:106] Iteration 43400, lr = 9e-06
I0423 13:07:12.507639 16565 solver.cpp:228] Iteration 43500, loss = 2.45858
I0423 13:07:12.507812 16565 solver.cpp:244]     Train net output #0: loss = 0.989241 (* 1 = 0.989241 loss)
I0423 13:07:12.507819 16565 solver.cpp:244]     Train net output #1: loss = 0.713902 (* 1 = 0.713902 loss)
I0423 13:07:12.507824 16565 solver.cpp:244]     Train net output #2: loss = 0.755441 (* 1 = 0.755441 loss)
I0423 13:07:12.507830 16565 sgd_solver.cpp:106] Iteration 43500, lr = 9e-06
I0423 13:08:50.623456 16565 solver.cpp:228] Iteration 43600, loss = 2.49492
I0423 13:08:50.623636 16565 solver.cpp:244]     Train net output #0: loss = 0.977446 (* 1 = 0.977446 loss)
I0423 13:08:50.623643 16565 solver.cpp:244]     Train net output #1: loss = 0.763621 (* 1 = 0.763621 loss)
I0423 13:08:50.623648 16565 solver.cpp:244]     Train net output #2: loss = 0.75385 (* 1 = 0.75385 loss)
I0423 13:08:50.623654 16565 sgd_solver.cpp:106] Iteration 43600, lr = 9e-06
I0423 13:10:30.258714 16565 solver.cpp:228] Iteration 43700, loss = 2.41804
I0423 13:10:30.258878 16565 solver.cpp:244]     Train net output #0: loss = 0.988972 (* 1 = 0.988972 loss)
I0423 13:10:30.258889 16565 solver.cpp:244]     Train net output #1: loss = 0.681509 (* 1 = 0.681509 loss)
I0423 13:10:30.258898 16565 solver.cpp:244]     Train net output #2: loss = 0.747563 (* 1 = 0.747563 loss)
I0423 13:10:30.258905 16565 sgd_solver.cpp:106] Iteration 43700, lr = 9e-06
I0423 13:12:09.571867 16565 solver.cpp:228] Iteration 43800, loss = 2.57443
I0423 13:12:09.572057 16565 solver.cpp:244]     Train net output #0: loss = 0.971002 (* 1 = 0.971002 loss)
I0423 13:12:09.572067 16565 solver.cpp:244]     Train net output #1: loss = 0.835781 (* 1 = 0.835781 loss)
I0423 13:12:09.572072 16565 solver.cpp:244]     Train net output #2: loss = 0.767649 (* 1 = 0.767649 loss)
I0423 13:12:09.572077 16565 sgd_solver.cpp:106] Iteration 43800, lr = 9e-06
I0423 13:13:48.886802 16565 solver.cpp:228] Iteration 43900, loss = 2.4383
I0423 13:13:48.886955 16565 solver.cpp:244]     Train net output #0: loss = 0.983396 (* 1 = 0.983396 loss)
I0423 13:13:48.886965 16565 solver.cpp:244]     Train net output #1: loss = 0.782484 (* 1 = 0.782484 loss)
I0423 13:13:48.886970 16565 solver.cpp:244]     Train net output #2: loss = 0.672419 (* 1 = 0.672419 loss)
I0423 13:13:48.886973 16565 sgd_solver.cpp:106] Iteration 43900, lr = 9e-06
I0423 13:15:27.453711 16565 solver.cpp:337] Iteration 44000, Testing net (#0)
I0423 13:15:27.453891 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 13:15:27.453894 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 13:15:27.453898 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 13:15:27.453913 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 13:15:27.453917 16565 net.cpp:693] Ignoring source layer visualize
I0423 13:15:27.453919 16565 net.cpp:693] Ignoring source layer fake
I0423 13:19:01.330513 16565 solver.cpp:404]     Test net output #0: loss = 0.976156 (* 1 = 0.976156 loss)
I0423 13:19:01.332033 16565 solver.cpp:404]     Test net output #1: loss = 0.751028 (* 1 = 0.751028 loss)
I0423 13:19:01.332041 16565 solver.cpp:404]     Test net output #2: loss = 0.809707 (* 1 = 0.809707 loss)
I0423 13:19:01.986631 16565 solver.cpp:228] Iteration 44000, loss = 2.31721
I0423 13:19:01.986656 16565 solver.cpp:244]     Train net output #0: loss = 0.983315 (* 1 = 0.983315 loss)
I0423 13:19:01.986677 16565 solver.cpp:244]     Train net output #1: loss = 0.776498 (* 1 = 0.776498 loss)
I0423 13:19:01.986681 16565 solver.cpp:244]     Train net output #2: loss = 0.557392 (* 1 = 0.557392 loss)
I0423 13:19:01.986685 16565 sgd_solver.cpp:106] Iteration 44000, lr = 9e-06
I0423 13:20:41.773890 16565 solver.cpp:228] Iteration 44100, loss = 2.68461
I0423 13:20:41.774065 16565 solver.cpp:244]     Train net output #0: loss = 0.963449 (* 1 = 0.963449 loss)
I0423 13:20:41.774072 16565 solver.cpp:244]     Train net output #1: loss = 0.839664 (* 1 = 0.839664 loss)
I0423 13:20:41.774077 16565 solver.cpp:244]     Train net output #2: loss = 0.881497 (* 1 = 0.881497 loss)
I0423 13:20:41.774081 16565 sgd_solver.cpp:106] Iteration 44100, lr = 9e-06
I0423 13:22:21.515571 16565 solver.cpp:228] Iteration 44200, loss = 2.66081
I0423 13:22:21.515746 16565 solver.cpp:244]     Train net output #0: loss = 0.972792 (* 1 = 0.972792 loss)
I0423 13:22:21.515754 16565 solver.cpp:244]     Train net output #1: loss = 0.823504 (* 1 = 0.823504 loss)
I0423 13:22:21.515759 16565 solver.cpp:244]     Train net output #2: loss = 0.864515 (* 1 = 0.864515 loss)
I0423 13:22:21.515764 16565 sgd_solver.cpp:106] Iteration 44200, lr = 9e-06
I0423 13:23:59.677969 16565 solver.cpp:228] Iteration 44300, loss = 2.73365
I0423 13:23:59.678117 16565 solver.cpp:244]     Train net output #0: loss = 0.968401 (* 1 = 0.968401 loss)
I0423 13:23:59.678124 16565 solver.cpp:244]     Train net output #1: loss = 0.837944 (* 1 = 0.837944 loss)
I0423 13:23:59.678129 16565 solver.cpp:244]     Train net output #2: loss = 0.927302 (* 1 = 0.927302 loss)
I0423 13:23:59.678135 16565 sgd_solver.cpp:106] Iteration 44300, lr = 9e-06
I0423 13:25:39.841315 16565 solver.cpp:228] Iteration 44400, loss = 2.7187
I0423 13:25:39.841509 16565 solver.cpp:244]     Train net output #0: loss = 0.976685 (* 1 = 0.976685 loss)
I0423 13:25:39.841517 16565 solver.cpp:244]     Train net output #1: loss = 0.837861 (* 1 = 0.837861 loss)
I0423 13:25:39.841523 16565 solver.cpp:244]     Train net output #2: loss = 0.904153 (* 1 = 0.904153 loss)
I0423 13:25:39.841528 16565 sgd_solver.cpp:106] Iteration 44400, lr = 9e-06
I0423 13:27:20.662128 16565 solver.cpp:228] Iteration 44500, loss = 2.63405
I0423 13:27:20.662317 16565 solver.cpp:244]     Train net output #0: loss = 0.986622 (* 1 = 0.986622 loss)
I0423 13:27:20.662327 16565 solver.cpp:244]     Train net output #1: loss = 0.801704 (* 1 = 0.801704 loss)
I0423 13:27:20.662331 16565 solver.cpp:244]     Train net output #2: loss = 0.845725 (* 1 = 0.845725 loss)
I0423 13:27:20.662338 16565 sgd_solver.cpp:106] Iteration 44500, lr = 9e-06
I0423 13:28:58.789297 16565 solver.cpp:228] Iteration 44600, loss = 2.54404
I0423 13:28:58.789451 16565 solver.cpp:244]     Train net output #0: loss = 0.981942 (* 1 = 0.981942 loss)
I0423 13:28:58.789459 16565 solver.cpp:244]     Train net output #1: loss = 0.731385 (* 1 = 0.731385 loss)
I0423 13:28:58.789464 16565 solver.cpp:244]     Train net output #2: loss = 0.830717 (* 1 = 0.830717 loss)
I0423 13:28:58.789469 16565 sgd_solver.cpp:106] Iteration 44600, lr = 9e-06
I0423 13:30:38.737903 16565 solver.cpp:228] Iteration 44700, loss = 2.71467
I0423 13:30:38.738055 16565 solver.cpp:244]     Train net output #0: loss = 0.983413 (* 1 = 0.983413 loss)
I0423 13:30:38.738073 16565 solver.cpp:244]     Train net output #1: loss = 0.831482 (* 1 = 0.831482 loss)
I0423 13:30:38.738077 16565 solver.cpp:244]     Train net output #2: loss = 0.899772 (* 1 = 0.899772 loss)
I0423 13:30:38.738083 16565 sgd_solver.cpp:106] Iteration 44700, lr = 9e-06
I0423 13:32:18.549115 16565 solver.cpp:228] Iteration 44800, loss = 1.95522
I0423 13:32:18.549263 16565 solver.cpp:244]     Train net output #0: loss = 0.98389 (* 1 = 0.98389 loss)
I0423 13:32:18.549271 16565 solver.cpp:244]     Train net output #1: loss = 0.592106 (* 1 = 0.592106 loss)
I0423 13:32:18.549278 16565 solver.cpp:244]     Train net output #2: loss = 0.379225 (* 1 = 0.379225 loss)
I0423 13:32:18.549283 16565 sgd_solver.cpp:106] Iteration 44800, lr = 9e-06
I0423 13:33:58.485180 16565 solver.cpp:228] Iteration 44900, loss = 2.48204
I0423 13:33:58.485347 16565 solver.cpp:244]     Train net output #0: loss = 0.985995 (* 1 = 0.985995 loss)
I0423 13:33:58.485355 16565 solver.cpp:244]     Train net output #1: loss = 0.748228 (* 1 = 0.748228 loss)
I0423 13:33:58.485360 16565 solver.cpp:244]     Train net output #2: loss = 0.747819 (* 1 = 0.747819 loss)
I0423 13:33:58.485366 16565 sgd_solver.cpp:106] Iteration 44900, lr = 9e-06
I0423 13:35:36.768787 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_45000.caffemodel
I0423 13:35:41.746902 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_45000.solverstate
I0423 13:35:41.939395 16565 solver.cpp:337] Iteration 45000, Testing net (#0)
I0423 13:35:41.939437 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 13:35:41.939440 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 13:35:41.939445 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 13:35:41.939458 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 13:35:41.939461 16565 net.cpp:693] Ignoring source layer visualize
I0423 13:35:41.939462 16565 net.cpp:693] Ignoring source layer fake
I0423 13:39:16.652523 16565 solver.cpp:404]     Test net output #0: loss = 0.970291 (* 1 = 0.970291 loss)
I0423 13:39:16.652673 16565 solver.cpp:404]     Test net output #1: loss = 0.738169 (* 1 = 0.738169 loss)
I0423 13:39:16.652679 16565 solver.cpp:404]     Test net output #2: loss = 0.81504 (* 1 = 0.81504 loss)
I0423 13:39:17.308390 16565 solver.cpp:228] Iteration 45000, loss = 2.5672
I0423 13:39:17.308439 16565 solver.cpp:244]     Train net output #0: loss = 0.978354 (* 1 = 0.978354 loss)
I0423 13:39:17.308444 16565 solver.cpp:244]     Train net output #1: loss = 0.820604 (* 1 = 0.820604 loss)
I0423 13:39:17.308449 16565 solver.cpp:244]     Train net output #2: loss = 0.768242 (* 1 = 0.768242 loss)
I0423 13:39:17.308454 16565 sgd_solver.cpp:106] Iteration 45000, lr = 9e-06
I0423 13:40:58.642698 16565 solver.cpp:228] Iteration 45100, loss = 2.54852
I0423 13:40:58.642904 16565 solver.cpp:244]     Train net output #0: loss = 0.961044 (* 1 = 0.961044 loss)
I0423 13:40:58.642912 16565 solver.cpp:244]     Train net output #1: loss = 0.820337 (* 1 = 0.820337 loss)
I0423 13:40:58.642917 16565 solver.cpp:244]     Train net output #2: loss = 0.767143 (* 1 = 0.767143 loss)
I0423 13:40:58.642925 16565 sgd_solver.cpp:106] Iteration 45100, lr = 9e-06
I0423 13:42:40.498693 16565 solver.cpp:228] Iteration 45200, loss = 2.14565
I0423 13:42:40.498857 16565 solver.cpp:244]     Train net output #0: loss = 0.977647 (* 1 = 0.977647 loss)
I0423 13:42:40.498864 16565 solver.cpp:244]     Train net output #1: loss = 0.595024 (* 1 = 0.595024 loss)
I0423 13:42:40.498869 16565 solver.cpp:244]     Train net output #2: loss = 0.572974 (* 1 = 0.572974 loss)
I0423 13:42:40.498874 16565 sgd_solver.cpp:106] Iteration 45200, lr = 9e-06
I0423 13:44:18.601536 16565 solver.cpp:228] Iteration 45300, loss = 2.13604
I0423 13:44:18.601704 16565 solver.cpp:244]     Train net output #0: loss = 0.981705 (* 1 = 0.981705 loss)
I0423 13:44:18.601712 16565 solver.cpp:244]     Train net output #1: loss = 0.583026 (* 1 = 0.583026 loss)
I0423 13:44:18.601717 16565 solver.cpp:244]     Train net output #2: loss = 0.571306 (* 1 = 0.571306 loss)
I0423 13:44:18.601722 16565 sgd_solver.cpp:106] Iteration 45300, lr = 9e-06
I0423 13:46:00.419672 16565 solver.cpp:228] Iteration 45400, loss = 2.66833
I0423 13:46:00.419841 16565 solver.cpp:244]     Train net output #0: loss = 0.967355 (* 1 = 0.967355 loss)
I0423 13:46:00.419847 16565 solver.cpp:244]     Train net output #1: loss = 0.855258 (* 1 = 0.855258 loss)
I0423 13:46:00.419852 16565 solver.cpp:244]     Train net output #2: loss = 0.845715 (* 1 = 0.845715 loss)
I0423 13:46:00.419857 16565 sgd_solver.cpp:106] Iteration 45400, lr = 9e-06
I0423 13:47:42.657614 16565 solver.cpp:228] Iteration 45500, loss = 2.75245
I0423 13:47:42.657789 16565 solver.cpp:244]     Train net output #0: loss = 0.975263 (* 1 = 0.975263 loss)
I0423 13:47:42.657797 16565 solver.cpp:244]     Train net output #1: loss = 0.846437 (* 1 = 0.846437 loss)
I0423 13:47:42.657802 16565 solver.cpp:244]     Train net output #2: loss = 0.930748 (* 1 = 0.930748 loss)
I0423 13:47:42.657809 16565 sgd_solver.cpp:106] Iteration 45500, lr = 9e-06
I0423 13:49:25.022053 16565 solver.cpp:228] Iteration 45600, loss = 2.69557
I0423 13:49:25.022202 16565 solver.cpp:244]     Train net output #0: loss = 0.957189 (* 1 = 0.957189 loss)
I0423 13:49:25.022210 16565 solver.cpp:244]     Train net output #1: loss = 0.805708 (* 1 = 0.805708 loss)
I0423 13:49:25.022217 16565 solver.cpp:244]     Train net output #2: loss = 0.932672 (* 1 = 0.932672 loss)
I0423 13:49:25.022220 16565 sgd_solver.cpp:106] Iteration 45600, lr = 9e-06
I0423 13:51:02.927326 16565 solver.cpp:228] Iteration 45700, loss = 2.74759
I0423 13:51:02.927466 16565 solver.cpp:244]     Train net output #0: loss = 0.9745 (* 1 = 0.9745 loss)
I0423 13:51:02.927475 16565 solver.cpp:244]     Train net output #1: loss = 0.86538 (* 1 = 0.86538 loss)
I0423 13:51:02.927480 16565 solver.cpp:244]     Train net output #2: loss = 0.907708 (* 1 = 0.907708 loss)
I0423 13:51:02.927485 16565 sgd_solver.cpp:106] Iteration 45700, lr = 9e-06
I0423 13:52:44.414881 16565 solver.cpp:228] Iteration 45800, loss = 2.6789
I0423 13:52:44.415045 16565 solver.cpp:244]     Train net output #0: loss = 0.974308 (* 1 = 0.974308 loss)
I0423 13:52:44.415051 16565 solver.cpp:244]     Train net output #1: loss = 0.793935 (* 1 = 0.793935 loss)
I0423 13:52:44.415056 16565 solver.cpp:244]     Train net output #2: loss = 0.910655 (* 1 = 0.910655 loss)
I0423 13:52:44.415061 16565 sgd_solver.cpp:106] Iteration 45800, lr = 9e-06
I0423 13:54:26.251273 16565 solver.cpp:228] Iteration 45900, loss = 2.81324
I0423 13:54:26.251423 16565 solver.cpp:244]     Train net output #0: loss = 0.988829 (* 1 = 0.988829 loss)
I0423 13:54:26.251430 16565 solver.cpp:244]     Train net output #1: loss = 0.873338 (* 1 = 0.873338 loss)
I0423 13:54:26.251435 16565 solver.cpp:244]     Train net output #2: loss = 0.951073 (* 1 = 0.951073 loss)
I0423 13:54:26.251441 16565 sgd_solver.cpp:106] Iteration 45900, lr = 9e-06
I0423 13:56:07.242264 16565 solver.cpp:337] Iteration 46000, Testing net (#0)
I0423 13:56:07.242445 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 13:56:07.242450 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 13:56:07.242455 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 13:56:07.242470 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 13:56:07.242473 16565 net.cpp:693] Ignoring source layer visualize
I0423 13:56:07.242475 16565 net.cpp:693] Ignoring source layer fake
I0423 13:59:40.883093 16565 solver.cpp:404]     Test net output #0: loss = 0.963224 (* 1 = 0.963224 loss)
I0423 13:59:40.883236 16565 solver.cpp:404]     Test net output #1: loss = 0.730223 (* 1 = 0.730223 loss)
I0423 13:59:40.883244 16565 solver.cpp:404]     Test net output #2: loss = 0.821541 (* 1 = 0.821541 loss)
I0423 13:59:41.538101 16565 solver.cpp:228] Iteration 46000, loss = 2.4135
I0423 13:59:41.538144 16565 solver.cpp:244]     Train net output #0: loss = 0.981381 (* 1 = 0.981381 loss)
I0423 13:59:41.538151 16565 solver.cpp:244]     Train net output #1: loss = 0.687563 (* 1 = 0.687563 loss)
I0423 13:59:41.538154 16565 solver.cpp:244]     Train net output #2: loss = 0.744556 (* 1 = 0.744556 loss)
I0423 13:59:41.538159 16565 sgd_solver.cpp:106] Iteration 46000, lr = 9e-06
I0423 14:01:19.700873 16565 solver.cpp:228] Iteration 46100, loss = 2.35658
I0423 14:01:19.701028 16565 solver.cpp:244]     Train net output #0: loss = 0.978191 (* 1 = 0.978191 loss)
I0423 14:01:19.701035 16565 solver.cpp:244]     Train net output #1: loss = 0.700666 (* 1 = 0.700666 loss)
I0423 14:01:19.701040 16565 solver.cpp:244]     Train net output #2: loss = 0.677726 (* 1 = 0.677726 loss)
I0423 14:01:19.701045 16565 sgd_solver.cpp:106] Iteration 46100, lr = 9e-06
I0423 14:03:01.858037 16565 solver.cpp:228] Iteration 46200, loss = 2.19477
I0423 14:03:01.858196 16565 solver.cpp:244]     Train net output #0: loss = 0.989717 (* 1 = 0.989717 loss)
I0423 14:03:01.858204 16565 solver.cpp:244]     Train net output #1: loss = 0.598591 (* 1 = 0.598591 loss)
I0423 14:03:01.858211 16565 solver.cpp:244]     Train net output #2: loss = 0.60646 (* 1 = 0.60646 loss)
I0423 14:03:01.858216 16565 sgd_solver.cpp:106] Iteration 46200, lr = 9e-06
I0423 14:04:41.006525 16565 solver.cpp:228] Iteration 46300, loss = 2.55778
I0423 14:04:41.007979 16565 solver.cpp:244]     Train net output #0: loss = 0.972 (* 1 = 0.972 loss)
I0423 14:04:41.007988 16565 solver.cpp:244]     Train net output #1: loss = 0.677023 (* 1 = 0.677023 loss)
I0423 14:04:41.007993 16565 solver.cpp:244]     Train net output #2: loss = 0.908759 (* 1 = 0.908759 loss)
I0423 14:04:41.007997 16565 sgd_solver.cpp:106] Iteration 46300, lr = 9e-06
I0423 14:06:20.267777 16565 solver.cpp:228] Iteration 46400, loss = 2.56262
I0423 14:06:20.267936 16565 solver.cpp:244]     Train net output #0: loss = 0.971607 (* 1 = 0.971607 loss)
I0423 14:06:20.267945 16565 solver.cpp:244]     Train net output #1: loss = 0.818711 (* 1 = 0.818711 loss)
I0423 14:06:20.267949 16565 solver.cpp:244]     Train net output #2: loss = 0.772305 (* 1 = 0.772305 loss)
I0423 14:06:20.267954 16565 sgd_solver.cpp:106] Iteration 46400, lr = 9e-06
I0423 14:08:00.014459 16565 solver.cpp:228] Iteration 46500, loss = 2.52529
I0423 14:08:00.014629 16565 solver.cpp:244]     Train net output #0: loss = 0.98346 (* 1 = 0.98346 loss)
I0423 14:08:00.014637 16565 solver.cpp:244]     Train net output #1: loss = 0.782441 (* 1 = 0.782441 loss)
I0423 14:08:00.014642 16565 solver.cpp:244]     Train net output #2: loss = 0.759391 (* 1 = 0.759391 loss)
I0423 14:08:00.014648 16565 sgd_solver.cpp:106] Iteration 46500, lr = 9e-06
I0423 14:09:40.105957 16565 solver.cpp:228] Iteration 46600, loss = 2.59238
I0423 14:09:40.106114 16565 solver.cpp:244]     Train net output #0: loss = 0.977838 (* 1 = 0.977838 loss)
I0423 14:09:40.106122 16565 solver.cpp:244]     Train net output #1: loss = 0.875946 (* 1 = 0.875946 loss)
I0423 14:09:40.106127 16565 solver.cpp:244]     Train net output #2: loss = 0.738598 (* 1 = 0.738598 loss)
I0423 14:09:40.106133 16565 sgd_solver.cpp:106] Iteration 46600, lr = 9e-06
I0423 14:11:20.137722 16565 solver.cpp:228] Iteration 46700, loss = 2.71034
I0423 14:11:20.137912 16565 solver.cpp:244]     Train net output #0: loss = 0.964403 (* 1 = 0.964403 loss)
I0423 14:11:20.137920 16565 solver.cpp:244]     Train net output #1: loss = 0.830526 (* 1 = 0.830526 loss)
I0423 14:11:20.137925 16565 solver.cpp:244]     Train net output #2: loss = 0.915408 (* 1 = 0.915408 loss)
I0423 14:11:20.137930 16565 sgd_solver.cpp:106] Iteration 46700, lr = 9e-06
I0423 14:12:58.285068 16565 solver.cpp:228] Iteration 46800, loss = 2.7982
I0423 14:12:58.285219 16565 solver.cpp:244]     Train net output #0: loss = 0.975921 (* 1 = 0.975921 loss)
I0423 14:12:58.285228 16565 solver.cpp:244]     Train net output #1: loss = 0.901579 (* 1 = 0.901579 loss)
I0423 14:12:58.285233 16565 solver.cpp:244]     Train net output #2: loss = 0.920699 (* 1 = 0.920699 loss)
I0423 14:12:58.285238 16565 sgd_solver.cpp:106] Iteration 46800, lr = 9e-06
I0423 14:14:38.854547 16565 solver.cpp:228] Iteration 46900, loss = 2.77098
I0423 14:14:38.854712 16565 solver.cpp:244]     Train net output #0: loss = 0.98605 (* 1 = 0.98605 loss)
I0423 14:14:38.854719 16565 solver.cpp:244]     Train net output #1: loss = 0.900616 (* 1 = 0.900616 loss)
I0423 14:14:38.854724 16565 solver.cpp:244]     Train net output #2: loss = 0.884315 (* 1 = 0.884315 loss)
I0423 14:14:38.854730 16565 sgd_solver.cpp:106] Iteration 46900, lr = 9e-06
I0423 14:16:17.985117 16565 solver.cpp:337] Iteration 47000, Testing net (#0)
I0423 14:16:17.985263 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 14:16:17.985267 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 14:16:17.985271 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 14:16:17.985286 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 14:16:17.985291 16565 net.cpp:693] Ignoring source layer visualize
I0423 14:16:17.985292 16565 net.cpp:693] Ignoring source layer fake
I0423 14:19:51.469422 16565 solver.cpp:404]     Test net output #0: loss = 0.976247 (* 1 = 0.976247 loss)
I0423 14:19:51.469583 16565 solver.cpp:404]     Test net output #1: loss = 0.747167 (* 1 = 0.747167 loss)
I0423 14:19:51.469590 16565 solver.cpp:404]     Test net output #2: loss = 0.807955 (* 1 = 0.807955 loss)
I0423 14:19:52.120159 16565 solver.cpp:228] Iteration 47000, loss = 2.66807
I0423 14:19:52.120206 16565 solver.cpp:244]     Train net output #0: loss = 0.974756 (* 1 = 0.974756 loss)
I0423 14:19:52.120213 16565 solver.cpp:244]     Train net output #1: loss = 0.787175 (* 1 = 0.787175 loss)
I0423 14:19:52.120216 16565 solver.cpp:244]     Train net output #2: loss = 0.906143 (* 1 = 0.906143 loss)
I0423 14:19:52.120220 16565 sgd_solver.cpp:106] Iteration 47000, lr = 9e-06
I0423 14:21:30.367144 16565 solver.cpp:228] Iteration 47100, loss = 2.75096
I0423 14:21:30.367274 16565 solver.cpp:244]     Train net output #0: loss = 0.988094 (* 1 = 0.988094 loss)
I0423 14:21:30.367281 16565 solver.cpp:244]     Train net output #1: loss = 0.841948 (* 1 = 0.841948 loss)
I0423 14:21:30.367286 16565 solver.cpp:244]     Train net output #2: loss = 0.920922 (* 1 = 0.920922 loss)
I0423 14:21:30.367292 16565 sgd_solver.cpp:106] Iteration 47100, lr = 9e-06
I0423 14:23:10.403146 16565 solver.cpp:228] Iteration 47200, loss = 2.77373
I0423 14:23:10.403293 16565 solver.cpp:244]     Train net output #0: loss = 0.979798 (* 1 = 0.979798 loss)
I0423 14:23:10.403301 16565 solver.cpp:244]     Train net output #1: loss = 0.841182 (* 1 = 0.841182 loss)
I0423 14:23:10.403307 16565 solver.cpp:244]     Train net output #2: loss = 0.952745 (* 1 = 0.952745 loss)
I0423 14:23:10.403312 16565 sgd_solver.cpp:106] Iteration 47200, lr = 9e-06
I0423 14:24:50.651458 16565 solver.cpp:228] Iteration 47300, loss = 2.45699
I0423 14:24:50.651612 16565 solver.cpp:244]     Train net output #0: loss = 0.987991 (* 1 = 0.987991 loss)
I0423 14:24:50.651619 16565 solver.cpp:244]     Train net output #1: loss = 0.707759 (* 1 = 0.707759 loss)
I0423 14:24:50.651625 16565 solver.cpp:244]     Train net output #2: loss = 0.761237 (* 1 = 0.761237 loss)
I0423 14:24:50.651629 16565 sgd_solver.cpp:106] Iteration 47300, lr = 9e-06
I0423 14:26:30.658468 16565 solver.cpp:228] Iteration 47400, loss = 2.69373
I0423 14:26:30.658663 16565 solver.cpp:244]     Train net output #0: loss = 0.981586 (* 1 = 0.981586 loss)
I0423 14:26:30.658671 16565 solver.cpp:244]     Train net output #1: loss = 0.7721 (* 1 = 0.7721 loss)
I0423 14:26:30.658676 16565 solver.cpp:244]     Train net output #2: loss = 0.940045 (* 1 = 0.940045 loss)
I0423 14:26:30.658680 16565 sgd_solver.cpp:106] Iteration 47400, lr = 9e-06
I0423 14:28:10.063233 16565 solver.cpp:228] Iteration 47500, loss = 2.57313
I0423 14:28:10.063392 16565 solver.cpp:244]     Train net output #0: loss = 0.960532 (* 1 = 0.960532 loss)
I0423 14:28:10.063400 16565 solver.cpp:244]     Train net output #1: loss = 0.841237 (* 1 = 0.841237 loss)
I0423 14:28:10.063405 16565 solver.cpp:244]     Train net output #2: loss = 0.77136 (* 1 = 0.77136 loss)
I0423 14:28:10.063410 16565 sgd_solver.cpp:106] Iteration 47500, lr = 9e-06
I0423 14:29:49.363418 16565 solver.cpp:228] Iteration 47600, loss = 2.59487
I0423 14:29:49.363585 16565 solver.cpp:244]     Train net output #0: loss = 0.981623 (* 1 = 0.981623 loss)
I0423 14:29:49.363593 16565 solver.cpp:244]     Train net output #1: loss = 0.841357 (* 1 = 0.841357 loss)
I0423 14:29:49.363600 16565 solver.cpp:244]     Train net output #2: loss = 0.77189 (* 1 = 0.77189 loss)
I0423 14:29:49.363603 16565 sgd_solver.cpp:106] Iteration 47600, lr = 9e-06
I0423 14:31:28.877759 16565 solver.cpp:228] Iteration 47700, loss = 2.04545
I0423 14:31:28.877944 16565 solver.cpp:244]     Train net output #0: loss = 0.983015 (* 1 = 0.983015 loss)
I0423 14:31:28.877954 16565 solver.cpp:244]     Train net output #1: loss = 0.484904 (* 1 = 0.484904 loss)
I0423 14:31:28.877959 16565 solver.cpp:244]     Train net output #2: loss = 0.577531 (* 1 = 0.577531 loss)
I0423 14:31:28.877964 16565 sgd_solver.cpp:106] Iteration 47700, lr = 9e-06
I0423 14:33:07.026816 16565 solver.cpp:228] Iteration 47800, loss = 2.43134
I0423 14:33:07.026974 16565 solver.cpp:244]     Train net output #0: loss = 0.973874 (* 1 = 0.973874 loss)
I0423 14:33:07.026981 16565 solver.cpp:244]     Train net output #1: loss = 0.683073 (* 1 = 0.683073 loss)
I0423 14:33:07.026986 16565 solver.cpp:244]     Train net output #2: loss = 0.774393 (* 1 = 0.774393 loss)
I0423 14:33:07.026991 16565 sgd_solver.cpp:106] Iteration 47800, lr = 9e-06
I0423 14:34:47.263732 16565 solver.cpp:228] Iteration 47900, loss = 2.70192
I0423 14:34:47.263880 16565 solver.cpp:244]     Train net output #0: loss = 0.965473 (* 1 = 0.965473 loss)
I0423 14:34:47.263887 16565 solver.cpp:244]     Train net output #1: loss = 0.864938 (* 1 = 0.864938 loss)
I0423 14:34:47.263891 16565 solver.cpp:244]     Train net output #2: loss = 0.871513 (* 1 = 0.871513 loss)
I0423 14:34:47.263898 16565 sgd_solver.cpp:106] Iteration 47900, lr = 9e-06
I0423 14:36:26.631285 16565 solver.cpp:337] Iteration 48000, Testing net (#0)
I0423 14:36:26.631438 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 14:36:26.631443 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 14:36:26.631448 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 14:36:26.631464 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 14:36:26.631466 16565 net.cpp:693] Ignoring source layer visualize
I0423 14:36:26.631469 16565 net.cpp:693] Ignoring source layer fake
I0423 14:40:00.910553 16565 solver.cpp:404]     Test net output #0: loss = 0.977266 (* 1 = 0.977266 loss)
I0423 14:40:00.910689 16565 solver.cpp:404]     Test net output #1: loss = 0.754974 (* 1 = 0.754974 loss)
I0423 14:40:00.910696 16565 solver.cpp:404]     Test net output #2: loss = 0.813397 (* 1 = 0.813397 loss)
I0423 14:40:01.562512 16565 solver.cpp:228] Iteration 48000, loss = 2.72585
I0423 14:40:01.562556 16565 solver.cpp:244]     Train net output #0: loss = 0.975473 (* 1 = 0.975473 loss)
I0423 14:40:01.562561 16565 solver.cpp:244]     Train net output #1: loss = 0.848361 (* 1 = 0.848361 loss)
I0423 14:40:01.562566 16565 solver.cpp:244]     Train net output #2: loss = 0.902014 (* 1 = 0.902014 loss)
I0423 14:40:01.562571 16565 sgd_solver.cpp:106] Iteration 48000, lr = 9e-06
I0423 14:41:41.544275 16565 solver.cpp:228] Iteration 48100, loss = 2.66787
I0423 14:41:41.544463 16565 solver.cpp:244]     Train net output #0: loss = 0.956367 (* 1 = 0.956367 loss)
I0423 14:41:41.544471 16565 solver.cpp:244]     Train net output #1: loss = 0.842207 (* 1 = 0.842207 loss)
I0423 14:41:41.544477 16565 solver.cpp:244]     Train net output #2: loss = 0.869291 (* 1 = 0.869291 loss)
I0423 14:41:41.544483 16565 sgd_solver.cpp:106] Iteration 48100, lr = 9e-06
I0423 14:43:19.745188 16565 solver.cpp:228] Iteration 48200, loss = 2.76374
I0423 14:43:19.745344 16565 solver.cpp:244]     Train net output #0: loss = 0.972754 (* 1 = 0.972754 loss)
I0423 14:43:19.745352 16565 solver.cpp:244]     Train net output #1: loss = 0.889806 (* 1 = 0.889806 loss)
I0423 14:43:19.745357 16565 solver.cpp:244]     Train net output #2: loss = 0.901178 (* 1 = 0.901178 loss)
I0423 14:43:19.745362 16565 sgd_solver.cpp:106] Iteration 48200, lr = 9e-06
I0423 14:44:59.730697 16565 solver.cpp:228] Iteration 48300, loss = 2.70886
I0423 14:44:59.730867 16565 solver.cpp:244]     Train net output #0: loss = 0.986534 (* 1 = 0.986534 loss)
I0423 14:44:59.730876 16565 solver.cpp:244]     Train net output #1: loss = 0.817896 (* 1 = 0.817896 loss)
I0423 14:44:59.730881 16565 solver.cpp:244]     Train net output #2: loss = 0.904427 (* 1 = 0.904427 loss)
I0423 14:44:59.730885 16565 sgd_solver.cpp:106] Iteration 48300, lr = 9e-06
I0423 14:46:40.024077 16565 solver.cpp:228] Iteration 48400, loss = 2.77792
I0423 14:46:40.024214 16565 solver.cpp:244]     Train net output #0: loss = 0.983415 (* 1 = 0.983415 loss)
I0423 14:46:40.024222 16565 solver.cpp:244]     Train net output #1: loss = 0.851196 (* 1 = 0.851196 loss)
I0423 14:46:40.024227 16565 solver.cpp:244]     Train net output #2: loss = 0.943304 (* 1 = 0.943304 loss)
I0423 14:46:40.024232 16565 sgd_solver.cpp:106] Iteration 48400, lr = 9e-06
I0423 14:48:20.014786 16565 solver.cpp:228] Iteration 48500, loss = 2.66215
I0423 14:48:20.014933 16565 solver.cpp:244]     Train net output #0: loss = 0.987759 (* 1 = 0.987759 loss)
I0423 14:48:20.014941 16565 solver.cpp:244]     Train net output #1: loss = 0.746806 (* 1 = 0.746806 loss)
I0423 14:48:20.014946 16565 solver.cpp:244]     Train net output #2: loss = 0.92758 (* 1 = 0.92758 loss)
I0423 14:48:20.014952 16565 sgd_solver.cpp:106] Iteration 48500, lr = 9e-06
I0423 14:49:58.255136 16565 solver.cpp:228] Iteration 48600, loss = 2.53454
I0423 14:49:58.255314 16565 solver.cpp:244]     Train net output #0: loss = 0.989842 (* 1 = 0.989842 loss)
I0423 14:49:58.255322 16565 solver.cpp:244]     Train net output #1: loss = 0.702158 (* 1 = 0.702158 loss)
I0423 14:49:58.255328 16565 solver.cpp:244]     Train net output #2: loss = 0.842543 (* 1 = 0.842543 loss)
I0423 14:49:58.255333 16565 sgd_solver.cpp:106] Iteration 48600, lr = 9e-06
I0423 14:51:40.417048 16565 solver.cpp:228] Iteration 48700, loss = 2.64414
I0423 14:51:40.417191 16565 solver.cpp:244]     Train net output #0: loss = 0.987599 (* 1 = 0.987599 loss)
I0423 14:51:40.417201 16565 solver.cpp:244]     Train net output #1: loss = 0.694867 (* 1 = 0.694867 loss)
I0423 14:51:40.417206 16565 solver.cpp:244]     Train net output #2: loss = 0.961674 (* 1 = 0.961674 loss)
I0423 14:51:40.417212 16565 sgd_solver.cpp:106] Iteration 48700, lr = 9e-06
I0423 14:53:20.352159 16565 solver.cpp:228] Iteration 48800, loss = 2.57395
I0423 14:53:20.352330 16565 solver.cpp:244]     Train net output #0: loss = 0.973427 (* 1 = 0.973427 loss)
I0423 14:53:20.352339 16565 solver.cpp:244]     Train net output #1: loss = 0.687597 (* 1 = 0.687597 loss)
I0423 14:53:20.352344 16565 solver.cpp:244]     Train net output #2: loss = 0.912925 (* 1 = 0.912925 loss)
I0423 14:53:20.352349 16565 sgd_solver.cpp:106] Iteration 48800, lr = 9e-06
I0423 14:55:00.545717 16565 solver.cpp:228] Iteration 48900, loss = 2.35923
I0423 14:55:00.545923 16565 solver.cpp:244]     Train net output #0: loss = 0.981307 (* 1 = 0.981307 loss)
I0423 14:55:00.545930 16565 solver.cpp:244]     Train net output #1: loss = 0.814717 (* 1 = 0.814717 loss)
I0423 14:55:00.545935 16565 solver.cpp:244]     Train net output #2: loss = 0.563201 (* 1 = 0.563201 loss)
I0423 14:55:00.545941 16565 sgd_solver.cpp:106] Iteration 48900, lr = 9e-06
I0423 14:56:40.704959 16565 solver.cpp:337] Iteration 49000, Testing net (#0)
I0423 14:56:40.705113 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 14:56:40.705117 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 14:56:40.705122 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 14:56:40.705137 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 14:56:40.705140 16565 net.cpp:693] Ignoring source layer visualize
I0423 14:56:40.705142 16565 net.cpp:693] Ignoring source layer fake
I0423 15:00:14.566412 16565 solver.cpp:404]     Test net output #0: loss = 0.976568 (* 1 = 0.976568 loss)
I0423 15:00:14.566534 16565 solver.cpp:404]     Test net output #1: loss = 0.751977 (* 1 = 0.751977 loss)
I0423 15:00:14.566541 16565 solver.cpp:404]     Test net output #2: loss = 0.811091 (* 1 = 0.811091 loss)
I0423 15:00:15.217092 16565 solver.cpp:228] Iteration 49000, loss = 2.34949
I0423 15:00:15.217140 16565 solver.cpp:244]     Train net output #0: loss = 0.976808 (* 1 = 0.976808 loss)
I0423 15:00:15.217146 16565 solver.cpp:244]     Train net output #1: loss = 0.789609 (* 1 = 0.789609 loss)
I0423 15:00:15.217150 16565 solver.cpp:244]     Train net output #2: loss = 0.583079 (* 1 = 0.583079 loss)
I0423 15:00:15.217154 16565 sgd_solver.cpp:106] Iteration 49000, lr = 9e-06
I0423 15:01:58.590575 16565 solver.cpp:228] Iteration 49100, loss = 2.48686
I0423 15:01:58.590837 16565 solver.cpp:244]     Train net output #0: loss = 0.978065 (* 1 = 0.978065 loss)
I0423 15:01:58.590845 16565 solver.cpp:244]     Train net output #1: loss = 0.82976 (* 1 = 0.82976 loss)
I0423 15:01:58.590850 16565 solver.cpp:244]     Train net output #2: loss = 0.679031 (* 1 = 0.679031 loss)
I0423 15:01:58.590857 16565 sgd_solver.cpp:106] Iteration 49100, lr = 9e-06
I0423 15:03:39.445339 16565 solver.cpp:228] Iteration 49200, loss = 2.69844
I0423 15:03:39.445509 16565 solver.cpp:244]     Train net output #0: loss = 0.978942 (* 1 = 0.978942 loss)
I0423 15:03:39.445518 16565 solver.cpp:244]     Train net output #1: loss = 0.907402 (* 1 = 0.907402 loss)
I0423 15:03:39.445523 16565 solver.cpp:244]     Train net output #2: loss = 0.812093 (* 1 = 0.812093 loss)
I0423 15:03:39.445528 16565 sgd_solver.cpp:106] Iteration 49200, lr = 9e-06
I0423 15:05:17.635140 16565 solver.cpp:228] Iteration 49300, loss = 2.77576
I0423 15:05:17.635951 16565 solver.cpp:244]     Train net output #0: loss = 0.978588 (* 1 = 0.978588 loss)
I0423 15:05:17.635959 16565 solver.cpp:244]     Train net output #1: loss = 0.883204 (* 1 = 0.883204 loss)
I0423 15:05:17.635963 16565 solver.cpp:244]     Train net output #2: loss = 0.913967 (* 1 = 0.913967 loss)
I0423 15:05:17.635968 16565 sgd_solver.cpp:106] Iteration 49300, lr = 9e-06
I0423 15:06:59.463790 16565 solver.cpp:228] Iteration 49400, loss = 2.71421
I0423 15:06:59.465203 16565 solver.cpp:244]     Train net output #0: loss = 0.984887 (* 1 = 0.984887 loss)
I0423 15:06:59.465210 16565 solver.cpp:244]     Train net output #1: loss = 0.854939 (* 1 = 0.854939 loss)
I0423 15:06:59.465215 16565 solver.cpp:244]     Train net output #2: loss = 0.874389 (* 1 = 0.874389 loss)
I0423 15:06:59.465220 16565 sgd_solver.cpp:106] Iteration 49400, lr = 9e-06
I0423 15:08:40.347519 16565 solver.cpp:228] Iteration 49500, loss = 2.67435
I0423 15:08:40.347702 16565 solver.cpp:244]     Train net output #0: loss = 0.985168 (* 1 = 0.985168 loss)
I0423 15:08:40.347710 16565 solver.cpp:244]     Train net output #1: loss = 0.790425 (* 1 = 0.790425 loss)
I0423 15:08:40.347717 16565 solver.cpp:244]     Train net output #2: loss = 0.89876 (* 1 = 0.89876 loss)
I0423 15:08:40.347723 16565 sgd_solver.cpp:106] Iteration 49500, lr = 9e-06
I0423 15:10:18.508985 16565 solver.cpp:228] Iteration 49600, loss = 2.66479
I0423 15:10:18.509167 16565 solver.cpp:244]     Train net output #0: loss = 0.987898 (* 1 = 0.987898 loss)
I0423 15:10:18.509174 16565 solver.cpp:244]     Train net output #1: loss = 0.800309 (* 1 = 0.800309 loss)
I0423 15:10:18.509181 16565 solver.cpp:244]     Train net output #2: loss = 0.87658 (* 1 = 0.87658 loss)
I0423 15:10:18.509186 16565 sgd_solver.cpp:106] Iteration 49600, lr = 9e-06
I0423 15:11:59.846935 16565 solver.cpp:228] Iteration 49700, loss = 2.78138
I0423 15:11:59.847102 16565 solver.cpp:244]     Train net output #0: loss = 0.987153 (* 1 = 0.987153 loss)
I0423 15:11:59.847111 16565 solver.cpp:244]     Train net output #1: loss = 0.87613 (* 1 = 0.87613 loss)
I0423 15:11:59.847116 16565 solver.cpp:244]     Train net output #2: loss = 0.918092 (* 1 = 0.918092 loss)
I0423 15:11:59.847121 16565 sgd_solver.cpp:106] Iteration 49700, lr = 9e-06
I0423 15:13:39.698889 16565 solver.cpp:228] Iteration 49800, loss = 2.5063
I0423 15:13:39.699059 16565 solver.cpp:244]     Train net output #0: loss = 0.988042 (* 1 = 0.988042 loss)
I0423 15:13:39.699066 16565 solver.cpp:244]     Train net output #1: loss = 0.763394 (* 1 = 0.763394 loss)
I0423 15:13:39.699071 16565 solver.cpp:244]     Train net output #2: loss = 0.754867 (* 1 = 0.754867 loss)
I0423 15:13:39.699076 16565 sgd_solver.cpp:106] Iteration 49800, lr = 9e-06
I0423 15:15:19.486584 16565 solver.cpp:228] Iteration 49900, loss = 2.48976
I0423 15:15:19.486739 16565 solver.cpp:244]     Train net output #0: loss = 0.982664 (* 1 = 0.982664 loss)
I0423 15:15:19.486747 16565 solver.cpp:244]     Train net output #1: loss = 0.738162 (* 1 = 0.738162 loss)
I0423 15:15:19.486752 16565 solver.cpp:244]     Train net output #2: loss = 0.768929 (* 1 = 0.768929 loss)
I0423 15:15:19.486758 16565 sgd_solver.cpp:106] Iteration 49900, lr = 9e-06
I0423 15:16:57.758919 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_50000.caffemodel
I0423 15:17:05.649685 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_50000.solverstate
I0423 15:17:05.851367 16565 solver.cpp:337] Iteration 50000, Testing net (#0)
I0423 15:17:05.851410 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 15:17:05.851413 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 15:17:05.851416 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 15:17:05.851430 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 15:17:05.851434 16565 net.cpp:693] Ignoring source layer visualize
I0423 15:17:05.851436 16565 net.cpp:693] Ignoring source layer fake
I0423 15:20:40.305045 16565 solver.cpp:404]     Test net output #0: loss = 0.967424 (* 1 = 0.967424 loss)
I0423 15:20:40.305191 16565 solver.cpp:404]     Test net output #1: loss = 0.733147 (* 1 = 0.733147 loss)
I0423 15:20:40.305198 16565 solver.cpp:404]     Test net output #2: loss = 0.818051 (* 1 = 0.818051 loss)
I0423 15:20:40.971654 16565 solver.cpp:228] Iteration 50000, loss = 2.54758
I0423 15:20:40.971698 16565 solver.cpp:244]     Train net output #0: loss = 0.976037 (* 1 = 0.976037 loss)
I0423 15:20:40.971704 16565 solver.cpp:244]     Train net output #1: loss = 0.645323 (* 1 = 0.645323 loss)
I0423 15:20:40.971707 16565 solver.cpp:244]     Train net output #2: loss = 0.926224 (* 1 = 0.926224 loss)
I0423 15:20:40.971712 16565 sgd_solver.cpp:106] Iteration 50000, lr = 9e-06
I0423 15:22:20.487143 16565 solver.cpp:228] Iteration 50100, loss = 2.54391
I0423 15:22:20.489573 16565 solver.cpp:244]     Train net output #0: loss = 0.959345 (* 1 = 0.959345 loss)
I0423 15:22:20.489581 16565 solver.cpp:244]     Train net output #1: loss = 0.809693 (* 1 = 0.809693 loss)
I0423 15:22:20.489588 16565 solver.cpp:244]     Train net output #2: loss = 0.774869 (* 1 = 0.774869 loss)
I0423 15:22:20.489591 16565 sgd_solver.cpp:106] Iteration 50100, lr = 9e-06
I0423 15:24:00.201849 16565 solver.cpp:228] Iteration 50200, loss = 1.95146
I0423 15:24:00.202026 16565 solver.cpp:244]     Train net output #0: loss = 0.995185 (* 1 = 0.995185 loss)
I0423 15:24:00.202034 16565 solver.cpp:244]     Train net output #1: loss = 0.570544 (* 1 = 0.570544 loss)
I0423 15:24:00.202039 16565 solver.cpp:244]     Train net output #2: loss = 0.385728 (* 1 = 0.385728 loss)
I0423 15:24:00.202045 16565 sgd_solver.cpp:106] Iteration 50200, lr = 9e-06
I0423 15:25:38.348304 16565 solver.cpp:228] Iteration 50300, loss = 2.43927
I0423 15:25:38.348456 16565 solver.cpp:244]     Train net output #0: loss = 0.965902 (* 1 = 0.965902 loss)
I0423 15:25:38.348464 16565 solver.cpp:244]     Train net output #1: loss = 0.699178 (* 1 = 0.699178 loss)
I0423 15:25:38.348469 16565 solver.cpp:244]     Train net output #2: loss = 0.774193 (* 1 = 0.774193 loss)
I0423 15:25:38.348480 16565 sgd_solver.cpp:106] Iteration 50300, lr = 9e-06
I0423 15:27:18.708575 16565 solver.cpp:228] Iteration 50400, loss = 2.49093
I0423 15:27:18.708940 16565 solver.cpp:244]     Train net output #0: loss = 0.972594 (* 1 = 0.972594 loss)
I0423 15:27:18.708947 16565 solver.cpp:244]     Train net output #1: loss = 0.842593 (* 1 = 0.842593 loss)
I0423 15:27:18.708952 16565 solver.cpp:244]     Train net output #2: loss = 0.675747 (* 1 = 0.675747 loss)
I0423 15:27:18.708957 16565 sgd_solver.cpp:106] Iteration 50400, lr = 9e-06
I0423 15:28:59.324411 16565 solver.cpp:228] Iteration 50500, loss = 2.62815
I0423 15:28:59.324561 16565 solver.cpp:244]     Train net output #0: loss = 0.984252 (* 1 = 0.984252 loss)
I0423 15:28:59.324569 16565 solver.cpp:244]     Train net output #1: loss = 0.902395 (* 1 = 0.902395 loss)
I0423 15:28:59.324574 16565 solver.cpp:244]     Train net output #2: loss = 0.741503 (* 1 = 0.741503 loss)
I0423 15:28:59.324579 16565 sgd_solver.cpp:106] Iteration 50500, lr = 9e-06
I0423 15:30:40.451891 16565 solver.cpp:228] Iteration 50600, loss = 2.77253
I0423 15:30:40.452070 16565 solver.cpp:244]     Train net output #0: loss = 0.977378 (* 1 = 0.977378 loss)
I0423 15:30:40.452078 16565 solver.cpp:244]     Train net output #1: loss = 0.89571 (* 1 = 0.89571 loss)
I0423 15:30:40.452085 16565 solver.cpp:244]     Train net output #2: loss = 0.899437 (* 1 = 0.899437 loss)
I0423 15:30:40.452088 16565 sgd_solver.cpp:106] Iteration 50600, lr = 9e-06
I0423 15:32:18.652730 16565 solver.cpp:228] Iteration 50700, loss = 2.7895
I0423 15:32:18.652876 16565 solver.cpp:244]     Train net output #0: loss = 0.982817 (* 1 = 0.982817 loss)
I0423 15:32:18.652884 16565 solver.cpp:244]     Train net output #1: loss = 0.900908 (* 1 = 0.900908 loss)
I0423 15:32:18.652889 16565 solver.cpp:244]     Train net output #2: loss = 0.905771 (* 1 = 0.905771 loss)
I0423 15:32:18.652894 16565 sgd_solver.cpp:106] Iteration 50700, lr = 9e-06
I0423 15:34:00.925829 16565 solver.cpp:228] Iteration 50800, loss = 2.68539
I0423 15:34:00.925994 16565 solver.cpp:244]     Train net output #0: loss = 0.988661 (* 1 = 0.988661 loss)
I0423 15:34:00.926002 16565 solver.cpp:244]     Train net output #1: loss = 0.844645 (* 1 = 0.844645 loss)
I0423 15:34:00.926008 16565 solver.cpp:244]     Train net output #2: loss = 0.852083 (* 1 = 0.852083 loss)
I0423 15:34:00.926013 16565 sgd_solver.cpp:106] Iteration 50800, lr = 9e-06
I0423 15:35:41.048928 16565 solver.cpp:228] Iteration 50900, loss = 2.83646
I0423 15:35:41.049082 16565 solver.cpp:244]     Train net output #0: loss = 0.987966 (* 1 = 0.987966 loss)
I0423 15:35:41.049091 16565 solver.cpp:244]     Train net output #1: loss = 0.899523 (* 1 = 0.899523 loss)
I0423 15:35:41.049096 16565 solver.cpp:244]     Train net output #2: loss = 0.948971 (* 1 = 0.948971 loss)
I0423 15:35:41.049101 16565 sgd_solver.cpp:106] Iteration 50900, lr = 9e-06
I0423 15:37:20.450261 16565 solver.cpp:337] Iteration 51000, Testing net (#0)
I0423 15:37:20.450407 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 15:37:20.450410 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 15:37:20.450414 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 15:37:20.450429 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 15:37:20.450433 16565 net.cpp:693] Ignoring source layer visualize
I0423 15:37:20.450435 16565 net.cpp:693] Ignoring source layer fake
I0423 15:40:54.854455 16565 solver.cpp:404]     Test net output #0: loss = 0.960095 (* 1 = 0.960095 loss)
I0423 15:40:54.856325 16565 solver.cpp:404]     Test net output #1: loss = 0.724419 (* 1 = 0.724419 loss)
I0423 15:40:54.856334 16565 solver.cpp:404]     Test net output #2: loss = 0.82661 (* 1 = 0.82661 loss)
I0423 15:40:55.507093 16565 solver.cpp:228] Iteration 51000, loss = 2.51238
I0423 15:40:55.507135 16565 solver.cpp:244]     Train net output #0: loss = 0.988203 (* 1 = 0.988203 loss)
I0423 15:40:55.507141 16565 solver.cpp:244]     Train net output #1: loss = 0.772755 (* 1 = 0.772755 loss)
I0423 15:40:55.507145 16565 solver.cpp:244]     Train net output #2: loss = 0.751419 (* 1 = 0.751419 loss)
I0423 15:40:55.507150 16565 sgd_solver.cpp:106] Iteration 51000, lr = 9e-06
I0423 15:42:33.747172 16565 solver.cpp:228] Iteration 51100, loss = 2.4499
I0423 15:42:33.747314 16565 solver.cpp:244]     Train net output #0: loss = 0.987863 (* 1 = 0.987863 loss)
I0423 15:42:33.747323 16565 solver.cpp:244]     Train net output #1: loss = 0.732274 (* 1 = 0.732274 loss)
I0423 15:42:33.747328 16565 solver.cpp:244]     Train net output #2: loss = 0.729763 (* 1 = 0.729763 loss)
I0423 15:42:33.747331 16565 sgd_solver.cpp:106] Iteration 51100, lr = 9e-06
I0423 15:44:14.242848 16565 solver.cpp:228] Iteration 51200, loss = 2.3862
I0423 15:44:14.242990 16565 solver.cpp:244]     Train net output #0: loss = 0.985006 (* 1 = 0.985006 loss)
I0423 15:44:14.242997 16565 solver.cpp:244]     Train net output #1: loss = 0.659854 (* 1 = 0.659854 loss)
I0423 15:44:14.243002 16565 solver.cpp:244]     Train net output #2: loss = 0.741346 (* 1 = 0.741346 loss)
I0423 15:44:14.243006 16565 sgd_solver.cpp:106] Iteration 51200, lr = 9e-06
I0423 15:45:53.854473 16565 solver.cpp:228] Iteration 51300, loss = 2.39559
I0423 15:45:53.854630 16565 solver.cpp:244]     Train net output #0: loss = 0.984438 (* 1 = 0.984438 loss)
I0423 15:45:53.854638 16565 solver.cpp:244]     Train net output #1: loss = 0.536063 (* 1 = 0.536063 loss)
I0423 15:45:53.854642 16565 solver.cpp:244]     Train net output #2: loss = 0.87509 (* 1 = 0.87509 loss)
I0423 15:45:53.854648 16565 sgd_solver.cpp:106] Iteration 51300, lr = 9e-06
I0423 15:47:33.447373 16565 solver.cpp:228] Iteration 51400, loss = 2.53631
I0423 15:47:33.447530 16565 solver.cpp:244]     Train net output #0: loss = 0.977469 (* 1 = 0.977469 loss)
I0423 15:47:33.447537 16565 solver.cpp:244]     Train net output #1: loss = 0.797554 (* 1 = 0.797554 loss)
I0423 15:47:33.447542 16565 solver.cpp:244]     Train net output #2: loss = 0.76129 (* 1 = 0.76129 loss)
I0423 15:47:33.447548 16565 sgd_solver.cpp:106] Iteration 51400, lr = 9e-06
I0423 15:49:13.822418 16565 solver.cpp:228] Iteration 51500, loss = 2.33786
I0423 15:49:13.822598 16565 solver.cpp:244]     Train net output #0: loss = 0.982924 (* 1 = 0.982924 loss)
I0423 15:49:13.822607 16565 solver.cpp:244]     Train net output #1: loss = 0.843831 (* 1 = 0.843831 loss)
I0423 15:49:13.822612 16565 solver.cpp:244]     Train net output #2: loss = 0.511102 (* 1 = 0.511102 loss)
I0423 15:49:13.822616 16565 sgd_solver.cpp:106] Iteration 51500, lr = 9e-06
I0423 15:50:54.257967 16565 solver.cpp:228] Iteration 51600, loss = 2.63504
I0423 15:50:54.259624 16565 solver.cpp:244]     Train net output #0: loss = 0.975094 (* 1 = 0.975094 loss)
I0423 15:50:54.259632 16565 solver.cpp:244]     Train net output #1: loss = 0.824239 (* 1 = 0.824239 loss)
I0423 15:50:54.259636 16565 solver.cpp:244]     Train net output #2: loss = 0.835711 (* 1 = 0.835711 loss)
I0423 15:50:54.259641 16565 sgd_solver.cpp:106] Iteration 51600, lr = 9e-06
I0423 15:52:35.229416 16565 solver.cpp:228] Iteration 51700, loss = 2.69221
I0423 15:52:35.229588 16565 solver.cpp:244]     Train net output #0: loss = 0.976484 (* 1 = 0.976484 loss)
I0423 15:52:35.229595 16565 solver.cpp:244]     Train net output #1: loss = 0.833693 (* 1 = 0.833693 loss)
I0423 15:52:35.229600 16565 solver.cpp:244]     Train net output #2: loss = 0.882032 (* 1 = 0.882032 loss)
I0423 15:52:35.229606 16565 sgd_solver.cpp:106] Iteration 51700, lr = 9e-06
I0423 15:54:13.698246 16565 solver.cpp:228] Iteration 51800, loss = 2.66835
I0423 15:54:13.698449 16565 solver.cpp:244]     Train net output #0: loss = 0.96674 (* 1 = 0.96674 loss)
I0423 15:54:13.698458 16565 solver.cpp:244]     Train net output #1: loss = 0.800081 (* 1 = 0.800081 loss)
I0423 15:54:13.698464 16565 solver.cpp:244]     Train net output #2: loss = 0.901529 (* 1 = 0.901529 loss)
I0423 15:54:13.698469 16565 sgd_solver.cpp:106] Iteration 51800, lr = 9e-06
I0423 15:55:54.591568 16565 solver.cpp:228] Iteration 51900, loss = 2.60472
I0423 15:55:54.591737 16565 solver.cpp:244]     Train net output #0: loss = 0.97765 (* 1 = 0.97765 loss)
I0423 15:55:54.591747 16565 solver.cpp:244]     Train net output #1: loss = 0.775825 (* 1 = 0.775825 loss)
I0423 15:55:54.591751 16565 solver.cpp:244]     Train net output #2: loss = 0.851249 (* 1 = 0.851249 loss)
I0423 15:55:54.591756 16565 sgd_solver.cpp:106] Iteration 51900, lr = 9e-06
I0423 15:57:34.965978 16565 solver.cpp:337] Iteration 52000, Testing net (#0)
I0423 15:57:34.966105 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 15:57:34.966109 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 15:57:34.966114 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 15:57:34.966127 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 15:57:34.966131 16565 net.cpp:693] Ignoring source layer visualize
I0423 15:57:34.966132 16565 net.cpp:693] Ignoring source layer fake
I0423 16:01:08.757395 16565 solver.cpp:404]     Test net output #0: loss = 0.976826 (* 1 = 0.976826 loss)
I0423 16:01:08.757531 16565 solver.cpp:404]     Test net output #1: loss = 0.746535 (* 1 = 0.746535 loss)
I0423 16:01:08.757539 16565 solver.cpp:404]     Test net output #2: loss = 0.800372 (* 1 = 0.800372 loss)
I0423 16:01:09.405206 16565 solver.cpp:228] Iteration 52000, loss = 2.67954
I0423 16:01:09.405246 16565 solver.cpp:244]     Train net output #0: loss = 0.987727 (* 1 = 0.987727 loss)
I0423 16:01:09.405252 16565 solver.cpp:244]     Train net output #1: loss = 0.806705 (* 1 = 0.806705 loss)
I0423 16:01:09.405256 16565 solver.cpp:244]     Train net output #2: loss = 0.885111 (* 1 = 0.885111 loss)
I0423 16:01:09.405261 16565 sgd_solver.cpp:106] Iteration 52000, lr = 9e-06
I0423 16:02:47.576678 16565 solver.cpp:228] Iteration 52100, loss = 2.6816
I0423 16:02:47.576829 16565 solver.cpp:244]     Train net output #0: loss = 0.987229 (* 1 = 0.987229 loss)
I0423 16:02:47.576838 16565 solver.cpp:244]     Train net output #1: loss = 0.809823 (* 1 = 0.809823 loss)
I0423 16:02:47.576843 16565 solver.cpp:244]     Train net output #2: loss = 0.884545 (* 1 = 0.884545 loss)
I0423 16:02:47.576846 16565 sgd_solver.cpp:106] Iteration 52100, lr = 9e-06
I0423 16:04:28.815225 16565 solver.cpp:228] Iteration 52200, loss = 2.76685
I0423 16:04:28.815389 16565 solver.cpp:244]     Train net output #0: loss = 0.985127 (* 1 = 0.985127 loss)
I0423 16:04:28.815397 16565 solver.cpp:244]     Train net output #1: loss = 0.868154 (* 1 = 0.868154 loss)
I0423 16:04:28.815402 16565 solver.cpp:244]     Train net output #2: loss = 0.913571 (* 1 = 0.913571 loss)
I0423 16:04:28.815408 16565 sgd_solver.cpp:106] Iteration 52200, lr = 9e-06
I0423 16:06:09.393474 16565 solver.cpp:228] Iteration 52300, loss = 2.15855
I0423 16:06:09.393615 16565 solver.cpp:244]     Train net output #0: loss = 0.988817 (* 1 = 0.988817 loss)
I0423 16:06:09.393621 16565 solver.cpp:244]     Train net output #1: loss = 0.608221 (* 1 = 0.608221 loss)
I0423 16:06:09.393626 16565 solver.cpp:244]     Train net output #2: loss = 0.561516 (* 1 = 0.561516 loss)
I0423 16:06:09.393633 16565 sgd_solver.cpp:106] Iteration 52300, lr = 9e-06
I0423 16:07:57.800245 16565 solver.cpp:228] Iteration 52400, loss = 2.31795
I0423 16:07:57.800397 16565 solver.cpp:244]     Train net output #0: loss = 0.976438 (* 1 = 0.976438 loss)
I0423 16:07:57.800405 16565 solver.cpp:244]     Train net output #1: loss = 0.684213 (* 1 = 0.684213 loss)
I0423 16:07:57.800411 16565 solver.cpp:244]     Train net output #2: loss = 0.657295 (* 1 = 0.657295 loss)
I0423 16:07:57.800416 16565 sgd_solver.cpp:106] Iteration 52400, lr = 9e-06
I0423 16:09:49.655788 16565 solver.cpp:228] Iteration 52500, loss = 2.57977
I0423 16:09:49.656172 16565 solver.cpp:244]     Train net output #0: loss = 0.980055 (* 1 = 0.980055 loss)
I0423 16:09:49.656180 16565 solver.cpp:244]     Train net output #1: loss = 0.657281 (* 1 = 0.657281 loss)
I0423 16:09:49.656185 16565 solver.cpp:244]     Train net output #2: loss = 0.942433 (* 1 = 0.942433 loss)
I0423 16:09:49.656190 16565 sgd_solver.cpp:106] Iteration 52500, lr = 9e-06
I0423 16:11:40.349382 16565 solver.cpp:228] Iteration 52600, loss = 2.28294
I0423 16:11:40.349536 16565 solver.cpp:244]     Train net output #0: loss = 0.962632 (* 1 = 0.962632 loss)
I0423 16:11:40.349545 16565 solver.cpp:244]     Train net output #1: loss = 0.655395 (* 1 = 0.655395 loss)
I0423 16:11:40.349550 16565 solver.cpp:244]     Train net output #2: loss = 0.664909 (* 1 = 0.664909 loss)
I0423 16:11:40.349555 16565 sgd_solver.cpp:106] Iteration 52600, lr = 9e-06
I0423 16:13:31.326920 16565 solver.cpp:228] Iteration 52700, loss = 2.24015
I0423 16:13:31.327078 16565 solver.cpp:244]     Train net output #0: loss = 0.976423 (* 1 = 0.976423 loss)
I0423 16:13:31.327086 16565 solver.cpp:244]     Train net output #1: loss = 0.691112 (* 1 = 0.691112 loss)
I0423 16:13:31.327091 16565 solver.cpp:244]     Train net output #2: loss = 0.572611 (* 1 = 0.572611 loss)
I0423 16:13:31.327096 16565 sgd_solver.cpp:106] Iteration 52700, lr = 9e-06
I0423 16:15:09.227885 16565 solver.cpp:228] Iteration 52800, loss = 2.55005
I0423 16:15:09.228045 16565 solver.cpp:244]     Train net output #0: loss = 0.978338 (* 1 = 0.978338 loss)
I0423 16:15:09.228054 16565 solver.cpp:244]     Train net output #1: loss = 0.808958 (* 1 = 0.808958 loss)
I0423 16:15:09.228060 16565 solver.cpp:244]     Train net output #2: loss = 0.762752 (* 1 = 0.762752 loss)
I0423 16:15:09.228065 16565 sgd_solver.cpp:106] Iteration 52800, lr = 9e-06
I0423 16:16:53.416590 16565 solver.cpp:228] Iteration 52900, loss = 2.64236
I0423 16:16:53.416764 16565 solver.cpp:244]     Train net output #0: loss = 0.951194 (* 1 = 0.951194 loss)
I0423 16:16:53.416774 16565 solver.cpp:244]     Train net output #1: loss = 0.806599 (* 1 = 0.806599 loss)
I0423 16:16:53.416779 16565 solver.cpp:244]     Train net output #2: loss = 0.884568 (* 1 = 0.884568 loss)
I0423 16:16:53.416784 16565 sgd_solver.cpp:106] Iteration 52900, lr = 9e-06
I0423 16:18:35.770037 16565 solver.cpp:337] Iteration 53000, Testing net (#0)
I0423 16:18:35.770187 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 16:18:35.770191 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 16:18:35.770195 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 16:18:35.770210 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 16:18:35.770215 16565 net.cpp:693] Ignoring source layer visualize
I0423 16:18:35.770216 16565 net.cpp:693] Ignoring source layer fake
I0423 16:22:11.847687 16565 solver.cpp:404]     Test net output #0: loss = 0.977325 (* 1 = 0.977325 loss)
I0423 16:22:11.848424 16565 solver.cpp:404]     Test net output #1: loss = 0.757267 (* 1 = 0.757267 loss)
I0423 16:22:11.848433 16565 solver.cpp:404]     Test net output #2: loss = 0.81482 (* 1 = 0.81482 loss)
I0423 16:22:12.505810 16565 solver.cpp:228] Iteration 53000, loss = 2.54812
I0423 16:22:12.505853 16565 solver.cpp:244]     Train net output #0: loss = 0.977309 (* 1 = 0.977309 loss)
I0423 16:22:12.505859 16565 solver.cpp:244]     Train net output #1: loss = 0.804765 (* 1 = 0.804765 loss)
I0423 16:22:12.505863 16565 solver.cpp:244]     Train net output #2: loss = 0.766041 (* 1 = 0.766041 loss)
I0423 16:22:12.505868 16565 sgd_solver.cpp:106] Iteration 53000, lr = 9e-06
I0423 16:23:58.152328 16565 solver.cpp:228] Iteration 53100, loss = 2.69069
I0423 16:23:58.152531 16565 solver.cpp:244]     Train net output #0: loss = 0.975852 (* 1 = 0.975852 loss)
I0423 16:23:58.152540 16565 solver.cpp:244]     Train net output #1: loss = 0.80386 (* 1 = 0.80386 loss)
I0423 16:23:58.152545 16565 solver.cpp:244]     Train net output #2: loss = 0.910981 (* 1 = 0.910981 loss)
I0423 16:23:58.152551 16565 sgd_solver.cpp:106] Iteration 53100, lr = 9e-06
I0423 16:25:36.081665 16565 solver.cpp:228] Iteration 53200, loss = 2.65087
I0423 16:25:36.081809 16565 solver.cpp:244]     Train net output #0: loss = 0.958922 (* 1 = 0.958922 loss)
I0423 16:25:36.081816 16565 solver.cpp:244]     Train net output #1: loss = 0.778233 (* 1 = 0.778233 loss)
I0423 16:25:36.081821 16565 solver.cpp:244]     Train net output #2: loss = 0.913716 (* 1 = 0.913716 loss)
I0423 16:25:36.081825 16565 sgd_solver.cpp:106] Iteration 53200, lr = 9e-06
I0423 16:27:19.298785 16565 solver.cpp:228] Iteration 53300, loss = 2.69012
I0423 16:27:19.298939 16565 solver.cpp:244]     Train net output #0: loss = 0.985318 (* 1 = 0.985318 loss)
I0423 16:27:19.298946 16565 solver.cpp:244]     Train net output #1: loss = 0.806651 (* 1 = 0.806651 loss)
I0423 16:27:19.298951 16565 solver.cpp:244]     Train net output #2: loss = 0.898148 (* 1 = 0.898148 loss)
I0423 16:27:19.298957 16565 sgd_solver.cpp:106] Iteration 53300, lr = 9e-06
I0423 16:29:01.041990 16565 solver.cpp:228] Iteration 53400, loss = 2.77961
I0423 16:29:01.042140 16565 solver.cpp:244]     Train net output #0: loss = 0.991145 (* 1 = 0.991145 loss)
I0423 16:29:01.042148 16565 solver.cpp:244]     Train net output #1: loss = 0.84311 (* 1 = 0.84311 loss)
I0423 16:29:01.042155 16565 solver.cpp:244]     Train net output #2: loss = 0.945357 (* 1 = 0.945357 loss)
I0423 16:29:01.042160 16565 sgd_solver.cpp:106] Iteration 53400, lr = 9e-06
I0423 16:30:42.417265 16565 solver.cpp:228] Iteration 53500, loss = 2.5381
I0423 16:30:42.417426 16565 solver.cpp:244]     Train net output #0: loss = 0.989016 (* 1 = 0.989016 loss)
I0423 16:30:42.417443 16565 solver.cpp:244]     Train net output #1: loss = 0.801526 (* 1 = 0.801526 loss)
I0423 16:30:42.417448 16565 solver.cpp:244]     Train net output #2: loss = 0.747562 (* 1 = 0.747562 loss)
I0423 16:30:42.417453 16565 sgd_solver.cpp:106] Iteration 53500, lr = 9e-06
I0423 16:32:20.324012 16565 solver.cpp:228] Iteration 53600, loss = 2.51287
I0423 16:32:20.324187 16565 solver.cpp:244]     Train net output #0: loss = 0.979123 (* 1 = 0.979123 loss)
I0423 16:32:20.324195 16565 solver.cpp:244]     Train net output #1: loss = 0.777828 (* 1 = 0.777828 loss)
I0423 16:32:20.324200 16565 solver.cpp:244]     Train net output #2: loss = 0.75592 (* 1 = 0.75592 loss)
I0423 16:32:20.324204 16565 sgd_solver.cpp:106] Iteration 53600, lr = 9e-06
I0423 16:34:01.860990 16565 solver.cpp:228] Iteration 53700, loss = 2.24639
I0423 16:34:01.861155 16565 solver.cpp:244]     Train net output #0: loss = 0.98799 (* 1 = 0.98799 loss)
I0423 16:34:01.861162 16565 solver.cpp:244]     Train net output #1: loss = 0.529476 (* 1 = 0.529476 loss)
I0423 16:34:01.861167 16565 solver.cpp:244]     Train net output #2: loss = 0.728929 (* 1 = 0.728929 loss)
I0423 16:34:01.861173 16565 sgd_solver.cpp:106] Iteration 53700, lr = 9e-06
I0423 16:35:42.467041 16565 solver.cpp:228] Iteration 53800, loss = 2.46753
I0423 16:35:42.467190 16565 solver.cpp:244]     Train net output #0: loss = 0.973216 (* 1 = 0.973216 loss)
I0423 16:35:42.467198 16565 solver.cpp:244]     Train net output #1: loss = 0.603595 (* 1 = 0.603595 loss)
I0423 16:35:42.467205 16565 solver.cpp:244]     Train net output #2: loss = 0.890719 (* 1 = 0.890719 loss)
I0423 16:35:42.467208 16565 sgd_solver.cpp:106] Iteration 53800, lr = 9e-06
I0423 16:37:22.795861 16565 solver.cpp:228] Iteration 53900, loss = 2.46691
I0423 16:37:22.796190 16565 solver.cpp:244]     Train net output #0: loss = 0.970896 (* 1 = 0.970896 loss)
I0423 16:37:22.796198 16565 solver.cpp:244]     Train net output #1: loss = 0.723921 (* 1 = 0.723921 loss)
I0423 16:37:22.796203 16565 solver.cpp:244]     Train net output #2: loss = 0.772097 (* 1 = 0.772097 loss)
I0423 16:37:22.796210 16565 sgd_solver.cpp:106] Iteration 53900, lr = 9e-06
I0423 16:39:03.200898 16565 solver.cpp:337] Iteration 54000, Testing net (#0)
I0423 16:39:03.201083 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 16:39:03.201087 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 16:39:03.201092 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 16:39:03.201107 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 16:39:03.201110 16565 net.cpp:693] Ignoring source layer visualize
I0423 16:39:03.201112 16565 net.cpp:693] Ignoring source layer fake
I0423 16:42:37.116379 16565 solver.cpp:404]     Test net output #0: loss = 0.976741 (* 1 = 0.976741 loss)
I0423 16:42:37.116538 16565 solver.cpp:404]     Test net output #1: loss = 0.755293 (* 1 = 0.755293 loss)
I0423 16:42:37.116545 16565 solver.cpp:404]     Test net output #2: loss = 0.812576 (* 1 = 0.812576 loss)
I0423 16:42:37.770288 16565 solver.cpp:228] Iteration 54000, loss = 2.44042
I0423 16:42:37.770329 16565 solver.cpp:244]     Train net output #0: loss = 0.980733 (* 1 = 0.980733 loss)
I0423 16:42:37.770334 16565 solver.cpp:244]     Train net output #1: loss = 0.763288 (* 1 = 0.763288 loss)
I0423 16:42:37.770339 16565 solver.cpp:244]     Train net output #2: loss = 0.696402 (* 1 = 0.696402 loss)
I0423 16:42:37.770344 16565 sgd_solver.cpp:106] Iteration 54000, lr = 9e-06
I0423 16:44:17.800346 16565 solver.cpp:228] Iteration 54100, loss = 2.52069
I0423 16:44:17.800515 16565 solver.cpp:244]     Train net output #0: loss = 0.976767 (* 1 = 0.976767 loss)
I0423 16:44:17.800524 16565 solver.cpp:244]     Train net output #1: loss = 0.842147 (* 1 = 0.842147 loss)
I0423 16:44:17.800529 16565 solver.cpp:244]     Train net output #2: loss = 0.701781 (* 1 = 0.701781 loss)
I0423 16:44:17.800534 16565 sgd_solver.cpp:106] Iteration 54100, lr = 9e-06
I0423 16:45:57.753409 16565 solver.cpp:228] Iteration 54200, loss = 2.67583
I0423 16:45:57.753577 16565 solver.cpp:244]     Train net output #0: loss = 0.97178 (* 1 = 0.97178 loss)
I0423 16:45:57.753585 16565 solver.cpp:244]     Train net output #1: loss = 0.815429 (* 1 = 0.815429 loss)
I0423 16:45:57.753589 16565 solver.cpp:244]     Train net output #2: loss = 0.888617 (* 1 = 0.888617 loss)
I0423 16:45:57.753594 16565 sgd_solver.cpp:106] Iteration 54200, lr = 9e-06
I0423 16:47:35.903985 16565 solver.cpp:228] Iteration 54300, loss = 2.74353
I0423 16:47:35.904141 16565 solver.cpp:244]     Train net output #0: loss = 0.967565 (* 1 = 0.967565 loss)
I0423 16:47:35.904150 16565 solver.cpp:244]     Train net output #1: loss = 0.853792 (* 1 = 0.853792 loss)
I0423 16:47:35.904155 16565 solver.cpp:244]     Train net output #2: loss = 0.922176 (* 1 = 0.922176 loss)
I0423 16:47:35.904160 16565 sgd_solver.cpp:106] Iteration 54300, lr = 9e-06
I0423 16:49:15.910796 16565 solver.cpp:228] Iteration 54400, loss = 2.71881
I0423 16:49:15.910935 16565 solver.cpp:244]     Train net output #0: loss = 0.97451 (* 1 = 0.97451 loss)
I0423 16:49:15.910943 16565 solver.cpp:244]     Train net output #1: loss = 0.849557 (* 1 = 0.849557 loss)
I0423 16:49:15.910949 16565 solver.cpp:244]     Train net output #2: loss = 0.894739 (* 1 = 0.894739 loss)
I0423 16:49:15.910954 16565 sgd_solver.cpp:106] Iteration 54400, lr = 9e-06
I0423 16:50:56.813285 16565 solver.cpp:228] Iteration 54500, loss = 2.6268
I0423 16:50:56.813459 16565 solver.cpp:244]     Train net output #0: loss = 0.979996 (* 1 = 0.979996 loss)
I0423 16:50:56.813468 16565 solver.cpp:244]     Train net output #1: loss = 0.734697 (* 1 = 0.734697 loss)
I0423 16:50:56.813473 16565 solver.cpp:244]     Train net output #2: loss = 0.912103 (* 1 = 0.912103 loss)
I0423 16:50:56.813479 16565 sgd_solver.cpp:106] Iteration 54500, lr = 9e-06
I0423 16:52:34.980849 16565 solver.cpp:228] Iteration 54600, loss = 2.72387
I0423 16:52:34.981004 16565 solver.cpp:244]     Train net output #0: loss = 0.97706 (* 1 = 0.97706 loss)
I0423 16:52:34.981012 16565 solver.cpp:244]     Train net output #1: loss = 0.807282 (* 1 = 0.807282 loss)
I0423 16:52:34.981017 16565 solver.cpp:244]     Train net output #2: loss = 0.939524 (* 1 = 0.939524 loss)
I0423 16:52:34.981022 16565 sgd_solver.cpp:106] Iteration 54600, lr = 9e-06
I0423 16:54:15.681426 16565 solver.cpp:228] Iteration 54700, loss = 2.79947
I0423 16:54:15.681627 16565 solver.cpp:244]     Train net output #0: loss = 0.981905 (* 1 = 0.981905 loss)
I0423 16:54:15.681634 16565 solver.cpp:244]     Train net output #1: loss = 0.862624 (* 1 = 0.862624 loss)
I0423 16:54:15.681639 16565 solver.cpp:244]     Train net output #2: loss = 0.954946 (* 1 = 0.954946 loss)
I0423 16:54:15.681646 16565 sgd_solver.cpp:106] Iteration 54700, lr = 9e-06
I0423 16:55:56.299572 16565 solver.cpp:228] Iteration 54800, loss = 2.59166
I0423 16:55:56.300509 16565 solver.cpp:244]     Train net output #0: loss = 0.987451 (* 1 = 0.987451 loss)
I0423 16:55:56.300518 16565 solver.cpp:244]     Train net output #1: loss = 0.685282 (* 1 = 0.685282 loss)
I0423 16:55:56.300524 16565 solver.cpp:244]     Train net output #2: loss = 0.918922 (* 1 = 0.918922 loss)
I0423 16:55:56.300529 16565 sgd_solver.cpp:106] Iteration 54800, lr = 9e-06
I0423 16:57:39.149518 16565 solver.cpp:228] Iteration 54900, loss = 2.6237
I0423 16:57:39.149672 16565 solver.cpp:244]     Train net output #0: loss = 0.986365 (* 1 = 0.986365 loss)
I0423 16:57:39.149679 16565 solver.cpp:244]     Train net output #1: loss = 0.767887 (* 1 = 0.767887 loss)
I0423 16:57:39.149684 16565 solver.cpp:244]     Train net output #2: loss = 0.869449 (* 1 = 0.869449 loss)
I0423 16:57:39.149689 16565 sgd_solver.cpp:106] Iteration 54900, lr = 9e-06
I0423 16:59:18.099345 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_55000.caffemodel
I0423 16:59:23.025657 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_55000.solverstate
I0423 16:59:23.227406 16565 solver.cpp:337] Iteration 55000, Testing net (#0)
I0423 16:59:23.227452 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 16:59:23.227453 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 16:59:23.227458 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 16:59:23.227474 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 16:59:23.227478 16565 net.cpp:693] Ignoring source layer visualize
I0423 16:59:23.227479 16565 net.cpp:693] Ignoring source layer fake
I0423 17:02:57.014117 16565 solver.cpp:404]     Test net output #0: loss = 0.967253 (* 1 = 0.967253 loss)
I0423 17:02:57.014250 16565 solver.cpp:404]     Test net output #1: loss = 0.735704 (* 1 = 0.735704 loss)
I0423 17:02:57.014256 16565 solver.cpp:404]     Test net output #2: loss = 0.817889 (* 1 = 0.817889 loss)
I0423 17:02:57.669028 16565 solver.cpp:228] Iteration 55000, loss = 2.39715
I0423 17:02:57.669057 16565 solver.cpp:244]     Train net output #0: loss = 0.981998 (* 1 = 0.981998 loss)
I0423 17:02:57.669062 16565 solver.cpp:244]     Train net output #1: loss = 0.514381 (* 1 = 0.514381 loss)
I0423 17:02:57.669067 16565 solver.cpp:244]     Train net output #2: loss = 0.90077 (* 1 = 0.90077 loss)
I0423 17:02:57.669071 16565 sgd_solver.cpp:106] Iteration 55000, lr = 9e-06
I0423 17:04:39.145059 16565 solver.cpp:228] Iteration 55100, loss = 2.67894
I0423 17:04:39.146983 16565 solver.cpp:244]     Train net output #0: loss = 0.959567 (* 1 = 0.959567 loss)
I0423 17:04:39.146991 16565 solver.cpp:244]     Train net output #1: loss = 0.763765 (* 1 = 0.763765 loss)
I0423 17:04:39.146997 16565 solver.cpp:244]     Train net output #2: loss = 0.955611 (* 1 = 0.955611 loss)
I0423 17:04:39.147001 16565 sgd_solver.cpp:106] Iteration 55100, lr = 9e-06
I0423 17:06:21.836025 16565 solver.cpp:228] Iteration 55200, loss = 2.72835
I0423 17:06:21.836194 16565 solver.cpp:244]     Train net output #0: loss = 0.972834 (* 1 = 0.972834 loss)
I0423 17:06:21.836202 16565 solver.cpp:244]     Train net output #1: loss = 0.799726 (* 1 = 0.799726 loss)
I0423 17:06:21.836208 16565 solver.cpp:244]     Train net output #2: loss = 0.955794 (* 1 = 0.955794 loss)
I0423 17:06:21.836213 16565 sgd_solver.cpp:106] Iteration 55200, lr = 9e-06
I0423 17:07:59.779858 16565 solver.cpp:228] Iteration 55300, loss = 2.51564
I0423 17:07:59.780026 16565 solver.cpp:244]     Train net output #0: loss = 0.984281 (* 1 = 0.984281 loss)
I0423 17:07:59.780035 16565 solver.cpp:244]     Train net output #1: loss = 0.771016 (* 1 = 0.771016 loss)
I0423 17:07:59.780040 16565 solver.cpp:244]     Train net output #2: loss = 0.760339 (* 1 = 0.760339 loss)
I0423 17:07:59.780045 16565 sgd_solver.cpp:106] Iteration 55300, lr = 9e-06
I0423 17:09:41.554664 16565 solver.cpp:228] Iteration 55400, loss = 2.72878
I0423 17:09:41.554996 16565 solver.cpp:244]     Train net output #0: loss = 0.957159 (* 1 = 0.957159 loss)
I0423 17:09:41.555003 16565 solver.cpp:244]     Train net output #1: loss = 0.843606 (* 1 = 0.843606 loss)
I0423 17:09:41.555008 16565 solver.cpp:244]     Train net output #2: loss = 0.928019 (* 1 = 0.928019 loss)
I0423 17:09:41.555013 16565 sgd_solver.cpp:106] Iteration 55400, lr = 9e-06
I0423 17:11:24.105006 16565 solver.cpp:228] Iteration 55500, loss = 2.62622
I0423 17:11:24.105175 16565 solver.cpp:244]     Train net output #0: loss = 0.976608 (* 1 = 0.976608 loss)
I0423 17:11:24.105183 16565 solver.cpp:244]     Train net output #1: loss = 0.781542 (* 1 = 0.781542 loss)
I0423 17:11:24.105188 16565 solver.cpp:244]     Train net output #2: loss = 0.868066 (* 1 = 0.868066 loss)
I0423 17:11:24.105195 16565 sgd_solver.cpp:106] Iteration 55500, lr = 9e-06
I0423 17:13:06.406805 16565 solver.cpp:228] Iteration 55600, loss = 2.61758
I0423 17:13:06.406988 16565 solver.cpp:244]     Train net output #0: loss = 0.972609 (* 1 = 0.972609 loss)
I0423 17:13:06.406996 16565 solver.cpp:244]     Train net output #1: loss = 0.776681 (* 1 = 0.776681 loss)
I0423 17:13:06.407002 16565 solver.cpp:244]     Train net output #2: loss = 0.868285 (* 1 = 0.868285 loss)
I0423 17:13:06.407007 16565 sgd_solver.cpp:106] Iteration 55600, lr = 9e-06
I0423 17:14:44.588558 16565 solver.cpp:228] Iteration 55700, loss = 2.70124
I0423 17:14:44.588719 16565 solver.cpp:244]     Train net output #0: loss = 0.95073 (* 1 = 0.95073 loss)
I0423 17:14:44.588728 16565 solver.cpp:244]     Train net output #1: loss = 0.799486 (* 1 = 0.799486 loss)
I0423 17:14:44.588733 16565 solver.cpp:244]     Train net output #2: loss = 0.951021 (* 1 = 0.951021 loss)
I0423 17:14:44.588737 16565 sgd_solver.cpp:106] Iteration 55700, lr = 9e-06
I0423 17:16:26.394757 16565 solver.cpp:228] Iteration 55800, loss = 2.60414
I0423 17:16:26.394920 16565 solver.cpp:244]     Train net output #0: loss = 0.988146 (* 1 = 0.988146 loss)
I0423 17:16:26.394928 16565 solver.cpp:244]     Train net output #1: loss = 0.722663 (* 1 = 0.722663 loss)
I0423 17:16:26.394933 16565 solver.cpp:244]     Train net output #2: loss = 0.893327 (* 1 = 0.893327 loss)
I0423 17:16:26.394938 16565 sgd_solver.cpp:106] Iteration 55800, lr = 9e-06
I0423 17:18:08.306411 16565 solver.cpp:228] Iteration 55900, loss = 2.83777
I0423 17:18:08.306545 16565 solver.cpp:244]     Train net output #0: loss = 0.98988 (* 1 = 0.98988 loss)
I0423 17:18:08.306551 16565 solver.cpp:244]     Train net output #1: loss = 0.886373 (* 1 = 0.886373 loss)
I0423 17:18:08.306556 16565 solver.cpp:244]     Train net output #2: loss = 0.96152 (* 1 = 0.96152 loss)
I0423 17:18:08.306562 16565 sgd_solver.cpp:106] Iteration 55900, lr = 9e-06
I0423 17:19:47.142117 16565 solver.cpp:337] Iteration 56000, Testing net (#0)
I0423 17:19:47.142284 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 17:19:47.142289 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 17:19:47.142294 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 17:19:47.142310 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 17:19:47.142313 16565 net.cpp:693] Ignoring source layer visualize
I0423 17:19:47.142315 16565 net.cpp:693] Ignoring source layer fake
I0423 17:23:20.997299 16565 solver.cpp:404]     Test net output #0: loss = 0.962285 (* 1 = 0.962285 loss)
I0423 17:23:20.997433 16565 solver.cpp:404]     Test net output #1: loss = 0.7303 (* 1 = 0.7303 loss)
I0423 17:23:20.997449 16565 solver.cpp:404]     Test net output #2: loss = 0.826994 (* 1 = 0.826994 loss)
I0423 17:23:21.653630 16565 solver.cpp:228] Iteration 56000, loss = 2.772
I0423 17:23:21.653672 16565 solver.cpp:244]     Train net output #0: loss = 0.985422 (* 1 = 0.985422 loss)
I0423 17:23:21.653678 16565 solver.cpp:244]     Train net output #1: loss = 0.871542 (* 1 = 0.871542 loss)
I0423 17:23:21.653682 16565 solver.cpp:244]     Train net output #2: loss = 0.915038 (* 1 = 0.915038 loss)
I0423 17:23:21.653687 16565 sgd_solver.cpp:106] Iteration 56000, lr = 9e-06
I0423 17:24:59.830061 16565 solver.cpp:228] Iteration 56100, loss = 2.79185
I0423 17:24:59.830222 16565 solver.cpp:244]     Train net output #0: loss = 0.985218 (* 1 = 0.985218 loss)
I0423 17:24:59.830230 16565 solver.cpp:244]     Train net output #1: loss = 0.873228 (* 1 = 0.873228 loss)
I0423 17:24:59.830235 16565 solver.cpp:244]     Train net output #2: loss = 0.933402 (* 1 = 0.933402 loss)
I0423 17:24:59.830241 16565 sgd_solver.cpp:106] Iteration 56100, lr = 9e-06
I0423 17:26:41.497970 16565 solver.cpp:228] Iteration 56200, loss = 2.63237
I0423 17:26:41.498142 16565 solver.cpp:244]     Train net output #0: loss = 0.985713 (* 1 = 0.985713 loss)
I0423 17:26:41.498150 16565 solver.cpp:244]     Train net output #1: loss = 0.738501 (* 1 = 0.738501 loss)
I0423 17:26:41.498155 16565 solver.cpp:244]     Train net output #2: loss = 0.908158 (* 1 = 0.908158 loss)
I0423 17:26:41.498160 16565 sgd_solver.cpp:106] Iteration 56200, lr = 9e-06
I0423 17:28:29.486335 16565 solver.cpp:228] Iteration 56300, loss = 2.69532
I0423 17:28:29.486491 16565 solver.cpp:244]     Train net output #0: loss = 0.969029 (* 1 = 0.969029 loss)
I0423 17:28:29.486500 16565 solver.cpp:244]     Train net output #1: loss = 0.778204 (* 1 = 0.778204 loss)
I0423 17:28:29.486506 16565 solver.cpp:244]     Train net output #2: loss = 0.948086 (* 1 = 0.948086 loss)
I0423 17:28:29.486512 16565 sgd_solver.cpp:106] Iteration 56300, lr = 9e-06
I0423 17:30:18.268848 16565 solver.cpp:228] Iteration 56400, loss = 2.18715
I0423 17:30:18.269011 16565 solver.cpp:244]     Train net output #0: loss = 0.984979 (* 1 = 0.984979 loss)
I0423 17:30:18.269019 16565 solver.cpp:244]     Train net output #1: loss = 0.655005 (* 1 = 0.655005 loss)
I0423 17:30:18.269024 16565 solver.cpp:244]     Train net output #2: loss = 0.547162 (* 1 = 0.547162 loss)
I0423 17:30:18.269029 16565 sgd_solver.cpp:106] Iteration 56400, lr = 9e-06
I0423 17:32:00.794004 16565 solver.cpp:228] Iteration 56500, loss = 2.54137
I0423 17:32:00.794145 16565 solver.cpp:244]     Train net output #0: loss = 0.976593 (* 1 = 0.976593 loss)
I0423 17:32:00.794153 16565 solver.cpp:244]     Train net output #1: loss = 0.799031 (* 1 = 0.799031 loss)
I0423 17:32:00.794159 16565 solver.cpp:244]     Train net output #2: loss = 0.765746 (* 1 = 0.765746 loss)
I0423 17:32:00.794164 16565 sgd_solver.cpp:106] Iteration 56500, lr = 9e-06
I0423 17:33:43.059106 16565 solver.cpp:228] Iteration 56600, loss = 2.5289
I0423 17:33:43.059257 16565 solver.cpp:244]     Train net output #0: loss = 0.975702 (* 1 = 0.975702 loss)
I0423 17:33:43.059264 16565 solver.cpp:244]     Train net output #1: loss = 0.864257 (* 1 = 0.864257 loss)
I0423 17:33:43.059270 16565 solver.cpp:244]     Train net output #2: loss = 0.688938 (* 1 = 0.688938 loss)
I0423 17:33:43.059274 16565 sgd_solver.cpp:106] Iteration 56600, lr = 9e-06
I0423 17:35:23.976730 16565 solver.cpp:228] Iteration 56700, loss = 2.55616
I0423 17:35:23.976888 16565 solver.cpp:244]     Train net output #0: loss = 0.979495 (* 1 = 0.979495 loss)
I0423 17:35:23.976897 16565 solver.cpp:244]     Train net output #1: loss = 0.850141 (* 1 = 0.850141 loss)
I0423 17:35:23.976902 16565 solver.cpp:244]     Train net output #2: loss = 0.726527 (* 1 = 0.726527 loss)
I0423 17:35:23.976908 16565 sgd_solver.cpp:106] Iteration 56700, lr = 9e-06
I0423 17:37:02.148980 16565 solver.cpp:228] Iteration 56800, loss = 2.78184
I0423 17:37:02.149137 16565 solver.cpp:244]     Train net output #0: loss = 0.971637 (* 1 = 0.971637 loss)
I0423 17:37:02.149144 16565 solver.cpp:244]     Train net output #1: loss = 0.875734 (* 1 = 0.875734 loss)
I0423 17:37:02.149148 16565 solver.cpp:244]     Train net output #2: loss = 0.934473 (* 1 = 0.934473 loss)
I0423 17:37:02.149154 16565 sgd_solver.cpp:106] Iteration 56800, lr = 9e-06
I0423 17:38:42.928140 16565 solver.cpp:228] Iteration 56900, loss = 2.75972
I0423 17:38:42.928323 16565 solver.cpp:244]     Train net output #0: loss = 0.970009 (* 1 = 0.970009 loss)
I0423 17:38:42.928330 16565 solver.cpp:244]     Train net output #1: loss = 0.872194 (* 1 = 0.872194 loss)
I0423 17:38:42.928335 16565 solver.cpp:244]     Train net output #2: loss = 0.917513 (* 1 = 0.917513 loss)
I0423 17:38:42.928341 16565 sgd_solver.cpp:106] Iteration 56900, lr = 9e-06
I0423 17:40:22.663424 16565 solver.cpp:337] Iteration 57000, Testing net (#0)
I0423 17:40:22.663584 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 17:40:22.663589 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 17:40:22.663594 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 17:40:22.663609 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 17:40:22.663614 16565 net.cpp:693] Ignoring source layer visualize
I0423 17:40:22.663615 16565 net.cpp:693] Ignoring source layer fake
I0423 17:43:57.020521 16565 solver.cpp:404]     Test net output #0: loss = 0.977385 (* 1 = 0.977385 loss)
I0423 17:43:57.020659 16565 solver.cpp:404]     Test net output #1: loss = 0.74713 (* 1 = 0.74713 loss)
I0423 17:43:57.020666 16565 solver.cpp:404]     Test net output #2: loss = 0.7973 (* 1 = 0.7973 loss)
I0423 17:43:57.674839 16565 solver.cpp:228] Iteration 57000, loss = 2.63562
I0423 17:43:57.674882 16565 solver.cpp:244]     Train net output #0: loss = 0.987693 (* 1 = 0.987693 loss)
I0423 17:43:57.674887 16565 solver.cpp:244]     Train net output #1: loss = 0.739451 (* 1 = 0.739451 loss)
I0423 17:43:57.674891 16565 solver.cpp:244]     Train net output #2: loss = 0.908479 (* 1 = 0.908479 loss)
I0423 17:43:57.674896 16565 sgd_solver.cpp:106] Iteration 57000, lr = 9e-06
I0423 17:45:35.881515 16565 solver.cpp:228] Iteration 57100, loss = 2.70096
I0423 17:45:35.882215 16565 solver.cpp:244]     Train net output #0: loss = 0.985085 (* 1 = 0.985085 loss)
I0423 17:45:35.882222 16565 solver.cpp:244]     Train net output #1: loss = 0.829527 (* 1 = 0.829527 loss)
I0423 17:45:35.882228 16565 solver.cpp:244]     Train net output #2: loss = 0.886343 (* 1 = 0.886343 loss)
I0423 17:45:35.882233 16565 sgd_solver.cpp:106] Iteration 57100, lr = 9e-06
I0423 17:47:23.725910 16565 solver.cpp:228] Iteration 57200, loss = 2.67672
I0423 17:47:23.726083 16565 solver.cpp:244]     Train net output #0: loss = 0.991063 (* 1 = 0.991063 loss)
I0423 17:47:23.726090 16565 solver.cpp:244]     Train net output #1: loss = 0.776025 (* 1 = 0.776025 loss)
I0423 17:47:23.726096 16565 solver.cpp:244]     Train net output #2: loss = 0.909631 (* 1 = 0.909631 loss)
I0423 17:47:23.726101 16565 sgd_solver.cpp:106] Iteration 57200, lr = 9e-06
I0423 17:49:06.838399 16565 solver.cpp:228] Iteration 57300, loss = 2.69422
I0423 17:49:06.838570 16565 solver.cpp:244]     Train net output #0: loss = 0.986688 (* 1 = 0.986688 loss)
I0423 17:49:06.838579 16565 solver.cpp:244]     Train net output #1: loss = 0.776015 (* 1 = 0.776015 loss)
I0423 17:49:06.838584 16565 solver.cpp:244]     Train net output #2: loss = 0.931514 (* 1 = 0.931514 loss)
I0423 17:49:06.838590 16565 sgd_solver.cpp:106] Iteration 57300, lr = 9e-06
I0423 17:50:48.115663 16565 solver.cpp:228] Iteration 57400, loss = 2.47471
I0423 17:50:48.115814 16565 solver.cpp:244]     Train net output #0: loss = 0.994474 (* 1 = 0.994474 loss)
I0423 17:50:48.115821 16565 solver.cpp:244]     Train net output #1: loss = 0.763818 (* 1 = 0.763818 loss)
I0423 17:50:48.115828 16565 solver.cpp:244]     Train net output #2: loss = 0.716422 (* 1 = 0.716422 loss)
I0423 17:50:48.115833 16565 sgd_solver.cpp:106] Iteration 57400, lr = 9e-06
I0423 17:52:27.922390 16565 solver.cpp:228] Iteration 57500, loss = 2.5339
I0423 17:52:27.922551 16565 solver.cpp:244]     Train net output #0: loss = 0.966707 (* 1 = 0.966707 loss)
I0423 17:52:27.922559 16565 solver.cpp:244]     Train net output #1: loss = 0.651979 (* 1 = 0.651979 loss)
I0423 17:52:27.922564 16565 solver.cpp:244]     Train net output #2: loss = 0.91521 (* 1 = 0.91521 loss)
I0423 17:52:27.922570 16565 sgd_solver.cpp:106] Iteration 57500, lr = 9e-06
I0423 17:54:07.260165 16565 solver.cpp:228] Iteration 57600, loss = 2.48117
I0423 17:54:07.260360 16565 solver.cpp:244]     Train net output #0: loss = 0.958687 (* 1 = 0.958687 loss)
I0423 17:54:07.260367 16565 solver.cpp:244]     Train net output #1: loss = 0.770698 (* 1 = 0.770698 loss)
I0423 17:54:07.260373 16565 solver.cpp:244]     Train net output #2: loss = 0.751789 (* 1 = 0.751789 loss)
I0423 17:54:07.260380 16565 sgd_solver.cpp:106] Iteration 57600, lr = 9e-06
I0423 17:55:47.166687 16565 solver.cpp:228] Iteration 57700, loss = 2.34938
I0423 17:55:47.166824 16565 solver.cpp:244]     Train net output #0: loss = 0.992595 (* 1 = 0.992595 loss)
I0423 17:55:47.166833 16565 solver.cpp:244]     Train net output #1: loss = 0.782522 (* 1 = 0.782522 loss)
I0423 17:55:47.166838 16565 solver.cpp:244]     Train net output #2: loss = 0.574264 (* 1 = 0.574264 loss)
I0423 17:55:47.166842 16565 sgd_solver.cpp:106] Iteration 57700, lr = 9e-06
I0423 17:57:25.382020 16565 solver.cpp:228] Iteration 57800, loss = 2.3069
I0423 17:57:25.382155 16565 solver.cpp:244]     Train net output #0: loss = 0.981222 (* 1 = 0.981222 loss)
I0423 17:57:25.382164 16565 solver.cpp:244]     Train net output #1: loss = 0.747986 (* 1 = 0.747986 loss)
I0423 17:57:25.382169 16565 solver.cpp:244]     Train net output #2: loss = 0.577688 (* 1 = 0.577688 loss)
I0423 17:57:25.382174 16565 sgd_solver.cpp:106] Iteration 57800, lr = 9e-06
I0423 17:59:05.629843 16565 solver.cpp:228] Iteration 57900, loss = 2.83245
I0423 17:59:05.630017 16565 solver.cpp:244]     Train net output #0: loss = 0.979316 (* 1 = 0.979316 loss)
I0423 17:59:05.630025 16565 solver.cpp:244]     Train net output #1: loss = 0.915197 (* 1 = 0.915197 loss)
I0423 17:59:05.630030 16565 solver.cpp:244]     Train net output #2: loss = 0.937934 (* 1 = 0.937934 loss)
I0423 17:59:05.630036 16565 sgd_solver.cpp:106] Iteration 57900, lr = 9e-06
I0423 18:00:45.011996 16565 solver.cpp:337] Iteration 58000, Testing net (#0)
I0423 18:00:45.012141 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 18:00:45.012145 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 18:00:45.012151 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 18:00:45.012166 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 18:00:45.012171 16565 net.cpp:693] Ignoring source layer visualize
I0423 18:00:45.012173 16565 net.cpp:693] Ignoring source layer fake
I0423 18:04:18.881186 16565 solver.cpp:404]     Test net output #0: loss = 0.97725 (* 1 = 0.97725 loss)
I0423 18:04:18.881357 16565 solver.cpp:404]     Test net output #1: loss = 0.75869 (* 1 = 0.75869 loss)
I0423 18:04:18.881364 16565 solver.cpp:404]     Test net output #2: loss = 0.815786 (* 1 = 0.815786 loss)
I0423 18:04:19.534489 16565 solver.cpp:228] Iteration 58000, loss = 2.72909
I0423 18:04:19.534534 16565 solver.cpp:244]     Train net output #0: loss = 0.981716 (* 1 = 0.981716 loss)
I0423 18:04:19.534539 16565 solver.cpp:244]     Train net output #1: loss = 0.858481 (* 1 = 0.858481 loss)
I0423 18:04:19.534543 16565 solver.cpp:244]     Train net output #2: loss = 0.888894 (* 1 = 0.888894 loss)
I0423 18:04:19.534548 16565 sgd_solver.cpp:106] Iteration 58000, lr = 9e-06
I0423 18:05:59.459754 16565 solver.cpp:228] Iteration 58100, loss = 2.77159
I0423 18:05:59.459913 16565 solver.cpp:244]     Train net output #0: loss = 0.977601 (* 1 = 0.977601 loss)
I0423 18:05:59.459919 16565 solver.cpp:244]     Train net output #1: loss = 0.855732 (* 1 = 0.855732 loss)
I0423 18:05:59.459924 16565 solver.cpp:244]     Train net output #2: loss = 0.938259 (* 1 = 0.938259 loss)
I0423 18:05:59.459930 16565 sgd_solver.cpp:106] Iteration 58100, lr = 9e-06
I0423 18:07:37.615983 16565 solver.cpp:228] Iteration 58200, loss = 2.84856
I0423 18:07:37.616169 16565 solver.cpp:244]     Train net output #0: loss = 0.978235 (* 1 = 0.978235 loss)
I0423 18:07:37.616178 16565 solver.cpp:244]     Train net output #1: loss = 0.912958 (* 1 = 0.912958 loss)
I0423 18:07:37.616184 16565 solver.cpp:244]     Train net output #2: loss = 0.957364 (* 1 = 0.957364 loss)
I0423 18:07:37.616189 16565 sgd_solver.cpp:106] Iteration 58200, lr = 9e-06
I0423 18:09:17.478022 16565 solver.cpp:228] Iteration 58300, loss = 2.6078
I0423 18:09:17.478179 16565 solver.cpp:244]     Train net output #0: loss = 0.98882 (* 1 = 0.98882 loss)
I0423 18:09:17.478188 16565 solver.cpp:244]     Train net output #1: loss = 0.822059 (* 1 = 0.822059 loss)
I0423 18:09:17.478193 16565 solver.cpp:244]     Train net output #2: loss = 0.796927 (* 1 = 0.796927 loss)
I0423 18:09:17.478199 16565 sgd_solver.cpp:106] Iteration 58300, lr = 9e-06
I0423 18:10:57.353179 16565 solver.cpp:228] Iteration 58400, loss = 2.80764
I0423 18:10:57.353318 16565 solver.cpp:244]     Train net output #0: loss = 0.989486 (* 1 = 0.989486 loss)
I0423 18:10:57.353325 16565 solver.cpp:244]     Train net output #1: loss = 0.855774 (* 1 = 0.855774 loss)
I0423 18:10:57.353330 16565 solver.cpp:244]     Train net output #2: loss = 0.962384 (* 1 = 0.962384 loss)
I0423 18:10:57.353337 16565 sgd_solver.cpp:106] Iteration 58400, lr = 9e-06
I0423 18:12:38.630017 16565 solver.cpp:228] Iteration 58500, loss = 2.61202
I0423 18:12:38.630167 16565 solver.cpp:244]     Train net output #0: loss = 0.990031 (* 1 = 0.990031 loss)
I0423 18:12:38.630174 16565 solver.cpp:244]     Train net output #1: loss = 0.771527 (* 1 = 0.771527 loss)
I0423 18:12:38.630179 16565 solver.cpp:244]     Train net output #2: loss = 0.850463 (* 1 = 0.850463 loss)
I0423 18:12:38.630185 16565 sgd_solver.cpp:106] Iteration 58500, lr = 9e-06
I0423 18:14:16.812535 16565 solver.cpp:228] Iteration 58600, loss = 2.63873
I0423 18:14:16.812726 16565 solver.cpp:244]     Train net output #0: loss = 0.989888 (* 1 = 0.989888 loss)
I0423 18:14:16.812732 16565 solver.cpp:244]     Train net output #1: loss = 0.771523 (* 1 = 0.771523 loss)
I0423 18:14:16.812738 16565 solver.cpp:244]     Train net output #2: loss = 0.877315 (* 1 = 0.877315 loss)
I0423 18:14:16.812743 16565 sgd_solver.cpp:106] Iteration 58600, lr = 9e-06
I0423 18:15:56.657709 16565 solver.cpp:228] Iteration 58700, loss = 2.44157
I0423 18:15:56.657886 16565 solver.cpp:244]     Train net output #0: loss = 0.987856 (* 1 = 0.987856 loss)
I0423 18:15:56.657894 16565 solver.cpp:244]     Train net output #1: loss = 0.713885 (* 1 = 0.713885 loss)
I0423 18:15:56.657899 16565 solver.cpp:244]     Train net output #2: loss = 0.739829 (* 1 = 0.739829 loss)
I0423 18:15:56.657904 16565 sgd_solver.cpp:106] Iteration 58700, lr = 9e-06
I0423 18:17:36.382138 16565 solver.cpp:228] Iteration 58800, loss = 2.49817
I0423 18:17:36.382292 16565 solver.cpp:244]     Train net output #0: loss = 0.975615 (* 1 = 0.975615 loss)
I0423 18:17:36.382300 16565 solver.cpp:244]     Train net output #1: loss = 0.68073 (* 1 = 0.68073 loss)
I0423 18:17:36.382305 16565 solver.cpp:244]     Train net output #2: loss = 0.841823 (* 1 = 0.841823 loss)
I0423 18:17:36.382311 16565 sgd_solver.cpp:106] Iteration 58800, lr = 9e-06
I0423 18:19:15.940750 16565 solver.cpp:228] Iteration 58900, loss = 2.66823
I0423 18:19:15.940915 16565 solver.cpp:244]     Train net output #0: loss = 0.968667 (* 1 = 0.968667 loss)
I0423 18:19:15.940923 16565 solver.cpp:244]     Train net output #1: loss = 0.772721 (* 1 = 0.772721 loss)
I0423 18:19:15.940928 16565 solver.cpp:244]     Train net output #2: loss = 0.926839 (* 1 = 0.926839 loss)
I0423 18:19:15.940934 16565 sgd_solver.cpp:106] Iteration 58900, lr = 9e-06
I0423 18:20:54.902578 16565 solver.cpp:337] Iteration 59000, Testing net (#0)
I0423 18:20:54.902745 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 18:20:54.902750 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 18:20:54.902755 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 18:20:54.902770 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 18:20:54.902773 16565 net.cpp:693] Ignoring source layer visualize
I0423 18:20:54.902776 16565 net.cpp:693] Ignoring source layer fake
I0423 18:24:28.735874 16565 solver.cpp:404]     Test net output #0: loss = 0.977274 (* 1 = 0.977274 loss)
I0423 18:24:28.736048 16565 solver.cpp:404]     Test net output #1: loss = 0.760305 (* 1 = 0.760305 loss)
I0423 18:24:28.736055 16565 solver.cpp:404]     Test net output #2: loss = 0.81049 (* 1 = 0.81049 loss)
I0423 18:24:29.393110 16565 solver.cpp:228] Iteration 59000, loss = 2.39257
I0423 18:24:29.393136 16565 solver.cpp:244]     Train net output #0: loss = 0.972459 (* 1 = 0.972459 loss)
I0423 18:24:29.393157 16565 solver.cpp:244]     Train net output #1: loss = 0.838809 (* 1 = 0.838809 loss)
I0423 18:24:29.393160 16565 solver.cpp:244]     Train net output #2: loss = 0.581305 (* 1 = 0.581305 loss)
I0423 18:24:29.393164 16565 sgd_solver.cpp:106] Iteration 59000, lr = 9e-06
I0423 18:26:11.589511 16565 solver.cpp:228] Iteration 59100, loss = 2.6733
I0423 18:26:11.589674 16565 solver.cpp:244]     Train net output #0: loss = 0.970042 (* 1 = 0.970042 loss)
I0423 18:26:11.589682 16565 solver.cpp:244]     Train net output #1: loss = 0.873118 (* 1 = 0.873118 loss)
I0423 18:26:11.589687 16565 solver.cpp:244]     Train net output #2: loss = 0.830144 (* 1 = 0.830144 loss)
I0423 18:26:11.589692 16565 sgd_solver.cpp:106] Iteration 59100, lr = 9e-06
I0423 18:27:54.278664 16565 solver.cpp:228] Iteration 59200, loss = 2.72515
I0423 18:27:54.278831 16565 solver.cpp:244]     Train net output #0: loss = 0.977943 (* 1 = 0.977943 loss)
I0423 18:27:54.278851 16565 solver.cpp:244]     Train net output #1: loss = 0.839233 (* 1 = 0.839233 loss)
I0423 18:27:54.278861 16565 solver.cpp:244]     Train net output #2: loss = 0.907978 (* 1 = 0.907978 loss)
I0423 18:27:54.278868 16565 sgd_solver.cpp:106] Iteration 59200, lr = 9e-06
I0423 18:29:32.192876 16565 solver.cpp:228] Iteration 59300, loss = 2.72488
I0423 18:29:32.193045 16565 solver.cpp:244]     Train net output #0: loss = 0.965918 (* 1 = 0.965918 loss)
I0423 18:29:32.193058 16565 solver.cpp:244]     Train net output #1: loss = 0.83414 (* 1 = 0.83414 loss)
I0423 18:29:32.193066 16565 solver.cpp:244]     Train net output #2: loss = 0.924822 (* 1 = 0.924822 loss)
I0423 18:29:32.193073 16565 sgd_solver.cpp:106] Iteration 59300, lr = 9e-06
I0423 18:31:15.554304 16565 solver.cpp:228] Iteration 59400, loss = 2.69159
I0423 18:31:15.554476 16565 solver.cpp:244]     Train net output #0: loss = 0.967642 (* 1 = 0.967642 loss)
I0423 18:31:15.554483 16565 solver.cpp:244]     Train net output #1: loss = 0.843382 (* 1 = 0.843382 loss)
I0423 18:31:15.554488 16565 solver.cpp:244]     Train net output #2: loss = 0.88057 (* 1 = 0.88057 loss)
I0423 18:31:15.554494 16565 sgd_solver.cpp:106] Iteration 59400, lr = 9e-06
I0423 18:32:58.293313 16565 solver.cpp:228] Iteration 59500, loss = 2.61314
I0423 18:32:58.293514 16565 solver.cpp:244]     Train net output #0: loss = 0.991122 (* 1 = 0.991122 loss)
I0423 18:32:58.293522 16565 solver.cpp:244]     Train net output #1: loss = 0.889317 (* 1 = 0.889317 loss)
I0423 18:32:58.293527 16565 solver.cpp:244]     Train net output #2: loss = 0.732698 (* 1 = 0.732698 loss)
I0423 18:32:58.293534 16565 sgd_solver.cpp:106] Iteration 59500, lr = 9e-06
I0423 18:34:40.998630 16565 solver.cpp:228] Iteration 59600, loss = 2.68373
I0423 18:34:40.998803 16565 solver.cpp:244]     Train net output #0: loss = 0.990751 (* 1 = 0.990751 loss)
I0423 18:34:40.998811 16565 solver.cpp:244]     Train net output #1: loss = 0.844181 (* 1 = 0.844181 loss)
I0423 18:34:40.998817 16565 solver.cpp:244]     Train net output #2: loss = 0.848798 (* 1 = 0.848798 loss)
I0423 18:34:40.998822 16565 sgd_solver.cpp:106] Iteration 59600, lr = 9e-06
I0423 18:36:18.915522 16565 solver.cpp:228] Iteration 59700, loss = 2.60062
I0423 18:36:18.915657 16565 solver.cpp:244]     Train net output #0: loss = 0.991975 (* 1 = 0.991975 loss)
I0423 18:36:18.915664 16565 solver.cpp:244]     Train net output #1: loss = 0.747798 (* 1 = 0.747798 loss)
I0423 18:36:18.915669 16565 solver.cpp:244]     Train net output #2: loss = 0.860843 (* 1 = 0.860843 loss)
I0423 18:36:18.915674 16565 sgd_solver.cpp:106] Iteration 59700, lr = 9e-06
I0423 18:38:00.717464 16565 solver.cpp:228] Iteration 59800, loss = 2.72506
I0423 18:38:00.717615 16565 solver.cpp:244]     Train net output #0: loss = 0.986085 (* 1 = 0.986085 loss)
I0423 18:38:00.717624 16565 solver.cpp:244]     Train net output #1: loss = 0.828505 (* 1 = 0.828505 loss)
I0423 18:38:00.717628 16565 solver.cpp:244]     Train net output #2: loss = 0.910472 (* 1 = 0.910472 loss)
I0423 18:38:00.717634 16565 sgd_solver.cpp:106] Iteration 59800, lr = 9e-06
I0423 18:39:46.249441 16565 solver.cpp:228] Iteration 59900, loss = 2.31588
I0423 18:39:46.249588 16565 solver.cpp:244]     Train net output #0: loss = 0.991605 (* 1 = 0.991605 loss)
I0423 18:39:46.249595 16565 solver.cpp:244]     Train net output #1: loss = 0.640042 (* 1 = 0.640042 loss)
I0423 18:39:46.249600 16565 solver.cpp:244]     Train net output #2: loss = 0.684237 (* 1 = 0.684237 loss)
I0423 18:39:46.249606 16565 sgd_solver.cpp:106] Iteration 59900, lr = 9e-06
I0423 18:41:37.197732 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_60000.caffemodel
I0423 18:41:50.317306 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_60000.solverstate
I0423 18:41:50.527231 16565 solver.cpp:337] Iteration 60000, Testing net (#0)
I0423 18:41:50.527276 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 18:41:50.527278 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 18:41:50.527281 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 18:41:50.527295 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 18:41:50.527299 16565 net.cpp:693] Ignoring source layer visualize
I0423 18:41:50.527300 16565 net.cpp:693] Ignoring source layer fake
I0423 18:45:24.393913 16565 solver.cpp:404]     Test net output #0: loss = 0.967734 (* 1 = 0.967734 loss)
I0423 18:45:24.394059 16565 solver.cpp:404]     Test net output #1: loss = 0.740933 (* 1 = 0.740933 loss)
I0423 18:45:24.394068 16565 solver.cpp:404]     Test net output #2: loss = 0.821213 (* 1 = 0.821213 loss)
I0423 18:45:25.050017 16565 solver.cpp:228] Iteration 60000, loss = 2.83965
I0423 18:45:25.050060 16565 solver.cpp:244]     Train net output #0: loss = 0.97572 (* 1 = 0.97572 loss)
I0423 18:45:25.050066 16565 solver.cpp:244]     Train net output #1: loss = 0.897421 (* 1 = 0.897421 loss)
I0423 18:45:25.050071 16565 solver.cpp:244]     Train net output #2: loss = 0.966505 (* 1 = 0.966505 loss)
I0423 18:45:25.050078 16565 sgd_solver.cpp:106] Iteration 60000, lr = 2.7e-06
I0423 18:47:15.579679 16565 solver.cpp:228] Iteration 60100, loss = 2.69221
I0423 18:47:15.579849 16565 solver.cpp:244]     Train net output #0: loss = 0.971004 (* 1 = 0.971004 loss)
I0423 18:47:15.579857 16565 solver.cpp:244]     Train net output #1: loss = 0.796788 (* 1 = 0.796788 loss)
I0423 18:47:15.579861 16565 solver.cpp:244]     Train net output #2: loss = 0.924418 (* 1 = 0.924418 loss)
I0423 18:47:15.579867 16565 sgd_solver.cpp:106] Iteration 60100, lr = 2.7e-06
I0423 18:48:56.970849 16565 solver.cpp:228] Iteration 60200, loss = 2.58638
I0423 18:48:56.970983 16565 solver.cpp:244]     Train net output #0: loss = 0.982393 (* 1 = 0.982393 loss)
I0423 18:48:56.970991 16565 solver.cpp:244]     Train net output #1: loss = 0.847892 (* 1 = 0.847892 loss)
I0423 18:48:56.970996 16565 solver.cpp:244]     Train net output #2: loss = 0.756091 (* 1 = 0.756091 loss)
I0423 18:48:56.971001 16565 sgd_solver.cpp:106] Iteration 60200, lr = 2.7e-06
I0423 18:50:34.898396 16565 solver.cpp:228] Iteration 60300, loss = 2.53458
I0423 18:50:34.898543 16565 solver.cpp:244]     Train net output #0: loss = 0.986925 (* 1 = 0.986925 loss)
I0423 18:50:34.898550 16565 solver.cpp:244]     Train net output #1: loss = 0.80085 (* 1 = 0.80085 loss)
I0423 18:50:34.898555 16565 solver.cpp:244]     Train net output #2: loss = 0.746803 (* 1 = 0.746803 loss)
I0423 18:50:34.898561 16565 sgd_solver.cpp:106] Iteration 60300, lr = 2.7e-06
I0423 18:52:16.674592 16565 solver.cpp:228] Iteration 60400, loss = 2.73816
I0423 18:52:16.674796 16565 solver.cpp:244]     Train net output #0: loss = 0.963369 (* 1 = 0.963369 loss)
I0423 18:52:16.674804 16565 solver.cpp:244]     Train net output #1: loss = 0.854558 (* 1 = 0.854558 loss)
I0423 18:52:16.674810 16565 solver.cpp:244]     Train net output #2: loss = 0.92023 (* 1 = 0.92023 loss)
I0423 18:52:16.674815 16565 sgd_solver.cpp:106] Iteration 60400, lr = 2.7e-06
I0423 18:53:58.969964 16565 solver.cpp:228] Iteration 60500, loss = 2.82288
I0423 18:53:58.970140 16565 solver.cpp:244]     Train net output #0: loss = 0.983407 (* 1 = 0.983407 loss)
I0423 18:53:58.970149 16565 solver.cpp:244]     Train net output #1: loss = 0.901902 (* 1 = 0.901902 loss)
I0423 18:53:58.970154 16565 solver.cpp:244]     Train net output #2: loss = 0.937566 (* 1 = 0.937566 loss)
I0423 18:53:58.970160 16565 sgd_solver.cpp:106] Iteration 60500, lr = 2.7e-06
I0423 18:55:39.166934 16565 solver.cpp:228] Iteration 60600, loss = 2.77114
I0423 18:55:39.167078 16565 solver.cpp:244]     Train net output #0: loss = 0.980581 (* 1 = 0.980581 loss)
I0423 18:55:39.167085 16565 solver.cpp:244]     Train net output #1: loss = 0.86019 (* 1 = 0.86019 loss)
I0423 18:55:39.167090 16565 solver.cpp:244]     Train net output #2: loss = 0.930365 (* 1 = 0.930365 loss)
I0423 18:55:39.167095 16565 sgd_solver.cpp:106] Iteration 60600, lr = 2.7e-06
I0423 18:57:17.344671 16565 solver.cpp:228] Iteration 60700, loss = 2.69461
I0423 18:57:17.344825 16565 solver.cpp:244]     Train net output #0: loss = 0.9629 (* 1 = 0.9629 loss)
I0423 18:57:17.344832 16565 solver.cpp:244]     Train net output #1: loss = 0.813856 (* 1 = 0.813856 loss)
I0423 18:57:17.344837 16565 solver.cpp:244]     Train net output #2: loss = 0.917852 (* 1 = 0.917852 loss)
I0423 18:57:17.344843 16565 sgd_solver.cpp:106] Iteration 60700, lr = 2.7e-06
I0423 18:58:57.130034 16565 solver.cpp:228] Iteration 60800, loss = 2.6331
I0423 18:58:57.130189 16565 solver.cpp:244]     Train net output #0: loss = 0.985322 (* 1 = 0.985322 loss)
I0423 18:58:57.130198 16565 solver.cpp:244]     Train net output #1: loss = 0.734404 (* 1 = 0.734404 loss)
I0423 18:58:57.130203 16565 solver.cpp:244]     Train net output #2: loss = 0.913372 (* 1 = 0.913372 loss)
I0423 18:58:57.130208 16565 sgd_solver.cpp:106] Iteration 60800, lr = 2.7e-06
I0423 19:00:36.861685 16565 solver.cpp:228] Iteration 60900, loss = 2.71135
I0423 19:00:36.861852 16565 solver.cpp:244]     Train net output #0: loss = 0.989889 (* 1 = 0.989889 loss)
I0423 19:00:36.861861 16565 solver.cpp:244]     Train net output #1: loss = 0.825202 (* 1 = 0.825202 loss)
I0423 19:00:36.861865 16565 solver.cpp:244]     Train net output #2: loss = 0.896262 (* 1 = 0.896262 loss)
I0423 19:00:36.861871 16565 sgd_solver.cpp:106] Iteration 60900, lr = 2.7e-06
I0423 19:02:16.507737 16565 solver.cpp:337] Iteration 61000, Testing net (#0)
I0423 19:02:16.507910 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 19:02:16.507915 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 19:02:16.507918 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 19:02:16.507933 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 19:02:16.507937 16565 net.cpp:693] Ignoring source layer visualize
I0423 19:02:16.507939 16565 net.cpp:693] Ignoring source layer fake
I0423 19:05:51.215806 16565 solver.cpp:404]     Test net output #0: loss = 0.974861 (* 1 = 0.974861 loss)
I0423 19:05:51.215962 16565 solver.cpp:404]     Test net output #1: loss = 0.767006 (* 1 = 0.767006 loss)
I0423 19:05:51.215970 16565 solver.cpp:404]     Test net output #2: loss = 0.829543 (* 1 = 0.829543 loss)
I0423 19:05:51.864756 16565 solver.cpp:228] Iteration 61000, loss = 2.22852
I0423 19:05:51.864804 16565 solver.cpp:244]     Train net output #0: loss = 0.992128 (* 1 = 0.992128 loss)
I0423 19:05:51.864809 16565 solver.cpp:244]     Train net output #1: loss = 0.620226 (* 1 = 0.620226 loss)
I0423 19:05:51.864814 16565 solver.cpp:244]     Train net output #2: loss = 0.616169 (* 1 = 0.616169 loss)
I0423 19:05:51.864820 16565 sgd_solver.cpp:106] Iteration 61000, lr = 2.7e-06
I0423 19:07:30.051372 16565 solver.cpp:228] Iteration 61100, loss = 2.31931
I0423 19:07:30.051542 16565 solver.cpp:244]     Train net output #0: loss = 0.991229 (* 1 = 0.991229 loss)
I0423 19:07:30.051550 16565 solver.cpp:244]     Train net output #1: loss = 0.648309 (* 1 = 0.648309 loss)
I0423 19:07:30.051555 16565 solver.cpp:244]     Train net output #2: loss = 0.679773 (* 1 = 0.679773 loss)
I0423 19:07:30.051561 16565 sgd_solver.cpp:106] Iteration 61100, lr = 2.7e-06
I0423 19:09:10.073500 16565 solver.cpp:228] Iteration 61200, loss = 2.34605
I0423 19:09:10.073652 16565 solver.cpp:244]     Train net output #0: loss = 0.984701 (* 1 = 0.984701 loss)
I0423 19:09:10.073660 16565 solver.cpp:244]     Train net output #1: loss = 0.602373 (* 1 = 0.602373 loss)
I0423 19:09:10.073665 16565 solver.cpp:244]     Train net output #2: loss = 0.758974 (* 1 = 0.758974 loss)
I0423 19:09:10.073670 16565 sgd_solver.cpp:106] Iteration 61200, lr = 2.7e-06
I0423 19:10:50.039710 16565 solver.cpp:228] Iteration 61300, loss = 2.72326
I0423 19:10:50.039866 16565 solver.cpp:244]     Train net output #0: loss = 0.965167 (* 1 = 0.965167 loss)
I0423 19:10:50.039875 16565 solver.cpp:244]     Train net output #1: loss = 0.822708 (* 1 = 0.822708 loss)
I0423 19:10:50.039880 16565 solver.cpp:244]     Train net output #2: loss = 0.935383 (* 1 = 0.935383 loss)
I0423 19:10:50.039885 16565 sgd_solver.cpp:106] Iteration 61300, lr = 2.7e-06
I0423 19:12:29.503309 16565 solver.cpp:228] Iteration 61400, loss = 2.70619
I0423 19:12:29.503458 16565 solver.cpp:244]     Train net output #0: loss = 0.946216 (* 1 = 0.946216 loss)
I0423 19:12:29.503466 16565 solver.cpp:244]     Train net output #1: loss = 0.800873 (* 1 = 0.800873 loss)
I0423 19:12:29.503473 16565 solver.cpp:244]     Train net output #2: loss = 0.959104 (* 1 = 0.959104 loss)
I0423 19:12:29.503478 16565 sgd_solver.cpp:106] Iteration 61400, lr = 2.7e-06
I0423 19:14:09.150238 16565 solver.cpp:228] Iteration 61500, loss = 2.46845
I0423 19:14:09.150380 16565 solver.cpp:244]     Train net output #0: loss = 0.987592 (* 1 = 0.987592 loss)
I0423 19:14:09.150389 16565 solver.cpp:244]     Train net output #1: loss = 0.736322 (* 1 = 0.736322 loss)
I0423 19:14:09.150394 16565 solver.cpp:244]     Train net output #2: loss = 0.744534 (* 1 = 0.744534 loss)
I0423 19:14:09.150399 16565 sgd_solver.cpp:106] Iteration 61500, lr = 2.7e-06
I0423 19:15:49.092764 16565 solver.cpp:228] Iteration 61600, loss = 2.71811
I0423 19:15:49.092928 16565 solver.cpp:244]     Train net output #0: loss = 0.970901 (* 1 = 0.970901 loss)
I0423 19:15:49.092936 16565 solver.cpp:244]     Train net output #1: loss = 0.879743 (* 1 = 0.879743 loss)
I0423 19:15:49.092941 16565 solver.cpp:244]     Train net output #2: loss = 0.867468 (* 1 = 0.867468 loss)
I0423 19:15:49.092947 16565 sgd_solver.cpp:106] Iteration 61600, lr = 2.7e-06
I0423 19:17:29.059136 16565 solver.cpp:228] Iteration 61700, loss = 2.72571
I0423 19:17:29.059294 16565 solver.cpp:244]     Train net output #0: loss = 0.979321 (* 1 = 0.979321 loss)
I0423 19:17:29.059303 16565 solver.cpp:244]     Train net output #1: loss = 0.856233 (* 1 = 0.856233 loss)
I0423 19:17:29.059307 16565 solver.cpp:244]     Train net output #2: loss = 0.890157 (* 1 = 0.890157 loss)
I0423 19:17:29.059314 16565 sgd_solver.cpp:106] Iteration 61700, lr = 2.7e-06
I0423 19:19:07.230989 16565 solver.cpp:228] Iteration 61800, loss = 2.74774
I0423 19:19:07.232393 16565 solver.cpp:244]     Train net output #0: loss = 0.967494 (* 1 = 0.967494 loss)
I0423 19:19:07.232399 16565 solver.cpp:244]     Train net output #1: loss = 0.861196 (* 1 = 0.861196 loss)
I0423 19:19:07.232404 16565 solver.cpp:244]     Train net output #2: loss = 0.919046 (* 1 = 0.919046 loss)
I0423 19:19:07.232410 16565 sgd_solver.cpp:106] Iteration 61800, lr = 2.7e-06
I0423 19:20:47.355370 16565 solver.cpp:228] Iteration 61900, loss = 2.66746
I0423 19:20:47.355530 16565 solver.cpp:244]     Train net output #0: loss = 0.962374 (* 1 = 0.962374 loss)
I0423 19:20:47.355537 16565 solver.cpp:244]     Train net output #1: loss = 0.858384 (* 1 = 0.858384 loss)
I0423 19:20:47.355542 16565 solver.cpp:244]     Train net output #2: loss = 0.846699 (* 1 = 0.846699 loss)
I0423 19:20:47.355547 16565 sgd_solver.cpp:106] Iteration 61900, lr = 2.7e-06
I0423 19:22:27.664080 16565 solver.cpp:337] Iteration 62000, Testing net (#0)
I0423 19:22:27.664245 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 19:22:27.664250 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 19:22:27.664254 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 19:22:27.664268 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 19:22:27.664273 16565 net.cpp:693] Ignoring source layer visualize
I0423 19:22:27.664274 16565 net.cpp:693] Ignoring source layer fake
I0423 19:26:02.378867 16565 solver.cpp:404]     Test net output #0: loss = 0.977743 (* 1 = 0.977743 loss)
I0423 19:26:02.379006 16565 solver.cpp:404]     Test net output #1: loss = 0.756772 (* 1 = 0.756772 loss)
I0423 19:26:02.379014 16565 solver.cpp:404]     Test net output #2: loss = 0.801564 (* 1 = 0.801564 loss)
I0423 19:26:03.034561 16565 solver.cpp:228] Iteration 62000, loss = 2.44195
I0423 19:26:03.034607 16565 solver.cpp:244]     Train net output #0: loss = 0.989048 (* 1 = 0.989048 loss)
I0423 19:26:03.034612 16565 solver.cpp:244]     Train net output #1: loss = 0.755577 (* 1 = 0.755577 loss)
I0423 19:26:03.034618 16565 solver.cpp:244]     Train net output #2: loss = 0.697328 (* 1 = 0.697328 loss)
I0423 19:26:03.034623 16565 sgd_solver.cpp:106] Iteration 62000, lr = 2.7e-06
I0423 19:27:43.212132 16565 solver.cpp:228] Iteration 62100, loss = 2.7184
I0423 19:27:43.212282 16565 solver.cpp:244]     Train net output #0: loss = 0.987799 (* 1 = 0.987799 loss)
I0423 19:27:43.212291 16565 solver.cpp:244]     Train net output #1: loss = 0.85056 (* 1 = 0.85056 loss)
I0423 19:27:43.212296 16565 solver.cpp:244]     Train net output #2: loss = 0.880038 (* 1 = 0.880038 loss)
I0423 19:27:43.212302 16565 sgd_solver.cpp:106] Iteration 62100, lr = 2.7e-06
I0423 19:29:21.393632 16565 solver.cpp:228] Iteration 62200, loss = 2.76113
I0423 19:29:21.393791 16565 solver.cpp:244]     Train net output #0: loss = 0.990028 (* 1 = 0.990028 loss)
I0423 19:29:21.393798 16565 solver.cpp:244]     Train net output #1: loss = 0.863296 (* 1 = 0.863296 loss)
I0423 19:29:21.393803 16565 solver.cpp:244]     Train net output #2: loss = 0.907808 (* 1 = 0.907808 loss)
I0423 19:29:21.393808 16565 sgd_solver.cpp:106] Iteration 62200, lr = 2.7e-06
I0423 19:31:01.460050 16565 solver.cpp:228] Iteration 62300, loss = 2.79513
I0423 19:31:01.460222 16565 solver.cpp:244]     Train net output #0: loss = 0.987223 (* 1 = 0.987223 loss)
I0423 19:31:01.460230 16565 solver.cpp:244]     Train net output #1: loss = 0.879917 (* 1 = 0.879917 loss)
I0423 19:31:01.460234 16565 solver.cpp:244]     Train net output #2: loss = 0.927993 (* 1 = 0.927993 loss)
I0423 19:31:01.460242 16565 sgd_solver.cpp:106] Iteration 62300, lr = 2.7e-06
I0423 19:32:41.322892 16565 solver.cpp:228] Iteration 62400, loss = 2.26116
I0423 19:32:41.323046 16565 solver.cpp:244]     Train net output #0: loss = 0.990487 (* 1 = 0.990487 loss)
I0423 19:32:41.323055 16565 solver.cpp:244]     Train net output #1: loss = 0.559299 (* 1 = 0.559299 loss)
I0423 19:32:41.323060 16565 solver.cpp:244]     Train net output #2: loss = 0.711374 (* 1 = 0.711374 loss)
I0423 19:32:41.323066 16565 sgd_solver.cpp:106] Iteration 62400, lr = 2.7e-06
I0423 19:34:20.718165 16565 solver.cpp:228] Iteration 62500, loss = 2.7558
I0423 19:34:20.718341 16565 solver.cpp:244]     Train net output #0: loss = 0.962458 (* 1 = 0.962458 loss)
I0423 19:34:20.718350 16565 solver.cpp:244]     Train net output #1: loss = 0.836948 (* 1 = 0.836948 loss)
I0423 19:34:20.718355 16565 solver.cpp:244]     Train net output #2: loss = 0.956399 (* 1 = 0.956399 loss)
I0423 19:34:20.718360 16565 sgd_solver.cpp:106] Iteration 62500, lr = 2.7e-06
I0423 19:36:00.210707 16565 solver.cpp:228] Iteration 62600, loss = 2.5651
I0423 19:36:00.210886 16565 solver.cpp:244]     Train net output #0: loss = 0.981806 (* 1 = 0.981806 loss)
I0423 19:36:00.210896 16565 solver.cpp:244]     Train net output #1: loss = 0.819465 (* 1 = 0.819465 loss)
I0423 19:36:00.210899 16565 solver.cpp:244]     Train net output #2: loss = 0.763826 (* 1 = 0.763826 loss)
I0423 19:36:00.210906 16565 sgd_solver.cpp:106] Iteration 62600, lr = 2.7e-06
I0423 19:37:39.888566 16565 solver.cpp:228] Iteration 62700, loss = 2.55199
I0423 19:37:39.888720 16565 solver.cpp:244]     Train net output #0: loss = 0.988578 (* 1 = 0.988578 loss)
I0423 19:37:39.888727 16565 solver.cpp:244]     Train net output #1: loss = 0.809817 (* 1 = 0.809817 loss)
I0423 19:37:39.888732 16565 solver.cpp:244]     Train net output #2: loss = 0.75359 (* 1 = 0.75359 loss)
I0423 19:37:39.888739 16565 sgd_solver.cpp:106] Iteration 62700, lr = 2.7e-06
I0423 19:39:18.085105 16565 solver.cpp:228] Iteration 62800, loss = 2.55275
I0423 19:39:18.085247 16565 solver.cpp:244]     Train net output #0: loss = 0.979337 (* 1 = 0.979337 loss)
I0423 19:39:18.085254 16565 solver.cpp:244]     Train net output #1: loss = 0.810223 (* 1 = 0.810223 loss)
I0423 19:39:18.085260 16565 solver.cpp:244]     Train net output #2: loss = 0.763192 (* 1 = 0.763192 loss)
I0423 19:39:18.085265 16565 sgd_solver.cpp:106] Iteration 62800, lr = 2.7e-06
I0423 19:40:57.958853 16565 solver.cpp:228] Iteration 62900, loss = 2.68011
I0423 19:40:57.958989 16565 solver.cpp:244]     Train net output #0: loss = 0.959551 (* 1 = 0.959551 loss)
I0423 19:40:57.958998 16565 solver.cpp:244]     Train net output #1: loss = 0.816521 (* 1 = 0.816521 loss)
I0423 19:40:57.959003 16565 solver.cpp:244]     Train net output #2: loss = 0.904033 (* 1 = 0.904033 loss)
I0423 19:40:57.959009 16565 sgd_solver.cpp:106] Iteration 62900, lr = 2.7e-06
I0423 19:42:37.143656 16565 solver.cpp:337] Iteration 63000, Testing net (#0)
I0423 19:42:37.143810 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 19:42:37.143813 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 19:42:37.143817 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 19:42:37.143832 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 19:42:37.143836 16565 net.cpp:693] Ignoring source layer visualize
I0423 19:42:37.143838 16565 net.cpp:693] Ignoring source layer fake
I0423 19:46:12.416663 16565 solver.cpp:404]     Test net output #0: loss = 0.971325 (* 1 = 0.971325 loss)
I0423 19:46:12.416810 16565 solver.cpp:404]     Test net output #1: loss = 0.74284 (* 1 = 0.74284 loss)
I0423 19:46:12.416818 16565 solver.cpp:404]     Test net output #2: loss = 0.820198 (* 1 = 0.820198 loss)
I0423 19:46:13.067733 16565 solver.cpp:228] Iteration 63000, loss = 2.79079
I0423 19:46:13.067778 16565 solver.cpp:244]     Train net output #0: loss = 0.978396 (* 1 = 0.978396 loss)
I0423 19:46:13.067783 16565 solver.cpp:244]     Train net output #1: loss = 0.885671 (* 1 = 0.885671 loss)
I0423 19:46:13.067788 16565 solver.cpp:244]     Train net output #2: loss = 0.926723 (* 1 = 0.926723 loss)
I0423 19:46:13.067793 16565 sgd_solver.cpp:106] Iteration 63000, lr = 2.7e-06
I0423 19:47:53.201745 16565 solver.cpp:228] Iteration 63100, loss = 2.69478
I0423 19:47:53.201937 16565 solver.cpp:244]     Train net output #0: loss = 0.976356 (* 1 = 0.976356 loss)
I0423 19:47:53.201946 16565 solver.cpp:244]     Train net output #1: loss = 0.846649 (* 1 = 0.846649 loss)
I0423 19:47:53.201951 16565 solver.cpp:244]     Train net output #2: loss = 0.871779 (* 1 = 0.871779 loss)
I0423 19:47:53.201957 16565 sgd_solver.cpp:106] Iteration 63100, lr = 2.7e-06
I0423 19:49:31.431699 16565 solver.cpp:228] Iteration 63200, loss = 2.61958
I0423 19:49:31.431844 16565 solver.cpp:244]     Train net output #0: loss = 0.963251 (* 1 = 0.963251 loss)
I0423 19:49:31.431852 16565 solver.cpp:244]     Train net output #1: loss = 0.784808 (* 1 = 0.784808 loss)
I0423 19:49:31.431857 16565 solver.cpp:244]     Train net output #2: loss = 0.871518 (* 1 = 0.871518 loss)
I0423 19:49:31.431862 16565 sgd_solver.cpp:106] Iteration 63200, lr = 2.7e-06
I0423 19:51:11.417316 16565 solver.cpp:228] Iteration 63300, loss = 2.64918
I0423 19:51:11.417498 16565 solver.cpp:244]     Train net output #0: loss = 0.988877 (* 1 = 0.988877 loss)
I0423 19:51:11.417507 16565 solver.cpp:244]     Train net output #1: loss = 0.740772 (* 1 = 0.740772 loss)
I0423 19:51:11.417512 16565 solver.cpp:244]     Train net output #2: loss = 0.919536 (* 1 = 0.919536 loss)
I0423 19:51:11.417520 16565 sgd_solver.cpp:106] Iteration 63300, lr = 2.7e-06
I0423 19:52:51.322381 16565 solver.cpp:228] Iteration 63400, loss = 2.80663
I0423 19:52:51.322545 16565 solver.cpp:244]     Train net output #0: loss = 0.989762 (* 1 = 0.989762 loss)
I0423 19:52:51.322552 16565 solver.cpp:244]     Train net output #1: loss = 0.882856 (* 1 = 0.882856 loss)
I0423 19:52:51.322558 16565 solver.cpp:244]     Train net output #2: loss = 0.934014 (* 1 = 0.934014 loss)
I0423 19:52:51.322563 16565 sgd_solver.cpp:106] Iteration 63400, lr = 2.7e-06
I0423 19:54:31.424880 16565 solver.cpp:228] Iteration 63500, loss = 2.35579
I0423 19:54:31.425060 16565 solver.cpp:244]     Train net output #0: loss = 0.990496 (* 1 = 0.990496 loss)
I0423 19:54:31.425067 16565 solver.cpp:244]     Train net output #1: loss = 0.693616 (* 1 = 0.693616 loss)
I0423 19:54:31.425073 16565 solver.cpp:244]     Train net output #2: loss = 0.671677 (* 1 = 0.671677 loss)
I0423 19:54:31.425078 16565 sgd_solver.cpp:106] Iteration 63500, lr = 2.7e-06
I0423 19:56:09.529515 16565 solver.cpp:228] Iteration 63600, loss = 2.57326
I0423 19:56:09.529671 16565 solver.cpp:244]     Train net output #0: loss = 0.984686 (* 1 = 0.984686 loss)
I0423 19:56:09.529680 16565 solver.cpp:244]     Train net output #1: loss = 0.823916 (* 1 = 0.823916 loss)
I0423 19:56:09.529685 16565 solver.cpp:244]     Train net output #2: loss = 0.764663 (* 1 = 0.764663 loss)
I0423 19:56:09.529690 16565 sgd_solver.cpp:106] Iteration 63600, lr = 2.7e-06
I0423 19:57:49.223068 16565 solver.cpp:228] Iteration 63700, loss = 2.65669
I0423 19:57:49.223214 16565 solver.cpp:244]     Train net output #0: loss = 0.978652 (* 1 = 0.978652 loss)
I0423 19:57:49.223222 16565 solver.cpp:244]     Train net output #1: loss = 0.745321 (* 1 = 0.745321 loss)
I0423 19:57:49.223227 16565 solver.cpp:244]     Train net output #2: loss = 0.93272 (* 1 = 0.93272 loss)
I0423 19:57:49.223233 16565 sgd_solver.cpp:106] Iteration 63700, lr = 2.7e-06
I0423 19:59:28.451771 16565 solver.cpp:228] Iteration 63800, loss = 2.6018
I0423 19:59:28.451925 16565 solver.cpp:244]     Train net output #0: loss = 0.979417 (* 1 = 0.979417 loss)
I0423 19:59:28.451933 16565 solver.cpp:244]     Train net output #1: loss = 0.683962 (* 1 = 0.683962 loss)
I0423 19:59:28.451938 16565 solver.cpp:244]     Train net output #2: loss = 0.93842 (* 1 = 0.93842 loss)
I0423 19:59:28.451944 16565 sgd_solver.cpp:106] Iteration 63800, lr = 2.7e-06
I0423 20:01:07.753171 16565 solver.cpp:228] Iteration 63900, loss = 2.72528
I0423 20:01:07.753327 16565 solver.cpp:244]     Train net output #0: loss = 0.961801 (* 1 = 0.961801 loss)
I0423 20:01:07.753336 16565 solver.cpp:244]     Train net output #1: loss = 0.80329 (* 1 = 0.80329 loss)
I0423 20:01:07.753341 16565 solver.cpp:244]     Train net output #2: loss = 0.960192 (* 1 = 0.960192 loss)
I0423 20:01:07.753347 16565 sgd_solver.cpp:106] Iteration 63900, lr = 2.7e-06
I0423 20:02:46.265599 16565 solver.cpp:337] Iteration 64000, Testing net (#0)
I0423 20:02:46.265738 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 20:02:46.265741 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 20:02:46.265745 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 20:02:46.265759 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 20:02:46.265763 16565 net.cpp:693] Ignoring source layer visualize
I0423 20:02:46.265765 16565 net.cpp:693] Ignoring source layer fake
I0423 20:06:20.374939 16565 solver.cpp:404]     Test net output #0: loss = 0.976583 (* 1 = 0.976583 loss)
I0423 20:06:20.375079 16565 solver.cpp:404]     Test net output #1: loss = 0.761111 (* 1 = 0.761111 loss)
I0423 20:06:20.375087 16565 solver.cpp:404]     Test net output #2: loss = 0.797893 (* 1 = 0.797893 loss)
I0423 20:06:21.033994 16565 solver.cpp:228] Iteration 64000, loss = 2.36857
I0423 20:06:21.034036 16565 solver.cpp:244]     Train net output #0: loss = 0.960936 (* 1 = 0.960936 loss)
I0423 20:06:21.034041 16565 solver.cpp:244]     Train net output #1: loss = 0.661254 (* 1 = 0.661254 loss)
I0423 20:06:21.034046 16565 solver.cpp:244]     Train net output #2: loss = 0.746376 (* 1 = 0.746376 loss)
I0423 20:06:21.034052 16565 sgd_solver.cpp:106] Iteration 64000, lr = 2.7e-06
I0423 20:08:00.804955 16565 solver.cpp:228] Iteration 64100, loss = 2.7192
I0423 20:08:00.805135 16565 solver.cpp:244]     Train net output #0: loss = 0.98578 (* 1 = 0.98578 loss)
I0423 20:08:00.805143 16565 solver.cpp:244]     Train net output #1: loss = 0.910905 (* 1 = 0.910905 loss)
I0423 20:08:00.805148 16565 solver.cpp:244]     Train net output #2: loss = 0.822516 (* 1 = 0.822516 loss)
I0423 20:08:00.805155 16565 sgd_solver.cpp:106] Iteration 64100, lr = 2.7e-06
I0423 20:09:40.572918 16565 solver.cpp:228] Iteration 64200, loss = 2.61741
I0423 20:09:40.573087 16565 solver.cpp:244]     Train net output #0: loss = 0.990886 (* 1 = 0.990886 loss)
I0423 20:09:40.573096 16565 solver.cpp:244]     Train net output #1: loss = 0.911403 (* 1 = 0.911403 loss)
I0423 20:09:40.573101 16565 solver.cpp:244]     Train net output #2: loss = 0.715119 (* 1 = 0.715119 loss)
I0423 20:09:40.573106 16565 sgd_solver.cpp:106] Iteration 64200, lr = 2.7e-06
I0423 20:11:18.730258 16565 solver.cpp:228] Iteration 64300, loss = 2.68691
I0423 20:11:18.730429 16565 solver.cpp:244]     Train net output #0: loss = 0.982644 (* 1 = 0.982644 loss)
I0423 20:11:18.730437 16565 solver.cpp:244]     Train net output #1: loss = 0.901992 (* 1 = 0.901992 loss)
I0423 20:11:18.730443 16565 solver.cpp:244]     Train net output #2: loss = 0.802277 (* 1 = 0.802277 loss)
I0423 20:11:18.730448 16565 sgd_solver.cpp:106] Iteration 64300, lr = 2.7e-06
I0423 20:12:58.562165 16565 solver.cpp:228] Iteration 64400, loss = 2.73881
I0423 20:12:58.562304 16565 solver.cpp:244]     Train net output #0: loss = 0.978534 (* 1 = 0.978534 loss)
I0423 20:12:58.562312 16565 solver.cpp:244]     Train net output #1: loss = 0.882628 (* 1 = 0.882628 loss)
I0423 20:12:58.562319 16565 solver.cpp:244]     Train net output #2: loss = 0.877647 (* 1 = 0.877647 loss)
I0423 20:12:58.562324 16565 sgd_solver.cpp:106] Iteration 64400, lr = 2.7e-06
I0423 20:14:38.369721 16565 solver.cpp:228] Iteration 64500, loss = 2.60397
I0423 20:14:38.369906 16565 solver.cpp:244]     Train net output #0: loss = 0.990087 (* 1 = 0.990087 loss)
I0423 20:14:38.369915 16565 solver.cpp:244]     Train net output #1: loss = 0.699934 (* 1 = 0.699934 loss)
I0423 20:14:38.369920 16565 solver.cpp:244]     Train net output #2: loss = 0.913952 (* 1 = 0.913952 loss)
I0423 20:14:38.369925 16565 sgd_solver.cpp:106] Iteration 64500, lr = 2.7e-06
I0423 20:16:18.174116 16565 solver.cpp:228] Iteration 64600, loss = 2.76372
I0423 20:16:18.174289 16565 solver.cpp:244]     Train net output #0: loss = 0.987823 (* 1 = 0.987823 loss)
I0423 20:16:18.174298 16565 solver.cpp:244]     Train net output #1: loss = 0.832246 (* 1 = 0.832246 loss)
I0423 20:16:18.174302 16565 solver.cpp:244]     Train net output #2: loss = 0.943654 (* 1 = 0.943654 loss)
I0423 20:16:18.174307 16565 sgd_solver.cpp:106] Iteration 64600, lr = 2.7e-06
I0423 20:17:56.362769 16565 solver.cpp:228] Iteration 64700, loss = 2.73785
I0423 20:17:56.362915 16565 solver.cpp:244]     Train net output #0: loss = 0.988221 (* 1 = 0.988221 loss)
I0423 20:17:56.362932 16565 solver.cpp:244]     Train net output #1: loss = 0.842296 (* 1 = 0.842296 loss)
I0423 20:17:56.362937 16565 solver.cpp:244]     Train net output #2: loss = 0.907333 (* 1 = 0.907333 loss)
I0423 20:17:56.362944 16565 sgd_solver.cpp:106] Iteration 64700, lr = 2.7e-06
I0423 20:19:36.239120 16565 solver.cpp:228] Iteration 64800, loss = 2.74002
I0423 20:19:36.239285 16565 solver.cpp:244]     Train net output #0: loss = 0.987128 (* 1 = 0.987128 loss)
I0423 20:19:36.239293 16565 solver.cpp:244]     Train net output #1: loss = 0.792443 (* 1 = 0.792443 loss)
I0423 20:19:36.239300 16565 solver.cpp:244]     Train net output #2: loss = 0.960451 (* 1 = 0.960451 loss)
I0423 20:19:36.239305 16565 sgd_solver.cpp:106] Iteration 64800, lr = 2.7e-06
I0423 20:21:15.910549 16565 solver.cpp:228] Iteration 64900, loss = 2.77607
I0423 20:21:15.910722 16565 solver.cpp:244]     Train net output #0: loss = 0.990675 (* 1 = 0.990675 loss)
I0423 20:21:15.910732 16565 solver.cpp:244]     Train net output #1: loss = 0.847459 (* 1 = 0.847459 loss)
I0423 20:21:15.910735 16565 solver.cpp:244]     Train net output #2: loss = 0.937933 (* 1 = 0.937933 loss)
I0423 20:21:15.910740 16565 sgd_solver.cpp:106] Iteration 64900, lr = 2.7e-06
I0423 20:22:54.229163 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_65000.caffemodel
I0423 20:23:13.571260 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_65000.solverstate
I0423 20:23:13.772616 16565 solver.cpp:337] Iteration 65000, Testing net (#0)
I0423 20:23:13.772656 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 20:23:13.772660 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 20:23:13.772663 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 20:23:13.772678 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 20:23:13.772681 16565 net.cpp:693] Ignoring source layer visualize
I0423 20:23:13.772683 16565 net.cpp:693] Ignoring source layer fake
I0423 20:26:46.648627 16565 solver.cpp:404]     Test net output #0: loss = 0.969278 (* 1 = 0.969278 loss)
I0423 20:26:46.648888 16565 solver.cpp:404]     Test net output #1: loss = 0.752639 (* 1 = 0.752639 loss)
I0423 20:26:46.648895 16565 solver.cpp:404]     Test net output #2: loss = 0.824843 (* 1 = 0.824843 loss)
I0423 20:26:47.301275 16565 solver.cpp:228] Iteration 65000, loss = 2.67674
I0423 20:26:47.301318 16565 solver.cpp:244]     Train net output #0: loss = 0.97316 (* 1 = 0.97316 loss)
I0423 20:26:47.301323 16565 solver.cpp:244]     Train net output #1: loss = 0.769206 (* 1 = 0.769206 loss)
I0423 20:26:47.301327 16565 solver.cpp:244]     Train net output #2: loss = 0.934369 (* 1 = 0.934369 loss)
I0423 20:26:47.301332 16565 sgd_solver.cpp:106] Iteration 65000, lr = 2.7e-06
I0423 20:28:26.653486 16565 solver.cpp:228] Iteration 65100, loss = 2.5217
I0423 20:28:26.653664 16565 solver.cpp:244]     Train net output #0: loss = 0.977643 (* 1 = 0.977643 loss)
I0423 20:28:26.653671 16565 solver.cpp:244]     Train net output #1: loss = 0.784488 (* 1 = 0.784488 loss)
I0423 20:28:26.653676 16565 solver.cpp:244]     Train net output #2: loss = 0.759574 (* 1 = 0.759574 loss)
I0423 20:28:26.653683 16565 sgd_solver.cpp:106] Iteration 65100, lr = 2.7e-06
I0423 20:30:06.223619 16565 solver.cpp:228] Iteration 65200, loss = 2.38761
I0423 20:30:06.223767 16565 solver.cpp:244]     Train net output #0: loss = 0.986704 (* 1 = 0.986704 loss)
I0423 20:30:06.223774 16565 solver.cpp:244]     Train net output #1: loss = 0.828647 (* 1 = 0.828647 loss)
I0423 20:30:06.223780 16565 solver.cpp:244]     Train net output #2: loss = 0.572255 (* 1 = 0.572255 loss)
I0423 20:30:06.223785 16565 sgd_solver.cpp:106] Iteration 65200, lr = 2.7e-06
I0423 20:31:44.430594 16565 solver.cpp:228] Iteration 65300, loss = 2.22002
I0423 20:31:44.430753 16565 solver.cpp:244]     Train net output #0: loss = 0.986286 (* 1 = 0.986286 loss)
I0423 20:31:44.430761 16565 solver.cpp:244]     Train net output #1: loss = 0.670204 (* 1 = 0.670204 loss)
I0423 20:31:44.430766 16565 solver.cpp:244]     Train net output #2: loss = 0.563528 (* 1 = 0.563528 loss)
I0423 20:31:44.430773 16565 sgd_solver.cpp:106] Iteration 65300, lr = 2.7e-06
I0423 20:33:24.112951 16565 solver.cpp:228] Iteration 65400, loss = 2.74277
I0423 20:33:24.113117 16565 solver.cpp:244]     Train net output #0: loss = 0.973485 (* 1 = 0.973485 loss)
I0423 20:33:24.113126 16565 solver.cpp:244]     Train net output #1: loss = 0.861702 (* 1 = 0.861702 loss)
I0423 20:33:24.113131 16565 solver.cpp:244]     Train net output #2: loss = 0.90758 (* 1 = 0.90758 loss)
I0423 20:33:24.113137 16565 sgd_solver.cpp:106] Iteration 65400, lr = 2.7e-06
I0423 20:35:04.357604 16565 solver.cpp:228] Iteration 65500, loss = 2.68052
I0423 20:35:04.357774 16565 solver.cpp:244]     Train net output #0: loss = 0.980071 (* 1 = 0.980071 loss)
I0423 20:35:04.357782 16565 solver.cpp:244]     Train net output #1: loss = 0.906011 (* 1 = 0.906011 loss)
I0423 20:35:04.357787 16565 solver.cpp:244]     Train net output #2: loss = 0.794438 (* 1 = 0.794438 loss)
I0423 20:35:04.357795 16565 sgd_solver.cpp:106] Iteration 65500, lr = 2.7e-06
I0423 20:36:44.853170 16565 solver.cpp:228] Iteration 65600, loss = 2.73553
I0423 20:36:44.853315 16565 solver.cpp:244]     Train net output #0: loss = 0.983373 (* 1 = 0.983373 loss)
I0423 20:36:44.853323 16565 solver.cpp:244]     Train net output #1: loss = 0.892588 (* 1 = 0.892588 loss)
I0423 20:36:44.853328 16565 solver.cpp:244]     Train net output #2: loss = 0.859565 (* 1 = 0.859565 loss)
I0423 20:36:44.853334 16565 sgd_solver.cpp:106] Iteration 65600, lr = 2.7e-06
I0423 20:38:23.000759 16565 solver.cpp:228] Iteration 65700, loss = 2.75537
I0423 20:38:23.002262 16565 solver.cpp:244]     Train net output #0: loss = 0.981756 (* 1 = 0.981756 loss)
I0423 20:38:23.002271 16565 solver.cpp:244]     Train net output #1: loss = 0.86021 (* 1 = 0.86021 loss)
I0423 20:38:23.002276 16565 solver.cpp:244]     Train net output #2: loss = 0.913409 (* 1 = 0.913409 loss)
I0423 20:38:23.002280 16565 sgd_solver.cpp:106] Iteration 65700, lr = 2.7e-06
I0423 20:40:03.428220 16565 solver.cpp:228] Iteration 65800, loss = 2.77297
I0423 20:40:03.428370 16565 solver.cpp:244]     Train net output #0: loss = 0.989116 (* 1 = 0.989116 loss)
I0423 20:40:03.428378 16565 solver.cpp:244]     Train net output #1: loss = 0.88087 (* 1 = 0.88087 loss)
I0423 20:40:03.428383 16565 solver.cpp:244]     Train net output #2: loss = 0.902987 (* 1 = 0.902987 loss)
I0423 20:40:03.428388 16565 sgd_solver.cpp:106] Iteration 65800, lr = 2.7e-06
I0423 20:41:43.955670 16565 solver.cpp:228] Iteration 65900, loss = 2.79036
I0423 20:41:43.955840 16565 solver.cpp:244]     Train net output #0: loss = 0.9829 (* 1 = 0.9829 loss)
I0423 20:41:43.955848 16565 solver.cpp:244]     Train net output #1: loss = 0.858013 (* 1 = 0.858013 loss)
I0423 20:41:43.955854 16565 solver.cpp:244]     Train net output #2: loss = 0.949445 (* 1 = 0.949445 loss)
I0423 20:41:43.955860 16565 sgd_solver.cpp:106] Iteration 65900, lr = 2.7e-06
I0423 20:43:23.140200 16565 solver.cpp:337] Iteration 66000, Testing net (#0)
I0423 20:43:23.140352 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 20:43:23.140357 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 20:43:23.140362 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 20:43:23.140377 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 20:43:23.140380 16565 net.cpp:693] Ignoring source layer visualize
I0423 20:43:23.140383 16565 net.cpp:693] Ignoring source layer fake
I0423 20:46:57.541340 16565 solver.cpp:404]     Test net output #0: loss = 0.974553 (* 1 = 0.974553 loss)
I0423 20:46:57.541505 16565 solver.cpp:404]     Test net output #1: loss = 0.76551 (* 1 = 0.76551 loss)
I0423 20:46:57.541512 16565 solver.cpp:404]     Test net output #2: loss = 0.82929 (* 1 = 0.82929 loss)
I0423 20:46:58.193099 16565 solver.cpp:228] Iteration 66000, loss = 2.55715
I0423 20:46:58.193140 16565 solver.cpp:244]     Train net output #0: loss = 0.98833 (* 1 = 0.98833 loss)
I0423 20:46:58.193146 16565 solver.cpp:244]     Train net output #1: loss = 0.747202 (* 1 = 0.747202 loss)
I0423 20:46:58.193150 16565 solver.cpp:244]     Train net output #2: loss = 0.821622 (* 1 = 0.821622 loss)
I0423 20:46:58.193156 16565 sgd_solver.cpp:106] Iteration 66000, lr = 2.7e-06
I0423 20:48:36.402776 16565 solver.cpp:228] Iteration 66100, loss = 2.59874
I0423 20:48:36.402926 16565 solver.cpp:244]     Train net output #0: loss = 0.984073 (* 1 = 0.984073 loss)
I0423 20:48:36.402933 16565 solver.cpp:244]     Train net output #1: loss = 0.720958 (* 1 = 0.720958 loss)
I0423 20:48:36.402938 16565 solver.cpp:244]     Train net output #2: loss = 0.89371 (* 1 = 0.89371 loss)
I0423 20:48:36.402945 16565 sgd_solver.cpp:106] Iteration 66100, lr = 2.7e-06
I0423 20:50:16.664355 16565 solver.cpp:228] Iteration 66200, loss = 2.45705
I0423 20:50:16.664535 16565 solver.cpp:244]     Train net output #0: loss = 0.983677 (* 1 = 0.983677 loss)
I0423 20:50:16.664543 16565 solver.cpp:244]     Train net output #1: loss = 0.725181 (* 1 = 0.725181 loss)
I0423 20:50:16.664549 16565 solver.cpp:244]     Train net output #2: loss = 0.748193 (* 1 = 0.748193 loss)
I0423 20:50:16.664556 16565 sgd_solver.cpp:106] Iteration 66200, lr = 2.7e-06
I0423 20:51:56.326129 16565 solver.cpp:228] Iteration 66300, loss = 2.60982
I0423 20:51:56.327320 16565 solver.cpp:244]     Train net output #0: loss = 0.985278 (* 1 = 0.985278 loss)
I0423 20:51:56.327328 16565 solver.cpp:244]     Train net output #1: loss = 0.695789 (* 1 = 0.695789 loss)
I0423 20:51:56.327333 16565 solver.cpp:244]     Train net output #2: loss = 0.928758 (* 1 = 0.928758 loss)
I0423 20:51:56.327337 16565 sgd_solver.cpp:106] Iteration 66300, lr = 2.7e-06
I0423 20:53:35.737519 16565 solver.cpp:228] Iteration 66400, loss = 2.38851
I0423 20:53:35.737690 16565 solver.cpp:244]     Train net output #0: loss = 0.972031 (* 1 = 0.972031 loss)
I0423 20:53:35.737699 16565 solver.cpp:244]     Train net output #1: loss = 0.648684 (* 1 = 0.648684 loss)
I0423 20:53:35.737704 16565 solver.cpp:244]     Train net output #2: loss = 0.767791 (* 1 = 0.767791 loss)
I0423 20:53:35.737709 16565 sgd_solver.cpp:106] Iteration 66400, lr = 2.7e-06
I0423 20:55:42.441224 16565 solver.cpp:228] Iteration 66500, loss = 2.44296
I0423 20:55:42.441388 16565 solver.cpp:244]     Train net output #0: loss = 0.955263 (* 1 = 0.955263 loss)
I0423 20:55:42.441395 16565 solver.cpp:244]     Train net output #1: loss = 0.729201 (* 1 = 0.729201 loss)
I0423 20:55:42.441401 16565 solver.cpp:244]     Train net output #2: loss = 0.758496 (* 1 = 0.758496 loss)
I0423 20:55:42.441407 16565 sgd_solver.cpp:106] Iteration 66500, lr = 2.7e-06
I0423 20:57:20.665417 16565 solver.cpp:228] Iteration 66600, loss = 2.68666
I0423 20:57:20.665572 16565 solver.cpp:244]     Train net output #0: loss = 0.961895 (* 1 = 0.961895 loss)
I0423 20:57:20.665585 16565 solver.cpp:244]     Train net output #1: loss = 0.830745 (* 1 = 0.830745 loss)
I0423 20:57:20.665591 16565 solver.cpp:244]     Train net output #2: loss = 0.894018 (* 1 = 0.894018 loss)
I0423 20:57:20.665596 16565 sgd_solver.cpp:106] Iteration 66600, lr = 2.7e-06
I0423 20:58:59.213850 16565 solver.cpp:228] Iteration 66700, loss = 2.51694
I0423 20:58:59.214013 16565 solver.cpp:244]     Train net output #0: loss = 0.98258 (* 1 = 0.98258 loss)
I0423 20:58:59.214021 16565 solver.cpp:244]     Train net output #1: loss = 0.810022 (* 1 = 0.810022 loss)
I0423 20:58:59.214026 16565 solver.cpp:244]     Train net output #2: loss = 0.724336 (* 1 = 0.724336 loss)
I0423 20:58:59.214032 16565 sgd_solver.cpp:106] Iteration 66700, lr = 2.7e-06
I0423 21:00:36.205879 16565 solver.cpp:228] Iteration 66800, loss = 2.61916
I0423 21:00:36.206063 16565 solver.cpp:244]     Train net output #0: loss = 0.976825 (* 1 = 0.976825 loss)
I0423 21:00:36.206071 16565 solver.cpp:244]     Train net output #1: loss = 0.790408 (* 1 = 0.790408 loss)
I0423 21:00:36.206076 16565 solver.cpp:244]     Train net output #2: loss = 0.851923 (* 1 = 0.851923 loss)
I0423 21:00:36.206081 16565 sgd_solver.cpp:106] Iteration 66800, lr = 2.7e-06
I0423 21:02:14.848198 16565 solver.cpp:228] Iteration 66900, loss = 2.66929
I0423 21:02:14.848351 16565 solver.cpp:244]     Train net output #0: loss = 0.966728 (* 1 = 0.966728 loss)
I0423 21:02:14.848358 16565 solver.cpp:244]     Train net output #1: loss = 0.788076 (* 1 = 0.788076 loss)
I0423 21:02:14.848363 16565 solver.cpp:244]     Train net output #2: loss = 0.914481 (* 1 = 0.914481 loss)
I0423 21:02:14.848369 16565 sgd_solver.cpp:106] Iteration 66900, lr = 2.7e-06
I0423 21:03:52.529453 16565 solver.cpp:337] Iteration 67000, Testing net (#0)
I0423 21:03:52.531211 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 21:03:52.531215 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 21:03:52.531219 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 21:03:52.531234 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 21:03:52.531236 16565 net.cpp:693] Ignoring source layer visualize
I0423 21:03:52.531237 16565 net.cpp:693] Ignoring source layer fake
I0423 21:07:22.177508 16565 solver.cpp:404]     Test net output #0: loss = 0.977639 (* 1 = 0.977639 loss)
I0423 21:07:22.177656 16565 solver.cpp:404]     Test net output #1: loss = 0.753242 (* 1 = 0.753242 loss)
I0423 21:07:22.177664 16565 solver.cpp:404]     Test net output #2: loss = 0.796196 (* 1 = 0.796196 loss)
I0423 21:07:22.825232 16565 solver.cpp:228] Iteration 67000, loss = 2.73246
I0423 21:07:22.825284 16565 solver.cpp:244]     Train net output #0: loss = 0.987486 (* 1 = 0.987486 loss)
I0423 21:07:22.825289 16565 solver.cpp:244]     Train net output #1: loss = 0.82075 (* 1 = 0.82075 loss)
I0423 21:07:22.825292 16565 solver.cpp:244]     Train net output #2: loss = 0.924224 (* 1 = 0.924224 loss)
I0423 21:07:22.825299 16565 sgd_solver.cpp:106] Iteration 67000, lr = 2.7e-06
I0423 21:09:01.424417 16565 solver.cpp:228] Iteration 67100, loss = 2.73271
I0423 21:09:01.424577 16565 solver.cpp:244]     Train net output #0: loss = 0.988616 (* 1 = 0.988616 loss)
I0423 21:09:01.424585 16565 solver.cpp:244]     Train net output #1: loss = 0.814116 (* 1 = 0.814116 loss)
I0423 21:09:01.424592 16565 solver.cpp:244]     Train net output #2: loss = 0.929981 (* 1 = 0.929981 loss)
I0423 21:09:01.424599 16565 sgd_solver.cpp:106] Iteration 67100, lr = 2.7e-06
I0423 21:10:38.344861 16565 solver.cpp:228] Iteration 67200, loss = 2.73393
I0423 21:10:38.345021 16565 solver.cpp:244]     Train net output #0: loss = 0.986494 (* 1 = 0.986494 loss)
I0423 21:10:38.345027 16565 solver.cpp:244]     Train net output #1: loss = 0.84172 (* 1 = 0.84172 loss)
I0423 21:10:38.345033 16565 solver.cpp:244]     Train net output #2: loss = 0.905716 (* 1 = 0.905716 loss)
I0423 21:10:38.345038 16565 sgd_solver.cpp:106] Iteration 67200, lr = 2.7e-06
I0423 21:12:16.855921 16565 solver.cpp:228] Iteration 67300, loss = 2.66553
I0423 21:12:16.856062 16565 solver.cpp:244]     Train net output #0: loss = 0.984754 (* 1 = 0.984754 loss)
I0423 21:12:16.856070 16565 solver.cpp:244]     Train net output #1: loss = 0.755174 (* 1 = 0.755174 loss)
I0423 21:12:16.856076 16565 solver.cpp:244]     Train net output #2: loss = 0.925605 (* 1 = 0.925605 loss)
I0423 21:12:16.856081 16565 sgd_solver.cpp:106] Iteration 67300, lr = 2.7e-06
I0423 21:13:55.255095 16565 solver.cpp:228] Iteration 67400, loss = 2.47527
I0423 21:13:55.255271 16565 solver.cpp:244]     Train net output #0: loss = 0.987506 (* 1 = 0.987506 loss)
I0423 21:13:55.255278 16565 solver.cpp:244]     Train net output #1: loss = 0.718319 (* 1 = 0.718319 loss)
I0423 21:13:55.255283 16565 solver.cpp:244]     Train net output #2: loss = 0.769448 (* 1 = 0.769448 loss)
I0423 21:13:55.255290 16565 sgd_solver.cpp:106] Iteration 67400, lr = 2.7e-06
I0423 21:15:33.376374 16565 solver.cpp:228] Iteration 67500, loss = 2.5286
I0423 21:15:33.376566 16565 solver.cpp:244]     Train net output #0: loss = 0.969874 (* 1 = 0.969874 loss)
I0423 21:15:33.376574 16565 solver.cpp:244]     Train net output #1: loss = 0.655053 (* 1 = 0.655053 loss)
I0423 21:15:33.376579 16565 solver.cpp:244]     Train net output #2: loss = 0.903674 (* 1 = 0.903674 loss)
I0423 21:15:33.376585 16565 sgd_solver.cpp:106] Iteration 67500, lr = 2.7e-06
I0423 21:17:11.469914 16565 solver.cpp:228] Iteration 67600, loss = 2.51288
I0423 21:17:11.470060 16565 solver.cpp:244]     Train net output #0: loss = 0.962418 (* 1 = 0.962418 loss)
I0423 21:17:11.470068 16565 solver.cpp:244]     Train net output #1: loss = 0.770991 (* 1 = 0.770991 loss)
I0423 21:17:11.470073 16565 solver.cpp:244]     Train net output #2: loss = 0.779471 (* 1 = 0.779471 loss)
I0423 21:17:11.470079 16565 sgd_solver.cpp:106] Iteration 67600, lr = 2.7e-06
I0423 21:18:49.763592 16565 solver.cpp:228] Iteration 67700, loss = 2.75907
I0423 21:18:49.763764 16565 solver.cpp:244]     Train net output #0: loss = 0.980003 (* 1 = 0.980003 loss)
I0423 21:18:49.763773 16565 solver.cpp:244]     Train net output #1: loss = 0.83934 (* 1 = 0.83934 loss)
I0423 21:18:49.763778 16565 solver.cpp:244]     Train net output #2: loss = 0.939723 (* 1 = 0.939723 loss)
I0423 21:18:49.763783 16565 sgd_solver.cpp:106] Iteration 67700, lr = 2.7e-06
I0423 21:20:26.667467 16565 solver.cpp:228] Iteration 67800, loss = 2.4585
I0423 21:20:26.667625 16565 solver.cpp:244]     Train net output #0: loss = 0.983268 (* 1 = 0.983268 loss)
I0423 21:20:26.667632 16565 solver.cpp:244]     Train net output #1: loss = 0.713573 (* 1 = 0.713573 loss)
I0423 21:20:26.667637 16565 solver.cpp:244]     Train net output #2: loss = 0.76166 (* 1 = 0.76166 loss)
I0423 21:20:26.667642 16565 sgd_solver.cpp:106] Iteration 67800, lr = 2.7e-06
I0423 21:22:05.341760 16565 solver.cpp:228] Iteration 67900, loss = 2.76654
I0423 21:22:05.341915 16565 solver.cpp:244]     Train net output #0: loss = 0.979019 (* 1 = 0.979019 loss)
I0423 21:22:05.341922 16565 solver.cpp:244]     Train net output #1: loss = 0.864134 (* 1 = 0.864134 loss)
I0423 21:22:05.341928 16565 solver.cpp:244]     Train net output #2: loss = 0.923385 (* 1 = 0.923385 loss)
I0423 21:22:05.341933 16565 sgd_solver.cpp:106] Iteration 67900, lr = 2.7e-06
I0423 21:23:43.023290 16565 solver.cpp:337] Iteration 68000, Testing net (#0)
I0423 21:23:43.023419 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 21:23:43.023423 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 21:23:43.023428 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 21:23:43.023442 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 21:23:43.023447 16565 net.cpp:693] Ignoring source layer visualize
I0423 21:23:43.023447 16565 net.cpp:693] Ignoring source layer fake
I0423 21:27:12.256104 16565 solver.cpp:404]     Test net output #0: loss = 0.970616 (* 1 = 0.970616 loss)
I0423 21:27:12.256264 16565 solver.cpp:404]     Test net output #1: loss = 0.742112 (* 1 = 0.742112 loss)
I0423 21:27:12.256271 16565 solver.cpp:404]     Test net output #2: loss = 0.821779 (* 1 = 0.821779 loss)
I0423 21:27:12.903446 16565 solver.cpp:228] Iteration 68000, loss = 2.68663
I0423 21:27:12.903489 16565 solver.cpp:244]     Train net output #0: loss = 0.986162 (* 1 = 0.986162 loss)
I0423 21:27:12.903496 16565 solver.cpp:244]     Train net output #1: loss = 0.893809 (* 1 = 0.893809 loss)
I0423 21:27:12.903499 16565 solver.cpp:244]     Train net output #2: loss = 0.80666 (* 1 = 0.80666 loss)
I0423 21:27:12.903504 16565 sgd_solver.cpp:106] Iteration 68000, lr = 2.7e-06
I0423 21:28:52.194268 16565 solver.cpp:228] Iteration 68100, loss = 2.68034
I0423 21:28:52.194429 16565 solver.cpp:244]     Train net output #0: loss = 0.983075 (* 1 = 0.983075 loss)
I0423 21:28:52.194437 16565 solver.cpp:244]     Train net output #1: loss = 0.823953 (* 1 = 0.823953 loss)
I0423 21:28:52.194442 16565 solver.cpp:244]     Train net output #2: loss = 0.87331 (* 1 = 0.87331 loss)
I0423 21:28:52.194447 16565 sgd_solver.cpp:106] Iteration 68100, lr = 2.7e-06
I0423 21:30:29.119591 16565 solver.cpp:228] Iteration 68200, loss = 2.71905
I0423 21:30:29.119729 16565 solver.cpp:244]     Train net output #0: loss = 0.973718 (* 1 = 0.973718 loss)
I0423 21:30:29.119736 16565 solver.cpp:244]     Train net output #1: loss = 0.811486 (* 1 = 0.811486 loss)
I0423 21:30:29.119741 16565 solver.cpp:244]     Train net output #2: loss = 0.933851 (* 1 = 0.933851 loss)
I0423 21:30:29.119747 16565 sgd_solver.cpp:106] Iteration 68200, lr = 2.7e-06
I0423 21:32:08.117367 16565 solver.cpp:228] Iteration 68300, loss = 2.57866
I0423 21:32:08.117508 16565 solver.cpp:244]     Train net output #0: loss = 0.985842 (* 1 = 0.985842 loss)
I0423 21:32:08.117516 16565 solver.cpp:244]     Train net output #1: loss = 0.732953 (* 1 = 0.732953 loss)
I0423 21:32:08.117522 16565 solver.cpp:244]     Train net output #2: loss = 0.859869 (* 1 = 0.859869 loss)
I0423 21:32:08.117527 16565 sgd_solver.cpp:106] Iteration 68300, lr = 2.7e-06
I0423 21:33:46.685214 16565 solver.cpp:228] Iteration 68400, loss = 2.69713
I0423 21:33:46.685390 16565 solver.cpp:244]     Train net output #0: loss = 0.983607 (* 1 = 0.983607 loss)
I0423 21:33:46.685398 16565 solver.cpp:244]     Train net output #1: loss = 0.809536 (* 1 = 0.809536 loss)
I0423 21:33:46.685403 16565 solver.cpp:244]     Train net output #2: loss = 0.903986 (* 1 = 0.903986 loss)
I0423 21:33:46.685410 16565 sgd_solver.cpp:106] Iteration 68400, lr = 2.7e-06
I0423 21:35:25.569538 16565 solver.cpp:228] Iteration 68500, loss = 2.32089
I0423 21:35:25.569710 16565 solver.cpp:244]     Train net output #0: loss = 0.98885 (* 1 = 0.98885 loss)
I0423 21:35:25.569717 16565 solver.cpp:244]     Train net output #1: loss = 0.6831 (* 1 = 0.6831 loss)
I0423 21:35:25.569722 16565 solver.cpp:244]     Train net output #2: loss = 0.648943 (* 1 = 0.648943 loss)
I0423 21:35:25.569728 16565 sgd_solver.cpp:106] Iteration 68500, lr = 2.7e-06
I0423 21:37:02.499819 16565 solver.cpp:228] Iteration 68600, loss = 2.14174
I0423 21:37:02.499975 16565 solver.cpp:244]     Train net output #0: loss = 0.988079 (* 1 = 0.988079 loss)
I0423 21:37:02.499984 16565 solver.cpp:244]     Train net output #1: loss = 0.613254 (* 1 = 0.613254 loss)
I0423 21:37:02.499989 16565 solver.cpp:244]     Train net output #2: loss = 0.540405 (* 1 = 0.540405 loss)
I0423 21:37:02.499994 16565 sgd_solver.cpp:106] Iteration 68600, lr = 2.7e-06
I0423 21:38:40.960732 16565 solver.cpp:228] Iteration 68700, loss = 2.62947
I0423 21:38:40.961659 16565 solver.cpp:244]     Train net output #0: loss = 0.983938 (* 1 = 0.983938 loss)
I0423 21:38:40.961680 16565 solver.cpp:244]     Train net output #1: loss = 0.699446 (* 1 = 0.699446 loss)
I0423 21:38:40.961690 16565 solver.cpp:244]     Train net output #2: loss = 0.946086 (* 1 = 0.946086 loss)
I0423 21:38:40.961709 16565 sgd_solver.cpp:106] Iteration 68700, lr = 2.7e-06
I0423 21:40:19.106554 16565 solver.cpp:228] Iteration 68800, loss = 2.55306
I0423 21:40:19.106695 16565 solver.cpp:244]     Train net output #0: loss = 0.978191 (* 1 = 0.978191 loss)
I0423 21:40:19.106703 16565 solver.cpp:244]     Train net output #1: loss = 0.651265 (* 1 = 0.651265 loss)
I0423 21:40:19.106708 16565 solver.cpp:244]     Train net output #2: loss = 0.923605 (* 1 = 0.923605 loss)
I0423 21:40:19.106712 16565 sgd_solver.cpp:106] Iteration 68800, lr = 2.7e-06
I0423 21:41:57.285276 16565 solver.cpp:228] Iteration 68900, loss = 2.50037
I0423 21:41:57.285449 16565 solver.cpp:244]     Train net output #0: loss = 0.956997 (* 1 = 0.956997 loss)
I0423 21:41:57.285457 16565 solver.cpp:244]     Train net output #1: loss = 0.770379 (* 1 = 0.770379 loss)
I0423 21:41:57.285462 16565 solver.cpp:244]     Train net output #2: loss = 0.772997 (* 1 = 0.772997 loss)
I0423 21:41:57.285468 16565 sgd_solver.cpp:106] Iteration 68900, lr = 2.7e-06
I0423 21:43:36.441067 16565 solver.cpp:337] Iteration 69000, Testing net (#0)
I0423 21:43:36.441233 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 21:43:36.441238 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 21:43:36.441243 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 21:43:36.441258 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 21:43:36.441262 16565 net.cpp:693] Ignoring source layer visualize
I0423 21:43:36.441264 16565 net.cpp:693] Ignoring source layer fake
I0423 21:47:06.086408 16565 solver.cpp:404]     Test net output #0: loss = 0.97567 (* 1 = 0.97567 loss)
I0423 21:47:06.086560 16565 solver.cpp:404]     Test net output #1: loss = 0.759393 (* 1 = 0.759393 loss)
I0423 21:47:06.086566 16565 solver.cpp:404]     Test net output #2: loss = 0.796107 (* 1 = 0.796107 loss)
I0423 21:47:06.729918 16565 solver.cpp:228] Iteration 69000, loss = 2.35721
I0423 21:47:06.729961 16565 solver.cpp:244]     Train net output #0: loss = 0.975321 (* 1 = 0.975321 loss)
I0423 21:47:06.729967 16565 solver.cpp:244]     Train net output #1: loss = 0.801834 (* 1 = 0.801834 loss)
I0423 21:47:06.729971 16565 solver.cpp:244]     Train net output #2: loss = 0.580056 (* 1 = 0.580056 loss)
I0423 21:47:06.729976 16565 sgd_solver.cpp:106] Iteration 69000, lr = 2.7e-06
I0423 21:48:48.353060 16565 solver.cpp:228] Iteration 69100, loss = 2.69515
I0423 21:48:48.353247 16565 solver.cpp:244]     Train net output #0: loss = 0.955373 (* 1 = 0.955373 loss)
I0423 21:48:48.353255 16565 solver.cpp:244]     Train net output #1: loss = 0.831743 (* 1 = 0.831743 loss)
I0423 21:48:48.353260 16565 solver.cpp:244]     Train net output #2: loss = 0.908031 (* 1 = 0.908031 loss)
I0423 21:48:48.353267 16565 sgd_solver.cpp:106] Iteration 69100, lr = 2.7e-06
I0423 21:50:28.186223 16565 solver.cpp:228] Iteration 69200, loss = 2.61401
I0423 21:50:28.186390 16565 solver.cpp:244]     Train net output #0: loss = 0.972668 (* 1 = 0.972668 loss)
I0423 21:50:28.186398 16565 solver.cpp:244]     Train net output #1: loss = 0.747972 (* 1 = 0.747972 loss)
I0423 21:50:28.186403 16565 solver.cpp:244]     Train net output #2: loss = 0.893373 (* 1 = 0.893373 loss)
I0423 21:50:28.186408 16565 sgd_solver.cpp:106] Iteration 69200, lr = 2.7e-06
I0423 21:52:05.175904 16565 solver.cpp:228] Iteration 69300, loss = 2.67969
I0423 21:52:05.176074 16565 solver.cpp:244]     Train net output #0: loss = 0.968992 (* 1 = 0.968992 loss)
I0423 21:52:05.176082 16565 solver.cpp:244]     Train net output #1: loss = 0.791281 (* 1 = 0.791281 loss)
I0423 21:52:05.176087 16565 solver.cpp:244]     Train net output #2: loss = 0.919415 (* 1 = 0.919415 loss)
I0423 21:52:05.176093 16565 sgd_solver.cpp:106] Iteration 69300, lr = 2.7e-06
I0423 21:53:43.882812 16565 solver.cpp:228] Iteration 69400, loss = 2.75981
I0423 21:53:43.882967 16565 solver.cpp:244]     Train net output #0: loss = 0.96736 (* 1 = 0.96736 loss)
I0423 21:53:43.882974 16565 solver.cpp:244]     Train net output #1: loss = 0.851668 (* 1 = 0.851668 loss)
I0423 21:53:43.882979 16565 solver.cpp:244]     Train net output #2: loss = 0.940781 (* 1 = 0.940781 loss)
I0423 21:53:43.882984 16565 sgd_solver.cpp:106] Iteration 69400, lr = 2.7e-06
I0423 21:55:22.562276 16565 solver.cpp:228] Iteration 69500, loss = 2.73745
I0423 21:55:22.562432 16565 solver.cpp:244]     Train net output #0: loss = 0.980641 (* 1 = 0.980641 loss)
I0423 21:55:22.562438 16565 solver.cpp:244]     Train net output #1: loss = 0.836276 (* 1 = 0.836276 loss)
I0423 21:55:22.562443 16565 solver.cpp:244]     Train net output #2: loss = 0.920534 (* 1 = 0.920534 loss)
I0423 21:55:22.562449 16565 sgd_solver.cpp:106] Iteration 69500, lr = 2.7e-06
I0423 21:57:01.195696 16565 solver.cpp:228] Iteration 69600, loss = 2.76312
I0423 21:57:01.195855 16565 solver.cpp:244]     Train net output #0: loss = 0.982025 (* 1 = 0.982025 loss)
I0423 21:57:01.195863 16565 solver.cpp:244]     Train net output #1: loss = 0.840664 (* 1 = 0.840664 loss)
I0423 21:57:01.195868 16565 solver.cpp:244]     Train net output #2: loss = 0.940429 (* 1 = 0.940429 loss)
I0423 21:57:01.195873 16565 sgd_solver.cpp:106] Iteration 69600, lr = 2.7e-06
I0423 21:58:38.133469 16565 solver.cpp:228] Iteration 69700, loss = 2.77925
I0423 21:58:38.134189 16565 solver.cpp:244]     Train net output #0: loss = 0.983303 (* 1 = 0.983303 loss)
I0423 21:58:38.134198 16565 solver.cpp:244]     Train net output #1: loss = 0.862985 (* 1 = 0.862985 loss)
I0423 21:58:38.134203 16565 solver.cpp:244]     Train net output #2: loss = 0.932962 (* 1 = 0.932962 loss)
I0423 21:58:38.134208 16565 sgd_solver.cpp:106] Iteration 69700, lr = 2.7e-06
I0423 22:00:16.814460 16565 solver.cpp:228] Iteration 69800, loss = 2.74348
I0423 22:00:16.814618 16565 solver.cpp:244]     Train net output #0: loss = 0.984678 (* 1 = 0.984678 loss)
I0423 22:00:16.814627 16565 solver.cpp:244]     Train net output #1: loss = 0.83012 (* 1 = 0.83012 loss)
I0423 22:00:16.814631 16565 solver.cpp:244]     Train net output #2: loss = 0.928679 (* 1 = 0.928679 loss)
I0423 22:00:16.814636 16565 sgd_solver.cpp:106] Iteration 69800, lr = 2.7e-06
I0423 22:01:55.267309 16565 solver.cpp:228] Iteration 69900, loss = 2.27642
I0423 22:01:55.267485 16565 solver.cpp:244]     Train net output #0: loss = 0.98907 (* 1 = 0.98907 loss)
I0423 22:01:55.267493 16565 solver.cpp:244]     Train net output #1: loss = 0.663385 (* 1 = 0.663385 loss)
I0423 22:01:55.267498 16565 solver.cpp:244]     Train net output #2: loss = 0.623968 (* 1 = 0.623968 loss)
I0423 22:01:55.267504 16565 sgd_solver.cpp:106] Iteration 69900, lr = 2.7e-06
I0423 22:03:32.389065 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_70000.caffemodel
I0423 22:03:50.013813 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_70000.solverstate
I0423 22:03:50.208487 16565 solver.cpp:337] Iteration 70000, Testing net (#0)
I0423 22:03:50.208529 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 22:03:50.208533 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 22:03:50.208536 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 22:03:50.208550 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 22:03:50.208554 16565 net.cpp:693] Ignoring source layer visualize
I0423 22:03:50.208555 16565 net.cpp:693] Ignoring source layer fake
I0423 22:07:18.343103 16565 solver.cpp:404]     Test net output #0: loss = 0.968979 (* 1 = 0.968979 loss)
I0423 22:07:18.343233 16565 solver.cpp:404]     Test net output #1: loss = 0.753816 (* 1 = 0.753816 loss)
I0423 22:07:18.343241 16565 solver.cpp:404]     Test net output #2: loss = 0.826044 (* 1 = 0.826044 loss)
I0423 22:07:18.988806 16565 solver.cpp:228] Iteration 70000, loss = 2.75558
I0423 22:07:18.988847 16565 solver.cpp:244]     Train net output #0: loss = 0.967909 (* 1 = 0.967909 loss)
I0423 22:07:18.988852 16565 solver.cpp:244]     Train net output #1: loss = 0.831464 (* 1 = 0.831464 loss)
I0423 22:07:18.988857 16565 solver.cpp:244]     Train net output #2: loss = 0.956204 (* 1 = 0.956204 loss)
I0423 22:07:18.988862 16565 sgd_solver.cpp:106] Iteration 70000, lr = 2.7e-06
I0423 22:08:57.174371 16565 solver.cpp:228] Iteration 70100, loss = 2.21259
I0423 22:08:57.174527 16565 solver.cpp:244]     Train net output #0: loss = 0.985629 (* 1 = 0.985629 loss)
I0423 22:08:57.174535 16565 solver.cpp:244]     Train net output #1: loss = 0.651059 (* 1 = 0.651059 loss)
I0423 22:08:57.174540 16565 solver.cpp:244]     Train net output #2: loss = 0.575902 (* 1 = 0.575902 loss)
I0423 22:08:57.174546 16565 sgd_solver.cpp:106] Iteration 70100, lr = 2.7e-06
I0423 22:10:35.529314 16565 solver.cpp:228] Iteration 70200, loss = 2.35738
I0423 22:10:35.529495 16565 solver.cpp:244]     Train net output #0: loss = 0.990465 (* 1 = 0.990465 loss)
I0423 22:10:35.529503 16565 solver.cpp:244]     Train net output #1: loss = 0.786182 (* 1 = 0.786182 loss)
I0423 22:10:35.529508 16565 solver.cpp:244]     Train net output #2: loss = 0.580732 (* 1 = 0.580732 loss)
I0423 22:10:35.529513 16565 sgd_solver.cpp:106] Iteration 70200, lr = 2.7e-06
I0423 22:12:12.524194 16565 solver.cpp:228] Iteration 70300, loss = 2.54874
I0423 22:12:12.524348 16565 solver.cpp:244]     Train net output #0: loss = 0.976397 (* 1 = 0.976397 loss)
I0423 22:12:12.524356 16565 solver.cpp:244]     Train net output #1: loss = 0.802735 (* 1 = 0.802735 loss)
I0423 22:12:12.524360 16565 solver.cpp:244]     Train net output #2: loss = 0.769609 (* 1 = 0.769609 loss)
I0423 22:12:12.524366 16565 sgd_solver.cpp:106] Iteration 70300, lr = 2.7e-06
I0423 22:13:51.018926 16565 solver.cpp:228] Iteration 70400, loss = 2.7052
I0423 22:13:51.019075 16565 solver.cpp:244]     Train net output #0: loss = 0.96614 (* 1 = 0.96614 loss)
I0423 22:13:51.019083 16565 solver.cpp:244]     Train net output #1: loss = 0.835965 (* 1 = 0.835965 loss)
I0423 22:13:51.019088 16565 solver.cpp:244]     Train net output #2: loss = 0.903099 (* 1 = 0.903099 loss)
I0423 22:13:51.019093 16565 sgd_solver.cpp:106] Iteration 70400, lr = 2.7e-06
I0423 22:15:29.616281 16565 solver.cpp:228] Iteration 70500, loss = 2.67369
I0423 22:15:29.616428 16565 solver.cpp:244]     Train net output #0: loss = 0.970323 (* 1 = 0.970323 loss)
I0423 22:15:29.616437 16565 solver.cpp:244]     Train net output #1: loss = 0.778427 (* 1 = 0.778427 loss)
I0423 22:15:29.616441 16565 solver.cpp:244]     Train net output #2: loss = 0.924942 (* 1 = 0.924942 loss)
I0423 22:15:29.616447 16565 sgd_solver.cpp:106] Iteration 70500, lr = 2.7e-06
I0423 22:17:08.256539 16565 solver.cpp:228] Iteration 70600, loss = 2.65801
I0423 22:17:08.256736 16565 solver.cpp:244]     Train net output #0: loss = 0.973491 (* 1 = 0.973491 loss)
I0423 22:17:08.256744 16565 solver.cpp:244]     Train net output #1: loss = 0.785894 (* 1 = 0.785894 loss)
I0423 22:17:08.256748 16565 solver.cpp:244]     Train net output #2: loss = 0.898625 (* 1 = 0.898625 loss)
I0423 22:17:08.256754 16565 sgd_solver.cpp:106] Iteration 70600, lr = 2.7e-06
I0423 22:18:45.215245 16565 solver.cpp:228] Iteration 70700, loss = 2.66838
I0423 22:18:45.215410 16565 solver.cpp:244]     Train net output #0: loss = 0.975908 (* 1 = 0.975908 loss)
I0423 22:18:45.215417 16565 solver.cpp:244]     Train net output #1: loss = 0.813079 (* 1 = 0.813079 loss)
I0423 22:18:45.215422 16565 solver.cpp:244]     Train net output #2: loss = 0.879392 (* 1 = 0.879392 loss)
I0423 22:18:45.215430 16565 sgd_solver.cpp:106] Iteration 70700, lr = 2.7e-06
I0423 22:20:23.829830 16565 solver.cpp:228] Iteration 70800, loss = 2.58457
I0423 22:20:23.829989 16565 solver.cpp:244]     Train net output #0: loss = 0.987912 (* 1 = 0.987912 loss)
I0423 22:20:23.829996 16565 solver.cpp:244]     Train net output #1: loss = 0.692489 (* 1 = 0.692489 loss)
I0423 22:20:23.830003 16565 solver.cpp:244]     Train net output #2: loss = 0.904174 (* 1 = 0.904174 loss)
I0423 22:20:23.830008 16565 sgd_solver.cpp:106] Iteration 70800, lr = 2.7e-06
I0423 22:22:02.387774 16565 solver.cpp:228] Iteration 70900, loss = 2.52606
I0423 22:22:02.388175 16565 solver.cpp:244]     Train net output #0: loss = 0.987345 (* 1 = 0.987345 loss)
I0423 22:22:02.388182 16565 solver.cpp:244]     Train net output #1: loss = 0.795642 (* 1 = 0.795642 loss)
I0423 22:22:02.388187 16565 solver.cpp:244]     Train net output #2: loss = 0.743075 (* 1 = 0.743075 loss)
I0423 22:22:02.388192 16565 sgd_solver.cpp:106] Iteration 70900, lr = 2.7e-06
I0423 22:23:39.939879 16565 solver.cpp:337] Iteration 71000, Testing net (#0)
I0423 22:23:39.940018 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 22:23:39.940023 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 22:23:39.940027 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 22:23:39.940042 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 22:23:39.940045 16565 net.cpp:693] Ignoring source layer visualize
I0423 22:23:39.940048 16565 net.cpp:693] Ignoring source layer fake
I0423 22:27:08.759492 16565 solver.cpp:404]     Test net output #0: loss = 0.974376 (* 1 = 0.974376 loss)
I0423 22:27:08.759642 16565 solver.cpp:404]     Test net output #1: loss = 0.765198 (* 1 = 0.765198 loss)
I0423 22:27:08.759650 16565 solver.cpp:404]     Test net output #2: loss = 0.830049 (* 1 = 0.830049 loss)
I0423 22:27:09.408053 16565 solver.cpp:228] Iteration 71000, loss = 2.51953
I0423 22:27:09.408095 16565 solver.cpp:244]     Train net output #0: loss = 0.986335 (* 1 = 0.986335 loss)
I0423 22:27:09.408100 16565 solver.cpp:244]     Train net output #1: loss = 0.765782 (* 1 = 0.765782 loss)
I0423 22:27:09.408105 16565 solver.cpp:244]     Train net output #2: loss = 0.767411 (* 1 = 0.767411 loss)
I0423 22:27:09.408112 16565 sgd_solver.cpp:106] Iteration 71000, lr = 2.7e-06
I0423 22:28:46.353019 16565 solver.cpp:228] Iteration 71100, loss = 2.36217
I0423 22:28:46.353178 16565 solver.cpp:244]     Train net output #0: loss = 0.992695 (* 1 = 0.992695 loss)
I0423 22:28:46.353188 16565 solver.cpp:244]     Train net output #1: loss = 0.773015 (* 1 = 0.773015 loss)
I0423 22:28:46.353193 16565 solver.cpp:244]     Train net output #2: loss = 0.596464 (* 1 = 0.596464 loss)
I0423 22:28:46.353198 16565 sgd_solver.cpp:106] Iteration 71100, lr = 2.7e-06
I0423 22:30:24.835042 16565 solver.cpp:228] Iteration 71200, loss = 2.62091
I0423 22:30:24.835230 16565 solver.cpp:244]     Train net output #0: loss = 0.974758 (* 1 = 0.974758 loss)
I0423 22:30:24.835238 16565 solver.cpp:244]     Train net output #1: loss = 0.744493 (* 1 = 0.744493 loss)
I0423 22:30:24.835244 16565 solver.cpp:244]     Train net output #2: loss = 0.901659 (* 1 = 0.901659 loss)
I0423 22:30:24.835249 16565 sgd_solver.cpp:106] Iteration 71200, lr = 2.7e-06
I0423 22:32:02.863035 16565 solver.cpp:228] Iteration 71300, loss = 2.57793
I0423 22:32:02.863179 16565 solver.cpp:244]     Train net output #0: loss = 0.972652 (* 1 = 0.972652 loss)
I0423 22:32:02.863188 16565 solver.cpp:244]     Train net output #1: loss = 0.667766 (* 1 = 0.667766 loss)
I0423 22:32:02.863193 16565 solver.cpp:244]     Train net output #2: loss = 0.937509 (* 1 = 0.937509 loss)
I0423 22:32:02.863198 16565 sgd_solver.cpp:106] Iteration 71300, lr = 2.7e-06
I0423 22:33:40.919272 16565 solver.cpp:228] Iteration 71400, loss = 2.66484
I0423 22:33:40.919416 16565 solver.cpp:244]     Train net output #0: loss = 0.962187 (* 1 = 0.962187 loss)
I0423 22:33:40.919425 16565 solver.cpp:244]     Train net output #1: loss = 0.750801 (* 1 = 0.750801 loss)
I0423 22:33:40.919430 16565 solver.cpp:244]     Train net output #2: loss = 0.951852 (* 1 = 0.951852 loss)
I0423 22:33:40.919435 16565 sgd_solver.cpp:106] Iteration 71400, lr = 2.7e-06
I0423 22:35:19.452749 16565 solver.cpp:228] Iteration 71500, loss = 2.36847
I0423 22:35:19.452942 16565 solver.cpp:244]     Train net output #0: loss = 0.985745 (* 1 = 0.985745 loss)
I0423 22:35:19.452951 16565 solver.cpp:244]     Train net output #1: loss = 0.820768 (* 1 = 0.820768 loss)
I0423 22:35:19.452956 16565 solver.cpp:244]     Train net output #2: loss = 0.561956 (* 1 = 0.561956 loss)
I0423 22:35:19.452962 16565 sgd_solver.cpp:106] Iteration 71500, lr = 2.7e-06
I0423 22:36:58.032461 16565 solver.cpp:228] Iteration 71600, loss = 2.7973
I0423 22:36:58.032616 16565 solver.cpp:244]     Train net output #0: loss = 0.975654 (* 1 = 0.975654 loss)
I0423 22:36:58.032624 16565 solver.cpp:244]     Train net output #1: loss = 0.901091 (* 1 = 0.901091 loss)
I0423 22:36:58.032629 16565 solver.cpp:244]     Train net output #2: loss = 0.920555 (* 1 = 0.920555 loss)
I0423 22:36:58.032636 16565 sgd_solver.cpp:106] Iteration 71600, lr = 2.7e-06
I0423 22:38:36.648197 16565 solver.cpp:228] Iteration 71700, loss = 2.73093
I0423 22:38:36.648352 16565 solver.cpp:244]     Train net output #0: loss = 0.979199 (* 1 = 0.979199 loss)
I0423 22:38:36.648360 16565 solver.cpp:244]     Train net output #1: loss = 0.852104 (* 1 = 0.852104 loss)
I0423 22:38:36.648365 16565 solver.cpp:244]     Train net output #2: loss = 0.899629 (* 1 = 0.899629 loss)
I0423 22:38:36.648371 16565 sgd_solver.cpp:106] Iteration 71700, lr = 2.7e-06
I0423 22:40:13.646080 16565 solver.cpp:228] Iteration 71800, loss = 2.62534
I0423 22:40:13.646203 16565 solver.cpp:244]     Train net output #0: loss = 0.982161 (* 1 = 0.982161 loss)
I0423 22:40:13.646209 16565 solver.cpp:244]     Train net output #1: loss = 0.891731 (* 1 = 0.891731 loss)
I0423 22:40:13.646215 16565 solver.cpp:244]     Train net output #2: loss = 0.751451 (* 1 = 0.751451 loss)
I0423 22:40:13.646221 16565 sgd_solver.cpp:106] Iteration 71800, lr = 2.7e-06
I0423 22:41:52.295385 16565 solver.cpp:228] Iteration 71900, loss = 2.81828
I0423 22:41:52.295544 16565 solver.cpp:244]     Train net output #0: loss = 0.980296 (* 1 = 0.980296 loss)
I0423 22:41:52.295553 16565 solver.cpp:244]     Train net output #1: loss = 0.896769 (* 1 = 0.896769 loss)
I0423 22:41:52.295558 16565 solver.cpp:244]     Train net output #2: loss = 0.941216 (* 1 = 0.941216 loss)
I0423 22:41:52.295564 16565 sgd_solver.cpp:106] Iteration 71900, lr = 2.7e-06
I0423 22:43:29.971489 16565 solver.cpp:337] Iteration 72000, Testing net (#0)
I0423 22:43:29.971638 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 22:43:29.971643 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 22:43:29.971647 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 22:43:29.971662 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 22:43:29.971665 16565 net.cpp:693] Ignoring source layer visualize
I0423 22:43:29.971668 16565 net.cpp:693] Ignoring source layer fake
I0423 22:47:00.252797 16565 solver.cpp:404]     Test net output #0: loss = 0.977564 (* 1 = 0.977564 loss)
I0423 22:47:00.253002 16565 solver.cpp:404]     Test net output #1: loss = 0.754336 (* 1 = 0.754336 loss)
I0423 22:47:00.253017 16565 solver.cpp:404]     Test net output #2: loss = 0.797412 (* 1 = 0.797412 loss)
I0423 22:47:00.921138 16565 solver.cpp:228] Iteration 72000, loss = 2.80164
I0423 22:47:00.921197 16565 solver.cpp:244]     Train net output #0: loss = 0.986569 (* 1 = 0.986569 loss)
I0423 22:47:00.921211 16565 solver.cpp:244]     Train net output #1: loss = 0.873171 (* 1 = 0.873171 loss)
I0423 22:47:00.921218 16565 solver.cpp:244]     Train net output #2: loss = 0.941896 (* 1 = 0.941896 loss)
I0423 22:47:00.921229 16565 sgd_solver.cpp:106] Iteration 72000, lr = 2.7e-06
I0423 22:48:39.795997 16565 solver.cpp:228] Iteration 72100, loss = 2.69794
I0423 22:48:39.797101 16565 solver.cpp:244]     Train net output #0: loss = 0.979012 (* 1 = 0.979012 loss)
I0423 22:48:39.797109 16565 solver.cpp:244]     Train net output #1: loss = 0.840257 (* 1 = 0.840257 loss)
I0423 22:48:39.797114 16565 solver.cpp:244]     Train net output #2: loss = 0.87867 (* 1 = 0.87867 loss)
I0423 22:48:39.797121 16565 sgd_solver.cpp:106] Iteration 72100, lr = 2.7e-06
I0423 22:50:16.802932 16565 solver.cpp:228] Iteration 72200, loss = 2.81446
I0423 22:50:16.803094 16565 solver.cpp:244]     Train net output #0: loss = 0.98878 (* 1 = 0.98878 loss)
I0423 22:50:16.803102 16565 solver.cpp:244]     Train net output #1: loss = 0.873982 (* 1 = 0.873982 loss)
I0423 22:50:16.803107 16565 solver.cpp:244]     Train net output #2: loss = 0.951695 (* 1 = 0.951695 loss)
I0423 22:50:16.803113 16565 sgd_solver.cpp:106] Iteration 72200, lr = 2.7e-06
I0423 22:51:55.577147 16565 solver.cpp:228] Iteration 72300, loss = 2.40056
I0423 22:51:55.577299 16565 solver.cpp:244]     Train net output #0: loss = 0.986892 (* 1 = 0.986892 loss)
I0423 22:51:55.577307 16565 solver.cpp:244]     Train net output #1: loss = 0.621516 (* 1 = 0.621516 loss)
I0423 22:51:55.577312 16565 solver.cpp:244]     Train net output #2: loss = 0.792148 (* 1 = 0.792148 loss)
I0423 22:51:55.577318 16565 sgd_solver.cpp:106] Iteration 72300, lr = 2.7e-06
I0423 22:53:34.188415 16565 solver.cpp:228] Iteration 72400, loss = 2.63656
I0423 22:53:34.188575 16565 solver.cpp:244]     Train net output #0: loss = 0.988219 (* 1 = 0.988219 loss)
I0423 22:53:34.188582 16565 solver.cpp:244]     Train net output #1: loss = 0.702208 (* 1 = 0.702208 loss)
I0423 22:53:34.188588 16565 solver.cpp:244]     Train net output #2: loss = 0.946138 (* 1 = 0.946138 loss)
I0423 22:53:34.188594 16565 sgd_solver.cpp:106] Iteration 72400, lr = 2.7e-06
I0423 22:55:12.386728 16565 solver.cpp:228] Iteration 72500, loss = 2.59912
I0423 22:55:12.386879 16565 solver.cpp:244]     Train net output #0: loss = 0.979207 (* 1 = 0.979207 loss)
I0423 22:55:12.386888 16565 solver.cpp:244]     Train net output #1: loss = 0.69068 (* 1 = 0.69068 loss)
I0423 22:55:12.386893 16565 solver.cpp:244]     Train net output #2: loss = 0.929229 (* 1 = 0.929229 loss)
I0423 22:55:12.386898 16565 sgd_solver.cpp:106] Iteration 72500, lr = 2.7e-06
I0423 22:56:50.665500 16565 solver.cpp:228] Iteration 72600, loss = 2.70407
I0423 22:56:50.665652 16565 solver.cpp:244]     Train net output #0: loss = 0.970552 (* 1 = 0.970552 loss)
I0423 22:56:50.665660 16565 solver.cpp:244]     Train net output #1: loss = 0.779118 (* 1 = 0.779118 loss)
I0423 22:56:50.665665 16565 solver.cpp:244]     Train net output #2: loss = 0.954401 (* 1 = 0.954401 loss)
I0423 22:56:50.665670 16565 sgd_solver.cpp:106] Iteration 72600, lr = 2.7e-06
I0423 22:58:29.147651 16565 solver.cpp:228] Iteration 72700, loss = 2.30902
I0423 22:58:29.147783 16565 solver.cpp:244]     Train net output #0: loss = 0.986871 (* 1 = 0.986871 loss)
I0423 22:58:29.147790 16565 solver.cpp:244]     Train net output #1: loss = 0.762413 (* 1 = 0.762413 loss)
I0423 22:58:29.147795 16565 solver.cpp:244]     Train net output #2: loss = 0.559736 (* 1 = 0.559736 loss)
I0423 22:58:29.147801 16565 sgd_solver.cpp:106] Iteration 72700, lr = 2.7e-06
I0423 23:00:06.123059 16565 solver.cpp:228] Iteration 72800, loss = 2.52666
I0423 23:00:06.123248 16565 solver.cpp:244]     Train net output #0: loss = 0.984838 (* 1 = 0.984838 loss)
I0423 23:00:06.123256 16565 solver.cpp:244]     Train net output #1: loss = 0.788712 (* 1 = 0.788712 loss)
I0423 23:00:06.123262 16565 solver.cpp:244]     Train net output #2: loss = 0.753112 (* 1 = 0.753112 loss)
I0423 23:00:06.123267 16565 sgd_solver.cpp:106] Iteration 72800, lr = 2.7e-06
I0423 23:01:44.795243 16565 solver.cpp:228] Iteration 72900, loss = 2.75972
I0423 23:01:44.795399 16565 solver.cpp:244]     Train net output #0: loss = 0.981135 (* 1 = 0.981135 loss)
I0423 23:01:44.795408 16565 solver.cpp:244]     Train net output #1: loss = 0.862959 (* 1 = 0.862959 loss)
I0423 23:01:44.795411 16565 solver.cpp:244]     Train net output #2: loss = 0.915627 (* 1 = 0.915627 loss)
I0423 23:01:44.795416 16565 sgd_solver.cpp:106] Iteration 72900, lr = 2.7e-06
I0423 23:03:22.635625 16565 solver.cpp:337] Iteration 73000, Testing net (#0)
I0423 23:03:22.635793 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 23:03:22.635798 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 23:03:22.635802 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 23:03:22.635818 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 23:03:22.635821 16565 net.cpp:693] Ignoring source layer visualize
I0423 23:03:22.635823 16565 net.cpp:693] Ignoring source layer fake
I0423 23:06:52.839037 16565 solver.cpp:404]     Test net output #0: loss = 0.970556 (* 1 = 0.970556 loss)
I0423 23:06:52.839190 16565 solver.cpp:404]     Test net output #1: loss = 0.743662 (* 1 = 0.743662 loss)
I0423 23:06:52.839198 16565 solver.cpp:404]     Test net output #2: loss = 0.821701 (* 1 = 0.821701 loss)
I0423 23:06:53.481398 16565 solver.cpp:228] Iteration 73000, loss = 2.71336
I0423 23:06:53.481429 16565 solver.cpp:244]     Train net output #0: loss = 0.965577 (* 1 = 0.965577 loss)
I0423 23:06:53.481439 16565 solver.cpp:244]     Train net output #1: loss = 0.812953 (* 1 = 0.812953 loss)
I0423 23:06:53.481444 16565 solver.cpp:244]     Train net output #2: loss = 0.934836 (* 1 = 0.934836 loss)
I0423 23:06:53.481467 16565 sgd_solver.cpp:106] Iteration 73000, lr = 2.7e-06
I0423 23:08:32.301661 16565 solver.cpp:228] Iteration 73100, loss = 2.77647
I0423 23:08:32.301836 16565 solver.cpp:244]     Train net output #0: loss = 0.978597 (* 1 = 0.978597 loss)
I0423 23:08:32.301844 16565 solver.cpp:244]     Train net output #1: loss = 0.882176 (* 1 = 0.882176 loss)
I0423 23:08:32.301849 16565 solver.cpp:244]     Train net output #2: loss = 0.915694 (* 1 = 0.915694 loss)
I0423 23:08:32.301856 16565 sgd_solver.cpp:106] Iteration 73100, lr = 2.7e-06
I0423 23:10:09.336081 16565 solver.cpp:228] Iteration 73200, loss = 2.77907
I0423 23:10:09.337491 16565 solver.cpp:244]     Train net output #0: loss = 0.989056 (* 1 = 0.989056 loss)
I0423 23:10:09.337498 16565 solver.cpp:244]     Train net output #1: loss = 0.908858 (* 1 = 0.908858 loss)
I0423 23:10:09.337503 16565 solver.cpp:244]     Train net output #2: loss = 0.881153 (* 1 = 0.881153 loss)
I0423 23:10:09.337509 16565 sgd_solver.cpp:106] Iteration 73200, lr = 2.7e-06
I0423 23:11:48.120852 16565 solver.cpp:228] Iteration 73300, loss = 2.73445
I0423 23:11:48.121006 16565 solver.cpp:244]     Train net output #0: loss = 0.989908 (* 1 = 0.989908 loss)
I0423 23:11:48.121013 16565 solver.cpp:244]     Train net output #1: loss = 0.827441 (* 1 = 0.827441 loss)
I0423 23:11:48.121018 16565 solver.cpp:244]     Train net output #2: loss = 0.917102 (* 1 = 0.917102 loss)
I0423 23:11:48.121024 16565 sgd_solver.cpp:106] Iteration 73300, lr = 2.7e-06
I0423 23:13:26.882195 16565 solver.cpp:228] Iteration 73400, loss = 2.61179
I0423 23:13:26.883633 16565 solver.cpp:244]     Train net output #0: loss = 0.985385 (* 1 = 0.985385 loss)
I0423 23:13:26.883641 16565 solver.cpp:244]     Train net output #1: loss = 0.858899 (* 1 = 0.858899 loss)
I0423 23:13:26.883647 16565 solver.cpp:244]     Train net output #2: loss = 0.767509 (* 1 = 0.767509 loss)
I0423 23:13:26.883652 16565 sgd_solver.cpp:106] Iteration 73400, lr = 2.7e-06
I0423 23:15:05.624733 16565 solver.cpp:228] Iteration 73500, loss = 2.66952
I0423 23:15:05.624959 16565 solver.cpp:244]     Train net output #0: loss = 0.98623 (* 1 = 0.98623 loss)
I0423 23:15:05.624969 16565 solver.cpp:244]     Train net output #1: loss = 0.823776 (* 1 = 0.823776 loss)
I0423 23:15:05.624974 16565 solver.cpp:244]     Train net output #2: loss = 0.859511 (* 1 = 0.859511 loss)
I0423 23:15:05.624980 16565 sgd_solver.cpp:106] Iteration 73500, lr = 2.7e-06
I0423 23:16:42.629765 16565 solver.cpp:228] Iteration 73600, loss = 2.56876
I0423 23:16:42.629927 16565 solver.cpp:244]     Train net output #0: loss = 0.988893 (* 1 = 0.988893 loss)
I0423 23:16:42.629935 16565 solver.cpp:244]     Train net output #1: loss = 0.748789 (* 1 = 0.748789 loss)
I0423 23:16:42.629940 16565 solver.cpp:244]     Train net output #2: loss = 0.831075 (* 1 = 0.831075 loss)
I0423 23:16:42.629945 16565 sgd_solver.cpp:106] Iteration 73600, lr = 2.7e-06
I0423 23:18:21.241593 16565 solver.cpp:228] Iteration 73700, loss = 2.19431
I0423 23:18:21.241740 16565 solver.cpp:244]     Train net output #0: loss = 0.979346 (* 1 = 0.979346 loss)
I0423 23:18:21.241749 16565 solver.cpp:244]     Train net output #1: loss = 0.540261 (* 1 = 0.540261 loss)
I0423 23:18:21.241753 16565 solver.cpp:244]     Train net output #2: loss = 0.674707 (* 1 = 0.674707 loss)
I0423 23:18:21.241760 16565 sgd_solver.cpp:106] Iteration 73700, lr = 2.7e-06
I0423 23:19:59.442589 16565 solver.cpp:228] Iteration 73800, loss = 2.72138
I0423 23:19:59.442746 16565 solver.cpp:244]     Train net output #0: loss = 0.973383 (* 1 = 0.973383 loss)
I0423 23:19:59.442754 16565 solver.cpp:244]     Train net output #1: loss = 0.803605 (* 1 = 0.803605 loss)
I0423 23:19:59.442760 16565 solver.cpp:244]     Train net output #2: loss = 0.94439 (* 1 = 0.94439 loss)
I0423 23:19:59.442765 16565 sgd_solver.cpp:106] Iteration 73800, lr = 2.7e-06
I0423 23:21:37.761368 16565 solver.cpp:228] Iteration 73900, loss = 2.53792
I0423 23:21:37.761508 16565 solver.cpp:244]     Train net output #0: loss = 0.969715 (* 1 = 0.969715 loss)
I0423 23:21:37.761518 16565 solver.cpp:244]     Train net output #1: loss = 0.837905 (* 1 = 0.837905 loss)
I0423 23:21:37.761523 16565 solver.cpp:244]     Train net output #2: loss = 0.730304 (* 1 = 0.730304 loss)
I0423 23:21:37.761528 16565 sgd_solver.cpp:106] Iteration 73900, lr = 2.7e-06
I0423 23:23:15.278928 16565 solver.cpp:337] Iteration 74000, Testing net (#0)
I0423 23:23:15.279099 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 23:23:15.279103 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 23:23:15.279108 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 23:23:15.279122 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 23:23:15.279126 16565 net.cpp:693] Ignoring source layer visualize
I0423 23:23:15.279129 16565 net.cpp:693] Ignoring source layer fake
I0423 23:26:45.526912 16565 solver.cpp:404]     Test net output #0: loss = 0.974997 (* 1 = 0.974997 loss)
I0423 23:26:45.527067 16565 solver.cpp:404]     Test net output #1: loss = 0.756066 (* 1 = 0.756066 loss)
I0423 23:26:45.527076 16565 solver.cpp:404]     Test net output #2: loss = 0.792085 (* 1 = 0.792085 loss)
I0423 23:26:46.172396 16565 solver.cpp:228] Iteration 74000, loss = 2.54965
I0423 23:26:46.172447 16565 solver.cpp:244]     Train net output #0: loss = 0.985641 (* 1 = 0.985641 loss)
I0423 23:26:46.172453 16565 solver.cpp:244]     Train net output #1: loss = 0.806164 (* 1 = 0.806164 loss)
I0423 23:26:46.172458 16565 solver.cpp:244]     Train net output #2: loss = 0.757847 (* 1 = 0.757847 loss)
I0423 23:26:46.172464 16565 sgd_solver.cpp:106] Iteration 74000, lr = 2.7e-06
I0423 23:28:24.941185 16565 solver.cpp:228] Iteration 74100, loss = 2.71422
I0423 23:28:24.941365 16565 solver.cpp:244]     Train net output #0: loss = 0.961089 (* 1 = 0.961089 loss)
I0423 23:28:24.941373 16565 solver.cpp:244]     Train net output #1: loss = 0.842759 (* 1 = 0.842759 loss)
I0423 23:28:24.941378 16565 solver.cpp:244]     Train net output #2: loss = 0.910367 (* 1 = 0.910367 loss)
I0423 23:28:24.941385 16565 sgd_solver.cpp:106] Iteration 74100, lr = 2.7e-06
I0423 23:30:03.762820 16565 solver.cpp:228] Iteration 74200, loss = 2.77606
I0423 23:30:03.763005 16565 solver.cpp:244]     Train net output #0: loss = 0.979206 (* 1 = 0.979206 loss)
I0423 23:30:03.763012 16565 solver.cpp:244]     Train net output #1: loss = 0.885749 (* 1 = 0.885749 loss)
I0423 23:30:03.763017 16565 solver.cpp:244]     Train net output #2: loss = 0.911104 (* 1 = 0.911104 loss)
I0423 23:30:03.763025 16565 sgd_solver.cpp:106] Iteration 74200, lr = 2.7e-06
I0423 23:31:40.767453 16565 solver.cpp:228] Iteration 74300, loss = 2.58541
I0423 23:31:40.767598 16565 solver.cpp:244]     Train net output #0: loss = 0.984447 (* 1 = 0.984447 loss)
I0423 23:31:40.767606 16565 solver.cpp:244]     Train net output #1: loss = 0.867396 (* 1 = 0.867396 loss)
I0423 23:31:40.767611 16565 solver.cpp:244]     Train net output #2: loss = 0.733567 (* 1 = 0.733567 loss)
I0423 23:31:40.767616 16565 sgd_solver.cpp:106] Iteration 74300, lr = 2.7e-06
I0423 23:33:19.620713 16565 solver.cpp:228] Iteration 74400, loss = 2.68438
I0423 23:33:19.620872 16565 solver.cpp:244]     Train net output #0: loss = 0.975459 (* 1 = 0.975459 loss)
I0423 23:33:19.620880 16565 solver.cpp:244]     Train net output #1: loss = 0.818014 (* 1 = 0.818014 loss)
I0423 23:33:19.620885 16565 solver.cpp:244]     Train net output #2: loss = 0.890904 (* 1 = 0.890904 loss)
I0423 23:33:19.620892 16565 sgd_solver.cpp:106] Iteration 74400, lr = 2.7e-06
I0423 23:34:58.404675 16565 solver.cpp:228] Iteration 74500, loss = 2.77548
I0423 23:34:58.404842 16565 solver.cpp:244]     Train net output #0: loss = 0.992949 (* 1 = 0.992949 loss)
I0423 23:34:58.404850 16565 solver.cpp:244]     Train net output #1: loss = 0.863118 (* 1 = 0.863118 loss)
I0423 23:34:58.404855 16565 solver.cpp:244]     Train net output #2: loss = 0.919409 (* 1 = 0.919409 loss)
I0423 23:34:58.404861 16565 sgd_solver.cpp:106] Iteration 74500, lr = 2.7e-06
I0423 23:36:37.154199 16565 solver.cpp:228] Iteration 74600, loss = 2.67545
I0423 23:36:37.154379 16565 solver.cpp:244]     Train net output #0: loss = 0.980777 (* 1 = 0.980777 loss)
I0423 23:36:37.154387 16565 solver.cpp:244]     Train net output #1: loss = 0.810459 (* 1 = 0.810459 loss)
I0423 23:36:37.154392 16565 solver.cpp:244]     Train net output #2: loss = 0.884215 (* 1 = 0.884215 loss)
I0423 23:36:37.154397 16565 sgd_solver.cpp:106] Iteration 74600, lr = 2.7e-06
I0423 23:38:14.136385 16565 solver.cpp:228] Iteration 74700, loss = 2.75831
I0423 23:38:14.136566 16565 solver.cpp:244]     Train net output #0: loss = 0.990164 (* 1 = 0.990164 loss)
I0423 23:38:14.136574 16565 solver.cpp:244]     Train net output #1: loss = 0.808397 (* 1 = 0.808397 loss)
I0423 23:38:14.136579 16565 solver.cpp:244]     Train net output #2: loss = 0.959753 (* 1 = 0.959753 loss)
I0423 23:38:14.136585 16565 sgd_solver.cpp:106] Iteration 74700, lr = 2.7e-06
I0423 23:39:52.890830 16565 solver.cpp:228] Iteration 74800, loss = 2.24635
I0423 23:39:52.891985 16565 solver.cpp:244]     Train net output #0: loss = 0.989632 (* 1 = 0.989632 loss)
I0423 23:39:52.891993 16565 solver.cpp:244]     Train net output #1: loss = 0.593649 (* 1 = 0.593649 loss)
I0423 23:39:52.891997 16565 solver.cpp:244]     Train net output #2: loss = 0.663071 (* 1 = 0.663071 loss)
I0423 23:39:52.892004 16565 sgd_solver.cpp:106] Iteration 74800, lr = 2.7e-06
I0423 23:41:31.565991 16565 solver.cpp:228] Iteration 74900, loss = 2.41147
I0423 23:41:31.566151 16565 solver.cpp:244]     Train net output #0: loss = 0.986011 (* 1 = 0.986011 loss)
I0423 23:41:31.566160 16565 solver.cpp:244]     Train net output #1: loss = 0.692396 (* 1 = 0.692396 loss)
I0423 23:41:31.566165 16565 solver.cpp:244]     Train net output #2: loss = 0.733063 (* 1 = 0.733063 loss)
I0423 23:41:31.566171 16565 sgd_solver.cpp:106] Iteration 74900, lr = 2.7e-06
I0423 23:43:08.866852 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_75000.caffemodel
I0423 23:43:11.595644 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_75000.solverstate
I0423 23:43:11.801076 16565 solver.cpp:337] Iteration 75000, Testing net (#0)
I0423 23:43:11.801120 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0423 23:43:11.801123 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0423 23:43:11.801127 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0423 23:43:11.801141 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0423 23:43:11.801144 16565 net.cpp:693] Ignoring source layer visualize
I0423 23:43:11.801146 16565 net.cpp:693] Ignoring source layer fake
I0423 23:46:41.685602 16565 solver.cpp:404]     Test net output #0: loss = 0.969049 (* 1 = 0.969049 loss)
I0423 23:46:41.685734 16565 solver.cpp:404]     Test net output #1: loss = 0.754872 (* 1 = 0.754872 loss)
I0423 23:46:41.685745 16565 solver.cpp:404]     Test net output #2: loss = 0.827863 (* 1 = 0.827863 loss)
I0423 23:46:42.329947 16565 solver.cpp:228] Iteration 75000, loss = 2.57479
I0423 23:46:42.329996 16565 solver.cpp:244]     Train net output #0: loss = 0.982085 (* 1 = 0.982085 loss)
I0423 23:46:42.330001 16565 solver.cpp:244]     Train net output #1: loss = 0.67135 (* 1 = 0.67135 loss)
I0423 23:46:42.330006 16565 solver.cpp:244]     Train net output #2: loss = 0.921355 (* 1 = 0.921355 loss)
I0423 23:46:42.330011 16565 sgd_solver.cpp:106] Iteration 75000, lr = 2.7e-06
I0423 23:48:20.636477 16565 solver.cpp:228] Iteration 75100, loss = 2.75035
I0423 23:48:20.636649 16565 solver.cpp:244]     Train net output #0: loss = 0.964662 (* 1 = 0.964662 loss)
I0423 23:48:20.636657 16565 solver.cpp:244]     Train net output #1: loss = 0.886151 (* 1 = 0.886151 loss)
I0423 23:48:20.636662 16565 solver.cpp:244]     Train net output #2: loss = 0.899536 (* 1 = 0.899536 loss)
I0423 23:48:20.636669 16565 sgd_solver.cpp:106] Iteration 75100, lr = 2.7e-06
I0423 23:49:59.111575 16565 solver.cpp:228] Iteration 75200, loss = 2.69468
I0423 23:49:59.111729 16565 solver.cpp:244]     Train net output #0: loss = 0.984549 (* 1 = 0.984549 loss)
I0423 23:49:59.111737 16565 solver.cpp:244]     Train net output #1: loss = 0.76485 (* 1 = 0.76485 loss)
I0423 23:49:59.111742 16565 solver.cpp:244]     Train net output #2: loss = 0.945281 (* 1 = 0.945281 loss)
I0423 23:49:59.111748 16565 sgd_solver.cpp:106] Iteration 75200, lr = 2.7e-06
I0423 23:51:37.899471 16565 solver.cpp:228] Iteration 75300, loss = 2.16625
I0423 23:51:37.899631 16565 solver.cpp:244]     Train net output #0: loss = 0.980288 (* 1 = 0.980288 loss)
I0423 23:51:37.899639 16565 solver.cpp:244]     Train net output #1: loss = 0.624233 (* 1 = 0.624233 loss)
I0423 23:51:37.899644 16565 solver.cpp:244]     Train net output #2: loss = 0.561729 (* 1 = 0.561729 loss)
I0423 23:51:37.899649 16565 sgd_solver.cpp:106] Iteration 75300, lr = 2.7e-06
I0423 23:53:14.878219 16565 solver.cpp:228] Iteration 75400, loss = 2.26332
I0423 23:53:14.879405 16565 solver.cpp:244]     Train net output #0: loss = 0.981293 (* 1 = 0.981293 loss)
I0423 23:53:14.879413 16565 solver.cpp:244]     Train net output #1: loss = 0.718873 (* 1 = 0.718873 loss)
I0423 23:53:14.879417 16565 solver.cpp:244]     Train net output #2: loss = 0.563155 (* 1 = 0.563155 loss)
I0423 23:53:14.879425 16565 sgd_solver.cpp:106] Iteration 75400, lr = 2.7e-06
I0423 23:54:53.711187 16565 solver.cpp:228] Iteration 75500, loss = 2.85866
I0423 23:54:53.711328 16565 solver.cpp:244]     Train net output #0: loss = 0.984204 (* 1 = 0.984204 loss)
I0423 23:54:53.711336 16565 solver.cpp:244]     Train net output #1: loss = 0.921869 (* 1 = 0.921869 loss)
I0423 23:54:53.711341 16565 solver.cpp:244]     Train net output #2: loss = 0.952589 (* 1 = 0.952589 loss)
I0423 23:54:53.711349 16565 sgd_solver.cpp:106] Iteration 75500, lr = 2.7e-06
I0423 23:56:32.582491 16565 solver.cpp:228] Iteration 75600, loss = 2.82692
I0423 23:56:32.582659 16565 solver.cpp:244]     Train net output #0: loss = 0.986279 (* 1 = 0.986279 loss)
I0423 23:56:32.582667 16565 solver.cpp:244]     Train net output #1: loss = 0.933346 (* 1 = 0.933346 loss)
I0423 23:56:32.582674 16565 solver.cpp:244]     Train net output #2: loss = 0.907294 (* 1 = 0.907294 loss)
I0423 23:56:32.582679 16565 sgd_solver.cpp:106] Iteration 75600, lr = 2.7e-06
I0423 23:58:09.566145 16565 solver.cpp:228] Iteration 75700, loss = 2.74476
I0423 23:58:09.566309 16565 solver.cpp:244]     Train net output #0: loss = 0.98593 (* 1 = 0.98593 loss)
I0423 23:58:09.566318 16565 solver.cpp:244]     Train net output #1: loss = 0.857669 (* 1 = 0.857669 loss)
I0423 23:58:09.566323 16565 solver.cpp:244]     Train net output #2: loss = 0.901167 (* 1 = 0.901167 loss)
I0423 23:58:09.566329 16565 sgd_solver.cpp:106] Iteration 75700, lr = 2.7e-06
I0423 23:59:48.319093 16565 solver.cpp:228] Iteration 75800, loss = 2.76838
I0423 23:59:48.319242 16565 solver.cpp:244]     Train net output #0: loss = 0.989674 (* 1 = 0.989674 loss)
I0423 23:59:48.319250 16565 solver.cpp:244]     Train net output #1: loss = 0.886992 (* 1 = 0.886992 loss)
I0423 23:59:48.319255 16565 solver.cpp:244]     Train net output #2: loss = 0.891712 (* 1 = 0.891712 loss)
I0423 23:59:48.319260 16565 sgd_solver.cpp:106] Iteration 75800, lr = 2.7e-06
I0424 00:01:27.157099 16565 solver.cpp:228] Iteration 75900, loss = 2.81754
I0424 00:01:27.157263 16565 solver.cpp:244]     Train net output #0: loss = 0.991637 (* 1 = 0.991637 loss)
I0424 00:01:27.157271 16565 solver.cpp:244]     Train net output #1: loss = 0.873809 (* 1 = 0.873809 loss)
I0424 00:01:27.157276 16565 solver.cpp:244]     Train net output #2: loss = 0.95209 (* 1 = 0.95209 loss)
I0424 00:01:27.157284 16565 sgd_solver.cpp:106] Iteration 75900, lr = 2.7e-06
I0424 00:03:04.958979 16565 solver.cpp:337] Iteration 76000, Testing net (#0)
I0424 00:03:04.959130 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0424 00:03:04.959134 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0424 00:03:04.959139 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0424 00:03:04.959154 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0424 00:03:04.959157 16565 net.cpp:693] Ignoring source layer visualize
I0424 00:03:04.959159 16565 net.cpp:693] Ignoring source layer fake
I0424 00:06:35.190392 16565 solver.cpp:404]     Test net output #0: loss = 0.97333 (* 1 = 0.97333 loss)
I0424 00:06:35.190534 16565 solver.cpp:404]     Test net output #1: loss = 0.761624 (* 1 = 0.761624 loss)
I0424 00:06:35.190542 16565 solver.cpp:404]     Test net output #2: loss = 0.829368 (* 1 = 0.829368 loss)
I0424 00:06:35.837055 16565 solver.cpp:228] Iteration 76000, loss = 2.44499
I0424 00:06:35.837098 16565 solver.cpp:244]     Train net output #0: loss = 0.98455 (* 1 = 0.98455 loss)
I0424 00:06:35.837105 16565 solver.cpp:244]     Train net output #1: loss = 0.662419 (* 1 = 0.662419 loss)
I0424 00:06:35.837108 16565 solver.cpp:244]     Train net output #2: loss = 0.798023 (* 1 = 0.798023 loss)
I0424 00:06:35.837113 16565 sgd_solver.cpp:106] Iteration 76000, lr = 2.7e-06
I0424 00:08:12.861913 16565 solver.cpp:228] Iteration 76100, loss = 2.35719
I0424 00:08:12.862092 16565 solver.cpp:244]     Train net output #0: loss = 0.987627 (* 1 = 0.987627 loss)
I0424 00:08:12.862098 16565 solver.cpp:244]     Train net output #1: loss = 0.725874 (* 1 = 0.725874 loss)
I0424 00:08:12.862103 16565 solver.cpp:244]     Train net output #2: loss = 0.643694 (* 1 = 0.643694 loss)
I0424 00:08:12.862109 16565 sgd_solver.cpp:106] Iteration 76100, lr = 2.7e-06
I0424 00:09:51.509711 16565 solver.cpp:228] Iteration 76200, loss = 2.40794
I0424 00:09:51.509887 16565 solver.cpp:244]     Train net output #0: loss = 0.96271 (* 1 = 0.96271 loss)
I0424 00:09:51.509896 16565 solver.cpp:244]     Train net output #1: loss = 0.600383 (* 1 = 0.600383 loss)
I0424 00:09:51.509901 16565 solver.cpp:244]     Train net output #2: loss = 0.844848 (* 1 = 0.844848 loss)
I0424 00:09:51.509907 16565 sgd_solver.cpp:106] Iteration 76200, lr = 2.7e-06
I0424 00:11:29.827230 16565 solver.cpp:228] Iteration 76300, loss = 2.55194
I0424 00:11:29.827424 16565 solver.cpp:244]     Train net output #0: loss = 0.983623 (* 1 = 0.983623 loss)
I0424 00:11:29.827432 16565 solver.cpp:244]     Train net output #1: loss = 0.649035 (* 1 = 0.649035 loss)
I0424 00:11:29.827437 16565 solver.cpp:244]     Train net output #2: loss = 0.91928 (* 1 = 0.91928 loss)
I0424 00:11:29.827443 16565 sgd_solver.cpp:106] Iteration 76300, lr = 2.7e-06
I0424 00:13:08.100059 16565 solver.cpp:228] Iteration 76400, loss = 2.49711
I0424 00:13:08.100213 16565 solver.cpp:244]     Train net output #0: loss = 0.987724 (* 1 = 0.987724 loss)
I0424 00:13:08.100220 16565 solver.cpp:244]     Train net output #1: loss = 0.800409 (* 1 = 0.800409 loss)
I0424 00:13:08.100224 16565 solver.cpp:244]     Train net output #2: loss = 0.708973 (* 1 = 0.708973 loss)
I0424 00:13:08.100230 16565 sgd_solver.cpp:106] Iteration 76400, lr = 2.7e-06
I0424 00:14:46.619940 16565 solver.cpp:228] Iteration 76500, loss = 2.3084
I0424 00:14:46.620100 16565 solver.cpp:244]     Train net output #0: loss = 0.983221 (* 1 = 0.983221 loss)
I0424 00:14:46.620107 16565 solver.cpp:244]     Train net output #1: loss = 0.753928 (* 1 = 0.753928 loss)
I0424 00:14:46.620112 16565 solver.cpp:244]     Train net output #2: loss = 0.571254 (* 1 = 0.571254 loss)
I0424 00:14:46.620118 16565 sgd_solver.cpp:106] Iteration 76500, lr = 2.7e-06
I0424 00:16:25.421850 16565 solver.cpp:228] Iteration 76600, loss = 2.69069
I0424 00:16:25.422024 16565 solver.cpp:244]     Train net output #0: loss = 0.964273 (* 1 = 0.964273 loss)
I0424 00:16:25.422031 16565 solver.cpp:244]     Train net output #1: loss = 0.835633 (* 1 = 0.835633 loss)
I0424 00:16:25.422036 16565 solver.cpp:244]     Train net output #2: loss = 0.890784 (* 1 = 0.890784 loss)
I0424 00:16:25.422041 16565 sgd_solver.cpp:106] Iteration 76600, lr = 2.7e-06
I0424 00:18:04.223426 16565 solver.cpp:228] Iteration 76700, loss = 2.75364
I0424 00:18:04.223595 16565 solver.cpp:244]     Train net output #0: loss = 0.975431 (* 1 = 0.975431 loss)
I0424 00:18:04.223603 16565 solver.cpp:244]     Train net output #1: loss = 0.858942 (* 1 = 0.858942 loss)
I0424 00:18:04.223608 16565 solver.cpp:244]     Train net output #2: loss = 0.919267 (* 1 = 0.919267 loss)
I0424 00:18:04.223613 16565 sgd_solver.cpp:106] Iteration 76700, lr = 2.7e-06
I0424 00:19:41.247576 16565 solver.cpp:228] Iteration 76800, loss = 2.66792
I0424 00:19:41.247737 16565 solver.cpp:244]     Train net output #0: loss = 0.976422 (* 1 = 0.976422 loss)
I0424 00:19:41.247745 16565 solver.cpp:244]     Train net output #1: loss = 0.825329 (* 1 = 0.825329 loss)
I0424 00:19:41.247750 16565 solver.cpp:244]     Train net output #2: loss = 0.86617 (* 1 = 0.86617 loss)
I0424 00:19:41.247756 16565 sgd_solver.cpp:106] Iteration 76800, lr = 2.7e-06
I0424 00:21:20.146374 16565 solver.cpp:228] Iteration 76900, loss = 2.60853
I0424 00:21:20.146530 16565 solver.cpp:244]     Train net output #0: loss = 0.971122 (* 1 = 0.971122 loss)
I0424 00:21:20.146538 16565 solver.cpp:244]     Train net output #1: loss = 0.778351 (* 1 = 0.778351 loss)
I0424 00:21:20.146543 16565 solver.cpp:244]     Train net output #2: loss = 0.859052 (* 1 = 0.859052 loss)
I0424 00:21:20.146549 16565 sgd_solver.cpp:106] Iteration 76900, lr = 2.7e-06
I0424 00:22:58.065479 16565 solver.cpp:337] Iteration 77000, Testing net (#0)
I0424 00:22:58.068085 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0424 00:22:58.068091 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0424 00:22:58.068096 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0424 00:22:58.068112 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0424 00:22:58.068115 16565 net.cpp:693] Ignoring source layer visualize
I0424 00:22:58.068117 16565 net.cpp:693] Ignoring source layer fake
I0424 00:26:28.900321 16565 solver.cpp:404]     Test net output #0: loss = 0.976889 (* 1 = 0.976889 loss)
I0424 00:26:28.902478 16565 solver.cpp:404]     Test net output #1: loss = 0.74842 (* 1 = 0.74842 loss)
I0424 00:26:28.902496 16565 solver.cpp:404]     Test net output #2: loss = 0.792925 (* 1 = 0.792925 loss)
I0424 00:26:29.562731 16565 solver.cpp:228] Iteration 77000, loss = 2.78329
I0424 00:26:29.562779 16565 solver.cpp:244]     Train net output #0: loss = 0.991608 (* 1 = 0.991608 loss)
I0424 00:26:29.562785 16565 solver.cpp:244]     Train net output #1: loss = 0.891102 (* 1 = 0.891102 loss)
I0424 00:26:29.562790 16565 solver.cpp:244]     Train net output #2: loss = 0.900581 (* 1 = 0.900581 loss)
I0424 00:26:29.562795 16565 sgd_solver.cpp:106] Iteration 77000, lr = 2.7e-06
I0424 00:28:08.245682 16565 solver.cpp:228] Iteration 77100, loss = 2.52601
I0424 00:28:08.245826 16565 solver.cpp:244]     Train net output #0: loss = 0.983456 (* 1 = 0.983456 loss)
I0424 00:28:08.245833 16565 solver.cpp:244]     Train net output #1: loss = 0.787101 (* 1 = 0.787101 loss)
I0424 00:28:08.245838 16565 solver.cpp:244]     Train net output #2: loss = 0.755449 (* 1 = 0.755449 loss)
I0424 00:28:08.245846 16565 sgd_solver.cpp:106] Iteration 77100, lr = 2.7e-06
I0424 00:29:45.621824 16565 solver.cpp:228] Iteration 77200, loss = 2.74258
I0424 00:29:45.622005 16565 solver.cpp:244]     Train net output #0: loss = 0.983283 (* 1 = 0.983283 loss)
I0424 00:29:45.622014 16565 solver.cpp:244]     Train net output #1: loss = 0.808259 (* 1 = 0.808259 loss)
I0424 00:29:45.622018 16565 solver.cpp:244]     Train net output #2: loss = 0.951035 (* 1 = 0.951035 loss)
I0424 00:29:45.622025 16565 sgd_solver.cpp:106] Iteration 77200, lr = 2.7e-06
I0424 00:31:24.233099 16565 solver.cpp:228] Iteration 77300, loss = 2.60834
I0424 00:31:24.233271 16565 solver.cpp:244]     Train net output #0: loss = 0.982604 (* 1 = 0.982604 loss)
I0424 00:31:24.233280 16565 solver.cpp:244]     Train net output #1: loss = 0.854631 (* 1 = 0.854631 loss)
I0424 00:31:24.233285 16565 solver.cpp:244]     Train net output #2: loss = 0.771105 (* 1 = 0.771105 loss)
I0424 00:31:24.233290 16565 sgd_solver.cpp:106] Iteration 77300, lr = 2.7e-06
I0424 00:33:02.723942 16565 solver.cpp:228] Iteration 77400, loss = 2.23939
I0424 00:33:02.724092 16565 solver.cpp:244]     Train net output #0: loss = 0.987729 (* 1 = 0.987729 loss)
I0424 00:33:02.724100 16565 solver.cpp:244]     Train net output #1: loss = 0.540795 (* 1 = 0.540795 loss)
I0424 00:33:02.724105 16565 solver.cpp:244]     Train net output #2: loss = 0.71087 (* 1 = 0.71087 loss)
I0424 00:33:02.724112 16565 sgd_solver.cpp:106] Iteration 77400, lr = 2.7e-06
I0424 00:34:42.968595 16565 solver.cpp:228] Iteration 77500, loss = 2.53677
I0424 00:34:42.970651 16565 solver.cpp:244]     Train net output #0: loss = 0.979197 (* 1 = 0.979197 loss)
I0424 00:34:42.970659 16565 solver.cpp:244]     Train net output #1: loss = 0.644321 (* 1 = 0.644321 loss)
I0424 00:34:42.970664 16565 solver.cpp:244]     Train net output #2: loss = 0.913251 (* 1 = 0.913251 loss)
I0424 00:34:42.970669 16565 sgd_solver.cpp:106] Iteration 77500, lr = 2.7e-06
I0424 00:36:22.446873 16565 solver.cpp:228] Iteration 77600, loss = 2.66313
I0424 00:36:22.447042 16565 solver.cpp:244]     Train net output #0: loss = 0.970959 (* 1 = 0.970959 loss)
I0424 00:36:22.447051 16565 solver.cpp:244]     Train net output #1: loss = 0.798863 (* 1 = 0.798863 loss)
I0424 00:36:22.447055 16565 solver.cpp:244]     Train net output #2: loss = 0.893305 (* 1 = 0.893305 loss)
I0424 00:36:22.447060 16565 sgd_solver.cpp:106] Iteration 77600, lr = 2.7e-06
I0424 00:38:00.944707 16565 solver.cpp:228] Iteration 77700, loss = 2.57336
I0424 00:38:00.944869 16565 solver.cpp:244]     Train net output #0: loss = 0.983436 (* 1 = 0.983436 loss)
I0424 00:38:00.944877 16565 solver.cpp:244]     Train net output #1: loss = 0.816665 (* 1 = 0.816665 loss)
I0424 00:38:00.944882 16565 solver.cpp:244]     Train net output #2: loss = 0.773257 (* 1 = 0.773257 loss)
I0424 00:38:00.944887 16565 sgd_solver.cpp:106] Iteration 77700, lr = 2.7e-06
I0424 00:39:40.945987 16565 solver.cpp:228] Iteration 77800, loss = 1.95672
I0424 00:39:40.946148 16565 solver.cpp:244]     Train net output #0: loss = 0.978975 (* 1 = 0.978975 loss)
I0424 00:39:40.946156 16565 solver.cpp:244]     Train net output #1: loss = 0.603684 (* 1 = 0.603684 loss)
I0424 00:39:40.946161 16565 solver.cpp:244]     Train net output #2: loss = 0.374058 (* 1 = 0.374058 loss)
I0424 00:39:40.946167 16565 sgd_solver.cpp:106] Iteration 77800, lr = 2.7e-06
I0424 00:41:17.947042 16565 solver.cpp:228] Iteration 77900, loss = 2.34285
I0424 00:41:17.947227 16565 solver.cpp:244]     Train net output #0: loss = 0.967952 (* 1 = 0.967952 loss)
I0424 00:41:17.947234 16565 solver.cpp:244]     Train net output #1: loss = 0.620661 (* 1 = 0.620661 loss)
I0424 00:41:17.947239 16565 solver.cpp:244]     Train net output #2: loss = 0.754233 (* 1 = 0.754233 loss)
I0424 00:41:17.947245 16565 sgd_solver.cpp:106] Iteration 77900, lr = 2.7e-06
I0424 00:42:56.121983 16565 solver.cpp:337] Iteration 78000, Testing net (#0)
I0424 00:42:56.122164 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0424 00:42:56.122169 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0424 00:42:56.122174 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0424 00:42:56.122189 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0424 00:42:56.122193 16565 net.cpp:693] Ignoring source layer visualize
I0424 00:42:56.122195 16565 net.cpp:693] Ignoring source layer fake
I0424 00:46:25.376389 16565 solver.cpp:404]     Test net output #0: loss = 0.97006 (* 1 = 0.97006 loss)
I0424 00:46:25.376559 16565 solver.cpp:404]     Test net output #1: loss = 0.742707 (* 1 = 0.742707 loss)
I0424 00:46:25.376566 16565 solver.cpp:404]     Test net output #2: loss = 0.821396 (* 1 = 0.821396 loss)
I0424 00:46:26.022739 16565 solver.cpp:228] Iteration 78000, loss = 2.7714
I0424 00:46:26.022788 16565 solver.cpp:244]     Train net output #0: loss = 0.978749 (* 1 = 0.978749 loss)
I0424 00:46:26.022792 16565 solver.cpp:244]     Train net output #1: loss = 0.869151 (* 1 = 0.869151 loss)
I0424 00:46:26.022796 16565 solver.cpp:244]     Train net output #2: loss = 0.9235 (* 1 = 0.9235 loss)
I0424 00:46:26.022802 16565 sgd_solver.cpp:106] Iteration 78000, lr = 2.7e-06
I0424 00:48:04.782526 16565 solver.cpp:228] Iteration 78100, loss = 2.7381
I0424 00:48:04.782688 16565 solver.cpp:244]     Train net output #0: loss = 0.983535 (* 1 = 0.983535 loss)
I0424 00:48:04.782696 16565 solver.cpp:244]     Train net output #1: loss = 0.846525 (* 1 = 0.846525 loss)
I0424 00:48:04.782702 16565 solver.cpp:244]     Train net output #2: loss = 0.90804 (* 1 = 0.90804 loss)
I0424 00:48:04.782708 16565 sgd_solver.cpp:106] Iteration 78100, lr = 2.7e-06
I0424 00:49:41.744364 16565 solver.cpp:228] Iteration 78200, loss = 2.59027
I0424 00:49:41.744779 16565 solver.cpp:244]     Train net output #0: loss = 0.973124 (* 1 = 0.973124 loss)
I0424 00:49:41.744807 16565 solver.cpp:244]     Train net output #1: loss = 0.771864 (* 1 = 0.771864 loss)
I0424 00:49:41.744827 16565 solver.cpp:244]     Train net output #2: loss = 0.845281 (* 1 = 0.845281 loss)
I0424 00:49:41.744832 16565 sgd_solver.cpp:106] Iteration 78200, lr = 2.7e-06
I0424 00:51:20.394481 16565 solver.cpp:228] Iteration 78300, loss = 2.78512
I0424 00:51:20.394646 16565 solver.cpp:244]     Train net output #0: loss = 0.991109 (* 1 = 0.991109 loss)
I0424 00:51:20.394654 16565 solver.cpp:244]     Train net output #1: loss = 0.884506 (* 1 = 0.884506 loss)
I0424 00:51:20.394659 16565 solver.cpp:244]     Train net output #2: loss = 0.90951 (* 1 = 0.90951 loss)
I0424 00:51:20.394665 16565 sgd_solver.cpp:106] Iteration 78300, lr = 2.7e-06
I0424 00:52:59.083219 16565 solver.cpp:228] Iteration 78400, loss = 2.78689
I0424 00:52:59.083394 16565 solver.cpp:244]     Train net output #0: loss = 0.989227 (* 1 = 0.989227 loss)
I0424 00:52:59.083401 16565 solver.cpp:244]     Train net output #1: loss = 0.849413 (* 1 = 0.849413 loss)
I0424 00:52:59.083406 16565 solver.cpp:244]     Train net output #2: loss = 0.948251 (* 1 = 0.948251 loss)
I0424 00:52:59.083412 16565 sgd_solver.cpp:106] Iteration 78400, lr = 2.7e-06
I0424 00:54:37.775720 16565 solver.cpp:228] Iteration 78500, loss = 2.51137
I0424 00:54:37.775892 16565 solver.cpp:244]     Train net output #0: loss = 0.985498 (* 1 = 0.985498 loss)
I0424 00:54:37.775900 16565 solver.cpp:244]     Train net output #1: loss = 0.785737 (* 1 = 0.785737 loss)
I0424 00:54:37.775907 16565 solver.cpp:244]     Train net output #2: loss = 0.74013 (* 1 = 0.74013 loss)
I0424 00:54:37.775912 16565 sgd_solver.cpp:106] Iteration 78500, lr = 2.7e-06
I0424 00:56:14.756793 16565 solver.cpp:228] Iteration 78600, loss = 2.5767
I0424 00:56:14.758524 16565 solver.cpp:244]     Train net output #0: loss = 0.988642 (* 1 = 0.988642 loss)
I0424 00:56:14.758533 16565 solver.cpp:244]     Train net output #1: loss = 0.82536 (* 1 = 0.82536 loss)
I0424 00:56:14.758539 16565 solver.cpp:244]     Train net output #2: loss = 0.762694 (* 1 = 0.762694 loss)
I0424 00:56:14.758543 16565 sgd_solver.cpp:106] Iteration 78600, lr = 2.7e-06
I0424 00:57:53.272378 16565 solver.cpp:228] Iteration 78700, loss = 2.36742
I0424 00:57:53.272549 16565 solver.cpp:244]     Train net output #0: loss = 0.924664 (* 1 = 0.924664 loss)
I0424 00:57:53.272557 16565 solver.cpp:244]     Train net output #1: loss = 0.581135 (* 1 = 0.581135 loss)
I0424 00:57:53.272562 16565 solver.cpp:244]     Train net output #2: loss = 0.861623 (* 1 = 0.861623 loss)
I0424 00:57:53.272567 16565 sgd_solver.cpp:106] Iteration 78700, lr = 2.7e-06
I0424 00:59:31.385857 16565 solver.cpp:228] Iteration 78800, loss = 2.61628
I0424 00:59:31.386857 16565 solver.cpp:244]     Train net output #0: loss = 0.979936 (* 1 = 0.979936 loss)
I0424 00:59:31.386863 16565 solver.cpp:244]     Train net output #1: loss = 0.697722 (* 1 = 0.697722 loss)
I0424 00:59:31.386868 16565 solver.cpp:244]     Train net output #2: loss = 0.938621 (* 1 = 0.938621 loss)
I0424 00:59:31.386874 16565 sgd_solver.cpp:106] Iteration 78800, lr = 2.7e-06
I0424 01:01:09.511245 16565 solver.cpp:228] Iteration 78900, loss = 2.45021
I0424 01:01:09.511387 16565 solver.cpp:244]     Train net output #0: loss = 0.964446 (* 1 = 0.964446 loss)
I0424 01:01:09.511395 16565 solver.cpp:244]     Train net output #1: loss = 0.735811 (* 1 = 0.735811 loss)
I0424 01:01:09.511400 16565 solver.cpp:244]     Train net output #2: loss = 0.749953 (* 1 = 0.749953 loss)
I0424 01:01:09.511407 16565 sgd_solver.cpp:106] Iteration 78900, lr = 2.7e-06
I0424 01:02:46.909309 16565 solver.cpp:337] Iteration 79000, Testing net (#0)
I0424 01:02:46.909451 16565 net.cpp:693] Ignoring source layer dropout_d3c
I0424 01:02:46.909456 16565 net.cpp:693] Ignoring source layer d3c_dropout_d3c_0_split
I0424 01:02:46.909461 16565 net.cpp:693] Ignoring source layer dropout_d4c
I0424 01:02:46.909474 16565 net.cpp:693] Ignoring source layer score_conv_u0d-score_0_split
I0424 01:02:46.909477 16565 net.cpp:693] Ignoring source layer visualize
I0424 01:02:46.909479 16565 net.cpp:693] Ignoring source layer fake
I0424 01:06:16.576534 16565 solver.cpp:404]     Test net output #0: loss = 0.974486 (* 1 = 0.974486 loss)
I0424 01:06:16.576664 16565 solver.cpp:404]     Test net output #1: loss = 0.752468 (* 1 = 0.752468 loss)
I0424 01:06:16.576671 16565 solver.cpp:404]     Test net output #2: loss = 0.788178 (* 1 = 0.788178 loss)
I0424 01:06:17.228585 16565 solver.cpp:228] Iteration 79000, loss = 2.69628
I0424 01:06:17.228627 16565 solver.cpp:244]     Train net output #0: loss = 0.973392 (* 1 = 0.973392 loss)
I0424 01:06:17.228632 16565 solver.cpp:244]     Train net output #1: loss = 0.823609 (* 1 = 0.823609 loss)
I0424 01:06:17.228636 16565 solver.cpp:244]     Train net output #2: loss = 0.899275 (* 1 = 0.899275 loss)
I0424 01:06:17.228641 16565 sgd_solver.cpp:106] Iteration 79000, lr = 2.7e-06
I0424 01:07:55.822059 16565 solver.cpp:228] Iteration 79100, loss = 2.6701
I0424 01:07:55.822218 16565 solver.cpp:244]     Train net output #0: loss = 0.968292 (* 1 = 0.968292 loss)
I0424 01:07:55.822227 16565 solver.cpp:244]     Train net output #1: loss = 0.770991 (* 1 = 0.770991 loss)
I0424 01:07:55.822232 16565 solver.cpp:244]     Train net output #2: loss = 0.93082 (* 1 = 0.93082 loss)
I0424 01:07:55.822237 16565 sgd_solver.cpp:106] Iteration 79100, lr = 2.7e-06
I0424 01:09:34.563772 16565 solver.cpp:228] Iteration 79200, loss = 2.8067
I0424 01:09:34.563943 16565 solver.cpp:244]     Train net output #0: loss = 0.983773 (* 1 = 0.983773 loss)
I0424 01:09:34.563951 16565 solver.cpp:244]     Train net output #1: loss = 0.921213 (* 1 = 0.921213 loss)
I0424 01:09:34.563956 16565 solver.cpp:244]     Train net output #2: loss = 0.901713 (* 1 = 0.901713 loss)
I0424 01:09:34.563962 16565 sgd_solver.cpp:106] Iteration 79200, lr = 2.7e-06
I0424 01:11:11.559034 16565 solver.cpp:228] Iteration 79300, loss = 2.58832
I0424 01:11:11.559195 16565 solver.cpp:244]     Train net output #0: loss = 0.987306 (* 1 = 0.987306 loss)
I0424 01:11:11.559202 16565 solver.cpp:244]     Train net output #1: loss = 0.882322 (* 1 = 0.882322 loss)
I0424 01:11:11.559207 16565 solver.cpp:244]     Train net output #2: loss = 0.718696 (* 1 = 0.718696 loss)
I0424 01:11:11.559213 16565 sgd_solver.cpp:106] Iteration 79300, lr = 2.7e-06
I0424 01:12:50.269505 16565 solver.cpp:228] Iteration 79400, loss = 2.69793
I0424 01:12:50.269660 16565 solver.cpp:244]     Train net output #0: loss = 0.97686 (* 1 = 0.97686 loss)
I0424 01:12:50.269668 16565 solver.cpp:244]     Train net output #1: loss = 0.826319 (* 1 = 0.826319 loss)
I0424 01:12:50.269673 16565 solver.cpp:244]     Train net output #2: loss = 0.894755 (* 1 = 0.894755 loss)
I0424 01:12:50.269680 16565 sgd_solver.cpp:106] Iteration 79400, lr = 2.7e-06
I0424 01:14:28.977316 16565 solver.cpp:228] Iteration 79500, loss = 2.62691
I0424 01:14:28.977481 16565 solver.cpp:244]     Train net output #0: loss = 0.987764 (* 1 = 0.987764 loss)
I0424 01:14:28.977488 16565 solver.cpp:244]     Train net output #1: loss = 0.735934 (* 1 = 0.735934 loss)
I0424 01:14:28.977494 16565 solver.cpp:244]     Train net output #2: loss = 0.903215 (* 1 = 0.903215 loss)
I0424 01:14:28.977499 16565 sgd_solver.cpp:106] Iteration 79500, lr = 2.7e-06
I0424 01:16:07.624155 16565 solver.cpp:228] Iteration 79600, loss = 2.7726
I0424 01:16:07.624939 16565 solver.cpp:244]     Train net output #0: loss = 0.98387 (* 1 = 0.98387 loss)
I0424 01:16:07.624948 16565 solver.cpp:244]     Train net output #1: loss = 0.847335 (* 1 = 0.847335 loss)
I0424 01:16:07.624955 16565 solver.cpp:244]     Train net output #2: loss = 0.941398 (* 1 = 0.941398 loss)
I0424 01:16:07.624959 16565 sgd_solver.cpp:106] Iteration 79600, lr = 2.7e-06
I0424 01:17:44.619874 16565 solver.cpp:228] Iteration 79700, loss = 2.77254
I0424 01:17:44.620031 16565 solver.cpp:244]     Train net output #0: loss = 0.990362 (* 1 = 0.990362 loss)
I0424 01:17:44.620040 16565 solver.cpp:244]     Train net output #1: loss = 0.860982 (* 1 = 0.860982 loss)
I0424 01:17:44.620045 16565 solver.cpp:244]     Train net output #2: loss = 0.921196 (* 1 = 0.921196 loss)
I0424 01:17:44.620051 16565 sgd_solver.cpp:106] Iteration 79700, lr = 2.7e-06
I0424 01:19:23.370673 16565 solver.cpp:228] Iteration 79800, loss = 2.63963
I0424 01:19:23.371188 16565 solver.cpp:244]     Train net output #0: loss = 0.979305 (* 1 = 0.979305 loss)
I0424 01:19:23.371196 16565 solver.cpp:244]     Train net output #1: loss = 0.806121 (* 1 = 0.806121 loss)
I0424 01:19:23.371201 16565 solver.cpp:244]     Train net output #2: loss = 0.854207 (* 1 = 0.854207 loss)
I0424 01:19:23.371206 16565 sgd_solver.cpp:106] Iteration 79800, lr = 2.7e-06
I0424 01:21:01.888576 16565 solver.cpp:228] Iteration 79900, loss = 2.61793
I0424 01:21:01.888736 16565 solver.cpp:244]     Train net output #0: loss = 0.985482 (* 1 = 0.985482 loss)
I0424 01:21:01.888743 16565 solver.cpp:244]     Train net output #1: loss = 0.732684 (* 1 = 0.732684 loss)
I0424 01:21:01.888748 16565 solver.cpp:244]     Train net output #2: loss = 0.899765 (* 1 = 0.899765 loss)
I0424 01:21:01.888756 16565 sgd_solver.cpp:106] Iteration 79900, lr = 2.7e-06
I0424 01:22:39.060708 16565 solver.cpp:454] Snapshotting to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_80000.caffemodel
I0424 01:23:04.872843 16565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/unet_f1_3/unet_f1_3_iter_80000.solverstate
